id,quality_attribute,keyword,matched_word,match_idx,sentence,source,filename,author,repo,version,wiki,url
https://root.cern/doc/master/NeuralNet_8h_source.html:17965,Usability,clear,clear,17965,"tInputBegin (other.m_itInputBegin); 541 , m_itInputEnd (other.m_itInputEnd); 542 , m_deltas (std::move(other.m_deltas)); 543 , m_valueGradients (std::move(other.m_valueGradients)); 544 , m_values (std::move(other.m_values)); 545 , m_itDropOut (other.m_itDropOut); 546 , m_hasDropOut (other.m_hasDropOut); 547 , m_itConstWeightBegin (other.m_itConstWeightBegin); 548 , m_itGradientBegin (other.m_itGradientBegin); 549 , m_activationFunction (std::move(other.m_activationFunction)); 550 , m_inverseActivationFunction (std::move(other.m_inverseActivationFunction)); 551 , m_isInputLayer (other.m_isInputLayer); 552 , m_hasWeights (other.m_hasWeights); 553 , m_hasGradients (other.m_hasGradients); 554 , m_eModeOutput (other.m_eModeOutput); 555 {}; 556 ; 557 ; 558 /*! \brief change the input iterators; 559 *; 560 *; 561 * \param itInputBegin indicates the start of the input node vector; 562 * \param itInputEnd indicates the end of the input node vector; 563 *; 564 */; 565 void setInput (const_iterator_type itInputBegin, const_iterator_type itInputEnd); 566 {; 567 m_isInputLayer = true;; 568 m_itInputBegin = itInputBegin;; 569 m_itInputEnd = itInputEnd;; 570 }; 571 ; 572 /*! \brief clear the values and the deltas; 573 *; 574 *; 575 */; 576 void clear (); 577 {; 578 m_values.assign (m_values.size (), 0.0);; 579 m_deltas.assign (m_deltas.size (), 0.0);; 580 }; 581 ; 582 const_iterator_type valuesBegin () const { return m_isInputLayer ? m_itInputBegin : begin (m_values); } ///< returns const iterator to the begin of the (node) values; 583 const_iterator_type valuesEnd () const { return m_isInputLayer ? m_itInputEnd : end (m_values); } ///< returns iterator to the end of the (node) values; 584 ; 585 iterator_type valuesBegin () { assert (!m_isInputLayer); return begin (m_values); } ///< returns iterator to the begin of the (node) values; 586 iterator_type valuesEnd () { assert (!m_isInputLayer); return end (m_values); } ///< returns iterator to the end of the (node) values; 587 ; 588 M",MatchSource.WIKI,doc/master/NeuralNet_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8h_source.html
https://root.cern/doc/master/NeuralNet_8h_source.html:18029,Usability,clear,clear,18029,"tInputBegin (other.m_itInputBegin); 541 , m_itInputEnd (other.m_itInputEnd); 542 , m_deltas (std::move(other.m_deltas)); 543 , m_valueGradients (std::move(other.m_valueGradients)); 544 , m_values (std::move(other.m_values)); 545 , m_itDropOut (other.m_itDropOut); 546 , m_hasDropOut (other.m_hasDropOut); 547 , m_itConstWeightBegin (other.m_itConstWeightBegin); 548 , m_itGradientBegin (other.m_itGradientBegin); 549 , m_activationFunction (std::move(other.m_activationFunction)); 550 , m_inverseActivationFunction (std::move(other.m_inverseActivationFunction)); 551 , m_isInputLayer (other.m_isInputLayer); 552 , m_hasWeights (other.m_hasWeights); 553 , m_hasGradients (other.m_hasGradients); 554 , m_eModeOutput (other.m_eModeOutput); 555 {}; 556 ; 557 ; 558 /*! \brief change the input iterators; 559 *; 560 *; 561 * \param itInputBegin indicates the start of the input node vector; 562 * \param itInputEnd indicates the end of the input node vector; 563 *; 564 */; 565 void setInput (const_iterator_type itInputBegin, const_iterator_type itInputEnd); 566 {; 567 m_isInputLayer = true;; 568 m_itInputBegin = itInputBegin;; 569 m_itInputEnd = itInputEnd;; 570 }; 571 ; 572 /*! \brief clear the values and the deltas; 573 *; 574 *; 575 */; 576 void clear (); 577 {; 578 m_values.assign (m_values.size (), 0.0);; 579 m_deltas.assign (m_deltas.size (), 0.0);; 580 }; 581 ; 582 const_iterator_type valuesBegin () const { return m_isInputLayer ? m_itInputBegin : begin (m_values); } ///< returns const iterator to the begin of the (node) values; 583 const_iterator_type valuesEnd () const { return m_isInputLayer ? m_itInputEnd : end (m_values); } ///< returns iterator to the end of the (node) values; 584 ; 585 iterator_type valuesBegin () { assert (!m_isInputLayer); return begin (m_values); } ///< returns iterator to the begin of the (node) values; 586 iterator_type valuesEnd () { assert (!m_isInputLayer); return end (m_values); } ///< returns iterator to the end of the (node) values; 587 ; 588 M",MatchSource.WIKI,doc/master/NeuralNet_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8h_source.html
https://root.cern/doc/master/NeuralNet_8h_source.html:21134,Usability,clear,clear,21134,turns const iterator to the end of the gradients; 602 ; 603 iterator_type gradientsBegin () { assert (m_hasGradients); return m_itGradientBegin; } ///< returns iterator to the begin of the gradients; 604 const_iterator_type gradientsBegin () const { assert (m_hasGradients); return m_itGradientBegin; } ///< returns const iterator to the begin of the gradients; 605 const_iterator_type weightsBegin () const { assert (m_hasWeights); return m_itConstWeightBegin; } ///< returns const iterator to the begin of the weights for this layer; 606 ; 607 std::shared_ptr<std::function<double(double)>> activationFunction () const { return m_activationFunction; }; 608 std::shared_ptr<std::function<double(double)>> inverseActivationFunction () const { return m_inverseActivationFunction; }; 609 ; 610 /*! \brief set the drop-out info for this layer; 611 *; 612 */; 613 template <typename Iterator>; 614 void setDropOut (Iterator itDrop) { m_itDropOut = itDrop; m_hasDropOut = true; }; 615 ; 616 /*! \brief clear the drop-out-data for this layer; 617 *; 618 *; 619 */; 620 void clearDropOut () { m_hasDropOut = false; }; 621 ; 622 bool hasDropOut () const { return m_hasDropOut; } ///< has this layer drop-out turned on?; 623 const_dropout_iterator dropOut () const { assert (m_hasDropOut); return m_itDropOut; } ///< return the begin of the drop-out information; 624 ; 625 size_t size () const { return m_size; } ///< return the size of the layer; 626 ; 627 private:; 628 ; 629 /*! \brief compute the probabilities from the node values; 630 *; 631 *; 632 */; 633 container_type computeProbabilities () const;; 634 ; 635 private:; 636 ; 637 size_t m_size; ////< layer size; 638 ; 639 const_iterator_type m_itInputBegin; ///< iterator to the first of the nodes in the input node vector; 640 const_iterator_type m_itInputEnd; ///< iterator to the end of the nodes in the input node vector; 641 ; 642 std::vector<double> m_deltas; ///< stores the deltas for the DNN training; 643 std::vector<double> m_valueGradie,MatchSource.WIKI,doc/master/NeuralNet_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8h_source.html
https://root.cern/doc/master/NeuralNet_8h_source.html:21205,Usability,clear,clearDropOut,21205,gradientsBegin () { assert (m_hasGradients); return m_itGradientBegin; } ///< returns iterator to the begin of the gradients; 604 const_iterator_type gradientsBegin () const { assert (m_hasGradients); return m_itGradientBegin; } ///< returns const iterator to the begin of the gradients; 605 const_iterator_type weightsBegin () const { assert (m_hasWeights); return m_itConstWeightBegin; } ///< returns const iterator to the begin of the weights for this layer; 606 ; 607 std::shared_ptr<std::function<double(double)>> activationFunction () const { return m_activationFunction; }; 608 std::shared_ptr<std::function<double(double)>> inverseActivationFunction () const { return m_inverseActivationFunction; }; 609 ; 610 /*! \brief set the drop-out info for this layer; 611 *; 612 */; 613 template <typename Iterator>; 614 void setDropOut (Iterator itDrop) { m_itDropOut = itDrop; m_hasDropOut = true; }; 615 ; 616 /*! \brief clear the drop-out-data for this layer; 617 *; 618 *; 619 */; 620 void clearDropOut () { m_hasDropOut = false; }; 621 ; 622 bool hasDropOut () const { return m_hasDropOut; } ///< has this layer drop-out turned on?; 623 const_dropout_iterator dropOut () const { assert (m_hasDropOut); return m_itDropOut; } ///< return the begin of the drop-out information; 624 ; 625 size_t size () const { return m_size; } ///< return the size of the layer; 626 ; 627 private:; 628 ; 629 /*! \brief compute the probabilities from the node values; 630 *; 631 *; 632 */; 633 container_type computeProbabilities () const;; 634 ; 635 private:; 636 ; 637 size_t m_size; ////< layer size; 638 ; 639 const_iterator_type m_itInputBegin; ///< iterator to the first of the nodes in the input node vector; 640 const_iterator_type m_itInputEnd; ///< iterator to the end of the nodes in the input node vector; 641 ; 642 std::vector<double> m_deltas; ///< stores the deltas for the DNN training; 643 std::vector<double> m_valueGradients; ///< stores the gradients of the values (nodes); 644 std::vector<doubl,MatchSource.WIKI,doc/master/NeuralNet_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8h_source.html
https://root.cern/doc/master/NeuralNet_8h_source.html:27845,Usability,learn,learningRate,27845," ; 752 /*! \brief set the drop-out configuration (layer-wise); 753 *; 754 * \param begin begin of an array or vector denoting the drop-out probabilities for each layer; 755 * \param end end of an array or vector denoting the drop-out probabilities for each layer; 756 * \param _dropRepetitions denotes after how many repetitions the drop-out setting (which nodes are dropped out exactly) is changed; 757 */; 758 template <typename Iterator>; 759 void setDropOut (Iterator begin, Iterator end, size_t _dropRepetitions) { m_dropOut.assign (begin, end); m_dropRepetitions = _dropRepetitions; }; 760 ; 761 size_t dropRepetitions () const { return m_dropRepetitions; }; 762 const std::vector<double>& dropFractions () const { return m_dropOut; }; 763 ; 764 void setMonitoring (std::shared_ptr<Monitoring> ptrMonitoring) { fMonitoring = ptrMonitoring; } ///< prepared for monitoring; 765 ; 766 size_t convergenceSteps () const { return m_convergenceSteps; } ///< how many steps until training is deemed to have converged; 767 size_t batchSize () const { return m_batchSize; } ///< mini-batch size; 768 size_t testRepetitions () const { return m_testRepetitions; } ///< how often is the test data tested; 769 double factorWeightDecay () const { return m_factorWeightDecay; } ///< get the weight-decay factor; 770 ; 771 double learningRate () const { return fLearningRate; } ///< get the learning rate; 772 double momentum () const { return fMomentum; } ///< get the momentum (e.g. for SGD); 773 int repetitions () const { return fRepetitions; } ///< how many steps have to be gone until the batch is changed; 774 MinimizerType minimizerType () const { return fMinimizerType; } ///< which minimizer shall be used (e.g. SGD); 775 ; 776 ; 777 ; 778 ; 779 ; 780 ; 781 virtual void testSample (double /*error*/, double /*output*/, double /*target*/, double /*weight*/) {} ///< virtual function to be used for monitoring (callback); 782 virtual void startTrainCycle () ///< callback for monitoring and logging; 783",MatchSource.WIKI,doc/master/NeuralNet_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8h_source.html
https://root.cern/doc/master/NeuralNet_8h_source.html:27906,Usability,learn,learning,27906," ; 752 /*! \brief set the drop-out configuration (layer-wise); 753 *; 754 * \param begin begin of an array or vector denoting the drop-out probabilities for each layer; 755 * \param end end of an array or vector denoting the drop-out probabilities for each layer; 756 * \param _dropRepetitions denotes after how many repetitions the drop-out setting (which nodes are dropped out exactly) is changed; 757 */; 758 template <typename Iterator>; 759 void setDropOut (Iterator begin, Iterator end, size_t _dropRepetitions) { m_dropOut.assign (begin, end); m_dropRepetitions = _dropRepetitions; }; 760 ; 761 size_t dropRepetitions () const { return m_dropRepetitions; }; 762 const std::vector<double>& dropFractions () const { return m_dropOut; }; 763 ; 764 void setMonitoring (std::shared_ptr<Monitoring> ptrMonitoring) { fMonitoring = ptrMonitoring; } ///< prepared for monitoring; 765 ; 766 size_t convergenceSteps () const { return m_convergenceSteps; } ///< how many steps until training is deemed to have converged; 767 size_t batchSize () const { return m_batchSize; } ///< mini-batch size; 768 size_t testRepetitions () const { return m_testRepetitions; } ///< how often is the test data tested; 769 double factorWeightDecay () const { return m_factorWeightDecay; } ///< get the weight-decay factor; 770 ; 771 double learningRate () const { return fLearningRate; } ///< get the learning rate; 772 double momentum () const { return fMomentum; } ///< get the momentum (e.g. for SGD); 773 int repetitions () const { return fRepetitions; } ///< how many steps have to be gone until the batch is changed; 774 MinimizerType minimizerType () const { return fMinimizerType; } ///< which minimizer shall be used (e.g. SGD); 775 ; 776 ; 777 ; 778 ; 779 ; 780 ; 781 virtual void testSample (double /*error*/, double /*output*/, double /*target*/, double /*weight*/) {} ///< virtual function to be used for monitoring (callback); 782 virtual void startTrainCycle () ///< callback for monitoring and logging; 783",MatchSource.WIKI,doc/master/NeuralNet_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8h_source.html
https://root.cern/doc/master/NeuralNet_8h_source.html:29115,Usability,progress bar,progress bar,29115," often is the test data tested; 769 double factorWeightDecay () const { return m_factorWeightDecay; } ///< get the weight-decay factor; 770 ; 771 double learningRate () const { return fLearningRate; } ///< get the learning rate; 772 double momentum () const { return fMomentum; } ///< get the momentum (e.g. for SGD); 773 int repetitions () const { return fRepetitions; } ///< how many steps have to be gone until the batch is changed; 774 MinimizerType minimizerType () const { return fMinimizerType; } ///< which minimizer shall be used (e.g. SGD); 775 ; 776 ; 777 ; 778 ; 779 ; 780 ; 781 virtual void testSample (double /*error*/, double /*output*/, double /*target*/, double /*weight*/) {} ///< virtual function to be used for monitoring (callback); 782 virtual void startTrainCycle () ///< callback for monitoring and logging; 783 {; 784 m_convergenceCount = 0;; 785 m_maxConvergenceCount= 0;; 786 m_minError = 1e10;; 787 }; 788 virtual void endTrainCycle (double /*error*/) {} ///< callback for monitoring and logging; 789 ; 790 virtual void setProgressLimits (double minProgress = 0, double maxProgress = 100) ///< for monitoring and logging (set the current ""progress"" limits for the display of the progress) \param minProgress minimum value \param maxProgress maximum value; 791 {; 792 m_minProgress = minProgress;; 793 m_maxProgress = maxProgress;; 794 }; 795 virtual void startTraining () ///< start drawing the progress bar; 796 {; 797 m_timer.DrawProgressBar (Int_t(m_minProgress));; 798 }; 799 virtual void cycle (double progress, TString text) ///< advance on the progress bar \param progress the new value \param text a label; 800 {; 801 m_timer.DrawProgressBar (Int_t(m_minProgress+(m_maxProgress-m_minProgress)*(progress/100.0)), text);; 802 }; 803 ; 804 virtual void startTestCycle () {} ///< callback for monitoring and loggging; 805 virtual void endTestCycle () {} ///< callback for monitoring and loggging; 806 virtual void testIteration () {} ///< callback for monitoring and l",MatchSource.WIKI,doc/master/NeuralNet_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8h_source.html
https://root.cern/doc/master/NeuralNet_8h_source.html:29271,Usability,progress bar,progress bar,29271,"6 ; 777 ; 778 ; 779 ; 780 ; 781 virtual void testSample (double /*error*/, double /*output*/, double /*target*/, double /*weight*/) {} ///< virtual function to be used for monitoring (callback); 782 virtual void startTrainCycle () ///< callback for monitoring and logging; 783 {; 784 m_convergenceCount = 0;; 785 m_maxConvergenceCount= 0;; 786 m_minError = 1e10;; 787 }; 788 virtual void endTrainCycle (double /*error*/) {} ///< callback for monitoring and logging; 789 ; 790 virtual void setProgressLimits (double minProgress = 0, double maxProgress = 100) ///< for monitoring and logging (set the current ""progress"" limits for the display of the progress) \param minProgress minimum value \param maxProgress maximum value; 791 {; 792 m_minProgress = minProgress;; 793 m_maxProgress = maxProgress;; 794 }; 795 virtual void startTraining () ///< start drawing the progress bar; 796 {; 797 m_timer.DrawProgressBar (Int_t(m_minProgress));; 798 }; 799 virtual void cycle (double progress, TString text) ///< advance on the progress bar \param progress the new value \param text a label; 800 {; 801 m_timer.DrawProgressBar (Int_t(m_minProgress+(m_maxProgress-m_minProgress)*(progress/100.0)), text);; 802 }; 803 ; 804 virtual void startTestCycle () {} ///< callback for monitoring and loggging; 805 virtual void endTestCycle () {} ///< callback for monitoring and loggging; 806 virtual void testIteration () {} ///< callback for monitoring and loggging; 807 virtual void drawSample (const std::vector<double>& /*input*/, const std::vector<double>& /* output */, const std::vector<double>& /* target */, double /* patternWeight */) {} ///< callback for monitoring and logging; 808 ; 809 virtual void computeResult (const Net& /* net */, std::vector<double>& /* weights */) {} ///< callback for monitoring and logging; 810 ; 811 virtual bool hasConverged (double testError); ///< has this training converged already?; 812 ; 813 EnumRegularization regularization () const { return m_regularization; } ///< s",MatchSource.WIKI,doc/master/NeuralNet_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8h_source.html
https://root.cern/doc/master/NeuralNet_8h_source.html:31375,Usability,clear,clear,31375,"multithreading turned on?; 816 ; 817 ; 818 void pads (int numPads) { if (fMonitoring) fMonitoring->pads (numPads); } ///< preparation for monitoring; 819 void create (std::string histoName, int bins, double min, double max) { if (fMonitoring) fMonitoring->create (histoName, bins, min, max); } ///< for monitoring; 820 void create (std::string histoName, int bins, double min, double max, int bins2, double min2, double max2) { if (fMonitoring) fMonitoring->create (histoName, bins, min, max, bins2, min2, max2); } ///< for monitoring; 821 void addPoint (std::string histoName, double x) { if (fMonitoring) fMonitoring->addPoint (histoName, x); } ///< for monitoring; 822 void addPoint (std::string histoName, double x, double y) {if (fMonitoring) fMonitoring->addPoint (histoName, x, y); } ///< for monitoring; 823 void plot (std::string histoName, std::string options, int pad, EColor color) { if (fMonitoring) fMonitoring->plot (histoName, options, pad, color); } ///< for monitoring; 824 void clear (std::string histoName) { if (fMonitoring) fMonitoring->clear (histoName); } ///< for monitoring; 825 bool exists (std::string histoName) { if (fMonitoring) return fMonitoring->exists (histoName); return false; } ///< for monitoring; 826 ; 827 size_t convergenceCount () const { return m_convergenceCount; } ///< returns the current convergence count; 828 size_t maxConvergenceCount () const { return m_maxConvergenceCount; } ///< returns the max convergence count so far; 829 size_t minError () const { return m_minError; } ///< returns the smallest error so far; 830 ; 831 public:; 832 Timer m_timer; ///< timer for monitoring; 833 double m_minProgress; ///< current limits for the progress bar; 834 double m_maxProgress; ///< current limits for the progress bar; 835 ; 836 ; 837 size_t m_convergenceSteps; ///< number of steps without improvement to consider the DNN to have converged; 838 size_t m_batchSize; ///< mini-batch size; 839 size_t m_testRepetitions;; 840 double m_factorWeightDecay;",MatchSource.WIKI,doc/master/NeuralNet_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8h_source.html
https://root.cern/doc/master/NeuralNet_8h_source.html:31437,Usability,clear,clear,31437,"ads) { if (fMonitoring) fMonitoring->pads (numPads); } ///< preparation for monitoring; 819 void create (std::string histoName, int bins, double min, double max) { if (fMonitoring) fMonitoring->create (histoName, bins, min, max); } ///< for monitoring; 820 void create (std::string histoName, int bins, double min, double max, int bins2, double min2, double max2) { if (fMonitoring) fMonitoring->create (histoName, bins, min, max, bins2, min2, max2); } ///< for monitoring; 821 void addPoint (std::string histoName, double x) { if (fMonitoring) fMonitoring->addPoint (histoName, x); } ///< for monitoring; 822 void addPoint (std::string histoName, double x, double y) {if (fMonitoring) fMonitoring->addPoint (histoName, x, y); } ///< for monitoring; 823 void plot (std::string histoName, std::string options, int pad, EColor color) { if (fMonitoring) fMonitoring->plot (histoName, options, pad, color); } ///< for monitoring; 824 void clear (std::string histoName) { if (fMonitoring) fMonitoring->clear (histoName); } ///< for monitoring; 825 bool exists (std::string histoName) { if (fMonitoring) return fMonitoring->exists (histoName); return false; } ///< for monitoring; 826 ; 827 size_t convergenceCount () const { return m_convergenceCount; } ///< returns the current convergence count; 828 size_t maxConvergenceCount () const { return m_maxConvergenceCount; } ///< returns the max convergence count so far; 829 size_t minError () const { return m_minError; } ///< returns the smallest error so far; 830 ; 831 public:; 832 Timer m_timer; ///< timer for monitoring; 833 double m_minProgress; ///< current limits for the progress bar; 834 double m_maxProgress; ///< current limits for the progress bar; 835 ; 836 ; 837 size_t m_convergenceSteps; ///< number of steps without improvement to consider the DNN to have converged; 838 size_t m_batchSize; ///< mini-batch size; 839 size_t m_testRepetitions;; 840 double m_factorWeightDecay;; 841 ; 842 size_t count_E;; 843 size_t count_dE;; 844 size_t ",MatchSource.WIKI,doc/master/NeuralNet_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8h_source.html
https://root.cern/doc/master/NeuralNet_8h_source.html:32065,Usability,progress bar,progress bar,32065,"tring histoName, double x, double y) {if (fMonitoring) fMonitoring->addPoint (histoName, x, y); } ///< for monitoring; 823 void plot (std::string histoName, std::string options, int pad, EColor color) { if (fMonitoring) fMonitoring->plot (histoName, options, pad, color); } ///< for monitoring; 824 void clear (std::string histoName) { if (fMonitoring) fMonitoring->clear (histoName); } ///< for monitoring; 825 bool exists (std::string histoName) { if (fMonitoring) return fMonitoring->exists (histoName); return false; } ///< for monitoring; 826 ; 827 size_t convergenceCount () const { return m_convergenceCount; } ///< returns the current convergence count; 828 size_t maxConvergenceCount () const { return m_maxConvergenceCount; } ///< returns the max convergence count so far; 829 size_t minError () const { return m_minError; } ///< returns the smallest error so far; 830 ; 831 public:; 832 Timer m_timer; ///< timer for monitoring; 833 double m_minProgress; ///< current limits for the progress bar; 834 double m_maxProgress; ///< current limits for the progress bar; 835 ; 836 ; 837 size_t m_convergenceSteps; ///< number of steps without improvement to consider the DNN to have converged; 838 size_t m_batchSize; ///< mini-batch size; 839 size_t m_testRepetitions;; 840 double m_factorWeightDecay;; 841 ; 842 size_t count_E;; 843 size_t count_dE;; 844 size_t count_mb_E;; 845 size_t count_mb_dE;; 846 ; 847 EnumRegularization m_regularization;; 848 ; 849 double m_dropRepetitions;; 850 std::vector<double> m_dropOut;; 851 ; 852 double fLearningRate;; 853 double fMomentum;; 854 int fRepetitions;; 855 MinimizerType fMinimizerType;; 856 ; 857 size_t m_convergenceCount;; 858 size_t m_maxConvergenceCount;; 859 double m_minError;; 860 ; 861 ; 862 protected:; 863 bool m_useMultithreading;; 864 ; 865 std::shared_ptr<Monitoring> fMonitoring;; 866 };; 867 ; 868 ; 869 ; 870 ; 871 ; 872 ; 873 ; 874 ; 875 ; 876 ; 877 ; 878 ; 879 ; 880 ; 881 ; 882 ; 883 ; 884 ; 885 ; 886 ; 887 ; 888 ; 889 ; 890 /",MatchSource.WIKI,doc/master/NeuralNet_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8h_source.html
https://root.cern/doc/master/NeuralNet_8h_source.html:32133,Usability,progress bar,progress bar,32133,"addPoint (histoName, x, y); } ///< for monitoring; 823 void plot (std::string histoName, std::string options, int pad, EColor color) { if (fMonitoring) fMonitoring->plot (histoName, options, pad, color); } ///< for monitoring; 824 void clear (std::string histoName) { if (fMonitoring) fMonitoring->clear (histoName); } ///< for monitoring; 825 bool exists (std::string histoName) { if (fMonitoring) return fMonitoring->exists (histoName); return false; } ///< for monitoring; 826 ; 827 size_t convergenceCount () const { return m_convergenceCount; } ///< returns the current convergence count; 828 size_t maxConvergenceCount () const { return m_maxConvergenceCount; } ///< returns the max convergence count so far; 829 size_t minError () const { return m_minError; } ///< returns the smallest error so far; 830 ; 831 public:; 832 Timer m_timer; ///< timer for monitoring; 833 double m_minProgress; ///< current limits for the progress bar; 834 double m_maxProgress; ///< current limits for the progress bar; 835 ; 836 ; 837 size_t m_convergenceSteps; ///< number of steps without improvement to consider the DNN to have converged; 838 size_t m_batchSize; ///< mini-batch size; 839 size_t m_testRepetitions;; 840 double m_factorWeightDecay;; 841 ; 842 size_t count_E;; 843 size_t count_dE;; 844 size_t count_mb_E;; 845 size_t count_mb_dE;; 846 ; 847 EnumRegularization m_regularization;; 848 ; 849 double m_dropRepetitions;; 850 std::vector<double> m_dropOut;; 851 ; 852 double fLearningRate;; 853 double fMomentum;; 854 int fRepetitions;; 855 MinimizerType fMinimizerType;; 856 ; 857 size_t m_convergenceCount;; 858 size_t m_maxConvergenceCount;; 859 double m_minError;; 860 ; 861 ; 862 protected:; 863 bool m_useMultithreading;; 864 ; 865 std::shared_ptr<Monitoring> fMonitoring;; 866 };; 867 ; 868 ; 869 ; 870 ; 871 ; 872 ; 873 ; 874 ; 875 ; 876 ; 877 ; 878 ; 879 ; 880 ; 881 ; 882 ; 883 ; 884 ; 885 ; 886 ; 887 ; 888 ; 889 ; 890 /*! \brief Settings for classification; 891 *; 892 * contains additio",MatchSource.WIKI,doc/master/NeuralNet_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8h_source.html
https://root.cern/doc/master/NeuralNet_8h_source.html:45920,Usability,clear,clear,45920,"Container& layers, PassThrough& settingsAndBatch,; 1220 ItWeight itWeightBegin, ItWeight itWeightEnd,; 1221 ItGradient itGradientBegin, ItGradient itGradientEnd,; 1222 size_t trainFromLayer,; 1223 OutContainer& outputContainer, bool fetchOutput) const;; 1224 ; 1225 ; 1226 ; 1227 double E ();; 1228 void dE ();; 1229 ; 1230 ; 1231 /*! \brief computes the error of the DNN; 1232 *; 1233 *; 1234 */; 1235 template <typename Container, typename ItWeight>; 1236 double errorFunction (LayerData& layerData,; 1237 Container truth,; 1238 ItWeight itWeight,; 1239 ItWeight itWeightEnd,; 1240 double patternWeight,; 1241 double factorWeightDecay,; 1242 EnumRegularization eRegularization) const;; 1243 ; 1244 ; 1245 const std::vector<Layer>& layers () const { return m_layers; } ///< returns the layers (structure); 1246 std::vector<Layer>& layers () { return m_layers; } ///< returns the layers (structure); 1247 ; 1248 void removeLayer () { m_layers.pop_back (); } ///< remove one layer; 1249 ; 1250 ; 1251 void clear () ///< clear one layer; 1252 {; 1253 m_layers.clear ();; 1254 m_eErrorFunction = ModeErrorFunction::SUMOFSQUARES;; 1255 }; 1256 ; 1257 ; 1258 template <typename OutIterator>; 1259 void initializeWeights (WeightInitializationStrategy eInitStrategy,; 1260 OutIterator itWeight); ///< initialize the weights with the given strategy; 1261 ; 1262 protected:; 1263 ; 1264 void fillDropContainer (DropContainer& dropContainer, double dropFraction, size_t numNodes) const; ///< prepare the drop-out-container (select the nodes which are to be dropped out); 1265 ; 1266 ; 1267 private:; 1268 ; 1269 ModeErrorFunction m_eErrorFunction; ///< denotes the error function; 1270 size_t m_sizeInput; ///< input size of this DNN; 1271 size_t m_sizeOutput; ///< output size of this DNN; 1272 std::vector<Layer> m_layers; ///< layer-structure-data; 1273 ; 1274 protected:; 1275 // variables for JsMVA (interactive training in jupyter notebook); 1276 IPythonInteractive *fInteractive = nullptr;; 1277 bool * f",MatchSource.WIKI,doc/master/NeuralNet_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8h_source.html
https://root.cern/doc/master/NeuralNet_8h_source.html:45934,Usability,clear,clear,45934,"Container& layers, PassThrough& settingsAndBatch,; 1220 ItWeight itWeightBegin, ItWeight itWeightEnd,; 1221 ItGradient itGradientBegin, ItGradient itGradientEnd,; 1222 size_t trainFromLayer,; 1223 OutContainer& outputContainer, bool fetchOutput) const;; 1224 ; 1225 ; 1226 ; 1227 double E ();; 1228 void dE ();; 1229 ; 1230 ; 1231 /*! \brief computes the error of the DNN; 1232 *; 1233 *; 1234 */; 1235 template <typename Container, typename ItWeight>; 1236 double errorFunction (LayerData& layerData,; 1237 Container truth,; 1238 ItWeight itWeight,; 1239 ItWeight itWeightEnd,; 1240 double patternWeight,; 1241 double factorWeightDecay,; 1242 EnumRegularization eRegularization) const;; 1243 ; 1244 ; 1245 const std::vector<Layer>& layers () const { return m_layers; } ///< returns the layers (structure); 1246 std::vector<Layer>& layers () { return m_layers; } ///< returns the layers (structure); 1247 ; 1248 void removeLayer () { m_layers.pop_back (); } ///< remove one layer; 1249 ; 1250 ; 1251 void clear () ///< clear one layer; 1252 {; 1253 m_layers.clear ();; 1254 m_eErrorFunction = ModeErrorFunction::SUMOFSQUARES;; 1255 }; 1256 ; 1257 ; 1258 template <typename OutIterator>; 1259 void initializeWeights (WeightInitializationStrategy eInitStrategy,; 1260 OutIterator itWeight); ///< initialize the weights with the given strategy; 1261 ; 1262 protected:; 1263 ; 1264 void fillDropContainer (DropContainer& dropContainer, double dropFraction, size_t numNodes) const; ///< prepare the drop-out-container (select the nodes which are to be dropped out); 1265 ; 1266 ; 1267 private:; 1268 ; 1269 ModeErrorFunction m_eErrorFunction; ///< denotes the error function; 1270 size_t m_sizeInput; ///< input size of this DNN; 1271 size_t m_sizeOutput; ///< output size of this DNN; 1272 std::vector<Layer> m_layers; ///< layer-structure-data; 1273 ; 1274 protected:; 1275 // variables for JsMVA (interactive training in jupyter notebook); 1276 IPythonInteractive *fInteractive = nullptr;; 1277 bool * f",MatchSource.WIKI,doc/master/NeuralNet_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8h_source.html
https://root.cern/doc/master/NeuralNet_8h_source.html:45973,Usability,clear,clear,45973,"ers (structure); 1247 ; 1248 void removeLayer () { m_layers.pop_back (); } ///< remove one layer; 1249 ; 1250 ; 1251 void clear () ///< clear one layer; 1252 {; 1253 m_layers.clear ();; 1254 m_eErrorFunction = ModeErrorFunction::SUMOFSQUARES;; 1255 }; 1256 ; 1257 ; 1258 template <typename OutIterator>; 1259 void initializeWeights (WeightInitializationStrategy eInitStrategy,; 1260 OutIterator itWeight); ///< initialize the weights with the given strategy; 1261 ; 1262 protected:; 1263 ; 1264 void fillDropContainer (DropContainer& dropContainer, double dropFraction, size_t numNodes) const; ///< prepare the drop-out-container (select the nodes which are to be dropped out); 1265 ; 1266 ; 1267 private:; 1268 ; 1269 ModeErrorFunction m_eErrorFunction; ///< denotes the error function; 1270 size_t m_sizeInput; ///< input size of this DNN; 1271 size_t m_sizeOutput; ///< output size of this DNN; 1272 std::vector<Layer> m_layers; ///< layer-structure-data; 1273 ; 1274 protected:; 1275 // variables for JsMVA (interactive training in jupyter notebook); 1276 IPythonInteractive *fInteractive = nullptr;; 1277 bool * fExitFromTraining = nullptr;; 1278 UInt_t *fIPyMaxIter = nullptr, *fIPyCurrentIter = nullptr;; 1279 ; 1280 public:; 1281 ; 1282 // setup ipython interactive variables; 1283 void SetIpythonInteractive(IPythonInteractive* fI, bool* fE, UInt_t *M, UInt_t *C){; 1284 fInteractive = fI;; 1285 fExitFromTraining = fE;; 1286 fIPyMaxIter = M;; 1287 fIPyCurrentIter = C;; 1288 }; 1289 };; 1290 ; 1291 ; 1292 ; 1293 ; 1294typedef std::tuple<Settings&, Batch&, DropContainer&> pass_through_type;; 1295 ; 1296 ; 1297 ; 1298 ; 1299 ; 1300 ; 1301 ; 1302 } // namespace DNN; 1303} // namespace TMVA; 1304 ; 1305 ; 1306// include the implementations (in header file, because they are templated); 1307#include ""TMVA/NeuralNet.icc""; 1308 ; 1309#endif; 1310 ; Monitoring.h; NeuralNet.icc; Pattern.h; R#define R(a, b, c, d, e, f, g, h, i)Definition RSha256.hxx:110; e#define e(i)Definition RSha256.hxx:10",MatchSource.WIKI,doc/master/NeuralNet_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8h_source.html
https://root.cern/doc/master/NeuralNet_8h_source.html:58910,Usability,clear,clearvoid,58910,et.h:649; TMVA::DNN::LayerData::gradientsBeginconst_iterator_type gradientsBegin() constreturns const iterator to the begin of the gradientsDefinition NeuralNet.h:604; TMVA::DNN::LayerData::inverseActivationFunctionstd::shared_ptr< std::function< double(double)> > inverseActivationFunction() constDefinition NeuralNet.h:608; TMVA::DNN::LayerData::deltasEnditerator_type deltasEnd()returns iterator to the end of the deltas (back-propagation)Definition NeuralNet.h:592; TMVA::DNN::LayerData::m_valueGradientsstd::vector< double > m_valueGradientsstores the gradients of the values (nodes)Definition NeuralNet.h:643; TMVA::DNN::LayerData::m_itConstWeightBeginconst_iterator_type m_itConstWeightBeginconst iterator to the first weight of this layer in the weight vectorDefinition NeuralNet.h:648; TMVA::DNN::LayerData::valueGradientsEnditerator_type valueGradientsEnd()returns iterator to the end of the gradients of the node valuesDefinition NeuralNet.h:598; TMVA::DNN::LayerData::clearvoid clear()clear the values and the deltasDefinition NeuralNet.h:576; TMVA::DNN::LayerData::activationFunctionstd::shared_ptr< std::function< double(double)> > activationFunction() constDefinition NeuralNet.h:607; TMVA::DNN::LayerData::computeProbabilitiescontainer_type computeProbabilities() constcompute the probabilities from the node valuesDefinition NeuralNet.cxx:140; TMVA::DNN::LayerData::deltasEndconst_iterator_type deltasEnd() constreturns const iterator to the end of the deltas (back-propagation)Definition NeuralNet.h:595; TMVA::DNN::LayerData::m_hasDropOutbool m_hasDropOutdropOut is turned on?Definition NeuralNet.h:646; TMVA::DNN::LayerData::m_isInputLayerbool m_isInputLayeris this layer an input layerDefinition NeuralNet.h:654; TMVA::DNN::LayerData::m_sizesize_t m_sizeDefinition NeuralNet.h:637; TMVA::DNN::LayerData::hasDropOutbool hasDropOut() consthas this layer drop-out turned on?Definition NeuralNet.h:622; TMVA::DNN::LayerData::valueGradientsBeginconst_iterator_type valueGradientsBegin,MatchSource.WIKI,doc/master/NeuralNet_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8h_source.html
https://root.cern/doc/master/NeuralNet_8h_source.html:58920,Usability,clear,clear,58920,et.h:649; TMVA::DNN::LayerData::gradientsBeginconst_iterator_type gradientsBegin() constreturns const iterator to the begin of the gradientsDefinition NeuralNet.h:604; TMVA::DNN::LayerData::inverseActivationFunctionstd::shared_ptr< std::function< double(double)> > inverseActivationFunction() constDefinition NeuralNet.h:608; TMVA::DNN::LayerData::deltasEnditerator_type deltasEnd()returns iterator to the end of the deltas (back-propagation)Definition NeuralNet.h:592; TMVA::DNN::LayerData::m_valueGradientsstd::vector< double > m_valueGradientsstores the gradients of the values (nodes)Definition NeuralNet.h:643; TMVA::DNN::LayerData::m_itConstWeightBeginconst_iterator_type m_itConstWeightBeginconst iterator to the first weight of this layer in the weight vectorDefinition NeuralNet.h:648; TMVA::DNN::LayerData::valueGradientsEnditerator_type valueGradientsEnd()returns iterator to the end of the gradients of the node valuesDefinition NeuralNet.h:598; TMVA::DNN::LayerData::clearvoid clear()clear the values and the deltasDefinition NeuralNet.h:576; TMVA::DNN::LayerData::activationFunctionstd::shared_ptr< std::function< double(double)> > activationFunction() constDefinition NeuralNet.h:607; TMVA::DNN::LayerData::computeProbabilitiescontainer_type computeProbabilities() constcompute the probabilities from the node valuesDefinition NeuralNet.cxx:140; TMVA::DNN::LayerData::deltasEndconst_iterator_type deltasEnd() constreturns const iterator to the end of the deltas (back-propagation)Definition NeuralNet.h:595; TMVA::DNN::LayerData::m_hasDropOutbool m_hasDropOutdropOut is turned on?Definition NeuralNet.h:646; TMVA::DNN::LayerData::m_isInputLayerbool m_isInputLayeris this layer an input layerDefinition NeuralNet.h:654; TMVA::DNN::LayerData::m_sizesize_t m_sizeDefinition NeuralNet.h:637; TMVA::DNN::LayerData::hasDropOutbool hasDropOut() consthas this layer drop-out turned on?Definition NeuralNet.h:622; TMVA::DNN::LayerData::valueGradientsBeginconst_iterator_type valueGradientsBegin,MatchSource.WIKI,doc/master/NeuralNet_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8h_source.html
https://root.cern/doc/master/NeuralNet_8h_source.html:58927,Usability,clear,clear,58927,et.h:649; TMVA::DNN::LayerData::gradientsBeginconst_iterator_type gradientsBegin() constreturns const iterator to the begin of the gradientsDefinition NeuralNet.h:604; TMVA::DNN::LayerData::inverseActivationFunctionstd::shared_ptr< std::function< double(double)> > inverseActivationFunction() constDefinition NeuralNet.h:608; TMVA::DNN::LayerData::deltasEnditerator_type deltasEnd()returns iterator to the end of the deltas (back-propagation)Definition NeuralNet.h:592; TMVA::DNN::LayerData::m_valueGradientsstd::vector< double > m_valueGradientsstores the gradients of the values (nodes)Definition NeuralNet.h:643; TMVA::DNN::LayerData::m_itConstWeightBeginconst_iterator_type m_itConstWeightBeginconst iterator to the first weight of this layer in the weight vectorDefinition NeuralNet.h:648; TMVA::DNN::LayerData::valueGradientsEnditerator_type valueGradientsEnd()returns iterator to the end of the gradients of the node valuesDefinition NeuralNet.h:598; TMVA::DNN::LayerData::clearvoid clear()clear the values and the deltasDefinition NeuralNet.h:576; TMVA::DNN::LayerData::activationFunctionstd::shared_ptr< std::function< double(double)> > activationFunction() constDefinition NeuralNet.h:607; TMVA::DNN::LayerData::computeProbabilitiescontainer_type computeProbabilities() constcompute the probabilities from the node valuesDefinition NeuralNet.cxx:140; TMVA::DNN::LayerData::deltasEndconst_iterator_type deltasEnd() constreturns const iterator to the end of the deltas (back-propagation)Definition NeuralNet.h:595; TMVA::DNN::LayerData::m_hasDropOutbool m_hasDropOutdropOut is turned on?Definition NeuralNet.h:646; TMVA::DNN::LayerData::m_isInputLayerbool m_isInputLayeris this layer an input layerDefinition NeuralNet.h:654; TMVA::DNN::LayerData::m_sizesize_t m_sizeDefinition NeuralNet.h:637; TMVA::DNN::LayerData::hasDropOutbool hasDropOut() consthas this layer drop-out turned on?Definition NeuralNet.h:622; TMVA::DNN::LayerData::valueGradientsBeginconst_iterator_type valueGradientsBegin,MatchSource.WIKI,doc/master/NeuralNet_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8h_source.html
https://root.cern/doc/master/NeuralNet_8h_source.html:60373,Usability,clear,clearDropOutvoid,60373,"tas (back-propagation)Definition NeuralNet.h:595; TMVA::DNN::LayerData::m_hasDropOutbool m_hasDropOutdropOut is turned on?Definition NeuralNet.h:646; TMVA::DNN::LayerData::m_isInputLayerbool m_isInputLayeris this layer an input layerDefinition NeuralNet.h:654; TMVA::DNN::LayerData::m_sizesize_t m_sizeDefinition NeuralNet.h:637; TMVA::DNN::LayerData::hasDropOutbool hasDropOut() consthas this layer drop-out turned on?Definition NeuralNet.h:622; TMVA::DNN::LayerData::valueGradientsBeginconst_iterator_type valueGradientsBegin() constreturns const iterator to the begin of the gradientsDefinition NeuralNet.h:600; TMVA::DNN::LayerData::valueGradientsEndconst_iterator_type valueGradientsEnd() constreturns const iterator to the end of the gradientsDefinition NeuralNet.h:601; TMVA::DNN::LayerData::probabilitiescontainer_type probabilities() constcomputes the probabilities from the current node values and returns themDefinition NeuralNet.h:589; TMVA::DNN::LayerData::clearDropOutvoid clearDropOut()clear the drop-out-data for this layerDefinition NeuralNet.h:620; TMVA::DNN::LayerData::m_eModeOutputModeOutputValues m_eModeOutputstores the output mode (DIRECT, SIGMOID, SOFTMAX)Definition NeuralNet.h:658; TMVA::DNN::LayerData::m_inverseActivationFunctionstd::shared_ptr< std::function< double(double)> > m_inverseActivationFunctioninverse activation function for this layerDefinition NeuralNet.h:652; TMVA::DNN::LayerData::const_dropout_iteratorDropContainer::const_iterator const_dropout_iteratorDefinition NeuralNet.h:448; TMVA::DNN::LayerData::valuesBeginconst_iterator_type valuesBegin() constreturns const iterator to the begin of the (node) valuesDefinition NeuralNet.h:582; TMVA::DNN::LayerData::m_activationFunctionstd::shared_ptr< std::function< double(double)> > m_activationFunctionactivation function for this layerDefinition NeuralNet.h:651; TMVA::DNN::LayerLayer defines the layout of a layer.Definition NeuralNet.h:673; TMVA::DNN::Layer::modeOutputValuesvoid modeOutputValues(ModeOu",MatchSource.WIKI,doc/master/NeuralNet_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8h_source.html
https://root.cern/doc/master/NeuralNet_8h_source.html:60390,Usability,clear,clearDropOut,60390,"tas (back-propagation)Definition NeuralNet.h:595; TMVA::DNN::LayerData::m_hasDropOutbool m_hasDropOutdropOut is turned on?Definition NeuralNet.h:646; TMVA::DNN::LayerData::m_isInputLayerbool m_isInputLayeris this layer an input layerDefinition NeuralNet.h:654; TMVA::DNN::LayerData::m_sizesize_t m_sizeDefinition NeuralNet.h:637; TMVA::DNN::LayerData::hasDropOutbool hasDropOut() consthas this layer drop-out turned on?Definition NeuralNet.h:622; TMVA::DNN::LayerData::valueGradientsBeginconst_iterator_type valueGradientsBegin() constreturns const iterator to the begin of the gradientsDefinition NeuralNet.h:600; TMVA::DNN::LayerData::valueGradientsEndconst_iterator_type valueGradientsEnd() constreturns const iterator to the end of the gradientsDefinition NeuralNet.h:601; TMVA::DNN::LayerData::probabilitiescontainer_type probabilities() constcomputes the probabilities from the current node values and returns themDefinition NeuralNet.h:589; TMVA::DNN::LayerData::clearDropOutvoid clearDropOut()clear the drop-out-data for this layerDefinition NeuralNet.h:620; TMVA::DNN::LayerData::m_eModeOutputModeOutputValues m_eModeOutputstores the output mode (DIRECT, SIGMOID, SOFTMAX)Definition NeuralNet.h:658; TMVA::DNN::LayerData::m_inverseActivationFunctionstd::shared_ptr< std::function< double(double)> > m_inverseActivationFunctioninverse activation function for this layerDefinition NeuralNet.h:652; TMVA::DNN::LayerData::const_dropout_iteratorDropContainer::const_iterator const_dropout_iteratorDefinition NeuralNet.h:448; TMVA::DNN::LayerData::valuesBeginconst_iterator_type valuesBegin() constreturns const iterator to the begin of the (node) valuesDefinition NeuralNet.h:582; TMVA::DNN::LayerData::m_activationFunctionstd::shared_ptr< std::function< double(double)> > m_activationFunctionactivation function for this layerDefinition NeuralNet.h:651; TMVA::DNN::LayerLayer defines the layout of a layer.Definition NeuralNet.h:673; TMVA::DNN::Layer::modeOutputValuesvoid modeOutputValues(ModeOu",MatchSource.WIKI,doc/master/NeuralNet_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8h_source.html
https://root.cern/doc/master/NeuralNet_8h_source.html:60404,Usability,clear,clear,60404,"tas (back-propagation)Definition NeuralNet.h:595; TMVA::DNN::LayerData::m_hasDropOutbool m_hasDropOutdropOut is turned on?Definition NeuralNet.h:646; TMVA::DNN::LayerData::m_isInputLayerbool m_isInputLayeris this layer an input layerDefinition NeuralNet.h:654; TMVA::DNN::LayerData::m_sizesize_t m_sizeDefinition NeuralNet.h:637; TMVA::DNN::LayerData::hasDropOutbool hasDropOut() consthas this layer drop-out turned on?Definition NeuralNet.h:622; TMVA::DNN::LayerData::valueGradientsBeginconst_iterator_type valueGradientsBegin() constreturns const iterator to the begin of the gradientsDefinition NeuralNet.h:600; TMVA::DNN::LayerData::valueGradientsEndconst_iterator_type valueGradientsEnd() constreturns const iterator to the end of the gradientsDefinition NeuralNet.h:601; TMVA::DNN::LayerData::probabilitiescontainer_type probabilities() constcomputes the probabilities from the current node values and returns themDefinition NeuralNet.h:589; TMVA::DNN::LayerData::clearDropOutvoid clearDropOut()clear the drop-out-data for this layerDefinition NeuralNet.h:620; TMVA::DNN::LayerData::m_eModeOutputModeOutputValues m_eModeOutputstores the output mode (DIRECT, SIGMOID, SOFTMAX)Definition NeuralNet.h:658; TMVA::DNN::LayerData::m_inverseActivationFunctionstd::shared_ptr< std::function< double(double)> > m_inverseActivationFunctioninverse activation function for this layerDefinition NeuralNet.h:652; TMVA::DNN::LayerData::const_dropout_iteratorDropContainer::const_iterator const_dropout_iteratorDefinition NeuralNet.h:448; TMVA::DNN::LayerData::valuesBeginconst_iterator_type valuesBegin() constreturns const iterator to the begin of the (node) valuesDefinition NeuralNet.h:582; TMVA::DNN::LayerData::m_activationFunctionstd::shared_ptr< std::function< double(double)> > m_activationFunctionactivation function for this layerDefinition NeuralNet.h:651; TMVA::DNN::LayerLayer defines the layout of a layer.Definition NeuralNet.h:673; TMVA::DNN::Layer::modeOutputValuesvoid modeOutputValues(ModeOu",MatchSource.WIKI,doc/master/NeuralNet_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8h_source.html
https://root.cern/doc/master/NeuralNet_8h_source.html:63433,Usability,clear,clearvoid,63433,":numWeightssize_t numWeights(size_t numInputNodes) constreturn the number of weights for this layer (fully connected)Definition NeuralNet.h:686; TMVA::DNN::Layer::inverseActivationFunctionstd::shared_ptr< std::function< double(double)> > inverseActivationFunction() constfetch the inverse activation function for this layerDefinition NeuralNet.h:689; TMVA::DNN::Layer::m_activationFunctionTypeEnumFunction m_activationFunctionTypeDefinition NeuralNet.h:703; TMVA::DNN::Layer::activationFunctionTypeEnumFunction activationFunctionType() constget the activation function type for this layerDefinition NeuralNet.h:691; TMVA::DNN::Layer::modeOutputValuesModeOutputValues modeOutputValues() constget the mode-output-value (direct, probabilities)Definition NeuralNet.h:682; TMVA::DNN::MeanVarianceDefinition NeuralNet.h:75; TMVA::DNN::MeanVariance::meandouble mean() constDefinition NeuralNet.h:126; TMVA::DNN::MeanVariance::MeanVarianceMeanVariance()Definition NeuralNet.h:77; TMVA::DNN::MeanVariance::clearvoid clear()Definition NeuralNet.h:84; TMVA::DNN::MeanVariance::var_corrdouble var_corr() constDefinition NeuralNet.h:136; TMVA::DNN::MeanVariance::countint count() constDefinition NeuralNet.h:124; TMVA::DNN::MeanVariance::addvoid add(T value, double weight=1.0)Definition NeuralNet.h:93; TMVA::DNN::MeanVariance::stdDev_corrdouble stdDev_corr() constDefinition NeuralNet.h:144; TMVA::DNN::MeanVariance::weightsdouble weights() constDefinition NeuralNet.h:125; TMVA::DNN::MeanVariance::m_meandouble m_meanDefinition NeuralNet.h:150; TMVA::DNN::MeanVariance::m_nsize_t m_nDefinition NeuralNet.h:148; TMVA::DNN::MeanVariance::m_squareddouble m_squaredDefinition NeuralNet.h:151; TMVA::DNN::MeanVariance::m_sumWeightsdouble m_sumWeightsDefinition NeuralNet.h:149; TMVA::DNN::MeanVariance::addvoid add(ITERATOR itBegin, ITERATOR itEnd)Definition NeuralNet.h:116; TMVA::DNN::MeanVariance::vardouble var() constDefinition NeuralNet.h:127; TMVA::DNN::MeanVariance::stdDevdouble stdDev() constDefinition Neu",MatchSource.WIKI,doc/master/NeuralNet_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8h_source.html
https://root.cern/doc/master/NeuralNet_8h_source.html:63443,Usability,clear,clear,63443,":numWeightssize_t numWeights(size_t numInputNodes) constreturn the number of weights for this layer (fully connected)Definition NeuralNet.h:686; TMVA::DNN::Layer::inverseActivationFunctionstd::shared_ptr< std::function< double(double)> > inverseActivationFunction() constfetch the inverse activation function for this layerDefinition NeuralNet.h:689; TMVA::DNN::Layer::m_activationFunctionTypeEnumFunction m_activationFunctionTypeDefinition NeuralNet.h:703; TMVA::DNN::Layer::activationFunctionTypeEnumFunction activationFunctionType() constget the activation function type for this layerDefinition NeuralNet.h:691; TMVA::DNN::Layer::modeOutputValuesModeOutputValues modeOutputValues() constget the mode-output-value (direct, probabilities)Definition NeuralNet.h:682; TMVA::DNN::MeanVarianceDefinition NeuralNet.h:75; TMVA::DNN::MeanVariance::meandouble mean() constDefinition NeuralNet.h:126; TMVA::DNN::MeanVariance::MeanVarianceMeanVariance()Definition NeuralNet.h:77; TMVA::DNN::MeanVariance::clearvoid clear()Definition NeuralNet.h:84; TMVA::DNN::MeanVariance::var_corrdouble var_corr() constDefinition NeuralNet.h:136; TMVA::DNN::MeanVariance::countint count() constDefinition NeuralNet.h:124; TMVA::DNN::MeanVariance::addvoid add(T value, double weight=1.0)Definition NeuralNet.h:93; TMVA::DNN::MeanVariance::stdDev_corrdouble stdDev_corr() constDefinition NeuralNet.h:144; TMVA::DNN::MeanVariance::weightsdouble weights() constDefinition NeuralNet.h:125; TMVA::DNN::MeanVariance::m_meandouble m_meanDefinition NeuralNet.h:150; TMVA::DNN::MeanVariance::m_nsize_t m_nDefinition NeuralNet.h:148; TMVA::DNN::MeanVariance::m_squareddouble m_squaredDefinition NeuralNet.h:151; TMVA::DNN::MeanVariance::m_sumWeightsdouble m_sumWeightsDefinition NeuralNet.h:149; TMVA::DNN::MeanVariance::addvoid add(ITERATOR itBegin, ITERATOR itEnd)Definition NeuralNet.h:116; TMVA::DNN::MeanVariance::vardouble var() constDefinition NeuralNet.h:127; TMVA::DNN::MeanVariance::stdDevdouble stdDev() constDefinition Neu",MatchSource.WIKI,doc/master/NeuralNet_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8h_source.html
https://root.cern/doc/master/NeuralNet_8h_source.html:66410,Usability,clear,clearvoid,66410,"vevoid SetIpythonInteractive(IPythonInteractive *fI, bool *fE, UInt_t *M, UInt_t *C)Definition NeuralNet.h:1283; TMVA::DNN::Net::computestd::vector< double > compute(const std::vector< double > &input, const Weights &weights) constcompute the net with the given input and the given weightsDefinition NeuralNet.icc:1037; TMVA::DNN::Net::container_typestd::vector< double > container_typeDefinition NeuralNet.h:1065; TMVA::DNN::Net::iterator_typecontainer_type::iterator iterator_typeDefinition NeuralNet.h:1066; TMVA::DNN::Net::preTrainvoid preTrain(std::vector< double > &weights, std::vector< Pattern > &trainPattern, const std::vector< Pattern > &testPattern, Minimizer &minimizer, Settings &settings)pre-training for future use; TMVA::DNN::Net::fetchOutputvoid fetchOutput(const LayerData &lastLayerData, OutputContainer &outputContainer) constDefinition NeuralNet.icc:1291; TMVA::DNN::Net::inputSizesize_t inputSize() constinput size of the DNNDefinition NeuralNet.h:1098; TMVA::DNN::Net::clearvoid clear()Definition NeuralNet.h:1251; TMVA::DNN::Net::begin_end_typestd::pair< iterator_type, iterator_type > begin_end_typeDefinition NeuralNet.h:1067; TMVA::DNN::Net::m_eErrorFunctionModeErrorFunction m_eErrorFunctiondenotes the error functionDefinition NeuralNet.h:1269; TMVA::DNN::Net::dEvoid dE(); TMVA::DNN::Net::addLayervoid addLayer(Layer &&layer)Definition NeuralNet.h:1095; TMVA::DNN::Net::numNodessize_t numNodes(size_t trainingStartLayer=0) constreturns the number of nodes in this netDefinition NeuralNet.cxx:556; TMVA::DNN::Net::traindouble train(std::vector< double > &weights, std::vector< Pattern > &trainPattern, const std::vector< Pattern > &testPattern, Minimizer &minimizer, Settings &settings)start the trainingDefinition NeuralNet.icc:712; TMVA::DNN::Net::layersconst std::vector< Layer > & layers() constreturns the layers (structure)Definition NeuralNet.h:1245; TMVA::DNN::Net::prepareLayerDatastd::vector< std::vector< LayerData > > prepareLayerData(LayerContainer &layers,",MatchSource.WIKI,doc/master/NeuralNet_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8h_source.html
https://root.cern/doc/master/NeuralNet_8h_source.html:66420,Usability,clear,clear,66420,"vevoid SetIpythonInteractive(IPythonInteractive *fI, bool *fE, UInt_t *M, UInt_t *C)Definition NeuralNet.h:1283; TMVA::DNN::Net::computestd::vector< double > compute(const std::vector< double > &input, const Weights &weights) constcompute the net with the given input and the given weightsDefinition NeuralNet.icc:1037; TMVA::DNN::Net::container_typestd::vector< double > container_typeDefinition NeuralNet.h:1065; TMVA::DNN::Net::iterator_typecontainer_type::iterator iterator_typeDefinition NeuralNet.h:1066; TMVA::DNN::Net::preTrainvoid preTrain(std::vector< double > &weights, std::vector< Pattern > &trainPattern, const std::vector< Pattern > &testPattern, Minimizer &minimizer, Settings &settings)pre-training for future use; TMVA::DNN::Net::fetchOutputvoid fetchOutput(const LayerData &lastLayerData, OutputContainer &outputContainer) constDefinition NeuralNet.icc:1291; TMVA::DNN::Net::inputSizesize_t inputSize() constinput size of the DNNDefinition NeuralNet.h:1098; TMVA::DNN::Net::clearvoid clear()Definition NeuralNet.h:1251; TMVA::DNN::Net::begin_end_typestd::pair< iterator_type, iterator_type > begin_end_typeDefinition NeuralNet.h:1067; TMVA::DNN::Net::m_eErrorFunctionModeErrorFunction m_eErrorFunctiondenotes the error functionDefinition NeuralNet.h:1269; TMVA::DNN::Net::dEvoid dE(); TMVA::DNN::Net::addLayervoid addLayer(Layer &&layer)Definition NeuralNet.h:1095; TMVA::DNN::Net::numNodessize_t numNodes(size_t trainingStartLayer=0) constreturns the number of nodes in this netDefinition NeuralNet.cxx:556; TMVA::DNN::Net::traindouble train(std::vector< double > &weights, std::vector< Pattern > &trainPattern, const std::vector< Pattern > &testPattern, Minimizer &minimizer, Settings &settings)start the trainingDefinition NeuralNet.icc:712; TMVA::DNN::Net::layersconst std::vector< Layer > & layers() constreturns the layers (structure)Definition NeuralNet.h:1245; TMVA::DNN::Net::prepareLayerDatastd::vector< std::vector< LayerData > > prepareLayerData(LayerContainer &layers,",MatchSource.WIKI,doc/master/NeuralNet_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8h_source.html
https://root.cern/doc/master/NeuralNet_8h_source.html:72443,Usability,clear,clearvoid,72443,"::createvoid create(std::string histoName, int bins, double min, double max, int bins2, double min2, double max2)for monitoringDefinition NeuralNet.h:820; TMVA::DNN::Settings::useMultithreadingbool useMultithreading() constis multithreading turned on?Definition NeuralNet.h:815; TMVA::DNN::Settings::regularizationEnumRegularization regularization() constsome regularization of the DNN is turned on?Definition NeuralNet.h:813; TMVA::DNN::Settings::convergenceCountsize_t convergenceCount() constreturns the current convergence countDefinition NeuralNet.h:827; TMVA::DNN::Settings::momentumdouble momentum() constget the momentum (e.g. for SGD)Definition NeuralNet.h:772; TMVA::DNN::Settings::count_Esize_t count_EDefinition NeuralNet.h:842; TMVA::DNN::Settings::m_timerTimer m_timertimer for monitoringDefinition NeuralNet.h:832; TMVA::DNN::Settings::testRepetitionssize_t testRepetitions() consthow often is the test data testedDefinition NeuralNet.h:768; TMVA::DNN::Settings::clearvoid clear(std::string histoName)for monitoringDefinition NeuralNet.h:824; TMVA::DNN::Settings::endTestCyclevirtual void endTestCycle()callback for monitoring and logggingDefinition NeuralNet.h:805; TMVA::DNN::Settings::fMinimizerTypeMinimizerType fMinimizerTypeDefinition NeuralNet.h:855; TMVA::DNN::Settings::addPointvoid addPoint(std::string histoName, double x, double y)for monitoringDefinition NeuralNet.h:822; TMVA::DNN::Settings::setMonitoringvoid setMonitoring(std::shared_ptr< Monitoring > ptrMonitoring)prepared for monitoringDefinition NeuralNet.h:764; TMVA::DNN::Settings::testIterationvirtual void testIteration()callback for monitoring and logggingDefinition NeuralNet.h:806; TMVA::DNN::Settings::m_convergenceStepssize_t m_convergenceStepsnumber of steps without improvement to consider the DNN to have convergedDefinition NeuralNet.h:837; TMVA::DNN::Settings::hasConvergedvirtual bool hasConverged(double testError)has this training converged already?Definition NeuralNet.cxx:485; TMVA::DNN::Settings:",MatchSource.WIKI,doc/master/NeuralNet_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8h_source.html
https://root.cern/doc/master/NeuralNet_8h_source.html:72453,Usability,clear,clear,72453,"::createvoid create(std::string histoName, int bins, double min, double max, int bins2, double min2, double max2)for monitoringDefinition NeuralNet.h:820; TMVA::DNN::Settings::useMultithreadingbool useMultithreading() constis multithreading turned on?Definition NeuralNet.h:815; TMVA::DNN::Settings::regularizationEnumRegularization regularization() constsome regularization of the DNN is turned on?Definition NeuralNet.h:813; TMVA::DNN::Settings::convergenceCountsize_t convergenceCount() constreturns the current convergence countDefinition NeuralNet.h:827; TMVA::DNN::Settings::momentumdouble momentum() constget the momentum (e.g. for SGD)Definition NeuralNet.h:772; TMVA::DNN::Settings::count_Esize_t count_EDefinition NeuralNet.h:842; TMVA::DNN::Settings::m_timerTimer m_timertimer for monitoringDefinition NeuralNet.h:832; TMVA::DNN::Settings::testRepetitionssize_t testRepetitions() consthow often is the test data testedDefinition NeuralNet.h:768; TMVA::DNN::Settings::clearvoid clear(std::string histoName)for monitoringDefinition NeuralNet.h:824; TMVA::DNN::Settings::endTestCyclevirtual void endTestCycle()callback for monitoring and logggingDefinition NeuralNet.h:805; TMVA::DNN::Settings::fMinimizerTypeMinimizerType fMinimizerTypeDefinition NeuralNet.h:855; TMVA::DNN::Settings::addPointvoid addPoint(std::string histoName, double x, double y)for monitoringDefinition NeuralNet.h:822; TMVA::DNN::Settings::setMonitoringvoid setMonitoring(std::shared_ptr< Monitoring > ptrMonitoring)prepared for monitoringDefinition NeuralNet.h:764; TMVA::DNN::Settings::testIterationvirtual void testIteration()callback for monitoring and logggingDefinition NeuralNet.h:806; TMVA::DNN::Settings::m_convergenceStepssize_t m_convergenceStepsnumber of steps without improvement to consider the DNN to have convergedDefinition NeuralNet.h:837; TMVA::DNN::Settings::hasConvergedvirtual bool hasConverged(double testError)has this training converged already?Definition NeuralNet.cxx:485; TMVA::DNN::Settings:",MatchSource.WIKI,doc/master/NeuralNet_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8h_source.html
https://root.cern/doc/master/NeuralNet_8h_source.html:73749,Usability,progress bar,progress barDefinition,73749,"uralNet.h:855; TMVA::DNN::Settings::addPointvoid addPoint(std::string histoName, double x, double y)for monitoringDefinition NeuralNet.h:822; TMVA::DNN::Settings::setMonitoringvoid setMonitoring(std::shared_ptr< Monitoring > ptrMonitoring)prepared for monitoringDefinition NeuralNet.h:764; TMVA::DNN::Settings::testIterationvirtual void testIteration()callback for monitoring and logggingDefinition NeuralNet.h:806; TMVA::DNN::Settings::m_convergenceStepssize_t m_convergenceStepsnumber of steps without improvement to consider the DNN to have convergedDefinition NeuralNet.h:837; TMVA::DNN::Settings::hasConvergedvirtual bool hasConverged(double testError)has this training converged already?Definition NeuralNet.cxx:485; TMVA::DNN::Settings::minimizerTypeMinimizerType minimizerType() constwhich minimizer shall be used (e.g. SGD)Definition NeuralNet.h:774; TMVA::DNN::Settings::m_dropOutstd::vector< double > m_dropOutDefinition NeuralNet.h:850; TMVA::DNN::Settings::m_minProgressdouble m_minProgresscurrent limits for the progress barDefinition NeuralNet.h:833; TMVA::DNN::Settings::cyclevirtual void cycle(double progress, TString text)Definition NeuralNet.h:799; TMVA::DNN::Settings::setProgressLimitsvirtual void setProgressLimits(double minProgress=0, double maxProgress=100)Definition NeuralNet.h:790; TMVA::DNN::Settings::m_maxProgressdouble m_maxProgresscurrent limits for the progress barDefinition NeuralNet.h:834; TMVA::DNN::Settings::endTrainCyclevirtual void endTrainCycle(double)callback for monitoring and loggingDefinition NeuralNet.h:788; TMVA::DNN::Settings::count_dEsize_t count_dEDefinition NeuralNet.h:843; TMVA::DNN::Settings::drawSamplevirtual void drawSample(const std::vector< double > &, const std::vector< double > &, const std::vector< double > &, double)callback for monitoring and loggingDefinition NeuralNet.h:807; TMVA::DNN::Settings::learningRatedouble learningRate() constget the learning rateDefinition NeuralNet.h:771; TMVA::DNN::Settings::m_dropRepetitionsdoubl",MatchSource.WIKI,doc/master/NeuralNet_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8h_source.html
https://root.cern/doc/master/NeuralNet_8h_source.html:74111,Usability,progress bar,progress barDefinition,74111,"or monitoring and logggingDefinition NeuralNet.h:806; TMVA::DNN::Settings::m_convergenceStepssize_t m_convergenceStepsnumber of steps without improvement to consider the DNN to have convergedDefinition NeuralNet.h:837; TMVA::DNN::Settings::hasConvergedvirtual bool hasConverged(double testError)has this training converged already?Definition NeuralNet.cxx:485; TMVA::DNN::Settings::minimizerTypeMinimizerType minimizerType() constwhich minimizer shall be used (e.g. SGD)Definition NeuralNet.h:774; TMVA::DNN::Settings::m_dropOutstd::vector< double > m_dropOutDefinition NeuralNet.h:850; TMVA::DNN::Settings::m_minProgressdouble m_minProgresscurrent limits for the progress barDefinition NeuralNet.h:833; TMVA::DNN::Settings::cyclevirtual void cycle(double progress, TString text)Definition NeuralNet.h:799; TMVA::DNN::Settings::setProgressLimitsvirtual void setProgressLimits(double minProgress=0, double maxProgress=100)Definition NeuralNet.h:790; TMVA::DNN::Settings::m_maxProgressdouble m_maxProgresscurrent limits for the progress barDefinition NeuralNet.h:834; TMVA::DNN::Settings::endTrainCyclevirtual void endTrainCycle(double)callback for monitoring and loggingDefinition NeuralNet.h:788; TMVA::DNN::Settings::count_dEsize_t count_dEDefinition NeuralNet.h:843; TMVA::DNN::Settings::drawSamplevirtual void drawSample(const std::vector< double > &, const std::vector< double > &, const std::vector< double > &, double)callback for monitoring and loggingDefinition NeuralNet.h:807; TMVA::DNN::Settings::learningRatedouble learningRate() constget the learning rateDefinition NeuralNet.h:771; TMVA::DNN::Settings::m_dropRepetitionsdouble m_dropRepetitionsDefinition NeuralNet.h:849; TMVA::DNN::Settings::dropFractionsconst std::vector< double > & dropFractions() constDefinition NeuralNet.h:762; TMVA::DNN::Settings::addPointvoid addPoint(std::string histoName, double x)for monitoringDefinition NeuralNet.h:821; TMVA::DNN::Settings::~Settingsvirtual ~Settings()d'torDefinition NeuralNet.cxx:261; T",MatchSource.WIKI,doc/master/NeuralNet_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8h_source.html
https://root.cern/doc/master/NeuralNet_8h_source.html:74593,Usability,learn,learningRatedouble,74593,"ector< double > m_dropOutDefinition NeuralNet.h:850; TMVA::DNN::Settings::m_minProgressdouble m_minProgresscurrent limits for the progress barDefinition NeuralNet.h:833; TMVA::DNN::Settings::cyclevirtual void cycle(double progress, TString text)Definition NeuralNet.h:799; TMVA::DNN::Settings::setProgressLimitsvirtual void setProgressLimits(double minProgress=0, double maxProgress=100)Definition NeuralNet.h:790; TMVA::DNN::Settings::m_maxProgressdouble m_maxProgresscurrent limits for the progress barDefinition NeuralNet.h:834; TMVA::DNN::Settings::endTrainCyclevirtual void endTrainCycle(double)callback for monitoring and loggingDefinition NeuralNet.h:788; TMVA::DNN::Settings::count_dEsize_t count_dEDefinition NeuralNet.h:843; TMVA::DNN::Settings::drawSamplevirtual void drawSample(const std::vector< double > &, const std::vector< double > &, const std::vector< double > &, double)callback for monitoring and loggingDefinition NeuralNet.h:807; TMVA::DNN::Settings::learningRatedouble learningRate() constget the learning rateDefinition NeuralNet.h:771; TMVA::DNN::Settings::m_dropRepetitionsdouble m_dropRepetitionsDefinition NeuralNet.h:849; TMVA::DNN::Settings::dropFractionsconst std::vector< double > & dropFractions() constDefinition NeuralNet.h:762; TMVA::DNN::Settings::addPointvoid addPoint(std::string histoName, double x)for monitoringDefinition NeuralNet.h:821; TMVA::DNN::Settings::~Settingsvirtual ~Settings()d'torDefinition NeuralNet.cxx:261; TMVA::DNN::Settings::m_convergenceCountsize_t m_convergenceCountDefinition NeuralNet.h:857; TMVA::DNN::Settings::m_regularizationEnumRegularization m_regularizationDefinition NeuralNet.h:847; TMVA::DNN::Settings::repetitionsint repetitions() consthow many steps have to be gone until the batch is changedDefinition NeuralNet.h:773; TMVA::DNN::Settings::m_minErrordouble m_minErrorDefinition NeuralNet.h:859; TMVA::DNN::Settings::testSamplevirtual void testSample(double, double, double, double)virtual function to be used for monitorin",MatchSource.WIKI,doc/master/NeuralNet_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8h_source.html
https://root.cern/doc/master/NeuralNet_8h_source.html:74612,Usability,learn,learningRate,74612,"ector< double > m_dropOutDefinition NeuralNet.h:850; TMVA::DNN::Settings::m_minProgressdouble m_minProgresscurrent limits for the progress barDefinition NeuralNet.h:833; TMVA::DNN::Settings::cyclevirtual void cycle(double progress, TString text)Definition NeuralNet.h:799; TMVA::DNN::Settings::setProgressLimitsvirtual void setProgressLimits(double minProgress=0, double maxProgress=100)Definition NeuralNet.h:790; TMVA::DNN::Settings::m_maxProgressdouble m_maxProgresscurrent limits for the progress barDefinition NeuralNet.h:834; TMVA::DNN::Settings::endTrainCyclevirtual void endTrainCycle(double)callback for monitoring and loggingDefinition NeuralNet.h:788; TMVA::DNN::Settings::count_dEsize_t count_dEDefinition NeuralNet.h:843; TMVA::DNN::Settings::drawSamplevirtual void drawSample(const std::vector< double > &, const std::vector< double > &, const std::vector< double > &, double)callback for monitoring and loggingDefinition NeuralNet.h:807; TMVA::DNN::Settings::learningRatedouble learningRate() constget the learning rateDefinition NeuralNet.h:771; TMVA::DNN::Settings::m_dropRepetitionsdouble m_dropRepetitionsDefinition NeuralNet.h:849; TMVA::DNN::Settings::dropFractionsconst std::vector< double > & dropFractions() constDefinition NeuralNet.h:762; TMVA::DNN::Settings::addPointvoid addPoint(std::string histoName, double x)for monitoringDefinition NeuralNet.h:821; TMVA::DNN::Settings::~Settingsvirtual ~Settings()d'torDefinition NeuralNet.cxx:261; TMVA::DNN::Settings::m_convergenceCountsize_t m_convergenceCountDefinition NeuralNet.h:857; TMVA::DNN::Settings::m_regularizationEnumRegularization m_regularizationDefinition NeuralNet.h:847; TMVA::DNN::Settings::repetitionsint repetitions() consthow many steps have to be gone until the batch is changedDefinition NeuralNet.h:773; TMVA::DNN::Settings::m_minErrordouble m_minErrorDefinition NeuralNet.h:859; TMVA::DNN::Settings::testSamplevirtual void testSample(double, double, double, double)virtual function to be used for monitorin",MatchSource.WIKI,doc/master/NeuralNet_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8h_source.html
https://root.cern/doc/master/NeuralNet_8h_source.html:74640,Usability,learn,learning,74640,"ector< double > m_dropOutDefinition NeuralNet.h:850; TMVA::DNN::Settings::m_minProgressdouble m_minProgresscurrent limits for the progress barDefinition NeuralNet.h:833; TMVA::DNN::Settings::cyclevirtual void cycle(double progress, TString text)Definition NeuralNet.h:799; TMVA::DNN::Settings::setProgressLimitsvirtual void setProgressLimits(double minProgress=0, double maxProgress=100)Definition NeuralNet.h:790; TMVA::DNN::Settings::m_maxProgressdouble m_maxProgresscurrent limits for the progress barDefinition NeuralNet.h:834; TMVA::DNN::Settings::endTrainCyclevirtual void endTrainCycle(double)callback for monitoring and loggingDefinition NeuralNet.h:788; TMVA::DNN::Settings::count_dEsize_t count_dEDefinition NeuralNet.h:843; TMVA::DNN::Settings::drawSamplevirtual void drawSample(const std::vector< double > &, const std::vector< double > &, const std::vector< double > &, double)callback for monitoring and loggingDefinition NeuralNet.h:807; TMVA::DNN::Settings::learningRatedouble learningRate() constget the learning rateDefinition NeuralNet.h:771; TMVA::DNN::Settings::m_dropRepetitionsdouble m_dropRepetitionsDefinition NeuralNet.h:849; TMVA::DNN::Settings::dropFractionsconst std::vector< double > & dropFractions() constDefinition NeuralNet.h:762; TMVA::DNN::Settings::addPointvoid addPoint(std::string histoName, double x)for monitoringDefinition NeuralNet.h:821; TMVA::DNN::Settings::~Settingsvirtual ~Settings()d'torDefinition NeuralNet.cxx:261; TMVA::DNN::Settings::m_convergenceCountsize_t m_convergenceCountDefinition NeuralNet.h:857; TMVA::DNN::Settings::m_regularizationEnumRegularization m_regularizationDefinition NeuralNet.h:847; TMVA::DNN::Settings::repetitionsint repetitions() consthow many steps have to be gone until the batch is changedDefinition NeuralNet.h:773; TMVA::DNN::Settings::m_minErrordouble m_minErrorDefinition NeuralNet.h:859; TMVA::DNN::Settings::testSamplevirtual void testSample(double, double, double, double)virtual function to be used for monitorin",MatchSource.WIKI,doc/master/NeuralNet_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8h_source.html
https://root.cern/doc/master/NeuralNet_8h_source.html:78823,Usability,learn,learningRate,78823,"ze_t minError() constreturns the smallest error so farDefinition NeuralNet.h:829; TMVA::DNN::Settings::startTrainingvirtual void startTraining()Definition NeuralNet.h:795; TMVA::DNN::Settings::m_maxConvergenceCountsize_t m_maxConvergenceCountDefinition NeuralNet.h:858; TMVA::DNN::Settings::startTestCyclevirtual void startTestCycle()callback for monitoring and logggingDefinition NeuralNet.h:804; TMVA::DNN::SteepestSteepest Gradient Descent algorithm (SGD)Definition NeuralNet.h:334; TMVA::DNN::Steepest::m_repetitionssize_t m_repetitionsDefinition NeuralNet.h:337; TMVA::DNN::Steepest::m_betadouble m_betainternal parameter (momentum)Definition NeuralNet.h:372; TMVA::DNN::Steepest::m_localGradientsstd::vector< double > m_localGradientslocal gradients for reuse in thread.Definition NeuralNet.h:376; TMVA::DNN::Steepest::m_prevGradientsstd::vector< double > m_prevGradientsvector remembers the gradients of the previous stepDefinition NeuralNet.h:373; TMVA::DNN::Steepest::m_alphadouble m_alphainternal parameter (learningRate)Definition NeuralNet.h:371; TMVA::DNN::Steepest::m_localWeightsstd::vector< double > m_localWeightslocal weights for reuse in thread.Definition NeuralNet.h:375; TMVA::DNN::Steepest::operator()double operator()(Function &fitnessFunction, Weights &weights, PassThrough &passThrough)operator to call the steepest gradient descent algorithmDefinition NeuralNet.icc:271; TMVA::DNN::Steepest::SteepestSteepest(double learningRate=1e-4, double momentum=0.5, size_t repetitions=10)c'torDefinition NeuralNet.h:348; TMVA::IPythonInteractiveThis class is needed by JsMVA, and it's a helper class for tracking errors during the training in Jup...Definition MethodBase.h:94; TMVA::TimerTiming information for training and evaluation of MVA methods.Definition Timer.h:58; TMVA::Timer::DrawProgressBarvoid DrawProgressBar(Int_t, const TString &comment="""")draws progress bar in color or B&W caution:Definition Timer.cxx:202; TStringBasic string class.Definition TString.h:139; double; u",MatchSource.WIKI,doc/master/NeuralNet_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8h_source.html
https://root.cern/doc/master/NeuralNet_8h_source.html:79247,Usability,learn,learningRate,79247,"t Descent algorithm (SGD)Definition NeuralNet.h:334; TMVA::DNN::Steepest::m_repetitionssize_t m_repetitionsDefinition NeuralNet.h:337; TMVA::DNN::Steepest::m_betadouble m_betainternal parameter (momentum)Definition NeuralNet.h:372; TMVA::DNN::Steepest::m_localGradientsstd::vector< double > m_localGradientslocal gradients for reuse in thread.Definition NeuralNet.h:376; TMVA::DNN::Steepest::m_prevGradientsstd::vector< double > m_prevGradientsvector remembers the gradients of the previous stepDefinition NeuralNet.h:373; TMVA::DNN::Steepest::m_alphadouble m_alphainternal parameter (learningRate)Definition NeuralNet.h:371; TMVA::DNN::Steepest::m_localWeightsstd::vector< double > m_localWeightslocal weights for reuse in thread.Definition NeuralNet.h:375; TMVA::DNN::Steepest::operator()double operator()(Function &fitnessFunction, Weights &weights, PassThrough &passThrough)operator to call the steepest gradient descent algorithmDefinition NeuralNet.icc:271; TMVA::DNN::Steepest::SteepestSteepest(double learningRate=1e-4, double momentum=0.5, size_t repetitions=10)c'torDefinition NeuralNet.h:348; TMVA::IPythonInteractiveThis class is needed by JsMVA, and it's a helper class for tracking errors during the training in Jup...Definition MethodBase.h:94; TMVA::TimerTiming information for training and evaluation of MVA methods.Definition Timer.h:58; TMVA::Timer::DrawProgressBarvoid DrawProgressBar(Int_t, const TString &comment="""")draws progress bar in color or B&W caution:Definition Timer.cxx:202; TStringBasic string class.Definition TString.h:139; double; unsigned int; sigmaconst Double_t sigmaDefinition h1analysisProxy.h:11; yDouble_t y[n]Definition legend1.C:17; xDouble_t x[n]Definition legend1.C:17; TMVA::DNN::sumOfSquaresdouble sumOfSquares(ItOutput itOutputBegin, ItOutput itOutputEnd, ItTruth itTruthBegin, ItTruth itTruthEnd, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc itInvActFnc, double patternWeight); TMVA::DNN::uniformDoubledouble uniformDouble(double minValue, double",MatchSource.WIKI,doc/master/NeuralNet_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8h_source.html
https://root.cern/doc/master/NeuralNet_8h_source.html:79682,Usability,progress bar,progress bar,79682,"le > m_prevGradientsvector remembers the gradients of the previous stepDefinition NeuralNet.h:373; TMVA::DNN::Steepest::m_alphadouble m_alphainternal parameter (learningRate)Definition NeuralNet.h:371; TMVA::DNN::Steepest::m_localWeightsstd::vector< double > m_localWeightslocal weights for reuse in thread.Definition NeuralNet.h:375; TMVA::DNN::Steepest::operator()double operator()(Function &fitnessFunction, Weights &weights, PassThrough &passThrough)operator to call the steepest gradient descent algorithmDefinition NeuralNet.icc:271; TMVA::DNN::Steepest::SteepestSteepest(double learningRate=1e-4, double momentum=0.5, size_t repetitions=10)c'torDefinition NeuralNet.h:348; TMVA::IPythonInteractiveThis class is needed by JsMVA, and it's a helper class for tracking errors during the training in Jup...Definition MethodBase.h:94; TMVA::TimerTiming information for training and evaluation of MVA methods.Definition Timer.h:58; TMVA::Timer::DrawProgressBarvoid DrawProgressBar(Int_t, const TString &comment="""")draws progress bar in color or B&W caution:Definition Timer.cxx:202; TStringBasic string class.Definition TString.h:139; double; unsigned int; sigmaconst Double_t sigmaDefinition h1analysisProxy.h:11; yDouble_t y[n]Definition legend1.C:17; xDouble_t x[n]Definition legend1.C:17; TMVA::DNN::sumOfSquaresdouble sumOfSquares(ItOutput itOutputBegin, ItOutput itOutputEnd, ItTruth itTruthBegin, ItTruth itTruthEnd, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc itInvActFnc, double patternWeight); TMVA::DNN::uniformDoubledouble uniformDouble(double minValue, double maxValue)Definition NeuralNet.cxx:43; TMVA::DNN::forwardvoid forward(const LAYERDATA &prevLayerData, LAYERDATA &currLayerData)apply the weights (and functions) in forward direction of the DNNDefinition NeuralNet.icc:546; TMVA::DNN::applyFunctionsvoid applyFunctions(ItValue itValue, ItValue itValueEnd, ItFunction itFunction); TMVA::DNN::operator|ModeOutputValues operator|(ModeOutputValues lhs, ModeOutputValues rhs)Defin",MatchSource.WIKI,doc/master/NeuralNet_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8h_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:276,Availability,error,error,276,". ROOT: tmva/tmva/inc/TMVA/NeuralNet.icc Source File. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. NeuralNet.icc. Go to the documentation of this file. 1#ifndef TMVA_NEURAL_NET_I; 2#define TMVA_NEURAL_NET_I; 3 ; 4#ifndef TMVA_NEURAL_NET; 5#error ""Do not use NeuralNet.icc directly. #include \""NeuralNet.h\"" instead.""; 6#endif // TMVA_NEURAL_NET; 7#pragma once; 8#ifndef _MSC_VER; 9#pragma GCC diagnostic ignored ""-Wunused-variable""; 10#endif; 11 ; 12#include ""Math/Util.h""; 13 ; 14#include ""TMVA/Pattern.h""; 15#include ""TMVA/MethodBase.h""; 16 ; 17#include <tuple>; 18#include <future>; 19#include <random>; 20 ; 21namespace TMVA; 22{; 23 namespace DNN; 24 {; 25 ; 26 ; 27 ; 28 ; 29 ; 30 ; 31 ; 32 ; 33 template <typename T>; 34 T uniformFromTo (T from, T to); 35 {; 36 return from + (rand ()* (to - from)/RAND_MAX);; 37 }; 38 ; 39 ; 40 ; 41 template <typename Container, typename T>; 42 void uniformDouble (Container& container, T maxValue); 43 {; 44 for (auto it = begin (container), itEnd = end (container); it != itEnd; ++it); 45 {; 46// (*it) = uniformFromTo (-1.0*maxValue, 1.0*maxValue);; 47 (*it) = TMVA::DNN::uniformFromTo (-1.0*maxValue, 1.0*maxValue);; 48 }; 49 }; 50 ; 51 ; 52 extern std::shared_ptr<std::function<double(double)>> ZeroFnc;; 53 ; 54 ; 55 extern std::shared_ptr<std::function<double(double)>> Sigmoid;; 56 extern std::shared_ptr<std::function<double(double)>> InvSigmoid;; 57 ; 58 extern std::shared_ptr<std::function<double(double)>> Tanh;; 59 extern std::shared_ptr<std::function<double(double)>> InvTanh;; 60 ; 61 extern std::shared_ptr<std::function<double(double)>> Linear;; 62 extern std::shared_ptr<std::function<double(double)>> InvLinear;; 63 ; 64 extern std::shared_ptr<std::function<double(double)>> SymmReLU;; 65 extern std::shared_ptr<std::function<double(double)>> InvSymmReLU;; 66 ; 67 extern std::shared_ptr<std::function<double(double)>> ReLU;; 68 extern std::shared_ptr<std::function<double(double)>> InvReLU;; 69 ; 70 ex",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:10858,Availability,error,error,10858,"or (; itG != itGEnd; ++itG, ++itPrevG); 319 {; 320 double currGrad = (*itG);; 321 double prevGrad = (*itPrevG);; 322 currGrad *= alpha;; 323 ; 324 //(*itPrevG) = m_beta * (prevGrad + currGrad);; 325 currGrad += prevGrad;; 326 (*itG) = currGrad;; 327 (*itPrevG) = currGrad;; 328 ; 329 if (std::fabs (currGrad) > maxGrad); 330 maxGrad = currGrad;; 331 }; 332 ; 333 if (maxGrad > 1); 334 {; 335 m_alpha /= 2;; 336 std::cout << ""\nlearning rate reduced to "" << m_alpha << std::endl;; 337 std::for_each (weights.begin (), weights.end (), [maxGrad](double& w); 338 {; 339 w /= maxGrad;; 340 });; 341 m_prevGradients.clear ();; 342 }; 343 else; 344 {; 345 auto itW = std::begin (weights);; 346 std::for_each (std::begin (m_localGradients), std::end (m_localGradients), [&itW](double& g); 347 {; 348 *itW += g;; 349 ++itW;; 350 });; 351 }; 352 ; 353 ++currentRepetition;; 354 }; 355 return E;; 356 }; 357 ; 358 ; 359 ; 360 ; 361 ; 362 ; 363 ; 364 ; 365 ; 366 ; 367 ; 368 ; 369 ; 370 ; 371 ; 372 ; 373 ; 374 ; 375 ; 376 ; 377/*! \brief sum of squares error function; 378 *; 379 *; 380 */; 381 template <typename ItOutput, typename ItTruth, typename ItDelta, typename InvFnc>; 382 double sumOfSquares (ItOutput itOutputBegin, ItOutput itOutputEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, InvFnc invFnc, double patternWeight); 383 {; 384 double errorSum = 0.0;; 385 ; 386 // output - truth; 387 ItTruth itTruth = itTruthBegin;; 388 bool hasDeltas = (itDelta != itDeltaEnd);; 389 for (ItOutput itOutput = itOutputBegin; itOutput != itOutputEnd; ++itOutput, ++itTruth); 390 {; 391// assert (itTruth != itTruthEnd);; 392 double output = (*itOutput);; 393 double error = output - (*itTruth);; 394 if (hasDeltas); 395 {; 396 (*itDelta) = (*invFnc.get ()) (output) * error * patternWeight;; 397 ++itDelta;; 398 }; 399 errorSum += error*error * patternWeight;; 400 }; 401 ; 402 return 0.5*errorSum;; 403 }; 404 ; 405 ; 406 ; 407/*! \brief cross entropy error function; 408 *;",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:11193,Availability,error,errorSum,11193,"or (; itG != itGEnd; ++itG, ++itPrevG); 319 {; 320 double currGrad = (*itG);; 321 double prevGrad = (*itPrevG);; 322 currGrad *= alpha;; 323 ; 324 //(*itPrevG) = m_beta * (prevGrad + currGrad);; 325 currGrad += prevGrad;; 326 (*itG) = currGrad;; 327 (*itPrevG) = currGrad;; 328 ; 329 if (std::fabs (currGrad) > maxGrad); 330 maxGrad = currGrad;; 331 }; 332 ; 333 if (maxGrad > 1); 334 {; 335 m_alpha /= 2;; 336 std::cout << ""\nlearning rate reduced to "" << m_alpha << std::endl;; 337 std::for_each (weights.begin (), weights.end (), [maxGrad](double& w); 338 {; 339 w /= maxGrad;; 340 });; 341 m_prevGradients.clear ();; 342 }; 343 else; 344 {; 345 auto itW = std::begin (weights);; 346 std::for_each (std::begin (m_localGradients), std::end (m_localGradients), [&itW](double& g); 347 {; 348 *itW += g;; 349 ++itW;; 350 });; 351 }; 352 ; 353 ++currentRepetition;; 354 }; 355 return E;; 356 }; 357 ; 358 ; 359 ; 360 ; 361 ; 362 ; 363 ; 364 ; 365 ; 366 ; 367 ; 368 ; 369 ; 370 ; 371 ; 372 ; 373 ; 374 ; 375 ; 376 ; 377/*! \brief sum of squares error function; 378 *; 379 *; 380 */; 381 template <typename ItOutput, typename ItTruth, typename ItDelta, typename InvFnc>; 382 double sumOfSquares (ItOutput itOutputBegin, ItOutput itOutputEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, InvFnc invFnc, double patternWeight); 383 {; 384 double errorSum = 0.0;; 385 ; 386 // output - truth; 387 ItTruth itTruth = itTruthBegin;; 388 bool hasDeltas = (itDelta != itDeltaEnd);; 389 for (ItOutput itOutput = itOutputBegin; itOutput != itOutputEnd; ++itOutput, ++itTruth); 390 {; 391// assert (itTruth != itTruthEnd);; 392 double output = (*itOutput);; 393 double error = output - (*itTruth);; 394 if (hasDeltas); 395 {; 396 (*itDelta) = (*invFnc.get ()) (output) * error * patternWeight;; 397 ++itDelta;; 398 }; 399 errorSum += error*error * patternWeight;; 400 }; 401 ; 402 return 0.5*errorSum;; 403 }; 404 ; 405 ; 406 ; 407/*! \brief cross entropy error function; 408 *;",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:11507,Availability,error,error,11507,"40 });; 341 m_prevGradients.clear ();; 342 }; 343 else; 344 {; 345 auto itW = std::begin (weights);; 346 std::for_each (std::begin (m_localGradients), std::end (m_localGradients), [&itW](double& g); 347 {; 348 *itW += g;; 349 ++itW;; 350 });; 351 }; 352 ; 353 ++currentRepetition;; 354 }; 355 return E;; 356 }; 357 ; 358 ; 359 ; 360 ; 361 ; 362 ; 363 ; 364 ; 365 ; 366 ; 367 ; 368 ; 369 ; 370 ; 371 ; 372 ; 373 ; 374 ; 375 ; 376 ; 377/*! \brief sum of squares error function; 378 *; 379 *; 380 */; 381 template <typename ItOutput, typename ItTruth, typename ItDelta, typename InvFnc>; 382 double sumOfSquares (ItOutput itOutputBegin, ItOutput itOutputEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, InvFnc invFnc, double patternWeight); 383 {; 384 double errorSum = 0.0;; 385 ; 386 // output - truth; 387 ItTruth itTruth = itTruthBegin;; 388 bool hasDeltas = (itDelta != itDeltaEnd);; 389 for (ItOutput itOutput = itOutputBegin; itOutput != itOutputEnd; ++itOutput, ++itTruth); 390 {; 391// assert (itTruth != itTruthEnd);; 392 double output = (*itOutput);; 393 double error = output - (*itTruth);; 394 if (hasDeltas); 395 {; 396 (*itDelta) = (*invFnc.get ()) (output) * error * patternWeight;; 397 ++itDelta;; 398 }; 399 errorSum += error*error * patternWeight;; 400 }; 401 ; 402 return 0.5*errorSum;; 403 }; 404 ; 405 ; 406 ; 407/*! \brief cross entropy error function; 408 *; 409 *; 410 */; 411 template <typename ItProbability, typename ItTruth, typename ItDelta, typename ItInvActFnc>; 412 double crossEntropy (ItProbability itProbabilityBegin, ItProbability itProbabilityEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc /*itInvActFnc*/, double patternWeight); 413 {; 414 bool hasDeltas = (itDelta != itDeltaEnd);; 415 ; 416 double errorSum = 0.0;; 417 for (ItProbability itProbability = itProbabilityBegin; itProbability != itProbabilityEnd; ++itProbability); 418 {; 419 double probability = *itProbabil",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:11609,Availability,error,error,11609,"+currentRepetition;; 354 }; 355 return E;; 356 }; 357 ; 358 ; 359 ; 360 ; 361 ; 362 ; 363 ; 364 ; 365 ; 366 ; 367 ; 368 ; 369 ; 370 ; 371 ; 372 ; 373 ; 374 ; 375 ; 376 ; 377/*! \brief sum of squares error function; 378 *; 379 *; 380 */; 381 template <typename ItOutput, typename ItTruth, typename ItDelta, typename InvFnc>; 382 double sumOfSquares (ItOutput itOutputBegin, ItOutput itOutputEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, InvFnc invFnc, double patternWeight); 383 {; 384 double errorSum = 0.0;; 385 ; 386 // output - truth; 387 ItTruth itTruth = itTruthBegin;; 388 bool hasDeltas = (itDelta != itDeltaEnd);; 389 for (ItOutput itOutput = itOutputBegin; itOutput != itOutputEnd; ++itOutput, ++itTruth); 390 {; 391// assert (itTruth != itTruthEnd);; 392 double output = (*itOutput);; 393 double error = output - (*itTruth);; 394 if (hasDeltas); 395 {; 396 (*itDelta) = (*invFnc.get ()) (output) * error * patternWeight;; 397 ++itDelta;; 398 }; 399 errorSum += error*error * patternWeight;; 400 }; 401 ; 402 return 0.5*errorSum;; 403 }; 404 ; 405 ; 406 ; 407/*! \brief cross entropy error function; 408 *; 409 *; 410 */; 411 template <typename ItProbability, typename ItTruth, typename ItDelta, typename ItInvActFnc>; 412 double crossEntropy (ItProbability itProbabilityBegin, ItProbability itProbabilityEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc /*itInvActFnc*/, double patternWeight); 413 {; 414 bool hasDeltas = (itDelta != itDeltaEnd);; 415 ; 416 double errorSum = 0.0;; 417 for (ItProbability itProbability = itProbabilityBegin; itProbability != itProbabilityEnd; ++itProbability); 418 {; 419 double probability = *itProbability;; 420 double truth = *itTruthBegin;; 421 /* truth = truth < 0.1 ? 0.1 : truth; */; 422 /* truth = truth > 0.9 ? 0.9 : truth; */; 423 truth = truth < 0.5 ? 0.1 : 0.9;; 424 if (hasDeltas); 425 {; 426 double delta = probability - truth;; 427 (*itDelta) = delta",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:11660,Availability,error,errorSum,11660,"+currentRepetition;; 354 }; 355 return E;; 356 }; 357 ; 358 ; 359 ; 360 ; 361 ; 362 ; 363 ; 364 ; 365 ; 366 ; 367 ; 368 ; 369 ; 370 ; 371 ; 372 ; 373 ; 374 ; 375 ; 376 ; 377/*! \brief sum of squares error function; 378 *; 379 *; 380 */; 381 template <typename ItOutput, typename ItTruth, typename ItDelta, typename InvFnc>; 382 double sumOfSquares (ItOutput itOutputBegin, ItOutput itOutputEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, InvFnc invFnc, double patternWeight); 383 {; 384 double errorSum = 0.0;; 385 ; 386 // output - truth; 387 ItTruth itTruth = itTruthBegin;; 388 bool hasDeltas = (itDelta != itDeltaEnd);; 389 for (ItOutput itOutput = itOutputBegin; itOutput != itOutputEnd; ++itOutput, ++itTruth); 390 {; 391// assert (itTruth != itTruthEnd);; 392 double output = (*itOutput);; 393 double error = output - (*itTruth);; 394 if (hasDeltas); 395 {; 396 (*itDelta) = (*invFnc.get ()) (output) * error * patternWeight;; 397 ++itDelta;; 398 }; 399 errorSum += error*error * patternWeight;; 400 }; 401 ; 402 return 0.5*errorSum;; 403 }; 404 ; 405 ; 406 ; 407/*! \brief cross entropy error function; 408 *; 409 *; 410 */; 411 template <typename ItProbability, typename ItTruth, typename ItDelta, typename ItInvActFnc>; 412 double crossEntropy (ItProbability itProbabilityBegin, ItProbability itProbabilityEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc /*itInvActFnc*/, double patternWeight); 413 {; 414 bool hasDeltas = (itDelta != itDeltaEnd);; 415 ; 416 double errorSum = 0.0;; 417 for (ItProbability itProbability = itProbabilityBegin; itProbability != itProbabilityEnd; ++itProbability); 418 {; 419 double probability = *itProbability;; 420 double truth = *itTruthBegin;; 421 /* truth = truth < 0.1 ? 0.1 : truth; */; 422 /* truth = truth > 0.9 ? 0.9 : truth; */; 423 truth = truth < 0.5 ? 0.1 : 0.9;; 424 if (hasDeltas); 425 {; 426 double delta = probability - truth;; 427 (*itDelta) = delta",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:11672,Availability,error,error,11672,"+currentRepetition;; 354 }; 355 return E;; 356 }; 357 ; 358 ; 359 ; 360 ; 361 ; 362 ; 363 ; 364 ; 365 ; 366 ; 367 ; 368 ; 369 ; 370 ; 371 ; 372 ; 373 ; 374 ; 375 ; 376 ; 377/*! \brief sum of squares error function; 378 *; 379 *; 380 */; 381 template <typename ItOutput, typename ItTruth, typename ItDelta, typename InvFnc>; 382 double sumOfSquares (ItOutput itOutputBegin, ItOutput itOutputEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, InvFnc invFnc, double patternWeight); 383 {; 384 double errorSum = 0.0;; 385 ; 386 // output - truth; 387 ItTruth itTruth = itTruthBegin;; 388 bool hasDeltas = (itDelta != itDeltaEnd);; 389 for (ItOutput itOutput = itOutputBegin; itOutput != itOutputEnd; ++itOutput, ++itTruth); 390 {; 391// assert (itTruth != itTruthEnd);; 392 double output = (*itOutput);; 393 double error = output - (*itTruth);; 394 if (hasDeltas); 395 {; 396 (*itDelta) = (*invFnc.get ()) (output) * error * patternWeight;; 397 ++itDelta;; 398 }; 399 errorSum += error*error * patternWeight;; 400 }; 401 ; 402 return 0.5*errorSum;; 403 }; 404 ; 405 ; 406 ; 407/*! \brief cross entropy error function; 408 *; 409 *; 410 */; 411 template <typename ItProbability, typename ItTruth, typename ItDelta, typename ItInvActFnc>; 412 double crossEntropy (ItProbability itProbabilityBegin, ItProbability itProbabilityEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc /*itInvActFnc*/, double patternWeight); 413 {; 414 bool hasDeltas = (itDelta != itDeltaEnd);; 415 ; 416 double errorSum = 0.0;; 417 for (ItProbability itProbability = itProbabilityBegin; itProbability != itProbabilityEnd; ++itProbability); 418 {; 419 double probability = *itProbability;; 420 double truth = *itTruthBegin;; 421 /* truth = truth < 0.1 ? 0.1 : truth; */; 422 /* truth = truth > 0.9 ? 0.9 : truth; */; 423 truth = truth < 0.5 ? 0.1 : 0.9;; 424 if (hasDeltas); 425 {; 426 double delta = probability - truth;; 427 (*itDelta) = delta",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:11678,Availability,error,error,11678,"+currentRepetition;; 354 }; 355 return E;; 356 }; 357 ; 358 ; 359 ; 360 ; 361 ; 362 ; 363 ; 364 ; 365 ; 366 ; 367 ; 368 ; 369 ; 370 ; 371 ; 372 ; 373 ; 374 ; 375 ; 376 ; 377/*! \brief sum of squares error function; 378 *; 379 *; 380 */; 381 template <typename ItOutput, typename ItTruth, typename ItDelta, typename InvFnc>; 382 double sumOfSquares (ItOutput itOutputBegin, ItOutput itOutputEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, InvFnc invFnc, double patternWeight); 383 {; 384 double errorSum = 0.0;; 385 ; 386 // output - truth; 387 ItTruth itTruth = itTruthBegin;; 388 bool hasDeltas = (itDelta != itDeltaEnd);; 389 for (ItOutput itOutput = itOutputBegin; itOutput != itOutputEnd; ++itOutput, ++itTruth); 390 {; 391// assert (itTruth != itTruthEnd);; 392 double output = (*itOutput);; 393 double error = output - (*itTruth);; 394 if (hasDeltas); 395 {; 396 (*itDelta) = (*invFnc.get ()) (output) * error * patternWeight;; 397 ++itDelta;; 398 }; 399 errorSum += error*error * patternWeight;; 400 }; 401 ; 402 return 0.5*errorSum;; 403 }; 404 ; 405 ; 406 ; 407/*! \brief cross entropy error function; 408 *; 409 *; 410 */; 411 template <typename ItProbability, typename ItTruth, typename ItDelta, typename ItInvActFnc>; 412 double crossEntropy (ItProbability itProbabilityBegin, ItProbability itProbabilityEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc /*itInvActFnc*/, double patternWeight); 413 {; 414 bool hasDeltas = (itDelta != itDeltaEnd);; 415 ; 416 double errorSum = 0.0;; 417 for (ItProbability itProbability = itProbabilityBegin; itProbability != itProbabilityEnd; ++itProbability); 418 {; 419 double probability = *itProbability;; 420 double truth = *itTruthBegin;; 421 /* truth = truth < 0.1 ? 0.1 : truth; */; 422 /* truth = truth > 0.9 ? 0.9 : truth; */; 423 truth = truth < 0.5 ? 0.1 : 0.9;; 424 if (hasDeltas); 425 {; 426 double delta = probability - truth;; 427 (*itDelta) = delta",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:11730,Availability,error,errorSum,11730,"382 double sumOfSquares (ItOutput itOutputBegin, ItOutput itOutputEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, InvFnc invFnc, double patternWeight); 383 {; 384 double errorSum = 0.0;; 385 ; 386 // output - truth; 387 ItTruth itTruth = itTruthBegin;; 388 bool hasDeltas = (itDelta != itDeltaEnd);; 389 for (ItOutput itOutput = itOutputBegin; itOutput != itOutputEnd; ++itOutput, ++itTruth); 390 {; 391// assert (itTruth != itTruthEnd);; 392 double output = (*itOutput);; 393 double error = output - (*itTruth);; 394 if (hasDeltas); 395 {; 396 (*itDelta) = (*invFnc.get ()) (output) * error * patternWeight;; 397 ++itDelta;; 398 }; 399 errorSum += error*error * patternWeight;; 400 }; 401 ; 402 return 0.5*errorSum;; 403 }; 404 ; 405 ; 406 ; 407/*! \brief cross entropy error function; 408 *; 409 *; 410 */; 411 template <typename ItProbability, typename ItTruth, typename ItDelta, typename ItInvActFnc>; 412 double crossEntropy (ItProbability itProbabilityBegin, ItProbability itProbabilityEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc /*itInvActFnc*/, double patternWeight); 413 {; 414 bool hasDeltas = (itDelta != itDeltaEnd);; 415 ; 416 double errorSum = 0.0;; 417 for (ItProbability itProbability = itProbabilityBegin; itProbability != itProbabilityEnd; ++itProbability); 418 {; 419 double probability = *itProbability;; 420 double truth = *itTruthBegin;; 421 /* truth = truth < 0.1 ? 0.1 : truth; */; 422 /* truth = truth > 0.9 ? 0.9 : truth; */; 423 truth = truth < 0.5 ? 0.1 : 0.9;; 424 if (hasDeltas); 425 {; 426 double delta = probability - truth;; 427 (*itDelta) = delta*patternWeight;; 428// (*itDelta) = (*itInvActFnc)(probability) * delta * patternWeight;; 429 ++itDelta;; 430 }; 431 double error (0);; 432 if (probability == 0) // protection against log (0); 433 {; 434 if (truth >= 0.5); 435 error += 1.0;; 436 }; 437 else if (probability == 1); 438 {; 439 if (truth < 0.5); 440 error += 1.",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:11794,Availability,error,error,11794,"382 double sumOfSquares (ItOutput itOutputBegin, ItOutput itOutputEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, InvFnc invFnc, double patternWeight); 383 {; 384 double errorSum = 0.0;; 385 ; 386 // output - truth; 387 ItTruth itTruth = itTruthBegin;; 388 bool hasDeltas = (itDelta != itDeltaEnd);; 389 for (ItOutput itOutput = itOutputBegin; itOutput != itOutputEnd; ++itOutput, ++itTruth); 390 {; 391// assert (itTruth != itTruthEnd);; 392 double output = (*itOutput);; 393 double error = output - (*itTruth);; 394 if (hasDeltas); 395 {; 396 (*itDelta) = (*invFnc.get ()) (output) * error * patternWeight;; 397 ++itDelta;; 398 }; 399 errorSum += error*error * patternWeight;; 400 }; 401 ; 402 return 0.5*errorSum;; 403 }; 404 ; 405 ; 406 ; 407/*! \brief cross entropy error function; 408 *; 409 *; 410 */; 411 template <typename ItProbability, typename ItTruth, typename ItDelta, typename ItInvActFnc>; 412 double crossEntropy (ItProbability itProbabilityBegin, ItProbability itProbabilityEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc /*itInvActFnc*/, double patternWeight); 413 {; 414 bool hasDeltas = (itDelta != itDeltaEnd);; 415 ; 416 double errorSum = 0.0;; 417 for (ItProbability itProbability = itProbabilityBegin; itProbability != itProbabilityEnd; ++itProbability); 418 {; 419 double probability = *itProbability;; 420 double truth = *itTruthBegin;; 421 /* truth = truth < 0.1 ? 0.1 : truth; */; 422 /* truth = truth > 0.9 ? 0.9 : truth; */; 423 truth = truth < 0.5 ? 0.1 : 0.9;; 424 if (hasDeltas); 425 {; 426 double delta = probability - truth;; 427 (*itDelta) = delta*patternWeight;; 428// (*itDelta) = (*itInvActFnc)(probability) * delta * patternWeight;; 429 ++itDelta;; 430 }; 431 double error (0);; 432 if (probability == 0) // protection against log (0); 433 {; 434 if (truth >= 0.5); 435 error += 1.0;; 436 }; 437 else if (probability == 1); 438 {; 439 if (truth < 0.5); 440 error += 1.",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:12226,Availability,error,errorSum,12226,"382 double sumOfSquares (ItOutput itOutputBegin, ItOutput itOutputEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, InvFnc invFnc, double patternWeight); 383 {; 384 double errorSum = 0.0;; 385 ; 386 // output - truth; 387 ItTruth itTruth = itTruthBegin;; 388 bool hasDeltas = (itDelta != itDeltaEnd);; 389 for (ItOutput itOutput = itOutputBegin; itOutput != itOutputEnd; ++itOutput, ++itTruth); 390 {; 391// assert (itTruth != itTruthEnd);; 392 double output = (*itOutput);; 393 double error = output - (*itTruth);; 394 if (hasDeltas); 395 {; 396 (*itDelta) = (*invFnc.get ()) (output) * error * patternWeight;; 397 ++itDelta;; 398 }; 399 errorSum += error*error * patternWeight;; 400 }; 401 ; 402 return 0.5*errorSum;; 403 }; 404 ; 405 ; 406 ; 407/*! \brief cross entropy error function; 408 *; 409 *; 410 */; 411 template <typename ItProbability, typename ItTruth, typename ItDelta, typename ItInvActFnc>; 412 double crossEntropy (ItProbability itProbabilityBegin, ItProbability itProbabilityEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc /*itInvActFnc*/, double patternWeight); 413 {; 414 bool hasDeltas = (itDelta != itDeltaEnd);; 415 ; 416 double errorSum = 0.0;; 417 for (ItProbability itProbability = itProbabilityBegin; itProbability != itProbabilityEnd; ++itProbability); 418 {; 419 double probability = *itProbability;; 420 double truth = *itTruthBegin;; 421 /* truth = truth < 0.1 ? 0.1 : truth; */; 422 /* truth = truth > 0.9 ? 0.9 : truth; */; 423 truth = truth < 0.5 ? 0.1 : 0.9;; 424 if (hasDeltas); 425 {; 426 double delta = probability - truth;; 427 (*itDelta) = delta*patternWeight;; 428// (*itDelta) = (*itInvActFnc)(probability) * delta * patternWeight;; 429 ++itDelta;; 430 }; 431 double error (0);; 432 if (probability == 0) // protection against log (0); 433 {; 434 if (truth >= 0.5); 435 error += 1.0;; 436 }; 437 else if (probability == 1); 438 {; 439 if (truth < 0.5); 440 error += 1.",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:12783,Availability,error,error,12783,"turn 0.5*errorSum;; 403 }; 404 ; 405 ; 406 ; 407/*! \brief cross entropy error function; 408 *; 409 *; 410 */; 411 template <typename ItProbability, typename ItTruth, typename ItDelta, typename ItInvActFnc>; 412 double crossEntropy (ItProbability itProbabilityBegin, ItProbability itProbabilityEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc /*itInvActFnc*/, double patternWeight); 413 {; 414 bool hasDeltas = (itDelta != itDeltaEnd);; 415 ; 416 double errorSum = 0.0;; 417 for (ItProbability itProbability = itProbabilityBegin; itProbability != itProbabilityEnd; ++itProbability); 418 {; 419 double probability = *itProbability;; 420 double truth = *itTruthBegin;; 421 /* truth = truth < 0.1 ? 0.1 : truth; */; 422 /* truth = truth > 0.9 ? 0.9 : truth; */; 423 truth = truth < 0.5 ? 0.1 : 0.9;; 424 if (hasDeltas); 425 {; 426 double delta = probability - truth;; 427 (*itDelta) = delta*patternWeight;; 428// (*itDelta) = (*itInvActFnc)(probability) * delta * patternWeight;; 429 ++itDelta;; 430 }; 431 double error (0);; 432 if (probability == 0) // protection against log (0); 433 {; 434 if (truth >= 0.5); 435 error += 1.0;; 436 }; 437 else if (probability == 1); 438 {; 439 if (truth < 0.5); 440 error += 1.0;; 441 }; 442 else; 443 error += - (truth * log (probability) + (1.0-truth) * log (1.0-probability)); // cross entropy function; 444 errorSum += error * patternWeight;; 445 ; 446 }; 447 return errorSum;; 448 }; 449 ; 450 ; 451 ; 452 ; 453/*! \brief soft-max-cross-entropy error function (for mutual exclusive cross-entropy); 454 *; 455 *; 456 */; 457 template <typename ItOutput, typename ItTruth, typename ItDelta, typename ItInvActFnc>; 458 double softMaxCrossEntropy (ItOutput itProbabilityBegin, ItOutput itProbabilityEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc /*itInvActFnc*/, double patternWeight); 459 {; 460 double errorSum = 0.0;; 461 ; 462 bool hasDeltas = (itDelta != i",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:12886,Availability,error,error,12886," typename ItDelta, typename ItInvActFnc>; 412 double crossEntropy (ItProbability itProbabilityBegin, ItProbability itProbabilityEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc /*itInvActFnc*/, double patternWeight); 413 {; 414 bool hasDeltas = (itDelta != itDeltaEnd);; 415 ; 416 double errorSum = 0.0;; 417 for (ItProbability itProbability = itProbabilityBegin; itProbability != itProbabilityEnd; ++itProbability); 418 {; 419 double probability = *itProbability;; 420 double truth = *itTruthBegin;; 421 /* truth = truth < 0.1 ? 0.1 : truth; */; 422 /* truth = truth > 0.9 ? 0.9 : truth; */; 423 truth = truth < 0.5 ? 0.1 : 0.9;; 424 if (hasDeltas); 425 {; 426 double delta = probability - truth;; 427 (*itDelta) = delta*patternWeight;; 428// (*itDelta) = (*itInvActFnc)(probability) * delta * patternWeight;; 429 ++itDelta;; 430 }; 431 double error (0);; 432 if (probability == 0) // protection against log (0); 433 {; 434 if (truth >= 0.5); 435 error += 1.0;; 436 }; 437 else if (probability == 1); 438 {; 439 if (truth < 0.5); 440 error += 1.0;; 441 }; 442 else; 443 error += - (truth * log (probability) + (1.0-truth) * log (1.0-probability)); // cross entropy function; 444 errorSum += error * patternWeight;; 445 ; 446 }; 447 return errorSum;; 448 }; 449 ; 450 ; 451 ; 452 ; 453/*! \brief soft-max-cross-entropy error function (for mutual exclusive cross-entropy); 454 *; 455 *; 456 */; 457 template <typename ItOutput, typename ItTruth, typename ItDelta, typename ItInvActFnc>; 458 double softMaxCrossEntropy (ItOutput itProbabilityBegin, ItOutput itProbabilityEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc /*itInvActFnc*/, double patternWeight); 459 {; 460 double errorSum = 0.0;; 461 ; 462 bool hasDeltas = (itDelta != itDeltaEnd);; 463 // output - truth; 464 ItTruth itTruth = itTruthBegin;; 465 for (auto itProbability = itProbabilityBegin; itProbability != itProbabilityEnd; ++itProb",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:12973,Availability,error,error,12973,"abilityBegin, ItProbability itProbabilityEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc /*itInvActFnc*/, double patternWeight); 413 {; 414 bool hasDeltas = (itDelta != itDeltaEnd);; 415 ; 416 double errorSum = 0.0;; 417 for (ItProbability itProbability = itProbabilityBegin; itProbability != itProbabilityEnd; ++itProbability); 418 {; 419 double probability = *itProbability;; 420 double truth = *itTruthBegin;; 421 /* truth = truth < 0.1 ? 0.1 : truth; */; 422 /* truth = truth > 0.9 ? 0.9 : truth; */; 423 truth = truth < 0.5 ? 0.1 : 0.9;; 424 if (hasDeltas); 425 {; 426 double delta = probability - truth;; 427 (*itDelta) = delta*patternWeight;; 428// (*itDelta) = (*itInvActFnc)(probability) * delta * patternWeight;; 429 ++itDelta;; 430 }; 431 double error (0);; 432 if (probability == 0) // protection against log (0); 433 {; 434 if (truth >= 0.5); 435 error += 1.0;; 436 }; 437 else if (probability == 1); 438 {; 439 if (truth < 0.5); 440 error += 1.0;; 441 }; 442 else; 443 error += - (truth * log (probability) + (1.0-truth) * log (1.0-probability)); // cross entropy function; 444 errorSum += error * patternWeight;; 445 ; 446 }; 447 return errorSum;; 448 }; 449 ; 450 ; 451 ; 452 ; 453/*! \brief soft-max-cross-entropy error function (for mutual exclusive cross-entropy); 454 *; 455 *; 456 */; 457 template <typename ItOutput, typename ItTruth, typename ItDelta, typename ItInvActFnc>; 458 double softMaxCrossEntropy (ItOutput itProbabilityBegin, ItOutput itProbabilityEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc /*itInvActFnc*/, double patternWeight); 459 {; 460 double errorSum = 0.0;; 461 ; 462 bool hasDeltas = (itDelta != itDeltaEnd);; 463 // output - truth; 464 ItTruth itTruth = itTruthBegin;; 465 for (auto itProbability = itProbabilityBegin; itProbability != itProbabilityEnd; ++itProbability, ++itTruth); 466 {; 467// assert (itTruth != itTruthEnd);; 468 double probabili",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:13009,Availability,error,error,13009,", ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc /*itInvActFnc*/, double patternWeight); 413 {; 414 bool hasDeltas = (itDelta != itDeltaEnd);; 415 ; 416 double errorSum = 0.0;; 417 for (ItProbability itProbability = itProbabilityBegin; itProbability != itProbabilityEnd; ++itProbability); 418 {; 419 double probability = *itProbability;; 420 double truth = *itTruthBegin;; 421 /* truth = truth < 0.1 ? 0.1 : truth; */; 422 /* truth = truth > 0.9 ? 0.9 : truth; */; 423 truth = truth < 0.5 ? 0.1 : 0.9;; 424 if (hasDeltas); 425 {; 426 double delta = probability - truth;; 427 (*itDelta) = delta*patternWeight;; 428// (*itDelta) = (*itInvActFnc)(probability) * delta * patternWeight;; 429 ++itDelta;; 430 }; 431 double error (0);; 432 if (probability == 0) // protection against log (0); 433 {; 434 if (truth >= 0.5); 435 error += 1.0;; 436 }; 437 else if (probability == 1); 438 {; 439 if (truth < 0.5); 440 error += 1.0;; 441 }; 442 else; 443 error += - (truth * log (probability) + (1.0-truth) * log (1.0-probability)); // cross entropy function; 444 errorSum += error * patternWeight;; 445 ; 446 }; 447 return errorSum;; 448 }; 449 ; 450 ; 451 ; 452 ; 453/*! \brief soft-max-cross-entropy error function (for mutual exclusive cross-entropy); 454 *; 455 *; 456 */; 457 template <typename ItOutput, typename ItTruth, typename ItDelta, typename ItInvActFnc>; 458 double softMaxCrossEntropy (ItOutput itProbabilityBegin, ItOutput itProbabilityEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc /*itInvActFnc*/, double patternWeight); 459 {; 460 double errorSum = 0.0;; 461 ; 462 bool hasDeltas = (itDelta != itDeltaEnd);; 463 // output - truth; 464 ItTruth itTruth = itTruthBegin;; 465 for (auto itProbability = itProbabilityBegin; itProbability != itProbabilityEnd; ++itProbability, ++itTruth); 466 {; 467// assert (itTruth != itTruthEnd);; 468 double probability = (*itProbability);; 469 double truth = ",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:13118,Availability,error,errorSum,13118,"robability = *itProbability;; 420 double truth = *itTruthBegin;; 421 /* truth = truth < 0.1 ? 0.1 : truth; */; 422 /* truth = truth > 0.9 ? 0.9 : truth; */; 423 truth = truth < 0.5 ? 0.1 : 0.9;; 424 if (hasDeltas); 425 {; 426 double delta = probability - truth;; 427 (*itDelta) = delta*patternWeight;; 428// (*itDelta) = (*itInvActFnc)(probability) * delta * patternWeight;; 429 ++itDelta;; 430 }; 431 double error (0);; 432 if (probability == 0) // protection against log (0); 433 {; 434 if (truth >= 0.5); 435 error += 1.0;; 436 }; 437 else if (probability == 1); 438 {; 439 if (truth < 0.5); 440 error += 1.0;; 441 }; 442 else; 443 error += - (truth * log (probability) + (1.0-truth) * log (1.0-probability)); // cross entropy function; 444 errorSum += error * patternWeight;; 445 ; 446 }; 447 return errorSum;; 448 }; 449 ; 450 ; 451 ; 452 ; 453/*! \brief soft-max-cross-entropy error function (for mutual exclusive cross-entropy); 454 *; 455 *; 456 */; 457 template <typename ItOutput, typename ItTruth, typename ItDelta, typename ItInvActFnc>; 458 double softMaxCrossEntropy (ItOutput itProbabilityBegin, ItOutput itProbabilityEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc /*itInvActFnc*/, double patternWeight); 459 {; 460 double errorSum = 0.0;; 461 ; 462 bool hasDeltas = (itDelta != itDeltaEnd);; 463 // output - truth; 464 ItTruth itTruth = itTruthBegin;; 465 for (auto itProbability = itProbabilityBegin; itProbability != itProbabilityEnd; ++itProbability, ++itTruth); 466 {; 467// assert (itTruth != itTruthEnd);; 468 double probability = (*itProbability);; 469 double truth = (*itTruth);; 470 if (hasDeltas); 471 {; 472 (*itDelta) = probability - truth;; 473// (*itDelta) = (*itInvActFnc)(sm) * delta * patternWeight;; 474 ++itDelta; //++itInvActFnc;; 475 }; 476 double error (0);; 477 ; 478 error += truth * log (probability);; 479 errorSum += error;; 480 }; 481 ; 482 return -errorSum * patternWeight;; 483 }; 484 ; 485 ; 486 ; 48",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:13130,Availability,error,error,13130,"robability = *itProbability;; 420 double truth = *itTruthBegin;; 421 /* truth = truth < 0.1 ? 0.1 : truth; */; 422 /* truth = truth > 0.9 ? 0.9 : truth; */; 423 truth = truth < 0.5 ? 0.1 : 0.9;; 424 if (hasDeltas); 425 {; 426 double delta = probability - truth;; 427 (*itDelta) = delta*patternWeight;; 428// (*itDelta) = (*itInvActFnc)(probability) * delta * patternWeight;; 429 ++itDelta;; 430 }; 431 double error (0);; 432 if (probability == 0) // protection against log (0); 433 {; 434 if (truth >= 0.5); 435 error += 1.0;; 436 }; 437 else if (probability == 1); 438 {; 439 if (truth < 0.5); 440 error += 1.0;; 441 }; 442 else; 443 error += - (truth * log (probability) + (1.0-truth) * log (1.0-probability)); // cross entropy function; 444 errorSum += error * patternWeight;; 445 ; 446 }; 447 return errorSum;; 448 }; 449 ; 450 ; 451 ; 452 ; 453/*! \brief soft-max-cross-entropy error function (for mutual exclusive cross-entropy); 454 *; 455 *; 456 */; 457 template <typename ItOutput, typename ItTruth, typename ItDelta, typename ItInvActFnc>; 458 double softMaxCrossEntropy (ItOutput itProbabilityBegin, ItOutput itProbabilityEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc /*itInvActFnc*/, double patternWeight); 459 {; 460 double errorSum = 0.0;; 461 ; 462 bool hasDeltas = (itDelta != itDeltaEnd);; 463 // output - truth; 464 ItTruth itTruth = itTruthBegin;; 465 for (auto itProbability = itProbabilityBegin; itProbability != itProbabilityEnd; ++itProbability, ++itTruth); 466 {; 467// assert (itTruth != itTruthEnd);; 468 double probability = (*itProbability);; 469 double truth = (*itTruth);; 470 if (hasDeltas); 471 {; 472 (*itDelta) = probability - truth;; 473// (*itDelta) = (*itInvActFnc)(sm) * delta * patternWeight;; 474 ++itDelta; //++itInvActFnc;; 475 }; 476 double error (0);; 477 ; 478 error += truth * log (probability);; 479 errorSum += error;; 480 }; 481 ; 482 return -errorSum * patternWeight;; 483 }; 484 ; 485 ; 486 ; 48",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:13178,Availability,error,errorSum,13178,"robability = *itProbability;; 420 double truth = *itTruthBegin;; 421 /* truth = truth < 0.1 ? 0.1 : truth; */; 422 /* truth = truth > 0.9 ? 0.9 : truth; */; 423 truth = truth < 0.5 ? 0.1 : 0.9;; 424 if (hasDeltas); 425 {; 426 double delta = probability - truth;; 427 (*itDelta) = delta*patternWeight;; 428// (*itDelta) = (*itInvActFnc)(probability) * delta * patternWeight;; 429 ++itDelta;; 430 }; 431 double error (0);; 432 if (probability == 0) // protection against log (0); 433 {; 434 if (truth >= 0.5); 435 error += 1.0;; 436 }; 437 else if (probability == 1); 438 {; 439 if (truth < 0.5); 440 error += 1.0;; 441 }; 442 else; 443 error += - (truth * log (probability) + (1.0-truth) * log (1.0-probability)); // cross entropy function; 444 errorSum += error * patternWeight;; 445 ; 446 }; 447 return errorSum;; 448 }; 449 ; 450 ; 451 ; 452 ; 453/*! \brief soft-max-cross-entropy error function (for mutual exclusive cross-entropy); 454 *; 455 *; 456 */; 457 template <typename ItOutput, typename ItTruth, typename ItDelta, typename ItInvActFnc>; 458 double softMaxCrossEntropy (ItOutput itProbabilityBegin, ItOutput itProbabilityEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc /*itInvActFnc*/, double patternWeight); 459 {; 460 double errorSum = 0.0;; 461 ; 462 bool hasDeltas = (itDelta != itDeltaEnd);; 463 // output - truth; 464 ItTruth itTruth = itTruthBegin;; 465 for (auto itProbability = itProbabilityBegin; itProbability != itProbabilityEnd; ++itProbability, ++itTruth); 466 {; 467// assert (itTruth != itTruthEnd);; 468 double probability = (*itProbability);; 469 double truth = (*itTruth);; 470 if (hasDeltas); 471 {; 472 (*itDelta) = probability - truth;; 473// (*itDelta) = (*itInvActFnc)(sm) * delta * patternWeight;; 474 ++itDelta; //++itInvActFnc;; 475 }; 476 double error (0);; 477 ; 478 error += truth * log (probability);; 479 errorSum += error;; 480 }; 481 ; 482 return -errorSum * patternWeight;; 483 }; 484 ; 485 ; 486 ; 48",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:13257,Availability,error,error,13257,"robability = *itProbability;; 420 double truth = *itTruthBegin;; 421 /* truth = truth < 0.1 ? 0.1 : truth; */; 422 /* truth = truth > 0.9 ? 0.9 : truth; */; 423 truth = truth < 0.5 ? 0.1 : 0.9;; 424 if (hasDeltas); 425 {; 426 double delta = probability - truth;; 427 (*itDelta) = delta*patternWeight;; 428// (*itDelta) = (*itInvActFnc)(probability) * delta * patternWeight;; 429 ++itDelta;; 430 }; 431 double error (0);; 432 if (probability == 0) // protection against log (0); 433 {; 434 if (truth >= 0.5); 435 error += 1.0;; 436 }; 437 else if (probability == 1); 438 {; 439 if (truth < 0.5); 440 error += 1.0;; 441 }; 442 else; 443 error += - (truth * log (probability) + (1.0-truth) * log (1.0-probability)); // cross entropy function; 444 errorSum += error * patternWeight;; 445 ; 446 }; 447 return errorSum;; 448 }; 449 ; 450 ; 451 ; 452 ; 453/*! \brief soft-max-cross-entropy error function (for mutual exclusive cross-entropy); 454 *; 455 *; 456 */; 457 template <typename ItOutput, typename ItTruth, typename ItDelta, typename ItInvActFnc>; 458 double softMaxCrossEntropy (ItOutput itProbabilityBegin, ItOutput itProbabilityEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc /*itInvActFnc*/, double patternWeight); 459 {; 460 double errorSum = 0.0;; 461 ; 462 bool hasDeltas = (itDelta != itDeltaEnd);; 463 // output - truth; 464 ItTruth itTruth = itTruthBegin;; 465 for (auto itProbability = itProbabilityBegin; itProbability != itProbabilityEnd; ++itProbability, ++itTruth); 466 {; 467// assert (itTruth != itTruthEnd);; 468 double probability = (*itProbability);; 469 double truth = (*itTruth);; 470 if (hasDeltas); 471 {; 472 (*itDelta) = probability - truth;; 473// (*itDelta) = (*itInvActFnc)(sm) * delta * patternWeight;; 474 ++itDelta; //++itInvActFnc;; 475 }; 476 double error (0);; 477 ; 478 error += truth * log (probability);; 479 errorSum += error;; 480 }; 481 ; 482 return -errorSum * patternWeight;; 483 }; 484 ; 485 ; 486 ; 48",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:13665,Availability,error,errorSum,13665,"robability = *itProbability;; 420 double truth = *itTruthBegin;; 421 /* truth = truth < 0.1 ? 0.1 : truth; */; 422 /* truth = truth > 0.9 ? 0.9 : truth; */; 423 truth = truth < 0.5 ? 0.1 : 0.9;; 424 if (hasDeltas); 425 {; 426 double delta = probability - truth;; 427 (*itDelta) = delta*patternWeight;; 428// (*itDelta) = (*itInvActFnc)(probability) * delta * patternWeight;; 429 ++itDelta;; 430 }; 431 double error (0);; 432 if (probability == 0) // protection against log (0); 433 {; 434 if (truth >= 0.5); 435 error += 1.0;; 436 }; 437 else if (probability == 1); 438 {; 439 if (truth < 0.5); 440 error += 1.0;; 441 }; 442 else; 443 error += - (truth * log (probability) + (1.0-truth) * log (1.0-probability)); // cross entropy function; 444 errorSum += error * patternWeight;; 445 ; 446 }; 447 return errorSum;; 448 }; 449 ; 450 ; 451 ; 452 ; 453/*! \brief soft-max-cross-entropy error function (for mutual exclusive cross-entropy); 454 *; 455 *; 456 */; 457 template <typename ItOutput, typename ItTruth, typename ItDelta, typename ItInvActFnc>; 458 double softMaxCrossEntropy (ItOutput itProbabilityBegin, ItOutput itProbabilityEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc /*itInvActFnc*/, double patternWeight); 459 {; 460 double errorSum = 0.0;; 461 ; 462 bool hasDeltas = (itDelta != itDeltaEnd);; 463 // output - truth; 464 ItTruth itTruth = itTruthBegin;; 465 for (auto itProbability = itProbabilityBegin; itProbability != itProbabilityEnd; ++itProbability, ++itTruth); 466 {; 467// assert (itTruth != itTruthEnd);; 468 double probability = (*itProbability);; 469 double truth = (*itTruth);; 470 if (hasDeltas); 471 {; 472 (*itDelta) = probability - truth;; 473// (*itDelta) = (*itInvActFnc)(sm) * delta * patternWeight;; 474 ++itDelta; //++itInvActFnc;; 475 }; 476 double error (0);; 477 ; 478 error += truth * log (probability);; 479 errorSum += error;; 480 }; 481 ; 482 return -errorSum * patternWeight;; 483 }; 484 ; 485 ; 486 ; 48",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:14212,Availability,error,error,14212,"456 */; 457 template <typename ItOutput, typename ItTruth, typename ItDelta, typename ItInvActFnc>; 458 double softMaxCrossEntropy (ItOutput itProbabilityBegin, ItOutput itProbabilityEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc /*itInvActFnc*/, double patternWeight); 459 {; 460 double errorSum = 0.0;; 461 ; 462 bool hasDeltas = (itDelta != itDeltaEnd);; 463 // output - truth; 464 ItTruth itTruth = itTruthBegin;; 465 for (auto itProbability = itProbabilityBegin; itProbability != itProbabilityEnd; ++itProbability, ++itTruth); 466 {; 467// assert (itTruth != itTruthEnd);; 468 double probability = (*itProbability);; 469 double truth = (*itTruth);; 470 if (hasDeltas); 471 {; 472 (*itDelta) = probability - truth;; 473// (*itDelta) = (*itInvActFnc)(sm) * delta * patternWeight;; 474 ++itDelta; //++itInvActFnc;; 475 }; 476 double error (0);; 477 ; 478 error += truth * log (probability);; 479 errorSum += error;; 480 }; 481 ; 482 return -errorSum * patternWeight;; 483 }; 484 ; 485 ; 486 ; 487 ; 488 ; 489 ; 490 ; 491 ; 492 ; 493/*! \brief compute the weight decay for regularization (L1 or L2); 494 *; 495 *; 496 */; 497 template <typename ItWeight>; 498 double weightDecay (double error, ItWeight itWeight, ItWeight itWeightEnd, double factorWeightDecay, EnumRegularization eRegularization); 499 {; 500 if (eRegularization == EnumRegularization::L1); 501 {; 502 // weight decay (regularization); 503 double w = 0;; 504 size_t n = 0;; 505 for (; itWeight != itWeightEnd; ++itWeight, ++n); 506 {; 507 double weight = (*itWeight);; 508 w += std::fabs (weight);; 509 }; 510 return error + 0.5 * w * factorWeightDecay / n;; 511 }; 512 else if (eRegularization == EnumRegularization::L2); 513 {; 514 // weight decay (regularization); 515 double w = 0;; 516 size_t n = 0;; 517 for (; itWeight != itWeightEnd; ++itWeight, ++n); 518 {; 519 double weight = (*itWeight);; 520 w += weight*weight;; 521 }; 522 return error + 0.5 * w * factorWeightDecay /",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:14234,Availability,error,error,14234,"456 */; 457 template <typename ItOutput, typename ItTruth, typename ItDelta, typename ItInvActFnc>; 458 double softMaxCrossEntropy (ItOutput itProbabilityBegin, ItOutput itProbabilityEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc /*itInvActFnc*/, double patternWeight); 459 {; 460 double errorSum = 0.0;; 461 ; 462 bool hasDeltas = (itDelta != itDeltaEnd);; 463 // output - truth; 464 ItTruth itTruth = itTruthBegin;; 465 for (auto itProbability = itProbabilityBegin; itProbability != itProbabilityEnd; ++itProbability, ++itTruth); 466 {; 467// assert (itTruth != itTruthEnd);; 468 double probability = (*itProbability);; 469 double truth = (*itTruth);; 470 if (hasDeltas); 471 {; 472 (*itDelta) = probability - truth;; 473// (*itDelta) = (*itInvActFnc)(sm) * delta * patternWeight;; 474 ++itDelta; //++itInvActFnc;; 475 }; 476 double error (0);; 477 ; 478 error += truth * log (probability);; 479 errorSum += error;; 480 }; 481 ; 482 return -errorSum * patternWeight;; 483 }; 484 ; 485 ; 486 ; 487 ; 488 ; 489 ; 490 ; 491 ; 492 ; 493/*! \brief compute the weight decay for regularization (L1 or L2); 494 *; 495 *; 496 */; 497 template <typename ItWeight>; 498 double weightDecay (double error, ItWeight itWeight, ItWeight itWeightEnd, double factorWeightDecay, EnumRegularization eRegularization); 499 {; 500 if (eRegularization == EnumRegularization::L1); 501 {; 502 // weight decay (regularization); 503 double w = 0;; 504 size_t n = 0;; 505 for (; itWeight != itWeightEnd; ++itWeight, ++n); 506 {; 507 double weight = (*itWeight);; 508 w += std::fabs (weight);; 509 }; 510 return error + 0.5 * w * factorWeightDecay / n;; 511 }; 512 else if (eRegularization == EnumRegularization::L2); 513 {; 514 // weight decay (regularization); 515 double w = 0;; 516 size_t n = 0;; 517 for (; itWeight != itWeightEnd; ++itWeight, ++n); 518 {; 519 double weight = (*itWeight);; 520 w += weight*weight;; 521 }; 522 return error + 0.5 * w * factorWeightDecay /",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:14275,Availability,error,errorSum,14275,"456 */; 457 template <typename ItOutput, typename ItTruth, typename ItDelta, typename ItInvActFnc>; 458 double softMaxCrossEntropy (ItOutput itProbabilityBegin, ItOutput itProbabilityEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc /*itInvActFnc*/, double patternWeight); 459 {; 460 double errorSum = 0.0;; 461 ; 462 bool hasDeltas = (itDelta != itDeltaEnd);; 463 // output - truth; 464 ItTruth itTruth = itTruthBegin;; 465 for (auto itProbability = itProbabilityBegin; itProbability != itProbabilityEnd; ++itProbability, ++itTruth); 466 {; 467// assert (itTruth != itTruthEnd);; 468 double probability = (*itProbability);; 469 double truth = (*itTruth);; 470 if (hasDeltas); 471 {; 472 (*itDelta) = probability - truth;; 473// (*itDelta) = (*itInvActFnc)(sm) * delta * patternWeight;; 474 ++itDelta; //++itInvActFnc;; 475 }; 476 double error (0);; 477 ; 478 error += truth * log (probability);; 479 errorSum += error;; 480 }; 481 ; 482 return -errorSum * patternWeight;; 483 }; 484 ; 485 ; 486 ; 487 ; 488 ; 489 ; 490 ; 491 ; 492 ; 493/*! \brief compute the weight decay for regularization (L1 or L2); 494 *; 495 *; 496 */; 497 template <typename ItWeight>; 498 double weightDecay (double error, ItWeight itWeight, ItWeight itWeightEnd, double factorWeightDecay, EnumRegularization eRegularization); 499 {; 500 if (eRegularization == EnumRegularization::L1); 501 {; 502 // weight decay (regularization); 503 double w = 0;; 504 size_t n = 0;; 505 for (; itWeight != itWeightEnd; ++itWeight, ++n); 506 {; 507 double weight = (*itWeight);; 508 w += std::fabs (weight);; 509 }; 510 return error + 0.5 * w * factorWeightDecay / n;; 511 }; 512 else if (eRegularization == EnumRegularization::L2); 513 {; 514 // weight decay (regularization); 515 double w = 0;; 516 size_t n = 0;; 517 for (; itWeight != itWeightEnd; ++itWeight, ++n); 518 {; 519 double weight = (*itWeight);; 520 w += weight*weight;; 521 }; 522 return error + 0.5 * w * factorWeightDecay /",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:14287,Availability,error,error,14287,"456 */; 457 template <typename ItOutput, typename ItTruth, typename ItDelta, typename ItInvActFnc>; 458 double softMaxCrossEntropy (ItOutput itProbabilityBegin, ItOutput itProbabilityEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc /*itInvActFnc*/, double patternWeight); 459 {; 460 double errorSum = 0.0;; 461 ; 462 bool hasDeltas = (itDelta != itDeltaEnd);; 463 // output - truth; 464 ItTruth itTruth = itTruthBegin;; 465 for (auto itProbability = itProbabilityBegin; itProbability != itProbabilityEnd; ++itProbability, ++itTruth); 466 {; 467// assert (itTruth != itTruthEnd);; 468 double probability = (*itProbability);; 469 double truth = (*itTruth);; 470 if (hasDeltas); 471 {; 472 (*itDelta) = probability - truth;; 473// (*itDelta) = (*itInvActFnc)(sm) * delta * patternWeight;; 474 ++itDelta; //++itInvActFnc;; 475 }; 476 double error (0);; 477 ; 478 error += truth * log (probability);; 479 errorSum += error;; 480 }; 481 ; 482 return -errorSum * patternWeight;; 483 }; 484 ; 485 ; 486 ; 487 ; 488 ; 489 ; 490 ; 491 ; 492 ; 493/*! \brief compute the weight decay for regularization (L1 or L2); 494 *; 495 *; 496 */; 497 template <typename ItWeight>; 498 double weightDecay (double error, ItWeight itWeight, ItWeight itWeightEnd, double factorWeightDecay, EnumRegularization eRegularization); 499 {; 500 if (eRegularization == EnumRegularization::L1); 501 {; 502 // weight decay (regularization); 503 double w = 0;; 504 size_t n = 0;; 505 for (; itWeight != itWeightEnd; ++itWeight, ++n); 506 {; 507 double weight = (*itWeight);; 508 w += std::fabs (weight);; 509 }; 510 return error + 0.5 * w * factorWeightDecay / n;; 511 }; 512 else if (eRegularization == EnumRegularization::L2); 513 {; 514 // weight decay (regularization); 515 double w = 0;; 516 size_t n = 0;; 517 for (; itWeight != itWeightEnd; ++itWeight, ++n); 518 {; 519 double weight = (*itWeight);; 520 w += weight*weight;; 521 }; 522 return error + 0.5 * w * factorWeightDecay /",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:14320,Availability,error,errorSum,14320,"456 */; 457 template <typename ItOutput, typename ItTruth, typename ItDelta, typename ItInvActFnc>; 458 double softMaxCrossEntropy (ItOutput itProbabilityBegin, ItOutput itProbabilityEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc /*itInvActFnc*/, double patternWeight); 459 {; 460 double errorSum = 0.0;; 461 ; 462 bool hasDeltas = (itDelta != itDeltaEnd);; 463 // output - truth; 464 ItTruth itTruth = itTruthBegin;; 465 for (auto itProbability = itProbabilityBegin; itProbability != itProbabilityEnd; ++itProbability, ++itTruth); 466 {; 467// assert (itTruth != itTruthEnd);; 468 double probability = (*itProbability);; 469 double truth = (*itTruth);; 470 if (hasDeltas); 471 {; 472 (*itDelta) = probability - truth;; 473// (*itDelta) = (*itInvActFnc)(sm) * delta * patternWeight;; 474 ++itDelta; //++itInvActFnc;; 475 }; 476 double error (0);; 477 ; 478 error += truth * log (probability);; 479 errorSum += error;; 480 }; 481 ; 482 return -errorSum * patternWeight;; 483 }; 484 ; 485 ; 486 ; 487 ; 488 ; 489 ; 490 ; 491 ; 492 ; 493/*! \brief compute the weight decay for regularization (L1 or L2); 494 *; 495 *; 496 */; 497 template <typename ItWeight>; 498 double weightDecay (double error, ItWeight itWeight, ItWeight itWeightEnd, double factorWeightDecay, EnumRegularization eRegularization); 499 {; 500 if (eRegularization == EnumRegularization::L1); 501 {; 502 // weight decay (regularization); 503 double w = 0;; 504 size_t n = 0;; 505 for (; itWeight != itWeightEnd; ++itWeight, ++n); 506 {; 507 double weight = (*itWeight);; 508 w += std::fabs (weight);; 509 }; 510 return error + 0.5 * w * factorWeightDecay / n;; 511 }; 512 else if (eRegularization == EnumRegularization::L2); 513 {; 514 // weight decay (regularization); 515 double w = 0;; 516 size_t n = 0;; 517 for (; itWeight != itWeightEnd; ++itWeight, ++n); 518 {; 519 double weight = (*itWeight);; 520 w += weight*weight;; 521 }; 522 return error + 0.5 * w * factorWeightDecay /",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:14565,Availability,error,error,14565,"456 */; 457 template <typename ItOutput, typename ItTruth, typename ItDelta, typename ItInvActFnc>; 458 double softMaxCrossEntropy (ItOutput itProbabilityBegin, ItOutput itProbabilityEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc /*itInvActFnc*/, double patternWeight); 459 {; 460 double errorSum = 0.0;; 461 ; 462 bool hasDeltas = (itDelta != itDeltaEnd);; 463 // output - truth; 464 ItTruth itTruth = itTruthBegin;; 465 for (auto itProbability = itProbabilityBegin; itProbability != itProbabilityEnd; ++itProbability, ++itTruth); 466 {; 467// assert (itTruth != itTruthEnd);; 468 double probability = (*itProbability);; 469 double truth = (*itTruth);; 470 if (hasDeltas); 471 {; 472 (*itDelta) = probability - truth;; 473// (*itDelta) = (*itInvActFnc)(sm) * delta * patternWeight;; 474 ++itDelta; //++itInvActFnc;; 475 }; 476 double error (0);; 477 ; 478 error += truth * log (probability);; 479 errorSum += error;; 480 }; 481 ; 482 return -errorSum * patternWeight;; 483 }; 484 ; 485 ; 486 ; 487 ; 488 ; 489 ; 490 ; 491 ; 492 ; 493/*! \brief compute the weight decay for regularization (L1 or L2); 494 *; 495 *; 496 */; 497 template <typename ItWeight>; 498 double weightDecay (double error, ItWeight itWeight, ItWeight itWeightEnd, double factorWeightDecay, EnumRegularization eRegularization); 499 {; 500 if (eRegularization == EnumRegularization::L1); 501 {; 502 // weight decay (regularization); 503 double w = 0;; 504 size_t n = 0;; 505 for (; itWeight != itWeightEnd; ++itWeight, ++n); 506 {; 507 double weight = (*itWeight);; 508 w += std::fabs (weight);; 509 }; 510 return error + 0.5 * w * factorWeightDecay / n;; 511 }; 512 else if (eRegularization == EnumRegularization::L2); 513 {; 514 // weight decay (regularization); 515 double w = 0;; 516 size_t n = 0;; 517 for (; itWeight != itWeightEnd; ++itWeight, ++n); 518 {; 519 double weight = (*itWeight);; 520 w += weight*weight;; 521 }; 522 return error + 0.5 * w * factorWeightDecay /",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:14961,Availability,error,error,14961,"456 */; 457 template <typename ItOutput, typename ItTruth, typename ItDelta, typename ItInvActFnc>; 458 double softMaxCrossEntropy (ItOutput itProbabilityBegin, ItOutput itProbabilityEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc /*itInvActFnc*/, double patternWeight); 459 {; 460 double errorSum = 0.0;; 461 ; 462 bool hasDeltas = (itDelta != itDeltaEnd);; 463 // output - truth; 464 ItTruth itTruth = itTruthBegin;; 465 for (auto itProbability = itProbabilityBegin; itProbability != itProbabilityEnd; ++itProbability, ++itTruth); 466 {; 467// assert (itTruth != itTruthEnd);; 468 double probability = (*itProbability);; 469 double truth = (*itTruth);; 470 if (hasDeltas); 471 {; 472 (*itDelta) = probability - truth;; 473// (*itDelta) = (*itInvActFnc)(sm) * delta * patternWeight;; 474 ++itDelta; //++itInvActFnc;; 475 }; 476 double error (0);; 477 ; 478 error += truth * log (probability);; 479 errorSum += error;; 480 }; 481 ; 482 return -errorSum * patternWeight;; 483 }; 484 ; 485 ; 486 ; 487 ; 488 ; 489 ; 490 ; 491 ; 492 ; 493/*! \brief compute the weight decay for regularization (L1 or L2); 494 *; 495 *; 496 */; 497 template <typename ItWeight>; 498 double weightDecay (double error, ItWeight itWeight, ItWeight itWeightEnd, double factorWeightDecay, EnumRegularization eRegularization); 499 {; 500 if (eRegularization == EnumRegularization::L1); 501 {; 502 // weight decay (regularization); 503 double w = 0;; 504 size_t n = 0;; 505 for (; itWeight != itWeightEnd; ++itWeight, ++n); 506 {; 507 double weight = (*itWeight);; 508 w += std::fabs (weight);; 509 }; 510 return error + 0.5 * w * factorWeightDecay / n;; 511 }; 512 else if (eRegularization == EnumRegularization::L2); 513 {; 514 // weight decay (regularization); 515 double w = 0;; 516 size_t n = 0;; 517 for (; itWeight != itWeightEnd; ++itWeight, ++n); 518 {; 519 double weight = (*itWeight);; 520 w += weight*weight;; 521 }; 522 return error + 0.5 * w * factorWeightDecay /",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:15288,Availability,error,error,15288," * delta * patternWeight;; 474 ++itDelta; //++itInvActFnc;; 475 }; 476 double error (0);; 477 ; 478 error += truth * log (probability);; 479 errorSum += error;; 480 }; 481 ; 482 return -errorSum * patternWeight;; 483 }; 484 ; 485 ; 486 ; 487 ; 488 ; 489 ; 490 ; 491 ; 492 ; 493/*! \brief compute the weight decay for regularization (L1 or L2); 494 *; 495 *; 496 */; 497 template <typename ItWeight>; 498 double weightDecay (double error, ItWeight itWeight, ItWeight itWeightEnd, double factorWeightDecay, EnumRegularization eRegularization); 499 {; 500 if (eRegularization == EnumRegularization::L1); 501 {; 502 // weight decay (regularization); 503 double w = 0;; 504 size_t n = 0;; 505 for (; itWeight != itWeightEnd; ++itWeight, ++n); 506 {; 507 double weight = (*itWeight);; 508 w += std::fabs (weight);; 509 }; 510 return error + 0.5 * w * factorWeightDecay / n;; 511 }; 512 else if (eRegularization == EnumRegularization::L2); 513 {; 514 // weight decay (regularization); 515 double w = 0;; 516 size_t n = 0;; 517 for (; itWeight != itWeightEnd; ++itWeight, ++n); 518 {; 519 double weight = (*itWeight);; 520 w += weight*weight;; 521 }; 522 return error + 0.5 * w * factorWeightDecay / n;; 523 }; 524 else; 525 return error;; 526 }; 527 ; 528 ; 529 ; 530 ; 531 ; 532 ; 533 ; 534 ; 535 ; 536 ; 537 ; 538 ; 539 ; 540 ; 541/*! \brief apply the weights (and functions) in forward direction of the DNN; 542 *; 543 *; 544 */; 545 template <typename LAYERDATA>; 546 void forward (const LAYERDATA& prevLayerData, LAYERDATA& currLayerData); 547 {; 548 if (prevLayerData.hasDropOut ()); 549 {; 550 applyWeights<true> (prevLayerData.valuesBegin (), prevLayerData.valuesEnd (),; 551 currLayerData.weightsBegin (),; 552 currLayerData.valuesBegin (), currLayerData.valuesEnd (),; 553 prevLayerData.dropOut ());; 554 }; 555 else; 556 {; 557 bool dummy = true;; 558 applyWeights<false> (prevLayerData.valuesBegin (), prevLayerData.valuesEnd (),; 559 currLayerData.weightsBegin (),; 560 currLayerData.valuesBegin",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:15358,Availability,error,error,15358," 497 template <typename ItWeight>; 498 double weightDecay (double error, ItWeight itWeight, ItWeight itWeightEnd, double factorWeightDecay, EnumRegularization eRegularization); 499 {; 500 if (eRegularization == EnumRegularization::L1); 501 {; 502 // weight decay (regularization); 503 double w = 0;; 504 size_t n = 0;; 505 for (; itWeight != itWeightEnd; ++itWeight, ++n); 506 {; 507 double weight = (*itWeight);; 508 w += std::fabs (weight);; 509 }; 510 return error + 0.5 * w * factorWeightDecay / n;; 511 }; 512 else if (eRegularization == EnumRegularization::L2); 513 {; 514 // weight decay (regularization); 515 double w = 0;; 516 size_t n = 0;; 517 for (; itWeight != itWeightEnd; ++itWeight, ++n); 518 {; 519 double weight = (*itWeight);; 520 w += weight*weight;; 521 }; 522 return error + 0.5 * w * factorWeightDecay / n;; 523 }; 524 else; 525 return error;; 526 }; 527 ; 528 ; 529 ; 530 ; 531 ; 532 ; 533 ; 534 ; 535 ; 536 ; 537 ; 538 ; 539 ; 540 ; 541/*! \brief apply the weights (and functions) in forward direction of the DNN; 542 *; 543 *; 544 */; 545 template <typename LAYERDATA>; 546 void forward (const LAYERDATA& prevLayerData, LAYERDATA& currLayerData); 547 {; 548 if (prevLayerData.hasDropOut ()); 549 {; 550 applyWeights<true> (prevLayerData.valuesBegin (), prevLayerData.valuesEnd (),; 551 currLayerData.weightsBegin (),; 552 currLayerData.valuesBegin (), currLayerData.valuesEnd (),; 553 prevLayerData.dropOut ());; 554 }; 555 else; 556 {; 557 bool dummy = true;; 558 applyWeights<false> (prevLayerData.valuesBegin (), prevLayerData.valuesEnd (),; 559 currLayerData.weightsBegin (),; 560 currLayerData.valuesBegin (), currLayerData.valuesEnd (),; 561 &dummy); // dummy to turn on all nodes (no drop out); 562 }; 563 }; 564 ; 565 ; 566 ; 567/*! \brief backward application of the weights (back-propagation of the error); 568 *; 569 *; 570 */; 571template <typename LAYERDATA>; 572 void backward (LAYERDATA& prevLayerData, LAYERDATA& currLayerData); 573{; 574 if (prevLayerData.ha",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:16334,Availability,error,error,16334,"n;; 523 }; 524 else; 525 return error;; 526 }; 527 ; 528 ; 529 ; 530 ; 531 ; 532 ; 533 ; 534 ; 535 ; 536 ; 537 ; 538 ; 539 ; 540 ; 541/*! \brief apply the weights (and functions) in forward direction of the DNN; 542 *; 543 *; 544 */; 545 template <typename LAYERDATA>; 546 void forward (const LAYERDATA& prevLayerData, LAYERDATA& currLayerData); 547 {; 548 if (prevLayerData.hasDropOut ()); 549 {; 550 applyWeights<true> (prevLayerData.valuesBegin (), prevLayerData.valuesEnd (),; 551 currLayerData.weightsBegin (),; 552 currLayerData.valuesBegin (), currLayerData.valuesEnd (),; 553 prevLayerData.dropOut ());; 554 }; 555 else; 556 {; 557 bool dummy = true;; 558 applyWeights<false> (prevLayerData.valuesBegin (), prevLayerData.valuesEnd (),; 559 currLayerData.weightsBegin (),; 560 currLayerData.valuesBegin (), currLayerData.valuesEnd (),; 561 &dummy); // dummy to turn on all nodes (no drop out); 562 }; 563 }; 564 ; 565 ; 566 ; 567/*! \brief backward application of the weights (back-propagation of the error); 568 *; 569 *; 570 */; 571template <typename LAYERDATA>; 572 void backward (LAYERDATA& prevLayerData, LAYERDATA& currLayerData); 573{; 574 if (prevLayerData.hasDropOut ()); 575 {; 576 applyWeightsBackwards<true> (currLayerData.deltasBegin (), currLayerData.deltasEnd (),; 577 currLayerData.weightsBegin (),; 578 prevLayerData.deltasBegin (), prevLayerData.deltasEnd (),; 579 prevLayerData.dropOut ());; 580 }; 581 else; 582 {; 583 bool dummy = true;; 584 applyWeightsBackwards<false> (currLayerData.deltasBegin (), currLayerData.deltasEnd (),; 585 currLayerData.weightsBegin (),; 586 prevLayerData.deltasBegin (), prevLayerData.deltasEnd (),; 587 &dummy); // dummy to use all nodes (no drop out); 588 }; 589}; 590 ; 591 ; 592 ; 593 ; 594 ; 595/*! \brief update the node values; 596 *; 597 *; 598 */; 599 template <typename LAYERDATA>; 600 void update (const LAYERDATA& prevLayerData, LAYERDATA& currLayerData, double factorWeightDecay, EnumRegularization regularization); 601 {; 602 //",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:26785,Availability,error,errors,26785,"output);; 853 if (output.size() == (outputSize() - 1) * batch.size()); 854 {; 855 auto output_iterator = output.begin();; 856 for (auto pattern_it = batch.begin(); pattern_it != batch.end(); ++pattern_it); 857 {; 858 for (size_t output_index = 1; output_index < outputSize(); ++output_index); 859 {; 860 settings.testSample (0, *output_iterator, (*pattern_it).output ().at (0),; 861 (*pattern_it).weight ());; 862 ++output_iterator;; 863 }; 864 }; 865 }; 866 testError += testPatternError; /// batch.size ();; 867 }; 868 // testError /= testPattern.size ();; 869 }; 870 settings.endTestCycle ();; 871// testError /= weightSum;; 872 ; 873 settings.computeResult (*this, weights);; 874 ; 875 hasConverged = settings.hasConverged (testError);; 876 if (!hasConverged && !isWeightsForDrop); 877 {; 878 dropOutWeightFactor (weights, dropFractions, true); // inverse; 879 isWeightsForDrop = true;; 880 }; 881 }; 882 ++testCycleCount;; 883 ++dropOutChangeCount;; 884 ; 885 ; 886// settings.resetPlot (""errors"");; 887 settings.addPoint (""trainErrors"", cycleCount, trainError);; 888 settings.addPoint (""testErrors"", cycleCount, testError);; 889 settings.plot (""trainErrors"", ""C"", 1, kBlue);; 890 settings.plot (""testErrors"", ""C"", 1, kMagenta);; 891 ; 892 ; 893 // setup error plots and progress bar variables for JsMVA; 894 if (fInteractive){; 895 fInteractive->AddPoint(cycleCount, trainError, testError);; 896 if (*fExitFromTraining) break;; 897 *fIPyCurrentIter = 100*(double)settings.maxConvergenceCount () /(double)settings.convergenceSteps ();; 898 }; 899 ; 900 if (hasConverged); 901 break;; 902 ; 903 if ((int)cycleCount % 10 == 0) {; 904 ; 905 TString convText = TString::Format( ""(train/test/epo/conv/maxco): %.3g/%.3g/%d/%d/%d"",; 906 trainError,; 907 testError,; 908 (int)cycleCount,; 909 (int)settings.convergenceCount (),; 910 (int)settings.maxConvergenceCount ());; 911 double progress = 100*(double)settings.maxConvergenceCount () /(double)settings.convergenceSteps ();; 912 settings.cycle (prog",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:27051,Availability,error,error,27051,"iterator, (*pattern_it).output ().at (0),; 861 (*pattern_it).weight ());; 862 ++output_iterator;; 863 }; 864 }; 865 }; 866 testError += testPatternError; /// batch.size ();; 867 }; 868 // testError /= testPattern.size ();; 869 }; 870 settings.endTestCycle ();; 871// testError /= weightSum;; 872 ; 873 settings.computeResult (*this, weights);; 874 ; 875 hasConverged = settings.hasConverged (testError);; 876 if (!hasConverged && !isWeightsForDrop); 877 {; 878 dropOutWeightFactor (weights, dropFractions, true); // inverse; 879 isWeightsForDrop = true;; 880 }; 881 }; 882 ++testCycleCount;; 883 ++dropOutChangeCount;; 884 ; 885 ; 886// settings.resetPlot (""errors"");; 887 settings.addPoint (""trainErrors"", cycleCount, trainError);; 888 settings.addPoint (""testErrors"", cycleCount, testError);; 889 settings.plot (""trainErrors"", ""C"", 1, kBlue);; 890 settings.plot (""testErrors"", ""C"", 1, kMagenta);; 891 ; 892 ; 893 // setup error plots and progress bar variables for JsMVA; 894 if (fInteractive){; 895 fInteractive->AddPoint(cycleCount, trainError, testError);; 896 if (*fExitFromTraining) break;; 897 *fIPyCurrentIter = 100*(double)settings.maxConvergenceCount () /(double)settings.convergenceSteps ();; 898 }; 899 ; 900 if (hasConverged); 901 break;; 902 ; 903 if ((int)cycleCount % 10 == 0) {; 904 ; 905 TString convText = TString::Format( ""(train/test/epo/conv/maxco): %.3g/%.3g/%d/%d/%d"",; 906 trainError,; 907 testError,; 908 (int)cycleCount,; 909 (int)settings.convergenceCount (),; 910 (int)settings.maxConvergenceCount ());; 911 double progress = 100*(double)settings.maxConvergenceCount () /(double)settings.convergenceSteps ();; 912 settings.cycle (progress, convText);; 913 }; 914 }; 915 while (true);; 916 settings.endTrainCycle (trainError);; 917 ; 918 TString convText = TString::Format( ""(train/test/epoch): %.4g/%.4g/%d"", trainError, testError, (int)cycleCount);; 919 double progress = 100*(double)settings.maxConvergenceCount() /(double)settings.convergenceSteps ();; 920 settings.cy",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:29025,Availability,error,error,29025,"tings.endTrainCycle (trainError);; 917 ; 918 TString convText = TString::Format( ""(train/test/epoch): %.4g/%.4g/%d"", trainError, testError, (int)cycleCount);; 919 double progress = 100*(double)settings.maxConvergenceCount() /(double)settings.convergenceSteps ();; 920 settings.cycle (progress, convText);; 921 ; 922 return testError;; 923 }; 924 ; 925 ; 926 ; 927/*! \brief execute a single training cycle; 928 *; 929 * uses multithreading if turned on; 930 *; 931 * \param minimizer the minimizer to be used (e.g. SGD); 932 * \param weights the weight container with all the synapse weights; 933 * \param itPatternBegin begin of the pattern container; 934 * \param itPatternEnd the end of the pattern container; 935 * \param settings the settings for this training (e.g. multithreading or not, regularization, etc.); 936 * \param dropContainer the data for dropping-out nodes (regularization technique); 937 */; 938 template <typename Iterator, typename Minimizer>; 939 inline double Net::trainCycle (Minimizer& minimizer, std::vector<double>& weights,; 940 Iterator itPatternBegin, Iterator itPatternEnd, Settings& settings, DropContainer& dropContainer); 941 {; 942 double error = 0.0;; 943 size_t numPattern = std::distance (itPatternBegin, itPatternEnd);; 944 size_t numBatches = numPattern/settings.batchSize ();; 945 size_t numBatches_stored = numBatches;; 946 ; 947 std::shuffle(itPatternBegin, itPatternEnd, std::default_random_engine{});; 948 Iterator itPatternBatchBegin = itPatternBegin;; 949 Iterator itPatternBatchEnd = itPatternBatchBegin;; 950 ; 951 // create batches; 952 std::vector<Batch> batches;; 953 while (numBatches > 0); 954 {; 955 std::advance (itPatternBatchEnd, settings.batchSize ());; 956 batches.push_back (Batch (itPatternBatchBegin, itPatternBatchEnd));; 957 itPatternBatchBegin = itPatternBatchEnd;; 958 --numBatches;; 959 }; 960 ; 961 // add the last pattern to the last batch; 962 if (itPatternBatchEnd != itPatternEnd); 963 batches.push_back (Batch (itPatternBatch",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:31629,Availability,error,error,31629,"terator itBatchEnd = std::end (batches);; 977 for (size_t iT = 0; iT < numThreads; ++iT); 978 {; 979 if (iT == numThreads-1); 980 itBatchCurrEnd = itBatchEnd;; 981 else; 982 std::advance (itBatchCurrEnd, batchesPerThread);; 983 batchVec.push_back (std::make_pair (itBatchBegin, itBatchCurrEnd));; 984 itBatchBegin = itBatchCurrEnd;; 985 }; 986 ; 987 // -------------------- loop over batches -------------------------------------------; 988 std::vector<std::future<double>> futures;; 989 for (auto& batchRange : batchVec); 990 {; 991 // -------------------- execute each of the batch ranges on a different thread -------------------------------; 992 futures.push_back (; 993 std::async (std::launch::async, [&](); 994 {; 995 double localError = 0.0;; 996 for (auto it = batchRange.first, itEnd = batchRange.second; it != itEnd; ++it); 997 {; 998 Batch& batch = *it;; 999 pass_through_type settingsAndBatch (settings, batch, dropContainer);; 1000 Minimizer minimizerClone (minimizer);; 1001 localError += minimizerClone ((*this), weights, settingsAndBatch); /// call the minimizer; 1002 }; 1003 return localError;; 1004 }); 1005 );; 1006 }; 1007 ; 1008 for (auto& f : futures); 1009 error += f.get ();; 1010 }; 1011 else; 1012 {; 1013 for (auto& batch : batches); 1014 {; 1015 std::tuple<Settings&, Batch&, DropContainer&> settingsAndBatch (settings, batch, dropContainer);; 1016 error += minimizer ((*this), weights, settingsAndBatch);; 1017 }; 1018 }; 1019 ; 1020 numBatches_stored = std::max (numBatches_stored, size_t(1)); /// normalize the error; 1021 error /= numBatches_stored;; 1022 settings.testIteration ();; 1023 ; 1024 return error;; 1025 }; 1026 ; 1027 ; 1028 ; 1029 ; 1030 ; 1031/*! \brief compute the neural net; 1032 *; 1033 * \param input the input data; 1034 * \param weights the weight data; 1035 */; 1036 template <typename Weights>; 1037 std::vector<double> Net::compute (const std::vector<double>& input, const Weights& weights) const; 1038 {; 1039 std::vector<LayerData> layerDa",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:31826,Availability,error,error,31826,"---------------------------------------; 988 std::vector<std::future<double>> futures;; 989 for (auto& batchRange : batchVec); 990 {; 991 // -------------------- execute each of the batch ranges on a different thread -------------------------------; 992 futures.push_back (; 993 std::async (std::launch::async, [&](); 994 {; 995 double localError = 0.0;; 996 for (auto it = batchRange.first, itEnd = batchRange.second; it != itEnd; ++it); 997 {; 998 Batch& batch = *it;; 999 pass_through_type settingsAndBatch (settings, batch, dropContainer);; 1000 Minimizer minimizerClone (minimizer);; 1001 localError += minimizerClone ((*this), weights, settingsAndBatch); /// call the minimizer; 1002 }; 1003 return localError;; 1004 }); 1005 );; 1006 }; 1007 ; 1008 for (auto& f : futures); 1009 error += f.get ();; 1010 }; 1011 else; 1012 {; 1013 for (auto& batch : batches); 1014 {; 1015 std::tuple<Settings&, Batch&, DropContainer&> settingsAndBatch (settings, batch, dropContainer);; 1016 error += minimizer ((*this), weights, settingsAndBatch);; 1017 }; 1018 }; 1019 ; 1020 numBatches_stored = std::max (numBatches_stored, size_t(1)); /// normalize the error; 1021 error /= numBatches_stored;; 1022 settings.testIteration ();; 1023 ; 1024 return error;; 1025 }; 1026 ; 1027 ; 1028 ; 1029 ; 1030 ; 1031/*! \brief compute the neural net; 1032 *; 1033 * \param input the input data; 1034 * \param weights the weight data; 1035 */; 1036 template <typename Weights>; 1037 std::vector<double> Net::compute (const std::vector<double>& input, const Weights& weights) const; 1038 {; 1039 std::vector<LayerData> layerData;; 1040 layerData.reserve (m_layers.size ()+1);; 1041 auto itWeight = begin (weights);; 1042 auto itInputBegin = begin (input);; 1043 auto itInputEnd = end (input);; 1044 layerData.push_back (LayerData (itInputBegin, itInputEnd));; 1045 size_t numNodesPrev = input.size ();; 1046 ; 1047 // -------------------- prepare layer data with one pattern -------------------------------; 1048 for (auto",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:31991,Availability,error,error,31991,"---------------------------------------; 988 std::vector<std::future<double>> futures;; 989 for (auto& batchRange : batchVec); 990 {; 991 // -------------------- execute each of the batch ranges on a different thread -------------------------------; 992 futures.push_back (; 993 std::async (std::launch::async, [&](); 994 {; 995 double localError = 0.0;; 996 for (auto it = batchRange.first, itEnd = batchRange.second; it != itEnd; ++it); 997 {; 998 Batch& batch = *it;; 999 pass_through_type settingsAndBatch (settings, batch, dropContainer);; 1000 Minimizer minimizerClone (minimizer);; 1001 localError += minimizerClone ((*this), weights, settingsAndBatch); /// call the minimizer; 1002 }; 1003 return localError;; 1004 }); 1005 );; 1006 }; 1007 ; 1008 for (auto& f : futures); 1009 error += f.get ();; 1010 }; 1011 else; 1012 {; 1013 for (auto& batch : batches); 1014 {; 1015 std::tuple<Settings&, Batch&, DropContainer&> settingsAndBatch (settings, batch, dropContainer);; 1016 error += minimizer ((*this), weights, settingsAndBatch);; 1017 }; 1018 }; 1019 ; 1020 numBatches_stored = std::max (numBatches_stored, size_t(1)); /// normalize the error; 1021 error /= numBatches_stored;; 1022 settings.testIteration ();; 1023 ; 1024 return error;; 1025 }; 1026 ; 1027 ; 1028 ; 1029 ; 1030 ; 1031/*! \brief compute the neural net; 1032 *; 1033 * \param input the input data; 1034 * \param weights the weight data; 1035 */; 1036 template <typename Weights>; 1037 std::vector<double> Net::compute (const std::vector<double>& input, const Weights& weights) const; 1038 {; 1039 std::vector<LayerData> layerData;; 1040 layerData.reserve (m_layers.size ()+1);; 1041 auto itWeight = begin (weights);; 1042 auto itInputBegin = begin (input);; 1043 auto itInputEnd = end (input);; 1044 layerData.push_back (LayerData (itInputBegin, itInputEnd));; 1045 size_t numNodesPrev = input.size ();; 1046 ; 1047 // -------------------- prepare layer data with one pattern -------------------------------; 1048 for (auto",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:32003,Availability,error,error,32003,"---------------------------------------; 988 std::vector<std::future<double>> futures;; 989 for (auto& batchRange : batchVec); 990 {; 991 // -------------------- execute each of the batch ranges on a different thread -------------------------------; 992 futures.push_back (; 993 std::async (std::launch::async, [&](); 994 {; 995 double localError = 0.0;; 996 for (auto it = batchRange.first, itEnd = batchRange.second; it != itEnd; ++it); 997 {; 998 Batch& batch = *it;; 999 pass_through_type settingsAndBatch (settings, batch, dropContainer);; 1000 Minimizer minimizerClone (minimizer);; 1001 localError += minimizerClone ((*this), weights, settingsAndBatch); /// call the minimizer; 1002 }; 1003 return localError;; 1004 }); 1005 );; 1006 }; 1007 ; 1008 for (auto& f : futures); 1009 error += f.get ();; 1010 }; 1011 else; 1012 {; 1013 for (auto& batch : batches); 1014 {; 1015 std::tuple<Settings&, Batch&, DropContainer&> settingsAndBatch (settings, batch, dropContainer);; 1016 error += minimizer ((*this), weights, settingsAndBatch);; 1017 }; 1018 }; 1019 ; 1020 numBatches_stored = std::max (numBatches_stored, size_t(1)); /// normalize the error; 1021 error /= numBatches_stored;; 1022 settings.testIteration ();; 1023 ; 1024 return error;; 1025 }; 1026 ; 1027 ; 1028 ; 1029 ; 1030 ; 1031/*! \brief compute the neural net; 1032 *; 1033 * \param input the input data; 1034 * \param weights the weight data; 1035 */; 1036 template <typename Weights>; 1037 std::vector<double> Net::compute (const std::vector<double>& input, const Weights& weights) const; 1038 {; 1039 std::vector<LayerData> layerData;; 1040 layerData.reserve (m_layers.size ()+1);; 1041 auto itWeight = begin (weights);; 1042 auto itInputBegin = begin (input);; 1043 auto itInputEnd = end (input);; 1044 layerData.push_back (LayerData (itInputBegin, itInputEnd));; 1045 size_t numNodesPrev = input.size ();; 1046 ; 1047 // -------------------- prepare layer data with one pattern -------------------------------; 1048 for (auto",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:32084,Availability,error,error,32084,"cond; it != itEnd; ++it); 997 {; 998 Batch& batch = *it;; 999 pass_through_type settingsAndBatch (settings, batch, dropContainer);; 1000 Minimizer minimizerClone (minimizer);; 1001 localError += minimizerClone ((*this), weights, settingsAndBatch); /// call the minimizer; 1002 }; 1003 return localError;; 1004 }); 1005 );; 1006 }; 1007 ; 1008 for (auto& f : futures); 1009 error += f.get ();; 1010 }; 1011 else; 1012 {; 1013 for (auto& batch : batches); 1014 {; 1015 std::tuple<Settings&, Batch&, DropContainer&> settingsAndBatch (settings, batch, dropContainer);; 1016 error += minimizer ((*this), weights, settingsAndBatch);; 1017 }; 1018 }; 1019 ; 1020 numBatches_stored = std::max (numBatches_stored, size_t(1)); /// normalize the error; 1021 error /= numBatches_stored;; 1022 settings.testIteration ();; 1023 ; 1024 return error;; 1025 }; 1026 ; 1027 ; 1028 ; 1029 ; 1030 ; 1031/*! \brief compute the neural net; 1032 *; 1033 * \param input the input data; 1034 * \param weights the weight data; 1035 */; 1036 template <typename Weights>; 1037 std::vector<double> Net::compute (const std::vector<double>& input, const Weights& weights) const; 1038 {; 1039 std::vector<LayerData> layerData;; 1040 layerData.reserve (m_layers.size ()+1);; 1041 auto itWeight = begin (weights);; 1042 auto itInputBegin = begin (input);; 1043 auto itInputEnd = end (input);; 1044 layerData.push_back (LayerData (itInputBegin, itInputEnd));; 1045 size_t numNodesPrev = input.size ();; 1046 ; 1047 // -------------------- prepare layer data with one pattern -------------------------------; 1048 for (auto& layer: m_layers); 1049 {; 1050 layerData.push_back (LayerData (layer.numNodes (), itWeight,; 1051 layer.activationFunction (),; 1052 layer.modeOutputValues ()));; 1053 size_t _numWeights = layer.numWeights (numNodesPrev);; 1054 itWeight += _numWeights;; 1055 numNodesPrev = layer.numNodes ();; 1056 }; 1057 ; 1058 ; 1059 // --------- forward -------------; 1060 forwardPattern (m_layers, layerData);; 1061 ; 1062",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:33744,Availability,error,error,33744,"ize_t _numWeights = layer.numWeights (numNodesPrev);; 1054 itWeight += _numWeights;; 1055 numNodesPrev = layer.numNodes ();; 1056 }; 1057 ; 1058 ; 1059 // --------- forward -------------; 1060 forwardPattern (m_layers, layerData);; 1061 ; 1062 // ------------- fetch output ------------------; 1063 std::vector<double> output;; 1064 fetchOutput (layerData.back (), output);; 1065 return output;; 1066 }; 1067 ; 1068 ; 1069 template <typename Weights, typename PassThrough>; 1070 double Net::operator() (PassThrough& settingsAndBatch, const Weights& weights) const; 1071 {; 1072 std::vector<double> nothing; // empty gradients; no backpropagation is done, just forward; 1073 assert (numWeights () == weights.size ());; 1074 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (nothing), std::end (nothing), 10000, nothing, false);; 1075 return error;; 1076 }; 1077 ; 1078 template <typename Weights, typename PassThrough, typename OutContainer>; 1079 double Net::operator() (PassThrough& settingsAndBatch, const Weights& weights, ModeOutput /*eFetch*/, OutContainer& outputContainer) const; 1080 {; 1081 std::vector<double> nothing; // empty gradients; no backpropagation is done, just forward; 1082 assert (numWeights () == weights.size ());; 1083 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (nothing), std::end (nothing), 10000, outputContainer, true);; 1084 return error;; 1085 }; 1086 ; 1087 ; 1088 template <typename Weights, typename Gradients, typename PassThrough>; 1089 double Net::operator() (PassThrough& settingsAndBatch, Weights& weights, Gradients& gradients) const; 1090 {; 1091 std::vector<double> nothing;; 1092 assert (numWeights () == weights.size ());; 1093 assert (weights.size () == gradients.size ());; 1094 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (gradients), std::end (grad",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:33918,Availability,error,error,33918,"ize_t _numWeights = layer.numWeights (numNodesPrev);; 1054 itWeight += _numWeights;; 1055 numNodesPrev = layer.numNodes ();; 1056 }; 1057 ; 1058 ; 1059 // --------- forward -------------; 1060 forwardPattern (m_layers, layerData);; 1061 ; 1062 // ------------- fetch output ------------------; 1063 std::vector<double> output;; 1064 fetchOutput (layerData.back (), output);; 1065 return output;; 1066 }; 1067 ; 1068 ; 1069 template <typename Weights, typename PassThrough>; 1070 double Net::operator() (PassThrough& settingsAndBatch, const Weights& weights) const; 1071 {; 1072 std::vector<double> nothing; // empty gradients; no backpropagation is done, just forward; 1073 assert (numWeights () == weights.size ());; 1074 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (nothing), std::end (nothing), 10000, nothing, false);; 1075 return error;; 1076 }; 1077 ; 1078 template <typename Weights, typename PassThrough, typename OutContainer>; 1079 double Net::operator() (PassThrough& settingsAndBatch, const Weights& weights, ModeOutput /*eFetch*/, OutContainer& outputContainer) const; 1080 {; 1081 std::vector<double> nothing; // empty gradients; no backpropagation is done, just forward; 1082 assert (numWeights () == weights.size ());; 1083 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (nothing), std::end (nothing), 10000, outputContainer, true);; 1084 return error;; 1085 }; 1086 ; 1087 ; 1088 template <typename Weights, typename Gradients, typename PassThrough>; 1089 double Net::operator() (PassThrough& settingsAndBatch, Weights& weights, Gradients& gradients) const; 1090 {; 1091 std::vector<double> nothing;; 1092 assert (numWeights () == weights.size ());; 1093 assert (weights.size () == gradients.size ());; 1094 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (gradients), std::end (grad",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:34330,Availability,error,error,34330,"ights& weights) const; 1071 {; 1072 std::vector<double> nothing; // empty gradients; no backpropagation is done, just forward; 1073 assert (numWeights () == weights.size ());; 1074 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (nothing), std::end (nothing), 10000, nothing, false);; 1075 return error;; 1076 }; 1077 ; 1078 template <typename Weights, typename PassThrough, typename OutContainer>; 1079 double Net::operator() (PassThrough& settingsAndBatch, const Weights& weights, ModeOutput /*eFetch*/, OutContainer& outputContainer) const; 1080 {; 1081 std::vector<double> nothing; // empty gradients; no backpropagation is done, just forward; 1082 assert (numWeights () == weights.size ());; 1083 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (nothing), std::end (nothing), 10000, outputContainer, true);; 1084 return error;; 1085 }; 1086 ; 1087 ; 1088 template <typename Weights, typename Gradients, typename PassThrough>; 1089 double Net::operator() (PassThrough& settingsAndBatch, Weights& weights, Gradients& gradients) const; 1090 {; 1091 std::vector<double> nothing;; 1092 assert (numWeights () == weights.size ());; 1093 assert (weights.size () == gradients.size ());; 1094 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (gradients), std::end (gradients), 0, nothing, false);; 1095 return error;; 1096 }; 1097 ; 1098 template <typename Weights, typename Gradients, typename PassThrough, typename OutContainer>; 1099 double Net::operator() (PassThrough& settingsAndBatch, Weights& weights, Gradients& gradients, ModeOutput eFetch, OutContainer& outputContainer) const; 1100 {; 1101 MATH_UNUSED(eFetch);; 1102 assert (numWeights () == weights.size ());; 1103 assert (weights.size () == gradients.size ());; 1104 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights)",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:34511,Availability,error,error,34511,"ights& weights) const; 1071 {; 1072 std::vector<double> nothing; // empty gradients; no backpropagation is done, just forward; 1073 assert (numWeights () == weights.size ());; 1074 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (nothing), std::end (nothing), 10000, nothing, false);; 1075 return error;; 1076 }; 1077 ; 1078 template <typename Weights, typename PassThrough, typename OutContainer>; 1079 double Net::operator() (PassThrough& settingsAndBatch, const Weights& weights, ModeOutput /*eFetch*/, OutContainer& outputContainer) const; 1080 {; 1081 std::vector<double> nothing; // empty gradients; no backpropagation is done, just forward; 1082 assert (numWeights () == weights.size ());; 1083 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (nothing), std::end (nothing), 10000, outputContainer, true);; 1084 return error;; 1085 }; 1086 ; 1087 ; 1088 template <typename Weights, typename Gradients, typename PassThrough>; 1089 double Net::operator() (PassThrough& settingsAndBatch, Weights& weights, Gradients& gradients) const; 1090 {; 1091 std::vector<double> nothing;; 1092 assert (numWeights () == weights.size ());; 1093 assert (weights.size () == gradients.size ());; 1094 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (gradients), std::end (gradients), 0, nothing, false);; 1095 return error;; 1096 }; 1097 ; 1098 template <typename Weights, typename Gradients, typename PassThrough, typename OutContainer>; 1099 double Net::operator() (PassThrough& settingsAndBatch, Weights& weights, Gradients& gradients, ModeOutput eFetch, OutContainer& outputContainer) const; 1100 {; 1101 MATH_UNUSED(eFetch);; 1102 assert (numWeights () == weights.size ());; 1103 assert (weights.size () == gradients.size ());; 1104 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights)",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:34881,Availability,error,error,34881,"ntainer& outputContainer) const; 1080 {; 1081 std::vector<double> nothing; // empty gradients; no backpropagation is done, just forward; 1082 assert (numWeights () == weights.size ());; 1083 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (nothing), std::end (nothing), 10000, outputContainer, true);; 1084 return error;; 1085 }; 1086 ; 1087 ; 1088 template <typename Weights, typename Gradients, typename PassThrough>; 1089 double Net::operator() (PassThrough& settingsAndBatch, Weights& weights, Gradients& gradients) const; 1090 {; 1091 std::vector<double> nothing;; 1092 assert (numWeights () == weights.size ());; 1093 assert (weights.size () == gradients.size ());; 1094 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (gradients), std::end (gradients), 0, nothing, false);; 1095 return error;; 1096 }; 1097 ; 1098 template <typename Weights, typename Gradients, typename PassThrough, typename OutContainer>; 1099 double Net::operator() (PassThrough& settingsAndBatch, Weights& weights, Gradients& gradients, ModeOutput eFetch, OutContainer& outputContainer) const; 1100 {; 1101 MATH_UNUSED(eFetch);; 1102 assert (numWeights () == weights.size ());; 1103 assert (weights.size () == gradients.size ());; 1104 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (gradients), std::end (gradients), 0, outputContainer, true);; 1105 return error;; 1106 }; 1107 ; 1108 ; 1109 ; 1110 template <typename LayerContainer, typename DropContainer, typename ItWeight, typename ItGradient>; 1111 std::vector<std::vector<LayerData>> Net::prepareLayerData (LayerContainer& _layers,; 1112 Batch& batch,; 1113 const DropContainer& dropContainer,; 1114 ItWeight itWeightBegin,; 1115 ItWeight /*itWeightEnd*/,; 1116 ItGradient itGradientBegin,; 1117 ItGradient itGradientEnd,; 1118 size_t& totalNumWeights) const; 1119 {; 11",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:35055,Availability,error,error,35055,"ntainer& outputContainer) const; 1080 {; 1081 std::vector<double> nothing; // empty gradients; no backpropagation is done, just forward; 1082 assert (numWeights () == weights.size ());; 1083 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (nothing), std::end (nothing), 10000, outputContainer, true);; 1084 return error;; 1085 }; 1086 ; 1087 ; 1088 template <typename Weights, typename Gradients, typename PassThrough>; 1089 double Net::operator() (PassThrough& settingsAndBatch, Weights& weights, Gradients& gradients) const; 1090 {; 1091 std::vector<double> nothing;; 1092 assert (numWeights () == weights.size ());; 1093 assert (weights.size () == gradients.size ());; 1094 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (gradients), std::end (gradients), 0, nothing, false);; 1095 return error;; 1096 }; 1097 ; 1098 template <typename Weights, typename Gradients, typename PassThrough, typename OutContainer>; 1099 double Net::operator() (PassThrough& settingsAndBatch, Weights& weights, Gradients& gradients, ModeOutput eFetch, OutContainer& outputContainer) const; 1100 {; 1101 MATH_UNUSED(eFetch);; 1102 assert (numWeights () == weights.size ());; 1103 assert (weights.size () == gradients.size ());; 1104 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (gradients), std::end (gradients), 0, outputContainer, true);; 1105 return error;; 1106 }; 1107 ; 1108 ; 1109 ; 1110 template <typename LayerContainer, typename DropContainer, typename ItWeight, typename ItGradient>; 1111 std::vector<std::vector<LayerData>> Net::prepareLayerData (LayerContainer& _layers,; 1112 Batch& batch,; 1113 const DropContainer& dropContainer,; 1114 ItWeight itWeightBegin,; 1115 ItWeight /*itWeightEnd*/,; 1116 ItGradient itGradientBegin,; 1117 ItGradient itGradientEnd,; 1118 size_t& totalNumWeights) const; 1119 {; 11",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:35483,Availability,error,error,35483,"e () == gradients.size ());; 1094 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (gradients), std::end (gradients), 0, nothing, false);; 1095 return error;; 1096 }; 1097 ; 1098 template <typename Weights, typename Gradients, typename PassThrough, typename OutContainer>; 1099 double Net::operator() (PassThrough& settingsAndBatch, Weights& weights, Gradients& gradients, ModeOutput eFetch, OutContainer& outputContainer) const; 1100 {; 1101 MATH_UNUSED(eFetch);; 1102 assert (numWeights () == weights.size ());; 1103 assert (weights.size () == gradients.size ());; 1104 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (gradients), std::end (gradients), 0, outputContainer, true);; 1105 return error;; 1106 }; 1107 ; 1108 ; 1109 ; 1110 template <typename LayerContainer, typename DropContainer, typename ItWeight, typename ItGradient>; 1111 std::vector<std::vector<LayerData>> Net::prepareLayerData (LayerContainer& _layers,; 1112 Batch& batch,; 1113 const DropContainer& dropContainer,; 1114 ItWeight itWeightBegin,; 1115 ItWeight /*itWeightEnd*/,; 1116 ItGradient itGradientBegin,; 1117 ItGradient itGradientEnd,; 1118 size_t& totalNumWeights) const; 1119 {; 1120 LayerData::const_dropout_iterator itDropOut;; 1121 bool usesDropOut = !dropContainer.empty ();; 1122 if (usesDropOut); 1123 itDropOut = std::begin (dropContainer);; 1124 ; 1125 if (_layers.empty ()); 1126 throw std::string (""no layers in this net"");; 1127 ; 1128 ; 1129 // ----------- create layer data -------------------------------------------------------; 1130 //LM- This assert not needed anymore (outputsize is actually numNodes+1); 1131 //assert (_layers.back ().numNodes () == outputSize ());; 1132 totalNumWeights = 0;; 1133 std::vector<std::vector<LayerData>> layerPatternData;; 1134 layerPatternData.reserve (_layers.size ()+1);; 1135 ItWeight itWeight = itWeightBegin;; 1136 ItGradient itGradi",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:35664,Availability,error,error,35664,"e () == gradients.size ());; 1094 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (gradients), std::end (gradients), 0, nothing, false);; 1095 return error;; 1096 }; 1097 ; 1098 template <typename Weights, typename Gradients, typename PassThrough, typename OutContainer>; 1099 double Net::operator() (PassThrough& settingsAndBatch, Weights& weights, Gradients& gradients, ModeOutput eFetch, OutContainer& outputContainer) const; 1100 {; 1101 MATH_UNUSED(eFetch);; 1102 assert (numWeights () == weights.size ());; 1103 assert (weights.size () == gradients.size ());; 1104 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (gradients), std::end (gradients), 0, outputContainer, true);; 1105 return error;; 1106 }; 1107 ; 1108 ; 1109 ; 1110 template <typename LayerContainer, typename DropContainer, typename ItWeight, typename ItGradient>; 1111 std::vector<std::vector<LayerData>> Net::prepareLayerData (LayerContainer& _layers,; 1112 Batch& batch,; 1113 const DropContainer& dropContainer,; 1114 ItWeight itWeightBegin,; 1115 ItWeight /*itWeightEnd*/,; 1116 ItGradient itGradientBegin,; 1117 ItGradient itGradientEnd,; 1118 size_t& totalNumWeights) const; 1119 {; 1120 LayerData::const_dropout_iterator itDropOut;; 1121 bool usesDropOut = !dropContainer.empty ();; 1122 if (usesDropOut); 1123 itDropOut = std::begin (dropContainer);; 1124 ; 1125 if (_layers.empty ()); 1126 throw std::string (""no layers in this net"");; 1127 ; 1128 ; 1129 // ----------- create layer data -------------------------------------------------------; 1130 //LM- This assert not needed anymore (outputsize is actually numNodes+1); 1131 //assert (_layers.back ().numNodes () == outputSize ());; 1132 totalNumWeights = 0;; 1133 std::vector<std::vector<LayerData>> layerPatternData;; 1134 layerPatternData.reserve (_layers.size ()+1);; 1135 ItWeight itWeight = itWeightBegin;; 1136 ItGradient itGradi",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:44616,Availability,error,error,44616,"yerData& lastLayerData : lastLayerPatternData); 1315 fetchOutput (lastLayerData, outputContainer);; 1316 }; 1317 ; 1318 ; 1319 ; 1320 template <typename ItWeight>; 1321 std::tuple</*sumError*/double,/*sumWeights*/double> Net::computeError (const Settings& settings,; 1322 std::vector<LayerData>& lastLayerData,; 1323 Batch& batch,; 1324 ItWeight itWeightBegin,; 1325 ItWeight itWeightEnd) const; 1326 {; 1327 typename std::vector<LayerData>::iterator itLayerData = lastLayerData.begin ();; 1328// typename std::vector<LayerData>::iterator itLayerDataEnd = lastLayerData.end ();; 1329 ; 1330 typename std::vector<Pattern>::const_iterator itPattern = batch.begin ();; 1331 typename std::vector<Pattern>::const_iterator itPatternEnd = batch.end ();; 1332 ; 1333 double sumWeights (0.0);; 1334 double sumError (0.0);; 1335 ; 1336// FIXME: check that iteration doesn't go beyond itLayerDataEnd!; 1337 for ( ; itPattern != itPatternEnd; ++itPattern, ++itLayerData); 1338 {; 1339 // compute E and the deltas of the computed output and the true output; 1340 LayerData& layerData = (*itLayerData);; 1341 const Pattern& _pattern = (*itPattern);; 1342 double error = errorFunction (layerData, _pattern.output (),; 1343 itWeightBegin, itWeightEnd,; 1344 _pattern.weight (), settings.factorWeightDecay (),; 1345 settings.regularization ());; 1346 sumWeights += fabs (_pattern.weight ());; 1347 sumError += error;; 1348 }; 1349 return std::make_tuple (sumError, sumWeights);; 1350 }; 1351 ; 1352 ; 1353 ; 1354 template <typename Settings>; 1355 void Net::backPropagate (std::vector<std::vector<LayerData>>& layerPatternData,; 1356 const Settings& settings,; 1357 size_t trainFromLayer,; 1358 size_t totalNumWeights) const; 1359 {; 1360 bool doTraining = layerPatternData.size () > trainFromLayer;; 1361 if (doTraining) // training; 1362 {; 1363 // ------------- backpropagation -------------; 1364 size_t idxLayer = layerPatternData.size ();; 1365 for (auto itLayerPatternData = layerPatternData.rbegin (), itLayer",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:44624,Availability,error,errorFunction,44624,"yerData& lastLayerData : lastLayerPatternData); 1315 fetchOutput (lastLayerData, outputContainer);; 1316 }; 1317 ; 1318 ; 1319 ; 1320 template <typename ItWeight>; 1321 std::tuple</*sumError*/double,/*sumWeights*/double> Net::computeError (const Settings& settings,; 1322 std::vector<LayerData>& lastLayerData,; 1323 Batch& batch,; 1324 ItWeight itWeightBegin,; 1325 ItWeight itWeightEnd) const; 1326 {; 1327 typename std::vector<LayerData>::iterator itLayerData = lastLayerData.begin ();; 1328// typename std::vector<LayerData>::iterator itLayerDataEnd = lastLayerData.end ();; 1329 ; 1330 typename std::vector<Pattern>::const_iterator itPattern = batch.begin ();; 1331 typename std::vector<Pattern>::const_iterator itPatternEnd = batch.end ();; 1332 ; 1333 double sumWeights (0.0);; 1334 double sumError (0.0);; 1335 ; 1336// FIXME: check that iteration doesn't go beyond itLayerDataEnd!; 1337 for ( ; itPattern != itPatternEnd; ++itPattern, ++itLayerData); 1338 {; 1339 // compute E and the deltas of the computed output and the true output; 1340 LayerData& layerData = (*itLayerData);; 1341 const Pattern& _pattern = (*itPattern);; 1342 double error = errorFunction (layerData, _pattern.output (),; 1343 itWeightBegin, itWeightEnd,; 1344 _pattern.weight (), settings.factorWeightDecay (),; 1345 settings.regularization ());; 1346 sumWeights += fabs (_pattern.weight ());; 1347 sumError += error;; 1348 }; 1349 return std::make_tuple (sumError, sumWeights);; 1350 }; 1351 ; 1352 ; 1353 ; 1354 template <typename Settings>; 1355 void Net::backPropagate (std::vector<std::vector<LayerData>>& layerPatternData,; 1356 const Settings& settings,; 1357 size_t trainFromLayer,; 1358 size_t totalNumWeights) const; 1359 {; 1360 bool doTraining = layerPatternData.size () > trainFromLayer;; 1361 if (doTraining) // training; 1362 {; 1363 // ------------- backpropagation -------------; 1364 size_t idxLayer = layerPatternData.size ();; 1365 for (auto itLayerPatternData = layerPatternData.rbegin (), itLayer",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:44861,Availability,error,error,44861,"LayerData.end ();; 1329 ; 1330 typename std::vector<Pattern>::const_iterator itPattern = batch.begin ();; 1331 typename std::vector<Pattern>::const_iterator itPatternEnd = batch.end ();; 1332 ; 1333 double sumWeights (0.0);; 1334 double sumError (0.0);; 1335 ; 1336// FIXME: check that iteration doesn't go beyond itLayerDataEnd!; 1337 for ( ; itPattern != itPatternEnd; ++itPattern, ++itLayerData); 1338 {; 1339 // compute E and the deltas of the computed output and the true output; 1340 LayerData& layerData = (*itLayerData);; 1341 const Pattern& _pattern = (*itPattern);; 1342 double error = errorFunction (layerData, _pattern.output (),; 1343 itWeightBegin, itWeightEnd,; 1344 _pattern.weight (), settings.factorWeightDecay (),; 1345 settings.regularization ());; 1346 sumWeights += fabs (_pattern.weight ());; 1347 sumError += error;; 1348 }; 1349 return std::make_tuple (sumError, sumWeights);; 1350 }; 1351 ; 1352 ; 1353 ; 1354 template <typename Settings>; 1355 void Net::backPropagate (std::vector<std::vector<LayerData>>& layerPatternData,; 1356 const Settings& settings,; 1357 size_t trainFromLayer,; 1358 size_t totalNumWeights) const; 1359 {; 1360 bool doTraining = layerPatternData.size () > trainFromLayer;; 1361 if (doTraining) // training; 1362 {; 1363 // ------------- backpropagation -------------; 1364 size_t idxLayer = layerPatternData.size ();; 1365 for (auto itLayerPatternData = layerPatternData.rbegin (), itLayerPatternDataBegin = layerPatternData.rend ();; 1366 itLayerPatternData != itLayerPatternDataBegin; ++itLayerPatternData); 1367 {; 1368 --idxLayer;; 1369 if (idxLayer <= trainFromLayer) // no training; 1370 break;; 1371 ; 1372 std::vector<LayerData>& currLayerDataColl = *(itLayerPatternData);; 1373 std::vector<LayerData>& prevLayerDataColl = *(itLayerPatternData+1);; 1374 ; 1375// FIXME: check that itPrevLayerData doesn't go beyond itPrevLayerDataEnd!; 1376 for (typename std::vector<LayerData>::iterator itCurrLayerData = begin (currLayerDataColl), itCurrLa",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:48625,Availability,error,error,48625,"; 1415 double sumError = 0.0;; 1416 double sumWeights = 0.0; // -------------; 1417 ; 1418 ; 1419 // ----------------------------- prepare layer data -------------------------------------; 1420 size_t totalNumWeights (0);; 1421 std::vector<std::vector<LayerData>> layerPatternData = prepareLayerData (_layers,; 1422 batch,; 1423 dropContainer,; 1424 itWeightBegin,; 1425 itWeightEnd,; 1426 itGradientBegin,; 1427 itGradientEnd,; 1428 totalNumWeights);; 1429 ; 1430 ; 1431 ; 1432 // ---------------------------------- propagate forward ------------------------------------------------------------------; 1433 std::vector<double> valuesMean;; 1434 std::vector<double> valuesStdDev;; 1435 forwardBatch (_layers, layerPatternData, valuesMean, valuesStdDev, trainFromLayer);; 1436 ; 1437 ; 1438 // ------------- fetch output ------------------; 1439 if (doFetchOutput); 1440 {; 1441 fetchOutput (layerPatternData.back (), outputContainer);; 1442 }; 1443 ; 1444 ; 1445 // ------------- error computation -------------; 1446 std::tie (sumError, sumWeights) = computeError (settings, layerPatternData.back (), batch, itWeightBegin, itWeightBegin + totalNumWeights);; 1447 ; 1448 ; 1449 // ------------- backpropagation -------------; 1450 backPropagate (layerPatternData, settings, trainFromLayer, totalNumWeights);; 1451 ; 1452 ; 1453 // --- compile the measures; 1454 double batchSize = std::distance (std::begin (batch), std::end (batch));; 1455 for (auto it = itGradientBegin; it != itGradientEnd; ++it); 1456 (*it) /= batchSize;; 1457 ; 1458 ; 1459 sumError /= sumWeights;; 1460 return sumError;; 1461 }; 1462 ; 1463 ; 1464 ; 1465/*! \brief initialization of the weights; 1466 *; 1467 *; 1468 */; 1469 template <typename OutIterator>; 1470 void Net::initializeWeights (WeightInitializationStrategy eInitStrategy, OutIterator itWeight); 1471 {; 1472 if (eInitStrategy == WeightInitializationStrategy::XAVIER); 1473 {; 1474 // input and output properties; 1475 int numInput = inputSize ();; 1476 ; 1477 // ",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:52177,Availability,error,error,52177," ++itWeight;; 1539 }; 1540 numInput = layer.numNodes ();; 1541 }; 1542 return;; 1543 }; 1544 ; 1545 if (eInitStrategy == WeightInitializationStrategy::LAYERSIZE); 1546 {; 1547 // input and output properties; 1548 int numInput = inputSize ();; 1549 ; 1550 // compute variance and mean of input and output; 1551 //...; 1552 ; 1553 ; 1554 // compute the weights; 1555 for (auto& layer: layers ()); 1556 {; 1557 double nIn = numInput;; 1558 for (size_t iWeight = 0, iWeightEnd = layer.numWeights (numInput); iWeight < iWeightEnd; ++iWeight); 1559 {; 1560 (*itWeight) = DNN::gaussDouble (0.0, sqrt (layer.numWeights (nIn))); // factor 2.0 for ReLU; 1561 ++itWeight;; 1562 }; 1563 numInput = layer.numNodes ();; 1564 }; 1565 return;; 1566 }; 1567 ; 1568 }; 1569 ; 1570 ; 1571 ; 1572 ; 1573 ; 1574/*! \brief compute the error function; 1575 *; 1576 *; 1577 */; 1578 template <typename Container, typename ItWeight>; 1579 double Net::errorFunction (LayerData& layerData,; 1580 Container truth,; 1581 ItWeight itWeight,; 1582 ItWeight itWeightEnd,; 1583 double patternWeight,; 1584 double factorWeightDecay,; 1585 EnumRegularization eRegularization) const; 1586 {; 1587 double error (0);; 1588 switch (m_eErrorFunction); 1589 {; 1590 case ModeErrorFunction::SUMOFSQUARES:; 1591 {; 1592 error = sumOfSquares (layerData.valuesBegin (), layerData.valuesEnd (), begin (truth), end (truth),; 1593 layerData.deltasBegin (), layerData.deltasEnd (),; 1594 layerData.inverseActivationFunction (),; 1595 patternWeight);; 1596 break;; 1597 }; 1598 case ModeErrorFunction::CROSSENTROPY:; 1599 {; 1600 assert (!TMVA::DNN::isFlagSet (ModeOutputValues::DIRECT, layerData.outputMode ()));; 1601 std::vector<double> probabilities = layerData.probabilities ();; 1602 error = crossEntropy (begin (probabilities), end (probabilities),; 1603 begin (truth), end (truth),; 1604 layerData.deltasBegin (), layerData.deltasEnd (),; 1605 layerData.inverseActivationFunction (),; 1606 patternWeight);; 1607 break;; 1608 }; 1609 case ModeE",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:52290,Availability,error,errorFunction,52290," ++itWeight;; 1539 }; 1540 numInput = layer.numNodes ();; 1541 }; 1542 return;; 1543 }; 1544 ; 1545 if (eInitStrategy == WeightInitializationStrategy::LAYERSIZE); 1546 {; 1547 // input and output properties; 1548 int numInput = inputSize ();; 1549 ; 1550 // compute variance and mean of input and output; 1551 //...; 1552 ; 1553 ; 1554 // compute the weights; 1555 for (auto& layer: layers ()); 1556 {; 1557 double nIn = numInput;; 1558 for (size_t iWeight = 0, iWeightEnd = layer.numWeights (numInput); iWeight < iWeightEnd; ++iWeight); 1559 {; 1560 (*itWeight) = DNN::gaussDouble (0.0, sqrt (layer.numWeights (nIn))); // factor 2.0 for ReLU; 1561 ++itWeight;; 1562 }; 1563 numInput = layer.numNodes ();; 1564 }; 1565 return;; 1566 }; 1567 ; 1568 }; 1569 ; 1570 ; 1571 ; 1572 ; 1573 ; 1574/*! \brief compute the error function; 1575 *; 1576 *; 1577 */; 1578 template <typename Container, typename ItWeight>; 1579 double Net::errorFunction (LayerData& layerData,; 1580 Container truth,; 1581 ItWeight itWeight,; 1582 ItWeight itWeightEnd,; 1583 double patternWeight,; 1584 double factorWeightDecay,; 1585 EnumRegularization eRegularization) const; 1586 {; 1587 double error (0);; 1588 switch (m_eErrorFunction); 1589 {; 1590 case ModeErrorFunction::SUMOFSQUARES:; 1591 {; 1592 error = sumOfSquares (layerData.valuesBegin (), layerData.valuesEnd (), begin (truth), end (truth),; 1593 layerData.deltasBegin (), layerData.deltasEnd (),; 1594 layerData.inverseActivationFunction (),; 1595 patternWeight);; 1596 break;; 1597 }; 1598 case ModeErrorFunction::CROSSENTROPY:; 1599 {; 1600 assert (!TMVA::DNN::isFlagSet (ModeOutputValues::DIRECT, layerData.outputMode ()));; 1601 std::vector<double> probabilities = layerData.probabilities ();; 1602 error = crossEntropy (begin (probabilities), end (probabilities),; 1603 begin (truth), end (truth),; 1604 layerData.deltasBegin (), layerData.deltasEnd (),; 1605 layerData.inverseActivationFunction (),; 1606 patternWeight);; 1607 break;; 1608 }; 1609 case ModeE",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:52532,Availability,error,error,52532," ++itWeight;; 1539 }; 1540 numInput = layer.numNodes ();; 1541 }; 1542 return;; 1543 }; 1544 ; 1545 if (eInitStrategy == WeightInitializationStrategy::LAYERSIZE); 1546 {; 1547 // input and output properties; 1548 int numInput = inputSize ();; 1549 ; 1550 // compute variance and mean of input and output; 1551 //...; 1552 ; 1553 ; 1554 // compute the weights; 1555 for (auto& layer: layers ()); 1556 {; 1557 double nIn = numInput;; 1558 for (size_t iWeight = 0, iWeightEnd = layer.numWeights (numInput); iWeight < iWeightEnd; ++iWeight); 1559 {; 1560 (*itWeight) = DNN::gaussDouble (0.0, sqrt (layer.numWeights (nIn))); // factor 2.0 for ReLU; 1561 ++itWeight;; 1562 }; 1563 numInput = layer.numNodes ();; 1564 }; 1565 return;; 1566 }; 1567 ; 1568 }; 1569 ; 1570 ; 1571 ; 1572 ; 1573 ; 1574/*! \brief compute the error function; 1575 *; 1576 *; 1577 */; 1578 template <typename Container, typename ItWeight>; 1579 double Net::errorFunction (LayerData& layerData,; 1580 Container truth,; 1581 ItWeight itWeight,; 1582 ItWeight itWeightEnd,; 1583 double patternWeight,; 1584 double factorWeightDecay,; 1585 EnumRegularization eRegularization) const; 1586 {; 1587 double error (0);; 1588 switch (m_eErrorFunction); 1589 {; 1590 case ModeErrorFunction::SUMOFSQUARES:; 1591 {; 1592 error = sumOfSquares (layerData.valuesBegin (), layerData.valuesEnd (), begin (truth), end (truth),; 1593 layerData.deltasBegin (), layerData.deltasEnd (),; 1594 layerData.inverseActivationFunction (),; 1595 patternWeight);; 1596 break;; 1597 }; 1598 case ModeErrorFunction::CROSSENTROPY:; 1599 {; 1600 assert (!TMVA::DNN::isFlagSet (ModeOutputValues::DIRECT, layerData.outputMode ()));; 1601 std::vector<double> probabilities = layerData.probabilities ();; 1602 error = crossEntropy (begin (probabilities), end (probabilities),; 1603 begin (truth), end (truth),; 1604 layerData.deltasBegin (), layerData.deltasEnd (),; 1605 layerData.inverseActivationFunction (),; 1606 patternWeight);; 1607 break;; 1608 }; 1609 case ModeE",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:52641,Availability,error,error,52641," ++itWeight;; 1539 }; 1540 numInput = layer.numNodes ();; 1541 }; 1542 return;; 1543 }; 1544 ; 1545 if (eInitStrategy == WeightInitializationStrategy::LAYERSIZE); 1546 {; 1547 // input and output properties; 1548 int numInput = inputSize ();; 1549 ; 1550 // compute variance and mean of input and output; 1551 //...; 1552 ; 1553 ; 1554 // compute the weights; 1555 for (auto& layer: layers ()); 1556 {; 1557 double nIn = numInput;; 1558 for (size_t iWeight = 0, iWeightEnd = layer.numWeights (numInput); iWeight < iWeightEnd; ++iWeight); 1559 {; 1560 (*itWeight) = DNN::gaussDouble (0.0, sqrt (layer.numWeights (nIn))); // factor 2.0 for ReLU; 1561 ++itWeight;; 1562 }; 1563 numInput = layer.numNodes ();; 1564 }; 1565 return;; 1566 }; 1567 ; 1568 }; 1569 ; 1570 ; 1571 ; 1572 ; 1573 ; 1574/*! \brief compute the error function; 1575 *; 1576 *; 1577 */; 1578 template <typename Container, typename ItWeight>; 1579 double Net::errorFunction (LayerData& layerData,; 1580 Container truth,; 1581 ItWeight itWeight,; 1582 ItWeight itWeightEnd,; 1583 double patternWeight,; 1584 double factorWeightDecay,; 1585 EnumRegularization eRegularization) const; 1586 {; 1587 double error (0);; 1588 switch (m_eErrorFunction); 1589 {; 1590 case ModeErrorFunction::SUMOFSQUARES:; 1591 {; 1592 error = sumOfSquares (layerData.valuesBegin (), layerData.valuesEnd (), begin (truth), end (truth),; 1593 layerData.deltasBegin (), layerData.deltasEnd (),; 1594 layerData.inverseActivationFunction (),; 1595 patternWeight);; 1596 break;; 1597 }; 1598 case ModeErrorFunction::CROSSENTROPY:; 1599 {; 1600 assert (!TMVA::DNN::isFlagSet (ModeOutputValues::DIRECT, layerData.outputMode ()));; 1601 std::vector<double> probabilities = layerData.probabilities ();; 1602 error = crossEntropy (begin (probabilities), end (probabilities),; 1603 begin (truth), end (truth),; 1604 layerData.deltasBegin (), layerData.deltasEnd (),; 1605 layerData.inverseActivationFunction (),; 1606 patternWeight);; 1607 break;; 1608 }; 1609 case ModeE",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:53104,Availability,error,error,53104,"1574/*! \brief compute the error function; 1575 *; 1576 *; 1577 */; 1578 template <typename Container, typename ItWeight>; 1579 double Net::errorFunction (LayerData& layerData,; 1580 Container truth,; 1581 ItWeight itWeight,; 1582 ItWeight itWeightEnd,; 1583 double patternWeight,; 1584 double factorWeightDecay,; 1585 EnumRegularization eRegularization) const; 1586 {; 1587 double error (0);; 1588 switch (m_eErrorFunction); 1589 {; 1590 case ModeErrorFunction::SUMOFSQUARES:; 1591 {; 1592 error = sumOfSquares (layerData.valuesBegin (), layerData.valuesEnd (), begin (truth), end (truth),; 1593 layerData.deltasBegin (), layerData.deltasEnd (),; 1594 layerData.inverseActivationFunction (),; 1595 patternWeight);; 1596 break;; 1597 }; 1598 case ModeErrorFunction::CROSSENTROPY:; 1599 {; 1600 assert (!TMVA::DNN::isFlagSet (ModeOutputValues::DIRECT, layerData.outputMode ()));; 1601 std::vector<double> probabilities = layerData.probabilities ();; 1602 error = crossEntropy (begin (probabilities), end (probabilities),; 1603 begin (truth), end (truth),; 1604 layerData.deltasBegin (), layerData.deltasEnd (),; 1605 layerData.inverseActivationFunction (),; 1606 patternWeight);; 1607 break;; 1608 }; 1609 case ModeErrorFunction::CROSSENTROPY_MUTUALEXCLUSIVE:; 1610 {; 1611 std::cout << ""softmax."" << std::endl;; 1612 assert (!TMVA::DNN::isFlagSet (ModeOutputValues::DIRECT, layerData.outputMode ()));; 1613 std::vector<double> probabilities = layerData.probabilities ();; 1614 error = softMaxCrossEntropy (begin (probabilities), end (probabilities),; 1615 begin (truth), end (truth),; 1616 layerData.deltasBegin (), layerData.deltasEnd (),; 1617 layerData.inverseActivationFunction (),; 1618 patternWeight);; 1619 break;; 1620 }; 1621 }; 1622 if (factorWeightDecay != 0 && eRegularization != EnumRegularization::NONE); 1623 {; 1624 error = weightDecay (error, itWeight, itWeightEnd, factorWeightDecay, eRegularization);; 1625 }; 1626 return error;; 1627 }; 1628 ; 1629 ; 1630 ; 1631 ; 1632 ; 1633 ; 1",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:53627,Availability,error,error,53627,"uesBegin (), layerData.valuesEnd (), begin (truth), end (truth),; 1593 layerData.deltasBegin (), layerData.deltasEnd (),; 1594 layerData.inverseActivationFunction (),; 1595 patternWeight);; 1596 break;; 1597 }; 1598 case ModeErrorFunction::CROSSENTROPY:; 1599 {; 1600 assert (!TMVA::DNN::isFlagSet (ModeOutputValues::DIRECT, layerData.outputMode ()));; 1601 std::vector<double> probabilities = layerData.probabilities ();; 1602 error = crossEntropy (begin (probabilities), end (probabilities),; 1603 begin (truth), end (truth),; 1604 layerData.deltasBegin (), layerData.deltasEnd (),; 1605 layerData.inverseActivationFunction (),; 1606 patternWeight);; 1607 break;; 1608 }; 1609 case ModeErrorFunction::CROSSENTROPY_MUTUALEXCLUSIVE:; 1610 {; 1611 std::cout << ""softmax."" << std::endl;; 1612 assert (!TMVA::DNN::isFlagSet (ModeOutputValues::DIRECT, layerData.outputMode ()));; 1613 std::vector<double> probabilities = layerData.probabilities ();; 1614 error = softMaxCrossEntropy (begin (probabilities), end (probabilities),; 1615 begin (truth), end (truth),; 1616 layerData.deltasBegin (), layerData.deltasEnd (),; 1617 layerData.inverseActivationFunction (),; 1618 patternWeight);; 1619 break;; 1620 }; 1621 }; 1622 if (factorWeightDecay != 0 && eRegularization != EnumRegularization::NONE); 1623 {; 1624 error = weightDecay (error, itWeight, itWeightEnd, factorWeightDecay, eRegularization);; 1625 }; 1626 return error;; 1627 }; 1628 ; 1629 ; 1630 ; 1631 ; 1632 ; 1633 ; 1634 ; 1635// /*! \brief pre-training; 1636// *; 1637// * in development; 1638// */; 1639// template <typename Minimizer>; 1640// void Net::preTrain (std::vector<double>& weights,; 1641// std::vector<Pattern>& trainPattern,; 1642// const std::vector<Pattern>& testPattern,; 1643// Minimizer& minimizer, Settings& settings); 1644// {; 1645// auto itWeightGeneral = std::begin (weights);; 1646// std::vector<Pattern> prePatternTrain (trainPattern.size ());; 1647// std::vector<Pattern> prePatternTest (testPattern.size ());; 1648 ",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:53982,Availability,error,error,53982,"h),; 1604 layerData.deltasBegin (), layerData.deltasEnd (),; 1605 layerData.inverseActivationFunction (),; 1606 patternWeight);; 1607 break;; 1608 }; 1609 case ModeErrorFunction::CROSSENTROPY_MUTUALEXCLUSIVE:; 1610 {; 1611 std::cout << ""softmax."" << std::endl;; 1612 assert (!TMVA::DNN::isFlagSet (ModeOutputValues::DIRECT, layerData.outputMode ()));; 1613 std::vector<double> probabilities = layerData.probabilities ();; 1614 error = softMaxCrossEntropy (begin (probabilities), end (probabilities),; 1615 begin (truth), end (truth),; 1616 layerData.deltasBegin (), layerData.deltasEnd (),; 1617 layerData.inverseActivationFunction (),; 1618 patternWeight);; 1619 break;; 1620 }; 1621 }; 1622 if (factorWeightDecay != 0 && eRegularization != EnumRegularization::NONE); 1623 {; 1624 error = weightDecay (error, itWeight, itWeightEnd, factorWeightDecay, eRegularization);; 1625 }; 1626 return error;; 1627 }; 1628 ; 1629 ; 1630 ; 1631 ; 1632 ; 1633 ; 1634 ; 1635// /*! \brief pre-training; 1636// *; 1637// * in development; 1638// */; 1639// template <typename Minimizer>; 1640// void Net::preTrain (std::vector<double>& weights,; 1641// std::vector<Pattern>& trainPattern,; 1642// const std::vector<Pattern>& testPattern,; 1643// Minimizer& minimizer, Settings& settings); 1644// {; 1645// auto itWeightGeneral = std::begin (weights);; 1646// std::vector<Pattern> prePatternTrain (trainPattern.size ());; 1647// std::vector<Pattern> prePatternTest (testPattern.size ());; 1648 ; 1649// size_t _inputSize = inputSize ();; 1650 ; 1651// // transform pattern using the created preNet; 1652// auto initializePrePattern = [&](const std::vector<Pattern>& pttrnInput, std::vector<Pattern>& pttrnOutput); 1653// {; 1654// pttrnOutput.clear ();; 1655// std::transform (std::begin (pttrnInput), std::end (pttrnInput),; 1656// std::back_inserter (pttrnOutput),; 1657// [](const Pattern& p); 1658// {; 1659// Pattern pat (p.input (), p.input (), p.weight ());; 1660// return pat;; 1661// });; 1662// };; 1663 ; 1",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:54003,Availability,error,error,54003,"h),; 1604 layerData.deltasBegin (), layerData.deltasEnd (),; 1605 layerData.inverseActivationFunction (),; 1606 patternWeight);; 1607 break;; 1608 }; 1609 case ModeErrorFunction::CROSSENTROPY_MUTUALEXCLUSIVE:; 1610 {; 1611 std::cout << ""softmax."" << std::endl;; 1612 assert (!TMVA::DNN::isFlagSet (ModeOutputValues::DIRECT, layerData.outputMode ()));; 1613 std::vector<double> probabilities = layerData.probabilities ();; 1614 error = softMaxCrossEntropy (begin (probabilities), end (probabilities),; 1615 begin (truth), end (truth),; 1616 layerData.deltasBegin (), layerData.deltasEnd (),; 1617 layerData.inverseActivationFunction (),; 1618 patternWeight);; 1619 break;; 1620 }; 1621 }; 1622 if (factorWeightDecay != 0 && eRegularization != EnumRegularization::NONE); 1623 {; 1624 error = weightDecay (error, itWeight, itWeightEnd, factorWeightDecay, eRegularization);; 1625 }; 1626 return error;; 1627 }; 1628 ; 1629 ; 1630 ; 1631 ; 1632 ; 1633 ; 1634 ; 1635// /*! \brief pre-training; 1636// *; 1637// * in development; 1638// */; 1639// template <typename Minimizer>; 1640// void Net::preTrain (std::vector<double>& weights,; 1641// std::vector<Pattern>& trainPattern,; 1642// const std::vector<Pattern>& testPattern,; 1643// Minimizer& minimizer, Settings& settings); 1644// {; 1645// auto itWeightGeneral = std::begin (weights);; 1646// std::vector<Pattern> prePatternTrain (trainPattern.size ());; 1647// std::vector<Pattern> prePatternTest (testPattern.size ());; 1648 ; 1649// size_t _inputSize = inputSize ();; 1650 ; 1651// // transform pattern using the created preNet; 1652// auto initializePrePattern = [&](const std::vector<Pattern>& pttrnInput, std::vector<Pattern>& pttrnOutput); 1653// {; 1654// pttrnOutput.clear ();; 1655// std::transform (std::begin (pttrnInput), std::end (pttrnInput),; 1656// std::back_inserter (pttrnOutput),; 1657// [](const Pattern& p); 1658// {; 1659// Pattern pat (p.input (), p.input (), p.weight ());; 1660// return pat;; 1661// });; 1662// };; 1663 ; 1",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:54091,Availability,error,error,54091,"h),; 1604 layerData.deltasBegin (), layerData.deltasEnd (),; 1605 layerData.inverseActivationFunction (),; 1606 patternWeight);; 1607 break;; 1608 }; 1609 case ModeErrorFunction::CROSSENTROPY_MUTUALEXCLUSIVE:; 1610 {; 1611 std::cout << ""softmax."" << std::endl;; 1612 assert (!TMVA::DNN::isFlagSet (ModeOutputValues::DIRECT, layerData.outputMode ()));; 1613 std::vector<double> probabilities = layerData.probabilities ();; 1614 error = softMaxCrossEntropy (begin (probabilities), end (probabilities),; 1615 begin (truth), end (truth),; 1616 layerData.deltasBegin (), layerData.deltasEnd (),; 1617 layerData.inverseActivationFunction (),; 1618 patternWeight);; 1619 break;; 1620 }; 1621 }; 1622 if (factorWeightDecay != 0 && eRegularization != EnumRegularization::NONE); 1623 {; 1624 error = weightDecay (error, itWeight, itWeightEnd, factorWeightDecay, eRegularization);; 1625 }; 1626 return error;; 1627 }; 1628 ; 1629 ; 1630 ; 1631 ; 1632 ; 1633 ; 1634 ; 1635// /*! \brief pre-training; 1636// *; 1637// * in development; 1638// */; 1639// template <typename Minimizer>; 1640// void Net::preTrain (std::vector<double>& weights,; 1641// std::vector<Pattern>& trainPattern,; 1642// const std::vector<Pattern>& testPattern,; 1643// Minimizer& minimizer, Settings& settings); 1644// {; 1645// auto itWeightGeneral = std::begin (weights);; 1646// std::vector<Pattern> prePatternTrain (trainPattern.size ());; 1647// std::vector<Pattern> prePatternTest (testPattern.size ());; 1648 ; 1649// size_t _inputSize = inputSize ();; 1650 ; 1651// // transform pattern using the created preNet; 1652// auto initializePrePattern = [&](const std::vector<Pattern>& pttrnInput, std::vector<Pattern>& pttrnOutput); 1653// {; 1654// pttrnOutput.clear ();; 1655// std::transform (std::begin (pttrnInput), std::end (pttrnInput),; 1656// std::back_inserter (pttrnOutput),; 1657// [](const Pattern& p); 1658// {; 1659// Pattern pat (p.input (), p.input (), p.weight ());; 1660// return pat;; 1661// });; 1662// };; 1663 ; 1",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:63252,Availability,error,error,63252,"orwardBatchvoid forwardBatch(const LayerContainer &_layers, LayerPatternContainer &layerPatternData, std::vector< double > &valuesMean, std::vector< double > &valuesStdDev, size_t trainFromLayer) constDefinition NeuralNet.icc:1240; TMVA::DNN::Net::fExitFromTrainingbool * fExitFromTrainingDefinition NeuralNet.h:1277; TMVA::DNN::Net::m_layersstd::vector< Layer > m_layerslayer-structure-dataDefinition NeuralNet.h:1272; TMVA::DNN::Net::fIPyMaxIterUInt_t * fIPyMaxIterDefinition NeuralNet.h:1278; TMVA::DNN::Net::computestd::vector< double > compute(const std::vector< double > &input, const Weights &weights) constcompute the net with the given input and the given weightsDefinition NeuralNet.icc:1037; TMVA::DNN::Net::fetchOutputvoid fetchOutput(const LayerData &lastLayerData, OutputContainer &outputContainer) constDefinition NeuralNet.icc:1291; TMVA::DNN::Net::inputSizesize_t inputSize() constinput size of the DNNDefinition NeuralNet.h:1098; TMVA::DNN::Net::m_eErrorFunctionModeErrorFunction m_eErrorFunctiondenotes the error functionDefinition NeuralNet.h:1269; TMVA::DNN::Net::traindouble train(std::vector< double > &weights, std::vector< Pattern > &trainPattern, const std::vector< Pattern > &testPattern, Minimizer &minimizer, Settings &settings)start the trainingDefinition NeuralNet.icc:712; TMVA::DNN::Net::layersconst std::vector< Layer > & layers() constreturns the layers (structure)Definition NeuralNet.h:1245; TMVA::DNN::Net::prepareLayerDatastd::vector< std::vector< LayerData > > prepareLayerData(LayerContainer &layers, Batch &batch, const DropContainer &dropContainer, ItWeight itWeightBegin, ItWeight itWeightEnd, ItGradient itGradientBegin, ItGradient itGradientEnd, size_t &totalNumWeights) constDefinition NeuralNet.icc:1111; TMVA::DNN::Net::initializeWeightsvoid initializeWeights(WeightInitializationStrategy eInitStrategy, OutIterator itWeight)initialize the weights with the given strategyDefinition NeuralNet.icc:1470; TMVA::DNN::Net::outputSizesize_t outputSize() cons",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:64295,Availability,error,errorFunctiondouble,64295,":vector< Pattern > &testPattern, Minimizer &minimizer, Settings &settings)start the trainingDefinition NeuralNet.icc:712; TMVA::DNN::Net::layersconst std::vector< Layer > & layers() constreturns the layers (structure)Definition NeuralNet.h:1245; TMVA::DNN::Net::prepareLayerDatastd::vector< std::vector< LayerData > > prepareLayerData(LayerContainer &layers, Batch &batch, const DropContainer &dropContainer, ItWeight itWeightBegin, ItWeight itWeightEnd, ItGradient itGradientBegin, ItGradient itGradientEnd, size_t &totalNumWeights) constDefinition NeuralNet.icc:1111; TMVA::DNN::Net::initializeWeightsvoid initializeWeights(WeightInitializationStrategy eInitStrategy, OutIterator itWeight)initialize the weights with the given strategyDefinition NeuralNet.icc:1470; TMVA::DNN::Net::outputSizesize_t outputSize() constoutput size of the DNNDefinition NeuralNet.h:1099; TMVA::DNN::Net::errorFunctiondouble errorFunction(LayerData &layerData, Container truth, ItWeight itWeight, ItWeight itWeightEnd, double patternWeight, double factorWeightDecay, EnumRegularization eRegularization) constcomputes the error of the DNNDefinition NeuralNet.icc:1579; TMVA::DNN::Net::forward_backwarddouble forward_backward(LayerContainer &layers, PassThrough &settingsAndBatch, ItWeight itWeightBegin, ItWeight itWeightEnd, ItGradient itGradientBegin, ItGradient itGradientEnd, size_t trainFromLayer, OutContainer &outputContainer, bool fetchOutput) constmain NN computation functionDefinition NeuralNet.icc:1405; TMVA::DNN::Net::trainCycledouble trainCycle(Minimizer &minimizer, std::vector< double > &weights, Iterator itPatternBegin, Iterator itPatternEnd, Settings &settings, DropContainer &dropContainer)executes one training cycleDefinition NeuralNet.icc:939; TMVA::DNN::Net::fIPyCurrentIterUInt_t * fIPyCurrentIterDefinition NeuralNet.h:1278; TMVA::DNN::Net::operator()double operator()(PassThrough &settingsAndBatch, const Weights &weights) constexecute computation of the DNN for one mini-batch (used by the mi",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:64315,Availability,error,errorFunction,64315,":vector< Pattern > &testPattern, Minimizer &minimizer, Settings &settings)start the trainingDefinition NeuralNet.icc:712; TMVA::DNN::Net::layersconst std::vector< Layer > & layers() constreturns the layers (structure)Definition NeuralNet.h:1245; TMVA::DNN::Net::prepareLayerDatastd::vector< std::vector< LayerData > > prepareLayerData(LayerContainer &layers, Batch &batch, const DropContainer &dropContainer, ItWeight itWeightBegin, ItWeight itWeightEnd, ItGradient itGradientBegin, ItGradient itGradientEnd, size_t &totalNumWeights) constDefinition NeuralNet.icc:1111; TMVA::DNN::Net::initializeWeightsvoid initializeWeights(WeightInitializationStrategy eInitStrategy, OutIterator itWeight)initialize the weights with the given strategyDefinition NeuralNet.icc:1470; TMVA::DNN::Net::outputSizesize_t outputSize() constoutput size of the DNNDefinition NeuralNet.h:1099; TMVA::DNN::Net::errorFunctiondouble errorFunction(LayerData &layerData, Container truth, ItWeight itWeight, ItWeight itWeightEnd, double patternWeight, double factorWeightDecay, EnumRegularization eRegularization) constcomputes the error of the DNNDefinition NeuralNet.icc:1579; TMVA::DNN::Net::forward_backwarddouble forward_backward(LayerContainer &layers, PassThrough &settingsAndBatch, ItWeight itWeightBegin, ItWeight itWeightEnd, ItGradient itGradientBegin, ItGradient itGradientEnd, size_t trainFromLayer, OutContainer &outputContainer, bool fetchOutput) constmain NN computation functionDefinition NeuralNet.icc:1405; TMVA::DNN::Net::trainCycledouble trainCycle(Minimizer &minimizer, std::vector< double > &weights, Iterator itPatternBegin, Iterator itPatternEnd, Settings &settings, DropContainer &dropContainer)executes one training cycleDefinition NeuralNet.icc:939; TMVA::DNN::Net::fIPyCurrentIterUInt_t * fIPyCurrentIterDefinition NeuralNet.h:1278; TMVA::DNN::Net::operator()double operator()(PassThrough &settingsAndBatch, const Weights &weights) constexecute computation of the DNN for one mini-batch (used by the mi",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:64511,Availability,error,error,64511,":vector< Pattern > &testPattern, Minimizer &minimizer, Settings &settings)start the trainingDefinition NeuralNet.icc:712; TMVA::DNN::Net::layersconst std::vector< Layer > & layers() constreturns the layers (structure)Definition NeuralNet.h:1245; TMVA::DNN::Net::prepareLayerDatastd::vector< std::vector< LayerData > > prepareLayerData(LayerContainer &layers, Batch &batch, const DropContainer &dropContainer, ItWeight itWeightBegin, ItWeight itWeightEnd, ItGradient itGradientBegin, ItGradient itGradientEnd, size_t &totalNumWeights) constDefinition NeuralNet.icc:1111; TMVA::DNN::Net::initializeWeightsvoid initializeWeights(WeightInitializationStrategy eInitStrategy, OutIterator itWeight)initialize the weights with the given strategyDefinition NeuralNet.icc:1470; TMVA::DNN::Net::outputSizesize_t outputSize() constoutput size of the DNNDefinition NeuralNet.h:1099; TMVA::DNN::Net::errorFunctiondouble errorFunction(LayerData &layerData, Container truth, ItWeight itWeight, ItWeight itWeightEnd, double patternWeight, double factorWeightDecay, EnumRegularization eRegularization) constcomputes the error of the DNNDefinition NeuralNet.icc:1579; TMVA::DNN::Net::forward_backwarddouble forward_backward(LayerContainer &layers, PassThrough &settingsAndBatch, ItWeight itWeightBegin, ItWeight itWeightEnd, ItGradient itGradientBegin, ItGradient itGradientEnd, size_t trainFromLayer, OutContainer &outputContainer, bool fetchOutput) constmain NN computation functionDefinition NeuralNet.icc:1405; TMVA::DNN::Net::trainCycledouble trainCycle(Minimizer &minimizer, std::vector< double > &weights, Iterator itPatternBegin, Iterator itPatternEnd, Settings &settings, DropContainer &dropContainer)executes one training cycleDefinition NeuralNet.icc:939; TMVA::DNN::Net::fIPyCurrentIterUInt_t * fIPyCurrentIterDefinition NeuralNet.h:1278; TMVA::DNN::Net::operator()double operator()(PassThrough &settingsAndBatch, const Weights &weights) constexecute computation of the DNN for one mini-batch (used by the mi",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:73227,Availability,error,error,73227,"LAYERDATA &prevLayerData, LAYERDATA &currLayerData)apply the weights (and functions) in forward direction of the DNNDefinition NeuralNet.icc:546; TMVA::DNN::applyFunctionsvoid applyFunctions(ItValue itValue, ItValue itValueEnd, ItFunction itFunction); TMVA::DNN::uniformFromToT uniformFromTo(T from, T to)Definition NeuralNet.icc:34; TMVA::DNN::computeRegularization< EnumRegularization::L1 >double computeRegularization< EnumRegularization::L1 >(double weight, const double &factorWeightDecay)Definition NeuralNet.icc:219; TMVA::DNN::ModeOutputModeOutputDefinition NeuralNet.h:1030; TMVA::DNN::ModeOutput::FETCH@ FETCH; TMVA::DNN::SoftPlusstd::shared_ptr< std::function< double(double)> > SoftPlusDefinition NeuralNet.cxx:27; TMVA::DNN::EnumRegularizationEnumRegularizationDefinition NeuralNet.h:173; TMVA::DNN::EnumRegularization::L2@ L2; TMVA::DNN::EnumRegularization::L1@ L1; TMVA::DNN::EnumRegularization::NONE@ NONE; TMVA::DNN::crossEntropydouble crossEntropy(ItProbability itProbabilityBegin, ItProbability itProbabilityEnd, ItTruth itTruthBegin, ItTruth itTruthEnd, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc itInvActFnc, double patternWeight)cross entropy error functionDefinition NeuralNet.icc:412; TMVA::DNN::backwardvoid backward(LAYERDATA &prevLayerData, LAYERDATA &currLayerData)backward application of the weights (back-propagation of the error)Definition NeuralNet.icc:572; TMVA::DNN::ZeroFncstd::shared_ptr< std::function< double(double)> > ZeroFncDefinition NeuralNet.cxx:28; TMVA::DNN::weightDecaydouble weightDecay(double error, ItWeight itWeight, ItWeight itWeightEnd, double factorWeightDecay, EnumRegularization eRegularization)compute the weight decay for regularization (L1 or L2)Definition NeuralNet.icc:498; TMVA::DNN::InvSoftSignstd::shared_ptr< std::function< double(double)> > InvSoftSignDefinition NeuralNet.cxx:20; TMVA::DNN::InvGaussComplementstd::shared_ptr< std::function< double(double)> > InvGaussComplementDefinition NeuralNet.cxx:15; TMVA::DNN::computeRegu",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:73416,Availability,error,error,73416,"om, T to)Definition NeuralNet.icc:34; TMVA::DNN::computeRegularization< EnumRegularization::L1 >double computeRegularization< EnumRegularization::L1 >(double weight, const double &factorWeightDecay)Definition NeuralNet.icc:219; TMVA::DNN::ModeOutputModeOutputDefinition NeuralNet.h:1030; TMVA::DNN::ModeOutput::FETCH@ FETCH; TMVA::DNN::SoftPlusstd::shared_ptr< std::function< double(double)> > SoftPlusDefinition NeuralNet.cxx:27; TMVA::DNN::EnumRegularizationEnumRegularizationDefinition NeuralNet.h:173; TMVA::DNN::EnumRegularization::L2@ L2; TMVA::DNN::EnumRegularization::L1@ L1; TMVA::DNN::EnumRegularization::NONE@ NONE; TMVA::DNN::crossEntropydouble crossEntropy(ItProbability itProbabilityBegin, ItProbability itProbabilityEnd, ItTruth itTruthBegin, ItTruth itTruthEnd, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc itInvActFnc, double patternWeight)cross entropy error functionDefinition NeuralNet.icc:412; TMVA::DNN::backwardvoid backward(LAYERDATA &prevLayerData, LAYERDATA &currLayerData)backward application of the weights (back-propagation of the error)Definition NeuralNet.icc:572; TMVA::DNN::ZeroFncstd::shared_ptr< std::function< double(double)> > ZeroFncDefinition NeuralNet.cxx:28; TMVA::DNN::weightDecaydouble weightDecay(double error, ItWeight itWeight, ItWeight itWeightEnd, double factorWeightDecay, EnumRegularization eRegularization)compute the weight decay for regularization (L1 or L2)Definition NeuralNet.icc:498; TMVA::DNN::InvSoftSignstd::shared_ptr< std::function< double(double)> > InvSoftSignDefinition NeuralNet.cxx:20; TMVA::DNN::InvGaussComplementstd::shared_ptr< std::function< double(double)> > InvGaussComplementDefinition NeuralNet.cxx:15; TMVA::DNN::computeRegularization< EnumRegularization::L2 >double computeRegularization< EnumRegularization::L2 >(double weight, const double &factorWeightDecay)Definition NeuralNet.icc:226; TMVA::DNN::regularizationauto regularization(const typename Architecture_t::Matrix_t &A, ERegularization R) -> decltype(Architec",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:73604,Availability,error,error,73604,"@ FETCH; TMVA::DNN::SoftPlusstd::shared_ptr< std::function< double(double)> > SoftPlusDefinition NeuralNet.cxx:27; TMVA::DNN::EnumRegularizationEnumRegularizationDefinition NeuralNet.h:173; TMVA::DNN::EnumRegularization::L2@ L2; TMVA::DNN::EnumRegularization::L1@ L1; TMVA::DNN::EnumRegularization::NONE@ NONE; TMVA::DNN::crossEntropydouble crossEntropy(ItProbability itProbabilityBegin, ItProbability itProbabilityEnd, ItTruth itTruthBegin, ItTruth itTruthEnd, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc itInvActFnc, double patternWeight)cross entropy error functionDefinition NeuralNet.icc:412; TMVA::DNN::backwardvoid backward(LAYERDATA &prevLayerData, LAYERDATA &currLayerData)backward application of the weights (back-propagation of the error)Definition NeuralNet.icc:572; TMVA::DNN::ZeroFncstd::shared_ptr< std::function< double(double)> > ZeroFncDefinition NeuralNet.cxx:28; TMVA::DNN::weightDecaydouble weightDecay(double error, ItWeight itWeight, ItWeight itWeightEnd, double factorWeightDecay, EnumRegularization eRegularization)compute the weight decay for regularization (L1 or L2)Definition NeuralNet.icc:498; TMVA::DNN::InvSoftSignstd::shared_ptr< std::function< double(double)> > InvSoftSignDefinition NeuralNet.cxx:20; TMVA::DNN::InvGaussComplementstd::shared_ptr< std::function< double(double)> > InvGaussComplementDefinition NeuralNet.cxx:15; TMVA::DNN::computeRegularization< EnumRegularization::L2 >double computeRegularization< EnumRegularization::L2 >(double weight, const double &factorWeightDecay)Definition NeuralNet.icc:226; TMVA::DNN::regularizationauto regularization(const typename Architecture_t::Matrix_t &A, ERegularization R) -> decltype(Architecture_t::L1Regularization(A))Evaluate the regularization functional for a given weight matrix.Definition Functions.h:238; TMVA::DNN::ModeErrorFunction::CROSSENTROPY@ CROSSENTROPY; TMVA::DNN::ModeErrorFunction::SUMOFSQUARES@ SUMOFSQUARES; TMVA::DNN::ModeErrorFunction::CROSSENTROPY_MUTUALEXCLUSIVE@ CROSSENTROPY_MUTUA",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:74941,Availability,error,error,74941,"r regularization (L1 or L2)Definition NeuralNet.icc:498; TMVA::DNN::InvSoftSignstd::shared_ptr< std::function< double(double)> > InvSoftSignDefinition NeuralNet.cxx:20; TMVA::DNN::InvGaussComplementstd::shared_ptr< std::function< double(double)> > InvGaussComplementDefinition NeuralNet.cxx:15; TMVA::DNN::computeRegularization< EnumRegularization::L2 >double computeRegularization< EnumRegularization::L2 >(double weight, const double &factorWeightDecay)Definition NeuralNet.icc:226; TMVA::DNN::regularizationauto regularization(const typename Architecture_t::Matrix_t &A, ERegularization R) -> decltype(Architecture_t::L1Regularization(A))Evaluate the regularization functional for a given weight matrix.Definition Functions.h:238; TMVA::DNN::ModeErrorFunction::CROSSENTROPY@ CROSSENTROPY; TMVA::DNN::ModeErrorFunction::SUMOFSQUARES@ SUMOFSQUARES; TMVA::DNN::ModeErrorFunction::CROSSENTROPY_MUTUALEXCLUSIVE@ CROSSENTROPY_MUTUALEXCLUSIVE; TMVA::DNN::softMaxCrossEntropydouble softMaxCrossEntropy(ItOutput itProbabilityBegin, ItOutput itProbabilityEnd, ItTruth itTruthBegin, ItTruth itTruthEnd, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc itInvActFnc, double patternWeight)soft-max-cross-entropy error function (for mutual exclusive cross-entropy)Definition NeuralNet.icc:458; TMVA::DNN::InvTanhstd::shared_ptr< std::function< double(double)> > InvTanhDefinition NeuralNet.cxx:22; TMVA::DNN::Linearstd::shared_ptr< std::function< double(double)> > LinearDefinition NeuralNet.cxx:24; TMVA::DNN::WeightInitializationStrategyWeightInitializationStrategyweight initialization strategies to be chosen fromDefinition NeuralNet.h:1050; TMVA::DNN::WeightInitializationStrategy::TEST@ TEST; TMVA::DNN::WeightInitializationStrategy::XAVIERUNIFORM@ XAVIERUNIFORM; TMVA::DNN::WeightInitializationStrategy::XAVIER@ XAVIER; TMVA::DNN::WeightInitializationStrategy::LAYERSIZE@ LAYERSIZE; TMVA::DNN::InvReLUstd::shared_ptr< std::function< double(double)> > InvReLUDefinition NeuralNet.cxx:17; TMVA::DNN::GaussCo",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:5347,Deployability,update,update,5347,"plate <typename ItValue, typename Fnc, typename InvFnc, typename ItGradient>; 164 void applyFunctions (ItValue itValue, ItValue itValueEnd, Fnc fnc, InvFnc invFnc, ItGradient itGradient); 165 {; 166 while (itValue != itValueEnd); 167 {; 168 auto& value = (*itValue);; 169 value = (*fnc.get ()) (value);; 170 (*itGradient) = (*invFnc.get ()) (value);; 171 ; 172 ++itValue; ++itGradient;; 173 }; 174 }; 175 ; 176 ; 177 ; 178/*! \brief update the gradients; 179 *; 180 *; 181 */; 182 template <typename ItSource, typename ItDelta, typename ItTargetGradient, typename ItGradient>; 183 void update (ItSource itSource, ItSource itSourceEnd,; 184 ItDelta itTargetDeltaBegin, ItDelta itTargetDeltaEnd,; 185 ItTargetGradient itTargetGradientBegin,; 186 ItGradient itGradient); 187 {; 188 while (itSource != itSourceEnd); 189 {; 190 auto itTargetDelta = itTargetDeltaBegin;; 191 auto itTargetGradient = itTargetGradientBegin;; 192 while (itTargetDelta != itTargetDeltaEnd); 193 {; 194 (*itGradient) -= (*itTargetDelta) * (*itSource) * (*itTargetGradient);; 195 ++itTargetDelta; ++itTargetGradient; ++itGradient;; 196 }; 197 ++itSource;; 198 }; 199 }; 200 ; 201 ; 202 ; 203 ; 204/*! \brief compute the regularization (L1, L2); 205 *; 206 *; 207 */; 208 template <EnumRegularization Regularization>; 209 inline double computeRegularization (double weight, const double& factorWeightDecay); 210 {; 211 MATH_UNUSED(weight);; 212 MATH_UNUSED(factorWeightDecay);; 213 ; 214 return 0;; 215 }; 216 ; 217// L1 regularization; 218 template <>; 219 inline double computeRegularization<EnumRegularization::L1> (double weight, const double& factorWeightDecay); 220 {; 221 return weight == 0.0 ? 0.0 : std::copysign (factorWeightDecay, weight);; 222 }; 223 ; 224// L2 regularization; 225 template <>; 226 inline double computeRegularization<EnumRegularization::L2> (double weight, const double& factorWeightDecay); 227 {; 228 return factorWeightDecay * weight;; 229 }; 230 ; 231 ; 232/*! \brief update the gradients, using re",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:5500,Deployability,update,update,5500,"plate <typename ItValue, typename Fnc, typename InvFnc, typename ItGradient>; 164 void applyFunctions (ItValue itValue, ItValue itValueEnd, Fnc fnc, InvFnc invFnc, ItGradient itGradient); 165 {; 166 while (itValue != itValueEnd); 167 {; 168 auto& value = (*itValue);; 169 value = (*fnc.get ()) (value);; 170 (*itGradient) = (*invFnc.get ()) (value);; 171 ; 172 ++itValue; ++itGradient;; 173 }; 174 }; 175 ; 176 ; 177 ; 178/*! \brief update the gradients; 179 *; 180 *; 181 */; 182 template <typename ItSource, typename ItDelta, typename ItTargetGradient, typename ItGradient>; 183 void update (ItSource itSource, ItSource itSourceEnd,; 184 ItDelta itTargetDeltaBegin, ItDelta itTargetDeltaEnd,; 185 ItTargetGradient itTargetGradientBegin,; 186 ItGradient itGradient); 187 {; 188 while (itSource != itSourceEnd); 189 {; 190 auto itTargetDelta = itTargetDeltaBegin;; 191 auto itTargetGradient = itTargetGradientBegin;; 192 while (itTargetDelta != itTargetDeltaEnd); 193 {; 194 (*itGradient) -= (*itTargetDelta) * (*itSource) * (*itTargetGradient);; 195 ++itTargetDelta; ++itTargetGradient; ++itGradient;; 196 }; 197 ++itSource;; 198 }; 199 }; 200 ; 201 ; 202 ; 203 ; 204/*! \brief compute the regularization (L1, L2); 205 *; 206 *; 207 */; 208 template <EnumRegularization Regularization>; 209 inline double computeRegularization (double weight, const double& factorWeightDecay); 210 {; 211 MATH_UNUSED(weight);; 212 MATH_UNUSED(factorWeightDecay);; 213 ; 214 return 0;; 215 }; 216 ; 217// L1 regularization; 218 template <>; 219 inline double computeRegularization<EnumRegularization::L1> (double weight, const double& factorWeightDecay); 220 {; 221 return weight == 0.0 ? 0.0 : std::copysign (factorWeightDecay, weight);; 222 }; 223 ; 224// L2 regularization; 225 template <>; 226 inline double computeRegularization<EnumRegularization::L2> (double weight, const double& factorWeightDecay); 227 {; 228 return factorWeightDecay * weight;; 229 }; 230 ; 231 ; 232/*! \brief update the gradients, using re",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:6885,Deployability,update,update,6885,"(factorWeightDecay);; 213 ; 214 return 0;; 215 }; 216 ; 217// L1 regularization; 218 template <>; 219 inline double computeRegularization<EnumRegularization::L1> (double weight, const double& factorWeightDecay); 220 {; 221 return weight == 0.0 ? 0.0 : std::copysign (factorWeightDecay, weight);; 222 }; 223 ; 224// L2 regularization; 225 template <>; 226 inline double computeRegularization<EnumRegularization::L2> (double weight, const double& factorWeightDecay); 227 {; 228 return factorWeightDecay * weight;; 229 }; 230 ; 231 ; 232/*! \brief update the gradients, using regularization; 233 *; 234 *; 235 */; 236 template <EnumRegularization Regularization, typename ItSource, typename ItDelta, typename ItTargetGradient, typename ItGradient, typename ItWeight>; 237 void update (ItSource itSource, ItSource itSourceEnd,; 238 ItDelta itTargetDeltaBegin, ItDelta itTargetDeltaEnd,; 239 ItTargetGradient itTargetGradientBegin,; 240 ItGradient itGradient,; 241 ItWeight itWeight, double weightDecay); 242 {; 243 // ! the factor weightDecay has to be already scaled by 1/n where n is the number of weights; 244 while (itSource != itSourceEnd); 245 {; 246 auto itTargetDelta = itTargetDeltaBegin;; 247 auto itTargetGradient = itTargetGradientBegin;; 248 while (itTargetDelta != itTargetDeltaEnd); 249 {; 250 (*itGradient) -= + (*itTargetDelta) * (*itSource) * (*itTargetGradient) + computeRegularization<Regularization>(*itWeight,weightDecay);; 251 ++itTargetDelta; ++itTargetGradient; ++itGradient; ++itWeight;; 252 }; 253 ++itSource;; 254 }; 255 }; 256 ; 257 ; 258 ; 259 ; 260 ; 261 ; 262#define USELOCALWEIGHTS 1; 263 ; 264 ; 265 ; 266/*! \brief implementation of the steepest gradient descent algorithm; 267 *; 268 * Can be used with multithreading (i.e. ""HogWild!"" style); see call in trainCycle; 269 */; 270 template <typename Function, typename Weights, typename PassThrough>; 271 double Steepest::operator() (Function& fitnessFunction, Weights& weights, PassThrough& passThrough); 272 {; 273 size",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:7114,Deployability,update,update,7114,"(factorWeightDecay);; 213 ; 214 return 0;; 215 }; 216 ; 217// L1 regularization; 218 template <>; 219 inline double computeRegularization<EnumRegularization::L1> (double weight, const double& factorWeightDecay); 220 {; 221 return weight == 0.0 ? 0.0 : std::copysign (factorWeightDecay, weight);; 222 }; 223 ; 224// L2 regularization; 225 template <>; 226 inline double computeRegularization<EnumRegularization::L2> (double weight, const double& factorWeightDecay); 227 {; 228 return factorWeightDecay * weight;; 229 }; 230 ; 231 ; 232/*! \brief update the gradients, using regularization; 233 *; 234 *; 235 */; 236 template <EnumRegularization Regularization, typename ItSource, typename ItDelta, typename ItTargetGradient, typename ItGradient, typename ItWeight>; 237 void update (ItSource itSource, ItSource itSourceEnd,; 238 ItDelta itTargetDeltaBegin, ItDelta itTargetDeltaEnd,; 239 ItTargetGradient itTargetGradientBegin,; 240 ItGradient itGradient,; 241 ItWeight itWeight, double weightDecay); 242 {; 243 // ! the factor weightDecay has to be already scaled by 1/n where n is the number of weights; 244 while (itSource != itSourceEnd); 245 {; 246 auto itTargetDelta = itTargetDeltaBegin;; 247 auto itTargetGradient = itTargetGradientBegin;; 248 while (itTargetDelta != itTargetDeltaEnd); 249 {; 250 (*itGradient) -= + (*itTargetDelta) * (*itSource) * (*itTargetGradient) + computeRegularization<Regularization>(*itWeight,weightDecay);; 251 ++itTargetDelta; ++itTargetGradient; ++itGradient; ++itWeight;; 252 }; 253 ++itSource;; 254 }; 255 }; 256 ; 257 ; 258 ; 259 ; 260 ; 261 ; 262#define USELOCALWEIGHTS 1; 263 ; 264 ; 265 ; 266/*! \brief implementation of the steepest gradient descent algorithm; 267 *; 268 * Can be used with multithreading (i.e. ""HogWild!"" style); see call in trainCycle; 269 */; 270 template <typename Function, typename Weights, typename PassThrough>; 271 double Steepest::operator() (Function& fitnessFunction, Weights& weights, PassThrough& passThrough); 272 {; 273 size",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:17095,Deployability,update,update,17095,"es (no drop out); 562 }; 563 }; 564 ; 565 ; 566 ; 567/*! \brief backward application of the weights (back-propagation of the error); 568 *; 569 *; 570 */; 571template <typename LAYERDATA>; 572 void backward (LAYERDATA& prevLayerData, LAYERDATA& currLayerData); 573{; 574 if (prevLayerData.hasDropOut ()); 575 {; 576 applyWeightsBackwards<true> (currLayerData.deltasBegin (), currLayerData.deltasEnd (),; 577 currLayerData.weightsBegin (),; 578 prevLayerData.deltasBegin (), prevLayerData.deltasEnd (),; 579 prevLayerData.dropOut ());; 580 }; 581 else; 582 {; 583 bool dummy = true;; 584 applyWeightsBackwards<false> (currLayerData.deltasBegin (), currLayerData.deltasEnd (),; 585 currLayerData.weightsBegin (),; 586 prevLayerData.deltasBegin (), prevLayerData.deltasEnd (),; 587 &dummy); // dummy to use all nodes (no drop out); 588 }; 589}; 590 ; 591 ; 592 ; 593 ; 594 ; 595/*! \brief update the node values; 596 *; 597 *; 598 */; 599 template <typename LAYERDATA>; 600 void update (const LAYERDATA& prevLayerData, LAYERDATA& currLayerData, double factorWeightDecay, EnumRegularization regularization); 601 {; 602 // ! the ""factorWeightDecay"" has already to be scaled by 1/n where n is the number of weights; 603 if (factorWeightDecay != 0.0) // has weight regularization; 604 if (regularization == EnumRegularization::L1) // L1 regularization ( sum(|w|) ); 605 {; 606 update<EnumRegularization::L1> (prevLayerData.valuesBegin (), prevLayerData.valuesEnd (),; 607 currLayerData.deltasBegin (), currLayerData.deltasEnd (),; 608 currLayerData.valueGradientsBegin (), currLayerData.gradientsBegin (),; 609 currLayerData.weightsBegin (), factorWeightDecay);; 610 }; 611 else if (regularization == EnumRegularization::L2) // L2 regularization ( sum(w^2) ); 612 {; 613 update<EnumRegularization::L2> (prevLayerData.valuesBegin (), prevLayerData.valuesEnd (),; 614 currLayerData.deltasBegin (), currLayerData.deltasEnd (),; 615 currLayerData.valueGradientsBegin (), currLayerData.gradientsBegin (),; 616 cur",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:17185,Deployability,update,update,17185,"es (no drop out); 562 }; 563 }; 564 ; 565 ; 566 ; 567/*! \brief backward application of the weights (back-propagation of the error); 568 *; 569 *; 570 */; 571template <typename LAYERDATA>; 572 void backward (LAYERDATA& prevLayerData, LAYERDATA& currLayerData); 573{; 574 if (prevLayerData.hasDropOut ()); 575 {; 576 applyWeightsBackwards<true> (currLayerData.deltasBegin (), currLayerData.deltasEnd (),; 577 currLayerData.weightsBegin (),; 578 prevLayerData.deltasBegin (), prevLayerData.deltasEnd (),; 579 prevLayerData.dropOut ());; 580 }; 581 else; 582 {; 583 bool dummy = true;; 584 applyWeightsBackwards<false> (currLayerData.deltasBegin (), currLayerData.deltasEnd (),; 585 currLayerData.weightsBegin (),; 586 prevLayerData.deltasBegin (), prevLayerData.deltasEnd (),; 587 &dummy); // dummy to use all nodes (no drop out); 588 }; 589}; 590 ; 591 ; 592 ; 593 ; 594 ; 595/*! \brief update the node values; 596 *; 597 *; 598 */; 599 template <typename LAYERDATA>; 600 void update (const LAYERDATA& prevLayerData, LAYERDATA& currLayerData, double factorWeightDecay, EnumRegularization regularization); 601 {; 602 // ! the ""factorWeightDecay"" has already to be scaled by 1/n where n is the number of weights; 603 if (factorWeightDecay != 0.0) // has weight regularization; 604 if (regularization == EnumRegularization::L1) // L1 regularization ( sum(|w|) ); 605 {; 606 update<EnumRegularization::L1> (prevLayerData.valuesBegin (), prevLayerData.valuesEnd (),; 607 currLayerData.deltasBegin (), currLayerData.deltasEnd (),; 608 currLayerData.valueGradientsBegin (), currLayerData.gradientsBegin (),; 609 currLayerData.weightsBegin (), factorWeightDecay);; 610 }; 611 else if (regularization == EnumRegularization::L2) // L2 regularization ( sum(w^2) ); 612 {; 613 update<EnumRegularization::L2> (prevLayerData.valuesBegin (), prevLayerData.valuesEnd (),; 614 currLayerData.deltasBegin (), currLayerData.deltasEnd (),; 615 currLayerData.valueGradientsBegin (), currLayerData.gradientsBegin (),; 616 cur",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:17579,Deployability,update,update,17579,"Backwards<true> (currLayerData.deltasBegin (), currLayerData.deltasEnd (),; 577 currLayerData.weightsBegin (),; 578 prevLayerData.deltasBegin (), prevLayerData.deltasEnd (),; 579 prevLayerData.dropOut ());; 580 }; 581 else; 582 {; 583 bool dummy = true;; 584 applyWeightsBackwards<false> (currLayerData.deltasBegin (), currLayerData.deltasEnd (),; 585 currLayerData.weightsBegin (),; 586 prevLayerData.deltasBegin (), prevLayerData.deltasEnd (),; 587 &dummy); // dummy to use all nodes (no drop out); 588 }; 589}; 590 ; 591 ; 592 ; 593 ; 594 ; 595/*! \brief update the node values; 596 *; 597 *; 598 */; 599 template <typename LAYERDATA>; 600 void update (const LAYERDATA& prevLayerData, LAYERDATA& currLayerData, double factorWeightDecay, EnumRegularization regularization); 601 {; 602 // ! the ""factorWeightDecay"" has already to be scaled by 1/n where n is the number of weights; 603 if (factorWeightDecay != 0.0) // has weight regularization; 604 if (regularization == EnumRegularization::L1) // L1 regularization ( sum(|w|) ); 605 {; 606 update<EnumRegularization::L1> (prevLayerData.valuesBegin (), prevLayerData.valuesEnd (),; 607 currLayerData.deltasBegin (), currLayerData.deltasEnd (),; 608 currLayerData.valueGradientsBegin (), currLayerData.gradientsBegin (),; 609 currLayerData.weightsBegin (), factorWeightDecay);; 610 }; 611 else if (regularization == EnumRegularization::L2) // L2 regularization ( sum(w^2) ); 612 {; 613 update<EnumRegularization::L2> (prevLayerData.valuesBegin (), prevLayerData.valuesEnd (),; 614 currLayerData.deltasBegin (), currLayerData.deltasEnd (),; 615 currLayerData.valueGradientsBegin (), currLayerData.gradientsBegin (),; 616 currLayerData.weightsBegin (), factorWeightDecay);; 617 }; 618 else; 619 {; 620 update (prevLayerData.valuesBegin (), prevLayerData.valuesEnd (),; 621 currLayerData.deltasBegin (), currLayerData.deltasEnd (),; 622 currLayerData.valueGradientsBegin (), currLayerData.gradientsBegin ());; 623 }; 624 ; 625 else; 626 { // no weight re",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:17973,Deployability,update,update,17973,"6 prevLayerData.deltasBegin (), prevLayerData.deltasEnd (),; 587 &dummy); // dummy to use all nodes (no drop out); 588 }; 589}; 590 ; 591 ; 592 ; 593 ; 594 ; 595/*! \brief update the node values; 596 *; 597 *; 598 */; 599 template <typename LAYERDATA>; 600 void update (const LAYERDATA& prevLayerData, LAYERDATA& currLayerData, double factorWeightDecay, EnumRegularization regularization); 601 {; 602 // ! the ""factorWeightDecay"" has already to be scaled by 1/n where n is the number of weights; 603 if (factorWeightDecay != 0.0) // has weight regularization; 604 if (regularization == EnumRegularization::L1) // L1 regularization ( sum(|w|) ); 605 {; 606 update<EnumRegularization::L1> (prevLayerData.valuesBegin (), prevLayerData.valuesEnd (),; 607 currLayerData.deltasBegin (), currLayerData.deltasEnd (),; 608 currLayerData.valueGradientsBegin (), currLayerData.gradientsBegin (),; 609 currLayerData.weightsBegin (), factorWeightDecay);; 610 }; 611 else if (regularization == EnumRegularization::L2) // L2 regularization ( sum(w^2) ); 612 {; 613 update<EnumRegularization::L2> (prevLayerData.valuesBegin (), prevLayerData.valuesEnd (),; 614 currLayerData.deltasBegin (), currLayerData.deltasEnd (),; 615 currLayerData.valueGradientsBegin (), currLayerData.gradientsBegin (),; 616 currLayerData.weightsBegin (), factorWeightDecay);; 617 }; 618 else; 619 {; 620 update (prevLayerData.valuesBegin (), prevLayerData.valuesEnd (),; 621 currLayerData.deltasBegin (), currLayerData.deltasEnd (),; 622 currLayerData.valueGradientsBegin (), currLayerData.gradientsBegin ());; 623 }; 624 ; 625 else; 626 { // no weight regularization; 627 update (prevLayerData.valuesBegin (), prevLayerData.valuesEnd (),; 628 currLayerData.deltasBegin (), currLayerData.deltasEnd (),; 629 currLayerData.valueGradientsBegin (), currLayerData.gradientsBegin ());; 630 }; 631 }; 632 ; 633 ; 634 ; 635 ; 636 ; 637 ; 638 ; 639 ; 640 ; 641 ; 642 ; 643 ; 644/*! \brief compute the drop-out-weight factor; 645 *; 646 * when using ",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:18287,Deployability,update,update,18287,"eightDecay, EnumRegularization regularization); 601 {; 602 // ! the ""factorWeightDecay"" has already to be scaled by 1/n where n is the number of weights; 603 if (factorWeightDecay != 0.0) // has weight regularization; 604 if (regularization == EnumRegularization::L1) // L1 regularization ( sum(|w|) ); 605 {; 606 update<EnumRegularization::L1> (prevLayerData.valuesBegin (), prevLayerData.valuesEnd (),; 607 currLayerData.deltasBegin (), currLayerData.deltasEnd (),; 608 currLayerData.valueGradientsBegin (), currLayerData.gradientsBegin (),; 609 currLayerData.weightsBegin (), factorWeightDecay);; 610 }; 611 else if (regularization == EnumRegularization::L2) // L2 regularization ( sum(w^2) ); 612 {; 613 update<EnumRegularization::L2> (prevLayerData.valuesBegin (), prevLayerData.valuesEnd (),; 614 currLayerData.deltasBegin (), currLayerData.deltasEnd (),; 615 currLayerData.valueGradientsBegin (), currLayerData.gradientsBegin (),; 616 currLayerData.weightsBegin (), factorWeightDecay);; 617 }; 618 else; 619 {; 620 update (prevLayerData.valuesBegin (), prevLayerData.valuesEnd (),; 621 currLayerData.deltasBegin (), currLayerData.deltasEnd (),; 622 currLayerData.valueGradientsBegin (), currLayerData.gradientsBegin ());; 623 }; 624 ; 625 else; 626 { // no weight regularization; 627 update (prevLayerData.valuesBegin (), prevLayerData.valuesEnd (),; 628 currLayerData.deltasBegin (), currLayerData.deltasEnd (),; 629 currLayerData.valueGradientsBegin (), currLayerData.gradientsBegin ());; 630 }; 631 }; 632 ; 633 ; 634 ; 635 ; 636 ; 637 ; 638 ; 639 ; 640 ; 641 ; 642 ; 643 ; 644/*! \brief compute the drop-out-weight factor; 645 *; 646 * when using drop-out a fraction of the nodes is turned off at each cycle of the computation; 647 * once all nodes are turned on again (for instances when the test samples are evaluated),; 648 * the weights have to be adjusted to account for the different number of active nodes; 649 * this function computes the factor and applies it to the weights; 650 ",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:18556,Deployability,update,update,18556,"on::L1) // L1 regularization ( sum(|w|) ); 605 {; 606 update<EnumRegularization::L1> (prevLayerData.valuesBegin (), prevLayerData.valuesEnd (),; 607 currLayerData.deltasBegin (), currLayerData.deltasEnd (),; 608 currLayerData.valueGradientsBegin (), currLayerData.gradientsBegin (),; 609 currLayerData.weightsBegin (), factorWeightDecay);; 610 }; 611 else if (regularization == EnumRegularization::L2) // L2 regularization ( sum(w^2) ); 612 {; 613 update<EnumRegularization::L2> (prevLayerData.valuesBegin (), prevLayerData.valuesEnd (),; 614 currLayerData.deltasBegin (), currLayerData.deltasEnd (),; 615 currLayerData.valueGradientsBegin (), currLayerData.gradientsBegin (),; 616 currLayerData.weightsBegin (), factorWeightDecay);; 617 }; 618 else; 619 {; 620 update (prevLayerData.valuesBegin (), prevLayerData.valuesEnd (),; 621 currLayerData.deltasBegin (), currLayerData.deltasEnd (),; 622 currLayerData.valueGradientsBegin (), currLayerData.gradientsBegin ());; 623 }; 624 ; 625 else; 626 { // no weight regularization; 627 update (prevLayerData.valuesBegin (), prevLayerData.valuesEnd (),; 628 currLayerData.deltasBegin (), currLayerData.deltasEnd (),; 629 currLayerData.valueGradientsBegin (), currLayerData.gradientsBegin ());; 630 }; 631 }; 632 ; 633 ; 634 ; 635 ; 636 ; 637 ; 638 ; 639 ; 640 ; 641 ; 642 ; 643 ; 644/*! \brief compute the drop-out-weight factor; 645 *; 646 * when using drop-out a fraction of the nodes is turned off at each cycle of the computation; 647 * once all nodes are turned on again (for instances when the test samples are evaluated),; 648 * the weights have to be adjusted to account for the different number of active nodes; 649 * this function computes the factor and applies it to the weights; 650 */; 651 template <typename WeightsType, typename DropProbabilities>; 652 void Net::dropOutWeightFactor (WeightsType& weights,; 653 const DropProbabilities& drops,; 654 bool inverse); 655 {; 656 if (drops.empty () || weights.empty ()); 657 return;; 658 ; 659 aut",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:46778,Deployability,update,update,46778,"taColl = *(itLayerPatternData);; 1373 std::vector<LayerData>& prevLayerDataColl = *(itLayerPatternData+1);; 1374 ; 1375// FIXME: check that itPrevLayerData doesn't go beyond itPrevLayerDataEnd!; 1376 for (typename std::vector<LayerData>::iterator itCurrLayerData = begin (currLayerDataColl), itCurrLayerDataEnd = end (currLayerDataColl),; 1377 itPrevLayerData = begin (prevLayerDataColl) /*, itPrevLayerDataEnd = end (prevLayerDataColl)*/;; 1378 itCurrLayerData != itCurrLayerDataEnd; ++itCurrLayerData, ++itPrevLayerData); 1379 {; 1380 LayerData& currLayerData = (*itCurrLayerData);; 1381 LayerData& prevLayerData = *(itPrevLayerData);; 1382 ; 1383 backward (prevLayerData, currLayerData);; 1384 ; 1385 // the factorWeightDecay has to be scaled by 1/n where n is the number of weights (synapses); 1386 // because L1 and L2 regularization; 1387 //; 1388 // http://neuralnetworksanddeeplearning.com/chap3.html#overfitting_and_regularization; 1389 //; 1390 // L1 : -factorWeightDecay*sgn(w)/numWeights; 1391 // L2 : -factorWeightDecay/numWeights; 1392 update (prevLayerData, currLayerData, settings.factorWeightDecay ()/totalNumWeights, settings.regularization ());; 1393 }; 1394 }; 1395 }; 1396 }; 1397 ; 1398 ; 1399 ; 1400/*! \brief forward propagation and backward propagation; 1401 *; 1402 *; 1403 */; 1404 template <typename LayerContainer, typename PassThrough, typename ItWeight, typename ItGradient, typename OutContainer>; 1405 double Net::forward_backward (LayerContainer& _layers, PassThrough& settingsAndBatch,; 1406 ItWeight itWeightBegin, ItWeight itWeightEnd,; 1407 ItGradient itGradientBegin, ItGradient itGradientEnd,; 1408 size_t trainFromLayer,; 1409 OutContainer& outputContainer, bool doFetchOutput) const; 1410 {; 1411 Settings& settings = std::get<0>(settingsAndBatch);; 1412 Batch& batch = std::get<1>(settingsAndBatch);; 1413 DropContainer& dropContainer = std::get<2>(settingsAndBatch);; 1414 ; 1415 double sumError = 0.0;; 1416 double sumWeights = 0.0; // -------------; 1417 ",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:65630,Deployability,configurat,configurationDefinition,65630,"::Net::forward_backwarddouble forward_backward(LayerContainer &layers, PassThrough &settingsAndBatch, ItWeight itWeightBegin, ItWeight itWeightEnd, ItGradient itGradientBegin, ItGradient itGradientEnd, size_t trainFromLayer, OutContainer &outputContainer, bool fetchOutput) constmain NN computation functionDefinition NeuralNet.icc:1405; TMVA::DNN::Net::trainCycledouble trainCycle(Minimizer &minimizer, std::vector< double > &weights, Iterator itPatternBegin, Iterator itPatternEnd, Settings &settings, DropContainer &dropContainer)executes one training cycleDefinition NeuralNet.icc:939; TMVA::DNN::Net::fIPyCurrentIterUInt_t * fIPyCurrentIterDefinition NeuralNet.h:1278; TMVA::DNN::Net::operator()double operator()(PassThrough &settingsAndBatch, const Weights &weights) constexecute computation of the DNN for one mini-batch (used by the minimizer); no computation of gradient...Definition NeuralNet.icc:1070; TMVA::DNN::Net::dropOutWeightFactorvoid dropOutWeightFactor(WeightsType &weights, const DropProbabilities &drops, bool inverse=false)set the drop out configurationDefinition NeuralNet.icc:652; TMVA::DNN::Net::fillDropContainervoid fillDropContainer(DropContainer &dropContainer, double dropFraction, size_t numNodes) constprepare the drop-out-container (select the nodes which are to be dropped out)Definition NeuralNet.cxx:572; TMVA::DNN::Net::numWeightssize_t numWeights(size_t trainingStartLayer=0) constreturns the number of weights in this netDefinition NeuralNet.cxx:540; TMVA::DNN::Net::fInteractiveIPythonInteractive * fInteractiveDefinition NeuralNet.h:1276; TMVA::DNN::Net::computeErrorstd::tuple< double, double > computeError(const Settings &settings, std::vector< LayerData > &lastLayerData, Batch &batch, ItWeight itWeightBegin, ItWeight itWeightEnd) constDefinition NeuralNet.icc:1321; TMVA::DNN::Net::forwardPatternvoid forwardPattern(const LayerContainer &_layers, std::vector< LayerData > &layerData) constDefinition NeuralNet.icc:1221; TMVA::DNN::Net::backPropagatevoi",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:77323,Deployability,update,updatevoid,77323,"OFTMAX@ SOFTMAX; TMVA::DNN::ModeOutputValues::DIRECT@ DIRECT; TMVA::DNN::ModeOutputValues::SIGMOID@ SIGMOID; TMVA::DNN::SoftSignstd::shared_ptr< std::function< double(double)> > SoftSignDefinition NeuralNet.cxx:32; TMVA::DNN::InvSoftPlusstd::shared_ptr< std::function< double(double)> > InvSoftPlusDefinition NeuralNet.cxx:19; TMVA::DNN::ReLUstd::shared_ptr< std::function< double(double)> > ReLUDefinition NeuralNet.cxx:25; TMVA::DNN::computeRegularizationdouble computeRegularization(double weight, const double &factorWeightDecay)compute the regularization (L1, L2)Definition NeuralNet.icc:209; TMVA::DNN::applyWeightsvoid applyWeights(ItSource itSourceBegin, ItSource itSourceEnd, ItWeight itWeight, ItTarget itTargetBegin, ItTarget itTargetEnd); TMVA::DNN::pass_through_typestd::tuple< Settings &, Batch &, DropContainer & > pass_through_typeDefinition NeuralNet.h:1294; TMVA::DNN::isFlagSetbool isFlagSet(T flag, T value)Definition NeuralNet.h:212; TMVA::DNN::InvTanhShiftstd::shared_ptr< std::function< double(double)> > InvTanhShiftDefinition NeuralNet.cxx:23; TMVA::DNN::updatevoid update(ItSource itSource, ItSource itSourceEnd, ItDelta itTargetDeltaBegin, ItDelta itTargetDeltaEnd, ItTargetGradient itTargetGradientBegin, ItGradient itGradient)update the gradientsDefinition NeuralNet.icc:183; TMVA::DNN::DropContainerstd::vector< char > DropContainerDefinition NeuralNet.h:227; TMVA::DNN::applyWeightsBackwardsvoid applyWeightsBackwards(ItSource itCurrBegin, ItSource itCurrEnd, ItWeight itWeight, ItPrev itPrevBegin, ItPrev itPrevEnd); TMVA::DNN::InvSymmReLUstd::shared_ptr< std::function< double(double)> > InvSymmReLUDefinition NeuralNet.cxx:21; TMVA::DNN::InvLinearstd::shared_ptr< std::function< double(double)> > InvLinearDefinition NeuralNet.cxx:16; TMVAcreate variable transformationsDefinition GeneticMinimizer.h:22; outputstatic void output(). tmvatmvaincTMVANeuralNet.icc. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:40:58 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:77334,Deployability,update,update,77334,"OFTMAX@ SOFTMAX; TMVA::DNN::ModeOutputValues::DIRECT@ DIRECT; TMVA::DNN::ModeOutputValues::SIGMOID@ SIGMOID; TMVA::DNN::SoftSignstd::shared_ptr< std::function< double(double)> > SoftSignDefinition NeuralNet.cxx:32; TMVA::DNN::InvSoftPlusstd::shared_ptr< std::function< double(double)> > InvSoftPlusDefinition NeuralNet.cxx:19; TMVA::DNN::ReLUstd::shared_ptr< std::function< double(double)> > ReLUDefinition NeuralNet.cxx:25; TMVA::DNN::computeRegularizationdouble computeRegularization(double weight, const double &factorWeightDecay)compute the regularization (L1, L2)Definition NeuralNet.icc:209; TMVA::DNN::applyWeightsvoid applyWeights(ItSource itSourceBegin, ItSource itSourceEnd, ItWeight itWeight, ItTarget itTargetBegin, ItTarget itTargetEnd); TMVA::DNN::pass_through_typestd::tuple< Settings &, Batch &, DropContainer & > pass_through_typeDefinition NeuralNet.h:1294; TMVA::DNN::isFlagSetbool isFlagSet(T flag, T value)Definition NeuralNet.h:212; TMVA::DNN::InvTanhShiftstd::shared_ptr< std::function< double(double)> > InvTanhShiftDefinition NeuralNet.cxx:23; TMVA::DNN::updatevoid update(ItSource itSource, ItSource itSourceEnd, ItDelta itTargetDeltaBegin, ItDelta itTargetDeltaEnd, ItTargetGradient itTargetGradientBegin, ItGradient itGradient)update the gradientsDefinition NeuralNet.icc:183; TMVA::DNN::DropContainerstd::vector< char > DropContainerDefinition NeuralNet.h:227; TMVA::DNN::applyWeightsBackwardsvoid applyWeightsBackwards(ItSource itCurrBegin, ItSource itCurrEnd, ItWeight itWeight, ItPrev itPrevBegin, ItPrev itPrevEnd); TMVA::DNN::InvSymmReLUstd::shared_ptr< std::function< double(double)> > InvSymmReLUDefinition NeuralNet.cxx:21; TMVA::DNN::InvLinearstd::shared_ptr< std::function< double(double)> > InvLinearDefinition NeuralNet.cxx:16; TMVAcreate variable transformationsDefinition GeneticMinimizer.h:22; outputstatic void output(). tmvatmvaincTMVANeuralNet.icc. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:40:58 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:77498,Deployability,update,update,77498,"OFTMAX@ SOFTMAX; TMVA::DNN::ModeOutputValues::DIRECT@ DIRECT; TMVA::DNN::ModeOutputValues::SIGMOID@ SIGMOID; TMVA::DNN::SoftSignstd::shared_ptr< std::function< double(double)> > SoftSignDefinition NeuralNet.cxx:32; TMVA::DNN::InvSoftPlusstd::shared_ptr< std::function< double(double)> > InvSoftPlusDefinition NeuralNet.cxx:19; TMVA::DNN::ReLUstd::shared_ptr< std::function< double(double)> > ReLUDefinition NeuralNet.cxx:25; TMVA::DNN::computeRegularizationdouble computeRegularization(double weight, const double &factorWeightDecay)compute the regularization (L1, L2)Definition NeuralNet.icc:209; TMVA::DNN::applyWeightsvoid applyWeights(ItSource itSourceBegin, ItSource itSourceEnd, ItWeight itWeight, ItTarget itTargetBegin, ItTarget itTargetEnd); TMVA::DNN::pass_through_typestd::tuple< Settings &, Batch &, DropContainer & > pass_through_typeDefinition NeuralNet.h:1294; TMVA::DNN::isFlagSetbool isFlagSet(T flag, T value)Definition NeuralNet.h:212; TMVA::DNN::InvTanhShiftstd::shared_ptr< std::function< double(double)> > InvTanhShiftDefinition NeuralNet.cxx:23; TMVA::DNN::updatevoid update(ItSource itSource, ItSource itSourceEnd, ItDelta itTargetDeltaBegin, ItDelta itTargetDeltaEnd, ItTargetGradient itTargetGradientBegin, ItGradient itGradient)update the gradientsDefinition NeuralNet.icc:183; TMVA::DNN::DropContainerstd::vector< char > DropContainerDefinition NeuralNet.h:227; TMVA::DNN::applyWeightsBackwardsvoid applyWeightsBackwards(ItSource itCurrBegin, ItSource itCurrEnd, ItWeight itWeight, ItPrev itPrevBegin, ItPrev itPrevEnd); TMVA::DNN::InvSymmReLUstd::shared_ptr< std::function< double(double)> > InvSymmReLUDefinition NeuralNet.cxx:21; TMVA::DNN::InvLinearstd::shared_ptr< std::function< double(double)> > InvLinearDefinition NeuralNet.cxx:16; TMVAcreate variable transformationsDefinition GeneticMinimizer.h:22; outputstatic void output(). tmvatmvaincTMVANeuralNet.icc. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:40:58 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:10257,Energy Efficiency,reduce,reduced,10257,"omentum ---; 297 // apply momentum before computing the new gradient; 298 auto itPrevG = begin (m_prevGradients);; 299 auto itPrevGEnd = end (m_prevGradients);; 300 auto itLocWeight = begin (m_localWeights);; 301 for (; itPrevG != itPrevGEnd; ++itPrevG, ++itLocWeight); 302 {; 303 (*itPrevG) *= m_beta;; 304 (*itLocWeight) += (*itPrevG);; 305 }; 306 ; 307 E = fitnessFunction (passThrough, m_localWeights, m_localGradients);; 308// plotGradients (gradients);; 309// plotWeights (localWeights);; 310 ; 311 double alpha = gaussDouble (m_alpha, m_alpha/2.0);; 312// double alpha = m_alpha;; 313 ; 314 auto itG = begin (m_localGradients);; 315 auto itGEnd = end (m_localGradients);; 316 itPrevG = begin (m_prevGradients);; 317 double maxGrad = 0.0;; 318 for (; itG != itGEnd; ++itG, ++itPrevG); 319 {; 320 double currGrad = (*itG);; 321 double prevGrad = (*itPrevG);; 322 currGrad *= alpha;; 323 ; 324 //(*itPrevG) = m_beta * (prevGrad + currGrad);; 325 currGrad += prevGrad;; 326 (*itG) = currGrad;; 327 (*itPrevG) = currGrad;; 328 ; 329 if (std::fabs (currGrad) > maxGrad); 330 maxGrad = currGrad;; 331 }; 332 ; 333 if (maxGrad > 1); 334 {; 335 m_alpha /= 2;; 336 std::cout << ""\nlearning rate reduced to "" << m_alpha << std::endl;; 337 std::for_each (weights.begin (), weights.end (), [maxGrad](double& w); 338 {; 339 w /= maxGrad;; 340 });; 341 m_prevGradients.clear ();; 342 }; 343 else; 344 {; 345 auto itW = std::begin (weights);; 346 std::for_each (std::begin (m_localGradients), std::end (m_localGradients), [&itW](double& g); 347 {; 348 *itW += g;; 349 ++itW;; 350 });; 351 }; 352 ; 353 ++currentRepetition;; 354 }; 355 return E;; 356 }; 357 ; 358 ; 359 ; 360 ; 361 ; 362 ; 363 ; 364 ; 365 ; 366 ; 367 ; 368 ; 369 ; 370 ; 371 ; 372 ; 373 ; 374 ; 375 ; 376 ; 377/*! \brief sum of squares error function; 378 *; 379 *; 380 */; 381 template <typename ItOutput, typename ItTruth, typename ItDelta, typename InvFnc>; 382 double sumOfSquares (ItOutput itOutputBegin, ItOutput itOutputEnd, ItTruth itT",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:58615,Energy Efficiency,reduce,reduced,58615,";; 1710 ; 1711// // remove the weights of the output layer of the preNet; 1712// preWeights.erase (preWeights.begin () + _numWeights, preWeights.end ());; 1713 ; 1714// // remove the outputLayer of the preNet; 1715// preNet.removeLayer ();; 1716 ; 1717// // set the output size to the number of nodes in the new output layer (== last hidden layer); 1718// preNet.setOutputSize (numNodes);; 1719 ; 1720// // transform pattern using the created preNet; 1721// auto proceedPattern = [&](std::vector<Pattern>& pttrn); 1722// {; 1723// std::vector<Pattern> newPttrn;; 1724// std::for_each (std::begin (pttrn), std::end (pttrn),; 1725// [&preNet,&preWeights,&newPttrn](Pattern& p); 1726// {; 1727// std::vector<double> output = preNet.compute (p.input (), preWeights);; 1728// Pattern pat (output, output, p.weight ());; 1729// newPttrn.push_back (pat);; 1730// // p = pat;; 1731// });; 1732// return newPttrn;; 1733// };; 1734 ; 1735 ; 1736// prePatternTrain = proceedPattern (prePatternTrain);; 1737// prePatternTest = proceedPattern (prePatternTest);; 1738 ; 1739 ; 1740// // the new input size is the output size of the already reduced preNet; 1741// _inputSize = preNet.layers ().back ().numNodes ();; 1742// }; 1743// }; 1744 ; 1745 ; 1746 ; 1747 ; 1748 ; 1749 ; 1750 ; 1751 ; 1752 ; 1753 ; 1754 ; 1755 ; 1756 ; 1757 ; 1758 ; 1759 ; 1760 } // namespace DNN; 1761} // namespace TMVA; 1762 ; 1763#endif; MethodBase.h; Pattern.h; f#define f(i)Definition RSha256.hxx:104; g#define g(i)Definition RSha256.hxx:105; kMagenta@ kMagentaDefinition Rtypes.h:66; kBlue@ kBlueDefinition Rtypes.h:66; wwinID wDefinition TGWin32VirtualGLProxy.cxx:39; pwinID h TVirtualViewer3D TVirtualGLPainter pDefinition TGWin32VirtualGLProxy.cxx:51; inputOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void inputDefinition TGWin32VirtualXProxy.cxx:142; resultOption_t Option_t TPoint TPoint const char GetTextMagnitude GetF",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:67447,Energy Efficiency,monitor,monitoring,67447,"n(const LayerContainer &_layers, std::vector< LayerData > &layerData) constDefinition NeuralNet.icc:1221; TMVA::DNN::Net::backPropagatevoid backPropagate(std::vector< std::vector< LayerData > > &layerPatternData, const Settings &settings, size_t trainFromLayer, size_t totalNumWeights) constDefinition NeuralNet.icc:1355; TMVA::DNN::SettingsSettings for the training of the neural net.Definition NeuralNet.h:730; TMVA::DNN::Settings::useMultithreadingbool useMultithreading() constis multithreading turned on?Definition NeuralNet.h:815; TMVA::DNN::Settings::regularizationEnumRegularization regularization() constsome regularization of the DNN is turned on?Definition NeuralNet.h:813; TMVA::DNN::Settings::convergenceCountsize_t convergenceCount() constreturns the current convergence countDefinition NeuralNet.h:827; TMVA::DNN::Settings::testRepetitionssize_t testRepetitions() consthow often is the test data testedDefinition NeuralNet.h:768; TMVA::DNN::Settings::endTestCyclevirtual void endTestCycle()callback for monitoring and logggingDefinition NeuralNet.h:805; TMVA::DNN::Settings::testIterationvirtual void testIteration()callback for monitoring and logggingDefinition NeuralNet.h:806; TMVA::DNN::Settings::hasConvergedvirtual bool hasConverged(double testError)has this training converged already?Definition NeuralNet.cxx:485; TMVA::DNN::Settings::cyclevirtual void cycle(double progress, TString text)Definition NeuralNet.h:799; TMVA::DNN::Settings::endTrainCyclevirtual void endTrainCycle(double)callback for monitoring and loggingDefinition NeuralNet.h:788; TMVA::DNN::Settings::dropFractionsconst std::vector< double > & dropFractions() constDefinition NeuralNet.h:762; TMVA::DNN::Settings::addPointvoid addPoint(std::string histoName, double x)for monitoringDefinition NeuralNet.h:821; TMVA::DNN::Settings::testSamplevirtual void testSample(double, double, double, double)virtual function to be used for monitoring (callback)Definition NeuralNet.h:781; TMVA::DNN::Settings::plotvoid pl",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:67573,Energy Efficiency,monitor,monitoring,67573,"kPropagatevoid backPropagate(std::vector< std::vector< LayerData > > &layerPatternData, const Settings &settings, size_t trainFromLayer, size_t totalNumWeights) constDefinition NeuralNet.icc:1355; TMVA::DNN::SettingsSettings for the training of the neural net.Definition NeuralNet.h:730; TMVA::DNN::Settings::useMultithreadingbool useMultithreading() constis multithreading turned on?Definition NeuralNet.h:815; TMVA::DNN::Settings::regularizationEnumRegularization regularization() constsome regularization of the DNN is turned on?Definition NeuralNet.h:813; TMVA::DNN::Settings::convergenceCountsize_t convergenceCount() constreturns the current convergence countDefinition NeuralNet.h:827; TMVA::DNN::Settings::testRepetitionssize_t testRepetitions() consthow often is the test data testedDefinition NeuralNet.h:768; TMVA::DNN::Settings::endTestCyclevirtual void endTestCycle()callback for monitoring and logggingDefinition NeuralNet.h:805; TMVA::DNN::Settings::testIterationvirtual void testIteration()callback for monitoring and logggingDefinition NeuralNet.h:806; TMVA::DNN::Settings::hasConvergedvirtual bool hasConverged(double testError)has this training converged already?Definition NeuralNet.cxx:485; TMVA::DNN::Settings::cyclevirtual void cycle(double progress, TString text)Definition NeuralNet.h:799; TMVA::DNN::Settings::endTrainCyclevirtual void endTrainCycle(double)callback for monitoring and loggingDefinition NeuralNet.h:788; TMVA::DNN::Settings::dropFractionsconst std::vector< double > & dropFractions() constDefinition NeuralNet.h:762; TMVA::DNN::Settings::addPointvoid addPoint(std::string histoName, double x)for monitoringDefinition NeuralNet.h:821; TMVA::DNN::Settings::testSamplevirtual void testSample(double, double, double, double)virtual function to be used for monitoring (callback)Definition NeuralNet.h:781; TMVA::DNN::Settings::plotvoid plot(std::string histoName, std::string options, int pad, EColor color)for monitoringDefinition NeuralNet.h:823; TMVA::DNN::Set",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:67950,Energy Efficiency,monitor,monitoring,67950," turned on?Definition NeuralNet.h:815; TMVA::DNN::Settings::regularizationEnumRegularization regularization() constsome regularization of the DNN is turned on?Definition NeuralNet.h:813; TMVA::DNN::Settings::convergenceCountsize_t convergenceCount() constreturns the current convergence countDefinition NeuralNet.h:827; TMVA::DNN::Settings::testRepetitionssize_t testRepetitions() consthow often is the test data testedDefinition NeuralNet.h:768; TMVA::DNN::Settings::endTestCyclevirtual void endTestCycle()callback for monitoring and logggingDefinition NeuralNet.h:805; TMVA::DNN::Settings::testIterationvirtual void testIteration()callback for monitoring and logggingDefinition NeuralNet.h:806; TMVA::DNN::Settings::hasConvergedvirtual bool hasConverged(double testError)has this training converged already?Definition NeuralNet.cxx:485; TMVA::DNN::Settings::cyclevirtual void cycle(double progress, TString text)Definition NeuralNet.h:799; TMVA::DNN::Settings::endTrainCyclevirtual void endTrainCycle(double)callback for monitoring and loggingDefinition NeuralNet.h:788; TMVA::DNN::Settings::dropFractionsconst std::vector< double > & dropFractions() constDefinition NeuralNet.h:762; TMVA::DNN::Settings::addPointvoid addPoint(std::string histoName, double x)for monitoringDefinition NeuralNet.h:821; TMVA::DNN::Settings::testSamplevirtual void testSample(double, double, double, double)virtual function to be used for monitoring (callback)Definition NeuralNet.h:781; TMVA::DNN::Settings::plotvoid plot(std::string histoName, std::string options, int pad, EColor color)for monitoringDefinition NeuralNet.h:823; TMVA::DNN::Settings::startTrainCyclevirtual void startTrainCycle()Definition NeuralNet.h:782; TMVA::DNN::Settings::convergenceStepssize_t convergenceSteps() consthow many steps until training is deemed to have convergedDefinition NeuralNet.h:766; TMVA::DNN::Settings::factorWeightDecaydouble factorWeightDecay() constget the weight-decay factorDefinition NeuralNet.h:769; TMVA::DNN::Setti",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:68192,Energy Efficiency,monitor,monitoringDefinition,68192,"genceCount() constreturns the current convergence countDefinition NeuralNet.h:827; TMVA::DNN::Settings::testRepetitionssize_t testRepetitions() consthow often is the test data testedDefinition NeuralNet.h:768; TMVA::DNN::Settings::endTestCyclevirtual void endTestCycle()callback for monitoring and logggingDefinition NeuralNet.h:805; TMVA::DNN::Settings::testIterationvirtual void testIteration()callback for monitoring and logggingDefinition NeuralNet.h:806; TMVA::DNN::Settings::hasConvergedvirtual bool hasConverged(double testError)has this training converged already?Definition NeuralNet.cxx:485; TMVA::DNN::Settings::cyclevirtual void cycle(double progress, TString text)Definition NeuralNet.h:799; TMVA::DNN::Settings::endTrainCyclevirtual void endTrainCycle(double)callback for monitoring and loggingDefinition NeuralNet.h:788; TMVA::DNN::Settings::dropFractionsconst std::vector< double > & dropFractions() constDefinition NeuralNet.h:762; TMVA::DNN::Settings::addPointvoid addPoint(std::string histoName, double x)for monitoringDefinition NeuralNet.h:821; TMVA::DNN::Settings::testSamplevirtual void testSample(double, double, double, double)virtual function to be used for monitoring (callback)Definition NeuralNet.h:781; TMVA::DNN::Settings::plotvoid plot(std::string histoName, std::string options, int pad, EColor color)for monitoringDefinition NeuralNet.h:823; TMVA::DNN::Settings::startTrainCyclevirtual void startTrainCycle()Definition NeuralNet.h:782; TMVA::DNN::Settings::convergenceStepssize_t convergenceSteps() consthow many steps until training is deemed to have convergedDefinition NeuralNet.h:766; TMVA::DNN::Settings::factorWeightDecaydouble factorWeightDecay() constget the weight-decay factorDefinition NeuralNet.h:769; TMVA::DNN::Settings::maxConvergenceCountsize_t maxConvergenceCount() constreturns the max convergence count so farDefinition NeuralNet.h:828; TMVA::DNN::Settings::padsvoid pads(int numPads)preparation for monitoringDefinition NeuralNet.h:818; TMVA::DNN:",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:68348,Energy Efficiency,monitor,monitoring,68348,") consthow often is the test data testedDefinition NeuralNet.h:768; TMVA::DNN::Settings::endTestCyclevirtual void endTestCycle()callback for monitoring and logggingDefinition NeuralNet.h:805; TMVA::DNN::Settings::testIterationvirtual void testIteration()callback for monitoring and logggingDefinition NeuralNet.h:806; TMVA::DNN::Settings::hasConvergedvirtual bool hasConverged(double testError)has this training converged already?Definition NeuralNet.cxx:485; TMVA::DNN::Settings::cyclevirtual void cycle(double progress, TString text)Definition NeuralNet.h:799; TMVA::DNN::Settings::endTrainCyclevirtual void endTrainCycle(double)callback for monitoring and loggingDefinition NeuralNet.h:788; TMVA::DNN::Settings::dropFractionsconst std::vector< double > & dropFractions() constDefinition NeuralNet.h:762; TMVA::DNN::Settings::addPointvoid addPoint(std::string histoName, double x)for monitoringDefinition NeuralNet.h:821; TMVA::DNN::Settings::testSamplevirtual void testSample(double, double, double, double)virtual function to be used for monitoring (callback)Definition NeuralNet.h:781; TMVA::DNN::Settings::plotvoid plot(std::string histoName, std::string options, int pad, EColor color)for monitoringDefinition NeuralNet.h:823; TMVA::DNN::Settings::startTrainCyclevirtual void startTrainCycle()Definition NeuralNet.h:782; TMVA::DNN::Settings::convergenceStepssize_t convergenceSteps() consthow many steps until training is deemed to have convergedDefinition NeuralNet.h:766; TMVA::DNN::Settings::factorWeightDecaydouble factorWeightDecay() constget the weight-decay factorDefinition NeuralNet.h:769; TMVA::DNN::Settings::maxConvergenceCountsize_t maxConvergenceCount() constreturns the max convergence count so farDefinition NeuralNet.h:828; TMVA::DNN::Settings::padsvoid pads(int numPads)preparation for monitoringDefinition NeuralNet.h:818; TMVA::DNN::Settings::batchSizesize_t batchSize() constmini-batch sizeDefinition NeuralNet.h:767; TMVA::DNN::Settings::computeResultvirtual void computeR",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:68502,Energy Efficiency,monitor,monitoringDefinition,68502," logggingDefinition NeuralNet.h:805; TMVA::DNN::Settings::testIterationvirtual void testIteration()callback for monitoring and logggingDefinition NeuralNet.h:806; TMVA::DNN::Settings::hasConvergedvirtual bool hasConverged(double testError)has this training converged already?Definition NeuralNet.cxx:485; TMVA::DNN::Settings::cyclevirtual void cycle(double progress, TString text)Definition NeuralNet.h:799; TMVA::DNN::Settings::endTrainCyclevirtual void endTrainCycle(double)callback for monitoring and loggingDefinition NeuralNet.h:788; TMVA::DNN::Settings::dropFractionsconst std::vector< double > & dropFractions() constDefinition NeuralNet.h:762; TMVA::DNN::Settings::addPointvoid addPoint(std::string histoName, double x)for monitoringDefinition NeuralNet.h:821; TMVA::DNN::Settings::testSamplevirtual void testSample(double, double, double, double)virtual function to be used for monitoring (callback)Definition NeuralNet.h:781; TMVA::DNN::Settings::plotvoid plot(std::string histoName, std::string options, int pad, EColor color)for monitoringDefinition NeuralNet.h:823; TMVA::DNN::Settings::startTrainCyclevirtual void startTrainCycle()Definition NeuralNet.h:782; TMVA::DNN::Settings::convergenceStepssize_t convergenceSteps() consthow many steps until training is deemed to have convergedDefinition NeuralNet.h:766; TMVA::DNN::Settings::factorWeightDecaydouble factorWeightDecay() constget the weight-decay factorDefinition NeuralNet.h:769; TMVA::DNN::Settings::maxConvergenceCountsize_t maxConvergenceCount() constreturns the max convergence count so farDefinition NeuralNet.h:828; TMVA::DNN::Settings::padsvoid pads(int numPads)preparation for monitoringDefinition NeuralNet.h:818; TMVA::DNN::Settings::batchSizesize_t batchSize() constmini-batch sizeDefinition NeuralNet.h:767; TMVA::DNN::Settings::computeResultvirtual void computeResult(const Net &, std::vector< double > &)callback for monitoring and loggingDefinition NeuralNet.h:809; TMVA::DNN::Settings::dropRepetitionssize_t dropRe",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:69117,Energy Efficiency,monitor,monitoringDefinition,69117,"euralNet.h:762; TMVA::DNN::Settings::addPointvoid addPoint(std::string histoName, double x)for monitoringDefinition NeuralNet.h:821; TMVA::DNN::Settings::testSamplevirtual void testSample(double, double, double, double)virtual function to be used for monitoring (callback)Definition NeuralNet.h:781; TMVA::DNN::Settings::plotvoid plot(std::string histoName, std::string options, int pad, EColor color)for monitoringDefinition NeuralNet.h:823; TMVA::DNN::Settings::startTrainCyclevirtual void startTrainCycle()Definition NeuralNet.h:782; TMVA::DNN::Settings::convergenceStepssize_t convergenceSteps() consthow many steps until training is deemed to have convergedDefinition NeuralNet.h:766; TMVA::DNN::Settings::factorWeightDecaydouble factorWeightDecay() constget the weight-decay factorDefinition NeuralNet.h:769; TMVA::DNN::Settings::maxConvergenceCountsize_t maxConvergenceCount() constreturns the max convergence count so farDefinition NeuralNet.h:828; TMVA::DNN::Settings::padsvoid pads(int numPads)preparation for monitoringDefinition NeuralNet.h:818; TMVA::DNN::Settings::batchSizesize_t batchSize() constmini-batch sizeDefinition NeuralNet.h:767; TMVA::DNN::Settings::computeResultvirtual void computeResult(const Net &, std::vector< double > &)callback for monitoring and loggingDefinition NeuralNet.h:809; TMVA::DNN::Settings::dropRepetitionssize_t dropRepetitions() constDefinition NeuralNet.h:761; TMVA::DNN::Settings::createvoid create(std::string histoName, int bins, double min, double max)for monitoringDefinition NeuralNet.h:819; TMVA::DNN::Settings::startTestCyclevirtual void startTestCycle()callback for monitoring and logggingDefinition NeuralNet.h:804; TMVA::DNN::Steepest::m_repetitionssize_t m_repetitionsDefinition NeuralNet.h:337; TMVA::DNN::Steepest::m_betadouble m_betainternal parameter (momentum)Definition NeuralNet.h:372; TMVA::DNN::Steepest::m_localGradientsstd::vector< double > m_localGradientslocal gradients for reuse in thread.Definition NeuralNet.h:376; TMVA::DN",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:69363,Energy Efficiency,monitor,monitoring,69363,"unction to be used for monitoring (callback)Definition NeuralNet.h:781; TMVA::DNN::Settings::plotvoid plot(std::string histoName, std::string options, int pad, EColor color)for monitoringDefinition NeuralNet.h:823; TMVA::DNN::Settings::startTrainCyclevirtual void startTrainCycle()Definition NeuralNet.h:782; TMVA::DNN::Settings::convergenceStepssize_t convergenceSteps() consthow many steps until training is deemed to have convergedDefinition NeuralNet.h:766; TMVA::DNN::Settings::factorWeightDecaydouble factorWeightDecay() constget the weight-decay factorDefinition NeuralNet.h:769; TMVA::DNN::Settings::maxConvergenceCountsize_t maxConvergenceCount() constreturns the max convergence count so farDefinition NeuralNet.h:828; TMVA::DNN::Settings::padsvoid pads(int numPads)preparation for monitoringDefinition NeuralNet.h:818; TMVA::DNN::Settings::batchSizesize_t batchSize() constmini-batch sizeDefinition NeuralNet.h:767; TMVA::DNN::Settings::computeResultvirtual void computeResult(const Net &, std::vector< double > &)callback for monitoring and loggingDefinition NeuralNet.h:809; TMVA::DNN::Settings::dropRepetitionssize_t dropRepetitions() constDefinition NeuralNet.h:761; TMVA::DNN::Settings::createvoid create(std::string histoName, int bins, double min, double max)for monitoringDefinition NeuralNet.h:819; TMVA::DNN::Settings::startTestCyclevirtual void startTestCycle()callback for monitoring and logggingDefinition NeuralNet.h:804; TMVA::DNN::Steepest::m_repetitionssize_t m_repetitionsDefinition NeuralNet.h:337; TMVA::DNN::Steepest::m_betadouble m_betainternal parameter (momentum)Definition NeuralNet.h:372; TMVA::DNN::Steepest::m_localGradientsstd::vector< double > m_localGradientslocal gradients for reuse in thread.Definition NeuralNet.h:376; TMVA::DNN::Steepest::m_prevGradientsstd::vector< double > m_prevGradientsvector remembers the gradients of the previous stepDefinition NeuralNet.h:373; TMVA::DNN::Steepest::m_alphadouble m_alphainternal parameter (learningRate)Definitio",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:69606,Energy Efficiency,monitor,monitoringDefinition,69606,"ainCyclevirtual void startTrainCycle()Definition NeuralNet.h:782; TMVA::DNN::Settings::convergenceStepssize_t convergenceSteps() consthow many steps until training is deemed to have convergedDefinition NeuralNet.h:766; TMVA::DNN::Settings::factorWeightDecaydouble factorWeightDecay() constget the weight-decay factorDefinition NeuralNet.h:769; TMVA::DNN::Settings::maxConvergenceCountsize_t maxConvergenceCount() constreturns the max convergence count so farDefinition NeuralNet.h:828; TMVA::DNN::Settings::padsvoid pads(int numPads)preparation for monitoringDefinition NeuralNet.h:818; TMVA::DNN::Settings::batchSizesize_t batchSize() constmini-batch sizeDefinition NeuralNet.h:767; TMVA::DNN::Settings::computeResultvirtual void computeResult(const Net &, std::vector< double > &)callback for monitoring and loggingDefinition NeuralNet.h:809; TMVA::DNN::Settings::dropRepetitionssize_t dropRepetitions() constDefinition NeuralNet.h:761; TMVA::DNN::Settings::createvoid create(std::string histoName, int bins, double min, double max)for monitoringDefinition NeuralNet.h:819; TMVA::DNN::Settings::startTestCyclevirtual void startTestCycle()callback for monitoring and logggingDefinition NeuralNet.h:804; TMVA::DNN::Steepest::m_repetitionssize_t m_repetitionsDefinition NeuralNet.h:337; TMVA::DNN::Steepest::m_betadouble m_betainternal parameter (momentum)Definition NeuralNet.h:372; TMVA::DNN::Steepest::m_localGradientsstd::vector< double > m_localGradientslocal gradients for reuse in thread.Definition NeuralNet.h:376; TMVA::DNN::Steepest::m_prevGradientsstd::vector< double > m_prevGradientsvector remembers the gradients of the previous stepDefinition NeuralNet.h:373; TMVA::DNN::Steepest::m_alphadouble m_alphainternal parameter (learningRate)Definition NeuralNet.h:371; TMVA::DNN::Steepest::m_localWeightsstd::vector< double > m_localWeightslocal weights for reuse in thread.Definition NeuralNet.h:375; TMVA::DNN::Steepest::operator()double operator()(Function &fitnessFunction, Weights &weight",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:69721,Energy Efficiency,monitor,monitoring,69721,"thow many steps until training is deemed to have convergedDefinition NeuralNet.h:766; TMVA::DNN::Settings::factorWeightDecaydouble factorWeightDecay() constget the weight-decay factorDefinition NeuralNet.h:769; TMVA::DNN::Settings::maxConvergenceCountsize_t maxConvergenceCount() constreturns the max convergence count so farDefinition NeuralNet.h:828; TMVA::DNN::Settings::padsvoid pads(int numPads)preparation for monitoringDefinition NeuralNet.h:818; TMVA::DNN::Settings::batchSizesize_t batchSize() constmini-batch sizeDefinition NeuralNet.h:767; TMVA::DNN::Settings::computeResultvirtual void computeResult(const Net &, std::vector< double > &)callback for monitoring and loggingDefinition NeuralNet.h:809; TMVA::DNN::Settings::dropRepetitionssize_t dropRepetitions() constDefinition NeuralNet.h:761; TMVA::DNN::Settings::createvoid create(std::string histoName, int bins, double min, double max)for monitoringDefinition NeuralNet.h:819; TMVA::DNN::Settings::startTestCyclevirtual void startTestCycle()callback for monitoring and logggingDefinition NeuralNet.h:804; TMVA::DNN::Steepest::m_repetitionssize_t m_repetitionsDefinition NeuralNet.h:337; TMVA::DNN::Steepest::m_betadouble m_betainternal parameter (momentum)Definition NeuralNet.h:372; TMVA::DNN::Steepest::m_localGradientsstd::vector< double > m_localGradientslocal gradients for reuse in thread.Definition NeuralNet.h:376; TMVA::DNN::Steepest::m_prevGradientsstd::vector< double > m_prevGradientsvector remembers the gradients of the previous stepDefinition NeuralNet.h:373; TMVA::DNN::Steepest::m_alphadouble m_alphainternal parameter (learningRate)Definition NeuralNet.h:371; TMVA::DNN::Steepest::m_localWeightsstd::vector< double > m_localWeightslocal weights for reuse in thread.Definition NeuralNet.h:375; TMVA::DNN::Steepest::operator()double operator()(Function &fitnessFunction, Weights &weights, PassThrough &passThrough)operator to call the steepest gradient descent algorithmDefinition NeuralNet.icc:271; TMVA::IPythonInter",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:458,Modifiability,variab,variable,458,". ROOT: tmva/tmva/inc/TMVA/NeuralNet.icc Source File. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. NeuralNet.icc. Go to the documentation of this file. 1#ifndef TMVA_NEURAL_NET_I; 2#define TMVA_NEURAL_NET_I; 3 ; 4#ifndef TMVA_NEURAL_NET; 5#error ""Do not use NeuralNet.icc directly. #include \""NeuralNet.h\"" instead.""; 6#endif // TMVA_NEURAL_NET; 7#pragma once; 8#ifndef _MSC_VER; 9#pragma GCC diagnostic ignored ""-Wunused-variable""; 10#endif; 11 ; 12#include ""Math/Util.h""; 13 ; 14#include ""TMVA/Pattern.h""; 15#include ""TMVA/MethodBase.h""; 16 ; 17#include <tuple>; 18#include <future>; 19#include <random>; 20 ; 21namespace TMVA; 22{; 23 namespace DNN; 24 {; 25 ; 26 ; 27 ; 28 ; 29 ; 30 ; 31 ; 32 ; 33 template <typename T>; 34 T uniformFromTo (T from, T to); 35 {; 36 return from + (rand ()* (to - from)/RAND_MAX);; 37 }; 38 ; 39 ; 40 ; 41 template <typename Container, typename T>; 42 void uniformDouble (Container& container, T maxValue); 43 {; 44 for (auto it = begin (container), itEnd = end (container); it != itEnd; ++it); 45 {; 46// (*it) = uniformFromTo (-1.0*maxValue, 1.0*maxValue);; 47 (*it) = TMVA::DNN::uniformFromTo (-1.0*maxValue, 1.0*maxValue);; 48 }; 49 }; 50 ; 51 ; 52 extern std::shared_ptr<std::function<double(double)>> ZeroFnc;; 53 ; 54 ; 55 extern std::shared_ptr<std::function<double(double)>> Sigmoid;; 56 extern std::shared_ptr<std::function<double(double)>> InvSigmoid;; 57 ; 58 extern std::shared_ptr<std::function<double(double)>> Tanh;; 59 extern std::shared_ptr<std::function<double(double)>> InvTanh;; 60 ; 61 extern std::shared_ptr<std::function<double(double)>> Linear;; 62 extern std::shared_ptr<std::function<double(double)>> InvLinear;; 63 ; 64 extern std::shared_ptr<std::function<double(double)>> SymmReLU;; 65 extern std::shared_ptr<std::function<double(double)>> InvSymmReLU;; 66 ; 67 extern std::shared_ptr<std::function<double(double)>> ReLU;; 68 extern std::shared_ptr<std::function<double(double)>> InvReLU;; 69 ; 70 ex",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:19810,Modifiability,layers,layers,19810,"erData.valueGradientsBegin (), currLayerData.gradientsBegin ());; 630 }; 631 }; 632 ; 633 ; 634 ; 635 ; 636 ; 637 ; 638 ; 639 ; 640 ; 641 ; 642 ; 643 ; 644/*! \brief compute the drop-out-weight factor; 645 *; 646 * when using drop-out a fraction of the nodes is turned off at each cycle of the computation; 647 * once all nodes are turned on again (for instances when the test samples are evaluated),; 648 * the weights have to be adjusted to account for the different number of active nodes; 649 * this function computes the factor and applies it to the weights; 650 */; 651 template <typename WeightsType, typename DropProbabilities>; 652 void Net::dropOutWeightFactor (WeightsType& weights,; 653 const DropProbabilities& drops,; 654 bool inverse); 655 {; 656 if (drops.empty () || weights.empty ()); 657 return;; 658 ; 659 auto itWeight = std::begin (weights);; 660 auto itWeightEnd = std::end (weights);; 661 auto itDrop = std::begin (drops);; 662 auto itDropEnd = std::end (drops);; 663 size_t numNodesPrev = inputSize ();; 664 double dropFractionPrev = *itDrop;; 665 ++itDrop;; 666 ; 667 for (auto& layer : layers ()); 668 {; 669 if (itDrop == itDropEnd); 670 break;; 671 ; 672 size_t _numNodes = layer.numNodes ();; 673 ; 674 double dropFraction = *itDrop;; 675 double pPrev = 1.0 - dropFractionPrev;; 676 double p = 1.0 - dropFraction;; 677 p *= pPrev;; 678 ; 679 if (inverse); 680 {; 681 p = 1.0/p;; 682 }; 683 size_t _numWeights = layer.numWeights (numNodesPrev);; 684 for (size_t iWeight = 0; iWeight < _numWeights; ++iWeight); 685 {; 686 if (itWeight == itWeightEnd); 687 break;; 688 ; 689 *itWeight *= p;; 690 ++itWeight;; 691 }; 692 numNodesPrev = _numNodes;; 693 dropFractionPrev = dropFraction;; 694 ++itDrop;; 695 }; 696 }; 697 ; 698 ; 699 ; 700 ; 701 ; 702 ; 703/*! \brief execute the training until convergence emerges; 704 *; 705 * \param weights the container with the weights (synapses); 706 * \param trainPattern the pattern for the training; 707 * \param testPattern the patter",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:27080,Modifiability,variab,variables,27080,"iterator, (*pattern_it).output ().at (0),; 861 (*pattern_it).weight ());; 862 ++output_iterator;; 863 }; 864 }; 865 }; 866 testError += testPatternError; /// batch.size ();; 867 }; 868 // testError /= testPattern.size ();; 869 }; 870 settings.endTestCycle ();; 871// testError /= weightSum;; 872 ; 873 settings.computeResult (*this, weights);; 874 ; 875 hasConverged = settings.hasConverged (testError);; 876 if (!hasConverged && !isWeightsForDrop); 877 {; 878 dropOutWeightFactor (weights, dropFractions, true); // inverse; 879 isWeightsForDrop = true;; 880 }; 881 }; 882 ++testCycleCount;; 883 ++dropOutChangeCount;; 884 ; 885 ; 886// settings.resetPlot (""errors"");; 887 settings.addPoint (""trainErrors"", cycleCount, trainError);; 888 settings.addPoint (""testErrors"", cycleCount, testError);; 889 settings.plot (""trainErrors"", ""C"", 1, kBlue);; 890 settings.plot (""testErrors"", ""C"", 1, kMagenta);; 891 ; 892 ; 893 // setup error plots and progress bar variables for JsMVA; 894 if (fInteractive){; 895 fInteractive->AddPoint(cycleCount, trainError, testError);; 896 if (*fExitFromTraining) break;; 897 *fIPyCurrentIter = 100*(double)settings.maxConvergenceCount () /(double)settings.convergenceSteps ();; 898 }; 899 ; 900 if (hasConverged); 901 break;; 902 ; 903 if ((int)cycleCount % 10 == 0) {; 904 ; 905 TString convText = TString::Format( ""(train/test/epo/conv/maxco): %.3g/%.3g/%d/%d/%d"",; 906 trainError,; 907 testError,; 908 (int)cycleCount,; 909 (int)settings.convergenceCount (),; 910 (int)settings.maxConvergenceCount ());; 911 double progress = 100*(double)settings.maxConvergenceCount () /(double)settings.convergenceSteps ();; 912 settings.cycle (progress, convText);; 913 }; 914 }; 915 while (true);; 916 settings.endTrainCycle (trainError);; 917 ; 918 TString convText = TString::Format( ""(train/test/epoch): %.4g/%.4g/%d"", trainError, testError, (int)cycleCount);; 919 double progress = 100*(double)settings.maxConvergenceCount() /(double)settings.convergenceSteps ();; 920 settings.cy",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:36364,Modifiability,layers,layers,36364,"ize ());; 1104 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (gradients), std::end (gradients), 0, outputContainer, true);; 1105 return error;; 1106 }; 1107 ; 1108 ; 1109 ; 1110 template <typename LayerContainer, typename DropContainer, typename ItWeight, typename ItGradient>; 1111 std::vector<std::vector<LayerData>> Net::prepareLayerData (LayerContainer& _layers,; 1112 Batch& batch,; 1113 const DropContainer& dropContainer,; 1114 ItWeight itWeightBegin,; 1115 ItWeight /*itWeightEnd*/,; 1116 ItGradient itGradientBegin,; 1117 ItGradient itGradientEnd,; 1118 size_t& totalNumWeights) const; 1119 {; 1120 LayerData::const_dropout_iterator itDropOut;; 1121 bool usesDropOut = !dropContainer.empty ();; 1122 if (usesDropOut); 1123 itDropOut = std::begin (dropContainer);; 1124 ; 1125 if (_layers.empty ()); 1126 throw std::string (""no layers in this net"");; 1127 ; 1128 ; 1129 // ----------- create layer data -------------------------------------------------------; 1130 //LM- This assert not needed anymore (outputsize is actually numNodes+1); 1131 //assert (_layers.back ().numNodes () == outputSize ());; 1132 totalNumWeights = 0;; 1133 std::vector<std::vector<LayerData>> layerPatternData;; 1134 layerPatternData.reserve (_layers.size ()+1);; 1135 ItWeight itWeight = itWeightBegin;; 1136 ItGradient itGradient = itGradientBegin;; 1137 size_t numNodesPrev = inputSize ();; 1138 typename Pattern::const_iterator itInputBegin;; 1139 typename Pattern::const_iterator itInputEnd;; 1140 ; 1141 // ItWeight itGammaBegin = itWeightBegin + numWeights ();; 1142 // ItWeight itBetaBegin = itWeightBegin + numWeights () + numNodes ();; 1143 // ItGradient itGradGammaBegin = itGradientBegin + numWeights ();; 1144 // ItGradient itGradBetaBegin = itGradientBegin + numWeights () + numNodes ();; 1145 ; 1146 ; 1147 // --------------------- prepare layer data for input layer ----------------------------; 1148 layerPatternData.push_back (std:",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:38043,Modifiability,layers,layers,38043,"itGradientBegin + numWeights ();; 1144 // ItGradient itGradBetaBegin = itGradientBegin + numWeights () + numNodes ();; 1145 ; 1146 ; 1147 // --------------------- prepare layer data for input layer ----------------------------; 1148 layerPatternData.push_back (std::vector<LayerData>());; 1149 for (const Pattern& _pattern : batch); 1150 {; 1151 std::vector<LayerData>& layerData = layerPatternData.back ();; 1152 layerData.push_back (LayerData (numNodesPrev));; 1153 ; 1154 itInputBegin = _pattern.beginInput ();; 1155 itInputEnd = _pattern.endInput ();; 1156 layerData.back ().setInput (itInputBegin, itInputEnd);; 1157 ; 1158 if (usesDropOut); 1159 layerData.back ().setDropOut (itDropOut);; 1160 ; 1161 }; 1162 ; 1163 ; 1164 if (usesDropOut); 1165 itDropOut += _layers.back ().numNodes ();; 1166 ; 1167 // ---------------- prepare subsequent layers ---------------------------------------------; 1168 // for each of the layers; 1169 for (auto itLayer = begin (_layers), itLayerEnd = end (_layers); itLayer != itLayerEnd; ++itLayer); 1170 {; 1171 bool isOutputLayer = (itLayer+1 == itLayerEnd);; 1172 bool isFirstHiddenLayer = (itLayer == begin (_layers));; 1173 ; 1174 auto& layer = *itLayer;; 1175 layerPatternData.push_back (std::vector<LayerData>());; 1176 // for each pattern, prepare a layerData; 1177 for (const Pattern& _pattern : batch); 1178 {; 1179 std::vector<LayerData>& layerData = layerPatternData.back ();; 1180 //layerData.push_back (LayerData (numNodesPrev));; 1181 ; 1182 if (itGradientBegin == itGradientEnd); 1183 {; 1184 layerData.push_back (LayerData (layer.numNodes (), itWeight,; 1185 layer.activationFunction (),; 1186 layer.modeOutputValues ()));; 1187 }; 1188 else; 1189 {; 1190 layerData.push_back (LayerData (layer.numNodes (), itWeight, itGradient,; 1191 layer.activationFunction (),; 1192 layer.inverseActivationFunction (),; 1193 layer.modeOutputValues ()));; 1194 }; 1195 ; 1196 if (usesDropOut); 1197 {; 1198 layerData.back ().setDropOut (itDropOut);; 1199 }; 120",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:38121,Modifiability,layers,layers,38121,"itGradientBegin + numWeights ();; 1144 // ItGradient itGradBetaBegin = itGradientBegin + numWeights () + numNodes ();; 1145 ; 1146 ; 1147 // --------------------- prepare layer data for input layer ----------------------------; 1148 layerPatternData.push_back (std::vector<LayerData>());; 1149 for (const Pattern& _pattern : batch); 1150 {; 1151 std::vector<LayerData>& layerData = layerPatternData.back ();; 1152 layerData.push_back (LayerData (numNodesPrev));; 1153 ; 1154 itInputBegin = _pattern.beginInput ();; 1155 itInputEnd = _pattern.endInput ();; 1156 layerData.back ().setInput (itInputBegin, itInputEnd);; 1157 ; 1158 if (usesDropOut); 1159 layerData.back ().setDropOut (itDropOut);; 1160 ; 1161 }; 1162 ; 1163 ; 1164 if (usesDropOut); 1165 itDropOut += _layers.back ().numNodes ();; 1166 ; 1167 // ---------------- prepare subsequent layers ---------------------------------------------; 1168 // for each of the layers; 1169 for (auto itLayer = begin (_layers), itLayerEnd = end (_layers); itLayer != itLayerEnd; ++itLayer); 1170 {; 1171 bool isOutputLayer = (itLayer+1 == itLayerEnd);; 1172 bool isFirstHiddenLayer = (itLayer == begin (_layers));; 1173 ; 1174 auto& layer = *itLayer;; 1175 layerPatternData.push_back (std::vector<LayerData>());; 1176 // for each pattern, prepare a layerData; 1177 for (const Pattern& _pattern : batch); 1178 {; 1179 std::vector<LayerData>& layerData = layerPatternData.back ();; 1180 //layerData.push_back (LayerData (numNodesPrev));; 1181 ; 1182 if (itGradientBegin == itGradientEnd); 1183 {; 1184 layerData.push_back (LayerData (layer.numNodes (), itWeight,; 1185 layer.activationFunction (),; 1186 layer.modeOutputValues ()));; 1187 }; 1188 else; 1189 {; 1190 layerData.push_back (LayerData (layer.numNodes (), itWeight, itGradient,; 1191 layer.activationFunction (),; 1192 layer.inverseActivationFunction (),; 1193 layer.modeOutputValues ()));; 1194 }; 1195 ; 1196 if (usesDropOut); 1197 {; 1198 layerData.back ().setDropOut (itDropOut);; 1199 }; 120",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:40640,Modifiability,layers,layers,40640,"ern (const LayerContainer& _layers,; 1222 std::vector<LayerData>& layerData) const; 1223 {; 1224 size_t idxLayer = 0, idxLayerEnd = _layers.size ();; 1225 for (; idxLayer < idxLayerEnd; ++idxLayer); 1226 {; 1227 LayerData& prevLayerData = layerData.at (idxLayer);; 1228 LayerData& currLayerData = layerData.at (idxLayer+1);; 1229 ; 1230 forward (prevLayerData, currLayerData);; 1231 ; 1232 applyFunctions (currLayerData.valuesBegin (), currLayerData.valuesEnd (), currLayerData.activationFunction ());; 1233 }; 1234 }; 1235 ; 1236 ; 1237 ; 1238 ; 1239 template <typename LayerContainer, typename LayerPatternContainer>; 1240 void Net::forwardBatch (const LayerContainer& _layers,; 1241 LayerPatternContainer& layerPatternData,; 1242 std::vector<double>& valuesMean,; 1243 std::vector<double>& valuesStdDev,; 1244 size_t trainFromLayer) const; 1245 {; 1246 valuesMean.clear ();; 1247 valuesStdDev.clear ();; 1248 ; 1249 // ---------------------------------- loop over layers and pattern -------------------------------------------------------; 1250 for (size_t idxLayer = 0, idxLayerEnd = layerPatternData.size (); idxLayer < idxLayerEnd-1; ++idxLayer); 1251 {; 1252 bool doTraining = idxLayer >= trainFromLayer;; 1253 ; 1254 // get layer-pattern data for this and the corresponding one from the next layer; 1255 std::vector<LayerData>& prevLayerPatternData = layerPatternData.at (idxLayer);; 1256 std::vector<LayerData>& currLayerPatternData = layerPatternData.at (idxLayer+1);; 1257 ; 1258 size_t numPattern = prevLayerPatternData.size ();; 1259 size_t numNodesLayer = _layers.at (idxLayer).numNodes ();; 1260 ; 1261 std::vector<MeanVariance> means (numNodesLayer);; 1262 // ---------------- loop over layerDatas of pattern compute forward ----------------------------; 1263 for (size_t idxPattern = 0; idxPattern < numPattern; ++idxPattern); 1264 {; 1265 const LayerData& prevLayerData = prevLayerPatternData.at (idxPattern);; 1266 LayerData& currLayerData = currLayerPatternData.at (idxPattern);; 1",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:49771,Modifiability,layers,layers,49771,"tBegin + totalNumWeights);; 1447 ; 1448 ; 1449 // ------------- backpropagation -------------; 1450 backPropagate (layerPatternData, settings, trainFromLayer, totalNumWeights);; 1451 ; 1452 ; 1453 // --- compile the measures; 1454 double batchSize = std::distance (std::begin (batch), std::end (batch));; 1455 for (auto it = itGradientBegin; it != itGradientEnd; ++it); 1456 (*it) /= batchSize;; 1457 ; 1458 ; 1459 sumError /= sumWeights;; 1460 return sumError;; 1461 }; 1462 ; 1463 ; 1464 ; 1465/*! \brief initialization of the weights; 1466 *; 1467 *; 1468 */; 1469 template <typename OutIterator>; 1470 void Net::initializeWeights (WeightInitializationStrategy eInitStrategy, OutIterator itWeight); 1471 {; 1472 if (eInitStrategy == WeightInitializationStrategy::XAVIER); 1473 {; 1474 // input and output properties; 1475 int numInput = inputSize ();; 1476 ; 1477 // compute variance and mean of input and output; 1478 //...; 1479 ; 1480 ; 1481 // compute the weights; 1482 for (auto& layer: layers ()); 1483 {; 1484 double nIn = numInput;; 1485 double stdDev = sqrt (2.0/nIn);; 1486 for (size_t iWeight = 0, iWeightEnd = layer.numWeights (numInput); iWeight < iWeightEnd; ++iWeight); 1487 {; 1488 (*itWeight) = DNN::gaussDouble (0.0, stdDev); // factor 2.0 for ReLU; 1489 ++itWeight;; 1490 }; 1491 numInput = layer.numNodes ();; 1492 }; 1493 return;; 1494 }; 1495 ; 1496 if (eInitStrategy == WeightInitializationStrategy::XAVIERUNIFORM); 1497 {; 1498 // input and output properties; 1499 int numInput = inputSize ();; 1500 ; 1501 // compute variance and mean of input and output; 1502 //...; 1503 ; 1504 ; 1505 // compute the weights; 1506 for (auto& layer: layers ()); 1507 {; 1508 double nIn = numInput;; 1509 double minVal = -sqrt(2.0/nIn);; 1510 double maxVal = sqrt (2.0/nIn);; 1511 for (size_t iWeight = 0, iWeightEnd = layer.numWeights (numInput); iWeight < iWeightEnd; ++iWeight); 1512 {; 1513 ; 1514 (*itWeight) = DNN::uniformDouble (minVal, maxVal); // factor 2.0 for ReLU; 1515 ++itWei",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:50438,Modifiability,layers,layers,50438,"itStrategy, OutIterator itWeight); 1471 {; 1472 if (eInitStrategy == WeightInitializationStrategy::XAVIER); 1473 {; 1474 // input and output properties; 1475 int numInput = inputSize ();; 1476 ; 1477 // compute variance and mean of input and output; 1478 //...; 1479 ; 1480 ; 1481 // compute the weights; 1482 for (auto& layer: layers ()); 1483 {; 1484 double nIn = numInput;; 1485 double stdDev = sqrt (2.0/nIn);; 1486 for (size_t iWeight = 0, iWeightEnd = layer.numWeights (numInput); iWeight < iWeightEnd; ++iWeight); 1487 {; 1488 (*itWeight) = DNN::gaussDouble (0.0, stdDev); // factor 2.0 for ReLU; 1489 ++itWeight;; 1490 }; 1491 numInput = layer.numNodes ();; 1492 }; 1493 return;; 1494 }; 1495 ; 1496 if (eInitStrategy == WeightInitializationStrategy::XAVIERUNIFORM); 1497 {; 1498 // input and output properties; 1499 int numInput = inputSize ();; 1500 ; 1501 // compute variance and mean of input and output; 1502 //...; 1503 ; 1504 ; 1505 // compute the weights; 1506 for (auto& layer: layers ()); 1507 {; 1508 double nIn = numInput;; 1509 double minVal = -sqrt(2.0/nIn);; 1510 double maxVal = sqrt (2.0/nIn);; 1511 for (size_t iWeight = 0, iWeightEnd = layer.numWeights (numInput); iWeight < iWeightEnd; ++iWeight); 1512 {; 1513 ; 1514 (*itWeight) = DNN::uniformDouble (minVal, maxVal); // factor 2.0 for ReLU; 1515 ++itWeight;; 1516 }; 1517 numInput = layer.numNodes ();; 1518 }; 1519 return;; 1520 }; 1521 ; 1522 if (eInitStrategy == WeightInitializationStrategy::TEST); 1523 {; 1524 // input and output properties; 1525 int numInput = inputSize ();; 1526 ; 1527 // compute variance and mean of input and output; 1528 //...; 1529 ; 1530 ; 1531 // compute the weights; 1532 for (auto& layer: layers ()); 1533 {; 1534// double nIn = numInput;; 1535 for (size_t iWeight = 0, iWeightEnd = layer.numWeights (numInput); iWeight < iWeightEnd; ++iWeight); 1536 {; 1537 (*itWeight) = DNN::gaussDouble (0.0, 0.1);; 1538 ++itWeight;; 1539 }; 1540 numInput = layer.numNodes ();; 1541 }; 1542 return;;",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:51146,Modifiability,layers,layers,51146,"rategy == WeightInitializationStrategy::XAVIERUNIFORM); 1497 {; 1498 // input and output properties; 1499 int numInput = inputSize ();; 1500 ; 1501 // compute variance and mean of input and output; 1502 //...; 1503 ; 1504 ; 1505 // compute the weights; 1506 for (auto& layer: layers ()); 1507 {; 1508 double nIn = numInput;; 1509 double minVal = -sqrt(2.0/nIn);; 1510 double maxVal = sqrt (2.0/nIn);; 1511 for (size_t iWeight = 0, iWeightEnd = layer.numWeights (numInput); iWeight < iWeightEnd; ++iWeight); 1512 {; 1513 ; 1514 (*itWeight) = DNN::uniformDouble (minVal, maxVal); // factor 2.0 for ReLU; 1515 ++itWeight;; 1516 }; 1517 numInput = layer.numNodes ();; 1518 }; 1519 return;; 1520 }; 1521 ; 1522 if (eInitStrategy == WeightInitializationStrategy::TEST); 1523 {; 1524 // input and output properties; 1525 int numInput = inputSize ();; 1526 ; 1527 // compute variance and mean of input and output; 1528 //...; 1529 ; 1530 ; 1531 // compute the weights; 1532 for (auto& layer: layers ()); 1533 {; 1534// double nIn = numInput;; 1535 for (size_t iWeight = 0, iWeightEnd = layer.numWeights (numInput); iWeight < iWeightEnd; ++iWeight); 1536 {; 1537 (*itWeight) = DNN::gaussDouble (0.0, 0.1);; 1538 ++itWeight;; 1539 }; 1540 numInput = layer.numNodes ();; 1541 }; 1542 return;; 1543 }; 1544 ; 1545 if (eInitStrategy == WeightInitializationStrategy::LAYERSIZE); 1546 {; 1547 // input and output properties; 1548 int numInput = inputSize ();; 1549 ; 1550 // compute variance and mean of input and output; 1551 //...; 1552 ; 1553 ; 1554 // compute the weights; 1555 for (auto& layer: layers ()); 1556 {; 1557 double nIn = numInput;; 1558 for (size_t iWeight = 0, iWeightEnd = layer.numWeights (numInput); iWeight < iWeightEnd; ++iWeight); 1559 {; 1560 (*itWeight) = DNN::gaussDouble (0.0, sqrt (layer.numWeights (nIn))); // factor 2.0 for ReLU; 1561 ++itWeight;; 1562 }; 1563 numInput = layer.numNodes ();; 1564 }; 1565 return;; 1566 }; 1567 ; 1568 }; 1569 ; 1570 ; 1571 ; 1572 ; 1573 ; 1574/*! \bri",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:51747,Modifiability,layers,layers,51747,"; 1515 ++itWeight;; 1516 }; 1517 numInput = layer.numNodes ();; 1518 }; 1519 return;; 1520 }; 1521 ; 1522 if (eInitStrategy == WeightInitializationStrategy::TEST); 1523 {; 1524 // input and output properties; 1525 int numInput = inputSize ();; 1526 ; 1527 // compute variance and mean of input and output; 1528 //...; 1529 ; 1530 ; 1531 // compute the weights; 1532 for (auto& layer: layers ()); 1533 {; 1534// double nIn = numInput;; 1535 for (size_t iWeight = 0, iWeightEnd = layer.numWeights (numInput); iWeight < iWeightEnd; ++iWeight); 1536 {; 1537 (*itWeight) = DNN::gaussDouble (0.0, 0.1);; 1538 ++itWeight;; 1539 }; 1540 numInput = layer.numNodes ();; 1541 }; 1542 return;; 1543 }; 1544 ; 1545 if (eInitStrategy == WeightInitializationStrategy::LAYERSIZE); 1546 {; 1547 // input and output properties; 1548 int numInput = inputSize ();; 1549 ; 1550 // compute variance and mean of input and output; 1551 //...; 1552 ; 1553 ; 1554 // compute the weights; 1555 for (auto& layer: layers ()); 1556 {; 1557 double nIn = numInput;; 1558 for (size_t iWeight = 0, iWeightEnd = layer.numWeights (numInput); iWeight < iWeightEnd; ++iWeight); 1559 {; 1560 (*itWeight) = DNN::gaussDouble (0.0, sqrt (layer.numWeights (nIn))); // factor 2.0 for ReLU; 1561 ++itWeight;; 1562 }; 1563 numInput = layer.numNodes ();; 1564 }; 1565 return;; 1566 }; 1567 ; 1568 }; 1569 ; 1570 ; 1571 ; 1572 ; 1573 ; 1574/*! \brief compute the error function; 1575 *; 1576 *; 1577 */; 1578 template <typename Container, typename ItWeight>; 1579 double Net::errorFunction (LayerData& layerData,; 1580 Container truth,; 1581 ItWeight itWeight,; 1582 ItWeight itWeightEnd,; 1583 double patternWeight,; 1584 double factorWeightDecay,; 1585 EnumRegularization eRegularization) const; 1586 {; 1587 double error (0);; 1588 switch (m_eErrorFunction); 1589 {; 1590 case ModeErrorFunction::SUMOFSQUARES:; 1591 {; 1592 error = sumOfSquares (layerData.valuesBegin (), layerData.valuesEnd (), begin (truth), end (truth),; 1593 layerData.delta",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:55441,Modifiability,layers,layers,55441,"ghtGeneral = std::begin (weights);; 1646// std::vector<Pattern> prePatternTrain (trainPattern.size ());; 1647// std::vector<Pattern> prePatternTest (testPattern.size ());; 1648 ; 1649// size_t _inputSize = inputSize ();; 1650 ; 1651// // transform pattern using the created preNet; 1652// auto initializePrePattern = [&](const std::vector<Pattern>& pttrnInput, std::vector<Pattern>& pttrnOutput); 1653// {; 1654// pttrnOutput.clear ();; 1655// std::transform (std::begin (pttrnInput), std::end (pttrnInput),; 1656// std::back_inserter (pttrnOutput),; 1657// [](const Pattern& p); 1658// {; 1659// Pattern pat (p.input (), p.input (), p.weight ());; 1660// return pat;; 1661// });; 1662// };; 1663 ; 1664// initializePrePattern (trainPattern, prePatternTrain);; 1665// initializePrePattern (testPattern, prePatternTest);; 1666 ; 1667// std::vector<double> originalDropFractions = settings.dropFractions ();; 1668 ; 1669// for (auto& _layer : layers ()); 1670// {; 1671// // compute number of weights (as a function of the number of incoming nodes); 1672// // fetch number of nodes; 1673// size_t numNodes = _layer.numNodes ();; 1674// size_t _numWeights = _layer.numWeights (_inputSize);; 1675 ; 1676// // ------------------; 1677// DNN::Net preNet;; 1678// if (!originalDropFractions.empty ()); 1679// {; 1680// originalDropFractions.erase (originalDropFractions.begin ());; 1681// settings.setDropOut (originalDropFractions.begin (), originalDropFractions.end (), settings.dropRepetitions ());; 1682// }; 1683// std::vector<double> preWeights;; 1684 ; 1685// // define the preNet (pretraining-net) for this layer; 1686// // outputSize == inputSize, because this is an autoencoder;; 1687// preNet.setInputSize (_inputSize);; 1688// preNet.addLayer (DNN::Layer (numNodes, _layer.activationFunctionType ()));; 1689// preNet.addLayer (DNN::Layer (_inputSize, DNN::EnumFunction::LINEAR, DNN::ModeOutputValues::DIRECT));; 1690// preNet.setErrorFunction (DNN::ModeErrorFunction::SUMOFSQUARES);; 1691// preNe",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:58658,Modifiability,layers,layers,58658,"move the outputLayer of the preNet; 1715// preNet.removeLayer ();; 1716 ; 1717// // set the output size to the number of nodes in the new output layer (== last hidden layer); 1718// preNet.setOutputSize (numNodes);; 1719 ; 1720// // transform pattern using the created preNet; 1721// auto proceedPattern = [&](std::vector<Pattern>& pttrn); 1722// {; 1723// std::vector<Pattern> newPttrn;; 1724// std::for_each (std::begin (pttrn), std::end (pttrn),; 1725// [&preNet,&preWeights,&newPttrn](Pattern& p); 1726// {; 1727// std::vector<double> output = preNet.compute (p.input (), preWeights);; 1728// Pattern pat (output, output, p.weight ());; 1729// newPttrn.push_back (pat);; 1730// // p = pat;; 1731// });; 1732// return newPttrn;; 1733// };; 1734 ; 1735 ; 1736// prePatternTrain = proceedPattern (prePatternTrain);; 1737// prePatternTest = proceedPattern (prePatternTest);; 1738 ; 1739 ; 1740// // the new input size is the output size of the already reduced preNet; 1741// _inputSize = preNet.layers ().back ().numNodes ();; 1742// }; 1743// }; 1744 ; 1745 ; 1746 ; 1747 ; 1748 ; 1749 ; 1750 ; 1751 ; 1752 ; 1753 ; 1754 ; 1755 ; 1756 ; 1757 ; 1758 ; 1759 ; 1760 } // namespace DNN; 1761} // namespace TMVA; 1762 ; 1763#endif; MethodBase.h; Pattern.h; f#define f(i)Definition RSha256.hxx:104; g#define g(i)Definition RSha256.hxx:105; kMagenta@ kMagentaDefinition Rtypes.h:66; kBlue@ kBlueDefinition Rtypes.h:66; wwinID wDefinition TGWin32VirtualGLProxy.cxx:39; pwinID h TVirtualViewer3D TVirtualGLPainter pDefinition TGWin32VirtualGLProxy.cxx:51; inputOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void inputDefinition TGWin32VirtualXProxy.cxx:142; resultOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t Float_t Float_t Int_t Int_t U",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:63547,Modifiability,layers,layersconst,63547,"er > m_layerslayer-structure-dataDefinition NeuralNet.h:1272; TMVA::DNN::Net::fIPyMaxIterUInt_t * fIPyMaxIterDefinition NeuralNet.h:1278; TMVA::DNN::Net::computestd::vector< double > compute(const std::vector< double > &input, const Weights &weights) constcompute the net with the given input and the given weightsDefinition NeuralNet.icc:1037; TMVA::DNN::Net::fetchOutputvoid fetchOutput(const LayerData &lastLayerData, OutputContainer &outputContainer) constDefinition NeuralNet.icc:1291; TMVA::DNN::Net::inputSizesize_t inputSize() constinput size of the DNNDefinition NeuralNet.h:1098; TMVA::DNN::Net::m_eErrorFunctionModeErrorFunction m_eErrorFunctiondenotes the error functionDefinition NeuralNet.h:1269; TMVA::DNN::Net::traindouble train(std::vector< double > &weights, std::vector< Pattern > &trainPattern, const std::vector< Pattern > &testPattern, Minimizer &minimizer, Settings &settings)start the trainingDefinition NeuralNet.icc:712; TMVA::DNN::Net::layersconst std::vector< Layer > & layers() constreturns the layers (structure)Definition NeuralNet.h:1245; TMVA::DNN::Net::prepareLayerDatastd::vector< std::vector< LayerData > > prepareLayerData(LayerContainer &layers, Batch &batch, const DropContainer &dropContainer, ItWeight itWeightBegin, ItWeight itWeightEnd, ItGradient itGradientBegin, ItGradient itGradientEnd, size_t &totalNumWeights) constDefinition NeuralNet.icc:1111; TMVA::DNN::Net::initializeWeightsvoid initializeWeights(WeightInitializationStrategy eInitStrategy, OutIterator itWeight)initialize the weights with the given strategyDefinition NeuralNet.icc:1470; TMVA::DNN::Net::outputSizesize_t outputSize() constoutput size of the DNNDefinition NeuralNet.h:1099; TMVA::DNN::Net::errorFunctiondouble errorFunction(LayerData &layerData, Container truth, ItWeight itWeight, ItWeight itWeightEnd, double patternWeight, double factorWeightDecay, EnumRegularization eRegularization) constcomputes the error of the DNNDefinition NeuralNet.icc:1579; TMVA::DNN::Net::forward_bac",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:63582,Modifiability,layers,layers,63582,"er > m_layerslayer-structure-dataDefinition NeuralNet.h:1272; TMVA::DNN::Net::fIPyMaxIterUInt_t * fIPyMaxIterDefinition NeuralNet.h:1278; TMVA::DNN::Net::computestd::vector< double > compute(const std::vector< double > &input, const Weights &weights) constcompute the net with the given input and the given weightsDefinition NeuralNet.icc:1037; TMVA::DNN::Net::fetchOutputvoid fetchOutput(const LayerData &lastLayerData, OutputContainer &outputContainer) constDefinition NeuralNet.icc:1291; TMVA::DNN::Net::inputSizesize_t inputSize() constinput size of the DNNDefinition NeuralNet.h:1098; TMVA::DNN::Net::m_eErrorFunctionModeErrorFunction m_eErrorFunctiondenotes the error functionDefinition NeuralNet.h:1269; TMVA::DNN::Net::traindouble train(std::vector< double > &weights, std::vector< Pattern > &trainPattern, const std::vector< Pattern > &testPattern, Minimizer &minimizer, Settings &settings)start the trainingDefinition NeuralNet.icc:712; TMVA::DNN::Net::layersconst std::vector< Layer > & layers() constreturns the layers (structure)Definition NeuralNet.h:1245; TMVA::DNN::Net::prepareLayerDatastd::vector< std::vector< LayerData > > prepareLayerData(LayerContainer &layers, Batch &batch, const DropContainer &dropContainer, ItWeight itWeightBegin, ItWeight itWeightEnd, ItGradient itGradientBegin, ItGradient itGradientEnd, size_t &totalNumWeights) constDefinition NeuralNet.icc:1111; TMVA::DNN::Net::initializeWeightsvoid initializeWeights(WeightInitializationStrategy eInitStrategy, OutIterator itWeight)initialize the weights with the given strategyDefinition NeuralNet.icc:1470; TMVA::DNN::Net::outputSizesize_t outputSize() constoutput size of the DNNDefinition NeuralNet.h:1099; TMVA::DNN::Net::errorFunctiondouble errorFunction(LayerData &layerData, Container truth, ItWeight itWeight, ItWeight itWeightEnd, double patternWeight, double factorWeightDecay, EnumRegularization eRegularization) constcomputes the error of the DNNDefinition NeuralNet.icc:1579; TMVA::DNN::Net::forward_bac",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:63608,Modifiability,layers,layers,63608,"er > m_layerslayer-structure-dataDefinition NeuralNet.h:1272; TMVA::DNN::Net::fIPyMaxIterUInt_t * fIPyMaxIterDefinition NeuralNet.h:1278; TMVA::DNN::Net::computestd::vector< double > compute(const std::vector< double > &input, const Weights &weights) constcompute the net with the given input and the given weightsDefinition NeuralNet.icc:1037; TMVA::DNN::Net::fetchOutputvoid fetchOutput(const LayerData &lastLayerData, OutputContainer &outputContainer) constDefinition NeuralNet.icc:1291; TMVA::DNN::Net::inputSizesize_t inputSize() constinput size of the DNNDefinition NeuralNet.h:1098; TMVA::DNN::Net::m_eErrorFunctionModeErrorFunction m_eErrorFunctiondenotes the error functionDefinition NeuralNet.h:1269; TMVA::DNN::Net::traindouble train(std::vector< double > &weights, std::vector< Pattern > &trainPattern, const std::vector< Pattern > &testPattern, Minimizer &minimizer, Settings &settings)start the trainingDefinition NeuralNet.icc:712; TMVA::DNN::Net::layersconst std::vector< Layer > & layers() constreturns the layers (structure)Definition NeuralNet.h:1245; TMVA::DNN::Net::prepareLayerDatastd::vector< std::vector< LayerData > > prepareLayerData(LayerContainer &layers, Batch &batch, const DropContainer &dropContainer, ItWeight itWeightBegin, ItWeight itWeightEnd, ItGradient itGradientBegin, ItGradient itGradientEnd, size_t &totalNumWeights) constDefinition NeuralNet.icc:1111; TMVA::DNN::Net::initializeWeightsvoid initializeWeights(WeightInitializationStrategy eInitStrategy, OutIterator itWeight)initialize the weights with the given strategyDefinition NeuralNet.icc:1470; TMVA::DNN::Net::outputSizesize_t outputSize() constoutput size of the DNNDefinition NeuralNet.h:1099; TMVA::DNN::Net::errorFunctiondouble errorFunction(LayerData &layerData, Container truth, ItWeight itWeight, ItWeight itWeightEnd, double patternWeight, double factorWeightDecay, EnumRegularization eRegularization) constcomputes the error of the DNNDefinition NeuralNet.icc:1579; TMVA::DNN::Net::forward_bac",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:63760,Modifiability,layers,layers,63760,"t, const Weights &weights) constcompute the net with the given input and the given weightsDefinition NeuralNet.icc:1037; TMVA::DNN::Net::fetchOutputvoid fetchOutput(const LayerData &lastLayerData, OutputContainer &outputContainer) constDefinition NeuralNet.icc:1291; TMVA::DNN::Net::inputSizesize_t inputSize() constinput size of the DNNDefinition NeuralNet.h:1098; TMVA::DNN::Net::m_eErrorFunctionModeErrorFunction m_eErrorFunctiondenotes the error functionDefinition NeuralNet.h:1269; TMVA::DNN::Net::traindouble train(std::vector< double > &weights, std::vector< Pattern > &trainPattern, const std::vector< Pattern > &testPattern, Minimizer &minimizer, Settings &settings)start the trainingDefinition NeuralNet.icc:712; TMVA::DNN::Net::layersconst std::vector< Layer > & layers() constreturns the layers (structure)Definition NeuralNet.h:1245; TMVA::DNN::Net::prepareLayerDatastd::vector< std::vector< LayerData > > prepareLayerData(LayerContainer &layers, Batch &batch, const DropContainer &dropContainer, ItWeight itWeightBegin, ItWeight itWeightEnd, ItGradient itGradientBegin, ItGradient itGradientEnd, size_t &totalNumWeights) constDefinition NeuralNet.icc:1111; TMVA::DNN::Net::initializeWeightsvoid initializeWeights(WeightInitializationStrategy eInitStrategy, OutIterator itWeight)initialize the weights with the given strategyDefinition NeuralNet.icc:1470; TMVA::DNN::Net::outputSizesize_t outputSize() constoutput size of the DNNDefinition NeuralNet.h:1099; TMVA::DNN::Net::errorFunctiondouble errorFunction(LayerData &layerData, Container truth, ItWeight itWeight, ItWeight itWeightEnd, double patternWeight, double factorWeightDecay, EnumRegularization eRegularization) constcomputes the error of the DNNDefinition NeuralNet.icc:1579; TMVA::DNN::Net::forward_backwarddouble forward_backward(LayerContainer &layers, PassThrough &settingsAndBatch, ItWeight itWeightBegin, ItWeight itWeightEnd, ItGradient itGradientBegin, ItGradient itGradientEnd, size_t trainFromLayer, OutContainer &ou",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:64630,Modifiability,layers,layers,64630,"a > > prepareLayerData(LayerContainer &layers, Batch &batch, const DropContainer &dropContainer, ItWeight itWeightBegin, ItWeight itWeightEnd, ItGradient itGradientBegin, ItGradient itGradientEnd, size_t &totalNumWeights) constDefinition NeuralNet.icc:1111; TMVA::DNN::Net::initializeWeightsvoid initializeWeights(WeightInitializationStrategy eInitStrategy, OutIterator itWeight)initialize the weights with the given strategyDefinition NeuralNet.icc:1470; TMVA::DNN::Net::outputSizesize_t outputSize() constoutput size of the DNNDefinition NeuralNet.h:1099; TMVA::DNN::Net::errorFunctiondouble errorFunction(LayerData &layerData, Container truth, ItWeight itWeight, ItWeight itWeightEnd, double patternWeight, double factorWeightDecay, EnumRegularization eRegularization) constcomputes the error of the DNNDefinition NeuralNet.icc:1579; TMVA::DNN::Net::forward_backwarddouble forward_backward(LayerContainer &layers, PassThrough &settingsAndBatch, ItWeight itWeightBegin, ItWeight itWeightEnd, ItGradient itGradientBegin, ItGradient itGradientEnd, size_t trainFromLayer, OutContainer &outputContainer, bool fetchOutput) constmain NN computation functionDefinition NeuralNet.icc:1405; TMVA::DNN::Net::trainCycledouble trainCycle(Minimizer &minimizer, std::vector< double > &weights, Iterator itPatternBegin, Iterator itPatternEnd, Settings &settings, DropContainer &dropContainer)executes one training cycleDefinition NeuralNet.icc:939; TMVA::DNN::Net::fIPyCurrentIterUInt_t * fIPyCurrentIterDefinition NeuralNet.h:1278; TMVA::DNN::Net::operator()double operator()(PassThrough &settingsAndBatch, const Weights &weights) constexecute computation of the DNN for one mini-batch (used by the minimizer); no computation of gradient...Definition NeuralNet.icc:1070; TMVA::DNN::Net::dropOutWeightFactorvoid dropOutWeightFactor(WeightsType &weights, const DropProbabilities &drops, bool inverse=false)set the drop out configurationDefinition NeuralNet.icc:652; TMVA::DNN::Net::fillDropContainervoid fillDropCon",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:65630,Modifiability,config,configurationDefinition,65630,"::Net::forward_backwarddouble forward_backward(LayerContainer &layers, PassThrough &settingsAndBatch, ItWeight itWeightBegin, ItWeight itWeightEnd, ItGradient itGradientBegin, ItGradient itGradientEnd, size_t trainFromLayer, OutContainer &outputContainer, bool fetchOutput) constmain NN computation functionDefinition NeuralNet.icc:1405; TMVA::DNN::Net::trainCycledouble trainCycle(Minimizer &minimizer, std::vector< double > &weights, Iterator itPatternBegin, Iterator itPatternEnd, Settings &settings, DropContainer &dropContainer)executes one training cycleDefinition NeuralNet.icc:939; TMVA::DNN::Net::fIPyCurrentIterUInt_t * fIPyCurrentIterDefinition NeuralNet.h:1278; TMVA::DNN::Net::operator()double operator()(PassThrough &settingsAndBatch, const Weights &weights) constexecute computation of the DNN for one mini-batch (used by the minimizer); no computation of gradient...Definition NeuralNet.icc:1070; TMVA::DNN::Net::dropOutWeightFactorvoid dropOutWeightFactor(WeightsType &weights, const DropProbabilities &drops, bool inverse=false)set the drop out configurationDefinition NeuralNet.icc:652; TMVA::DNN::Net::fillDropContainervoid fillDropContainer(DropContainer &dropContainer, double dropFraction, size_t numNodes) constprepare the drop-out-container (select the nodes which are to be dropped out)Definition NeuralNet.cxx:572; TMVA::DNN::Net::numWeightssize_t numWeights(size_t trainingStartLayer=0) constreturns the number of weights in this netDefinition NeuralNet.cxx:540; TMVA::DNN::Net::fInteractiveIPythonInteractive * fInteractiveDefinition NeuralNet.h:1276; TMVA::DNN::Net::computeErrorstd::tuple< double, double > computeError(const Settings &settings, std::vector< LayerData > &lastLayerData, Batch &batch, ItWeight itWeightBegin, ItWeight itWeightEnd) constDefinition NeuralNet.icc:1321; TMVA::DNN::Net::forwardPatternvoid forwardPattern(const LayerContainer &_layers, std::vector< LayerData > &layerData) constDefinition NeuralNet.icc:1221; TMVA::DNN::Net::backPropagatevoi",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:78023,Modifiability,variab,variable,78023,"OFTMAX@ SOFTMAX; TMVA::DNN::ModeOutputValues::DIRECT@ DIRECT; TMVA::DNN::ModeOutputValues::SIGMOID@ SIGMOID; TMVA::DNN::SoftSignstd::shared_ptr< std::function< double(double)> > SoftSignDefinition NeuralNet.cxx:32; TMVA::DNN::InvSoftPlusstd::shared_ptr< std::function< double(double)> > InvSoftPlusDefinition NeuralNet.cxx:19; TMVA::DNN::ReLUstd::shared_ptr< std::function< double(double)> > ReLUDefinition NeuralNet.cxx:25; TMVA::DNN::computeRegularizationdouble computeRegularization(double weight, const double &factorWeightDecay)compute the regularization (L1, L2)Definition NeuralNet.icc:209; TMVA::DNN::applyWeightsvoid applyWeights(ItSource itSourceBegin, ItSource itSourceEnd, ItWeight itWeight, ItTarget itTargetBegin, ItTarget itTargetEnd); TMVA::DNN::pass_through_typestd::tuple< Settings &, Batch &, DropContainer & > pass_through_typeDefinition NeuralNet.h:1294; TMVA::DNN::isFlagSetbool isFlagSet(T flag, T value)Definition NeuralNet.h:212; TMVA::DNN::InvTanhShiftstd::shared_ptr< std::function< double(double)> > InvTanhShiftDefinition NeuralNet.cxx:23; TMVA::DNN::updatevoid update(ItSource itSource, ItSource itSourceEnd, ItDelta itTargetDeltaBegin, ItDelta itTargetDeltaEnd, ItTargetGradient itTargetGradientBegin, ItGradient itGradient)update the gradientsDefinition NeuralNet.icc:183; TMVA::DNN::DropContainerstd::vector< char > DropContainerDefinition NeuralNet.h:227; TMVA::DNN::applyWeightsBackwardsvoid applyWeightsBackwards(ItSource itCurrBegin, ItSource itCurrEnd, ItWeight itWeight, ItPrev itPrevBegin, ItPrev itPrevEnd); TMVA::DNN::InvSymmReLUstd::shared_ptr< std::function< double(double)> > InvSymmReLUDefinition NeuralNet.cxx:21; TMVA::DNN::InvLinearstd::shared_ptr< std::function< double(double)> > InvLinearDefinition NeuralNet.cxx:16; TMVAcreate variable transformationsDefinition GeneticMinimizer.h:22; outputstatic void output(). tmvatmvaincTMVANeuralNet.icc. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:40:58 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:11429,Testability,assert,assert,11429,"40 });; 341 m_prevGradients.clear ();; 342 }; 343 else; 344 {; 345 auto itW = std::begin (weights);; 346 std::for_each (std::begin (m_localGradients), std::end (m_localGradients), [&itW](double& g); 347 {; 348 *itW += g;; 349 ++itW;; 350 });; 351 }; 352 ; 353 ++currentRepetition;; 354 }; 355 return E;; 356 }; 357 ; 358 ; 359 ; 360 ; 361 ; 362 ; 363 ; 364 ; 365 ; 366 ; 367 ; 368 ; 369 ; 370 ; 371 ; 372 ; 373 ; 374 ; 375 ; 376 ; 377/*! \brief sum of squares error function; 378 *; 379 *; 380 */; 381 template <typename ItOutput, typename ItTruth, typename ItDelta, typename InvFnc>; 382 double sumOfSquares (ItOutput itOutputBegin, ItOutput itOutputEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, InvFnc invFnc, double patternWeight); 383 {; 384 double errorSum = 0.0;; 385 ; 386 // output - truth; 387 ItTruth itTruth = itTruthBegin;; 388 bool hasDeltas = (itDelta != itDeltaEnd);; 389 for (ItOutput itOutput = itOutputBegin; itOutput != itOutputEnd; ++itOutput, ++itTruth); 390 {; 391// assert (itTruth != itTruthEnd);; 392 double output = (*itOutput);; 393 double error = output - (*itTruth);; 394 if (hasDeltas); 395 {; 396 (*itDelta) = (*invFnc.get ()) (output) * error * patternWeight;; 397 ++itDelta;; 398 }; 399 errorSum += error*error * patternWeight;; 400 }; 401 ; 402 return 0.5*errorSum;; 403 }; 404 ; 405 ; 406 ; 407/*! \brief cross entropy error function; 408 *; 409 *; 410 */; 411 template <typename ItProbability, typename ItTruth, typename ItDelta, typename ItInvActFnc>; 412 double crossEntropy (ItProbability itProbabilityBegin, ItProbability itProbabilityEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc /*itInvActFnc*/, double patternWeight); 413 {; 414 bool hasDeltas = (itDelta != itDeltaEnd);; 415 ; 416 double errorSum = 0.0;; 417 for (ItProbability itProbability = itProbabilityBegin; itProbability != itProbabilityEnd; ++itProbability); 418 {; 419 double probability = *itProbabil",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:12843,Testability,log,log,12843,"turn 0.5*errorSum;; 403 }; 404 ; 405 ; 406 ; 407/*! \brief cross entropy error function; 408 *; 409 *; 410 */; 411 template <typename ItProbability, typename ItTruth, typename ItDelta, typename ItInvActFnc>; 412 double crossEntropy (ItProbability itProbabilityBegin, ItProbability itProbabilityEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc /*itInvActFnc*/, double patternWeight); 413 {; 414 bool hasDeltas = (itDelta != itDeltaEnd);; 415 ; 416 double errorSum = 0.0;; 417 for (ItProbability itProbability = itProbabilityBegin; itProbability != itProbabilityEnd; ++itProbability); 418 {; 419 double probability = *itProbability;; 420 double truth = *itTruthBegin;; 421 /* truth = truth < 0.1 ? 0.1 : truth; */; 422 /* truth = truth > 0.9 ? 0.9 : truth; */; 423 truth = truth < 0.5 ? 0.1 : 0.9;; 424 if (hasDeltas); 425 {; 426 double delta = probability - truth;; 427 (*itDelta) = delta*patternWeight;; 428// (*itDelta) = (*itInvActFnc)(probability) * delta * patternWeight;; 429 ++itDelta;; 430 }; 431 double error (0);; 432 if (probability == 0) // protection against log (0); 433 {; 434 if (truth >= 0.5); 435 error += 1.0;; 436 }; 437 else if (probability == 1); 438 {; 439 if (truth < 0.5); 440 error += 1.0;; 441 }; 442 else; 443 error += - (truth * log (probability) + (1.0-truth) * log (1.0-probability)); // cross entropy function; 444 errorSum += error * patternWeight;; 445 ; 446 }; 447 return errorSum;; 448 }; 449 ; 450 ; 451 ; 452 ; 453/*! \brief soft-max-cross-entropy error function (for mutual exclusive cross-entropy); 454 *; 455 *; 456 */; 457 template <typename ItOutput, typename ItTruth, typename ItDelta, typename ItInvActFnc>; 458 double softMaxCrossEntropy (ItOutput itProbabilityBegin, ItOutput itProbabilityEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc /*itInvActFnc*/, double patternWeight); 459 {; 460 double errorSum = 0.0;; 461 ; 462 bool hasDeltas = (itDelta != i",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:13029,Testability,log,log,13029,", ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc /*itInvActFnc*/, double patternWeight); 413 {; 414 bool hasDeltas = (itDelta != itDeltaEnd);; 415 ; 416 double errorSum = 0.0;; 417 for (ItProbability itProbability = itProbabilityBegin; itProbability != itProbabilityEnd; ++itProbability); 418 {; 419 double probability = *itProbability;; 420 double truth = *itTruthBegin;; 421 /* truth = truth < 0.1 ? 0.1 : truth; */; 422 /* truth = truth > 0.9 ? 0.9 : truth; */; 423 truth = truth < 0.5 ? 0.1 : 0.9;; 424 if (hasDeltas); 425 {; 426 double delta = probability - truth;; 427 (*itDelta) = delta*patternWeight;; 428// (*itDelta) = (*itInvActFnc)(probability) * delta * patternWeight;; 429 ++itDelta;; 430 }; 431 double error (0);; 432 if (probability == 0) // protection against log (0); 433 {; 434 if (truth >= 0.5); 435 error += 1.0;; 436 }; 437 else if (probability == 1); 438 {; 439 if (truth < 0.5); 440 error += 1.0;; 441 }; 442 else; 443 error += - (truth * log (probability) + (1.0-truth) * log (1.0-probability)); // cross entropy function; 444 errorSum += error * patternWeight;; 445 ; 446 }; 447 return errorSum;; 448 }; 449 ; 450 ; 451 ; 452 ; 453/*! \brief soft-max-cross-entropy error function (for mutual exclusive cross-entropy); 454 *; 455 *; 456 */; 457 template <typename ItOutput, typename ItTruth, typename ItDelta, typename ItInvActFnc>; 458 double softMaxCrossEntropy (ItOutput itProbabilityBegin, ItOutput itProbabilityEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc /*itInvActFnc*/, double patternWeight); 459 {; 460 double errorSum = 0.0;; 461 ; 462 bool hasDeltas = (itDelta != itDeltaEnd);; 463 // output - truth; 464 ItTruth itTruth = itTruthBegin;; 465 for (auto itProbability = itProbabilityBegin; itProbability != itProbabilityEnd; ++itProbability, ++itTruth); 466 {; 467// assert (itTruth != itTruthEnd);; 468 double probability = (*itProbability);; 469 double truth = ",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:13063,Testability,log,log,13063,"d*/, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc /*itInvActFnc*/, double patternWeight); 413 {; 414 bool hasDeltas = (itDelta != itDeltaEnd);; 415 ; 416 double errorSum = 0.0;; 417 for (ItProbability itProbability = itProbabilityBegin; itProbability != itProbabilityEnd; ++itProbability); 418 {; 419 double probability = *itProbability;; 420 double truth = *itTruthBegin;; 421 /* truth = truth < 0.1 ? 0.1 : truth; */; 422 /* truth = truth > 0.9 ? 0.9 : truth; */; 423 truth = truth < 0.5 ? 0.1 : 0.9;; 424 if (hasDeltas); 425 {; 426 double delta = probability - truth;; 427 (*itDelta) = delta*patternWeight;; 428// (*itDelta) = (*itInvActFnc)(probability) * delta * patternWeight;; 429 ++itDelta;; 430 }; 431 double error (0);; 432 if (probability == 0) // protection against log (0); 433 {; 434 if (truth >= 0.5); 435 error += 1.0;; 436 }; 437 else if (probability == 1); 438 {; 439 if (truth < 0.5); 440 error += 1.0;; 441 }; 442 else; 443 error += - (truth * log (probability) + (1.0-truth) * log (1.0-probability)); // cross entropy function; 444 errorSum += error * patternWeight;; 445 ; 446 }; 447 return errorSum;; 448 }; 449 ; 450 ; 451 ; 452 ; 453/*! \brief soft-max-cross-entropy error function (for mutual exclusive cross-entropy); 454 *; 455 *; 456 */; 457 template <typename ItOutput, typename ItTruth, typename ItDelta, typename ItInvActFnc>; 458 double softMaxCrossEntropy (ItOutput itProbabilityBegin, ItOutput itProbabilityEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc /*itInvActFnc*/, double patternWeight); 459 {; 460 double errorSum = 0.0;; 461 ; 462 bool hasDeltas = (itDelta != itDeltaEnd);; 463 // output - truth; 464 ItTruth itTruth = itTruthBegin;; 465 for (auto itProbability = itProbabilityBegin; itProbability != itProbabilityEnd; ++itProbability, ++itTruth); 466 {; 467// assert (itTruth != itTruthEnd);; 468 double probability = (*itProbability);; 469 double truth = (*itTruth);; 470 if (hasDeltas); 471 {; 472",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:13922,Testability,assert,assert,13922,"456 */; 457 template <typename ItOutput, typename ItTruth, typename ItDelta, typename ItInvActFnc>; 458 double softMaxCrossEntropy (ItOutput itProbabilityBegin, ItOutput itProbabilityEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc /*itInvActFnc*/, double patternWeight); 459 {; 460 double errorSum = 0.0;; 461 ; 462 bool hasDeltas = (itDelta != itDeltaEnd);; 463 // output - truth; 464 ItTruth itTruth = itTruthBegin;; 465 for (auto itProbability = itProbabilityBegin; itProbability != itProbabilityEnd; ++itProbability, ++itTruth); 466 {; 467// assert (itTruth != itTruthEnd);; 468 double probability = (*itProbability);; 469 double truth = (*itTruth);; 470 if (hasDeltas); 471 {; 472 (*itDelta) = probability - truth;; 473// (*itDelta) = (*itInvActFnc)(sm) * delta * patternWeight;; 474 ++itDelta; //++itInvActFnc;; 475 }; 476 double error (0);; 477 ; 478 error += truth * log (probability);; 479 errorSum += error;; 480 }; 481 ; 482 return -errorSum * patternWeight;; 483 }; 484 ; 485 ; 486 ; 487 ; 488 ; 489 ; 490 ; 491 ; 492 ; 493/*! \brief compute the weight decay for regularization (L1 or L2); 494 *; 495 *; 496 */; 497 template <typename ItWeight>; 498 double weightDecay (double error, ItWeight itWeight, ItWeight itWeightEnd, double factorWeightDecay, EnumRegularization eRegularization); 499 {; 500 if (eRegularization == EnumRegularization::L1); 501 {; 502 // weight decay (regularization); 503 double w = 0;; 504 size_t n = 0;; 505 for (; itWeight != itWeightEnd; ++itWeight, ++n); 506 {; 507 double weight = (*itWeight);; 508 w += std::fabs (weight);; 509 }; 510 return error + 0.5 * w * factorWeightDecay / n;; 511 }; 512 else if (eRegularization == EnumRegularization::L2); 513 {; 514 // weight decay (regularization); 515 double w = 0;; 516 size_t n = 0;; 517 for (; itWeight != itWeightEnd; ++itWeight, ++n); 518 {; 519 double weight = (*itWeight);; 520 w += weight*weight;; 521 }; 522 return error + 0.5 * w * factorWeightDecay /",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:14251,Testability,log,log,14251,"456 */; 457 template <typename ItOutput, typename ItTruth, typename ItDelta, typename ItInvActFnc>; 458 double softMaxCrossEntropy (ItOutput itProbabilityBegin, ItOutput itProbabilityEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, ItInvActFnc /*itInvActFnc*/, double patternWeight); 459 {; 460 double errorSum = 0.0;; 461 ; 462 bool hasDeltas = (itDelta != itDeltaEnd);; 463 // output - truth; 464 ItTruth itTruth = itTruthBegin;; 465 for (auto itProbability = itProbabilityBegin; itProbability != itProbabilityEnd; ++itProbability, ++itTruth); 466 {; 467// assert (itTruth != itTruthEnd);; 468 double probability = (*itProbability);; 469 double truth = (*itTruth);; 470 if (hasDeltas); 471 {; 472 (*itDelta) = probability - truth;; 473// (*itDelta) = (*itInvActFnc)(sm) * delta * patternWeight;; 474 ++itDelta; //++itInvActFnc;; 475 }; 476 double error (0);; 477 ; 478 error += truth * log (probability);; 479 errorSum += error;; 480 }; 481 ; 482 return -errorSum * patternWeight;; 483 }; 484 ; 485 ; 486 ; 487 ; 488 ; 489 ; 490 ; 491 ; 492 ; 493/*! \brief compute the weight decay for regularization (L1 or L2); 494 *; 495 *; 496 */; 497 template <typename ItWeight>; 498 double weightDecay (double error, ItWeight itWeight, ItWeight itWeightEnd, double factorWeightDecay, EnumRegularization eRegularization); 499 {; 500 if (eRegularization == EnumRegularization::L1); 501 {; 502 // weight decay (regularization); 503 double w = 0;; 504 size_t n = 0;; 505 for (; itWeight != itWeightEnd; ++itWeight, ++n); 506 {; 507 double weight = (*itWeight);; 508 w += std::fabs (weight);; 509 }; 510 return error + 0.5 * w * factorWeightDecay / n;; 511 }; 512 else if (eRegularization == EnumRegularization::L2); 513 {; 514 // weight decay (regularization); 515 double w = 0;; 516 size_t n = 0;; 517 for (; itWeight != itWeightEnd; ++itWeight, ++n); 518 {; 519 double weight = (*itWeight);; 520 w += weight*weight;; 521 }; 522 return error + 0.5 * w * factorWeightDecay /",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:19069,Testability,test,test,19069,"erData.deltasEnd (),; 615 currLayerData.valueGradientsBegin (), currLayerData.gradientsBegin (),; 616 currLayerData.weightsBegin (), factorWeightDecay);; 617 }; 618 else; 619 {; 620 update (prevLayerData.valuesBegin (), prevLayerData.valuesEnd (),; 621 currLayerData.deltasBegin (), currLayerData.deltasEnd (),; 622 currLayerData.valueGradientsBegin (), currLayerData.gradientsBegin ());; 623 }; 624 ; 625 else; 626 { // no weight regularization; 627 update (prevLayerData.valuesBegin (), prevLayerData.valuesEnd (),; 628 currLayerData.deltasBegin (), currLayerData.deltasEnd (),; 629 currLayerData.valueGradientsBegin (), currLayerData.gradientsBegin ());; 630 }; 631 }; 632 ; 633 ; 634 ; 635 ; 636 ; 637 ; 638 ; 639 ; 640 ; 641 ; 642 ; 643 ; 644/*! \brief compute the drop-out-weight factor; 645 *; 646 * when using drop-out a fraction of the nodes is turned off at each cycle of the computation; 647 * once all nodes are turned on again (for instances when the test samples are evaluated),; 648 * the weights have to be adjusted to account for the different number of active nodes; 649 * this function computes the factor and applies it to the weights; 650 */; 651 template <typename WeightsType, typename DropProbabilities>; 652 void Net::dropOutWeightFactor (WeightsType& weights,; 653 const DropProbabilities& drops,; 654 bool inverse); 655 {; 656 if (drops.empty () || weights.empty ()); 657 return;; 658 ; 659 auto itWeight = std::begin (weights);; 660 auto itWeightEnd = std::end (weights);; 661 auto itDrop = std::begin (drops);; 662 auto itDropEnd = std::end (drops);; 663 size_t numNodesPrev = inputSize ();; 664 double dropFractionPrev = *itDrop;; 665 ++itDrop;; 666 ; 667 for (auto& layer : layers ()); 668 {; 669 if (itDrop == itDropEnd); 670 break;; 671 ; 672 size_t _numNodes = layer.numNodes ();; 673 ; 674 double dropFraction = *itDrop;; 675 double pPrev = 1.0 - dropFractionPrev;; 676 double p = 1.0 - dropFraction;; 677 p *= pPrev;; 678 ; 679 if (inverse); 680 {; 681 p = 1.0/p;; ",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:20676,Testability,test,testPattern,20676,"5 {; 656 if (drops.empty () || weights.empty ()); 657 return;; 658 ; 659 auto itWeight = std::begin (weights);; 660 auto itWeightEnd = std::end (weights);; 661 auto itDrop = std::begin (drops);; 662 auto itDropEnd = std::end (drops);; 663 size_t numNodesPrev = inputSize ();; 664 double dropFractionPrev = *itDrop;; 665 ++itDrop;; 666 ; 667 for (auto& layer : layers ()); 668 {; 669 if (itDrop == itDropEnd); 670 break;; 671 ; 672 size_t _numNodes = layer.numNodes ();; 673 ; 674 double dropFraction = *itDrop;; 675 double pPrev = 1.0 - dropFractionPrev;; 676 double p = 1.0 - dropFraction;; 677 p *= pPrev;; 678 ; 679 if (inverse); 680 {; 681 p = 1.0/p;; 682 }; 683 size_t _numWeights = layer.numWeights (numNodesPrev);; 684 for (size_t iWeight = 0; iWeight < _numWeights; ++iWeight); 685 {; 686 if (itWeight == itWeightEnd); 687 break;; 688 ; 689 *itWeight *= p;; 690 ++itWeight;; 691 }; 692 numNodesPrev = _numNodes;; 693 dropFractionPrev = dropFraction;; 694 ++itDrop;; 695 }; 696 }; 697 ; 698 ; 699 ; 700 ; 701 ; 702 ; 703/*! \brief execute the training until convergence emerges; 704 *; 705 * \param weights the container with the weights (synapses); 706 * \param trainPattern the pattern for the training; 707 * \param testPattern the pattern for the testing; 708 * \param minimizer the minimizer (e.g. steepest gradient descent) to be used; 709 * \param settings the settings for the training (e.g. multithreading or not, regularization etc.); 710 */; 711 template <typename Minimizer>; 712 double Net::train (std::vector<double>& weights,; 713 std::vector<Pattern>& trainPattern,; 714 const std::vector<Pattern>& testPattern,; 715 Minimizer& minimizer,; 716 Settings& settings); 717 {; 718// std::cout << ""START TRAINING"" << std::endl;; 719 settings.startTrainCycle ();; 720 ; 721 // JsMVA progress bar maximum (100%); 722 if (fIPyMaxIter) *fIPyMaxIter = 100;; 723 ; 724 settings.pads (4);; 725 settings.create (""trainErrors"", 100, 0, 100, 100, 0,1);; 726 settings.create (""testErrors"", 100, ",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:20708,Testability,test,testing,20708,"5 {; 656 if (drops.empty () || weights.empty ()); 657 return;; 658 ; 659 auto itWeight = std::begin (weights);; 660 auto itWeightEnd = std::end (weights);; 661 auto itDrop = std::begin (drops);; 662 auto itDropEnd = std::end (drops);; 663 size_t numNodesPrev = inputSize ();; 664 double dropFractionPrev = *itDrop;; 665 ++itDrop;; 666 ; 667 for (auto& layer : layers ()); 668 {; 669 if (itDrop == itDropEnd); 670 break;; 671 ; 672 size_t _numNodes = layer.numNodes ();; 673 ; 674 double dropFraction = *itDrop;; 675 double pPrev = 1.0 - dropFractionPrev;; 676 double p = 1.0 - dropFraction;; 677 p *= pPrev;; 678 ; 679 if (inverse); 680 {; 681 p = 1.0/p;; 682 }; 683 size_t _numWeights = layer.numWeights (numNodesPrev);; 684 for (size_t iWeight = 0; iWeight < _numWeights; ++iWeight); 685 {; 686 if (itWeight == itWeightEnd); 687 break;; 688 ; 689 *itWeight *= p;; 690 ++itWeight;; 691 }; 692 numNodesPrev = _numNodes;; 693 dropFractionPrev = dropFraction;; 694 ++itDrop;; 695 }; 696 }; 697 ; 698 ; 699 ; 700 ; 701 ; 702 ; 703/*! \brief execute the training until convergence emerges; 704 *; 705 * \param weights the container with the weights (synapses); 706 * \param trainPattern the pattern for the training; 707 * \param testPattern the pattern for the testing; 708 * \param minimizer the minimizer (e.g. steepest gradient descent) to be used; 709 * \param settings the settings for the training (e.g. multithreading or not, regularization etc.); 710 */; 711 template <typename Minimizer>; 712 double Net::train (std::vector<double>& weights,; 713 std::vector<Pattern>& trainPattern,; 714 const std::vector<Pattern>& testPattern,; 715 Minimizer& minimizer,; 716 Settings& settings); 717 {; 718// std::cout << ""START TRAINING"" << std::endl;; 719 settings.startTrainCycle ();; 720 ; 721 // JsMVA progress bar maximum (100%); 722 if (fIPyMaxIter) *fIPyMaxIter = 100;; 723 ; 724 settings.pads (4);; 725 settings.create (""trainErrors"", 100, 0, 100, 100, 0,1);; 726 settings.create (""testErrors"", 100, ",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:21072,Testability,test,testPattern,21072,"ev;; 678 ; 679 if (inverse); 680 {; 681 p = 1.0/p;; 682 }; 683 size_t _numWeights = layer.numWeights (numNodesPrev);; 684 for (size_t iWeight = 0; iWeight < _numWeights; ++iWeight); 685 {; 686 if (itWeight == itWeightEnd); 687 break;; 688 ; 689 *itWeight *= p;; 690 ++itWeight;; 691 }; 692 numNodesPrev = _numNodes;; 693 dropFractionPrev = dropFraction;; 694 ++itDrop;; 695 }; 696 }; 697 ; 698 ; 699 ; 700 ; 701 ; 702 ; 703/*! \brief execute the training until convergence emerges; 704 *; 705 * \param weights the container with the weights (synapses); 706 * \param trainPattern the pattern for the training; 707 * \param testPattern the pattern for the testing; 708 * \param minimizer the minimizer (e.g. steepest gradient descent) to be used; 709 * \param settings the settings for the training (e.g. multithreading or not, regularization etc.); 710 */; 711 template <typename Minimizer>; 712 double Net::train (std::vector<double>& weights,; 713 std::vector<Pattern>& trainPattern,; 714 const std::vector<Pattern>& testPattern,; 715 Minimizer& minimizer,; 716 Settings& settings); 717 {; 718// std::cout << ""START TRAINING"" << std::endl;; 719 settings.startTrainCycle ();; 720 ; 721 // JsMVA progress bar maximum (100%); 722 if (fIPyMaxIter) *fIPyMaxIter = 100;; 723 ; 724 settings.pads (4);; 725 settings.create (""trainErrors"", 100, 0, 100, 100, 0,1);; 726 settings.create (""testErrors"", 100, 0, 100, 100, 0,1);; 727 ; 728 size_t cycleCount = 0;; 729 size_t testCycleCount = 0;; 730 double testError = 1e20;; 731 double trainError = 1e20;; 732 size_t dropOutChangeCount = 0;; 733 ; 734 DropContainer dropContainer;; 735 DropContainer dropContainerTest;; 736 const std::vector<double>& dropFractions = settings.dropFractions ();; 737 bool isWeightsForDrop = false;; 738 ; 739 ; 740 // until convergence; 741 do; 742 {; 743 ++cycleCount;; 744 ; 745 // if dropOut enabled; 746 size_t dropIndex = 0;; 747 if (!dropFractions.empty () && dropOutChangeCount % settings.dropRepetitions () == 0); 748 {; 7",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:21433,Testability,test,testErrors,21433,"synapses); 706 * \param trainPattern the pattern for the training; 707 * \param testPattern the pattern for the testing; 708 * \param minimizer the minimizer (e.g. steepest gradient descent) to be used; 709 * \param settings the settings for the training (e.g. multithreading or not, regularization etc.); 710 */; 711 template <typename Minimizer>; 712 double Net::train (std::vector<double>& weights,; 713 std::vector<Pattern>& trainPattern,; 714 const std::vector<Pattern>& testPattern,; 715 Minimizer& minimizer,; 716 Settings& settings); 717 {; 718// std::cout << ""START TRAINING"" << std::endl;; 719 settings.startTrainCycle ();; 720 ; 721 // JsMVA progress bar maximum (100%); 722 if (fIPyMaxIter) *fIPyMaxIter = 100;; 723 ; 724 settings.pads (4);; 725 settings.create (""trainErrors"", 100, 0, 100, 100, 0,1);; 726 settings.create (""testErrors"", 100, 0, 100, 100, 0,1);; 727 ; 728 size_t cycleCount = 0;; 729 size_t testCycleCount = 0;; 730 double testError = 1e20;; 731 double trainError = 1e20;; 732 size_t dropOutChangeCount = 0;; 733 ; 734 DropContainer dropContainer;; 735 DropContainer dropContainerTest;; 736 const std::vector<double>& dropFractions = settings.dropFractions ();; 737 bool isWeightsForDrop = false;; 738 ; 739 ; 740 // until convergence; 741 do; 742 {; 743 ++cycleCount;; 744 ; 745 // if dropOut enabled; 746 size_t dropIndex = 0;; 747 if (!dropFractions.empty () && dropOutChangeCount % settings.dropRepetitions () == 0); 748 {; 749 // fill the dropOut-container; 750 dropContainer.clear ();; 751 size_t _numNodes = inputSize ();; 752 double dropFraction = 0.0;; 753 dropFraction = dropFractions.at (dropIndex);; 754 ++dropIndex;; 755 fillDropContainer (dropContainer, dropFraction, _numNodes);; 756 for (auto itLayer = begin (m_layers), itLayerEnd = end (m_layers); itLayer != itLayerEnd; ++itLayer, ++dropIndex); 757 {; 758 auto& layer = *itLayer;; 759 _numNodes = layer.numNodes ();; 760 // how many nodes have to be dropped; 761 dropFraction = 0.0;; 762 if (dropFracti",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:21516,Testability,test,testCycleCount,21516,"synapses); 706 * \param trainPattern the pattern for the training; 707 * \param testPattern the pattern for the testing; 708 * \param minimizer the minimizer (e.g. steepest gradient descent) to be used; 709 * \param settings the settings for the training (e.g. multithreading or not, regularization etc.); 710 */; 711 template <typename Minimizer>; 712 double Net::train (std::vector<double>& weights,; 713 std::vector<Pattern>& trainPattern,; 714 const std::vector<Pattern>& testPattern,; 715 Minimizer& minimizer,; 716 Settings& settings); 717 {; 718// std::cout << ""START TRAINING"" << std::endl;; 719 settings.startTrainCycle ();; 720 ; 721 // JsMVA progress bar maximum (100%); 722 if (fIPyMaxIter) *fIPyMaxIter = 100;; 723 ; 724 settings.pads (4);; 725 settings.create (""trainErrors"", 100, 0, 100, 100, 0,1);; 726 settings.create (""testErrors"", 100, 0, 100, 100, 0,1);; 727 ; 728 size_t cycleCount = 0;; 729 size_t testCycleCount = 0;; 730 double testError = 1e20;; 731 double trainError = 1e20;; 732 size_t dropOutChangeCount = 0;; 733 ; 734 DropContainer dropContainer;; 735 DropContainer dropContainerTest;; 736 const std::vector<double>& dropFractions = settings.dropFractions ();; 737 bool isWeightsForDrop = false;; 738 ; 739 ; 740 // until convergence; 741 do; 742 {; 743 ++cycleCount;; 744 ; 745 // if dropOut enabled; 746 size_t dropIndex = 0;; 747 if (!dropFractions.empty () && dropOutChangeCount % settings.dropRepetitions () == 0); 748 {; 749 // fill the dropOut-container; 750 dropContainer.clear ();; 751 size_t _numNodes = inputSize ();; 752 double dropFraction = 0.0;; 753 dropFraction = dropFractions.at (dropIndex);; 754 ++dropIndex;; 755 fillDropContainer (dropContainer, dropFraction, _numNodes);; 756 for (auto itLayer = begin (m_layers), itLayerEnd = end (m_layers); itLayer != itLayerEnd; ++itLayer, ++dropIndex); 757 {; 758 auto& layer = *itLayer;; 759 _numNodes = layer.numNodes ();; 760 // how many nodes have to be dropped; 761 dropFraction = 0.0;; 762 if (dropFracti",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:21548,Testability,test,testError,21548,"synapses); 706 * \param trainPattern the pattern for the training; 707 * \param testPattern the pattern for the testing; 708 * \param minimizer the minimizer (e.g. steepest gradient descent) to be used; 709 * \param settings the settings for the training (e.g. multithreading or not, regularization etc.); 710 */; 711 template <typename Minimizer>; 712 double Net::train (std::vector<double>& weights,; 713 std::vector<Pattern>& trainPattern,; 714 const std::vector<Pattern>& testPattern,; 715 Minimizer& minimizer,; 716 Settings& settings); 717 {; 718// std::cout << ""START TRAINING"" << std::endl;; 719 settings.startTrainCycle ();; 720 ; 721 // JsMVA progress bar maximum (100%); 722 if (fIPyMaxIter) *fIPyMaxIter = 100;; 723 ; 724 settings.pads (4);; 725 settings.create (""trainErrors"", 100, 0, 100, 100, 0,1);; 726 settings.create (""testErrors"", 100, 0, 100, 100, 0,1);; 727 ; 728 size_t cycleCount = 0;; 729 size_t testCycleCount = 0;; 730 double testError = 1e20;; 731 double trainError = 1e20;; 732 size_t dropOutChangeCount = 0;; 733 ; 734 DropContainer dropContainer;; 735 DropContainer dropContainerTest;; 736 const std::vector<double>& dropFractions = settings.dropFractions ();; 737 bool isWeightsForDrop = false;; 738 ; 739 ; 740 // until convergence; 741 do; 742 {; 743 ++cycleCount;; 744 ; 745 // if dropOut enabled; 746 size_t dropIndex = 0;; 747 if (!dropFractions.empty () && dropOutChangeCount % settings.dropRepetitions () == 0); 748 {; 749 // fill the dropOut-container; 750 dropContainer.clear ();; 751 size_t _numNodes = inputSize ();; 752 double dropFraction = 0.0;; 753 dropFraction = dropFractions.at (dropIndex);; 754 ++dropIndex;; 755 fillDropContainer (dropContainer, dropFraction, _numNodes);; 756 for (auto itLayer = begin (m_layers), itLayerEnd = end (m_layers); itLayer != itLayerEnd; ++itLayer, ++dropIndex); 757 {; 758 auto& layer = *itLayer;; 759 _numNodes = layer.numNodes ();; 760 // how many nodes have to be dropped; 761 dropFraction = 0.0;; 762 if (dropFracti",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:22998,Testability,test,test,22998," {; 743 ++cycleCount;; 744 ; 745 // if dropOut enabled; 746 size_t dropIndex = 0;; 747 if (!dropFractions.empty () && dropOutChangeCount % settings.dropRepetitions () == 0); 748 {; 749 // fill the dropOut-container; 750 dropContainer.clear ();; 751 size_t _numNodes = inputSize ();; 752 double dropFraction = 0.0;; 753 dropFraction = dropFractions.at (dropIndex);; 754 ++dropIndex;; 755 fillDropContainer (dropContainer, dropFraction, _numNodes);; 756 for (auto itLayer = begin (m_layers), itLayerEnd = end (m_layers); itLayer != itLayerEnd; ++itLayer, ++dropIndex); 757 {; 758 auto& layer = *itLayer;; 759 _numNodes = layer.numNodes ();; 760 // how many nodes have to be dropped; 761 dropFraction = 0.0;; 762 if (dropFractions.size () > dropIndex); 763 dropFraction = dropFractions.at (dropIndex);; 764 ; 765 fillDropContainer (dropContainer, dropFraction, _numNodes);; 766 }; 767 isWeightsForDrop = true;; 768 }; 769 ; 770 // execute training cycle; 771 trainError = trainCycle (minimizer, weights, begin (trainPattern), end (trainPattern), settings, dropContainer);; 772 ; 773 ; 774 // ------ check if we have to execute a test ------------------; 775 bool hasConverged = false;; 776 if (testCycleCount % settings.testRepetitions () == 0) // we test only everye ""testRepetitions"" repetition; 777 {; 778 if (isWeightsForDrop); 779 {; 780 dropOutWeightFactor (weights, dropFractions);; 781 isWeightsForDrop = false;; 782 }; 783 ; 784 ; 785 testError = 0;; 786 //double weightSum = 0;; 787 settings.startTestCycle ();; 788 if (settings.useMultithreading ()); 789 {; 790 size_t numThreads = std::thread::hardware_concurrency ();; 791 size_t patternPerThread = testPattern.size () / numThreads;; 792 std::vector<Batch> batches;; 793 auto itPat = testPattern.begin ();; 794 // auto itPatEnd = testPattern.end ();; 795 for (size_t idxThread = 0; idxThread < numThreads-1; ++idxThread); 796 {; 797 batches.push_back (Batch (itPat, itPat + patternPerThread));; 798 itPat += patternPerThread;; 799 }; 800 if",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:23063,Testability,test,testCycleCount,23063," {; 743 ++cycleCount;; 744 ; 745 // if dropOut enabled; 746 size_t dropIndex = 0;; 747 if (!dropFractions.empty () && dropOutChangeCount % settings.dropRepetitions () == 0); 748 {; 749 // fill the dropOut-container; 750 dropContainer.clear ();; 751 size_t _numNodes = inputSize ();; 752 double dropFraction = 0.0;; 753 dropFraction = dropFractions.at (dropIndex);; 754 ++dropIndex;; 755 fillDropContainer (dropContainer, dropFraction, _numNodes);; 756 for (auto itLayer = begin (m_layers), itLayerEnd = end (m_layers); itLayer != itLayerEnd; ++itLayer, ++dropIndex); 757 {; 758 auto& layer = *itLayer;; 759 _numNodes = layer.numNodes ();; 760 // how many nodes have to be dropped; 761 dropFraction = 0.0;; 762 if (dropFractions.size () > dropIndex); 763 dropFraction = dropFractions.at (dropIndex);; 764 ; 765 fillDropContainer (dropContainer, dropFraction, _numNodes);; 766 }; 767 isWeightsForDrop = true;; 768 }; 769 ; 770 // execute training cycle; 771 trainError = trainCycle (minimizer, weights, begin (trainPattern), end (trainPattern), settings, dropContainer);; 772 ; 773 ; 774 // ------ check if we have to execute a test ------------------; 775 bool hasConverged = false;; 776 if (testCycleCount % settings.testRepetitions () == 0) // we test only everye ""testRepetitions"" repetition; 777 {; 778 if (isWeightsForDrop); 779 {; 780 dropOutWeightFactor (weights, dropFractions);; 781 isWeightsForDrop = false;; 782 }; 783 ; 784 ; 785 testError = 0;; 786 //double weightSum = 0;; 787 settings.startTestCycle ();; 788 if (settings.useMultithreading ()); 789 {; 790 size_t numThreads = std::thread::hardware_concurrency ();; 791 size_t patternPerThread = testPattern.size () / numThreads;; 792 std::vector<Batch> batches;; 793 auto itPat = testPattern.begin ();; 794 // auto itPatEnd = testPattern.end ();; 795 for (size_t idxThread = 0; idxThread < numThreads-1; ++idxThread); 796 {; 797 batches.push_back (Batch (itPat, itPat + patternPerThread));; 798 itPat += patternPerThread;; 799 }; 800 if",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:23089,Testability,test,testRepetitions,23089,"dex);; 754 ++dropIndex;; 755 fillDropContainer (dropContainer, dropFraction, _numNodes);; 756 for (auto itLayer = begin (m_layers), itLayerEnd = end (m_layers); itLayer != itLayerEnd; ++itLayer, ++dropIndex); 757 {; 758 auto& layer = *itLayer;; 759 _numNodes = layer.numNodes ();; 760 // how many nodes have to be dropped; 761 dropFraction = 0.0;; 762 if (dropFractions.size () > dropIndex); 763 dropFraction = dropFractions.at (dropIndex);; 764 ; 765 fillDropContainer (dropContainer, dropFraction, _numNodes);; 766 }; 767 isWeightsForDrop = true;; 768 }; 769 ; 770 // execute training cycle; 771 trainError = trainCycle (minimizer, weights, begin (trainPattern), end (trainPattern), settings, dropContainer);; 772 ; 773 ; 774 // ------ check if we have to execute a test ------------------; 775 bool hasConverged = false;; 776 if (testCycleCount % settings.testRepetitions () == 0) // we test only everye ""testRepetitions"" repetition; 777 {; 778 if (isWeightsForDrop); 779 {; 780 dropOutWeightFactor (weights, dropFractions);; 781 isWeightsForDrop = false;; 782 }; 783 ; 784 ; 785 testError = 0;; 786 //double weightSum = 0;; 787 settings.startTestCycle ();; 788 if (settings.useMultithreading ()); 789 {; 790 size_t numThreads = std::thread::hardware_concurrency ();; 791 size_t patternPerThread = testPattern.size () / numThreads;; 792 std::vector<Batch> batches;; 793 auto itPat = testPattern.begin ();; 794 // auto itPatEnd = testPattern.end ();; 795 for (size_t idxThread = 0; idxThread < numThreads-1; ++idxThread); 796 {; 797 batches.push_back (Batch (itPat, itPat + patternPerThread));; 798 itPat += patternPerThread;; 799 }; 800 if (itPat != testPattern.end ()); 801 batches.push_back (Batch (itPat, testPattern.end ()));; 802 ; 803 std::vector<std::future<std::tuple<double,std::vector<double>>>> futures;; 804 for (auto& batch : batches); 805 {; 806 // -------------------- execute each of the batch ranges on a different thread -------------------------------; 807 futures.push_back (; ",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:23120,Testability,test,test,23120,"dex);; 754 ++dropIndex;; 755 fillDropContainer (dropContainer, dropFraction, _numNodes);; 756 for (auto itLayer = begin (m_layers), itLayerEnd = end (m_layers); itLayer != itLayerEnd; ++itLayer, ++dropIndex); 757 {; 758 auto& layer = *itLayer;; 759 _numNodes = layer.numNodes ();; 760 // how many nodes have to be dropped; 761 dropFraction = 0.0;; 762 if (dropFractions.size () > dropIndex); 763 dropFraction = dropFractions.at (dropIndex);; 764 ; 765 fillDropContainer (dropContainer, dropFraction, _numNodes);; 766 }; 767 isWeightsForDrop = true;; 768 }; 769 ; 770 // execute training cycle; 771 trainError = trainCycle (minimizer, weights, begin (trainPattern), end (trainPattern), settings, dropContainer);; 772 ; 773 ; 774 // ------ check if we have to execute a test ------------------; 775 bool hasConverged = false;; 776 if (testCycleCount % settings.testRepetitions () == 0) // we test only everye ""testRepetitions"" repetition; 777 {; 778 if (isWeightsForDrop); 779 {; 780 dropOutWeightFactor (weights, dropFractions);; 781 isWeightsForDrop = false;; 782 }; 783 ; 784 ; 785 testError = 0;; 786 //double weightSum = 0;; 787 settings.startTestCycle ();; 788 if (settings.useMultithreading ()); 789 {; 790 size_t numThreads = std::thread::hardware_concurrency ();; 791 size_t patternPerThread = testPattern.size () / numThreads;; 792 std::vector<Batch> batches;; 793 auto itPat = testPattern.begin ();; 794 // auto itPatEnd = testPattern.end ();; 795 for (size_t idxThread = 0; idxThread < numThreads-1; ++idxThread); 796 {; 797 batches.push_back (Batch (itPat, itPat + patternPerThread));; 798 itPat += patternPerThread;; 799 }; 800 if (itPat != testPattern.end ()); 801 batches.push_back (Batch (itPat, testPattern.end ()));; 802 ; 803 std::vector<std::future<std::tuple<double,std::vector<double>>>> futures;; 804 for (auto& batch : batches); 805 {; 806 // -------------------- execute each of the batch ranges on a different thread -------------------------------; 807 futures.push_back (; ",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:23138,Testability,test,testRepetitions,23138,"dex);; 754 ++dropIndex;; 755 fillDropContainer (dropContainer, dropFraction, _numNodes);; 756 for (auto itLayer = begin (m_layers), itLayerEnd = end (m_layers); itLayer != itLayerEnd; ++itLayer, ++dropIndex); 757 {; 758 auto& layer = *itLayer;; 759 _numNodes = layer.numNodes ();; 760 // how many nodes have to be dropped; 761 dropFraction = 0.0;; 762 if (dropFractions.size () > dropIndex); 763 dropFraction = dropFractions.at (dropIndex);; 764 ; 765 fillDropContainer (dropContainer, dropFraction, _numNodes);; 766 }; 767 isWeightsForDrop = true;; 768 }; 769 ; 770 // execute training cycle; 771 trainError = trainCycle (minimizer, weights, begin (trainPattern), end (trainPattern), settings, dropContainer);; 772 ; 773 ; 774 // ------ check if we have to execute a test ------------------; 775 bool hasConverged = false;; 776 if (testCycleCount % settings.testRepetitions () == 0) // we test only everye ""testRepetitions"" repetition; 777 {; 778 if (isWeightsForDrop); 779 {; 780 dropOutWeightFactor (weights, dropFractions);; 781 isWeightsForDrop = false;; 782 }; 783 ; 784 ; 785 testError = 0;; 786 //double weightSum = 0;; 787 settings.startTestCycle ();; 788 if (settings.useMultithreading ()); 789 {; 790 size_t numThreads = std::thread::hardware_concurrency ();; 791 size_t patternPerThread = testPattern.size () / numThreads;; 792 std::vector<Batch> batches;; 793 auto itPat = testPattern.begin ();; 794 // auto itPatEnd = testPattern.end ();; 795 for (size_t idxThread = 0; idxThread < numThreads-1; ++idxThread); 796 {; 797 batches.push_back (Batch (itPat, itPat + patternPerThread));; 798 itPat += patternPerThread;; 799 }; 800 if (itPat != testPattern.end ()); 801 batches.push_back (Batch (itPat, testPattern.end ()));; 802 ; 803 std::vector<std::future<std::tuple<double,std::vector<double>>>> futures;; 804 for (auto& batch : batches); 805 {; 806 // -------------------- execute each of the batch ranges on a different thread -------------------------------; 807 futures.push_back (; ",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:23313,Testability,test,testError,23313,"dex);; 754 ++dropIndex;; 755 fillDropContainer (dropContainer, dropFraction, _numNodes);; 756 for (auto itLayer = begin (m_layers), itLayerEnd = end (m_layers); itLayer != itLayerEnd; ++itLayer, ++dropIndex); 757 {; 758 auto& layer = *itLayer;; 759 _numNodes = layer.numNodes ();; 760 // how many nodes have to be dropped; 761 dropFraction = 0.0;; 762 if (dropFractions.size () > dropIndex); 763 dropFraction = dropFractions.at (dropIndex);; 764 ; 765 fillDropContainer (dropContainer, dropFraction, _numNodes);; 766 }; 767 isWeightsForDrop = true;; 768 }; 769 ; 770 // execute training cycle; 771 trainError = trainCycle (minimizer, weights, begin (trainPattern), end (trainPattern), settings, dropContainer);; 772 ; 773 ; 774 // ------ check if we have to execute a test ------------------; 775 bool hasConverged = false;; 776 if (testCycleCount % settings.testRepetitions () == 0) // we test only everye ""testRepetitions"" repetition; 777 {; 778 if (isWeightsForDrop); 779 {; 780 dropOutWeightFactor (weights, dropFractions);; 781 isWeightsForDrop = false;; 782 }; 783 ; 784 ; 785 testError = 0;; 786 //double weightSum = 0;; 787 settings.startTestCycle ();; 788 if (settings.useMultithreading ()); 789 {; 790 size_t numThreads = std::thread::hardware_concurrency ();; 791 size_t patternPerThread = testPattern.size () / numThreads;; 792 std::vector<Batch> batches;; 793 auto itPat = testPattern.begin ();; 794 // auto itPatEnd = testPattern.end ();; 795 for (size_t idxThread = 0; idxThread < numThreads-1; ++idxThread); 796 {; 797 batches.push_back (Batch (itPat, itPat + patternPerThread));; 798 itPat += patternPerThread;; 799 }; 800 if (itPat != testPattern.end ()); 801 batches.push_back (Batch (itPat, testPattern.end ()));; 802 ; 803 std::vector<std::future<std::tuple<double,std::vector<double>>>> futures;; 804 for (auto& batch : batches); 805 {; 806 // -------------------- execute each of the batch ranges on a different thread -------------------------------; 807 futures.push_back (; ",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:23531,Testability,test,testPattern,23531,"759 _numNodes = layer.numNodes ();; 760 // how many nodes have to be dropped; 761 dropFraction = 0.0;; 762 if (dropFractions.size () > dropIndex); 763 dropFraction = dropFractions.at (dropIndex);; 764 ; 765 fillDropContainer (dropContainer, dropFraction, _numNodes);; 766 }; 767 isWeightsForDrop = true;; 768 }; 769 ; 770 // execute training cycle; 771 trainError = trainCycle (minimizer, weights, begin (trainPattern), end (trainPattern), settings, dropContainer);; 772 ; 773 ; 774 // ------ check if we have to execute a test ------------------; 775 bool hasConverged = false;; 776 if (testCycleCount % settings.testRepetitions () == 0) // we test only everye ""testRepetitions"" repetition; 777 {; 778 if (isWeightsForDrop); 779 {; 780 dropOutWeightFactor (weights, dropFractions);; 781 isWeightsForDrop = false;; 782 }; 783 ; 784 ; 785 testError = 0;; 786 //double weightSum = 0;; 787 settings.startTestCycle ();; 788 if (settings.useMultithreading ()); 789 {; 790 size_t numThreads = std::thread::hardware_concurrency ();; 791 size_t patternPerThread = testPattern.size () / numThreads;; 792 std::vector<Batch> batches;; 793 auto itPat = testPattern.begin ();; 794 // auto itPatEnd = testPattern.end ();; 795 for (size_t idxThread = 0; idxThread < numThreads-1; ++idxThread); 796 {; 797 batches.push_back (Batch (itPat, itPat + patternPerThread));; 798 itPat += patternPerThread;; 799 }; 800 if (itPat != testPattern.end ()); 801 batches.push_back (Batch (itPat, testPattern.end ()));; 802 ; 803 std::vector<std::future<std::tuple<double,std::vector<double>>>> futures;; 804 for (auto& batch : batches); 805 {; 806 // -------------------- execute each of the batch ranges on a different thread -------------------------------; 807 futures.push_back (; 808 std::async (std::launch::async, [&](); 809 {; 810 std::vector<double> localOutput;; 811 pass_through_type passThrough (settings, batch, dropContainerTest);; 812 double testBatchError = (*this) (passThrough, weights, ModeOutput::FETCH, localOu",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:23616,Testability,test,testPattern,23616,"(dropFractions.size () > dropIndex); 763 dropFraction = dropFractions.at (dropIndex);; 764 ; 765 fillDropContainer (dropContainer, dropFraction, _numNodes);; 766 }; 767 isWeightsForDrop = true;; 768 }; 769 ; 770 // execute training cycle; 771 trainError = trainCycle (minimizer, weights, begin (trainPattern), end (trainPattern), settings, dropContainer);; 772 ; 773 ; 774 // ------ check if we have to execute a test ------------------; 775 bool hasConverged = false;; 776 if (testCycleCount % settings.testRepetitions () == 0) // we test only everye ""testRepetitions"" repetition; 777 {; 778 if (isWeightsForDrop); 779 {; 780 dropOutWeightFactor (weights, dropFractions);; 781 isWeightsForDrop = false;; 782 }; 783 ; 784 ; 785 testError = 0;; 786 //double weightSum = 0;; 787 settings.startTestCycle ();; 788 if (settings.useMultithreading ()); 789 {; 790 size_t numThreads = std::thread::hardware_concurrency ();; 791 size_t patternPerThread = testPattern.size () / numThreads;; 792 std::vector<Batch> batches;; 793 auto itPat = testPattern.begin ();; 794 // auto itPatEnd = testPattern.end ();; 795 for (size_t idxThread = 0; idxThread < numThreads-1; ++idxThread); 796 {; 797 batches.push_back (Batch (itPat, itPat + patternPerThread));; 798 itPat += patternPerThread;; 799 }; 800 if (itPat != testPattern.end ()); 801 batches.push_back (Batch (itPat, testPattern.end ()));; 802 ; 803 std::vector<std::future<std::tuple<double,std::vector<double>>>> futures;; 804 for (auto& batch : batches); 805 {; 806 // -------------------- execute each of the batch ranges on a different thread -------------------------------; 807 futures.push_back (; 808 std::async (std::launch::async, [&](); 809 {; 810 std::vector<double> localOutput;; 811 pass_through_type passThrough (settings, batch, dropContainerTest);; 812 double testBatchError = (*this) (passThrough, weights, ModeOutput::FETCH, localOutput);; 813 return std::make_tuple (testBatchError, localOutput);; 814 }); 815 );; 816 }; 817 ; 818 auto itBat",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:23662,Testability,test,testPattern,23662,"ons.at (dropIndex);; 764 ; 765 fillDropContainer (dropContainer, dropFraction, _numNodes);; 766 }; 767 isWeightsForDrop = true;; 768 }; 769 ; 770 // execute training cycle; 771 trainError = trainCycle (minimizer, weights, begin (trainPattern), end (trainPattern), settings, dropContainer);; 772 ; 773 ; 774 // ------ check if we have to execute a test ------------------; 775 bool hasConverged = false;; 776 if (testCycleCount % settings.testRepetitions () == 0) // we test only everye ""testRepetitions"" repetition; 777 {; 778 if (isWeightsForDrop); 779 {; 780 dropOutWeightFactor (weights, dropFractions);; 781 isWeightsForDrop = false;; 782 }; 783 ; 784 ; 785 testError = 0;; 786 //double weightSum = 0;; 787 settings.startTestCycle ();; 788 if (settings.useMultithreading ()); 789 {; 790 size_t numThreads = std::thread::hardware_concurrency ();; 791 size_t patternPerThread = testPattern.size () / numThreads;; 792 std::vector<Batch> batches;; 793 auto itPat = testPattern.begin ();; 794 // auto itPatEnd = testPattern.end ();; 795 for (size_t idxThread = 0; idxThread < numThreads-1; ++idxThread); 796 {; 797 batches.push_back (Batch (itPat, itPat + patternPerThread));; 798 itPat += patternPerThread;; 799 }; 800 if (itPat != testPattern.end ()); 801 batches.push_back (Batch (itPat, testPattern.end ()));; 802 ; 803 std::vector<std::future<std::tuple<double,std::vector<double>>>> futures;; 804 for (auto& batch : batches); 805 {; 806 // -------------------- execute each of the batch ranges on a different thread -------------------------------; 807 futures.push_back (; 808 std::async (std::launch::async, [&](); 809 {; 810 std::vector<double> localOutput;; 811 pass_through_type passThrough (settings, batch, dropContainerTest);; 812 double testBatchError = (*this) (passThrough, weights, ModeOutput::FETCH, localOutput);; 813 return std::make_tuple (testBatchError, localOutput);; 814 }); 815 );; 816 }; 817 ; 818 auto itBatch = batches.begin ();; 819 for (auto& f : futures); 820 {; 821 s",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:23883,Testability,test,testPattern,23883,"rror = trainCycle (minimizer, weights, begin (trainPattern), end (trainPattern), settings, dropContainer);; 772 ; 773 ; 774 // ------ check if we have to execute a test ------------------; 775 bool hasConverged = false;; 776 if (testCycleCount % settings.testRepetitions () == 0) // we test only everye ""testRepetitions"" repetition; 777 {; 778 if (isWeightsForDrop); 779 {; 780 dropOutWeightFactor (weights, dropFractions);; 781 isWeightsForDrop = false;; 782 }; 783 ; 784 ; 785 testError = 0;; 786 //double weightSum = 0;; 787 settings.startTestCycle ();; 788 if (settings.useMultithreading ()); 789 {; 790 size_t numThreads = std::thread::hardware_concurrency ();; 791 size_t patternPerThread = testPattern.size () / numThreads;; 792 std::vector<Batch> batches;; 793 auto itPat = testPattern.begin ();; 794 // auto itPatEnd = testPattern.end ();; 795 for (size_t idxThread = 0; idxThread < numThreads-1; ++idxThread); 796 {; 797 batches.push_back (Batch (itPat, itPat + patternPerThread));; 798 itPat += patternPerThread;; 799 }; 800 if (itPat != testPattern.end ()); 801 batches.push_back (Batch (itPat, testPattern.end ()));; 802 ; 803 std::vector<std::future<std::tuple<double,std::vector<double>>>> futures;; 804 for (auto& batch : batches); 805 {; 806 // -------------------- execute each of the batch ranges on a different thread -------------------------------; 807 futures.push_back (; 808 std::async (std::launch::async, [&](); 809 {; 810 std::vector<double> localOutput;; 811 pass_through_type passThrough (settings, batch, dropContainerTest);; 812 double testBatchError = (*this) (passThrough, weights, ModeOutput::FETCH, localOutput);; 813 return std::make_tuple (testBatchError, localOutput);; 814 }); 815 );; 816 }; 817 ; 818 auto itBatch = batches.begin ();; 819 for (auto& f : futures); 820 {; 821 std::tuple<double,std::vector<double>> result = f.get ();; 822 testError += std::get<0>(result) / batches.size ();; 823 std::vector<double> output = std::get<1>(result);; 824 if (outpu",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:23941,Testability,test,testPattern,23941,"iner);; 772 ; 773 ; 774 // ------ check if we have to execute a test ------------------; 775 bool hasConverged = false;; 776 if (testCycleCount % settings.testRepetitions () == 0) // we test only everye ""testRepetitions"" repetition; 777 {; 778 if (isWeightsForDrop); 779 {; 780 dropOutWeightFactor (weights, dropFractions);; 781 isWeightsForDrop = false;; 782 }; 783 ; 784 ; 785 testError = 0;; 786 //double weightSum = 0;; 787 settings.startTestCycle ();; 788 if (settings.useMultithreading ()); 789 {; 790 size_t numThreads = std::thread::hardware_concurrency ();; 791 size_t patternPerThread = testPattern.size () / numThreads;; 792 std::vector<Batch> batches;; 793 auto itPat = testPattern.begin ();; 794 // auto itPatEnd = testPattern.end ();; 795 for (size_t idxThread = 0; idxThread < numThreads-1; ++idxThread); 796 {; 797 batches.push_back (Batch (itPat, itPat + patternPerThread));; 798 itPat += patternPerThread;; 799 }; 800 if (itPat != testPattern.end ()); 801 batches.push_back (Batch (itPat, testPattern.end ()));; 802 ; 803 std::vector<std::future<std::tuple<double,std::vector<double>>>> futures;; 804 for (auto& batch : batches); 805 {; 806 // -------------------- execute each of the batch ranges on a different thread -------------------------------; 807 futures.push_back (; 808 std::async (std::launch::async, [&](); 809 {; 810 std::vector<double> localOutput;; 811 pass_through_type passThrough (settings, batch, dropContainerTest);; 812 double testBatchError = (*this) (passThrough, weights, ModeOutput::FETCH, localOutput);; 813 return std::make_tuple (testBatchError, localOutput);; 814 }); 815 );; 816 }; 817 ; 818 auto itBatch = batches.begin ();; 819 for (auto& f : futures); 820 {; 821 std::tuple<double,std::vector<double>> result = f.get ();; 822 testError += std::get<0>(result) / batches.size ();; 823 std::vector<double> output = std::get<1>(result);; 824 if (output.size() == (outputSize() - 1) * itBatch->size()); 825 {; 826 auto output_iterator = output.begin();;",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:24402,Testability,test,testBatchError,24402,"useMultithreading ()); 789 {; 790 size_t numThreads = std::thread::hardware_concurrency ();; 791 size_t patternPerThread = testPattern.size () / numThreads;; 792 std::vector<Batch> batches;; 793 auto itPat = testPattern.begin ();; 794 // auto itPatEnd = testPattern.end ();; 795 for (size_t idxThread = 0; idxThread < numThreads-1; ++idxThread); 796 {; 797 batches.push_back (Batch (itPat, itPat + patternPerThread));; 798 itPat += patternPerThread;; 799 }; 800 if (itPat != testPattern.end ()); 801 batches.push_back (Batch (itPat, testPattern.end ()));; 802 ; 803 std::vector<std::future<std::tuple<double,std::vector<double>>>> futures;; 804 for (auto& batch : batches); 805 {; 806 // -------------------- execute each of the batch ranges on a different thread -------------------------------; 807 futures.push_back (; 808 std::async (std::launch::async, [&](); 809 {; 810 std::vector<double> localOutput;; 811 pass_through_type passThrough (settings, batch, dropContainerTest);; 812 double testBatchError = (*this) (passThrough, weights, ModeOutput::FETCH, localOutput);; 813 return std::make_tuple (testBatchError, localOutput);; 814 }); 815 );; 816 }; 817 ; 818 auto itBatch = batches.begin ();; 819 for (auto& f : futures); 820 {; 821 std::tuple<double,std::vector<double>> result = f.get ();; 822 testError += std::get<0>(result) / batches.size ();; 823 std::vector<double> output = std::get<1>(result);; 824 if (output.size() == (outputSize() - 1) * itBatch->size()); 825 {; 826 auto output_iterator = output.begin();; 827 for (auto pattern_it = itBatch->begin(); pattern_it != itBatch->end(); ++pattern_it); 828 {; 829 for (size_t output_index = 1; output_index < outputSize(); ++output_index); 830 {; 831 settings.testSample (0, *output_iterator, (*pattern_it).output ().at (0),; 832 (*pattern_it).weight ());; 833 ++output_iterator;; 834 }; 835 }; 836 }; 837 ++itBatch;; 838 }; 839 ; 840 }; 841 else; 842 {; 843 std::vector<double> output;; 844 //for (auto it = begin (testPattern), itEnd",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:24512,Testability,test,testBatchError,24512,"useMultithreading ()); 789 {; 790 size_t numThreads = std::thread::hardware_concurrency ();; 791 size_t patternPerThread = testPattern.size () / numThreads;; 792 std::vector<Batch> batches;; 793 auto itPat = testPattern.begin ();; 794 // auto itPatEnd = testPattern.end ();; 795 for (size_t idxThread = 0; idxThread < numThreads-1; ++idxThread); 796 {; 797 batches.push_back (Batch (itPat, itPat + patternPerThread));; 798 itPat += patternPerThread;; 799 }; 800 if (itPat != testPattern.end ()); 801 batches.push_back (Batch (itPat, testPattern.end ()));; 802 ; 803 std::vector<std::future<std::tuple<double,std::vector<double>>>> futures;; 804 for (auto& batch : batches); 805 {; 806 // -------------------- execute each of the batch ranges on a different thread -------------------------------; 807 futures.push_back (; 808 std::async (std::launch::async, [&](); 809 {; 810 std::vector<double> localOutput;; 811 pass_through_type passThrough (settings, batch, dropContainerTest);; 812 double testBatchError = (*this) (passThrough, weights, ModeOutput::FETCH, localOutput);; 813 return std::make_tuple (testBatchError, localOutput);; 814 }); 815 );; 816 }; 817 ; 818 auto itBatch = batches.begin ();; 819 for (auto& f : futures); 820 {; 821 std::tuple<double,std::vector<double>> result = f.get ();; 822 testError += std::get<0>(result) / batches.size ();; 823 std::vector<double> output = std::get<1>(result);; 824 if (output.size() == (outputSize() - 1) * itBatch->size()); 825 {; 826 auto output_iterator = output.begin();; 827 for (auto pattern_it = itBatch->begin(); pattern_it != itBatch->end(); ++pattern_it); 828 {; 829 for (size_t output_index = 1; output_index < outputSize(); ++output_index); 830 {; 831 settings.testSample (0, *output_iterator, (*pattern_it).output ().at (0),; 832 (*pattern_it).weight ());; 833 ++output_iterator;; 834 }; 835 }; 836 }; 837 ++itBatch;; 838 }; 839 ; 840 }; 841 else; 842 {; 843 std::vector<double> output;; 844 //for (auto it = begin (testPattern), itEnd",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:24713,Testability,test,testError,24713,"mThreads-1; ++idxThread); 796 {; 797 batches.push_back (Batch (itPat, itPat + patternPerThread));; 798 itPat += patternPerThread;; 799 }; 800 if (itPat != testPattern.end ()); 801 batches.push_back (Batch (itPat, testPattern.end ()));; 802 ; 803 std::vector<std::future<std::tuple<double,std::vector<double>>>> futures;; 804 for (auto& batch : batches); 805 {; 806 // -------------------- execute each of the batch ranges on a different thread -------------------------------; 807 futures.push_back (; 808 std::async (std::launch::async, [&](); 809 {; 810 std::vector<double> localOutput;; 811 pass_through_type passThrough (settings, batch, dropContainerTest);; 812 double testBatchError = (*this) (passThrough, weights, ModeOutput::FETCH, localOutput);; 813 return std::make_tuple (testBatchError, localOutput);; 814 }); 815 );; 816 }; 817 ; 818 auto itBatch = batches.begin ();; 819 for (auto& f : futures); 820 {; 821 std::tuple<double,std::vector<double>> result = f.get ();; 822 testError += std::get<0>(result) / batches.size ();; 823 std::vector<double> output = std::get<1>(result);; 824 if (output.size() == (outputSize() - 1) * itBatch->size()); 825 {; 826 auto output_iterator = output.begin();; 827 for (auto pattern_it = itBatch->begin(); pattern_it != itBatch->end(); ++pattern_it); 828 {; 829 for (size_t output_index = 1; output_index < outputSize(); ++output_index); 830 {; 831 settings.testSample (0, *output_iterator, (*pattern_it).output ().at (0),; 832 (*pattern_it).weight ());; 833 ++output_iterator;; 834 }; 835 }; 836 }; 837 ++itBatch;; 838 }; 839 ; 840 }; 841 else; 842 {; 843 std::vector<double> output;; 844 //for (auto it = begin (testPattern), itEnd = end (testPattern); it != itEnd; ++it); 845 {; 846 //const Pattern& p = (*it);; 847 //double weight = p.weight ();; 848 //Batch batch (it, it+1);; 849 Batch batch (begin (testPattern), end (testPattern));; 850 output.clear ();; 851 pass_through_type passThrough (settings, batch, dropContainerTest);; 852 double testPa",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:25133,Testability,test,testSample,25133,"ifferent thread -------------------------------; 807 futures.push_back (; 808 std::async (std::launch::async, [&](); 809 {; 810 std::vector<double> localOutput;; 811 pass_through_type passThrough (settings, batch, dropContainerTest);; 812 double testBatchError = (*this) (passThrough, weights, ModeOutput::FETCH, localOutput);; 813 return std::make_tuple (testBatchError, localOutput);; 814 }); 815 );; 816 }; 817 ; 818 auto itBatch = batches.begin ();; 819 for (auto& f : futures); 820 {; 821 std::tuple<double,std::vector<double>> result = f.get ();; 822 testError += std::get<0>(result) / batches.size ();; 823 std::vector<double> output = std::get<1>(result);; 824 if (output.size() == (outputSize() - 1) * itBatch->size()); 825 {; 826 auto output_iterator = output.begin();; 827 for (auto pattern_it = itBatch->begin(); pattern_it != itBatch->end(); ++pattern_it); 828 {; 829 for (size_t output_index = 1; output_index < outputSize(); ++output_index); 830 {; 831 settings.testSample (0, *output_iterator, (*pattern_it).output ().at (0),; 832 (*pattern_it).weight ());; 833 ++output_iterator;; 834 }; 835 }; 836 }; 837 ++itBatch;; 838 }; 839 ; 840 }; 841 else; 842 {; 843 std::vector<double> output;; 844 //for (auto it = begin (testPattern), itEnd = end (testPattern); it != itEnd; ++it); 845 {; 846 //const Pattern& p = (*it);; 847 //double weight = p.weight ();; 848 //Batch batch (it, it+1);; 849 Batch batch (begin (testPattern), end (testPattern));; 850 output.clear ();; 851 pass_through_type passThrough (settings, batch, dropContainerTest);; 852 double testPatternError = (*this) (passThrough, weights, ModeOutput::FETCH, output);; 853 if (output.size() == (outputSize() - 1) * batch.size()); 854 {; 855 auto output_iterator = output.begin();; 856 for (auto pattern_it = batch.begin(); pattern_it != batch.end(); ++pattern_it); 857 {; 858 for (size_t output_index = 1; output_index < outputSize(); ++output_index); 859 {; 860 settings.testSample (0, *output_iterator, (*pattern_it).output",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:25389,Testability,test,testPattern,25389,"tch, dropContainerTest);; 812 double testBatchError = (*this) (passThrough, weights, ModeOutput::FETCH, localOutput);; 813 return std::make_tuple (testBatchError, localOutput);; 814 }); 815 );; 816 }; 817 ; 818 auto itBatch = batches.begin ();; 819 for (auto& f : futures); 820 {; 821 std::tuple<double,std::vector<double>> result = f.get ();; 822 testError += std::get<0>(result) / batches.size ();; 823 std::vector<double> output = std::get<1>(result);; 824 if (output.size() == (outputSize() - 1) * itBatch->size()); 825 {; 826 auto output_iterator = output.begin();; 827 for (auto pattern_it = itBatch->begin(); pattern_it != itBatch->end(); ++pattern_it); 828 {; 829 for (size_t output_index = 1; output_index < outputSize(); ++output_index); 830 {; 831 settings.testSample (0, *output_iterator, (*pattern_it).output ().at (0),; 832 (*pattern_it).weight ());; 833 ++output_iterator;; 834 }; 835 }; 836 }; 837 ++itBatch;; 838 }; 839 ; 840 }; 841 else; 842 {; 843 std::vector<double> output;; 844 //for (auto it = begin (testPattern), itEnd = end (testPattern); it != itEnd; ++it); 845 {; 846 //const Pattern& p = (*it);; 847 //double weight = p.weight ();; 848 //Batch batch (it, it+1);; 849 Batch batch (begin (testPattern), end (testPattern));; 850 output.clear ();; 851 pass_through_type passThrough (settings, batch, dropContainerTest);; 852 double testPatternError = (*this) (passThrough, weights, ModeOutput::FETCH, output);; 853 if (output.size() == (outputSize() - 1) * batch.size()); 854 {; 855 auto output_iterator = output.begin();; 856 for (auto pattern_it = batch.begin(); pattern_it != batch.end(); ++pattern_it); 857 {; 858 for (size_t output_index = 1; output_index < outputSize(); ++output_index); 859 {; 860 settings.testSample (0, *output_iterator, (*pattern_it).output ().at (0),; 861 (*pattern_it).weight ());; 862 ++output_iterator;; 863 }; 864 }; 865 }; 866 testError += testPatternError; /// batch.size ();; 867 }; 868 // testError /= testPattern.size ();; 869 }; 870 setti",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:25416,Testability,test,testPattern,25416,"tch, dropContainerTest);; 812 double testBatchError = (*this) (passThrough, weights, ModeOutput::FETCH, localOutput);; 813 return std::make_tuple (testBatchError, localOutput);; 814 }); 815 );; 816 }; 817 ; 818 auto itBatch = batches.begin ();; 819 for (auto& f : futures); 820 {; 821 std::tuple<double,std::vector<double>> result = f.get ();; 822 testError += std::get<0>(result) / batches.size ();; 823 std::vector<double> output = std::get<1>(result);; 824 if (output.size() == (outputSize() - 1) * itBatch->size()); 825 {; 826 auto output_iterator = output.begin();; 827 for (auto pattern_it = itBatch->begin(); pattern_it != itBatch->end(); ++pattern_it); 828 {; 829 for (size_t output_index = 1; output_index < outputSize(); ++output_index); 830 {; 831 settings.testSample (0, *output_iterator, (*pattern_it).output ().at (0),; 832 (*pattern_it).weight ());; 833 ++output_iterator;; 834 }; 835 }; 836 }; 837 ++itBatch;; 838 }; 839 ; 840 }; 841 else; 842 {; 843 std::vector<double> output;; 844 //for (auto it = begin (testPattern), itEnd = end (testPattern); it != itEnd; ++it); 845 {; 846 //const Pattern& p = (*it);; 847 //double weight = p.weight ();; 848 //Batch batch (it, it+1);; 849 Batch batch (begin (testPattern), end (testPattern));; 850 output.clear ();; 851 pass_through_type passThrough (settings, batch, dropContainerTest);; 852 double testPatternError = (*this) (passThrough, weights, ModeOutput::FETCH, output);; 853 if (output.size() == (outputSize() - 1) * batch.size()); 854 {; 855 auto output_iterator = output.begin();; 856 for (auto pattern_it = batch.begin(); pattern_it != batch.end(); ++pattern_it); 857 {; 858 for (size_t output_index = 1; output_index < outputSize(); ++output_index); 859 {; 860 settings.testSample (0, *output_iterator, (*pattern_it).output ().at (0),; 861 (*pattern_it).weight ());; 862 ++output_iterator;; 863 }; 864 }; 865 }; 866 testError += testPatternError; /// batch.size ();; 867 }; 868 // testError /= testPattern.size ();; 869 }; 870 setti",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:25581,Testability,test,testPattern,25581,"; 818 auto itBatch = batches.begin ();; 819 for (auto& f : futures); 820 {; 821 std::tuple<double,std::vector<double>> result = f.get ();; 822 testError += std::get<0>(result) / batches.size ();; 823 std::vector<double> output = std::get<1>(result);; 824 if (output.size() == (outputSize() - 1) * itBatch->size()); 825 {; 826 auto output_iterator = output.begin();; 827 for (auto pattern_it = itBatch->begin(); pattern_it != itBatch->end(); ++pattern_it); 828 {; 829 for (size_t output_index = 1; output_index < outputSize(); ++output_index); 830 {; 831 settings.testSample (0, *output_iterator, (*pattern_it).output ().at (0),; 832 (*pattern_it).weight ());; 833 ++output_iterator;; 834 }; 835 }; 836 }; 837 ++itBatch;; 838 }; 839 ; 840 }; 841 else; 842 {; 843 std::vector<double> output;; 844 //for (auto it = begin (testPattern), itEnd = end (testPattern); it != itEnd; ++it); 845 {; 846 //const Pattern& p = (*it);; 847 //double weight = p.weight ();; 848 //Batch batch (it, it+1);; 849 Batch batch (begin (testPattern), end (testPattern));; 850 output.clear ();; 851 pass_through_type passThrough (settings, batch, dropContainerTest);; 852 double testPatternError = (*this) (passThrough, weights, ModeOutput::FETCH, output);; 853 if (output.size() == (outputSize() - 1) * batch.size()); 854 {; 855 auto output_iterator = output.begin();; 856 for (auto pattern_it = batch.begin(); pattern_it != batch.end(); ++pattern_it); 857 {; 858 for (size_t output_index = 1; output_index < outputSize(); ++output_index); 859 {; 860 settings.testSample (0, *output_iterator, (*pattern_it).output ().at (0),; 861 (*pattern_it).weight ());; 862 ++output_iterator;; 863 }; 864 }; 865 }; 866 testError += testPatternError; /// batch.size ();; 867 }; 868 // testError /= testPattern.size ();; 869 }; 870 settings.endTestCycle ();; 871// testError /= weightSum;; 872 ; 873 settings.computeResult (*this, weights);; 874 ; 875 hasConverged = settings.hasConverged (testError);; 876 if (!hasConverged && !isWeightsForD",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:25600,Testability,test,testPattern,25600,"; 818 auto itBatch = batches.begin ();; 819 for (auto& f : futures); 820 {; 821 std::tuple<double,std::vector<double>> result = f.get ();; 822 testError += std::get<0>(result) / batches.size ();; 823 std::vector<double> output = std::get<1>(result);; 824 if (output.size() == (outputSize() - 1) * itBatch->size()); 825 {; 826 auto output_iterator = output.begin();; 827 for (auto pattern_it = itBatch->begin(); pattern_it != itBatch->end(); ++pattern_it); 828 {; 829 for (size_t output_index = 1; output_index < outputSize(); ++output_index); 830 {; 831 settings.testSample (0, *output_iterator, (*pattern_it).output ().at (0),; 832 (*pattern_it).weight ());; 833 ++output_iterator;; 834 }; 835 }; 836 }; 837 ++itBatch;; 838 }; 839 ; 840 }; 841 else; 842 {; 843 std::vector<double> output;; 844 //for (auto it = begin (testPattern), itEnd = end (testPattern); it != itEnd; ++it); 845 {; 846 //const Pattern& p = (*it);; 847 //double weight = p.weight ();; 848 //Batch batch (it, it+1);; 849 Batch batch (begin (testPattern), end (testPattern));; 850 output.clear ();; 851 pass_through_type passThrough (settings, batch, dropContainerTest);; 852 double testPatternError = (*this) (passThrough, weights, ModeOutput::FETCH, output);; 853 if (output.size() == (outputSize() - 1) * batch.size()); 854 {; 855 auto output_iterator = output.begin();; 856 for (auto pattern_it = batch.begin(); pattern_it != batch.end(); ++pattern_it); 857 {; 858 for (size_t output_index = 1; output_index < outputSize(); ++output_index); 859 {; 860 settings.testSample (0, *output_iterator, (*pattern_it).output ().at (0),; 861 (*pattern_it).weight ());; 862 ++output_iterator;; 863 }; 864 }; 865 }; 866 testError += testPatternError; /// batch.size ();; 867 }; 868 // testError /= testPattern.size ();; 869 }; 870 settings.endTestCycle ();; 871// testError /= weightSum;; 872 ; 873 settings.computeResult (*this, weights);; 874 ; 875 hasConverged = settings.hasConverged (testError);; 876 if (!hasConverged && !isWeightsForD",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:25722,Testability,test,testPatternError,25722,"r += std::get<0>(result) / batches.size ();; 823 std::vector<double> output = std::get<1>(result);; 824 if (output.size() == (outputSize() - 1) * itBatch->size()); 825 {; 826 auto output_iterator = output.begin();; 827 for (auto pattern_it = itBatch->begin(); pattern_it != itBatch->end(); ++pattern_it); 828 {; 829 for (size_t output_index = 1; output_index < outputSize(); ++output_index); 830 {; 831 settings.testSample (0, *output_iterator, (*pattern_it).output ().at (0),; 832 (*pattern_it).weight ());; 833 ++output_iterator;; 834 }; 835 }; 836 }; 837 ++itBatch;; 838 }; 839 ; 840 }; 841 else; 842 {; 843 std::vector<double> output;; 844 //for (auto it = begin (testPattern), itEnd = end (testPattern); it != itEnd; ++it); 845 {; 846 //const Pattern& p = (*it);; 847 //double weight = p.weight ();; 848 //Batch batch (it, it+1);; 849 Batch batch (begin (testPattern), end (testPattern));; 850 output.clear ();; 851 pass_through_type passThrough (settings, batch, dropContainerTest);; 852 double testPatternError = (*this) (passThrough, weights, ModeOutput::FETCH, output);; 853 if (output.size() == (outputSize() - 1) * batch.size()); 854 {; 855 auto output_iterator = output.begin();; 856 for (auto pattern_it = batch.begin(); pattern_it != batch.end(); ++pattern_it); 857 {; 858 for (size_t output_index = 1; output_index < outputSize(); ++output_index); 859 {; 860 settings.testSample (0, *output_iterator, (*pattern_it).output ().at (0),; 861 (*pattern_it).weight ());; 862 ++output_iterator;; 863 }; 864 }; 865 }; 866 testError += testPatternError; /// batch.size ();; 867 }; 868 // testError /= testPattern.size ();; 869 }; 870 settings.endTestCycle ();; 871// testError /= weightSum;; 872 ; 873 settings.computeResult (*this, weights);; 874 ; 875 hasConverged = settings.hasConverged (testError);; 876 if (!hasConverged && !isWeightsForDrop); 877 {; 878 dropOutWeightFactor (weights, dropFractions, true); // inverse; 879 isWeightsForDrop = true;; 880 }; 881 }; 882 ++testCycleCount;; 883",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:26104,Testability,test,testSample,26104,"tings.testSample (0, *output_iterator, (*pattern_it).output ().at (0),; 832 (*pattern_it).weight ());; 833 ++output_iterator;; 834 }; 835 }; 836 }; 837 ++itBatch;; 838 }; 839 ; 840 }; 841 else; 842 {; 843 std::vector<double> output;; 844 //for (auto it = begin (testPattern), itEnd = end (testPattern); it != itEnd; ++it); 845 {; 846 //const Pattern& p = (*it);; 847 //double weight = p.weight ();; 848 //Batch batch (it, it+1);; 849 Batch batch (begin (testPattern), end (testPattern));; 850 output.clear ();; 851 pass_through_type passThrough (settings, batch, dropContainerTest);; 852 double testPatternError = (*this) (passThrough, weights, ModeOutput::FETCH, output);; 853 if (output.size() == (outputSize() - 1) * batch.size()); 854 {; 855 auto output_iterator = output.begin();; 856 for (auto pattern_it = batch.begin(); pattern_it != batch.end(); ++pattern_it); 857 {; 858 for (size_t output_index = 1; output_index < outputSize(); ++output_index); 859 {; 860 settings.testSample (0, *output_iterator, (*pattern_it).output ().at (0),; 861 (*pattern_it).weight ());; 862 ++output_iterator;; 863 }; 864 }; 865 }; 866 testError += testPatternError; /// batch.size ();; 867 }; 868 // testError /= testPattern.size ();; 869 }; 870 settings.endTestCycle ();; 871// testError /= weightSum;; 872 ; 873 settings.computeResult (*this, weights);; 874 ; 875 hasConverged = settings.hasConverged (testError);; 876 if (!hasConverged && !isWeightsForDrop); 877 {; 878 dropOutWeightFactor (weights, dropFractions, true); // inverse; 879 isWeightsForDrop = true;; 880 }; 881 }; 882 ++testCycleCount;; 883 ++dropOutChangeCount;; 884 ; 885 ; 886// settings.resetPlot (""errors"");; 887 settings.addPoint (""trainErrors"", cycleCount, trainError);; 888 settings.addPoint (""testErrors"", cycleCount, testError);; 889 settings.plot (""trainErrors"", ""C"", 1, kBlue);; 890 settings.plot (""testErrors"", ""C"", 1, kMagenta);; 891 ; 892 ; 893 // setup error plots and progress bar variables for JsMVA; 894 if (fInteractive){; 895",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:26250,Testability,test,testError,26250,"put_iterator;; 834 }; 835 }; 836 }; 837 ++itBatch;; 838 }; 839 ; 840 }; 841 else; 842 {; 843 std::vector<double> output;; 844 //for (auto it = begin (testPattern), itEnd = end (testPattern); it != itEnd; ++it); 845 {; 846 //const Pattern& p = (*it);; 847 //double weight = p.weight ();; 848 //Batch batch (it, it+1);; 849 Batch batch (begin (testPattern), end (testPattern));; 850 output.clear ();; 851 pass_through_type passThrough (settings, batch, dropContainerTest);; 852 double testPatternError = (*this) (passThrough, weights, ModeOutput::FETCH, output);; 853 if (output.size() == (outputSize() - 1) * batch.size()); 854 {; 855 auto output_iterator = output.begin();; 856 for (auto pattern_it = batch.begin(); pattern_it != batch.end(); ++pattern_it); 857 {; 858 for (size_t output_index = 1; output_index < outputSize(); ++output_index); 859 {; 860 settings.testSample (0, *output_iterator, (*pattern_it).output ().at (0),; 861 (*pattern_it).weight ());; 862 ++output_iterator;; 863 }; 864 }; 865 }; 866 testError += testPatternError; /// batch.size ();; 867 }; 868 // testError /= testPattern.size ();; 869 }; 870 settings.endTestCycle ();; 871// testError /= weightSum;; 872 ; 873 settings.computeResult (*this, weights);; 874 ; 875 hasConverged = settings.hasConverged (testError);; 876 if (!hasConverged && !isWeightsForDrop); 877 {; 878 dropOutWeightFactor (weights, dropFractions, true); // inverse; 879 isWeightsForDrop = true;; 880 }; 881 }; 882 ++testCycleCount;; 883 ++dropOutChangeCount;; 884 ; 885 ; 886// settings.resetPlot (""errors"");; 887 settings.addPoint (""trainErrors"", cycleCount, trainError);; 888 settings.addPoint (""testErrors"", cycleCount, testError);; 889 settings.plot (""trainErrors"", ""C"", 1, kBlue);; 890 settings.plot (""testErrors"", ""C"", 1, kMagenta);; 891 ; 892 ; 893 // setup error plots and progress bar variables for JsMVA; 894 if (fInteractive){; 895 fInteractive->AddPoint(cycleCount, trainError, testError);; 896 if (*fExitFromTraining) break;; 897 *fIPyCurren",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:26263,Testability,test,testPatternError,26263,"put_iterator;; 834 }; 835 }; 836 }; 837 ++itBatch;; 838 }; 839 ; 840 }; 841 else; 842 {; 843 std::vector<double> output;; 844 //for (auto it = begin (testPattern), itEnd = end (testPattern); it != itEnd; ++it); 845 {; 846 //const Pattern& p = (*it);; 847 //double weight = p.weight ();; 848 //Batch batch (it, it+1);; 849 Batch batch (begin (testPattern), end (testPattern));; 850 output.clear ();; 851 pass_through_type passThrough (settings, batch, dropContainerTest);; 852 double testPatternError = (*this) (passThrough, weights, ModeOutput::FETCH, output);; 853 if (output.size() == (outputSize() - 1) * batch.size()); 854 {; 855 auto output_iterator = output.begin();; 856 for (auto pattern_it = batch.begin(); pattern_it != batch.end(); ++pattern_it); 857 {; 858 for (size_t output_index = 1; output_index < outputSize(); ++output_index); 859 {; 860 settings.testSample (0, *output_iterator, (*pattern_it).output ().at (0),; 861 (*pattern_it).weight ());; 862 ++output_iterator;; 863 }; 864 }; 865 }; 866 testError += testPatternError; /// batch.size ();; 867 }; 868 // testError /= testPattern.size ();; 869 }; 870 settings.endTestCycle ();; 871// testError /= weightSum;; 872 ; 873 settings.computeResult (*this, weights);; 874 ; 875 hasConverged = settings.hasConverged (testError);; 876 if (!hasConverged && !isWeightsForDrop); 877 {; 878 dropOutWeightFactor (weights, dropFractions, true); // inverse; 879 isWeightsForDrop = true;; 880 }; 881 }; 882 ++testCycleCount;; 883 ++dropOutChangeCount;; 884 ; 885 ; 886// settings.resetPlot (""errors"");; 887 settings.addPoint (""trainErrors"", cycleCount, trainError);; 888 settings.addPoint (""testErrors"", cycleCount, testError);; 889 settings.plot (""trainErrors"", ""C"", 1, kBlue);; 890 settings.plot (""testErrors"", ""C"", 1, kMagenta);; 891 ; 892 ; 893 // setup error plots and progress bar variables for JsMVA; 894 if (fInteractive){; 895 fInteractive->AddPoint(cycleCount, trainError, testError);; 896 if (*fExitFromTraining) break;; 897 *fIPyCurren",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:26315,Testability,test,testError,26315,"else; 842 {; 843 std::vector<double> output;; 844 //for (auto it = begin (testPattern), itEnd = end (testPattern); it != itEnd; ++it); 845 {; 846 //const Pattern& p = (*it);; 847 //double weight = p.weight ();; 848 //Batch batch (it, it+1);; 849 Batch batch (begin (testPattern), end (testPattern));; 850 output.clear ();; 851 pass_through_type passThrough (settings, batch, dropContainerTest);; 852 double testPatternError = (*this) (passThrough, weights, ModeOutput::FETCH, output);; 853 if (output.size() == (outputSize() - 1) * batch.size()); 854 {; 855 auto output_iterator = output.begin();; 856 for (auto pattern_it = batch.begin(); pattern_it != batch.end(); ++pattern_it); 857 {; 858 for (size_t output_index = 1; output_index < outputSize(); ++output_index); 859 {; 860 settings.testSample (0, *output_iterator, (*pattern_it).output ().at (0),; 861 (*pattern_it).weight ());; 862 ++output_iterator;; 863 }; 864 }; 865 }; 866 testError += testPatternError; /// batch.size ();; 867 }; 868 // testError /= testPattern.size ();; 869 }; 870 settings.endTestCycle ();; 871// testError /= weightSum;; 872 ; 873 settings.computeResult (*this, weights);; 874 ; 875 hasConverged = settings.hasConverged (testError);; 876 if (!hasConverged && !isWeightsForDrop); 877 {; 878 dropOutWeightFactor (weights, dropFractions, true); // inverse; 879 isWeightsForDrop = true;; 880 }; 881 }; 882 ++testCycleCount;; 883 ++dropOutChangeCount;; 884 ; 885 ; 886// settings.resetPlot (""errors"");; 887 settings.addPoint (""trainErrors"", cycleCount, trainError);; 888 settings.addPoint (""testErrors"", cycleCount, testError);; 889 settings.plot (""trainErrors"", ""C"", 1, kBlue);; 890 settings.plot (""testErrors"", ""C"", 1, kMagenta);; 891 ; 892 ; 893 // setup error plots and progress bar variables for JsMVA; 894 if (fInteractive){; 895 fInteractive->AddPoint(cycleCount, trainError, testError);; 896 if (*fExitFromTraining) break;; 897 *fIPyCurrentIter = 100*(double)settings.maxConvergenceCount () /(double)settings.conver",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:26328,Testability,test,testPattern,26328,"else; 842 {; 843 std::vector<double> output;; 844 //for (auto it = begin (testPattern), itEnd = end (testPattern); it != itEnd; ++it); 845 {; 846 //const Pattern& p = (*it);; 847 //double weight = p.weight ();; 848 //Batch batch (it, it+1);; 849 Batch batch (begin (testPattern), end (testPattern));; 850 output.clear ();; 851 pass_through_type passThrough (settings, batch, dropContainerTest);; 852 double testPatternError = (*this) (passThrough, weights, ModeOutput::FETCH, output);; 853 if (output.size() == (outputSize() - 1) * batch.size()); 854 {; 855 auto output_iterator = output.begin();; 856 for (auto pattern_it = batch.begin(); pattern_it != batch.end(); ++pattern_it); 857 {; 858 for (size_t output_index = 1; output_index < outputSize(); ++output_index); 859 {; 860 settings.testSample (0, *output_iterator, (*pattern_it).output ().at (0),; 861 (*pattern_it).weight ());; 862 ++output_iterator;; 863 }; 864 }; 865 }; 866 testError += testPatternError; /// batch.size ();; 867 }; 868 // testError /= testPattern.size ();; 869 }; 870 settings.endTestCycle ();; 871// testError /= weightSum;; 872 ; 873 settings.computeResult (*this, weights);; 874 ; 875 hasConverged = settings.hasConverged (testError);; 876 if (!hasConverged && !isWeightsForDrop); 877 {; 878 dropOutWeightFactor (weights, dropFractions, true); // inverse; 879 isWeightsForDrop = true;; 880 }; 881 }; 882 ++testCycleCount;; 883 ++dropOutChangeCount;; 884 ; 885 ; 886// settings.resetPlot (""errors"");; 887 settings.addPoint (""trainErrors"", cycleCount, trainError);; 888 settings.addPoint (""testErrors"", cycleCount, testError);; 889 settings.plot (""trainErrors"", ""C"", 1, kBlue);; 890 settings.plot (""testErrors"", ""C"", 1, kMagenta);; 891 ; 892 ; 893 // setup error plots and progress bar variables for JsMVA; 894 if (fInteractive){; 895 fInteractive->AddPoint(cycleCount, trainError, testError);; 896 if (*fExitFromTraining) break;; 897 *fIPyCurrentIter = 100*(double)settings.maxConvergenceCount () /(double)settings.conver",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:26394,Testability,test,testError,26394,"tEnd = end (testPattern); it != itEnd; ++it); 845 {; 846 //const Pattern& p = (*it);; 847 //double weight = p.weight ();; 848 //Batch batch (it, it+1);; 849 Batch batch (begin (testPattern), end (testPattern));; 850 output.clear ();; 851 pass_through_type passThrough (settings, batch, dropContainerTest);; 852 double testPatternError = (*this) (passThrough, weights, ModeOutput::FETCH, output);; 853 if (output.size() == (outputSize() - 1) * batch.size()); 854 {; 855 auto output_iterator = output.begin();; 856 for (auto pattern_it = batch.begin(); pattern_it != batch.end(); ++pattern_it); 857 {; 858 for (size_t output_index = 1; output_index < outputSize(); ++output_index); 859 {; 860 settings.testSample (0, *output_iterator, (*pattern_it).output ().at (0),; 861 (*pattern_it).weight ());; 862 ++output_iterator;; 863 }; 864 }; 865 }; 866 testError += testPatternError; /// batch.size ();; 867 }; 868 // testError /= testPattern.size ();; 869 }; 870 settings.endTestCycle ();; 871// testError /= weightSum;; 872 ; 873 settings.computeResult (*this, weights);; 874 ; 875 hasConverged = settings.hasConverged (testError);; 876 if (!hasConverged && !isWeightsForDrop); 877 {; 878 dropOutWeightFactor (weights, dropFractions, true); // inverse; 879 isWeightsForDrop = true;; 880 }; 881 }; 882 ++testCycleCount;; 883 ++dropOutChangeCount;; 884 ; 885 ; 886// settings.resetPlot (""errors"");; 887 settings.addPoint (""trainErrors"", cycleCount, trainError);; 888 settings.addPoint (""testErrors"", cycleCount, testError);; 889 settings.plot (""trainErrors"", ""C"", 1, kBlue);; 890 settings.plot (""testErrors"", ""C"", 1, kMagenta);; 891 ; 892 ; 893 // setup error plots and progress bar variables for JsMVA; 894 if (fInteractive){; 895 fInteractive->AddPoint(cycleCount, trainError, testError);; 896 if (*fExitFromTraining) break;; 897 *fIPyCurrentIter = 100*(double)settings.maxConvergenceCount () /(double)settings.convergenceSteps ();; 898 }; 899 ; 900 if (hasConverged); 901 break;; 902 ; 903 if ((int)cycle",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:26519,Testability,test,testError,26519,"51 pass_through_type passThrough (settings, batch, dropContainerTest);; 852 double testPatternError = (*this) (passThrough, weights, ModeOutput::FETCH, output);; 853 if (output.size() == (outputSize() - 1) * batch.size()); 854 {; 855 auto output_iterator = output.begin();; 856 for (auto pattern_it = batch.begin(); pattern_it != batch.end(); ++pattern_it); 857 {; 858 for (size_t output_index = 1; output_index < outputSize(); ++output_index); 859 {; 860 settings.testSample (0, *output_iterator, (*pattern_it).output ().at (0),; 861 (*pattern_it).weight ());; 862 ++output_iterator;; 863 }; 864 }; 865 }; 866 testError += testPatternError; /// batch.size ();; 867 }; 868 // testError /= testPattern.size ();; 869 }; 870 settings.endTestCycle ();; 871// testError /= weightSum;; 872 ; 873 settings.computeResult (*this, weights);; 874 ; 875 hasConverged = settings.hasConverged (testError);; 876 if (!hasConverged && !isWeightsForDrop); 877 {; 878 dropOutWeightFactor (weights, dropFractions, true); // inverse; 879 isWeightsForDrop = true;; 880 }; 881 }; 882 ++testCycleCount;; 883 ++dropOutChangeCount;; 884 ; 885 ; 886// settings.resetPlot (""errors"");; 887 settings.addPoint (""trainErrors"", cycleCount, trainError);; 888 settings.addPoint (""testErrors"", cycleCount, testError);; 889 settings.plot (""trainErrors"", ""C"", 1, kBlue);; 890 settings.plot (""testErrors"", ""C"", 1, kMagenta);; 891 ; 892 ; 893 // setup error plots and progress bar variables for JsMVA; 894 if (fInteractive){; 895 fInteractive->AddPoint(cycleCount, trainError, testError);; 896 if (*fExitFromTraining) break;; 897 *fIPyCurrentIter = 100*(double)settings.maxConvergenceCount () /(double)settings.convergenceSteps ();; 898 }; 899 ; 900 if (hasConverged); 901 break;; 902 ; 903 if ((int)cycleCount % 10 == 0) {; 904 ; 905 TString convText = TString::Format( ""(train/test/epo/conv/maxco): %.3g/%.3g/%d/%d/%d"",; 906 trainError,; 907 testError,; 908 (int)cycleCount,; 909 (int)settings.convergenceCount (),; 910 (int)settings.maxC",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:26702,Testability,test,testCycleCount,26702,"51 pass_through_type passThrough (settings, batch, dropContainerTest);; 852 double testPatternError = (*this) (passThrough, weights, ModeOutput::FETCH, output);; 853 if (output.size() == (outputSize() - 1) * batch.size()); 854 {; 855 auto output_iterator = output.begin();; 856 for (auto pattern_it = batch.begin(); pattern_it != batch.end(); ++pattern_it); 857 {; 858 for (size_t output_index = 1; output_index < outputSize(); ++output_index); 859 {; 860 settings.testSample (0, *output_iterator, (*pattern_it).output ().at (0),; 861 (*pattern_it).weight ());; 862 ++output_iterator;; 863 }; 864 }; 865 }; 866 testError += testPatternError; /// batch.size ();; 867 }; 868 // testError /= testPattern.size ();; 869 }; 870 settings.endTestCycle ();; 871// testError /= weightSum;; 872 ; 873 settings.computeResult (*this, weights);; 874 ; 875 hasConverged = settings.hasConverged (testError);; 876 if (!hasConverged && !isWeightsForDrop); 877 {; 878 dropOutWeightFactor (weights, dropFractions, true); // inverse; 879 isWeightsForDrop = true;; 880 }; 881 }; 882 ++testCycleCount;; 883 ++dropOutChangeCount;; 884 ; 885 ; 886// settings.resetPlot (""errors"");; 887 settings.addPoint (""trainErrors"", cycleCount, trainError);; 888 settings.addPoint (""testErrors"", cycleCount, testError);; 889 settings.plot (""trainErrors"", ""C"", 1, kBlue);; 890 settings.plot (""testErrors"", ""C"", 1, kMagenta);; 891 ; 892 ; 893 // setup error plots and progress bar variables for JsMVA; 894 if (fInteractive){; 895 fInteractive->AddPoint(cycleCount, trainError, testError);; 896 if (*fExitFromTraining) break;; 897 *fIPyCurrentIter = 100*(double)settings.maxConvergenceCount () /(double)settings.convergenceSteps ();; 898 }; 899 ; 900 if (hasConverged); 901 break;; 902 ; 903 if ((int)cycleCount % 10 == 0) {; 904 ; 905 TString convText = TString::Format( ""(train/test/epo/conv/maxco): %.3g/%.3g/%d/%d/%d"",; 906 trainError,; 907 testError,; 908 (int)cycleCount,; 909 (int)settings.convergenceCount (),; 910 (int)settings.maxC",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:26884,Testability,test,testErrors,26884,"egin();; 856 for (auto pattern_it = batch.begin(); pattern_it != batch.end(); ++pattern_it); 857 {; 858 for (size_t output_index = 1; output_index < outputSize(); ++output_index); 859 {; 860 settings.testSample (0, *output_iterator, (*pattern_it).output ().at (0),; 861 (*pattern_it).weight ());; 862 ++output_iterator;; 863 }; 864 }; 865 }; 866 testError += testPatternError; /// batch.size ();; 867 }; 868 // testError /= testPattern.size ();; 869 }; 870 settings.endTestCycle ();; 871// testError /= weightSum;; 872 ; 873 settings.computeResult (*this, weights);; 874 ; 875 hasConverged = settings.hasConverged (testError);; 876 if (!hasConverged && !isWeightsForDrop); 877 {; 878 dropOutWeightFactor (weights, dropFractions, true); // inverse; 879 isWeightsForDrop = true;; 880 }; 881 }; 882 ++testCycleCount;; 883 ++dropOutChangeCount;; 884 ; 885 ; 886// settings.resetPlot (""errors"");; 887 settings.addPoint (""trainErrors"", cycleCount, trainError);; 888 settings.addPoint (""testErrors"", cycleCount, testError);; 889 settings.plot (""trainErrors"", ""C"", 1, kBlue);; 890 settings.plot (""testErrors"", ""C"", 1, kMagenta);; 891 ; 892 ; 893 // setup error plots and progress bar variables for JsMVA; 894 if (fInteractive){; 895 fInteractive->AddPoint(cycleCount, trainError, testError);; 896 if (*fExitFromTraining) break;; 897 *fIPyCurrentIter = 100*(double)settings.maxConvergenceCount () /(double)settings.convergenceSteps ();; 898 }; 899 ; 900 if (hasConverged); 901 break;; 902 ; 903 if ((int)cycleCount % 10 == 0) {; 904 ; 905 TString convText = TString::Format( ""(train/test/epo/conv/maxco): %.3g/%.3g/%d/%d/%d"",; 906 trainError,; 907 testError,; 908 (int)cycleCount,; 909 (int)settings.convergenceCount (),; 910 (int)settings.maxConvergenceCount ());; 911 double progress = 100*(double)settings.maxConvergenceCount () /(double)settings.convergenceSteps ();; 912 settings.cycle (progress, convText);; 913 }; 914 }; 915 while (true);; 916 settings.endTrainCycle (trainError);; 917 ; 918 TString co",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:26909,Testability,test,testError,26909,"egin();; 856 for (auto pattern_it = batch.begin(); pattern_it != batch.end(); ++pattern_it); 857 {; 858 for (size_t output_index = 1; output_index < outputSize(); ++output_index); 859 {; 860 settings.testSample (0, *output_iterator, (*pattern_it).output ().at (0),; 861 (*pattern_it).weight ());; 862 ++output_iterator;; 863 }; 864 }; 865 }; 866 testError += testPatternError; /// batch.size ();; 867 }; 868 // testError /= testPattern.size ();; 869 }; 870 settings.endTestCycle ();; 871// testError /= weightSum;; 872 ; 873 settings.computeResult (*this, weights);; 874 ; 875 hasConverged = settings.hasConverged (testError);; 876 if (!hasConverged && !isWeightsForDrop); 877 {; 878 dropOutWeightFactor (weights, dropFractions, true); // inverse; 879 isWeightsForDrop = true;; 880 }; 881 }; 882 ++testCycleCount;; 883 ++dropOutChangeCount;; 884 ; 885 ; 886// settings.resetPlot (""errors"");; 887 settings.addPoint (""trainErrors"", cycleCount, trainError);; 888 settings.addPoint (""testErrors"", cycleCount, testError);; 889 settings.plot (""trainErrors"", ""C"", 1, kBlue);; 890 settings.plot (""testErrors"", ""C"", 1, kMagenta);; 891 ; 892 ; 893 // setup error plots and progress bar variables for JsMVA; 894 if (fInteractive){; 895 fInteractive->AddPoint(cycleCount, trainError, testError);; 896 if (*fExitFromTraining) break;; 897 *fIPyCurrentIter = 100*(double)settings.maxConvergenceCount () /(double)settings.convergenceSteps ();; 898 }; 899 ; 900 if (hasConverged); 901 break;; 902 ; 903 if ((int)cycleCount % 10 == 0) {; 904 ; 905 TString convText = TString::Format( ""(train/test/epo/conv/maxco): %.3g/%.3g/%d/%d/%d"",; 906 trainError,; 907 testError,; 908 (int)cycleCount,; 909 (int)settings.convergenceCount (),; 910 (int)settings.maxConvergenceCount ());; 911 double progress = 100*(double)settings.maxConvergenceCount () /(double)settings.convergenceSteps ();; 912 settings.cycle (progress, convText);; 913 }; 914 }; 915 while (true);; 916 settings.endTrainCycle (trainError);; 917 ; 918 TString co",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:26993,Testability,test,testErrors,26993,"iterator, (*pattern_it).output ().at (0),; 861 (*pattern_it).weight ());; 862 ++output_iterator;; 863 }; 864 }; 865 }; 866 testError += testPatternError; /// batch.size ();; 867 }; 868 // testError /= testPattern.size ();; 869 }; 870 settings.endTestCycle ();; 871// testError /= weightSum;; 872 ; 873 settings.computeResult (*this, weights);; 874 ; 875 hasConverged = settings.hasConverged (testError);; 876 if (!hasConverged && !isWeightsForDrop); 877 {; 878 dropOutWeightFactor (weights, dropFractions, true); // inverse; 879 isWeightsForDrop = true;; 880 }; 881 }; 882 ++testCycleCount;; 883 ++dropOutChangeCount;; 884 ; 885 ; 886// settings.resetPlot (""errors"");; 887 settings.addPoint (""trainErrors"", cycleCount, trainError);; 888 settings.addPoint (""testErrors"", cycleCount, testError);; 889 settings.plot (""trainErrors"", ""C"", 1, kBlue);; 890 settings.plot (""testErrors"", ""C"", 1, kMagenta);; 891 ; 892 ; 893 // setup error plots and progress bar variables for JsMVA; 894 if (fInteractive){; 895 fInteractive->AddPoint(cycleCount, trainError, testError);; 896 if (*fExitFromTraining) break;; 897 *fIPyCurrentIter = 100*(double)settings.maxConvergenceCount () /(double)settings.convergenceSteps ();; 898 }; 899 ; 900 if (hasConverged); 901 break;; 902 ; 903 if ((int)cycleCount % 10 == 0) {; 904 ; 905 TString convText = TString::Format( ""(train/test/epo/conv/maxco): %.3g/%.3g/%d/%d/%d"",; 906 trainError,; 907 testError,; 908 (int)cycleCount,; 909 (int)settings.convergenceCount (),; 910 (int)settings.maxConvergenceCount ());; 911 double progress = 100*(double)settings.maxConvergenceCount () /(double)settings.convergenceSteps ();; 912 settings.cycle (progress, convText);; 913 }; 914 }; 915 while (true);; 916 settings.endTrainCycle (trainError);; 917 ; 918 TString convText = TString::Format( ""(train/test/epoch): %.4g/%.4g/%d"", trainError, testError, (int)cycleCount);; 919 double progress = 100*(double)settings.maxConvergenceCount() /(double)settings.convergenceSteps ();; 920 settings.cy",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:27176,Testability,test,testError,27176,"iterator, (*pattern_it).output ().at (0),; 861 (*pattern_it).weight ());; 862 ++output_iterator;; 863 }; 864 }; 865 }; 866 testError += testPatternError; /// batch.size ();; 867 }; 868 // testError /= testPattern.size ();; 869 }; 870 settings.endTestCycle ();; 871// testError /= weightSum;; 872 ; 873 settings.computeResult (*this, weights);; 874 ; 875 hasConverged = settings.hasConverged (testError);; 876 if (!hasConverged && !isWeightsForDrop); 877 {; 878 dropOutWeightFactor (weights, dropFractions, true); // inverse; 879 isWeightsForDrop = true;; 880 }; 881 }; 882 ++testCycleCount;; 883 ++dropOutChangeCount;; 884 ; 885 ; 886// settings.resetPlot (""errors"");; 887 settings.addPoint (""trainErrors"", cycleCount, trainError);; 888 settings.addPoint (""testErrors"", cycleCount, testError);; 889 settings.plot (""trainErrors"", ""C"", 1, kBlue);; 890 settings.plot (""testErrors"", ""C"", 1, kMagenta);; 891 ; 892 ; 893 // setup error plots and progress bar variables for JsMVA; 894 if (fInteractive){; 895 fInteractive->AddPoint(cycleCount, trainError, testError);; 896 if (*fExitFromTraining) break;; 897 *fIPyCurrentIter = 100*(double)settings.maxConvergenceCount () /(double)settings.convergenceSteps ();; 898 }; 899 ; 900 if (hasConverged); 901 break;; 902 ; 903 if ((int)cycleCount % 10 == 0) {; 904 ; 905 TString convText = TString::Format( ""(train/test/epo/conv/maxco): %.3g/%.3g/%d/%d/%d"",; 906 trainError,; 907 testError,; 908 (int)cycleCount,; 909 (int)settings.convergenceCount (),; 910 (int)settings.maxConvergenceCount ());; 911 double progress = 100*(double)settings.maxConvergenceCount () /(double)settings.convergenceSteps ();; 912 settings.cycle (progress, convText);; 913 }; 914 }; 915 while (true);; 916 settings.endTrainCycle (trainError);; 917 ; 918 TString convText = TString::Format( ""(train/test/epoch): %.4g/%.4g/%d"", trainError, testError, (int)cycleCount);; 919 double progress = 100*(double)settings.maxConvergenceCount() /(double)settings.convergenceSteps ();; 920 settings.cy",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:27478,Testability,test,test,27478," weightSum;; 872 ; 873 settings.computeResult (*this, weights);; 874 ; 875 hasConverged = settings.hasConverged (testError);; 876 if (!hasConverged && !isWeightsForDrop); 877 {; 878 dropOutWeightFactor (weights, dropFractions, true); // inverse; 879 isWeightsForDrop = true;; 880 }; 881 }; 882 ++testCycleCount;; 883 ++dropOutChangeCount;; 884 ; 885 ; 886// settings.resetPlot (""errors"");; 887 settings.addPoint (""trainErrors"", cycleCount, trainError);; 888 settings.addPoint (""testErrors"", cycleCount, testError);; 889 settings.plot (""trainErrors"", ""C"", 1, kBlue);; 890 settings.plot (""testErrors"", ""C"", 1, kMagenta);; 891 ; 892 ; 893 // setup error plots and progress bar variables for JsMVA; 894 if (fInteractive){; 895 fInteractive->AddPoint(cycleCount, trainError, testError);; 896 if (*fExitFromTraining) break;; 897 *fIPyCurrentIter = 100*(double)settings.maxConvergenceCount () /(double)settings.convergenceSteps ();; 898 }; 899 ; 900 if (hasConverged); 901 break;; 902 ; 903 if ((int)cycleCount % 10 == 0) {; 904 ; 905 TString convText = TString::Format( ""(train/test/epo/conv/maxco): %.3g/%.3g/%d/%d/%d"",; 906 trainError,; 907 testError,; 908 (int)cycleCount,; 909 (int)settings.convergenceCount (),; 910 (int)settings.maxConvergenceCount ());; 911 double progress = 100*(double)settings.maxConvergenceCount () /(double)settings.convergenceSteps ();; 912 settings.cycle (progress, convText);; 913 }; 914 }; 915 while (true);; 916 settings.endTrainCycle (trainError);; 917 ; 918 TString convText = TString::Format( ""(train/test/epoch): %.4g/%.4g/%d"", trainError, testError, (int)cycleCount);; 919 double progress = 100*(double)settings.maxConvergenceCount() /(double)settings.convergenceSteps ();; 920 settings.cycle (progress, convText);; 921 ; 922 return testError;; 923 }; 924 ; 925 ; 926 ; 927/*! \brief execute a single training cycle; 928 *; 929 * uses multithreading if turned on; 930 *; 931 * \param minimizer the minimizer to be used (e.g. SGD); 932 * \param weights the weight cont",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:27543,Testability,test,testError,27543,"ed && !isWeightsForDrop); 877 {; 878 dropOutWeightFactor (weights, dropFractions, true); // inverse; 879 isWeightsForDrop = true;; 880 }; 881 }; 882 ++testCycleCount;; 883 ++dropOutChangeCount;; 884 ; 885 ; 886// settings.resetPlot (""errors"");; 887 settings.addPoint (""trainErrors"", cycleCount, trainError);; 888 settings.addPoint (""testErrors"", cycleCount, testError);; 889 settings.plot (""trainErrors"", ""C"", 1, kBlue);; 890 settings.plot (""testErrors"", ""C"", 1, kMagenta);; 891 ; 892 ; 893 // setup error plots and progress bar variables for JsMVA; 894 if (fInteractive){; 895 fInteractive->AddPoint(cycleCount, trainError, testError);; 896 if (*fExitFromTraining) break;; 897 *fIPyCurrentIter = 100*(double)settings.maxConvergenceCount () /(double)settings.convergenceSteps ();; 898 }; 899 ; 900 if (hasConverged); 901 break;; 902 ; 903 if ((int)cycleCount % 10 == 0) {; 904 ; 905 TString convText = TString::Format( ""(train/test/epo/conv/maxco): %.3g/%.3g/%d/%d/%d"",; 906 trainError,; 907 testError,; 908 (int)cycleCount,; 909 (int)settings.convergenceCount (),; 910 (int)settings.maxConvergenceCount ());; 911 double progress = 100*(double)settings.maxConvergenceCount () /(double)settings.convergenceSteps ();; 912 settings.cycle (progress, convText);; 913 }; 914 }; 915 while (true);; 916 settings.endTrainCycle (trainError);; 917 ; 918 TString convText = TString::Format( ""(train/test/epoch): %.4g/%.4g/%d"", trainError, testError, (int)cycleCount);; 919 double progress = 100*(double)settings.maxConvergenceCount() /(double)settings.convergenceSteps ();; 920 settings.cycle (progress, convText);; 921 ; 922 return testError;; 923 }; 924 ; 925 ; 926 ; 927/*! \brief execute a single training cycle; 928 *; 929 * uses multithreading if turned on; 930 *; 931 * \param minimizer the minimizer to be used (e.g. SGD); 932 * \param weights the weight container with all the synapse weights; 933 * \param itPatternBegin begin of the pattern container; 934 * \param itPatternEnd the end of the pattern ",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:27938,Testability,test,test,27938,"unt, testError);; 889 settings.plot (""trainErrors"", ""C"", 1, kBlue);; 890 settings.plot (""testErrors"", ""C"", 1, kMagenta);; 891 ; 892 ; 893 // setup error plots and progress bar variables for JsMVA; 894 if (fInteractive){; 895 fInteractive->AddPoint(cycleCount, trainError, testError);; 896 if (*fExitFromTraining) break;; 897 *fIPyCurrentIter = 100*(double)settings.maxConvergenceCount () /(double)settings.convergenceSteps ();; 898 }; 899 ; 900 if (hasConverged); 901 break;; 902 ; 903 if ((int)cycleCount % 10 == 0) {; 904 ; 905 TString convText = TString::Format( ""(train/test/epo/conv/maxco): %.3g/%.3g/%d/%d/%d"",; 906 trainError,; 907 testError,; 908 (int)cycleCount,; 909 (int)settings.convergenceCount (),; 910 (int)settings.maxConvergenceCount ());; 911 double progress = 100*(double)settings.maxConvergenceCount () /(double)settings.convergenceSteps ();; 912 settings.cycle (progress, convText);; 913 }; 914 }; 915 while (true);; 916 settings.endTrainCycle (trainError);; 917 ; 918 TString convText = TString::Format( ""(train/test/epoch): %.4g/%.4g/%d"", trainError, testError, (int)cycleCount);; 919 double progress = 100*(double)settings.maxConvergenceCount() /(double)settings.convergenceSteps ();; 920 settings.cycle (progress, convText);; 921 ; 922 return testError;; 923 }; 924 ; 925 ; 926 ; 927/*! \brief execute a single training cycle; 928 *; 929 * uses multithreading if turned on; 930 *; 931 * \param minimizer the minimizer to be used (e.g. SGD); 932 * \param weights the weight container with all the synapse weights; 933 * \param itPatternBegin begin of the pattern container; 934 * \param itPatternEnd the end of the pattern container; 935 * \param settings the settings for this training (e.g. multithreading or not, regularization, etc.); 936 * \param dropContainer the data for dropping-out nodes (regularization technique); 937 */; 938 template <typename Iterator, typename Minimizer>; 939 inline double Net::trainCycle (Minimizer& minimizer, std::vector<double>& weights,; ",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:27978,Testability,test,testError,27978,", ""C"", 1, kMagenta);; 891 ; 892 ; 893 // setup error plots and progress bar variables for JsMVA; 894 if (fInteractive){; 895 fInteractive->AddPoint(cycleCount, trainError, testError);; 896 if (*fExitFromTraining) break;; 897 *fIPyCurrentIter = 100*(double)settings.maxConvergenceCount () /(double)settings.convergenceSteps ();; 898 }; 899 ; 900 if (hasConverged); 901 break;; 902 ; 903 if ((int)cycleCount % 10 == 0) {; 904 ; 905 TString convText = TString::Format( ""(train/test/epo/conv/maxco): %.3g/%.3g/%d/%d/%d"",; 906 trainError,; 907 testError,; 908 (int)cycleCount,; 909 (int)settings.convergenceCount (),; 910 (int)settings.maxConvergenceCount ());; 911 double progress = 100*(double)settings.maxConvergenceCount () /(double)settings.convergenceSteps ();; 912 settings.cycle (progress, convText);; 913 }; 914 }; 915 while (true);; 916 settings.endTrainCycle (trainError);; 917 ; 918 TString convText = TString::Format( ""(train/test/epoch): %.4g/%.4g/%d"", trainError, testError, (int)cycleCount);; 919 double progress = 100*(double)settings.maxConvergenceCount() /(double)settings.convergenceSteps ();; 920 settings.cycle (progress, convText);; 921 ; 922 return testError;; 923 }; 924 ; 925 ; 926 ; 927/*! \brief execute a single training cycle; 928 *; 929 * uses multithreading if turned on; 930 *; 931 * \param minimizer the minimizer to be used (e.g. SGD); 932 * \param weights the weight container with all the synapse weights; 933 * \param itPatternBegin begin of the pattern container; 934 * \param itPatternEnd the end of the pattern container; 935 * \param settings the settings for this training (e.g. multithreading or not, regularization, etc.); 936 * \param dropContainer the data for dropping-out nodes (regularization technique); 937 */; 938 template <typename Iterator, typename Minimizer>; 939 inline double Net::trainCycle (Minimizer& minimizer, std::vector<double>& weights,; 940 Iterator itPatternBegin, Iterator itPatternEnd, Settings& settings, DropContainer& dropContainer)",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:28172,Testability,test,testError,28172,"er = 100*(double)settings.maxConvergenceCount () /(double)settings.convergenceSteps ();; 898 }; 899 ; 900 if (hasConverged); 901 break;; 902 ; 903 if ((int)cycleCount % 10 == 0) {; 904 ; 905 TString convText = TString::Format( ""(train/test/epo/conv/maxco): %.3g/%.3g/%d/%d/%d"",; 906 trainError,; 907 testError,; 908 (int)cycleCount,; 909 (int)settings.convergenceCount (),; 910 (int)settings.maxConvergenceCount ());; 911 double progress = 100*(double)settings.maxConvergenceCount () /(double)settings.convergenceSteps ();; 912 settings.cycle (progress, convText);; 913 }; 914 }; 915 while (true);; 916 settings.endTrainCycle (trainError);; 917 ; 918 TString convText = TString::Format( ""(train/test/epoch): %.4g/%.4g/%d"", trainError, testError, (int)cycleCount);; 919 double progress = 100*(double)settings.maxConvergenceCount() /(double)settings.convergenceSteps ();; 920 settings.cycle (progress, convText);; 921 ; 922 return testError;; 923 }; 924 ; 925 ; 926 ; 927/*! \brief execute a single training cycle; 928 *; 929 * uses multithreading if turned on; 930 *; 931 * \param minimizer the minimizer to be used (e.g. SGD); 932 * \param weights the weight container with all the synapse weights; 933 * \param itPatternBegin begin of the pattern container; 934 * \param itPatternEnd the end of the pattern container; 935 * \param settings the settings for this training (e.g. multithreading or not, regularization, etc.); 936 * \param dropContainer the data for dropping-out nodes (regularization technique); 937 */; 938 template <typename Iterator, typename Minimizer>; 939 inline double Net::trainCycle (Minimizer& minimizer, std::vector<double>& weights,; 940 Iterator itPatternBegin, Iterator itPatternEnd, Settings& settings, DropContainer& dropContainer); 941 {; 942 double error = 0.0;; 943 size_t numPattern = std::distance (itPatternBegin, itPatternEnd);; 944 size_t numBatches = numPattern/settings.batchSize ();; 945 size_t numBatches_stored = numBatches;; 946 ; 947 std::shuffle(itPatter",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:32046,Testability,test,testIteration,32046,"cond; it != itEnd; ++it); 997 {; 998 Batch& batch = *it;; 999 pass_through_type settingsAndBatch (settings, batch, dropContainer);; 1000 Minimizer minimizerClone (minimizer);; 1001 localError += minimizerClone ((*this), weights, settingsAndBatch); /// call the minimizer; 1002 }; 1003 return localError;; 1004 }); 1005 );; 1006 }; 1007 ; 1008 for (auto& f : futures); 1009 error += f.get ();; 1010 }; 1011 else; 1012 {; 1013 for (auto& batch : batches); 1014 {; 1015 std::tuple<Settings&, Batch&, DropContainer&> settingsAndBatch (settings, batch, dropContainer);; 1016 error += minimizer ((*this), weights, settingsAndBatch);; 1017 }; 1018 }; 1019 ; 1020 numBatches_stored = std::max (numBatches_stored, size_t(1)); /// normalize the error; 1021 error /= numBatches_stored;; 1022 settings.testIteration ();; 1023 ; 1024 return error;; 1025 }; 1026 ; 1027 ; 1028 ; 1029 ; 1030 ; 1031/*! \brief compute the neural net; 1032 *; 1033 * \param input the input data; 1034 * \param weights the weight data; 1035 */; 1036 template <typename Weights>; 1037 std::vector<double> Net::compute (const std::vector<double>& input, const Weights& weights) const; 1038 {; 1039 std::vector<LayerData> layerData;; 1040 layerData.reserve (m_layers.size ()+1);; 1041 auto itWeight = begin (weights);; 1042 auto itInputBegin = begin (input);; 1043 auto itInputEnd = end (input);; 1044 layerData.push_back (LayerData (itInputBegin, itInputEnd));; 1045 size_t numNodesPrev = input.size ();; 1046 ; 1047 // -------------------- prepare layer data with one pattern -------------------------------; 1048 for (auto& layer: m_layers); 1049 {; 1050 layerData.push_back (LayerData (layer.numNodes (), itWeight,; 1051 layer.activationFunction (),; 1052 layer.modeOutputValues ()));; 1053 size_t _numWeights = layer.numWeights (numNodesPrev);; 1054 itWeight += _numWeights;; 1055 numNodesPrev = layer.numNodes ();; 1056 }; 1057 ; 1058 ; 1059 // --------- forward -------------; 1060 forwardPattern (m_layers, layerData);; 1061 ; 1062",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:33688,Testability,assert,assert,33688,"o itInputBegin = begin (input);; 1043 auto itInputEnd = end (input);; 1044 layerData.push_back (LayerData (itInputBegin, itInputEnd));; 1045 size_t numNodesPrev = input.size ();; 1046 ; 1047 // -------------------- prepare layer data with one pattern -------------------------------; 1048 for (auto& layer: m_layers); 1049 {; 1050 layerData.push_back (LayerData (layer.numNodes (), itWeight,; 1051 layer.activationFunction (),; 1052 layer.modeOutputValues ()));; 1053 size_t _numWeights = layer.numWeights (numNodesPrev);; 1054 itWeight += _numWeights;; 1055 numNodesPrev = layer.numNodes ();; 1056 }; 1057 ; 1058 ; 1059 // --------- forward -------------; 1060 forwardPattern (m_layers, layerData);; 1061 ; 1062 // ------------- fetch output ------------------; 1063 std::vector<double> output;; 1064 fetchOutput (layerData.back (), output);; 1065 return output;; 1066 }; 1067 ; 1068 ; 1069 template <typename Weights, typename PassThrough>; 1070 double Net::operator() (PassThrough& settingsAndBatch, const Weights& weights) const; 1071 {; 1072 std::vector<double> nothing; // empty gradients; no backpropagation is done, just forward; 1073 assert (numWeights () == weights.size ());; 1074 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (nothing), std::end (nothing), 10000, nothing, false);; 1075 return error;; 1076 }; 1077 ; 1078 template <typename Weights, typename PassThrough, typename OutContainer>; 1079 double Net::operator() (PassThrough& settingsAndBatch, const Weights& weights, ModeOutput /*eFetch*/, OutContainer& outputContainer) const; 1080 {; 1081 std::vector<double> nothing; // empty gradients; no backpropagation is done, just forward; 1082 assert (numWeights () == weights.size ());; 1083 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (nothing), std::end (nothing), 10000, outputContainer, true);; 1084 return error;; 1085 }; 1086 ; 1087 ; 1088 ",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:34274,Testability,assert,assert,34274,"ize_t _numWeights = layer.numWeights (numNodesPrev);; 1054 itWeight += _numWeights;; 1055 numNodesPrev = layer.numNodes ();; 1056 }; 1057 ; 1058 ; 1059 // --------- forward -------------; 1060 forwardPattern (m_layers, layerData);; 1061 ; 1062 // ------------- fetch output ------------------; 1063 std::vector<double> output;; 1064 fetchOutput (layerData.back (), output);; 1065 return output;; 1066 }; 1067 ; 1068 ; 1069 template <typename Weights, typename PassThrough>; 1070 double Net::operator() (PassThrough& settingsAndBatch, const Weights& weights) const; 1071 {; 1072 std::vector<double> nothing; // empty gradients; no backpropagation is done, just forward; 1073 assert (numWeights () == weights.size ());; 1074 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (nothing), std::end (nothing), 10000, nothing, false);; 1075 return error;; 1076 }; 1077 ; 1078 template <typename Weights, typename PassThrough, typename OutContainer>; 1079 double Net::operator() (PassThrough& settingsAndBatch, const Weights& weights, ModeOutput /*eFetch*/, OutContainer& outputContainer) const; 1080 {; 1081 std::vector<double> nothing; // empty gradients; no backpropagation is done, just forward; 1082 assert (numWeights () == weights.size ());; 1083 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (nothing), std::end (nothing), 10000, outputContainer, true);; 1084 return error;; 1085 }; 1086 ; 1087 ; 1088 template <typename Weights, typename Gradients, typename PassThrough>; 1089 double Net::operator() (PassThrough& settingsAndBatch, Weights& weights, Gradients& gradients) const; 1090 {; 1091 std::vector<double> nothing;; 1092 assert (numWeights () == weights.size ());; 1093 assert (weights.size () == gradients.size ());; 1094 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (gradients), std::end (grad",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:34772,Testability,assert,assert,34772,"ights& weights) const; 1071 {; 1072 std::vector<double> nothing; // empty gradients; no backpropagation is done, just forward; 1073 assert (numWeights () == weights.size ());; 1074 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (nothing), std::end (nothing), 10000, nothing, false);; 1075 return error;; 1076 }; 1077 ; 1078 template <typename Weights, typename PassThrough, typename OutContainer>; 1079 double Net::operator() (PassThrough& settingsAndBatch, const Weights& weights, ModeOutput /*eFetch*/, OutContainer& outputContainer) const; 1080 {; 1081 std::vector<double> nothing; // empty gradients; no backpropagation is done, just forward; 1082 assert (numWeights () == weights.size ());; 1083 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (nothing), std::end (nothing), 10000, outputContainer, true);; 1084 return error;; 1085 }; 1086 ; 1087 ; 1088 template <typename Weights, typename Gradients, typename PassThrough>; 1089 double Net::operator() (PassThrough& settingsAndBatch, Weights& weights, Gradients& gradients) const; 1090 {; 1091 std::vector<double> nothing;; 1092 assert (numWeights () == weights.size ());; 1093 assert (weights.size () == gradients.size ());; 1094 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (gradients), std::end (gradients), 0, nothing, false);; 1095 return error;; 1096 }; 1097 ; 1098 template <typename Weights, typename Gradients, typename PassThrough, typename OutContainer>; 1099 double Net::operator() (PassThrough& settingsAndBatch, Weights& weights, Gradients& gradients, ModeOutput eFetch, OutContainer& outputContainer) const; 1100 {; 1101 MATH_UNUSED(eFetch);; 1102 assert (numWeights () == weights.size ());; 1103 assert (weights.size () == gradients.size ());; 1104 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights)",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:34821,Testability,assert,assert,34821,"d::end (weights), std::begin (nothing), std::end (nothing), 10000, nothing, false);; 1075 return error;; 1076 }; 1077 ; 1078 template <typename Weights, typename PassThrough, typename OutContainer>; 1079 double Net::operator() (PassThrough& settingsAndBatch, const Weights& weights, ModeOutput /*eFetch*/, OutContainer& outputContainer) const; 1080 {; 1081 std::vector<double> nothing; // empty gradients; no backpropagation is done, just forward; 1082 assert (numWeights () == weights.size ());; 1083 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (nothing), std::end (nothing), 10000, outputContainer, true);; 1084 return error;; 1085 }; 1086 ; 1087 ; 1088 template <typename Weights, typename Gradients, typename PassThrough>; 1089 double Net::operator() (PassThrough& settingsAndBatch, Weights& weights, Gradients& gradients) const; 1090 {; 1091 std::vector<double> nothing;; 1092 assert (numWeights () == weights.size ());; 1093 assert (weights.size () == gradients.size ());; 1094 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (gradients), std::end (gradients), 0, nothing, false);; 1095 return error;; 1096 }; 1097 ; 1098 template <typename Weights, typename Gradients, typename PassThrough, typename OutContainer>; 1099 double Net::operator() (PassThrough& settingsAndBatch, Weights& weights, Gradients& gradients, ModeOutput eFetch, OutContainer& outputContainer) const; 1100 {; 1101 MATH_UNUSED(eFetch);; 1102 assert (numWeights () == weights.size ());; 1103 assert (weights.size () == gradients.size ());; 1104 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (gradients), std::end (gradients), 0, outputContainer, true);; 1105 return error;; 1106 }; 1107 ; 1108 ; 1109 ; 1110 template <typename LayerContainer, typename DropContainer, typename ItWeight, typename ItGradient>; 1111 std::vecto",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:35374,Testability,assert,assert,35374,"ntainer& outputContainer) const; 1080 {; 1081 std::vector<double> nothing; // empty gradients; no backpropagation is done, just forward; 1082 assert (numWeights () == weights.size ());; 1083 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (nothing), std::end (nothing), 10000, outputContainer, true);; 1084 return error;; 1085 }; 1086 ; 1087 ; 1088 template <typename Weights, typename Gradients, typename PassThrough>; 1089 double Net::operator() (PassThrough& settingsAndBatch, Weights& weights, Gradients& gradients) const; 1090 {; 1091 std::vector<double> nothing;; 1092 assert (numWeights () == weights.size ());; 1093 assert (weights.size () == gradients.size ());; 1094 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (gradients), std::end (gradients), 0, nothing, false);; 1095 return error;; 1096 }; 1097 ; 1098 template <typename Weights, typename Gradients, typename PassThrough, typename OutContainer>; 1099 double Net::operator() (PassThrough& settingsAndBatch, Weights& weights, Gradients& gradients, ModeOutput eFetch, OutContainer& outputContainer) const; 1100 {; 1101 MATH_UNUSED(eFetch);; 1102 assert (numWeights () == weights.size ());; 1103 assert (weights.size () == gradients.size ());; 1104 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (gradients), std::end (gradients), 0, outputContainer, true);; 1105 return error;; 1106 }; 1107 ; 1108 ; 1109 ; 1110 template <typename LayerContainer, typename DropContainer, typename ItWeight, typename ItGradient>; 1111 std::vector<std::vector<LayerData>> Net::prepareLayerData (LayerContainer& _layers,; 1112 Batch& batch,; 1113 const DropContainer& dropContainer,; 1114 ItWeight itWeightBegin,; 1115 ItWeight /*itWeightEnd*/,; 1116 ItGradient itGradientBegin,; 1117 ItGradient itGradientEnd,; 1118 size_t& totalNumWeights) const; 1119 {; 11",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:35423,Testability,assert,assert,35423,", std::begin (nothing), std::end (nothing), 10000, outputContainer, true);; 1084 return error;; 1085 }; 1086 ; 1087 ; 1088 template <typename Weights, typename Gradients, typename PassThrough>; 1089 double Net::operator() (PassThrough& settingsAndBatch, Weights& weights, Gradients& gradients) const; 1090 {; 1091 std::vector<double> nothing;; 1092 assert (numWeights () == weights.size ());; 1093 assert (weights.size () == gradients.size ());; 1094 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (gradients), std::end (gradients), 0, nothing, false);; 1095 return error;; 1096 }; 1097 ; 1098 template <typename Weights, typename Gradients, typename PassThrough, typename OutContainer>; 1099 double Net::operator() (PassThrough& settingsAndBatch, Weights& weights, Gradients& gradients, ModeOutput eFetch, OutContainer& outputContainer) const; 1100 {; 1101 MATH_UNUSED(eFetch);; 1102 assert (numWeights () == weights.size ());; 1103 assert (weights.size () == gradients.size ());; 1104 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (gradients), std::end (gradients), 0, outputContainer, true);; 1105 return error;; 1106 }; 1107 ; 1108 ; 1109 ; 1110 template <typename LayerContainer, typename DropContainer, typename ItWeight, typename ItGradient>; 1111 std::vector<std::vector<LayerData>> Net::prepareLayerData (LayerContainer& _layers,; 1112 Batch& batch,; 1113 const DropContainer& dropContainer,; 1114 ItWeight itWeightBegin,; 1115 ItWeight /*itWeightEnd*/,; 1116 ItGradient itGradientBegin,; 1117 ItGradient itGradientEnd,; 1118 size_t& totalNumWeights) const; 1119 {; 1120 LayerData::const_dropout_iterator itDropOut;; 1121 bool usesDropOut = !dropContainer.empty ();; 1122 if (usesDropOut); 1123 itDropOut = std::begin (dropContainer);; 1124 ; 1125 if (_layers.empty ()); 1126 throw std::string (""no layers in this net"");; 1127 ; 1128 ; 1129 // ----------- cr",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:36512,Testability,assert,assert,36512,"ize ());; 1104 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (gradients), std::end (gradients), 0, outputContainer, true);; 1105 return error;; 1106 }; 1107 ; 1108 ; 1109 ; 1110 template <typename LayerContainer, typename DropContainer, typename ItWeight, typename ItGradient>; 1111 std::vector<std::vector<LayerData>> Net::prepareLayerData (LayerContainer& _layers,; 1112 Batch& batch,; 1113 const DropContainer& dropContainer,; 1114 ItWeight itWeightBegin,; 1115 ItWeight /*itWeightEnd*/,; 1116 ItGradient itGradientBegin,; 1117 ItGradient itGradientEnd,; 1118 size_t& totalNumWeights) const; 1119 {; 1120 LayerData::const_dropout_iterator itDropOut;; 1121 bool usesDropOut = !dropContainer.empty ();; 1122 if (usesDropOut); 1123 itDropOut = std::begin (dropContainer);; 1124 ; 1125 if (_layers.empty ()); 1126 throw std::string (""no layers in this net"");; 1127 ; 1128 ; 1129 // ----------- create layer data -------------------------------------------------------; 1130 //LM- This assert not needed anymore (outputsize is actually numNodes+1); 1131 //assert (_layers.back ().numNodes () == outputSize ());; 1132 totalNumWeights = 0;; 1133 std::vector<std::vector<LayerData>> layerPatternData;; 1134 layerPatternData.reserve (_layers.size ()+1);; 1135 ItWeight itWeight = itWeightBegin;; 1136 ItGradient itGradient = itGradientBegin;; 1137 size_t numNodesPrev = inputSize ();; 1138 typename Pattern::const_iterator itInputBegin;; 1139 typename Pattern::const_iterator itInputEnd;; 1140 ; 1141 // ItWeight itGammaBegin = itWeightBegin + numWeights ();; 1142 // ItWeight itBetaBegin = itWeightBegin + numWeights () + numNodes ();; 1143 // ItGradient itGradGammaBegin = itGradientBegin + numWeights ();; 1144 // ItGradient itGradBetaBegin = itGradientBegin + numWeights () + numNodes ();; 1145 ; 1146 ; 1147 // --------------------- prepare layer data for input layer ----------------------------; 1148 layerPatternData.push_back (std:",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:36582,Testability,assert,assert,36582,"ize ());; 1104 double error = forward_backward(m_layers, settingsAndBatch, std::begin (weights), std::end (weights), std::begin (gradients), std::end (gradients), 0, outputContainer, true);; 1105 return error;; 1106 }; 1107 ; 1108 ; 1109 ; 1110 template <typename LayerContainer, typename DropContainer, typename ItWeight, typename ItGradient>; 1111 std::vector<std::vector<LayerData>> Net::prepareLayerData (LayerContainer& _layers,; 1112 Batch& batch,; 1113 const DropContainer& dropContainer,; 1114 ItWeight itWeightBegin,; 1115 ItWeight /*itWeightEnd*/,; 1116 ItGradient itGradientBegin,; 1117 ItGradient itGradientEnd,; 1118 size_t& totalNumWeights) const; 1119 {; 1120 LayerData::const_dropout_iterator itDropOut;; 1121 bool usesDropOut = !dropContainer.empty ();; 1122 if (usesDropOut); 1123 itDropOut = std::begin (dropContainer);; 1124 ; 1125 if (_layers.empty ()); 1126 throw std::string (""no layers in this net"");; 1127 ; 1128 ; 1129 // ----------- create layer data -------------------------------------------------------; 1130 //LM- This assert not needed anymore (outputsize is actually numNodes+1); 1131 //assert (_layers.back ().numNodes () == outputSize ());; 1132 totalNumWeights = 0;; 1133 std::vector<std::vector<LayerData>> layerPatternData;; 1134 layerPatternData.reserve (_layers.size ()+1);; 1135 ItWeight itWeight = itWeightBegin;; 1136 ItGradient itGradient = itGradientBegin;; 1137 size_t numNodesPrev = inputSize ();; 1138 typename Pattern::const_iterator itInputBegin;; 1139 typename Pattern::const_iterator itInputEnd;; 1140 ; 1141 // ItWeight itGammaBegin = itWeightBegin + numWeights ();; 1142 // ItWeight itBetaBegin = itWeightBegin + numWeights () + numNodes ();; 1143 // ItGradient itGradGammaBegin = itGradientBegin + numWeights ();; 1144 // ItGradient itGradBetaBegin = itGradientBegin + numWeights () + numNodes ();; 1145 ; 1146 ; 1147 // --------------------- prepare layer data for input layer ----------------------------; 1148 layerPatternData.push_back (std:",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:39516,Testability,assert,assert,39516,"ck (LayerData (numNodesPrev));; 1181 ; 1182 if (itGradientBegin == itGradientEnd); 1183 {; 1184 layerData.push_back (LayerData (layer.numNodes (), itWeight,; 1185 layer.activationFunction (),; 1186 layer.modeOutputValues ()));; 1187 }; 1188 else; 1189 {; 1190 layerData.push_back (LayerData (layer.numNodes (), itWeight, itGradient,; 1191 layer.activationFunction (),; 1192 layer.inverseActivationFunction (),; 1193 layer.modeOutputValues ()));; 1194 }; 1195 ; 1196 if (usesDropOut); 1197 {; 1198 layerData.back ().setDropOut (itDropOut);; 1199 }; 1200 ; 1201 }; 1202 ; 1203 if (usesDropOut); 1204 {; 1205 itDropOut += layer.numNodes ();; 1206 }; 1207 size_t _numWeights = layer.numWeights (numNodesPrev);; 1208 totalNumWeights += _numWeights;; 1209 itWeight += _numWeights;; 1210 itGradient += _numWeights;; 1211 numNodesPrev = layer.numNodes ();; 1212 ; 1213 }; 1214 assert (totalNumWeights > 0);; 1215 return layerPatternData;; 1216}; 1217 ; 1218 ; 1219 ; 1220 template <typename LayerContainer>; 1221 void Net::forwardPattern (const LayerContainer& _layers,; 1222 std::vector<LayerData>& layerData) const; 1223 {; 1224 size_t idxLayer = 0, idxLayerEnd = _layers.size ();; 1225 for (; idxLayer < idxLayerEnd; ++idxLayer); 1226 {; 1227 LayerData& prevLayerData = layerData.at (idxLayer);; 1228 LayerData& currLayerData = layerData.at (idxLayer+1);; 1229 ; 1230 forward (prevLayerData, currLayerData);; 1231 ; 1232 applyFunctions (currLayerData.valuesBegin (), currLayerData.valuesEnd (), currLayerData.activationFunction ());; 1233 }; 1234 }; 1235 ; 1236 ; 1237 ; 1238 ; 1239 template <typename LayerContainer, typename LayerPatternContainer>; 1240 void Net::forwardBatch (const LayerContainer& _layers,; 1241 LayerPatternContainer& layerPatternData,; 1242 std::vector<double>& valuesMean,; 1243 std::vector<double>& valuesStdDev,; 1244 size_t trainFromLayer) const; 1245 {; 1246 valuesMean.clear ();; 1247 valuesStdDev.clear ();; 1248 ; 1249 // ---------------------------------- loop over layers a",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:43226,Testability,assert,assert,43226,"d Net::fetchOutput (const LayerData& lastLayerData, OutputContainer& outputContainer) const; 1292 {; 1293 ModeOutputValues eModeOutput = lastLayerData.outputMode ();; 1294 if (isFlagSet (ModeOutputValues::DIRECT, eModeOutput)); 1295 {; 1296 outputContainer.insert (outputContainer.end (), lastLayerData.valuesBegin (), lastLayerData.valuesEnd ());; 1297 }; 1298 else if (isFlagSet (ModeOutputValues::SIGMOID, eModeOutput) ||; 1299 isFlagSet (ModeOutputValues::SOFTMAX, eModeOutput)); 1300 {; 1301 const auto& prob = lastLayerData.probabilities ();; 1302 outputContainer.insert (outputContainer.end (), prob.begin (), prob.end ()) ;; 1303 }; 1304 else; 1305 assert (false);; 1306 }; 1307 ; 1308 ; 1309 ; 1310 ; 1311 template <typename OutputContainer>; 1312 void Net::fetchOutput (const std::vector<LayerData>& lastLayerPatternData, OutputContainer& outputContainer) const; 1313 {; 1314 for (const LayerData& lastLayerData : lastLayerPatternData); 1315 fetchOutput (lastLayerData, outputContainer);; 1316 }; 1317 ; 1318 ; 1319 ; 1320 template <typename ItWeight>; 1321 std::tuple</*sumError*/double,/*sumWeights*/double> Net::computeError (const Settings& settings,; 1322 std::vector<LayerData>& lastLayerData,; 1323 Batch& batch,; 1324 ItWeight itWeightBegin,; 1325 ItWeight itWeightEnd) const; 1326 {; 1327 typename std::vector<LayerData>::iterator itLayerData = lastLayerData.begin ();; 1328// typename std::vector<LayerData>::iterator itLayerDataEnd = lastLayerData.end ();; 1329 ; 1330 typename std::vector<Pattern>::const_iterator itPattern = batch.begin ();; 1331 typename std::vector<Pattern>::const_iterator itPatternEnd = batch.end ();; 1332 ; 1333 double sumWeights (0.0);; 1334 double sumError (0.0);; 1335 ; 1336// FIXME: check that iteration doesn't go beyond itLayerDataEnd!; 1337 for ( ; itPattern != itPatternEnd; ++itPattern, ++itLayerData); 1338 {; 1339 // compute E and the deltas of the computed output and the true output; 1340 LayerData& layerData = (*itLayerData);; 1341 const ",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:52944,Testability,assert,assert,52944,"60 (*itWeight) = DNN::gaussDouble (0.0, sqrt (layer.numWeights (nIn))); // factor 2.0 for ReLU; 1561 ++itWeight;; 1562 }; 1563 numInput = layer.numNodes ();; 1564 }; 1565 return;; 1566 }; 1567 ; 1568 }; 1569 ; 1570 ; 1571 ; 1572 ; 1573 ; 1574/*! \brief compute the error function; 1575 *; 1576 *; 1577 */; 1578 template <typename Container, typename ItWeight>; 1579 double Net::errorFunction (LayerData& layerData,; 1580 Container truth,; 1581 ItWeight itWeight,; 1582 ItWeight itWeightEnd,; 1583 double patternWeight,; 1584 double factorWeightDecay,; 1585 EnumRegularization eRegularization) const; 1586 {; 1587 double error (0);; 1588 switch (m_eErrorFunction); 1589 {; 1590 case ModeErrorFunction::SUMOFSQUARES:; 1591 {; 1592 error = sumOfSquares (layerData.valuesBegin (), layerData.valuesEnd (), begin (truth), end (truth),; 1593 layerData.deltasBegin (), layerData.deltasEnd (),; 1594 layerData.inverseActivationFunction (),; 1595 patternWeight);; 1596 break;; 1597 }; 1598 case ModeErrorFunction::CROSSENTROPY:; 1599 {; 1600 assert (!TMVA::DNN::isFlagSet (ModeOutputValues::DIRECT, layerData.outputMode ()));; 1601 std::vector<double> probabilities = layerData.probabilities ();; 1602 error = crossEntropy (begin (probabilities), end (probabilities),; 1603 begin (truth), end (truth),; 1604 layerData.deltasBegin (), layerData.deltasEnd (),; 1605 layerData.inverseActivationFunction (),; 1606 patternWeight);; 1607 break;; 1608 }; 1609 case ModeErrorFunction::CROSSENTROPY_MUTUALEXCLUSIVE:; 1610 {; 1611 std::cout << ""softmax."" << std::endl;; 1612 assert (!TMVA::DNN::isFlagSet (ModeOutputValues::DIRECT, layerData.outputMode ()));; 1613 std::vector<double> probabilities = layerData.probabilities ();; 1614 error = softMaxCrossEntropy (begin (probabilities), end (probabilities),; 1615 begin (truth), end (truth),; 1616 layerData.deltasBegin (), layerData.deltasEnd (),; 1617 layerData.inverseActivationFunction (),; 1618 patternWeight);; 1619 break;; 1620 }; 1621 }; 1622 if (factorWeightDec",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:53467,Testability,assert,assert,53467,"Regularization) const; 1586 {; 1587 double error (0);; 1588 switch (m_eErrorFunction); 1589 {; 1590 case ModeErrorFunction::SUMOFSQUARES:; 1591 {; 1592 error = sumOfSquares (layerData.valuesBegin (), layerData.valuesEnd (), begin (truth), end (truth),; 1593 layerData.deltasBegin (), layerData.deltasEnd (),; 1594 layerData.inverseActivationFunction (),; 1595 patternWeight);; 1596 break;; 1597 }; 1598 case ModeErrorFunction::CROSSENTROPY:; 1599 {; 1600 assert (!TMVA::DNN::isFlagSet (ModeOutputValues::DIRECT, layerData.outputMode ()));; 1601 std::vector<double> probabilities = layerData.probabilities ();; 1602 error = crossEntropy (begin (probabilities), end (probabilities),; 1603 begin (truth), end (truth),; 1604 layerData.deltasBegin (), layerData.deltasEnd (),; 1605 layerData.inverseActivationFunction (),; 1606 patternWeight);; 1607 break;; 1608 }; 1609 case ModeErrorFunction::CROSSENTROPY_MUTUALEXCLUSIVE:; 1610 {; 1611 std::cout << ""softmax."" << std::endl;; 1612 assert (!TMVA::DNN::isFlagSet (ModeOutputValues::DIRECT, layerData.outputMode ()));; 1613 std::vector<double> probabilities = layerData.probabilities ();; 1614 error = softMaxCrossEntropy (begin (probabilities), end (probabilities),; 1615 begin (truth), end (truth),; 1616 layerData.deltasBegin (), layerData.deltasEnd (),; 1617 layerData.inverseActivationFunction (),; 1618 patternWeight);; 1619 break;; 1620 }; 1621 }; 1622 if (factorWeightDecay != 0 && eRegularization != EnumRegularization::NONE); 1623 {; 1624 error = weightDecay (error, itWeight, itWeightEnd, factorWeightDecay, eRegularization);; 1625 }; 1626 return error;; 1627 }; 1628 ; 1629 ; 1630 ; 1631 ; 1632 ; 1633 ; 1634 ; 1635// /*! \brief pre-training; 1636// *; 1637// * in development; 1638// */; 1639// template <typename Minimizer>; 1640// void Net::preTrain (std::vector<double>& weights,; 1641// std::vector<Pattern>& trainPattern,; 1642// const std::vector<Pattern>& testPattern,; 1643// Minimizer& minimizer, Settings& settings); 1644// {; 1645// ",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:54409,Testability,test,testPattern,54409,"h),; 1604 layerData.deltasBegin (), layerData.deltasEnd (),; 1605 layerData.inverseActivationFunction (),; 1606 patternWeight);; 1607 break;; 1608 }; 1609 case ModeErrorFunction::CROSSENTROPY_MUTUALEXCLUSIVE:; 1610 {; 1611 std::cout << ""softmax."" << std::endl;; 1612 assert (!TMVA::DNN::isFlagSet (ModeOutputValues::DIRECT, layerData.outputMode ()));; 1613 std::vector<double> probabilities = layerData.probabilities ();; 1614 error = softMaxCrossEntropy (begin (probabilities), end (probabilities),; 1615 begin (truth), end (truth),; 1616 layerData.deltasBegin (), layerData.deltasEnd (),; 1617 layerData.inverseActivationFunction (),; 1618 patternWeight);; 1619 break;; 1620 }; 1621 }; 1622 if (factorWeightDecay != 0 && eRegularization != EnumRegularization::NONE); 1623 {; 1624 error = weightDecay (error, itWeight, itWeightEnd, factorWeightDecay, eRegularization);; 1625 }; 1626 return error;; 1627 }; 1628 ; 1629 ; 1630 ; 1631 ; 1632 ; 1633 ; 1634 ; 1635// /*! \brief pre-training; 1636// *; 1637// * in development; 1638// */; 1639// template <typename Minimizer>; 1640// void Net::preTrain (std::vector<double>& weights,; 1641// std::vector<Pattern>& trainPattern,; 1642// const std::vector<Pattern>& testPattern,; 1643// Minimizer& minimizer, Settings& settings); 1644// {; 1645// auto itWeightGeneral = std::begin (weights);; 1646// std::vector<Pattern> prePatternTrain (trainPattern.size ());; 1647// std::vector<Pattern> prePatternTest (testPattern.size ());; 1648 ; 1649// size_t _inputSize = inputSize ();; 1650 ; 1651// // transform pattern using the created preNet; 1652// auto initializePrePattern = [&](const std::vector<Pattern>& pttrnInput, std::vector<Pattern>& pttrnOutput); 1653// {; 1654// pttrnOutput.clear ();; 1655// std::transform (std::begin (pttrnInput), std::end (pttrnInput),; 1656// std::back_inserter (pttrnOutput),; 1657// [](const Pattern& p); 1658// {; 1659// Pattern pat (p.input (), p.input (), p.weight ());; 1660// return pat;; 1661// });; 1662// };; 1663 ; 1",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:54649,Testability,test,testPattern,54649,"error = softMaxCrossEntropy (begin (probabilities), end (probabilities),; 1615 begin (truth), end (truth),; 1616 layerData.deltasBegin (), layerData.deltasEnd (),; 1617 layerData.inverseActivationFunction (),; 1618 patternWeight);; 1619 break;; 1620 }; 1621 }; 1622 if (factorWeightDecay != 0 && eRegularization != EnumRegularization::NONE); 1623 {; 1624 error = weightDecay (error, itWeight, itWeightEnd, factorWeightDecay, eRegularization);; 1625 }; 1626 return error;; 1627 }; 1628 ; 1629 ; 1630 ; 1631 ; 1632 ; 1633 ; 1634 ; 1635// /*! \brief pre-training; 1636// *; 1637// * in development; 1638// */; 1639// template <typename Minimizer>; 1640// void Net::preTrain (std::vector<double>& weights,; 1641// std::vector<Pattern>& trainPattern,; 1642// const std::vector<Pattern>& testPattern,; 1643// Minimizer& minimizer, Settings& settings); 1644// {; 1645// auto itWeightGeneral = std::begin (weights);; 1646// std::vector<Pattern> prePatternTrain (trainPattern.size ());; 1647// std::vector<Pattern> prePatternTest (testPattern.size ());; 1648 ; 1649// size_t _inputSize = inputSize ();; 1650 ; 1651// // transform pattern using the created preNet; 1652// auto initializePrePattern = [&](const std::vector<Pattern>& pttrnInput, std::vector<Pattern>& pttrnOutput); 1653// {; 1654// pttrnOutput.clear ();; 1655// std::transform (std::begin (pttrnInput), std::end (pttrnInput),; 1656// std::back_inserter (pttrnOutput),; 1657// [](const Pattern& p); 1658// {; 1659// Pattern pat (p.input (), p.input (), p.weight ());; 1660// return pat;; 1661// });; 1662// };; 1663 ; 1664// initializePrePattern (trainPattern, prePatternTrain);; 1665// initializePrePattern (testPattern, prePatternTest);; 1666 ; 1667// std::vector<double> originalDropFractions = settings.dropFractions ();; 1668 ; 1669// for (auto& _layer : layers ()); 1670// {; 1671// // compute number of weights (as a function of the number of incoming nodes); 1672// // fetch number of nodes; 1673// size_t numNodes = _layer.numNodes ();; 1",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:55290,Testability,test,testPattern,55290,"nimizer>; 1640// void Net::preTrain (std::vector<double>& weights,; 1641// std::vector<Pattern>& trainPattern,; 1642// const std::vector<Pattern>& testPattern,; 1643// Minimizer& minimizer, Settings& settings); 1644// {; 1645// auto itWeightGeneral = std::begin (weights);; 1646// std::vector<Pattern> prePatternTrain (trainPattern.size ());; 1647// std::vector<Pattern> prePatternTest (testPattern.size ());; 1648 ; 1649// size_t _inputSize = inputSize ();; 1650 ; 1651// // transform pattern using the created preNet; 1652// auto initializePrePattern = [&](const std::vector<Pattern>& pttrnInput, std::vector<Pattern>& pttrnOutput); 1653// {; 1654// pttrnOutput.clear ();; 1655// std::transform (std::begin (pttrnInput), std::end (pttrnInput),; 1656// std::back_inserter (pttrnOutput),; 1657// [](const Pattern& p); 1658// {; 1659// Pattern pat (p.input (), p.input (), p.weight ());; 1660// return pat;; 1661// });; 1662// };; 1663 ; 1664// initializePrePattern (trainPattern, prePatternTrain);; 1665// initializePrePattern (testPattern, prePatternTest);; 1666 ; 1667// std::vector<double> originalDropFractions = settings.dropFractions ();; 1668 ; 1669// for (auto& _layer : layers ()); 1670// {; 1671// // compute number of weights (as a function of the number of incoming nodes); 1672// // fetch number of nodes; 1673// size_t numNodes = _layer.numNodes ();; 1674// size_t _numWeights = _layer.numWeights (_inputSize);; 1675 ; 1676// // ------------------; 1677// DNN::Net preNet;; 1678// if (!originalDropFractions.empty ()); 1679// {; 1680// originalDropFractions.erase (originalDropFractions.begin ());; 1681// settings.setDropOut (originalDropFractions.begin (), originalDropFractions.end (), settings.dropRepetitions ());; 1682// }; 1683// std::vector<double> preWeights;; 1684 ; 1685// // define the preNet (pretraining-net) for this layer; 1686// // outputSize == inputSize, because this is an autoencoder;; 1687// preNet.setInputSize (_inputSize);; 1688// preNet.addLayer (DNN::Layer (n",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:63429,Testability,test,testPattern,63429,"t trainFromLayer) constDefinition NeuralNet.icc:1240; TMVA::DNN::Net::fExitFromTrainingbool * fExitFromTrainingDefinition NeuralNet.h:1277; TMVA::DNN::Net::m_layersstd::vector< Layer > m_layerslayer-structure-dataDefinition NeuralNet.h:1272; TMVA::DNN::Net::fIPyMaxIterUInt_t * fIPyMaxIterDefinition NeuralNet.h:1278; TMVA::DNN::Net::computestd::vector< double > compute(const std::vector< double > &input, const Weights &weights) constcompute the net with the given input and the given weightsDefinition NeuralNet.icc:1037; TMVA::DNN::Net::fetchOutputvoid fetchOutput(const LayerData &lastLayerData, OutputContainer &outputContainer) constDefinition NeuralNet.icc:1291; TMVA::DNN::Net::inputSizesize_t inputSize() constinput size of the DNNDefinition NeuralNet.h:1098; TMVA::DNN::Net::m_eErrorFunctionModeErrorFunction m_eErrorFunctiondenotes the error functionDefinition NeuralNet.h:1269; TMVA::DNN::Net::traindouble train(std::vector< double > &weights, std::vector< Pattern > &trainPattern, const std::vector< Pattern > &testPattern, Minimizer &minimizer, Settings &settings)start the trainingDefinition NeuralNet.icc:712; TMVA::DNN::Net::layersconst std::vector< Layer > & layers() constreturns the layers (structure)Definition NeuralNet.h:1245; TMVA::DNN::Net::prepareLayerDatastd::vector< std::vector< LayerData > > prepareLayerData(LayerContainer &layers, Batch &batch, const DropContainer &dropContainer, ItWeight itWeightBegin, ItWeight itWeightEnd, ItGradient itGradientBegin, ItGradient itGradientEnd, size_t &totalNumWeights) constDefinition NeuralNet.icc:1111; TMVA::DNN::Net::initializeWeightsvoid initializeWeights(WeightInitializationStrategy eInitStrategy, OutIterator itWeight)initialize the weights with the given strategyDefinition NeuralNet.icc:1470; TMVA::DNN::Net::outputSizesize_t outputSize() constoutput size of the DNNDefinition NeuralNet.h:1099; TMVA::DNN::Net::errorFunctiondouble errorFunction(LayerData &layerData, Container truth, ItWeight itWeight, ItWeight itWeightE",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:67290,Testability,test,testRepetitions,67290,"ight itWeightBegin, ItWeight itWeightEnd) constDefinition NeuralNet.icc:1321; TMVA::DNN::Net::forwardPatternvoid forwardPattern(const LayerContainer &_layers, std::vector< LayerData > &layerData) constDefinition NeuralNet.icc:1221; TMVA::DNN::Net::backPropagatevoid backPropagate(std::vector< std::vector< LayerData > > &layerPatternData, const Settings &settings, size_t trainFromLayer, size_t totalNumWeights) constDefinition NeuralNet.icc:1355; TMVA::DNN::SettingsSettings for the training of the neural net.Definition NeuralNet.h:730; TMVA::DNN::Settings::useMultithreadingbool useMultithreading() constis multithreading turned on?Definition NeuralNet.h:815; TMVA::DNN::Settings::regularizationEnumRegularization regularization() constsome regularization of the DNN is turned on?Definition NeuralNet.h:813; TMVA::DNN::Settings::convergenceCountsize_t convergenceCount() constreturns the current convergence countDefinition NeuralNet.h:827; TMVA::DNN::Settings::testRepetitionssize_t testRepetitions() consthow often is the test data testedDefinition NeuralNet.h:768; TMVA::DNN::Settings::endTestCyclevirtual void endTestCycle()callback for monitoring and logggingDefinition NeuralNet.h:805; TMVA::DNN::Settings::testIterationvirtual void testIteration()callback for monitoring and logggingDefinition NeuralNet.h:806; TMVA::DNN::Settings::hasConvergedvirtual bool hasConverged(double testError)has this training converged already?Definition NeuralNet.cxx:485; TMVA::DNN::Settings::cyclevirtual void cycle(double progress, TString text)Definition NeuralNet.h:799; TMVA::DNN::Settings::endTrainCyclevirtual void endTrainCycle(double)callback for monitoring and loggingDefinition NeuralNet.h:788; TMVA::DNN::Settings::dropFractionsconst std::vector< double > & dropFractions() constDefinition NeuralNet.h:762; TMVA::DNN::Settings::addPointvoid addPoint(std::string histoName, double x)for monitoringDefinition NeuralNet.h:821; TMVA::DNN::Settings::testSamplevirtual void testSample(double, double, dou",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:67330,Testability,test,test,67330,"ight itWeightBegin, ItWeight itWeightEnd) constDefinition NeuralNet.icc:1321; TMVA::DNN::Net::forwardPatternvoid forwardPattern(const LayerContainer &_layers, std::vector< LayerData > &layerData) constDefinition NeuralNet.icc:1221; TMVA::DNN::Net::backPropagatevoid backPropagate(std::vector< std::vector< LayerData > > &layerPatternData, const Settings &settings, size_t trainFromLayer, size_t totalNumWeights) constDefinition NeuralNet.icc:1355; TMVA::DNN::SettingsSettings for the training of the neural net.Definition NeuralNet.h:730; TMVA::DNN::Settings::useMultithreadingbool useMultithreading() constis multithreading turned on?Definition NeuralNet.h:815; TMVA::DNN::Settings::regularizationEnumRegularization regularization() constsome regularization of the DNN is turned on?Definition NeuralNet.h:813; TMVA::DNN::Settings::convergenceCountsize_t convergenceCount() constreturns the current convergence countDefinition NeuralNet.h:827; TMVA::DNN::Settings::testRepetitionssize_t testRepetitions() consthow often is the test data testedDefinition NeuralNet.h:768; TMVA::DNN::Settings::endTestCyclevirtual void endTestCycle()callback for monitoring and logggingDefinition NeuralNet.h:805; TMVA::DNN::Settings::testIterationvirtual void testIteration()callback for monitoring and logggingDefinition NeuralNet.h:806; TMVA::DNN::Settings::hasConvergedvirtual bool hasConverged(double testError)has this training converged already?Definition NeuralNet.cxx:485; TMVA::DNN::Settings::cyclevirtual void cycle(double progress, TString text)Definition NeuralNet.h:799; TMVA::DNN::Settings::endTrainCyclevirtual void endTrainCycle(double)callback for monitoring and loggingDefinition NeuralNet.h:788; TMVA::DNN::Settings::dropFractionsconst std::vector< double > & dropFractions() constDefinition NeuralNet.h:762; TMVA::DNN::Settings::addPointvoid addPoint(std::string histoName, double x)for monitoringDefinition NeuralNet.h:821; TMVA::DNN::Settings::testSamplevirtual void testSample(double, double, dou",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:67340,Testability,test,testedDefinition,67340,"ight itWeightBegin, ItWeight itWeightEnd) constDefinition NeuralNet.icc:1321; TMVA::DNN::Net::forwardPatternvoid forwardPattern(const LayerContainer &_layers, std::vector< LayerData > &layerData) constDefinition NeuralNet.icc:1221; TMVA::DNN::Net::backPropagatevoid backPropagate(std::vector< std::vector< LayerData > > &layerPatternData, const Settings &settings, size_t trainFromLayer, size_t totalNumWeights) constDefinition NeuralNet.icc:1355; TMVA::DNN::SettingsSettings for the training of the neural net.Definition NeuralNet.h:730; TMVA::DNN::Settings::useMultithreadingbool useMultithreading() constis multithreading turned on?Definition NeuralNet.h:815; TMVA::DNN::Settings::regularizationEnumRegularization regularization() constsome regularization of the DNN is turned on?Definition NeuralNet.h:813; TMVA::DNN::Settings::convergenceCountsize_t convergenceCount() constreturns the current convergence countDefinition NeuralNet.h:827; TMVA::DNN::Settings::testRepetitionssize_t testRepetitions() consthow often is the test data testedDefinition NeuralNet.h:768; TMVA::DNN::Settings::endTestCyclevirtual void endTestCycle()callback for monitoring and logggingDefinition NeuralNet.h:805; TMVA::DNN::Settings::testIterationvirtual void testIteration()callback for monitoring and logggingDefinition NeuralNet.h:806; TMVA::DNN::Settings::hasConvergedvirtual bool hasConverged(double testError)has this training converged already?Definition NeuralNet.cxx:485; TMVA::DNN::Settings::cyclevirtual void cycle(double progress, TString text)Definition NeuralNet.h:799; TMVA::DNN::Settings::endTrainCyclevirtual void endTrainCycle(double)callback for monitoring and loggingDefinition NeuralNet.h:788; TMVA::DNN::Settings::dropFractionsconst std::vector< double > & dropFractions() constDefinition NeuralNet.h:762; TMVA::DNN::Settings::addPointvoid addPoint(std::string histoName, double x)for monitoringDefinition NeuralNet.h:821; TMVA::DNN::Settings::testSamplevirtual void testSample(double, double, dou",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:67462,Testability,log,logggingDefinition,67462,"n(const LayerContainer &_layers, std::vector< LayerData > &layerData) constDefinition NeuralNet.icc:1221; TMVA::DNN::Net::backPropagatevoid backPropagate(std::vector< std::vector< LayerData > > &layerPatternData, const Settings &settings, size_t trainFromLayer, size_t totalNumWeights) constDefinition NeuralNet.icc:1355; TMVA::DNN::SettingsSettings for the training of the neural net.Definition NeuralNet.h:730; TMVA::DNN::Settings::useMultithreadingbool useMultithreading() constis multithreading turned on?Definition NeuralNet.h:815; TMVA::DNN::Settings::regularizationEnumRegularization regularization() constsome regularization of the DNN is turned on?Definition NeuralNet.h:813; TMVA::DNN::Settings::convergenceCountsize_t convergenceCount() constreturns the current convergence countDefinition NeuralNet.h:827; TMVA::DNN::Settings::testRepetitionssize_t testRepetitions() consthow often is the test data testedDefinition NeuralNet.h:768; TMVA::DNN::Settings::endTestCyclevirtual void endTestCycle()callback for monitoring and logggingDefinition NeuralNet.h:805; TMVA::DNN::Settings::testIterationvirtual void testIteration()callback for monitoring and logggingDefinition NeuralNet.h:806; TMVA::DNN::Settings::hasConvergedvirtual bool hasConverged(double testError)has this training converged already?Definition NeuralNet.cxx:485; TMVA::DNN::Settings::cyclevirtual void cycle(double progress, TString text)Definition NeuralNet.h:799; TMVA::DNN::Settings::endTrainCyclevirtual void endTrainCycle(double)callback for monitoring and loggingDefinition NeuralNet.h:788; TMVA::DNN::Settings::dropFractionsconst std::vector< double > & dropFractions() constDefinition NeuralNet.h:762; TMVA::DNN::Settings::addPointvoid addPoint(std::string histoName, double x)for monitoringDefinition NeuralNet.h:821; TMVA::DNN::Settings::testSamplevirtual void testSample(double, double, double, double)virtual function to be used for monitoring (callback)Definition NeuralNet.h:781; TMVA::DNN::Settings::plotvoid pl",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:67519,Testability,test,testIterationvirtual,67519,"kPropagatevoid backPropagate(std::vector< std::vector< LayerData > > &layerPatternData, const Settings &settings, size_t trainFromLayer, size_t totalNumWeights) constDefinition NeuralNet.icc:1355; TMVA::DNN::SettingsSettings for the training of the neural net.Definition NeuralNet.h:730; TMVA::DNN::Settings::useMultithreadingbool useMultithreading() constis multithreading turned on?Definition NeuralNet.h:815; TMVA::DNN::Settings::regularizationEnumRegularization regularization() constsome regularization of the DNN is turned on?Definition NeuralNet.h:813; TMVA::DNN::Settings::convergenceCountsize_t convergenceCount() constreturns the current convergence countDefinition NeuralNet.h:827; TMVA::DNN::Settings::testRepetitionssize_t testRepetitions() consthow often is the test data testedDefinition NeuralNet.h:768; TMVA::DNN::Settings::endTestCyclevirtual void endTestCycle()callback for monitoring and logggingDefinition NeuralNet.h:805; TMVA::DNN::Settings::testIterationvirtual void testIteration()callback for monitoring and logggingDefinition NeuralNet.h:806; TMVA::DNN::Settings::hasConvergedvirtual bool hasConverged(double testError)has this training converged already?Definition NeuralNet.cxx:485; TMVA::DNN::Settings::cyclevirtual void cycle(double progress, TString text)Definition NeuralNet.h:799; TMVA::DNN::Settings::endTrainCyclevirtual void endTrainCycle(double)callback for monitoring and loggingDefinition NeuralNet.h:788; TMVA::DNN::Settings::dropFractionsconst std::vector< double > & dropFractions() constDefinition NeuralNet.h:762; TMVA::DNN::Settings::addPointvoid addPoint(std::string histoName, double x)for monitoringDefinition NeuralNet.h:821; TMVA::DNN::Settings::testSamplevirtual void testSample(double, double, double, double)virtual function to be used for monitoring (callback)Definition NeuralNet.h:781; TMVA::DNN::Settings::plotvoid plot(std::string histoName, std::string options, int pad, EColor color)for monitoringDefinition NeuralNet.h:823; TMVA::DNN::Set",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:67545,Testability,test,testIteration,67545,"kPropagatevoid backPropagate(std::vector< std::vector< LayerData > > &layerPatternData, const Settings &settings, size_t trainFromLayer, size_t totalNumWeights) constDefinition NeuralNet.icc:1355; TMVA::DNN::SettingsSettings for the training of the neural net.Definition NeuralNet.h:730; TMVA::DNN::Settings::useMultithreadingbool useMultithreading() constis multithreading turned on?Definition NeuralNet.h:815; TMVA::DNN::Settings::regularizationEnumRegularization regularization() constsome regularization of the DNN is turned on?Definition NeuralNet.h:813; TMVA::DNN::Settings::convergenceCountsize_t convergenceCount() constreturns the current convergence countDefinition NeuralNet.h:827; TMVA::DNN::Settings::testRepetitionssize_t testRepetitions() consthow often is the test data testedDefinition NeuralNet.h:768; TMVA::DNN::Settings::endTestCyclevirtual void endTestCycle()callback for monitoring and logggingDefinition NeuralNet.h:805; TMVA::DNN::Settings::testIterationvirtual void testIteration()callback for monitoring and logggingDefinition NeuralNet.h:806; TMVA::DNN::Settings::hasConvergedvirtual bool hasConverged(double testError)has this training converged already?Definition NeuralNet.cxx:485; TMVA::DNN::Settings::cyclevirtual void cycle(double progress, TString text)Definition NeuralNet.h:799; TMVA::DNN::Settings::endTrainCyclevirtual void endTrainCycle(double)callback for monitoring and loggingDefinition NeuralNet.h:788; TMVA::DNN::Settings::dropFractionsconst std::vector< double > & dropFractions() constDefinition NeuralNet.h:762; TMVA::DNN::Settings::addPointvoid addPoint(std::string histoName, double x)for monitoringDefinition NeuralNet.h:821; TMVA::DNN::Settings::testSamplevirtual void testSample(double, double, double, double)virtual function to be used for monitoring (callback)Definition NeuralNet.h:781; TMVA::DNN::Settings::plotvoid plot(std::string histoName, std::string options, int pad, EColor color)for monitoringDefinition NeuralNet.h:823; TMVA::DNN::Set",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:67588,Testability,log,logggingDefinition,67588,"kPropagatevoid backPropagate(std::vector< std::vector< LayerData > > &layerPatternData, const Settings &settings, size_t trainFromLayer, size_t totalNumWeights) constDefinition NeuralNet.icc:1355; TMVA::DNN::SettingsSettings for the training of the neural net.Definition NeuralNet.h:730; TMVA::DNN::Settings::useMultithreadingbool useMultithreading() constis multithreading turned on?Definition NeuralNet.h:815; TMVA::DNN::Settings::regularizationEnumRegularization regularization() constsome regularization of the DNN is turned on?Definition NeuralNet.h:813; TMVA::DNN::Settings::convergenceCountsize_t convergenceCount() constreturns the current convergence countDefinition NeuralNet.h:827; TMVA::DNN::Settings::testRepetitionssize_t testRepetitions() consthow often is the test data testedDefinition NeuralNet.h:768; TMVA::DNN::Settings::endTestCyclevirtual void endTestCycle()callback for monitoring and logggingDefinition NeuralNet.h:805; TMVA::DNN::Settings::testIterationvirtual void testIteration()callback for monitoring and logggingDefinition NeuralNet.h:806; TMVA::DNN::Settings::hasConvergedvirtual bool hasConverged(double testError)has this training converged already?Definition NeuralNet.cxx:485; TMVA::DNN::Settings::cyclevirtual void cycle(double progress, TString text)Definition NeuralNet.h:799; TMVA::DNN::Settings::endTrainCyclevirtual void endTrainCycle(double)callback for monitoring and loggingDefinition NeuralNet.h:788; TMVA::DNN::Settings::dropFractionsconst std::vector< double > & dropFractions() constDefinition NeuralNet.h:762; TMVA::DNN::Settings::addPointvoid addPoint(std::string histoName, double x)for monitoringDefinition NeuralNet.h:821; TMVA::DNN::Settings::testSamplevirtual void testSample(double, double, double, double)virtual function to be used for monitoring (callback)Definition NeuralNet.h:781; TMVA::DNN::Settings::plotvoid plot(std::string histoName, std::string options, int pad, EColor color)for monitoringDefinition NeuralNet.h:823; TMVA::DNN::Set",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:67690,Testability,test,testError,67690,"er, size_t totalNumWeights) constDefinition NeuralNet.icc:1355; TMVA::DNN::SettingsSettings for the training of the neural net.Definition NeuralNet.h:730; TMVA::DNN::Settings::useMultithreadingbool useMultithreading() constis multithreading turned on?Definition NeuralNet.h:815; TMVA::DNN::Settings::regularizationEnumRegularization regularization() constsome regularization of the DNN is turned on?Definition NeuralNet.h:813; TMVA::DNN::Settings::convergenceCountsize_t convergenceCount() constreturns the current convergence countDefinition NeuralNet.h:827; TMVA::DNN::Settings::testRepetitionssize_t testRepetitions() consthow often is the test data testedDefinition NeuralNet.h:768; TMVA::DNN::Settings::endTestCyclevirtual void endTestCycle()callback for monitoring and logggingDefinition NeuralNet.h:805; TMVA::DNN::Settings::testIterationvirtual void testIteration()callback for monitoring and logggingDefinition NeuralNet.h:806; TMVA::DNN::Settings::hasConvergedvirtual bool hasConverged(double testError)has this training converged already?Definition NeuralNet.cxx:485; TMVA::DNN::Settings::cyclevirtual void cycle(double progress, TString text)Definition NeuralNet.h:799; TMVA::DNN::Settings::endTrainCyclevirtual void endTrainCycle(double)callback for monitoring and loggingDefinition NeuralNet.h:788; TMVA::DNN::Settings::dropFractionsconst std::vector< double > & dropFractions() constDefinition NeuralNet.h:762; TMVA::DNN::Settings::addPointvoid addPoint(std::string histoName, double x)for monitoringDefinition NeuralNet.h:821; TMVA::DNN::Settings::testSamplevirtual void testSample(double, double, double, double)virtual function to be used for monitoring (callback)Definition NeuralNet.h:781; TMVA::DNN::Settings::plotvoid plot(std::string histoName, std::string options, int pad, EColor color)for monitoringDefinition NeuralNet.h:823; TMVA::DNN::Settings::startTrainCyclevirtual void startTrainCycle()Definition NeuralNet.h:782; TMVA::DNN::Settings::convergenceStepssize_t convergen",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:67965,Testability,log,loggingDefinition,67965," turned on?Definition NeuralNet.h:815; TMVA::DNN::Settings::regularizationEnumRegularization regularization() constsome regularization of the DNN is turned on?Definition NeuralNet.h:813; TMVA::DNN::Settings::convergenceCountsize_t convergenceCount() constreturns the current convergence countDefinition NeuralNet.h:827; TMVA::DNN::Settings::testRepetitionssize_t testRepetitions() consthow often is the test data testedDefinition NeuralNet.h:768; TMVA::DNN::Settings::endTestCyclevirtual void endTestCycle()callback for monitoring and logggingDefinition NeuralNet.h:805; TMVA::DNN::Settings::testIterationvirtual void testIteration()callback for monitoring and logggingDefinition NeuralNet.h:806; TMVA::DNN::Settings::hasConvergedvirtual bool hasConverged(double testError)has this training converged already?Definition NeuralNet.cxx:485; TMVA::DNN::Settings::cyclevirtual void cycle(double progress, TString text)Definition NeuralNet.h:799; TMVA::DNN::Settings::endTrainCyclevirtual void endTrainCycle(double)callback for monitoring and loggingDefinition NeuralNet.h:788; TMVA::DNN::Settings::dropFractionsconst std::vector< double > & dropFractions() constDefinition NeuralNet.h:762; TMVA::DNN::Settings::addPointvoid addPoint(std::string histoName, double x)for monitoringDefinition NeuralNet.h:821; TMVA::DNN::Settings::testSamplevirtual void testSample(double, double, double, double)virtual function to be used for monitoring (callback)Definition NeuralNet.h:781; TMVA::DNN::Settings::plotvoid plot(std::string histoName, std::string options, int pad, EColor color)for monitoringDefinition NeuralNet.h:823; TMVA::DNN::Settings::startTrainCyclevirtual void startTrainCycle()Definition NeuralNet.h:782; TMVA::DNN::Settings::convergenceStepssize_t convergenceSteps() consthow many steps until training is deemed to have convergedDefinition NeuralNet.h:766; TMVA::DNN::Settings::factorWeightDecaydouble factorWeightDecay() constget the weight-decay factorDefinition NeuralNet.h:769; TMVA::DNN::Setti",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:68251,Testability,test,testSamplevirtual,68251,") consthow often is the test data testedDefinition NeuralNet.h:768; TMVA::DNN::Settings::endTestCyclevirtual void endTestCycle()callback for monitoring and logggingDefinition NeuralNet.h:805; TMVA::DNN::Settings::testIterationvirtual void testIteration()callback for monitoring and logggingDefinition NeuralNet.h:806; TMVA::DNN::Settings::hasConvergedvirtual bool hasConverged(double testError)has this training converged already?Definition NeuralNet.cxx:485; TMVA::DNN::Settings::cyclevirtual void cycle(double progress, TString text)Definition NeuralNet.h:799; TMVA::DNN::Settings::endTrainCyclevirtual void endTrainCycle(double)callback for monitoring and loggingDefinition NeuralNet.h:788; TMVA::DNN::Settings::dropFractionsconst std::vector< double > & dropFractions() constDefinition NeuralNet.h:762; TMVA::DNN::Settings::addPointvoid addPoint(std::string histoName, double x)for monitoringDefinition NeuralNet.h:821; TMVA::DNN::Settings::testSamplevirtual void testSample(double, double, double, double)virtual function to be used for monitoring (callback)Definition NeuralNet.h:781; TMVA::DNN::Settings::plotvoid plot(std::string histoName, std::string options, int pad, EColor color)for monitoringDefinition NeuralNet.h:823; TMVA::DNN::Settings::startTrainCyclevirtual void startTrainCycle()Definition NeuralNet.h:782; TMVA::DNN::Settings::convergenceStepssize_t convergenceSteps() consthow many steps until training is deemed to have convergedDefinition NeuralNet.h:766; TMVA::DNN::Settings::factorWeightDecaydouble factorWeightDecay() constget the weight-decay factorDefinition NeuralNet.h:769; TMVA::DNN::Settings::maxConvergenceCountsize_t maxConvergenceCount() constreturns the max convergence count so farDefinition NeuralNet.h:828; TMVA::DNN::Settings::padsvoid pads(int numPads)preparation for monitoringDefinition NeuralNet.h:818; TMVA::DNN::Settings::batchSizesize_t batchSize() constmini-batch sizeDefinition NeuralNet.h:767; TMVA::DNN::Settings::computeResultvirtual void computeR",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:68274,Testability,test,testSample,68274,") consthow often is the test data testedDefinition NeuralNet.h:768; TMVA::DNN::Settings::endTestCyclevirtual void endTestCycle()callback for monitoring and logggingDefinition NeuralNet.h:805; TMVA::DNN::Settings::testIterationvirtual void testIteration()callback for monitoring and logggingDefinition NeuralNet.h:806; TMVA::DNN::Settings::hasConvergedvirtual bool hasConverged(double testError)has this training converged already?Definition NeuralNet.cxx:485; TMVA::DNN::Settings::cyclevirtual void cycle(double progress, TString text)Definition NeuralNet.h:799; TMVA::DNN::Settings::endTrainCyclevirtual void endTrainCycle(double)callback for monitoring and loggingDefinition NeuralNet.h:788; TMVA::DNN::Settings::dropFractionsconst std::vector< double > & dropFractions() constDefinition NeuralNet.h:762; TMVA::DNN::Settings::addPointvoid addPoint(std::string histoName, double x)for monitoringDefinition NeuralNet.h:821; TMVA::DNN::Settings::testSamplevirtual void testSample(double, double, double, double)virtual function to be used for monitoring (callback)Definition NeuralNet.h:781; TMVA::DNN::Settings::plotvoid plot(std::string histoName, std::string options, int pad, EColor color)for monitoringDefinition NeuralNet.h:823; TMVA::DNN::Settings::startTrainCyclevirtual void startTrainCycle()Definition NeuralNet.h:782; TMVA::DNN::Settings::convergenceStepssize_t convergenceSteps() consthow many steps until training is deemed to have convergedDefinition NeuralNet.h:766; TMVA::DNN::Settings::factorWeightDecaydouble factorWeightDecay() constget the weight-decay factorDefinition NeuralNet.h:769; TMVA::DNN::Settings::maxConvergenceCountsize_t maxConvergenceCount() constreturns the max convergence count so farDefinition NeuralNet.h:828; TMVA::DNN::Settings::padsvoid pads(int numPads)preparation for monitoringDefinition NeuralNet.h:818; TMVA::DNN::Settings::batchSizesize_t batchSize() constmini-batch sizeDefinition NeuralNet.h:767; TMVA::DNN::Settings::computeResultvirtual void computeR",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:69378,Testability,log,loggingDefinition,69378,"unction to be used for monitoring (callback)Definition NeuralNet.h:781; TMVA::DNN::Settings::plotvoid plot(std::string histoName, std::string options, int pad, EColor color)for monitoringDefinition NeuralNet.h:823; TMVA::DNN::Settings::startTrainCyclevirtual void startTrainCycle()Definition NeuralNet.h:782; TMVA::DNN::Settings::convergenceStepssize_t convergenceSteps() consthow many steps until training is deemed to have convergedDefinition NeuralNet.h:766; TMVA::DNN::Settings::factorWeightDecaydouble factorWeightDecay() constget the weight-decay factorDefinition NeuralNet.h:769; TMVA::DNN::Settings::maxConvergenceCountsize_t maxConvergenceCount() constreturns the max convergence count so farDefinition NeuralNet.h:828; TMVA::DNN::Settings::padsvoid pads(int numPads)preparation for monitoringDefinition NeuralNet.h:818; TMVA::DNN::Settings::batchSizesize_t batchSize() constmini-batch sizeDefinition NeuralNet.h:767; TMVA::DNN::Settings::computeResultvirtual void computeResult(const Net &, std::vector< double > &)callback for monitoring and loggingDefinition NeuralNet.h:809; TMVA::DNN::Settings::dropRepetitionssize_t dropRepetitions() constDefinition NeuralNet.h:761; TMVA::DNN::Settings::createvoid create(std::string histoName, int bins, double min, double max)for monitoringDefinition NeuralNet.h:819; TMVA::DNN::Settings::startTestCyclevirtual void startTestCycle()callback for monitoring and logggingDefinition NeuralNet.h:804; TMVA::DNN::Steepest::m_repetitionssize_t m_repetitionsDefinition NeuralNet.h:337; TMVA::DNN::Steepest::m_betadouble m_betainternal parameter (momentum)Definition NeuralNet.h:372; TMVA::DNN::Steepest::m_localGradientsstd::vector< double > m_localGradientslocal gradients for reuse in thread.Definition NeuralNet.h:376; TMVA::DNN::Steepest::m_prevGradientsstd::vector< double > m_prevGradientsvector remembers the gradients of the previous stepDefinition NeuralNet.h:373; TMVA::DNN::Steepest::m_alphadouble m_alphainternal parameter (learningRate)Definitio",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:69736,Testability,log,logggingDefinition,69736,"thow many steps until training is deemed to have convergedDefinition NeuralNet.h:766; TMVA::DNN::Settings::factorWeightDecaydouble factorWeightDecay() constget the weight-decay factorDefinition NeuralNet.h:769; TMVA::DNN::Settings::maxConvergenceCountsize_t maxConvergenceCount() constreturns the max convergence count so farDefinition NeuralNet.h:828; TMVA::DNN::Settings::padsvoid pads(int numPads)preparation for monitoringDefinition NeuralNet.h:818; TMVA::DNN::Settings::batchSizesize_t batchSize() constmini-batch sizeDefinition NeuralNet.h:767; TMVA::DNN::Settings::computeResultvirtual void computeResult(const Net &, std::vector< double > &)callback for monitoring and loggingDefinition NeuralNet.h:809; TMVA::DNN::Settings::dropRepetitionssize_t dropRepetitions() constDefinition NeuralNet.h:761; TMVA::DNN::Settings::createvoid create(std::string histoName, int bins, double min, double max)for monitoringDefinition NeuralNet.h:819; TMVA::DNN::Settings::startTestCyclevirtual void startTestCycle()callback for monitoring and logggingDefinition NeuralNet.h:804; TMVA::DNN::Steepest::m_repetitionssize_t m_repetitionsDefinition NeuralNet.h:337; TMVA::DNN::Steepest::m_betadouble m_betainternal parameter (momentum)Definition NeuralNet.h:372; TMVA::DNN::Steepest::m_localGradientsstd::vector< double > m_localGradientslocal gradients for reuse in thread.Definition NeuralNet.h:376; TMVA::DNN::Steepest::m_prevGradientsstd::vector< double > m_prevGradientsvector remembers the gradients of the previous stepDefinition NeuralNet.h:373; TMVA::DNN::Steepest::m_alphadouble m_alphainternal parameter (learningRate)Definition NeuralNet.h:371; TMVA::DNN::Steepest::m_localWeightsstd::vector< double > m_localWeightslocal weights for reuse in thread.Definition NeuralNet.h:375; TMVA::DNN::Steepest::operator()double operator()(Function &fitnessFunction, Weights &weights, PassThrough &passThrough)operator to call the steepest gradient descent algorithmDefinition NeuralNet.icc:271; TMVA::IPythonInter",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:8764,Usability,clear,clear,8764,";; 251 ++itTargetDelta; ++itTargetGradient; ++itGradient; ++itWeight;; 252 }; 253 ++itSource;; 254 }; 255 }; 256 ; 257 ; 258 ; 259 ; 260 ; 261 ; 262#define USELOCALWEIGHTS 1; 263 ; 264 ; 265 ; 266/*! \brief implementation of the steepest gradient descent algorithm; 267 *; 268 * Can be used with multithreading (i.e. ""HogWild!"" style); see call in trainCycle; 269 */; 270 template <typename Function, typename Weights, typename PassThrough>; 271 double Steepest::operator() (Function& fitnessFunction, Weights& weights, PassThrough& passThrough); 272 {; 273 size_t numWeights = weights.size ();; 274 // std::vector<double> gradients (numWeights, 0.0);; 275 m_localGradients.assign (numWeights, 0.0);; 276 // std::vector<double> localWeights (begin (weights), end (weights));; 277 // m_localWeights.reserve (numWeights);; 278 m_localWeights.assign (begin (weights), end (weights));; 279 ; 280 double E = 1e10;; 281 if (m_prevGradients.size () != numWeights); 282 {; 283 m_prevGradients.clear ();; 284 m_prevGradients.assign (weights.size (), 0);; 285 }; 286 ; 287 bool success = true;; 288 size_t currentRepetition = 0;; 289 while (success); 290 {; 291 if (currentRepetition >= m_repetitions); 292 break;; 293 ; 294 m_localGradients.assign (numWeights, 0.0);; 295 ; 296 // --- nesterov momentum ---; 297 // apply momentum before computing the new gradient; 298 auto itPrevG = begin (m_prevGradients);; 299 auto itPrevGEnd = end (m_prevGradients);; 300 auto itLocWeight = begin (m_localWeights);; 301 for (; itPrevG != itPrevGEnd; ++itPrevG, ++itLocWeight); 302 {; 303 (*itPrevG) *= m_beta;; 304 (*itLocWeight) += (*itPrevG);; 305 }; 306 ; 307 E = fitnessFunction (passThrough, m_localWeights, m_localGradients);; 308// plotGradients (gradients);; 309// plotWeights (localWeights);; 310 ; 311 double alpha = gaussDouble (m_alpha, m_alpha/2.0);; 312// double alpha = m_alpha;; 313 ; 314 auto itG = begin (m_localGradients);; 315 auto itGEnd = end (m_localGradients);; 316 itPrevG = begin (m_prevGradients",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:10426,Usability,clear,clear,10426,"or (; itG != itGEnd; ++itG, ++itPrevG); 319 {; 320 double currGrad = (*itG);; 321 double prevGrad = (*itPrevG);; 322 currGrad *= alpha;; 323 ; 324 //(*itPrevG) = m_beta * (prevGrad + currGrad);; 325 currGrad += prevGrad;; 326 (*itG) = currGrad;; 327 (*itPrevG) = currGrad;; 328 ; 329 if (std::fabs (currGrad) > maxGrad); 330 maxGrad = currGrad;; 331 }; 332 ; 333 if (maxGrad > 1); 334 {; 335 m_alpha /= 2;; 336 std::cout << ""\nlearning rate reduced to "" << m_alpha << std::endl;; 337 std::for_each (weights.begin (), weights.end (), [maxGrad](double& w); 338 {; 339 w /= maxGrad;; 340 });; 341 m_prevGradients.clear ();; 342 }; 343 else; 344 {; 345 auto itW = std::begin (weights);; 346 std::for_each (std::begin (m_localGradients), std::end (m_localGradients), [&itW](double& g); 347 {; 348 *itW += g;; 349 ++itW;; 350 });; 351 }; 352 ; 353 ++currentRepetition;; 354 }; 355 return E;; 356 }; 357 ; 358 ; 359 ; 360 ; 361 ; 362 ; 363 ; 364 ; 365 ; 366 ; 367 ; 368 ; 369 ; 370 ; 371 ; 372 ; 373 ; 374 ; 375 ; 376 ; 377/*! \brief sum of squares error function; 378 *; 379 *; 380 */; 381 template <typename ItOutput, typename ItTruth, typename ItDelta, typename InvFnc>; 382 double sumOfSquares (ItOutput itOutputBegin, ItOutput itOutputEnd, ItTruth itTruthBegin, ItTruth /*itTruthEnd*/, ItDelta itDelta, ItDelta itDeltaEnd, InvFnc invFnc, double patternWeight); 383 {; 384 double errorSum = 0.0;; 385 ; 386 // output - truth; 387 ItTruth itTruth = itTruthBegin;; 388 bool hasDeltas = (itDelta != itDeltaEnd);; 389 for (ItOutput itOutput = itOutputBegin; itOutput != itOutputEnd; ++itOutput, ++itTruth); 390 {; 391// assert (itTruth != itTruthEnd);; 392 double output = (*itOutput);; 393 double error = output - (*itTruth);; 394 if (hasDeltas); 395 {; 396 (*itDelta) = (*invFnc.get ()) (output) * error * patternWeight;; 397 ++itDelta;; 398 }; 399 errorSum += error*error * patternWeight;; 400 }; 401 ; 402 return 0.5*errorSum;; 403 }; 404 ; 405 ; 406 ; 407/*! \brief cross entropy error function; 408 *;",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:21249,Usability,progress bar,progress bar,21249,"); 687 break;; 688 ; 689 *itWeight *= p;; 690 ++itWeight;; 691 }; 692 numNodesPrev = _numNodes;; 693 dropFractionPrev = dropFraction;; 694 ++itDrop;; 695 }; 696 }; 697 ; 698 ; 699 ; 700 ; 701 ; 702 ; 703/*! \brief execute the training until convergence emerges; 704 *; 705 * \param weights the container with the weights (synapses); 706 * \param trainPattern the pattern for the training; 707 * \param testPattern the pattern for the testing; 708 * \param minimizer the minimizer (e.g. steepest gradient descent) to be used; 709 * \param settings the settings for the training (e.g. multithreading or not, regularization etc.); 710 */; 711 template <typename Minimizer>; 712 double Net::train (std::vector<double>& weights,; 713 std::vector<Pattern>& trainPattern,; 714 const std::vector<Pattern>& testPattern,; 715 Minimizer& minimizer,; 716 Settings& settings); 717 {; 718// std::cout << ""START TRAINING"" << std::endl;; 719 settings.startTrainCycle ();; 720 ; 721 // JsMVA progress bar maximum (100%); 722 if (fIPyMaxIter) *fIPyMaxIter = 100;; 723 ; 724 settings.pads (4);; 725 settings.create (""trainErrors"", 100, 0, 100, 100, 0,1);; 726 settings.create (""testErrors"", 100, 0, 100, 100, 0,1);; 727 ; 728 size_t cycleCount = 0;; 729 size_t testCycleCount = 0;; 730 double testError = 1e20;; 731 double trainError = 1e20;; 732 size_t dropOutChangeCount = 0;; 733 ; 734 DropContainer dropContainer;; 735 DropContainer dropContainerTest;; 736 const std::vector<double>& dropFractions = settings.dropFractions ();; 737 bool isWeightsForDrop = false;; 738 ; 739 ; 740 // until convergence; 741 do; 742 {; 743 ++cycleCount;; 744 ; 745 // if dropOut enabled; 746 size_t dropIndex = 0;; 747 if (!dropFractions.empty () && dropOutChangeCount % settings.dropRepetitions () == 0); 748 {; 749 // fill the dropOut-container; 750 dropContainer.clear ();; 751 size_t _numNodes = inputSize ();; 752 double dropFraction = 0.0;; 753 dropFraction = dropFractions.at (dropIndex);; 754 ++dropIndex;; 755 fillDropContain",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:22106,Usability,clear,clear,22106," 718// std::cout << ""START TRAINING"" << std::endl;; 719 settings.startTrainCycle ();; 720 ; 721 // JsMVA progress bar maximum (100%); 722 if (fIPyMaxIter) *fIPyMaxIter = 100;; 723 ; 724 settings.pads (4);; 725 settings.create (""trainErrors"", 100, 0, 100, 100, 0,1);; 726 settings.create (""testErrors"", 100, 0, 100, 100, 0,1);; 727 ; 728 size_t cycleCount = 0;; 729 size_t testCycleCount = 0;; 730 double testError = 1e20;; 731 double trainError = 1e20;; 732 size_t dropOutChangeCount = 0;; 733 ; 734 DropContainer dropContainer;; 735 DropContainer dropContainerTest;; 736 const std::vector<double>& dropFractions = settings.dropFractions ();; 737 bool isWeightsForDrop = false;; 738 ; 739 ; 740 // until convergence; 741 do; 742 {; 743 ++cycleCount;; 744 ; 745 // if dropOut enabled; 746 size_t dropIndex = 0;; 747 if (!dropFractions.empty () && dropOutChangeCount % settings.dropRepetitions () == 0); 748 {; 749 // fill the dropOut-container; 750 dropContainer.clear ();; 751 size_t _numNodes = inputSize ();; 752 double dropFraction = 0.0;; 753 dropFraction = dropFractions.at (dropIndex);; 754 ++dropIndex;; 755 fillDropContainer (dropContainer, dropFraction, _numNodes);; 756 for (auto itLayer = begin (m_layers), itLayerEnd = end (m_layers); itLayer != itLayerEnd; ++itLayer, ++dropIndex); 757 {; 758 auto& layer = *itLayer;; 759 _numNodes = layer.numNodes ();; 760 // how many nodes have to be dropped; 761 dropFraction = 0.0;; 762 if (dropFractions.size () > dropIndex); 763 dropFraction = dropFractions.at (dropIndex);; 764 ; 765 fillDropContainer (dropContainer, dropFraction, _numNodes);; 766 }; 767 isWeightsForDrop = true;; 768 }; 769 ; 770 // execute training cycle; 771 trainError = trainCycle (minimizer, weights, begin (trainPattern), end (trainPattern), settings, dropContainer);; 772 ; 773 ; 774 // ------ check if we have to execute a test ------------------; 775 bool hasConverged = false;; 776 if (testCycleCount % settings.testRepetitions () == 0) // we test only everye ""testRep",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:25627,Usability,clear,clear,25627,"r += std::get<0>(result) / batches.size ();; 823 std::vector<double> output = std::get<1>(result);; 824 if (output.size() == (outputSize() - 1) * itBatch->size()); 825 {; 826 auto output_iterator = output.begin();; 827 for (auto pattern_it = itBatch->begin(); pattern_it != itBatch->end(); ++pattern_it); 828 {; 829 for (size_t output_index = 1; output_index < outputSize(); ++output_index); 830 {; 831 settings.testSample (0, *output_iterator, (*pattern_it).output ().at (0),; 832 (*pattern_it).weight ());; 833 ++output_iterator;; 834 }; 835 }; 836 }; 837 ++itBatch;; 838 }; 839 ; 840 }; 841 else; 842 {; 843 std::vector<double> output;; 844 //for (auto it = begin (testPattern), itEnd = end (testPattern); it != itEnd; ++it); 845 {; 846 //const Pattern& p = (*it);; 847 //double weight = p.weight ();; 848 //Batch batch (it, it+1);; 849 Batch batch (begin (testPattern), end (testPattern));; 850 output.clear ();; 851 pass_through_type passThrough (settings, batch, dropContainerTest);; 852 double testPatternError = (*this) (passThrough, weights, ModeOutput::FETCH, output);; 853 if (output.size() == (outputSize() - 1) * batch.size()); 854 {; 855 auto output_iterator = output.begin();; 856 for (auto pattern_it = batch.begin(); pattern_it != batch.end(); ++pattern_it); 857 {; 858 for (size_t output_index = 1; output_index < outputSize(); ++output_index); 859 {; 860 settings.testSample (0, *output_iterator, (*pattern_it).output ().at (0),; 861 (*pattern_it).weight ());; 862 ++output_iterator;; 863 }; 864 }; 865 }; 866 testError += testPatternError; /// batch.size ();; 867 }; 868 // testError /= testPattern.size ();; 869 }; 870 settings.endTestCycle ();; 871// testError /= weightSum;; 872 ; 873 settings.computeResult (*this, weights);; 874 ; 875 hasConverged = settings.hasConverged (testError);; 876 if (!hasConverged && !isWeightsForDrop); 877 {; 878 dropOutWeightFactor (weights, dropFractions, true); // inverse; 879 isWeightsForDrop = true;; 880 }; 881 }; 882 ++testCycleCount;; 883",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:27067,Usability,progress bar,progress bar,27067,"iterator, (*pattern_it).output ().at (0),; 861 (*pattern_it).weight ());; 862 ++output_iterator;; 863 }; 864 }; 865 }; 866 testError += testPatternError; /// batch.size ();; 867 }; 868 // testError /= testPattern.size ();; 869 }; 870 settings.endTestCycle ();; 871// testError /= weightSum;; 872 ; 873 settings.computeResult (*this, weights);; 874 ; 875 hasConverged = settings.hasConverged (testError);; 876 if (!hasConverged && !isWeightsForDrop); 877 {; 878 dropOutWeightFactor (weights, dropFractions, true); // inverse; 879 isWeightsForDrop = true;; 880 }; 881 }; 882 ++testCycleCount;; 883 ++dropOutChangeCount;; 884 ; 885 ; 886// settings.resetPlot (""errors"");; 887 settings.addPoint (""trainErrors"", cycleCount, trainError);; 888 settings.addPoint (""testErrors"", cycleCount, testError);; 889 settings.plot (""trainErrors"", ""C"", 1, kBlue);; 890 settings.plot (""testErrors"", ""C"", 1, kMagenta);; 891 ; 892 ; 893 // setup error plots and progress bar variables for JsMVA; 894 if (fInteractive){; 895 fInteractive->AddPoint(cycleCount, trainError, testError);; 896 if (*fExitFromTraining) break;; 897 *fIPyCurrentIter = 100*(double)settings.maxConvergenceCount () /(double)settings.convergenceSteps ();; 898 }; 899 ; 900 if (hasConverged); 901 break;; 902 ; 903 if ((int)cycleCount % 10 == 0) {; 904 ; 905 TString convText = TString::Format( ""(train/test/epo/conv/maxco): %.3g/%.3g/%d/%d/%d"",; 906 trainError,; 907 testError,; 908 (int)cycleCount,; 909 (int)settings.convergenceCount (),; 910 (int)settings.maxConvergenceCount ());; 911 double progress = 100*(double)settings.maxConvergenceCount () /(double)settings.convergenceSteps ();; 912 settings.cycle (progress, convText);; 913 }; 914 }; 915 while (true);; 916 settings.endTrainCycle (trainError);; 917 ; 918 TString convText = TString::Format( ""(train/test/epoch): %.4g/%.4g/%d"", trainError, testError, (int)cycleCount);; 919 double progress = 100*(double)settings.maxConvergenceCount() /(double)settings.convergenceSteps ();; 920 settings.cy",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:40540,Usability,clear,clear,40540,"turn layerPatternData;; 1216}; 1217 ; 1218 ; 1219 ; 1220 template <typename LayerContainer>; 1221 void Net::forwardPattern (const LayerContainer& _layers,; 1222 std::vector<LayerData>& layerData) const; 1223 {; 1224 size_t idxLayer = 0, idxLayerEnd = _layers.size ();; 1225 for (; idxLayer < idxLayerEnd; ++idxLayer); 1226 {; 1227 LayerData& prevLayerData = layerData.at (idxLayer);; 1228 LayerData& currLayerData = layerData.at (idxLayer+1);; 1229 ; 1230 forward (prevLayerData, currLayerData);; 1231 ; 1232 applyFunctions (currLayerData.valuesBegin (), currLayerData.valuesEnd (), currLayerData.activationFunction ());; 1233 }; 1234 }; 1235 ; 1236 ; 1237 ; 1238 ; 1239 template <typename LayerContainer, typename LayerPatternContainer>; 1240 void Net::forwardBatch (const LayerContainer& _layers,; 1241 LayerPatternContainer& layerPatternData,; 1242 std::vector<double>& valuesMean,; 1243 std::vector<double>& valuesStdDev,; 1244 size_t trainFromLayer) const; 1245 {; 1246 valuesMean.clear ();; 1247 valuesStdDev.clear ();; 1248 ; 1249 // ---------------------------------- loop over layers and pattern -------------------------------------------------------; 1250 for (size_t idxLayer = 0, idxLayerEnd = layerPatternData.size (); idxLayer < idxLayerEnd-1; ++idxLayer); 1251 {; 1252 bool doTraining = idxLayer >= trainFromLayer;; 1253 ; 1254 // get layer-pattern data for this and the corresponding one from the next layer; 1255 std::vector<LayerData>& prevLayerPatternData = layerPatternData.at (idxLayer);; 1256 std::vector<LayerData>& currLayerPatternData = layerPatternData.at (idxLayer+1);; 1257 ; 1258 size_t numPattern = prevLayerPatternData.size ();; 1259 size_t numNodesLayer = _layers.at (idxLayer).numNodes ();; 1260 ; 1261 std::vector<MeanVariance> means (numNodesLayer);; 1262 // ---------------- loop over layerDatas of pattern compute forward ----------------------------; 1263 for (size_t idxPattern = 0; idxPattern < numPattern; ++idxPattern); 1264 {; 1265 const LayerData& prevLaye",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:40569,Usability,clear,clear,40569,"ern (const LayerContainer& _layers,; 1222 std::vector<LayerData>& layerData) const; 1223 {; 1224 size_t idxLayer = 0, idxLayerEnd = _layers.size ();; 1225 for (; idxLayer < idxLayerEnd; ++idxLayer); 1226 {; 1227 LayerData& prevLayerData = layerData.at (idxLayer);; 1228 LayerData& currLayerData = layerData.at (idxLayer+1);; 1229 ; 1230 forward (prevLayerData, currLayerData);; 1231 ; 1232 applyFunctions (currLayerData.valuesBegin (), currLayerData.valuesEnd (), currLayerData.activationFunction ());; 1233 }; 1234 }; 1235 ; 1236 ; 1237 ; 1238 ; 1239 template <typename LayerContainer, typename LayerPatternContainer>; 1240 void Net::forwardBatch (const LayerContainer& _layers,; 1241 LayerPatternContainer& layerPatternData,; 1242 std::vector<double>& valuesMean,; 1243 std::vector<double>& valuesStdDev,; 1244 size_t trainFromLayer) const; 1245 {; 1246 valuesMean.clear ();; 1247 valuesStdDev.clear ();; 1248 ; 1249 // ---------------------------------- loop over layers and pattern -------------------------------------------------------; 1250 for (size_t idxLayer = 0, idxLayerEnd = layerPatternData.size (); idxLayer < idxLayerEnd-1; ++idxLayer); 1251 {; 1252 bool doTraining = idxLayer >= trainFromLayer;; 1253 ; 1254 // get layer-pattern data for this and the corresponding one from the next layer; 1255 std::vector<LayerData>& prevLayerPatternData = layerPatternData.at (idxLayer);; 1256 std::vector<LayerData>& currLayerPatternData = layerPatternData.at (idxLayer+1);; 1257 ; 1258 size_t numPattern = prevLayerPatternData.size ();; 1259 size_t numNodesLayer = _layers.at (idxLayer).numNodes ();; 1260 ; 1261 std::vector<MeanVariance> means (numNodesLayer);; 1262 // ---------------- loop over layerDatas of pattern compute forward ----------------------------; 1263 for (size_t idxPattern = 0; idxPattern < numPattern; ++idxPattern); 1264 {; 1265 const LayerData& prevLayerData = prevLayerPatternData.at (idxPattern);; 1266 LayerData& currLayerData = currLayerPatternData.at (idxPattern);; 1",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:54926,Usability,clear,clear,54926," itWeightEnd, factorWeightDecay, eRegularization);; 1625 }; 1626 return error;; 1627 }; 1628 ; 1629 ; 1630 ; 1631 ; 1632 ; 1633 ; 1634 ; 1635// /*! \brief pre-training; 1636// *; 1637// * in development; 1638// */; 1639// template <typename Minimizer>; 1640// void Net::preTrain (std::vector<double>& weights,; 1641// std::vector<Pattern>& trainPattern,; 1642// const std::vector<Pattern>& testPattern,; 1643// Minimizer& minimizer, Settings& settings); 1644// {; 1645// auto itWeightGeneral = std::begin (weights);; 1646// std::vector<Pattern> prePatternTrain (trainPattern.size ());; 1647// std::vector<Pattern> prePatternTest (testPattern.size ());; 1648 ; 1649// size_t _inputSize = inputSize ();; 1650 ; 1651// // transform pattern using the created preNet; 1652// auto initializePrePattern = [&](const std::vector<Pattern>& pttrnInput, std::vector<Pattern>& pttrnOutput); 1653// {; 1654// pttrnOutput.clear ();; 1655// std::transform (std::begin (pttrnInput), std::end (pttrnInput),; 1656// std::back_inserter (pttrnOutput),; 1657// [](const Pattern& p); 1658// {; 1659// Pattern pat (p.input (), p.input (), p.weight ());; 1660// return pat;; 1661// });; 1662// };; 1663 ; 1664// initializePrePattern (trainPattern, prePatternTrain);; 1665// initializePrePattern (testPattern, prePatternTest);; 1666 ; 1667// std::vector<double> originalDropFractions = settings.dropFractions ();; 1668 ; 1669// for (auto& _layer : layers ()); 1670// {; 1671// // compute number of weights (as a function of the number of incoming nodes); 1672// // fetch number of nodes; 1673// size_t numNodes = _layer.numNodes ();; 1674// size_t _numWeights = _layer.numWeights (_inputSize);; 1675 ; 1676// // ------------------; 1677// DNN::Net preNet;; 1678// if (!originalDropFractions.empty ()); 1679// {; 1680// originalDropFractions.erase (originalDropFractions.begin ());; 1681// settings.setDropOut (originalDropFractions.begin (), originalDropFractions.end (), settings.dropRepetitions ());; 1682// }; 1683// std::v",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NeuralNet_8icc_source.html:70304,Usability,learn,learningRate,70304,"virtual void computeResult(const Net &, std::vector< double > &)callback for monitoring and loggingDefinition NeuralNet.h:809; TMVA::DNN::Settings::dropRepetitionssize_t dropRepetitions() constDefinition NeuralNet.h:761; TMVA::DNN::Settings::createvoid create(std::string histoName, int bins, double min, double max)for monitoringDefinition NeuralNet.h:819; TMVA::DNN::Settings::startTestCyclevirtual void startTestCycle()callback for monitoring and logggingDefinition NeuralNet.h:804; TMVA::DNN::Steepest::m_repetitionssize_t m_repetitionsDefinition NeuralNet.h:337; TMVA::DNN::Steepest::m_betadouble m_betainternal parameter (momentum)Definition NeuralNet.h:372; TMVA::DNN::Steepest::m_localGradientsstd::vector< double > m_localGradientslocal gradients for reuse in thread.Definition NeuralNet.h:376; TMVA::DNN::Steepest::m_prevGradientsstd::vector< double > m_prevGradientsvector remembers the gradients of the previous stepDefinition NeuralNet.h:373; TMVA::DNN::Steepest::m_alphadouble m_alphainternal parameter (learningRate)Definition NeuralNet.h:371; TMVA::DNN::Steepest::m_localWeightsstd::vector< double > m_localWeightslocal weights for reuse in thread.Definition NeuralNet.h:375; TMVA::DNN::Steepest::operator()double operator()(Function &fitnessFunction, Weights &weights, PassThrough &passThrough)operator to call the steepest gradient descent algorithmDefinition NeuralNet.icc:271; TMVA::IPythonInteractive::AddPointvoid AddPoint(Double_t x, Double_t y1, Double_t y2)This function is used only in 2 TGraph case, and it will add new data points to graphs.Definition MethodBase.cxx:207; TStringBasic string class.Definition TString.h:139; TString::Formatstatic TString Format(const char *fmt,...)Static method which formats a string using a printf style format descriptor and return a TString.Definition TString.cxx:2378; double; nconst Int_t nDefinition legend1.C:16; TMVA::DNN::InvGaussstd::shared_ptr< std::function< double(double)> > InvGaussDefinition NeuralNet.cxx:14; TMVA::DNN::su",MatchSource.WIKI,doc/master/NeuralNet_8icc_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NeuralNet_8icc_source.html
https://root.cern/doc/master/NormalizeHistogram_8C.html:2677,Availability,mask,mask,2677,"m->Integral(), ""width"");; ; // Drawing everything; TCanvas *c1 = new TCanvas(""c1"", ""Histogram Normalization"", 700, 900);; c1->Divide(1, 2);; ; c1->cd(1);; orig->Draw();; c1->cd(2);; norm->Draw();; }; TCanvas.h; rOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t rDefinition TGWin32VirtualXProxy.cxx:168; TH2F.h; TRandom.h; gStyleR__EXTERN TStyle * gStyleDefinition TStyle.h:436; TCanvasThe Canvas class.Definition TCanvas.h:23; TH1F1-D histogram with a float per channel (see TH1 documentation)Definition TH1.h:622; TH1::SetTitlevoid SetTitle(const char *title) overrideChange/set the title.Definition TH1.cxx:6718; TH1::Fillvirtual Int_t Fill(Double_t x)Increment bin with abscissa X by 1.Definition TH1.cxx:3344; TH1::Drawvoid Draw(Option_t *option="""") overrideDraw this histogram with options.Definition TH1.cxx:3066; TH1::Integralvirtual Double_t Integral(Option_t *option="""") constReturn integral of bin contents.Definition TH1.cxx:7941; TH1::Scalevirtual void Scale(Double_t c1=1, Option_t *option="""")Multiply this histogram by a constant c1.Definition TH1.cxx:6604; TH1::CloneTObject * Clone(const char *newname="""") const overrideMake a complete copy of the underlying object.Definition TH1.cxx:2752; TRandom2Random number generator class based on the maximally quidistributed combined Tausworthe generator by ...Definition TRandom2.h:27; TRandom2::RndmDouble_t Rndm() overrideTausWorth generator from L'Ecuyer, uses as seed 3x32bits integers Use a mask of 0xffffffffUL to make ...Definition TRandom2.cxx:55; TStyle::SetTitleFontSizevoid SetTitleFontSize(Float_t size=0)Definition TStyle.h:407; c1return c1Definition legend1.C:41; AuthorAdvait Dhingra ; Definition in file NormalizeHistogram.C. tutorialshistNormalizeHistogram.C. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:29 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/NormalizeHistogram_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NormalizeHistogram_8C.html
https://root.cern/doc/master/normal_8c.html:304,Integrability,depend,dependency,304,". ROOT: graf3d/eve7/glu/normal.c File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. Macros |; Functions ; normal.c File Reference. #include ""gluos.h""; #include ""mesh.h""; #include ""tess.h""; #include ""normal.h""; #include <math.h>; #include <assert.h>. Include dependency graph for normal.c:. This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead. Macros; #defineABS(x)((x) < 0 ? -(x) : (x)); ; #defineDot(u, v)(u[0]*v[0] + u[1]*v[1] + u[2]*v[2]); ; #defineFALSE0; ; #defineS_UNIT_X1.0; ; #defineS_UNIT_Y0.0; ; #defineTRUE1; . Functions; void__gl_projectPolygon (GLUtesselator *tess); ; static voidCheckOrientation (GLUtesselator *tess); ; static voidComputeNormal (GLUtesselator *tess, GLdouble norm[3]); ; static intLongAxis (GLdouble v[3]); . Macro Definition Documentation. ABS. #define ABS; (; ; x); ((x) < 0 ? -(x) : (x)). Definition at line 65 of file normal.c. Dot. #define Dot; (; ; u, . ; v. ); (u[0]*v[0] + u[1]*v[1] + u[2]*v[2]). Definition at line 49 of file normal.c. FALSE. #define FALSE0. Definition at line 46 of file normal.c. S_UNIT_X. #define S_UNIT_X1.0. Definition at line 190 of file normal.c. S_UNIT_Y. #define S_UNIT_Y0.0. Definition at line 191 of file normal.c. TRUE. #define TRUE1. Definition at line 43 of file normal.c. Function Documentation. __gl_projectPolygon(). void __gl_projectPolygon ; (; GLUtesselator *; tess). Definition at line 198 of file normal.c. CheckOrientation(). static void CheckOrientation ; (; GLUtesselator *; tess). static . Definition at line 141 of file normal.c. ComputeNormal(). static void ComputeNormal ; (; GLUtesselator *; tess, . GLdouble; norm[3]. ). static . Definition at line 76 of file normal.c. LongAxis(). static int LongAxis ; (; GLdouble; v[3]). static . Definition at line 67 of file normal.c. graf3deve7glunormal.c. ROOT master - Reference Guide Generated on Tue Nov 5",MatchSource.WIKI,doc/master/normal_8c.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/normal_8c.html
https://root.cern/doc/master/normal_8c.html:285,Testability,assert,assert,285,". ROOT: graf3d/eve7/glu/normal.c File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. Macros |; Functions ; normal.c File Reference. #include ""gluos.h""; #include ""mesh.h""; #include ""tess.h""; #include ""normal.h""; #include <math.h>; #include <assert.h>. Include dependency graph for normal.c:. This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead. Macros; #defineABS(x)((x) < 0 ? -(x) : (x)); ; #defineDot(u, v)(u[0]*v[0] + u[1]*v[1] + u[2]*v[2]); ; #defineFALSE0; ; #defineS_UNIT_X1.0; ; #defineS_UNIT_Y0.0; ; #defineTRUE1; . Functions; void__gl_projectPolygon (GLUtesselator *tess); ; static voidCheckOrientation (GLUtesselator *tess); ; static voidComputeNormal (GLUtesselator *tess, GLdouble norm[3]); ; static intLongAxis (GLdouble v[3]); . Macro Definition Documentation. ABS. #define ABS; (; ; x); ((x) < 0 ? -(x) : (x)). Definition at line 65 of file normal.c. Dot. #define Dot; (; ; u, . ; v. ); (u[0]*v[0] + u[1]*v[1] + u[2]*v[2]). Definition at line 49 of file normal.c. FALSE. #define FALSE0. Definition at line 46 of file normal.c. S_UNIT_X. #define S_UNIT_X1.0. Definition at line 190 of file normal.c. S_UNIT_Y. #define S_UNIT_Y0.0. Definition at line 191 of file normal.c. TRUE. #define TRUE1. Definition at line 43 of file normal.c. Function Documentation. __gl_projectPolygon(). void __gl_projectPolygon ; (; GLUtesselator *; tess). Definition at line 198 of file normal.c. CheckOrientation(). static void CheckOrientation ; (; GLUtesselator *; tess). static . Definition at line 141 of file normal.c. ComputeNormal(). static void ComputeNormal ; (; GLUtesselator *; tess, . GLdouble; norm[3]. ). static . Definition at line 76 of file normal.c. LongAxis(). static int LongAxis ; (; GLdouble; v[3]). static . Definition at line 67 of file normal.c. graf3deve7glunormal.c. ROOT master - Reference Guide Generated on Tue Nov 5",MatchSource.WIKI,doc/master/normal_8c.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/normal_8c.html
https://root.cern/doc/master/ntpl001__staff_8C.html:389,Integrability,interface,interface,389,". ROOT: tutorials/v7/ntuple/ntpl001_staff.C File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. ntpl001_staff.C File ReferenceTutorials  ROOT 7 tutorials  ROOT 7 ntuple tutorials. Detailed Description; Write and read tabular data with RNTuple. ; Adapted from the cernbuild and cernstaff tree tutorials. Illustrates the type-safe ntuple model interface, which is used to define a data model that is in a second step taken by an ntuple reader or writer. ; // NOTE: The RNTuple classes are experimental at this point.; // Functionality, interface, and data format is still subject to changes.; // Do not use for real data!; ; #include <ROOT/RNTupleModel.hxx>; #include <ROOT/RNTupleReader.hxx>; #include <ROOT/RNTupleWriter.hxx>; ; #include <TCanvas.h>; #include <TH1I.h>; #include <TROOT.h>; #include <TString.h>; ; #include <cassert>; #include <cstdio>; #include <fstream>; #include <iostream>; #include <memory>; #include <string>; #include <sstream>; #include <utility>; ; // Import classes from experimental namespace for the time being; using RNTupleModel = ROOT::Experimental::RNTupleModel;; using RNTupleReader = ROOT::Experimental::RNTupleReader;; using RNTupleWriter = ROOT::Experimental::RNTupleWriter;; ; constexpr char const* kNTupleFileName = ""ntpl001_staff.root"";; ; void Ingest() {; // The input file cernstaff.dat is a copy of the CERN staff data base from 1988; ifstream fin(gROOT->GetTutorialDir() + ""/tree/cernstaff.dat"");; assert(fin.is_open());; ; // We create a unique pointer to an empty data model; auto model = RNTupleModel::Create();; ; // To define the data model, we create fields with a given C++ type and name. Fields are roughly TTree branches.; // MakeField returns a shared pointer to a memory location that we can populate to fill the ntuple with data; auto fldCategory = model->MakeField<int>(""Category"");; auto fldFlag = model->MakeField<unsigned int>(""Flag"");; auto fldAge = model->MakeField<int>(""Age"");; auto fldServi",MatchSource.WIKI,doc/master/ntpl001__staff_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ntpl001__staff_8C.html
https://root.cern/doc/master/ntpl001__staff_8C.html:581,Integrability,interface,interface,581,". ROOT: tutorials/v7/ntuple/ntpl001_staff.C File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. ntpl001_staff.C File ReferenceTutorials  ROOT 7 tutorials  ROOT 7 ntuple tutorials. Detailed Description; Write and read tabular data with RNTuple. ; Adapted from the cernbuild and cernstaff tree tutorials. Illustrates the type-safe ntuple model interface, which is used to define a data model that is in a second step taken by an ntuple reader or writer. ; // NOTE: The RNTuple classes are experimental at this point.; // Functionality, interface, and data format is still subject to changes.; // Do not use for real data!; ; #include <ROOT/RNTupleModel.hxx>; #include <ROOT/RNTupleReader.hxx>; #include <ROOT/RNTupleWriter.hxx>; ; #include <TCanvas.h>; #include <TH1I.h>; #include <TROOT.h>; #include <TString.h>; ; #include <cassert>; #include <cstdio>; #include <fstream>; #include <iostream>; #include <memory>; #include <string>; #include <sstream>; #include <utility>; ; // Import classes from experimental namespace for the time being; using RNTupleModel = ROOT::Experimental::RNTupleModel;; using RNTupleReader = ROOT::Experimental::RNTupleReader;; using RNTupleWriter = ROOT::Experimental::RNTupleWriter;; ; constexpr char const* kNTupleFileName = ""ntpl001_staff.root"";; ; void Ingest() {; // The input file cernstaff.dat is a copy of the CERN staff data base from 1988; ifstream fin(gROOT->GetTutorialDir() + ""/tree/cernstaff.dat"");; assert(fin.is_open());; ; // We create a unique pointer to an empty data model; auto model = RNTupleModel::Create();; ; // To define the data model, we create fields with a given C++ type and name. Fields are roughly TTree branches.; // MakeField returns a shared pointer to a memory location that we can populate to fill the ntuple with data; auto fldCategory = model->MakeField<int>(""Category"");; auto fldFlag = model->MakeField<unsigned int>(""Flag"");; auto fldAge = model->MakeField<int>(""Age"");; auto fldServi",MatchSource.WIKI,doc/master/ntpl001__staff_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ntpl001__staff_8C.html
https://root.cern/doc/master/ntpl001__staff_8C.html:371,Safety,safe,safe,371,". ROOT: tutorials/v7/ntuple/ntpl001_staff.C File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. ntpl001_staff.C File ReferenceTutorials  ROOT 7 tutorials  ROOT 7 ntuple tutorials. Detailed Description; Write and read tabular data with RNTuple. ; Adapted from the cernbuild and cernstaff tree tutorials. Illustrates the type-safe ntuple model interface, which is used to define a data model that is in a second step taken by an ntuple reader or writer. ; // NOTE: The RNTuple classes are experimental at this point.; // Functionality, interface, and data format is still subject to changes.; // Do not use for real data!; ; #include <ROOT/RNTupleModel.hxx>; #include <ROOT/RNTupleReader.hxx>; #include <ROOT/RNTupleWriter.hxx>; ; #include <TCanvas.h>; #include <TH1I.h>; #include <TROOT.h>; #include <TString.h>; ; #include <cassert>; #include <cstdio>; #include <fstream>; #include <iostream>; #include <memory>; #include <string>; #include <sstream>; #include <utility>; ; // Import classes from experimental namespace for the time being; using RNTupleModel = ROOT::Experimental::RNTupleModel;; using RNTupleReader = ROOT::Experimental::RNTupleReader;; using RNTupleWriter = ROOT::Experimental::RNTupleWriter;; ; constexpr char const* kNTupleFileName = ""ntpl001_staff.root"";; ; void Ingest() {; // The input file cernstaff.dat is a copy of the CERN staff data base from 1988; ifstream fin(gROOT->GetTutorialDir() + ""/tree/cernstaff.dat"");; assert(fin.is_open());; ; // We create a unique pointer to an empty data model; auto model = RNTupleModel::Create();; ; // To define the data model, we create fields with a given C++ type and name. Fields are roughly TTree branches.; // MakeField returns a shared pointer to a memory location that we can populate to fill the ntuple with data; auto fldCategory = model->MakeField<int>(""Category"");; auto fldFlag = model->MakeField<unsigned int>(""Flag"");; auto fldAge = model->MakeField<int>(""Age"");; auto fldServi",MatchSource.WIKI,doc/master/ntpl001__staff_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ntpl001__staff_8C.html
https://root.cern/doc/master/ntpl001__staff_8C.html:1488,Testability,assert,assert,1488,"r writer. ; // NOTE: The RNTuple classes are experimental at this point.; // Functionality, interface, and data format is still subject to changes.; // Do not use for real data!; ; #include <ROOT/RNTupleModel.hxx>; #include <ROOT/RNTupleReader.hxx>; #include <ROOT/RNTupleWriter.hxx>; ; #include <TCanvas.h>; #include <TH1I.h>; #include <TROOT.h>; #include <TString.h>; ; #include <cassert>; #include <cstdio>; #include <fstream>; #include <iostream>; #include <memory>; #include <string>; #include <sstream>; #include <utility>; ; // Import classes from experimental namespace for the time being; using RNTupleModel = ROOT::Experimental::RNTupleModel;; using RNTupleReader = ROOT::Experimental::RNTupleReader;; using RNTupleWriter = ROOT::Experimental::RNTupleWriter;; ; constexpr char const* kNTupleFileName = ""ntpl001_staff.root"";; ; void Ingest() {; // The input file cernstaff.dat is a copy of the CERN staff data base from 1988; ifstream fin(gROOT->GetTutorialDir() + ""/tree/cernstaff.dat"");; assert(fin.is_open());; ; // We create a unique pointer to an empty data model; auto model = RNTupleModel::Create();; ; // To define the data model, we create fields with a given C++ type and name. Fields are roughly TTree branches.; // MakeField returns a shared pointer to a memory location that we can populate to fill the ntuple with data; auto fldCategory = model->MakeField<int>(""Category"");; auto fldFlag = model->MakeField<unsigned int>(""Flag"");; auto fldAge = model->MakeField<int>(""Age"");; auto fldService = model->MakeField<int>(""Service"");; auto fldChildren = model->MakeField<int>(""Children"");; auto fldGrade = model->MakeField<int>(""Grade"");; auto fldStep = model->MakeField<int>(""Step"");; auto fldHrweek = model->MakeField<int>(""Hrweek"");; auto fldCost = model->MakeField<int>(""Cost"");; auto fldDivision = model->MakeField<std::string>(""Division"");; auto fldNation = model->MakeField<std::string>(""Nation"");; ; // We hand-over the data model to a newly created ntuple of name ""Staff"", st",MatchSource.WIKI,doc/master/ntpl001__staff_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ntpl001__staff_8C.html
https://root.cern/doc/master/ntpl001__staff_8C_source.html:401,Integrability,interface,interface,401,". ROOT: tutorials/v7/ntuple/ntpl001_staff.C Source File. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. ntpl001_staff.C. Go to the documentation of this file. 1/// \file; 2/// \ingroup tutorial_ntuple; 3/// \notebook; 4/// Write and read tabular data with RNTuple. Adapted from the cernbuild and cernstaff tree tutorials.; 5/// Illustrates the type-safe ntuple model interface, which is used to define a data model that is in a second step; 6/// taken by an ntuple reader or writer.; 7///; 8/// \macro_image; 9/// \macro_code; 10///; 11/// \date April 2019; 12/// \author The ROOT Team; 13 ; 14// NOTE: The RNTuple classes are experimental at this point.; 15// Functionality, interface, and data format is still subject to changes.; 16// Do not use for real data!; 17 ; 18#include <ROOT/RNTupleModel.hxx>; 19#include <ROOT/RNTupleReader.hxx>; 20#include <ROOT/RNTupleWriter.hxx>; 21 ; 22#include <TCanvas.h>; 23#include <TH1I.h>; 24#include <TROOT.h>; 25#include <TString.h>; 26 ; 27#include <cassert>; 28#include <cstdio>; 29#include <fstream>; 30#include <iostream>; 31#include <memory>; 32#include <string>; 33#include <sstream>; 34#include <utility>; 35 ; 36// Import classes from experimental namespace for the time being; 37using RNTupleModel = ROOT::Experimental::RNTupleModel;; 38using RNTupleReader = ROOT::Experimental::RNTupleReader;; 39using RNTupleWriter = ROOT::Experimental::RNTupleWriter;; 40 ; 41constexpr char const* kNTupleFileName = ""ntpl001_staff.root"";; 42 ; 43void Ingest() {; 44 // The input file cernstaff.dat is a copy of the CERN staff data base from 1988; 45 ifstream fin(gROOT->GetTutorialDir() + ""/tree/cernstaff.dat"");; 46 assert(fin.is_open());; 47 ; 48 // We create a unique pointer to an empty data model; 49 auto model = RNTupleModel::Create();; 50 ; 51 // To define the data model, we create fields with a given C++ type and name. Fields are roughly TTree branches.; 52 // MakeField returns a shared pointer to a memory location th",MatchSource.WIKI,doc/master/ntpl001__staff_8C_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ntpl001__staff_8C_source.html
https://root.cern/doc/master/ntpl001__staff_8C_source.html:710,Integrability,interface,interface,710,". ROOT: tutorials/v7/ntuple/ntpl001_staff.C Source File. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. ntpl001_staff.C. Go to the documentation of this file. 1/// \file; 2/// \ingroup tutorial_ntuple; 3/// \notebook; 4/// Write and read tabular data with RNTuple. Adapted from the cernbuild and cernstaff tree tutorials.; 5/// Illustrates the type-safe ntuple model interface, which is used to define a data model that is in a second step; 6/// taken by an ntuple reader or writer.; 7///; 8/// \macro_image; 9/// \macro_code; 10///; 11/// \date April 2019; 12/// \author The ROOT Team; 13 ; 14// NOTE: The RNTuple classes are experimental at this point.; 15// Functionality, interface, and data format is still subject to changes.; 16// Do not use for real data!; 17 ; 18#include <ROOT/RNTupleModel.hxx>; 19#include <ROOT/RNTupleReader.hxx>; 20#include <ROOT/RNTupleWriter.hxx>; 21 ; 22#include <TCanvas.h>; 23#include <TH1I.h>; 24#include <TROOT.h>; 25#include <TString.h>; 26 ; 27#include <cassert>; 28#include <cstdio>; 29#include <fstream>; 30#include <iostream>; 31#include <memory>; 32#include <string>; 33#include <sstream>; 34#include <utility>; 35 ; 36// Import classes from experimental namespace for the time being; 37using RNTupleModel = ROOT::Experimental::RNTupleModel;; 38using RNTupleReader = ROOT::Experimental::RNTupleReader;; 39using RNTupleWriter = ROOT::Experimental::RNTupleWriter;; 40 ; 41constexpr char const* kNTupleFileName = ""ntpl001_staff.root"";; 42 ; 43void Ingest() {; 44 // The input file cernstaff.dat is a copy of the CERN staff data base from 1988; 45 ifstream fin(gROOT->GetTutorialDir() + ""/tree/cernstaff.dat"");; 46 assert(fin.is_open());; 47 ; 48 // We create a unique pointer to an empty data model; 49 auto model = RNTupleModel::Create();; 50 ; 51 // To define the data model, we create fields with a given C++ type and name. Fields are roughly TTree branches.; 52 // MakeField returns a shared pointer to a memory location th",MatchSource.WIKI,doc/master/ntpl001__staff_8C_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ntpl001__staff_8C_source.html
https://root.cern/doc/master/ntpl001__staff_8C_source.html:383,Safety,safe,safe,383,". ROOT: tutorials/v7/ntuple/ntpl001_staff.C Source File. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. ntpl001_staff.C. Go to the documentation of this file. 1/// \file; 2/// \ingroup tutorial_ntuple; 3/// \notebook; 4/// Write and read tabular data with RNTuple. Adapted from the cernbuild and cernstaff tree tutorials.; 5/// Illustrates the type-safe ntuple model interface, which is used to define a data model that is in a second step; 6/// taken by an ntuple reader or writer.; 7///; 8/// \macro_image; 9/// \macro_code; 10///; 11/// \date April 2019; 12/// \author The ROOT Team; 13 ; 14// NOTE: The RNTuple classes are experimental at this point.; 15// Functionality, interface, and data format is still subject to changes.; 16// Do not use for real data!; 17 ; 18#include <ROOT/RNTupleModel.hxx>; 19#include <ROOT/RNTupleReader.hxx>; 20#include <ROOT/RNTupleWriter.hxx>; 21 ; 22#include <TCanvas.h>; 23#include <TH1I.h>; 24#include <TROOT.h>; 25#include <TString.h>; 26 ; 27#include <cassert>; 28#include <cstdio>; 29#include <fstream>; 30#include <iostream>; 31#include <memory>; 32#include <string>; 33#include <sstream>; 34#include <utility>; 35 ; 36// Import classes from experimental namespace for the time being; 37using RNTupleModel = ROOT::Experimental::RNTupleModel;; 38using RNTupleReader = ROOT::Experimental::RNTupleReader;; 39using RNTupleWriter = ROOT::Experimental::RNTupleWriter;; 40 ; 41constexpr char const* kNTupleFileName = ""ntpl001_staff.root"";; 42 ; 43void Ingest() {; 44 // The input file cernstaff.dat is a copy of the CERN staff data base from 1988; 45 ifstream fin(gROOT->GetTutorialDir() + ""/tree/cernstaff.dat"");; 46 assert(fin.is_open());; 47 ; 48 // We create a unique pointer to an empty data model; 49 auto model = RNTupleModel::Create();; 50 ; 51 // To define the data model, we create fields with a given C++ type and name. Fields are roughly TTree branches.; 52 // MakeField returns a shared pointer to a memory location th",MatchSource.WIKI,doc/master/ntpl001__staff_8C_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ntpl001__staff_8C_source.html
https://root.cern/doc/master/ntpl001__staff_8C_source.html:1688,Testability,assert,assert,1688,"; 15// Functionality, interface, and data format is still subject to changes.; 16// Do not use for real data!; 17 ; 18#include <ROOT/RNTupleModel.hxx>; 19#include <ROOT/RNTupleReader.hxx>; 20#include <ROOT/RNTupleWriter.hxx>; 21 ; 22#include <TCanvas.h>; 23#include <TH1I.h>; 24#include <TROOT.h>; 25#include <TString.h>; 26 ; 27#include <cassert>; 28#include <cstdio>; 29#include <fstream>; 30#include <iostream>; 31#include <memory>; 32#include <string>; 33#include <sstream>; 34#include <utility>; 35 ; 36// Import classes from experimental namespace for the time being; 37using RNTupleModel = ROOT::Experimental::RNTupleModel;; 38using RNTupleReader = ROOT::Experimental::RNTupleReader;; 39using RNTupleWriter = ROOT::Experimental::RNTupleWriter;; 40 ; 41constexpr char const* kNTupleFileName = ""ntpl001_staff.root"";; 42 ; 43void Ingest() {; 44 // The input file cernstaff.dat is a copy of the CERN staff data base from 1988; 45 ifstream fin(gROOT->GetTutorialDir() + ""/tree/cernstaff.dat"");; 46 assert(fin.is_open());; 47 ; 48 // We create a unique pointer to an empty data model; 49 auto model = RNTupleModel::Create();; 50 ; 51 // To define the data model, we create fields with a given C++ type and name. Fields are roughly TTree branches.; 52 // MakeField returns a shared pointer to a memory location that we can populate to fill the ntuple with data; 53 auto fldCategory = model->MakeField<int>(""Category"");; 54 auto fldFlag = model->MakeField<unsigned int>(""Flag"");; 55 auto fldAge = model->MakeField<int>(""Age"");; 56 auto fldService = model->MakeField<int>(""Service"");; 57 auto fldChildren = model->MakeField<int>(""Children"");; 58 auto fldGrade = model->MakeField<int>(""Grade"");; 59 auto fldStep = model->MakeField<int>(""Step"");; 60 auto fldHrweek = model->MakeField<int>(""Hrweek"");; 61 auto fldCost = model->MakeField<int>(""Cost"");; 62 auto fldDivision = model->MakeField<std::string>(""Division"");; 63 auto fldNation = model->MakeField<std::string>(""Nation"");; 64 ; 65 // We hand-over t",MatchSource.WIKI,doc/master/ntpl001__staff_8C_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ntpl001__staff_8C_source.html
https://root.cern/doc/master/ntpl008__import_8C.html:396,Integrability,interface,interface,396,". ROOT: tutorials/v7/ntuple/ntpl008_import.C File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. ntpl008_import.C File ReferenceTutorials  ROOT 7 tutorials  ROOT 7 ntuple tutorials. Detailed Description; Example of converting data stored in a TTree into an RNTuple . ; // NOTE: The RNTuple classes are experimental at this point.; // Functionality, interface, and data format is still subject to changes.; // Do not use for real data!; ; #include <ROOT/RNTupleDS.hxx>; #include <ROOT/RNTupleImporter.hxx>; #include <ROOT/RNTupleReader.hxx>; #include <ROOT/RPageStorageFile.hxx>; ; #include <TFile.h>; #include <TROOT.h>; #include <TSystem.h>; ; // Import classes from experimental namespace for the time being.; using RNTupleImporter = ROOT::Experimental::RNTupleImporter;; using RNTupleReader = ROOT::Experimental::RNTupleReader;; ; // Input and output.; constexpr char const *kTreeFileName = ""http://root.cern.ch/files/HiggsTauTauReduced/GluGluToHToTauTau.root"";; constexpr char const *kTreeName = ""Events"";; constexpr char const *kNTupleFileName = ""ntpl008_import.root"";; ; void ntpl008_import(); {; // RNTupleImporter appends keys to the output file; make sure a second run of the tutorial does not fail; // with `Key 'Events' already exists in file ntpl008_import.root` by removing the output file.; gSystem->Unlink(kNTupleFileName);; ; // Use multiple threads to compress RNTuple data.; ROOT::EnableImplicitMT();; ; // Create a new RNTupleImporter object.; auto importer = RNTupleImporter::Create(kTreeFileName, kTreeName, kNTupleFileName);; ; // Begin importing.; importer->Import();; ; // Inspect the schema of the written RNTuple.; auto file = std::unique_ptr<TFile>(TFile::Open(kNTupleFileName));; if (!file || file->IsZombie()) {; std::cerr << ""cannot open "" << kNTupleFileName << std::endl;; return;; }; auto ntpl = std::unique_ptr<ROOT::RNTuple>(file->Get<ROOT::RNTuple>(""Events""));; auto reader = RNTupleReader::Open(*ntpl);; reader->PrintI",MatchSource.WIKI,doc/master/ntpl008__import_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ntpl008__import_8C.html
https://root.cern/doc/master/ntpl008__import_8C.html:2579,Integrability,interface,interface,2579,"TupleImporter object.; auto importer = RNTupleImporter::Create(kTreeFileName, kTreeName, kNTupleFileName);; ; // Begin importing.; importer->Import();; ; // Inspect the schema of the written RNTuple.; auto file = std::unique_ptr<TFile>(TFile::Open(kNTupleFileName));; if (!file || file->IsZombie()) {; std::cerr << ""cannot open "" << kNTupleFileName << std::endl;; return;; }; auto ntpl = std::unique_ptr<ROOT::RNTuple>(file->Get<ROOT::RNTuple>(""Events""));; auto reader = RNTupleReader::Open(*ntpl);; reader->PrintInfo();; ; ROOT::RDataFrame df(""Events"", kNTupleFileName);; df.Histo1D({""Jet_pt"", ""Jet_pt"", 100, 0, 0}, ""Jet_pt"")->DrawCopy();; }; RNTupleDS.hxx; RNTupleImporter.hxx; RNTupleReader.hxx; RPageStorageFile.hxx; TFile.h; TROOT.h; TSystem.h; gSystemR__EXTERN TSystem * gSystemDefinition TSystem.h:561; ROOT::Experimental::RNTupleImporterConverts a TTree into an RNTuple.Definition RNTupleImporter.hxx:103; ROOT::Experimental::RNTupleReaderAn RNTuple that is used to read data from storage.Definition RNTupleReader.hxx:71; ROOT::RDataFrameROOT's RDataFrame offers a modern, high-level interface for analysis of data stored in TTree ,...Definition RDataFrame.hxx:41; ROOT::RNTupleRepresentation of an RNTuple data set in a ROOT file.Definition RNTuple.hxx:69; TFile::Openstatic TFile * Open(const char *name, Option_t *option="""", const char *ftitle="""", Int_t compress=ROOT::RCompressionSetting::EDefaults::kUseCompiledDefault, Int_t netopt=0)Create / open a file.Definition TFile.cxx:4089; TSystem::Unlinkvirtual int Unlink(const char *name)Unlink, i.e.Definition TSystem.cxx:1381; ROOT::EnableImplicitMTvoid EnableImplicitMT(UInt_t numthreads=0)Enable ROOT's implicit multi-threading for all objects and methods that provide an internal paralleli...Definition TROOT.cxx:539; DateDecember 2022 ; AuthorThe ROOT Team ; Definition in file ntpl008_import.C. tutorialsv7ntuplentpl008_import.C. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:31 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/ntpl008__import_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ntpl008__import_8C.html
https://root.cern/doc/master/ntpl008__import_8C.html:3162,Performance,multi-thread,multi-threading,3162,"TupleImporter object.; auto importer = RNTupleImporter::Create(kTreeFileName, kTreeName, kNTupleFileName);; ; // Begin importing.; importer->Import();; ; // Inspect the schema of the written RNTuple.; auto file = std::unique_ptr<TFile>(TFile::Open(kNTupleFileName));; if (!file || file->IsZombie()) {; std::cerr << ""cannot open "" << kNTupleFileName << std::endl;; return;; }; auto ntpl = std::unique_ptr<ROOT::RNTuple>(file->Get<ROOT::RNTuple>(""Events""));; auto reader = RNTupleReader::Open(*ntpl);; reader->PrintInfo();; ; ROOT::RDataFrame df(""Events"", kNTupleFileName);; df.Histo1D({""Jet_pt"", ""Jet_pt"", 100, 0, 0}, ""Jet_pt"")->DrawCopy();; }; RNTupleDS.hxx; RNTupleImporter.hxx; RNTupleReader.hxx; RPageStorageFile.hxx; TFile.h; TROOT.h; TSystem.h; gSystemR__EXTERN TSystem * gSystemDefinition TSystem.h:561; ROOT::Experimental::RNTupleImporterConverts a TTree into an RNTuple.Definition RNTupleImporter.hxx:103; ROOT::Experimental::RNTupleReaderAn RNTuple that is used to read data from storage.Definition RNTupleReader.hxx:71; ROOT::RDataFrameROOT's RDataFrame offers a modern, high-level interface for analysis of data stored in TTree ,...Definition RDataFrame.hxx:41; ROOT::RNTupleRepresentation of an RNTuple data set in a ROOT file.Definition RNTuple.hxx:69; TFile::Openstatic TFile * Open(const char *name, Option_t *option="""", const char *ftitle="""", Int_t compress=ROOT::RCompressionSetting::EDefaults::kUseCompiledDefault, Int_t netopt=0)Create / open a file.Definition TFile.cxx:4089; TSystem::Unlinkvirtual int Unlink(const char *name)Unlink, i.e.Definition TSystem.cxx:1381; ROOT::EnableImplicitMTvoid EnableImplicitMT(UInt_t numthreads=0)Enable ROOT's implicit multi-threading for all objects and methods that provide an internal paralleli...Definition TROOT.cxx:539; DateDecember 2022 ; AuthorThe ROOT Team ; Definition in file ntpl008_import.C. tutorialsv7ntuplentpl008_import.C. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:31 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/ntpl008__import_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ntpl008__import_8C.html
https://root.cern/doc/master/ntpl008__import_8C_source.html:514,Integrability,interface,interface,514,". ROOT: tutorials/v7/ntuple/ntpl008_import.C Source File. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. ntpl008_import.C. Go to the documentation of this file. 1/// \file; 2/// \ingroup tutorial_ntuple; 3/// \notebook; 4/// Example of converting data stored in a TTree into an RNTuple; 5///; 6/// \macro_image; 7/// \macro_code; 8///; 9/// \date December 2022; 10/// \author The ROOT Team; 11 ; 12// NOTE: The RNTuple classes are experimental at this point.; 13// Functionality, interface, and data format is still subject to changes.; 14// Do not use for real data!; 15 ; 16#include <ROOT/RNTupleDS.hxx>; 17#include <ROOT/RNTupleImporter.hxx>; 18#include <ROOT/RNTupleReader.hxx>; 19#include <ROOT/RPageStorageFile.hxx>; 20 ; 21#include <TFile.h>; 22#include <TROOT.h>; 23#include <TSystem.h>; 24 ; 25// Import classes from experimental namespace for the time being.; 26using RNTupleImporter = ROOT::Experimental::RNTupleImporter;; 27using RNTupleReader = ROOT::Experimental::RNTupleReader;; 28 ; 29// Input and output.; 30constexpr char const *kTreeFileName = ""http://root.cern.ch/files/HiggsTauTauReduced/GluGluToHToTauTau.root"";; 31constexpr char const *kTreeName = ""Events"";; 32constexpr char const *kNTupleFileName = ""ntpl008_import.root"";; 33 ; 34void ntpl008_import(); 35{; 36 // RNTupleImporter appends keys to the output file; make sure a second run of the tutorial does not fail; 37 // with `Key 'Events' already exists in file ntpl008_import.root` by removing the output file.; 38 gSystem->Unlink(kNTupleFileName);; 39 ; 40 // Use multiple threads to compress RNTuple data.; 41 ROOT::EnableImplicitMT();; 42 ; 43 // Create a new RNTupleImporter object.; 44 auto importer = RNTupleImporter::Create(kTreeFileName, kTreeName, kNTupleFileName);; 45 ; 46 // Begin importing.; 47 importer->Import();; 48 ; 49 // Inspect the schema of the written RNTuple.; 50 auto file = std::unique_ptr<TFile>(TFile::Open(kNTupleFileName));; 51 if (!file || file->IsZombie()) ",MatchSource.WIKI,doc/master/ntpl008__import_8C_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ntpl008__import_8C_source.html
https://root.cern/doc/master/ntpl008__import_8C_source.html:2823,Integrability,interface,interface,2823,"42 ; 43 // Create a new RNTupleImporter object.; 44 auto importer = RNTupleImporter::Create(kTreeFileName, kTreeName, kNTupleFileName);; 45 ; 46 // Begin importing.; 47 importer->Import();; 48 ; 49 // Inspect the schema of the written RNTuple.; 50 auto file = std::unique_ptr<TFile>(TFile::Open(kNTupleFileName));; 51 if (!file || file->IsZombie()) {; 52 std::cerr << ""cannot open "" << kNTupleFileName << std::endl;; 53 return;; 54 }; 55 auto ntpl = std::unique_ptr<ROOT::RNTuple>(file->Get<ROOT::RNTuple>(""Events""));; 56 auto reader = RNTupleReader::Open(*ntpl);; 57 reader->PrintInfo();; 58 ; 59 ROOT::RDataFrame df(""Events"", kNTupleFileName);; 60 df.Histo1D({""Jet_pt"", ""Jet_pt"", 100, 0, 0}, ""Jet_pt"")->DrawCopy();; 61}; RNTupleDS.hxx; RNTupleImporter.hxx; RNTupleReader.hxx; RPageStorageFile.hxx; TFile.h; TROOT.h; TSystem.h; gSystemR__EXTERN TSystem * gSystemDefinition TSystem.h:561; ROOT::Experimental::RNTupleImporterConverts a TTree into an RNTuple.Definition RNTupleImporter.hxx:103; ROOT::Experimental::RNTupleReaderAn RNTuple that is used to read data from storage.Definition RNTupleReader.hxx:71; ROOT::RDataFrameROOT's RDataFrame offers a modern, high-level interface for analysis of data stored in TTree ,...Definition RDataFrame.hxx:41; ROOT::RNTupleRepresentation of an RNTuple data set in a ROOT file.Definition RNTuple.hxx:69; TFile::Openstatic TFile * Open(const char *name, Option_t *option="""", const char *ftitle="""", Int_t compress=ROOT::RCompressionSetting::EDefaults::kUseCompiledDefault, Int_t netopt=0)Create / open a file.Definition TFile.cxx:4089; TSystem::Unlinkvirtual int Unlink(const char *name)Unlink, i.e.Definition TSystem.cxx:1381; ROOT::EnableImplicitMTvoid EnableImplicitMT(UInt_t numthreads=0)Enable ROOT's implicit multi-threading for all objects and methods that provide an internal paralleli...Definition TROOT.cxx:539. tutorialsv7ntuplentpl008_import.C. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:11 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/ntpl008__import_8C_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ntpl008__import_8C_source.html
https://root.cern/doc/master/ntpl008__import_8C_source.html:3406,Performance,multi-thread,multi-threading,3406,"42 ; 43 // Create a new RNTupleImporter object.; 44 auto importer = RNTupleImporter::Create(kTreeFileName, kTreeName, kNTupleFileName);; 45 ; 46 // Begin importing.; 47 importer->Import();; 48 ; 49 // Inspect the schema of the written RNTuple.; 50 auto file = std::unique_ptr<TFile>(TFile::Open(kNTupleFileName));; 51 if (!file || file->IsZombie()) {; 52 std::cerr << ""cannot open "" << kNTupleFileName << std::endl;; 53 return;; 54 }; 55 auto ntpl = std::unique_ptr<ROOT::RNTuple>(file->Get<ROOT::RNTuple>(""Events""));; 56 auto reader = RNTupleReader::Open(*ntpl);; 57 reader->PrintInfo();; 58 ; 59 ROOT::RDataFrame df(""Events"", kNTupleFileName);; 60 df.Histo1D({""Jet_pt"", ""Jet_pt"", 100, 0, 0}, ""Jet_pt"")->DrawCopy();; 61}; RNTupleDS.hxx; RNTupleImporter.hxx; RNTupleReader.hxx; RPageStorageFile.hxx; TFile.h; TROOT.h; TSystem.h; gSystemR__EXTERN TSystem * gSystemDefinition TSystem.h:561; ROOT::Experimental::RNTupleImporterConverts a TTree into an RNTuple.Definition RNTupleImporter.hxx:103; ROOT::Experimental::RNTupleReaderAn RNTuple that is used to read data from storage.Definition RNTupleReader.hxx:71; ROOT::RDataFrameROOT's RDataFrame offers a modern, high-level interface for analysis of data stored in TTree ,...Definition RDataFrame.hxx:41; ROOT::RNTupleRepresentation of an RNTuple data set in a ROOT file.Definition RNTuple.hxx:69; TFile::Openstatic TFile * Open(const char *name, Option_t *option="""", const char *ftitle="""", Int_t compress=ROOT::RCompressionSetting::EDefaults::kUseCompiledDefault, Int_t netopt=0)Create / open a file.Definition TFile.cxx:4089; TSystem::Unlinkvirtual int Unlink(const char *name)Unlink, i.e.Definition TSystem.cxx:1381; ROOT::EnableImplicitMTvoid EnableImplicitMT(UInt_t numthreads=0)Enable ROOT's implicit multi-threading for all objects and methods that provide an internal paralleli...Definition TROOT.cxx:539. tutorialsv7ntuplentpl008_import.C. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:11 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/ntpl008__import_8C_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ntpl008__import_8C_source.html
https://root.cern/doc/master/ntuple1_8C.html:5962,Modifiability,variab,variables,5962,"_t align=11)Set the text alignment.Definition TAttText.h:42; TBenchmark::GetBenchInt_t GetBench(const char *name) constReturns index of Benchmark name.Definition TBenchmark.cxx:106; TBenchmark::Startvirtual void Start(const char *name)Starts Benchmark with the specified name.Definition TBenchmark.cxx:172; TBenchmark::Showvirtual void Show(const char *name)Stops Benchmark name and Prints results.Definition TBenchmark.cxx:155; TCanvasThe Canvas class.Definition TCanvas.h:23; TF11-Dim function classDefinition TF1.h:233; TFileA ROOT file is an on-disk file, usually with extension .root, that stores objects in a file-system-li...Definition TFile.h:53; TH1::Fitvirtual TFitResultPtr Fit(const char *formula, Option_t *option="""", Option_t *goption="""", Double_t xmin=0, Double_t xmax=0)Fit histogram with function fname.Definition TH1.cxx:3898; TH1::GetFunctionvirtual TF1 * GetFunction(const char *name) constReturn pointer to function with name.Definition TH1.cxx:9051; TNtupleA simple TTree restricted to a list of float variables only.Definition TNtuple.h:28; TPadThe most important graphics class in the ROOT system.Definition TPad.h:28; TPad::SetGridvoid SetGrid(Int_t valuex=1, Int_t valuey=1) overrideDefinition TPad.h:335; TPad::SetLogyvoid SetLogy(Int_t value=1) overrideSet Lin/Log scale for Y.Definition TPad.cxx:6100; TPad::RedrawAxisvoid RedrawAxis(Option_t *option="""") overrideRedraw the frame axis.Definition TPad.cxx:5450; TPad::cdTVirtualPad * cd(Int_t subpadnumber=0) overrideSet Current pad.Definition TPad.cxx:693; TPad::GetFrameTFrame * GetFrame() overrideGet frame.Definition TPad.cxx:2955; TPad::Drawvoid Draw(Option_t *option="""") overrideDraw Pad in Current pad (re-parent pad if necessary).Definition TPad.cxx:1364; TPaveTextA Pave (see TPave) with text, lines or/and boxes inside.Definition TPaveText.h:21; TPaveText::AddTextvirtual TText * AddText(Double_t x1, Double_t y1, const char *label)Add a new Text line to this pavetext at given coordinates.Definition TPaveText.cx",MatchSource.WIKI,doc/master/ntuple1_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ntuple1_8C.html
https://root.cern/doc/master/ntuple1_8C.html:5919,Usability,simpl,simple,5919,"_t align=11)Set the text alignment.Definition TAttText.h:42; TBenchmark::GetBenchInt_t GetBench(const char *name) constReturns index of Benchmark name.Definition TBenchmark.cxx:106; TBenchmark::Startvirtual void Start(const char *name)Starts Benchmark with the specified name.Definition TBenchmark.cxx:172; TBenchmark::Showvirtual void Show(const char *name)Stops Benchmark name and Prints results.Definition TBenchmark.cxx:155; TCanvasThe Canvas class.Definition TCanvas.h:23; TF11-Dim function classDefinition TF1.h:233; TFileA ROOT file is an on-disk file, usually with extension .root, that stores objects in a file-system-li...Definition TFile.h:53; TH1::Fitvirtual TFitResultPtr Fit(const char *formula, Option_t *option="""", Option_t *goption="""", Double_t xmin=0, Double_t xmax=0)Fit histogram with function fname.Definition TH1.cxx:3898; TH1::GetFunctionvirtual TF1 * GetFunction(const char *name) constReturn pointer to function with name.Definition TH1.cxx:9051; TNtupleA simple TTree restricted to a list of float variables only.Definition TNtuple.h:28; TPadThe most important graphics class in the ROOT system.Definition TPad.h:28; TPad::SetGridvoid SetGrid(Int_t valuex=1, Int_t valuey=1) overrideDefinition TPad.h:335; TPad::SetLogyvoid SetLogy(Int_t value=1) overrideSet Lin/Log scale for Y.Definition TPad.cxx:6100; TPad::RedrawAxisvoid RedrawAxis(Option_t *option="""") overrideRedraw the frame axis.Definition TPad.cxx:5450; TPad::cdTVirtualPad * cd(Int_t subpadnumber=0) overrideSet Current pad.Definition TPad.cxx:693; TPad::GetFrameTFrame * GetFrame() overrideGet frame.Definition TPad.cxx:2955; TPad::Drawvoid Draw(Option_t *option="""") overrideDraw Pad in Current pad (re-parent pad if necessary).Definition TPad.cxx:1364; TPaveTextA Pave (see TPave) with text, lines or/and boxes inside.Definition TPaveText.h:21; TPaveText::AddTextvirtual TText * AddText(Double_t x1, Double_t y1, const char *label)Add a new Text line to this pavetext at given coordinates.Definition TPaveText.cx",MatchSource.WIKI,doc/master/ntuple1_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ntuple1_8C.html
https://root.cern/doc/master/nucleus_8C.html:2646,Availability,down,down,2646,">Rannor(x, y);; gRandom->Rannor(z,dummy);; if ( TMath::Sqrt(x*x + y*y + z*z) < 1) {; x = (2 * x - 1) * NucleusRadius;; y = (2 * y - 1) * NucleusRadius;; z = (2 * z - 1) * NucleusRadius;; top->AddNode(proton, i, new TGeoTranslation(x, y, z));; i++;; }; }; i = 0;; while ( i < nNeutrons) {; gRandom->Rannor(x, y);; gRandom->Rannor(z,dummy);; if ( TMath::Sqrt(x*x + y*y + z*z) < 1) {; x = (2 * x - 1) * NucleusRadius;; y = (2 * y - 1) * NucleusRadius;; z = (2 * z - 1) * NucleusRadius;; top->AddNode(neutron, i + nProtons, new TGeoTranslation(x, y, z));; i++;; }; }; geom->CloseGeometry();; geom->SetVisLevel(4);; top->Draw(""ogl"");; }; Int_tint Int_tDefinition RtypesCore.h:45; Double_tdouble Double_tDefinition RtypesCore.h:59; kRed@ kRedDefinition Rtypes.h:66; kBlue@ kBlueDefinition Rtypes.h:66; gRandomR__EXTERN TRandom * gRandomDefinition TRandom.h:62; TGeoManagerThe manager class for any TGeo geometry.Definition TGeoManager.h:44; TGeoManager::SetVisLevelvoid SetVisLevel(Int_t level=3)set default level down to which visualization is performedDefinition TGeoManager.cxx:2459; TGeoManager::CloseGeometryvoid CloseGeometry(Option_t *option=""d"")Closing geometry implies checking the geometry validity, fixing shapes with negative parameters (run-...Definition TGeoManager.cxx:1480; TGeoManager::MakeBoxTGeoVolume * MakeBox(const char *name, TGeoMedium *medium, Double_t dx, Double_t dy, Double_t dz)Make in one step a volume pointing to a box shape with given medium.Definition TGeoManager.cxx:3169; TGeoManager::MakeSphereTGeoVolume * MakeSphere(const char *name, TGeoMedium *medium, Double_t rmin, Double_t rmax, Double_t themin=0, Double_t themax=180, Double_t phimin=0, Double_t phimax=360)Make in one step a volume pointing to a sphere shape with given medium.Definition TGeoManager.cxx:3186; TGeoManager::SetTopVolumevoid SetTopVolume(TGeoVolume *vol)Set the top volume and corresponding node as starting point of the geometry.Definition TGeoManager.cxx:3655; TGeoManager::SetNsegmentsvoid Se",MatchSource.WIKI,doc/master/nucleus_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/nucleus_8C.html
https://root.cern/doc/master/nucleus_8C.html:4994,Energy Efficiency,power,power,4994,"ble_t themin=0, Double_t themax=180, Double_t phimin=0, Double_t phimax=360)Make in one step a volume pointing to a sphere shape with given medium.Definition TGeoManager.cxx:3186; TGeoManager::SetTopVolumevoid SetTopVolume(TGeoVolume *vol)Set the top volume and corresponding node as starting point of the geometry.Definition TGeoManager.cxx:3655; TGeoManager::SetNsegmentsvoid SetNsegments(Int_t nseg)Set number of segments for approximating circles in drawing.Definition TGeoManager.cxx:3594; TGeoMaterialBase class describing materials.Definition TGeoMaterial.h:34; TGeoMediumMedia are used to store properties related to tracking and which are useful only when using geometry ...Definition TGeoMedium.h:23; TGeoTranslationClass describing translations.Definition TGeoMatrix.h:116; TGeoVolumeTGeoVolume, TGeoVolumeMulti, TGeoVolumeAssembly are the volume classes.Definition TGeoVolume.h:43; TGeoVolume::AddNodevirtual TGeoNode * AddNode(TGeoVolume *vol, Int_t copy_no, TGeoMatrix *mat=nullptr, Option_t *option="""")Add a TGeoNode to the list of nodes.Definition TGeoVolume.cxx:975; TGeoVolume::Drawvoid Draw(Option_t *option="""") overridedraw top volume according to optionDefinition TGeoVolume.cxx:1206; TGeoVolume::SetLineColorvoid SetLineColor(Color_t lcolor) overrideSet the line color.Definition TGeoVolume.cxx:2169; TRandom::Rannorvirtual void Rannor(Float_t &a, Float_t &b)Return 2 numbers distributed following a gaussian with mean=0 and sigma=1.Definition TRandom.cxx:507; yDouble_t y[n]Definition legend1.C:17; xDouble_t x[n]Definition legend1.C:17; TMath::SqrtDouble_t Sqrt(Double_t x)Returns the square root of x.Definition TMath.h:662; TMath::PowerLongDouble_t Power(LongDouble_t x, LongDouble_t y)Returns x raised to the power y.Definition TMath.h:721; TMath::Piconstexpr Double_t Pi()Definition TMath.h:37; AuthorOtto Schaile ; Definition in file nucleus.C. tutorialsglnucleus.C. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:28 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/nucleus_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/nucleus_8C.html
https://root.cern/doc/master/nucleus_8C.html:2677,Performance,perform,performedDefinition,2677,">Rannor(x, y);; gRandom->Rannor(z,dummy);; if ( TMath::Sqrt(x*x + y*y + z*z) < 1) {; x = (2 * x - 1) * NucleusRadius;; y = (2 * y - 1) * NucleusRadius;; z = (2 * z - 1) * NucleusRadius;; top->AddNode(proton, i, new TGeoTranslation(x, y, z));; i++;; }; }; i = 0;; while ( i < nNeutrons) {; gRandom->Rannor(x, y);; gRandom->Rannor(z,dummy);; if ( TMath::Sqrt(x*x + y*y + z*z) < 1) {; x = (2 * x - 1) * NucleusRadius;; y = (2 * y - 1) * NucleusRadius;; z = (2 * z - 1) * NucleusRadius;; top->AddNode(neutron, i + nProtons, new TGeoTranslation(x, y, z));; i++;; }; }; geom->CloseGeometry();; geom->SetVisLevel(4);; top->Draw(""ogl"");; }; Int_tint Int_tDefinition RtypesCore.h:45; Double_tdouble Double_tDefinition RtypesCore.h:59; kRed@ kRedDefinition Rtypes.h:66; kBlue@ kBlueDefinition Rtypes.h:66; gRandomR__EXTERN TRandom * gRandomDefinition TRandom.h:62; TGeoManagerThe manager class for any TGeo geometry.Definition TGeoManager.h:44; TGeoManager::SetVisLevelvoid SetVisLevel(Int_t level=3)set default level down to which visualization is performedDefinition TGeoManager.cxx:2459; TGeoManager::CloseGeometryvoid CloseGeometry(Option_t *option=""d"")Closing geometry implies checking the geometry validity, fixing shapes with negative parameters (run-...Definition TGeoManager.cxx:1480; TGeoManager::MakeBoxTGeoVolume * MakeBox(const char *name, TGeoMedium *medium, Double_t dx, Double_t dy, Double_t dz)Make in one step a volume pointing to a box shape with given medium.Definition TGeoManager.cxx:3169; TGeoManager::MakeSphereTGeoVolume * MakeSphere(const char *name, TGeoMedium *medium, Double_t rmin, Double_t rmax, Double_t themin=0, Double_t themax=180, Double_t phimin=0, Double_t phimax=360)Make in one step a volume pointing to a sphere shape with given medium.Definition TGeoManager.cxx:3186; TGeoManager::SetTopVolumevoid SetTopVolume(TGeoVolume *vol)Set the top volume and corresponding node as starting point of the geometry.Definition TGeoManager.cxx:3655; TGeoManager::SetNsegmentsvoid Se",MatchSource.WIKI,doc/master/nucleus_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/nucleus_8C.html
https://root.cern/doc/master/numberEntry_8py.html:335,Deployability,update,updated,335,". ROOT: tutorials/pyroot/numberEntry.py File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. Namespaces ; numberEntry.py File ReferenceTutorials  PyRoot tutorials. Detailed Description; Example frame with one box where the user can increase or decrease a number and the shown value will be updated accordingly. ; ; import ROOT; ; ; class pMyMainFrame(ROOT.TGMainFrame):; def __init__(self, parent, width, height):; ROOT.TGMainFrame.__init__(self, parent, width, height); ; self.fHor1 = ROOT.TGHorizontalFrame(self, 60, 20, ROOT.kFixedWidth); self.fExit = ROOT.TGTextButton(self.fHor1, ""&Exit"", ""gApplication->Terminate(0)""); self.fExit.SetCommand('TPython::Exec( ""raise SystemExit"" )'); self.fHor1.AddFrame(self.fExit, ROOT.TGLayoutHints(; ROOT.kLHintsTop | ROOT.kLHintsLeft | ROOT.kLHintsExpandX, 4, 4, 4, 4)); self.AddFrame(self.fHor1, ROOT.TGLayoutHints(ROOT.kLHintsBottom | ROOT.kLHintsRight, 2, 2, 5, 1)); ; self.fNumber = ROOT.TGNumberEntry(self, 0, 9, 999, ROOT.TGNumberFormat.kNESInteger,; ROOT.TGNumberFormat.kNEANonNegative,; ROOT.TGNumberFormat.kNELLimitMinMax,; 0, 99999); self.fLabelDispatch = ROOT.TPyDispatcher(self.DoSetlabel); self.fNumber.Connect(""ValueSet(Long_t)"", ""TPyDispatcher"", self.fLabelDispatch, ""Dispatch()""); self.fNumber.GetNumberEntry().Connect(""ReturnPressed()"", ""TPyDispatcher"", self.fLabelDispatch, ""Dispatch()""); self.AddFrame(self.fNumber, ROOT.TGLayoutHints(ROOT.kLHintsTop | ROOT.kLHintsLeft, 5, 5, 5, 5)); self.fGframe = ROOT.TGGroupFrame(self, ""Value""); self.fLabel = ROOT.TGLabel(self.fGframe, ""No input.""); self.fGframe.AddFrame(self.fLabel, ROOT.TGLayoutHints(ROOT.kLHintsTop | ROOT.kLHintsLeft, 5, 5, 5, 5)); self.AddFrame(self.fGframe, ROOT.TGLayoutHints(ROOT.kLHintsExpandX, 2, 2, 1, 1)); ; self.SetCleanup(ROOT.kDeepCleanup); self.SetWindowName(""Number Entry""); self.MapSubwindows(); self.Resize(self.GetDefaultSize()); self.MapWindow(); ; def __del__(self):; self.Cleanup(); ; def DoSetlabel(self):; self.fLa",MatchSource.WIKI,doc/master/numberEntry_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/numberEntry_8py.html
https://root.cern/doc/master/NumericalMinimization_8C.html:1566,Availability,toler,tolerance,1566," #include ""Math/Factory.h""; #include ""Math/Functor.h""; #include ""TRandom2.h""; #include ""TError.h""; #include <iostream>; ; double RosenBrock(const double *xx ); {; const double x = xx[0];; const double y = xx[1];; const double tmp1 = y-x*x;; const double tmp2 = 1-x;; return 100*tmp1*tmp1+tmp2*tmp2;; }; ; int NumericalMinimization(const char * minName = ""Minuit2"",; const char *algoName = """" ,; int randomSeed = -1); {; // create minimizer giving a name and a name (optionally) for the specific; // algorithm; // possible choices are:; // minName algoName; // Minuit /Minuit2 Migrad, Simplex,Combined,Scan (default is Migrad); // Minuit2 Fumili2; // Fumili; // GSLMultiMin ConjugateFR, ConjugatePR, BFGS,; // BFGS2, SteepestDescent; // GSLMultiFit; // GSLSimAn; // Genetic; ROOT::Math::Minimizer* minimum =; ROOT::Math::Factory::CreateMinimizer(minName, algoName);; if (!minimum) {; std::cerr << ""Error: cannot create minimizer \"""" << minName; << ""\"". Maybe the required library was not built?"" << std::endl;; return 1;; }; ; // set tolerance , etc...; minimum->SetMaxFunctionCalls(1000000); // for Minuit/Minuit2; minimum->SetMaxIterations(10000); // for GSL; minimum->SetTolerance(0.001);; minimum->SetPrintLevel(1);; ; // create function wrapper for minimizer; // a IMultiGenFunction type; ROOT::Math::Functor f(&RosenBrock,2);; double step[2] = {0.01,0.01};; // starting point; ; double variable[2] = { -1.,1.2};; if (randomSeed >= 0) {; TRandom2 r(randomSeed);; variable[0] = r.Uniform(-20,20);; variable[1] = r.Uniform(-20,20);; }; ; minimum->SetFunction(f);; ; // Set the free variables to be minimized !; minimum->SetVariable(0,""x"",variable[0], step[0]);; minimum->SetVariable(1,""y"",variable[1], step[1]);; ; // do the minimization; minimum->Minimize();; ; const double *xs = minimum->X();; std::cout << ""Minimum: f("" << xs[0] << "","" << xs[1] << ""): ""; << minimum->MinValue() << std::endl;; ; // expected minimum is 0; if ( minimum->MinValue() < 1.E-4 ); std::cout << ""Minimizer "" << minName ",MatchSource.WIKI,doc/master/NumericalMinimization_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NumericalMinimization_8C.html
https://root.cern/doc/master/NumericalMinimization_8C.html:2954,Availability,error,error,2954,"2};; if (randomSeed >= 0) {; TRandom2 r(randomSeed);; variable[0] = r.Uniform(-20,20);; variable[1] = r.Uniform(-20,20);; }; ; minimum->SetFunction(f);; ; // Set the free variables to be minimized !; minimum->SetVariable(0,""x"",variable[0], step[0]);; minimum->SetVariable(1,""y"",variable[1], step[1]);; ; // do the minimization; minimum->Minimize();; ; const double *xs = minimum->X();; std::cout << ""Minimum: f("" << xs[0] << "","" << xs[1] << ""): ""; << minimum->MinValue() << std::endl;; ; // expected minimum is 0; if ( minimum->MinValue() < 1.E-4 ); std::cout << ""Minimizer "" << minName << "" - "" << algoName; << "" converged to the right minimum"" << std::endl;; else {; std::cout << ""Minimizer "" << minName << "" - "" << algoName; << "" failed to converge !!!"" << std::endl;; Error(""NumericalMinimization"",""fail to converge"");; }; ; return 0;; }; Functor.h; Minimizer.h; f#define f(i)Definition RSha256.hxx:104; TError.h; Errorvoid Error(const char *location, const char *msgfmt,...)Use this function in case an error occurred.Definition TError.cxx:185; rOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t rDefinition TGWin32VirtualXProxy.cxx:168; TRandom2.h; ROOT::Math::Factory::CreateMinimizerstatic ROOT::Math::Minimizer * CreateMinimizer(const std::string &minimizerType="""", const std::string &algoType="""")static method to create the corresponding Minimizer given the string Supported Minimizers types are: ...Definition Factory.cxx:63; ROOT::Math::FunctorDocumentation for class Functor class.Definition Functor.h:47; ROOT::Math::MinimizerAbstract Minimizer class, defining the interface for the various minimizer (like Minuit2,...Definition Minimizer.h:119; ROOT::Math::Minimizer::Xvirtual const double * X() const =0return pointer to X values at the minimum; ROOT::Math::Minimizer::SetMaxIterationsvoid SetMaxIterations(unsigned int maxite",MatchSource.WIKI,doc/master/NumericalMinimization_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NumericalMinimization_8C.html
https://root.cern/doc/master/NumericalMinimization_8C.html:4249,Availability,toler,toleranceDefinition,4249," Point_t Rectangle_t WindowAttributes_t Float_t rDefinition TGWin32VirtualXProxy.cxx:168; TRandom2.h; ROOT::Math::Factory::CreateMinimizerstatic ROOT::Math::Minimizer * CreateMinimizer(const std::string &minimizerType="""", const std::string &algoType="""")static method to create the corresponding Minimizer given the string Supported Minimizers types are: ...Definition Factory.cxx:63; ROOT::Math::FunctorDocumentation for class Functor class.Definition Functor.h:47; ROOT::Math::MinimizerAbstract Minimizer class, defining the interface for the various minimizer (like Minuit2,...Definition Minimizer.h:119; ROOT::Math::Minimizer::Xvirtual const double * X() const =0return pointer to X values at the minimum; ROOT::Math::Minimizer::SetMaxIterationsvoid SetMaxIterations(unsigned int maxiter)set maximum iterations (one iteration can have many function calls)Definition Minimizer.h:334; ROOT::Math::Minimizer::SetFunctionvirtual void SetFunction(const ROOT::Math::IMultiGenFunction &func)=0set the function to minimize; ROOT::Math::Minimizer::SetTolerancevoid SetTolerance(double tol)set the toleranceDefinition Minimizer.h:337; ROOT::Math::Minimizer::Minimizevirtual bool Minimize()=0method to perform the minimization; ROOT::Math::Minimizer::SetPrintLevelvoid SetPrintLevel(int level)set print levelDefinition Minimizer.h:328; ROOT::Math::Minimizer::SetVariablevirtual bool SetVariable(unsigned int ivar, const std::string &name, double val, double step)=0set a new free variable; ROOT::Math::Minimizer::SetMaxFunctionCallsvoid SetMaxFunctionCalls(unsigned int maxfcn)set maximum of function callsDefinition Minimizer.h:331; ROOT::Math::Minimizer::MinValuevirtual double MinValue() const =0return minimum function value; TRandom2Random number generator class based on the maximally quidistributed combined Tausworthe generator by ...Definition TRandom2.h:27; yDouble_t y[n]Definition legend1.C:17; xDouble_t x[n]Definition legend1.C:17; Factory.h; NumericalMinimizationDefinition NumericalMinimizati",MatchSource.WIKI,doc/master/NumericalMinimization_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NumericalMinimization_8C.html
https://root.cern/doc/master/NumericalMinimization_8C.html:1774,Integrability,wrap,wrapper,1774,"eturn 100*tmp1*tmp1+tmp2*tmp2;; }; ; int NumericalMinimization(const char * minName = ""Minuit2"",; const char *algoName = """" ,; int randomSeed = -1); {; // create minimizer giving a name and a name (optionally) for the specific; // algorithm; // possible choices are:; // minName algoName; // Minuit /Minuit2 Migrad, Simplex,Combined,Scan (default is Migrad); // Minuit2 Fumili2; // Fumili; // GSLMultiMin ConjugateFR, ConjugatePR, BFGS,; // BFGS2, SteepestDescent; // GSLMultiFit; // GSLSimAn; // Genetic; ROOT::Math::Minimizer* minimum =; ROOT::Math::Factory::CreateMinimizer(minName, algoName);; if (!minimum) {; std::cerr << ""Error: cannot create minimizer \"""" << minName; << ""\"". Maybe the required library was not built?"" << std::endl;; return 1;; }; ; // set tolerance , etc...; minimum->SetMaxFunctionCalls(1000000); // for Minuit/Minuit2; minimum->SetMaxIterations(10000); // for GSL; minimum->SetTolerance(0.001);; minimum->SetPrintLevel(1);; ; // create function wrapper for minimizer; // a IMultiGenFunction type; ROOT::Math::Functor f(&RosenBrock,2);; double step[2] = {0.01,0.01};; // starting point; ; double variable[2] = { -1.,1.2};; if (randomSeed >= 0) {; TRandom2 r(randomSeed);; variable[0] = r.Uniform(-20,20);; variable[1] = r.Uniform(-20,20);; }; ; minimum->SetFunction(f);; ; // Set the free variables to be minimized !; minimum->SetVariable(0,""x"",variable[0], step[0]);; minimum->SetVariable(1,""y"",variable[1], step[1]);; ; // do the minimization; minimum->Minimize();; ; const double *xs = minimum->X();; std::cout << ""Minimum: f("" << xs[0] << "","" << xs[1] << ""): ""; << minimum->MinValue() << std::endl;; ; // expected minimum is 0; if ( minimum->MinValue() < 1.E-4 ); std::cout << ""Minimizer "" << minName << "" - "" << algoName; << "" converged to the right minimum"" << std::endl;; else {; std::cout << ""Minimizer "" << minName << "" - "" << algoName; << "" failed to converge !!!"" << std::endl;; Error(""NumericalMinimization"",""fail to converge"");; }; ; return 0;; }; Functor.h; Mi",MatchSource.WIKI,doc/master/NumericalMinimization_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NumericalMinimization_8C.html
https://root.cern/doc/master/NumericalMinimization_8C.html:3684,Integrability,interface,interface,3684," "" failed to converge !!!"" << std::endl;; Error(""NumericalMinimization"",""fail to converge"");; }; ; return 0;; }; Functor.h; Minimizer.h; f#define f(i)Definition RSha256.hxx:104; TError.h; Errorvoid Error(const char *location, const char *msgfmt,...)Use this function in case an error occurred.Definition TError.cxx:185; rOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t rDefinition TGWin32VirtualXProxy.cxx:168; TRandom2.h; ROOT::Math::Factory::CreateMinimizerstatic ROOT::Math::Minimizer * CreateMinimizer(const std::string &minimizerType="""", const std::string &algoType="""")static method to create the corresponding Minimizer given the string Supported Minimizers types are: ...Definition Factory.cxx:63; ROOT::Math::FunctorDocumentation for class Functor class.Definition Functor.h:47; ROOT::Math::MinimizerAbstract Minimizer class, defining the interface for the various minimizer (like Minuit2,...Definition Minimizer.h:119; ROOT::Math::Minimizer::Xvirtual const double * X() const =0return pointer to X values at the minimum; ROOT::Math::Minimizer::SetMaxIterationsvoid SetMaxIterations(unsigned int maxiter)set maximum iterations (one iteration can have many function calls)Definition Minimizer.h:334; ROOT::Math::Minimizer::SetFunctionvirtual void SetFunction(const ROOT::Math::IMultiGenFunction &func)=0set the function to minimize; ROOT::Math::Minimizer::SetTolerancevoid SetTolerance(double tol)set the toleranceDefinition Minimizer.h:337; ROOT::Math::Minimizer::Minimizevirtual bool Minimize()=0method to perform the minimization; ROOT::Math::Minimizer::SetPrintLevelvoid SetPrintLevel(int level)set print levelDefinition Minimizer.h:328; ROOT::Math::Minimizer::SetVariablevirtual bool SetVariable(unsigned int ivar, const std::string &name, double val, double step)=0set a new free variable; ROOT::Math::Minimizer::SetMaxFunction",MatchSource.WIKI,doc/master/NumericalMinimization_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NumericalMinimization_8C.html
https://root.cern/doc/master/NumericalMinimization_8C.html:1924,Modifiability,variab,variable,1924,"ame = """" ,; int randomSeed = -1); {; // create minimizer giving a name and a name (optionally) for the specific; // algorithm; // possible choices are:; // minName algoName; // Minuit /Minuit2 Migrad, Simplex,Combined,Scan (default is Migrad); // Minuit2 Fumili2; // Fumili; // GSLMultiMin ConjugateFR, ConjugatePR, BFGS,; // BFGS2, SteepestDescent; // GSLMultiFit; // GSLSimAn; // Genetic; ROOT::Math::Minimizer* minimum =; ROOT::Math::Factory::CreateMinimizer(minName, algoName);; if (!minimum) {; std::cerr << ""Error: cannot create minimizer \"""" << minName; << ""\"". Maybe the required library was not built?"" << std::endl;; return 1;; }; ; // set tolerance , etc...; minimum->SetMaxFunctionCalls(1000000); // for Minuit/Minuit2; minimum->SetMaxIterations(10000); // for GSL; minimum->SetTolerance(0.001);; minimum->SetPrintLevel(1);; ; // create function wrapper for minimizer; // a IMultiGenFunction type; ROOT::Math::Functor f(&RosenBrock,2);; double step[2] = {0.01,0.01};; // starting point; ; double variable[2] = { -1.,1.2};; if (randomSeed >= 0) {; TRandom2 r(randomSeed);; variable[0] = r.Uniform(-20,20);; variable[1] = r.Uniform(-20,20);; }; ; minimum->SetFunction(f);; ; // Set the free variables to be minimized !; minimum->SetVariable(0,""x"",variable[0], step[0]);; minimum->SetVariable(1,""y"",variable[1], step[1]);; ; // do the minimization; minimum->Minimize();; ; const double *xs = minimum->X();; std::cout << ""Minimum: f("" << xs[0] << "","" << xs[1] << ""): ""; << minimum->MinValue() << std::endl;; ; // expected minimum is 0; if ( minimum->MinValue() < 1.E-4 ); std::cout << ""Minimizer "" << minName << "" - "" << algoName; << "" converged to the right minimum"" << std::endl;; else {; std::cout << ""Minimizer "" << minName << "" - "" << algoName; << "" failed to converge !!!"" << std::endl;; Error(""NumericalMinimization"",""fail to converge"");; }; ; return 0;; }; Functor.h; Minimizer.h; f#define f(i)Definition RSha256.hxx:104; TError.h; Errorvoid Error(const char *location, const char *msg",MatchSource.WIKI,doc/master/NumericalMinimization_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NumericalMinimization_8C.html
https://root.cern/doc/master/NumericalMinimization_8C.html:2000,Modifiability,variab,variable,2000," name and a name (optionally) for the specific; // algorithm; // possible choices are:; // minName algoName; // Minuit /Minuit2 Migrad, Simplex,Combined,Scan (default is Migrad); // Minuit2 Fumili2; // Fumili; // GSLMultiMin ConjugateFR, ConjugatePR, BFGS,; // BFGS2, SteepestDescent; // GSLMultiFit; // GSLSimAn; // Genetic; ROOT::Math::Minimizer* minimum =; ROOT::Math::Factory::CreateMinimizer(minName, algoName);; if (!minimum) {; std::cerr << ""Error: cannot create minimizer \"""" << minName; << ""\"". Maybe the required library was not built?"" << std::endl;; return 1;; }; ; // set tolerance , etc...; minimum->SetMaxFunctionCalls(1000000); // for Minuit/Minuit2; minimum->SetMaxIterations(10000); // for GSL; minimum->SetTolerance(0.001);; minimum->SetPrintLevel(1);; ; // create function wrapper for minimizer; // a IMultiGenFunction type; ROOT::Math::Functor f(&RosenBrock,2);; double step[2] = {0.01,0.01};; // starting point; ; double variable[2] = { -1.,1.2};; if (randomSeed >= 0) {; TRandom2 r(randomSeed);; variable[0] = r.Uniform(-20,20);; variable[1] = r.Uniform(-20,20);; }; ; minimum->SetFunction(f);; ; // Set the free variables to be minimized !; minimum->SetVariable(0,""x"",variable[0], step[0]);; minimum->SetVariable(1,""y"",variable[1], step[1]);; ; // do the minimization; minimum->Minimize();; ; const double *xs = minimum->X();; std::cout << ""Minimum: f("" << xs[0] << "","" << xs[1] << ""): ""; << minimum->MinValue() << std::endl;; ; // expected minimum is 0; if ( minimum->MinValue() < 1.E-4 ); std::cout << ""Minimizer "" << minName << "" - "" << algoName; << "" converged to the right minimum"" << std::endl;; else {; std::cout << ""Minimizer "" << minName << "" - "" << algoName; << "" failed to converge !!!"" << std::endl;; Error(""NumericalMinimization"",""fail to converge"");; }; ; return 0;; }; Functor.h; Minimizer.h; f#define f(i)Definition RSha256.hxx:104; TError.h; Errorvoid Error(const char *location, const char *msgfmt,...)Use this function in case an error occurred.Definition T",MatchSource.WIKI,doc/master/NumericalMinimization_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NumericalMinimization_8C.html
https://root.cern/doc/master/NumericalMinimization_8C.html:2034,Modifiability,variab,variable,2034,"lgorithm; // possible choices are:; // minName algoName; // Minuit /Minuit2 Migrad, Simplex,Combined,Scan (default is Migrad); // Minuit2 Fumili2; // Fumili; // GSLMultiMin ConjugateFR, ConjugatePR, BFGS,; // BFGS2, SteepestDescent; // GSLMultiFit; // GSLSimAn; // Genetic; ROOT::Math::Minimizer* minimum =; ROOT::Math::Factory::CreateMinimizer(minName, algoName);; if (!minimum) {; std::cerr << ""Error: cannot create minimizer \"""" << minName; << ""\"". Maybe the required library was not built?"" << std::endl;; return 1;; }; ; // set tolerance , etc...; minimum->SetMaxFunctionCalls(1000000); // for Minuit/Minuit2; minimum->SetMaxIterations(10000); // for GSL; minimum->SetTolerance(0.001);; minimum->SetPrintLevel(1);; ; // create function wrapper for minimizer; // a IMultiGenFunction type; ROOT::Math::Functor f(&RosenBrock,2);; double step[2] = {0.01,0.01};; // starting point; ; double variable[2] = { -1.,1.2};; if (randomSeed >= 0) {; TRandom2 r(randomSeed);; variable[0] = r.Uniform(-20,20);; variable[1] = r.Uniform(-20,20);; }; ; minimum->SetFunction(f);; ; // Set the free variables to be minimized !; minimum->SetVariable(0,""x"",variable[0], step[0]);; minimum->SetVariable(1,""y"",variable[1], step[1]);; ; // do the minimization; minimum->Minimize();; ; const double *xs = minimum->X();; std::cout << ""Minimum: f("" << xs[0] << "","" << xs[1] << ""): ""; << minimum->MinValue() << std::endl;; ; // expected minimum is 0; if ( minimum->MinValue() < 1.E-4 ); std::cout << ""Minimizer "" << minName << "" - "" << algoName; << "" converged to the right minimum"" << std::endl;; else {; std::cout << ""Minimizer "" << minName << "" - "" << algoName; << "" failed to converge !!!"" << std::endl;; Error(""NumericalMinimization"",""fail to converge"");; }; ; return 0;; }; Functor.h; Minimizer.h; f#define f(i)Definition RSha256.hxx:104; TError.h; Errorvoid Error(const char *location, const char *msgfmt,...)Use this function in case an error occurred.Definition TError.cxx:185; rOption_t Option_t TPoint TPoint cons",MatchSource.WIKI,doc/master/NumericalMinimization_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NumericalMinimization_8C.html
https://root.cern/doc/master/NumericalMinimization_8C.html:2117,Modifiability,variab,variables,2117,"GSLMultiFit; // GSLSimAn; // Genetic; ROOT::Math::Minimizer* minimum =; ROOT::Math::Factory::CreateMinimizer(minName, algoName);; if (!minimum) {; std::cerr << ""Error: cannot create minimizer \"""" << minName; << ""\"". Maybe the required library was not built?"" << std::endl;; return 1;; }; ; // set tolerance , etc...; minimum->SetMaxFunctionCalls(1000000); // for Minuit/Minuit2; minimum->SetMaxIterations(10000); // for GSL; minimum->SetTolerance(0.001);; minimum->SetPrintLevel(1);; ; // create function wrapper for minimizer; // a IMultiGenFunction type; ROOT::Math::Functor f(&RosenBrock,2);; double step[2] = {0.01,0.01};; // starting point; ; double variable[2] = { -1.,1.2};; if (randomSeed >= 0) {; TRandom2 r(randomSeed);; variable[0] = r.Uniform(-20,20);; variable[1] = r.Uniform(-20,20);; }; ; minimum->SetFunction(f);; ; // Set the free variables to be minimized !; minimum->SetVariable(0,""x"",variable[0], step[0]);; minimum->SetVariable(1,""y"",variable[1], step[1]);; ; // do the minimization; minimum->Minimize();; ; const double *xs = minimum->X();; std::cout << ""Minimum: f("" << xs[0] << "","" << xs[1] << ""): ""; << minimum->MinValue() << std::endl;; ; // expected minimum is 0; if ( minimum->MinValue() < 1.E-4 ); std::cout << ""Minimizer "" << minName << "" - "" << algoName; << "" converged to the right minimum"" << std::endl;; else {; std::cout << ""Minimizer "" << minName << "" - "" << algoName; << "" failed to converge !!!"" << std::endl;; Error(""NumericalMinimization"",""fail to converge"");; }; ; return 0;; }; Functor.h; Minimizer.h; f#define f(i)Definition RSha256.hxx:104; TError.h; Errorvoid Error(const char *location, const char *msgfmt,...)Use this function in case an error occurred.Definition TError.cxx:185; rOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t rDefinition TGWin32VirtualXProxy.cxx:168; TRandom2.h; ROOT::Math",MatchSource.WIKI,doc/master/NumericalMinimization_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NumericalMinimization_8C.html
https://root.cern/doc/master/NumericalMinimization_8C.html:2173,Modifiability,variab,variable,2173,"GSLMultiFit; // GSLSimAn; // Genetic; ROOT::Math::Minimizer* minimum =; ROOT::Math::Factory::CreateMinimizer(minName, algoName);; if (!minimum) {; std::cerr << ""Error: cannot create minimizer \"""" << minName; << ""\"". Maybe the required library was not built?"" << std::endl;; return 1;; }; ; // set tolerance , etc...; minimum->SetMaxFunctionCalls(1000000); // for Minuit/Minuit2; minimum->SetMaxIterations(10000); // for GSL; minimum->SetTolerance(0.001);; minimum->SetPrintLevel(1);; ; // create function wrapper for minimizer; // a IMultiGenFunction type; ROOT::Math::Functor f(&RosenBrock,2);; double step[2] = {0.01,0.01};; // starting point; ; double variable[2] = { -1.,1.2};; if (randomSeed >= 0) {; TRandom2 r(randomSeed);; variable[0] = r.Uniform(-20,20);; variable[1] = r.Uniform(-20,20);; }; ; minimum->SetFunction(f);; ; // Set the free variables to be minimized !; minimum->SetVariable(0,""x"",variable[0], step[0]);; minimum->SetVariable(1,""y"",variable[1], step[1]);; ; // do the minimization; minimum->Minimize();; ; const double *xs = minimum->X();; std::cout << ""Minimum: f("" << xs[0] << "","" << xs[1] << ""): ""; << minimum->MinValue() << std::endl;; ; // expected minimum is 0; if ( minimum->MinValue() < 1.E-4 ); std::cout << ""Minimizer "" << minName << "" - "" << algoName; << "" converged to the right minimum"" << std::endl;; else {; std::cout << ""Minimizer "" << minName << "" - "" << algoName; << "" failed to converge !!!"" << std::endl;; Error(""NumericalMinimization"",""fail to converge"");; }; ; return 0;; }; Functor.h; Minimizer.h; f#define f(i)Definition RSha256.hxx:104; TError.h; Errorvoid Error(const char *location, const char *msgfmt,...)Use this function in case an error occurred.Definition TError.cxx:185; rOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t rDefinition TGWin32VirtualXProxy.cxx:168; TRandom2.h; ROOT::Math",MatchSource.WIKI,doc/master/NumericalMinimization_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NumericalMinimization_8C.html
https://root.cern/doc/master/NumericalMinimization_8C.html:2224,Modifiability,variab,variable,2224,"GSLMultiFit; // GSLSimAn; // Genetic; ROOT::Math::Minimizer* minimum =; ROOT::Math::Factory::CreateMinimizer(minName, algoName);; if (!minimum) {; std::cerr << ""Error: cannot create minimizer \"""" << minName; << ""\"". Maybe the required library was not built?"" << std::endl;; return 1;; }; ; // set tolerance , etc...; minimum->SetMaxFunctionCalls(1000000); // for Minuit/Minuit2; minimum->SetMaxIterations(10000); // for GSL; minimum->SetTolerance(0.001);; minimum->SetPrintLevel(1);; ; // create function wrapper for minimizer; // a IMultiGenFunction type; ROOT::Math::Functor f(&RosenBrock,2);; double step[2] = {0.01,0.01};; // starting point; ; double variable[2] = { -1.,1.2};; if (randomSeed >= 0) {; TRandom2 r(randomSeed);; variable[0] = r.Uniform(-20,20);; variable[1] = r.Uniform(-20,20);; }; ; minimum->SetFunction(f);; ; // Set the free variables to be minimized !; minimum->SetVariable(0,""x"",variable[0], step[0]);; minimum->SetVariable(1,""y"",variable[1], step[1]);; ; // do the minimization; minimum->Minimize();; ; const double *xs = minimum->X();; std::cout << ""Minimum: f("" << xs[0] << "","" << xs[1] << ""): ""; << minimum->MinValue() << std::endl;; ; // expected minimum is 0; if ( minimum->MinValue() < 1.E-4 ); std::cout << ""Minimizer "" << minName << "" - "" << algoName; << "" converged to the right minimum"" << std::endl;; else {; std::cout << ""Minimizer "" << minName << "" - "" << algoName; << "" failed to converge !!!"" << std::endl;; Error(""NumericalMinimization"",""fail to converge"");; }; ; return 0;; }; Functor.h; Minimizer.h; f#define f(i)Definition RSha256.hxx:104; TError.h; Errorvoid Error(const char *location, const char *msgfmt,...)Use this function in case an error occurred.Definition TError.cxx:185; rOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t rDefinition TGWin32VirtualXProxy.cxx:168; TRandom2.h; ROOT::Math",MatchSource.WIKI,doc/master/NumericalMinimization_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NumericalMinimization_8C.html
https://root.cern/doc/master/NumericalMinimization_8C.html:4630,Modifiability,variab,variable,4630,"="""", const std::string &algoType="""")static method to create the corresponding Minimizer given the string Supported Minimizers types are: ...Definition Factory.cxx:63; ROOT::Math::FunctorDocumentation for class Functor class.Definition Functor.h:47; ROOT::Math::MinimizerAbstract Minimizer class, defining the interface for the various minimizer (like Minuit2,...Definition Minimizer.h:119; ROOT::Math::Minimizer::Xvirtual const double * X() const =0return pointer to X values at the minimum; ROOT::Math::Minimizer::SetMaxIterationsvoid SetMaxIterations(unsigned int maxiter)set maximum iterations (one iteration can have many function calls)Definition Minimizer.h:334; ROOT::Math::Minimizer::SetFunctionvirtual void SetFunction(const ROOT::Math::IMultiGenFunction &func)=0set the function to minimize; ROOT::Math::Minimizer::SetTolerancevoid SetTolerance(double tol)set the toleranceDefinition Minimizer.h:337; ROOT::Math::Minimizer::Minimizevirtual bool Minimize()=0method to perform the minimization; ROOT::Math::Minimizer::SetPrintLevelvoid SetPrintLevel(int level)set print levelDefinition Minimizer.h:328; ROOT::Math::Minimizer::SetVariablevirtual bool SetVariable(unsigned int ivar, const std::string &name, double val, double step)=0set a new free variable; ROOT::Math::Minimizer::SetMaxFunctionCallsvoid SetMaxFunctionCalls(unsigned int maxfcn)set maximum of function callsDefinition Minimizer.h:331; ROOT::Math::Minimizer::MinValuevirtual double MinValue() const =0return minimum function value; TRandom2Random number generator class based on the maximally quidistributed combined Tausworthe generator by ...Definition TRandom2.h:27; yDouble_t y[n]Definition legend1.C:17; xDouble_t x[n]Definition legend1.C:17; Factory.h; NumericalMinimizationDefinition NumericalMinimization.py:1; AuthorLorenzo Moneta ; Definition in file NumericalMinimization.C. tutorialsfitNumericalMinimization.C. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:27 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/NumericalMinimization_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NumericalMinimization_8C.html
https://root.cern/doc/master/NumericalMinimization_8C.html:4352,Performance,perform,perform,4352,"="""", const std::string &algoType="""")static method to create the corresponding Minimizer given the string Supported Minimizers types are: ...Definition Factory.cxx:63; ROOT::Math::FunctorDocumentation for class Functor class.Definition Functor.h:47; ROOT::Math::MinimizerAbstract Minimizer class, defining the interface for the various minimizer (like Minuit2,...Definition Minimizer.h:119; ROOT::Math::Minimizer::Xvirtual const double * X() const =0return pointer to X values at the minimum; ROOT::Math::Minimizer::SetMaxIterationsvoid SetMaxIterations(unsigned int maxiter)set maximum iterations (one iteration can have many function calls)Definition Minimizer.h:334; ROOT::Math::Minimizer::SetFunctionvirtual void SetFunction(const ROOT::Math::IMultiGenFunction &func)=0set the function to minimize; ROOT::Math::Minimizer::SetTolerancevoid SetTolerance(double tol)set the toleranceDefinition Minimizer.h:337; ROOT::Math::Minimizer::Minimizevirtual bool Minimize()=0method to perform the minimization; ROOT::Math::Minimizer::SetPrintLevelvoid SetPrintLevel(int level)set print levelDefinition Minimizer.h:328; ROOT::Math::Minimizer::SetVariablevirtual bool SetVariable(unsigned int ivar, const std::string &name, double val, double step)=0set a new free variable; ROOT::Math::Minimizer::SetMaxFunctionCallsvoid SetMaxFunctionCalls(unsigned int maxfcn)set maximum of function callsDefinition Minimizer.h:331; ROOT::Math::Minimizer::MinValuevirtual double MinValue() const =0return minimum function value; TRandom2Random number generator class based on the maximally quidistributed combined Tausworthe generator by ...Definition TRandom2.h:27; yDouble_t y[n]Definition legend1.C:17; xDouble_t x[n]Definition legend1.C:17; Factory.h; NumericalMinimizationDefinition NumericalMinimization.py:1; AuthorLorenzo Moneta ; Definition in file NumericalMinimization.C. tutorialsfitNumericalMinimization.C. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:27 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/NumericalMinimization_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/NumericalMinimization_8C.html
https://root.cern/doc/master/Object_8C.html:215,Integrability,depend,dependency,215,". ROOT: bindings/r/tests/Object.C File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. Functions |; Variables ; Object.C File Reference. #include <TRInterface.h>. Include dependency graph for Object.C:. This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead. Functions; voidObject (); . Variables; ROOT::R::TRInterface &r = ROOT::R::TRInterface::Instance(); . Function Documentation. Object(). void Object ; (; ). Definition at line 6 of file Object.C. Variable Documentation. r. ROOT::R::TRInterface& r = ROOT::R::TRInterface::Instance(). Definition at line 4 of file Object.C. bindingsrtestsObject.C. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:12 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/Object_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Object_8C.html
https://root.cern/doc/master/Object_8C.html:19,Testability,test,tests,19,". ROOT: bindings/r/tests/Object.C File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. Functions |; Variables ; Object.C File Reference. #include <TRInterface.h>. Include dependency graph for Object.C:. This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead. Functions; voidObject (); . Variables; ROOT::R::TRInterface &r = ROOT::R::TRInterface::Instance(); . Function Documentation. Object(). void Object ; (; ). Definition at line 6 of file Object.C. Variable Documentation. r. ROOT::R::TRInterface& r = ROOT::R::TRInterface::Instance(). Definition at line 4 of file Object.C. bindingsrtestsObject.C. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:12 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/Object_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Object_8C.html
https://root.cern/doc/master/palettes_8C.html:264,Availability,avail,available,264,". ROOT: tutorials/graphics/palettes.C File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. palettes.C File ReferenceTutorials  Graphics tutorials. Detailed Description; This macro draws all the high definition palettes available in ROOT. ; It generates a png file for each palette and one pdf file, with a table of content, containing all the palettes.; In ROOT, more than 60 high quality palettes are predefined with 255 colors each.; These palettes can be accessed ""by name"" with gStyle->SetPalette(num). num can be taken within the enum given in the previous link. As an example gStyle->SetPalette(kCividis) will select the following palette. ; TCanvas *c = nullptr;; ; void draw_palette(int p, TString n); {; delete c;; c = new TCanvas(""c"",""Contours"",0,0,500,500);; TF2 *f2 = new TF2(""f2"",""0.1+(1-(x-2)*(x-2))*(1-(y-2)*(y-2))"",0.999,3.002,0.999,3.002);; f2->SetContour(99);; gStyle->SetPalette(p);; f2->SetLineWidth(1);; f2->SetLineColor(kBlack);; f2->Draw(""surf1z"");; ; // Title; TPaveText *pt = new TPaveText(10,11,10,11,""blNDC"");; pt->SetName(""title"");; pt->Draw();; TString num = n;; num.ReplaceAll("" "","""");; TLatex *l = new TLatex(-0.8704441,0.9779387,TString::Format(""Palette #%d: %s #scale[0.7]{(#font[82]{k%s})}"",p,n.Data(),num.Data()));; l->SetTextFont(42);; l->SetTextSize(0.035);; l->Draw();; c->Update();; c->Print(TString::Format(""palette_%d.png"", p));; ; TString opt = TString(""Title:"") + n;; if (p == kDeepSea); c->Print(""palettes.pdf("", opt.Data());; else if (p == kCividis); c->Print(""palettes.pdf)"", opt.Data());; else; c->Print(""palettes.pdf"", opt.Data());; }; ; void palettes(); {; gROOT->SetBatch(1);; draw_palette(kDeepSea, ""Deap Sea"");; draw_palette(kGreyScale, ""Grey Scale"");; draw_palette(kDarkBodyRadiator, ""Dark Body Radiator"");; draw_palette(kBlueYellow, ""Blue Yellow"");; draw_palette(kRainBow, ""Rain Bow"");; draw_palette(kInvertedDarkBodyRadiator, ""Inverted Dark Body Radiator"");; draw_palette(kBird, ""Bird"");; draw_palette",MatchSource.WIKI,doc/master/palettes_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/palettes_8C.html
https://root.cern/doc/master/palettes_8C.html:503,Security,access,accessed,503,". ROOT: tutorials/graphics/palettes.C File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. palettes.C File ReferenceTutorials  Graphics tutorials. Detailed Description; This macro draws all the high definition palettes available in ROOT. ; It generates a png file for each palette and one pdf file, with a table of content, containing all the palettes.; In ROOT, more than 60 high quality palettes are predefined with 255 colors each.; These palettes can be accessed ""by name"" with gStyle->SetPalette(num). num can be taken within the enum given in the previous link. As an example gStyle->SetPalette(kCividis) will select the following palette. ; TCanvas *c = nullptr;; ; void draw_palette(int p, TString n); {; delete c;; c = new TCanvas(""c"",""Contours"",0,0,500,500);; TF2 *f2 = new TF2(""f2"",""0.1+(1-(x-2)*(x-2))*(1-(y-2)*(y-2))"",0.999,3.002,0.999,3.002);; f2->SetContour(99);; gStyle->SetPalette(p);; f2->SetLineWidth(1);; f2->SetLineColor(kBlack);; f2->Draw(""surf1z"");; ; // Title; TPaveText *pt = new TPaveText(10,11,10,11,""blNDC"");; pt->SetName(""title"");; pt->Draw();; TString num = n;; num.ReplaceAll("" "","""");; TLatex *l = new TLatex(-0.8704441,0.9779387,TString::Format(""Palette #%d: %s #scale[0.7]{(#font[82]{k%s})}"",p,n.Data(),num.Data()));; l->SetTextFont(42);; l->SetTextSize(0.035);; l->Draw();; c->Update();; c->Print(TString::Format(""palette_%d.png"", p));; ; TString opt = TString(""Title:"") + n;; if (p == kDeepSea); c->Print(""palettes.pdf("", opt.Data());; else if (p == kCividis); c->Print(""palettes.pdf)"", opt.Data());; else; c->Print(""palettes.pdf"", opt.Data());; }; ; void palettes(); {; gROOT->SetBatch(1);; draw_palette(kDeepSea, ""Deap Sea"");; draw_palette(kGreyScale, ""Grey Scale"");; draw_palette(kDarkBodyRadiator, ""Dark Body Radiator"");; draw_palette(kBlueYellow, ""Blue Yellow"");; draw_palette(kRainBow, ""Rain Bow"");; draw_palette(kInvertedDarkBodyRadiator, ""Inverted Dark Body Radiator"");; draw_palette(kBird, ""Bird"");; draw_palette",MatchSource.WIKI,doc/master/palettes_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/palettes_8C.html
https://root.cern/doc/master/parallelcoord_8C.html:3258,Modifiability,variab,variables,3258,"nge+9);; firstaxis->AddRange(new TParallelCoordRange(firstaxis,-1.263024,-0.755292));; }; Int_tint Int_tDefinition RtypesCore.h:45; Double_tdouble Double_tDefinition RtypesCore.h:59; kOrange@ kOrangeDefinition Rtypes.h:67; kViolet@ kVioletDefinition Rtypes.h:67; TCanvas.h; TFile.h; rOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t rDefinition TGWin32VirtualXProxy.cxx:168; TNtuple.h; TParallelCoordRange.h; TParallelCoordVar.h; TParallelCoord.h; TRandom.h; TStyle.h; gPad#define gPadDefinition TVirtualPad.h:308; TAttLine::SetLineColorvirtual void SetLineColor(Color_t lcolor)Set the line color.Definition TAttLine.h:40; TCanvasThe Canvas class.Definition TCanvas.h:23; TList::FindObjectTObject * FindObject(const char *name) const overrideFind an object in this list using its name.Definition TList.cxx:576; TNtupleA simple TTree restricted to a list of float variables only.Definition TNtuple.h:28; TNtuple::FillInt_t Fill() overrideFill a Ntuple with current values in fArgs.Definition TNtuple.cxx:169; TObject::FindObjectvirtual TObject * FindObject(const char *name) constMust be redefined in derived classes.Definition TObject.cxx:408; TParallelCoordRangeA TParallelCoordRange is a range used for parallel coordinates plots.Definition TParallelCoordRange.h:25; TParallelCoordVarTParallelCoord axes.Definition TParallelCoordVar.h:24; TParallelCoordVar::AddRangevoid AddRange(TParallelCoordRange *range)Add a range to the current selection on the axis.Definition TParallelCoordVar.cxx:102; TParallelCoordParallel Coordinates class.Definition TParallelCoord.h:28; TParallelCoord::AddSelectionvoid AddSelection(const char *title)Add a selection.Definition TParallelCoord.cxx:242; TParallelCoord::GetCurrentSelectionTParallelCoordSelect * GetCurrentSelection()Return the selection currently being edited.Definition TParallelCoord.cxx:438",MatchSource.WIKI,doc/master/parallelcoord_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/parallelcoord_8C.html
https://root.cern/doc/master/parallelcoord_8C.html:3215,Usability,simpl,simple,3215,"nge+9);; firstaxis->AddRange(new TParallelCoordRange(firstaxis,-1.263024,-0.755292));; }; Int_tint Int_tDefinition RtypesCore.h:45; Double_tdouble Double_tDefinition RtypesCore.h:59; kOrange@ kOrangeDefinition Rtypes.h:67; kViolet@ kVioletDefinition Rtypes.h:67; TCanvas.h; TFile.h; rOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t rDefinition TGWin32VirtualXProxy.cxx:168; TNtuple.h; TParallelCoordRange.h; TParallelCoordVar.h; TParallelCoord.h; TRandom.h; TStyle.h; gPad#define gPadDefinition TVirtualPad.h:308; TAttLine::SetLineColorvirtual void SetLineColor(Color_t lcolor)Set the line color.Definition TAttLine.h:40; TCanvasThe Canvas class.Definition TCanvas.h:23; TList::FindObjectTObject * FindObject(const char *name) const overrideFind an object in this list using its name.Definition TList.cxx:576; TNtupleA simple TTree restricted to a list of float variables only.Definition TNtuple.h:28; TNtuple::FillInt_t Fill() overrideFill a Ntuple with current values in fArgs.Definition TNtuple.cxx:169; TObject::FindObjectvirtual TObject * FindObject(const char *name) constMust be redefined in derived classes.Definition TObject.cxx:408; TParallelCoordRangeA TParallelCoordRange is a range used for parallel coordinates plots.Definition TParallelCoordRange.h:25; TParallelCoordVarTParallelCoord axes.Definition TParallelCoordVar.h:24; TParallelCoordVar::AddRangevoid AddRange(TParallelCoordRange *range)Add a range to the current selection on the axis.Definition TParallelCoordVar.cxx:102; TParallelCoordParallel Coordinates class.Definition TParallelCoord.h:28; TParallelCoord::AddSelectionvoid AddSelection(const char *title)Add a selection.Definition TParallelCoord.cxx:242; TParallelCoord::GetCurrentSelectionTParallelCoordSelect * GetCurrentSelection()Return the selection currently being edited.Definition TParallelCoord.cxx:438",MatchSource.WIKI,doc/master/parallelcoord_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/parallelcoord_8C.html
https://root.cern/doc/master/parallel__world_8C.html:535,Availability,error,errors,535,". ROOT: tutorials/geom/parallel_world.C File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. parallel_world.C File ReferenceTutorials  Geometry tutorials. Detailed Description; Misaligning geometry generate in many cases overlaps, due to the idealization of the design and the fact that in real life movements of the geometry volumes have constraints and are correlated. ; This typically generates inconsistent response of the navigation methods, leading to inefficiencies during tracking, errors in the material budget calculations, and so on. Among those, there are dangerous cases when the hidden volumes are sensitive. This macro demonstrates how to use the ""parallel world"" feature to assign highest navigation priority to some physical paths in geometry. ; void align();; ; //______________________________________________________________________________; void parallel_world(Bool_t usepw=kTRUE, Bool_t useovlp=kTRUE); {; // web geometry display does not support ""parallel world"" feature; gROOT->SetWebDisplay(""off"");; ; TGeoManager *geom = new TGeoManager(""parallel_world"", ""Showcase for prioritized physical paths"");; TGeoMaterial *matV = new TGeoMaterial(""Vac"", 0,0,0);; TGeoMedium *medV = new TGeoMedium(""MEDVAC"",1,matV);; TGeoMaterial *matAl = new TGeoMaterial(""Al"", 26.98,13,2.7);; TGeoMedium *medAl = new TGeoMedium(""MEDAL"",2,matAl);; TGeoMaterial *matSi = new TGeoMaterial(""Si"", 28.085,14,2.329);; TGeoMedium *medSi = new TGeoMedium(""MEDSI"",3,matSi);; TGeoVolume *top = gGeoManager->MakeBox(""TOP"",medV,100,400,1000);; gGeoManager->SetTopVolume(top);; ; // Shape for the support block; TGeoBBox *sblock = new TGeoBBox(""sblock"", 20,10,2);; // The volume for the support; TGeoVolume *support = new TGeoVolume(""block"",sblock, medAl);; support->SetLineColor(kGreen);; ; // Shape for the sensor to be prioritized in case of overlap; TGeoBBox *ssensor = new TGeoBBox(""sensor"", 19,9,0.2);; // The volume for the sensor; TGeoVolume *sensor = new TGeoV",MatchSource.WIKI,doc/master/parallel__world_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/parallel__world_8C.html
https://root.cern/doc/master/parallel__world_8C.html:1841,Energy Efficiency,sensor,sensor,1841,"ow to use the ""parallel world"" feature to assign highest navigation priority to some physical paths in geometry. ; void align();; ; //______________________________________________________________________________; void parallel_world(Bool_t usepw=kTRUE, Bool_t useovlp=kTRUE); {; // web geometry display does not support ""parallel world"" feature; gROOT->SetWebDisplay(""off"");; ; TGeoManager *geom = new TGeoManager(""parallel_world"", ""Showcase for prioritized physical paths"");; TGeoMaterial *matV = new TGeoMaterial(""Vac"", 0,0,0);; TGeoMedium *medV = new TGeoMedium(""MEDVAC"",1,matV);; TGeoMaterial *matAl = new TGeoMaterial(""Al"", 26.98,13,2.7);; TGeoMedium *medAl = new TGeoMedium(""MEDAL"",2,matAl);; TGeoMaterial *matSi = new TGeoMaterial(""Si"", 28.085,14,2.329);; TGeoMedium *medSi = new TGeoMedium(""MEDSI"",3,matSi);; TGeoVolume *top = gGeoManager->MakeBox(""TOP"",medV,100,400,1000);; gGeoManager->SetTopVolume(top);; ; // Shape for the support block; TGeoBBox *sblock = new TGeoBBox(""sblock"", 20,10,2);; // The volume for the support; TGeoVolume *support = new TGeoVolume(""block"",sblock, medAl);; support->SetLineColor(kGreen);; ; // Shape for the sensor to be prioritized in case of overlap; TGeoBBox *ssensor = new TGeoBBox(""sensor"", 19,9,0.2);; // The volume for the sensor; TGeoVolume *sensor = new TGeoVolume(""sensor"",ssensor, medSi);; sensor->SetLineColor(kRed);; ; // Chip assembly of support+sensor; TGeoVolumeAssembly *chip = new TGeoVolumeAssembly(""chip"");; chip->AddNode(support, 1);; chip->AddNode(sensor,1, new TGeoTranslation(0,0,-2.1));; ; // A ladder that normally sags; TGeoBBox *sladder = new TGeoBBox(""sladder"", 20,300,5);; // The volume for the ladder; TGeoVolume *ladder = new TGeoVolume(""ladder"",sladder, medAl);; ladder->SetLineColor(kBlue);; ; // Add nodes; top->AddNode(ladder,1);; for (Int_t i=0; i<10; i++); top->AddNode(chip, i+1, new TGeoTranslation(0, -225.+50.*i, 10));; ; gGeoManager->CloseGeometry();; TGeoParallelWorld *pw = nullptr;; if (usepw) pw = gGeoManager->Cr",MatchSource.WIKI,doc/master/parallel__world_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/parallel__world_8C.html
https://root.cern/doc/master/parallel__world_8C.html:1920,Energy Efficiency,sensor,sensor,1920,"ow to use the ""parallel world"" feature to assign highest navigation priority to some physical paths in geometry. ; void align();; ; //______________________________________________________________________________; void parallel_world(Bool_t usepw=kTRUE, Bool_t useovlp=kTRUE); {; // web geometry display does not support ""parallel world"" feature; gROOT->SetWebDisplay(""off"");; ; TGeoManager *geom = new TGeoManager(""parallel_world"", ""Showcase for prioritized physical paths"");; TGeoMaterial *matV = new TGeoMaterial(""Vac"", 0,0,0);; TGeoMedium *medV = new TGeoMedium(""MEDVAC"",1,matV);; TGeoMaterial *matAl = new TGeoMaterial(""Al"", 26.98,13,2.7);; TGeoMedium *medAl = new TGeoMedium(""MEDAL"",2,matAl);; TGeoMaterial *matSi = new TGeoMaterial(""Si"", 28.085,14,2.329);; TGeoMedium *medSi = new TGeoMedium(""MEDSI"",3,matSi);; TGeoVolume *top = gGeoManager->MakeBox(""TOP"",medV,100,400,1000);; gGeoManager->SetTopVolume(top);; ; // Shape for the support block; TGeoBBox *sblock = new TGeoBBox(""sblock"", 20,10,2);; // The volume for the support; TGeoVolume *support = new TGeoVolume(""block"",sblock, medAl);; support->SetLineColor(kGreen);; ; // Shape for the sensor to be prioritized in case of overlap; TGeoBBox *ssensor = new TGeoBBox(""sensor"", 19,9,0.2);; // The volume for the sensor; TGeoVolume *sensor = new TGeoVolume(""sensor"",ssensor, medSi);; sensor->SetLineColor(kRed);; ; // Chip assembly of support+sensor; TGeoVolumeAssembly *chip = new TGeoVolumeAssembly(""chip"");; chip->AddNode(support, 1);; chip->AddNode(sensor,1, new TGeoTranslation(0,0,-2.1));; ; // A ladder that normally sags; TGeoBBox *sladder = new TGeoBBox(""sladder"", 20,300,5);; // The volume for the ladder; TGeoVolume *ladder = new TGeoVolume(""ladder"",sladder, medAl);; ladder->SetLineColor(kBlue);; ; // Add nodes; top->AddNode(ladder,1);; for (Int_t i=0; i<10; i++); top->AddNode(chip, i+1, new TGeoTranslation(0, -225.+50.*i, 10));; ; gGeoManager->CloseGeometry();; TGeoParallelWorld *pw = nullptr;; if (usepw) pw = gGeoManager->Cr",MatchSource.WIKI,doc/master/parallel__world_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/parallel__world_8C.html
https://root.cern/doc/master/parallel__world_8C.html:1963,Energy Efficiency,sensor,sensor,1963,"m = new TGeoManager(""parallel_world"", ""Showcase for prioritized physical paths"");; TGeoMaterial *matV = new TGeoMaterial(""Vac"", 0,0,0);; TGeoMedium *medV = new TGeoMedium(""MEDVAC"",1,matV);; TGeoMaterial *matAl = new TGeoMaterial(""Al"", 26.98,13,2.7);; TGeoMedium *medAl = new TGeoMedium(""MEDAL"",2,matAl);; TGeoMaterial *matSi = new TGeoMaterial(""Si"", 28.085,14,2.329);; TGeoMedium *medSi = new TGeoMedium(""MEDSI"",3,matSi);; TGeoVolume *top = gGeoManager->MakeBox(""TOP"",medV,100,400,1000);; gGeoManager->SetTopVolume(top);; ; // Shape for the support block; TGeoBBox *sblock = new TGeoBBox(""sblock"", 20,10,2);; // The volume for the support; TGeoVolume *support = new TGeoVolume(""block"",sblock, medAl);; support->SetLineColor(kGreen);; ; // Shape for the sensor to be prioritized in case of overlap; TGeoBBox *ssensor = new TGeoBBox(""sensor"", 19,9,0.2);; // The volume for the sensor; TGeoVolume *sensor = new TGeoVolume(""sensor"",ssensor, medSi);; sensor->SetLineColor(kRed);; ; // Chip assembly of support+sensor; TGeoVolumeAssembly *chip = new TGeoVolumeAssembly(""chip"");; chip->AddNode(support, 1);; chip->AddNode(sensor,1, new TGeoTranslation(0,0,-2.1));; ; // A ladder that normally sags; TGeoBBox *sladder = new TGeoBBox(""sladder"", 20,300,5);; // The volume for the ladder; TGeoVolume *ladder = new TGeoVolume(""ladder"",sladder, medAl);; ladder->SetLineColor(kBlue);; ; // Add nodes; top->AddNode(ladder,1);; for (Int_t i=0; i<10; i++); top->AddNode(chip, i+1, new TGeoTranslation(0, -225.+50.*i, 10));; ; gGeoManager->CloseGeometry();; TGeoParallelWorld *pw = nullptr;; if (usepw) pw = gGeoManager->CreateParallelWorld(""priority_sensors"");; // Align chips; align();; if (usepw) {; if (useovlp) pw->AddOverlap(ladder);; pw->CloseGeometry();; gGeoManager->SetUseParallelWorldNav(kTRUE);; }; TString cname;; cname = usepw ? ""cpw"" : ""cnopw"";; TCanvas *c = (TCanvas*)gROOT->GetListOfCanvases()->FindObject(cname);; if (c) c->cd();; else c = new TCanvas(cname, """",800,600);; top->Draw();; // top->Rando",MatchSource.WIKI,doc/master/parallel__world_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/parallel__world_8C.html
https://root.cern/doc/master/parallel__world_8C.html:1983,Energy Efficiency,sensor,sensor,1983,"m = new TGeoManager(""parallel_world"", ""Showcase for prioritized physical paths"");; TGeoMaterial *matV = new TGeoMaterial(""Vac"", 0,0,0);; TGeoMedium *medV = new TGeoMedium(""MEDVAC"",1,matV);; TGeoMaterial *matAl = new TGeoMaterial(""Al"", 26.98,13,2.7);; TGeoMedium *medAl = new TGeoMedium(""MEDAL"",2,matAl);; TGeoMaterial *matSi = new TGeoMaterial(""Si"", 28.085,14,2.329);; TGeoMedium *medSi = new TGeoMedium(""MEDSI"",3,matSi);; TGeoVolume *top = gGeoManager->MakeBox(""TOP"",medV,100,400,1000);; gGeoManager->SetTopVolume(top);; ; // Shape for the support block; TGeoBBox *sblock = new TGeoBBox(""sblock"", 20,10,2);; // The volume for the support; TGeoVolume *support = new TGeoVolume(""block"",sblock, medAl);; support->SetLineColor(kGreen);; ; // Shape for the sensor to be prioritized in case of overlap; TGeoBBox *ssensor = new TGeoBBox(""sensor"", 19,9,0.2);; // The volume for the sensor; TGeoVolume *sensor = new TGeoVolume(""sensor"",ssensor, medSi);; sensor->SetLineColor(kRed);; ; // Chip assembly of support+sensor; TGeoVolumeAssembly *chip = new TGeoVolumeAssembly(""chip"");; chip->AddNode(support, 1);; chip->AddNode(sensor,1, new TGeoTranslation(0,0,-2.1));; ; // A ladder that normally sags; TGeoBBox *sladder = new TGeoBBox(""sladder"", 20,300,5);; // The volume for the ladder; TGeoVolume *ladder = new TGeoVolume(""ladder"",sladder, medAl);; ladder->SetLineColor(kBlue);; ; // Add nodes; top->AddNode(ladder,1);; for (Int_t i=0; i<10; i++); top->AddNode(chip, i+1, new TGeoTranslation(0, -225.+50.*i, 10));; ; gGeoManager->CloseGeometry();; TGeoParallelWorld *pw = nullptr;; if (usepw) pw = gGeoManager->CreateParallelWorld(""priority_sensors"");; // Align chips; align();; if (usepw) {; if (useovlp) pw->AddOverlap(ladder);; pw->CloseGeometry();; gGeoManager->SetUseParallelWorldNav(kTRUE);; }; TString cname;; cname = usepw ? ""cpw"" : ""cnopw"";; TCanvas *c = (TCanvas*)gROOT->GetListOfCanvases()->FindObject(cname);; if (c) c->cd();; else c = new TCanvas(cname, """",800,600);; top->Draw();; // top->Rando",MatchSource.WIKI,doc/master/parallel__world_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/parallel__world_8C.html
https://root.cern/doc/master/parallel__world_8C.html:2008,Energy Efficiency,sensor,sensor,2008,"m = new TGeoManager(""parallel_world"", ""Showcase for prioritized physical paths"");; TGeoMaterial *matV = new TGeoMaterial(""Vac"", 0,0,0);; TGeoMedium *medV = new TGeoMedium(""MEDVAC"",1,matV);; TGeoMaterial *matAl = new TGeoMaterial(""Al"", 26.98,13,2.7);; TGeoMedium *medAl = new TGeoMedium(""MEDAL"",2,matAl);; TGeoMaterial *matSi = new TGeoMaterial(""Si"", 28.085,14,2.329);; TGeoMedium *medSi = new TGeoMedium(""MEDSI"",3,matSi);; TGeoVolume *top = gGeoManager->MakeBox(""TOP"",medV,100,400,1000);; gGeoManager->SetTopVolume(top);; ; // Shape for the support block; TGeoBBox *sblock = new TGeoBBox(""sblock"", 20,10,2);; // The volume for the support; TGeoVolume *support = new TGeoVolume(""block"",sblock, medAl);; support->SetLineColor(kGreen);; ; // Shape for the sensor to be prioritized in case of overlap; TGeoBBox *ssensor = new TGeoBBox(""sensor"", 19,9,0.2);; // The volume for the sensor; TGeoVolume *sensor = new TGeoVolume(""sensor"",ssensor, medSi);; sensor->SetLineColor(kRed);; ; // Chip assembly of support+sensor; TGeoVolumeAssembly *chip = new TGeoVolumeAssembly(""chip"");; chip->AddNode(support, 1);; chip->AddNode(sensor,1, new TGeoTranslation(0,0,-2.1));; ; // A ladder that normally sags; TGeoBBox *sladder = new TGeoBBox(""sladder"", 20,300,5);; // The volume for the ladder; TGeoVolume *ladder = new TGeoVolume(""ladder"",sladder, medAl);; ladder->SetLineColor(kBlue);; ; // Add nodes; top->AddNode(ladder,1);; for (Int_t i=0; i<10; i++); top->AddNode(chip, i+1, new TGeoTranslation(0, -225.+50.*i, 10));; ; gGeoManager->CloseGeometry();; TGeoParallelWorld *pw = nullptr;; if (usepw) pw = gGeoManager->CreateParallelWorld(""priority_sensors"");; // Align chips; align();; if (usepw) {; if (useovlp) pw->AddOverlap(ladder);; pw->CloseGeometry();; gGeoManager->SetUseParallelWorldNav(kTRUE);; }; TString cname;; cname = usepw ? ""cpw"" : ""cnopw"";; TCanvas *c = (TCanvas*)gROOT->GetListOfCanvases()->FindObject(cname);; if (c) c->cd();; else c = new TCanvas(cname, """",800,600);; top->Draw();; // top->Rando",MatchSource.WIKI,doc/master/parallel__world_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/parallel__world_8C.html
https://root.cern/doc/master/parallel__world_8C.html:2034,Energy Efficiency,sensor,sensor,2034,"m = new TGeoManager(""parallel_world"", ""Showcase for prioritized physical paths"");; TGeoMaterial *matV = new TGeoMaterial(""Vac"", 0,0,0);; TGeoMedium *medV = new TGeoMedium(""MEDVAC"",1,matV);; TGeoMaterial *matAl = new TGeoMaterial(""Al"", 26.98,13,2.7);; TGeoMedium *medAl = new TGeoMedium(""MEDAL"",2,matAl);; TGeoMaterial *matSi = new TGeoMaterial(""Si"", 28.085,14,2.329);; TGeoMedium *medSi = new TGeoMedium(""MEDSI"",3,matSi);; TGeoVolume *top = gGeoManager->MakeBox(""TOP"",medV,100,400,1000);; gGeoManager->SetTopVolume(top);; ; // Shape for the support block; TGeoBBox *sblock = new TGeoBBox(""sblock"", 20,10,2);; // The volume for the support; TGeoVolume *support = new TGeoVolume(""block"",sblock, medAl);; support->SetLineColor(kGreen);; ; // Shape for the sensor to be prioritized in case of overlap; TGeoBBox *ssensor = new TGeoBBox(""sensor"", 19,9,0.2);; // The volume for the sensor; TGeoVolume *sensor = new TGeoVolume(""sensor"",ssensor, medSi);; sensor->SetLineColor(kRed);; ; // Chip assembly of support+sensor; TGeoVolumeAssembly *chip = new TGeoVolumeAssembly(""chip"");; chip->AddNode(support, 1);; chip->AddNode(sensor,1, new TGeoTranslation(0,0,-2.1));; ; // A ladder that normally sags; TGeoBBox *sladder = new TGeoBBox(""sladder"", 20,300,5);; // The volume for the ladder; TGeoVolume *ladder = new TGeoVolume(""ladder"",sladder, medAl);; ladder->SetLineColor(kBlue);; ; // Add nodes; top->AddNode(ladder,1);; for (Int_t i=0; i<10; i++); top->AddNode(chip, i+1, new TGeoTranslation(0, -225.+50.*i, 10));; ; gGeoManager->CloseGeometry();; TGeoParallelWorld *pw = nullptr;; if (usepw) pw = gGeoManager->CreateParallelWorld(""priority_sensors"");; // Align chips; align();; if (usepw) {; if (useovlp) pw->AddOverlap(ladder);; pw->CloseGeometry();; gGeoManager->SetUseParallelWorldNav(kTRUE);; }; TString cname;; cname = usepw ? ""cpw"" : ""cnopw"";; TCanvas *c = (TCanvas*)gROOT->GetListOfCanvases()->FindObject(cname);; if (c) c->cd();; else c = new TCanvas(cname, """",800,600);; top->Draw();; // top->Rando",MatchSource.WIKI,doc/master/parallel__world_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/parallel__world_8C.html
https://root.cern/doc/master/parallel__world_8C.html:2093,Energy Efficiency,sensor,sensor,2093,"m = new TGeoManager(""parallel_world"", ""Showcase for prioritized physical paths"");; TGeoMaterial *matV = new TGeoMaterial(""Vac"", 0,0,0);; TGeoMedium *medV = new TGeoMedium(""MEDVAC"",1,matV);; TGeoMaterial *matAl = new TGeoMaterial(""Al"", 26.98,13,2.7);; TGeoMedium *medAl = new TGeoMedium(""MEDAL"",2,matAl);; TGeoMaterial *matSi = new TGeoMaterial(""Si"", 28.085,14,2.329);; TGeoMedium *medSi = new TGeoMedium(""MEDSI"",3,matSi);; TGeoVolume *top = gGeoManager->MakeBox(""TOP"",medV,100,400,1000);; gGeoManager->SetTopVolume(top);; ; // Shape for the support block; TGeoBBox *sblock = new TGeoBBox(""sblock"", 20,10,2);; // The volume for the support; TGeoVolume *support = new TGeoVolume(""block"",sblock, medAl);; support->SetLineColor(kGreen);; ; // Shape for the sensor to be prioritized in case of overlap; TGeoBBox *ssensor = new TGeoBBox(""sensor"", 19,9,0.2);; // The volume for the sensor; TGeoVolume *sensor = new TGeoVolume(""sensor"",ssensor, medSi);; sensor->SetLineColor(kRed);; ; // Chip assembly of support+sensor; TGeoVolumeAssembly *chip = new TGeoVolumeAssembly(""chip"");; chip->AddNode(support, 1);; chip->AddNode(sensor,1, new TGeoTranslation(0,0,-2.1));; ; // A ladder that normally sags; TGeoBBox *sladder = new TGeoBBox(""sladder"", 20,300,5);; // The volume for the ladder; TGeoVolume *ladder = new TGeoVolume(""ladder"",sladder, medAl);; ladder->SetLineColor(kBlue);; ; // Add nodes; top->AddNode(ladder,1);; for (Int_t i=0; i<10; i++); top->AddNode(chip, i+1, new TGeoTranslation(0, -225.+50.*i, 10));; ; gGeoManager->CloseGeometry();; TGeoParallelWorld *pw = nullptr;; if (usepw) pw = gGeoManager->CreateParallelWorld(""priority_sensors"");; // Align chips; align();; if (usepw) {; if (useovlp) pw->AddOverlap(ladder);; pw->CloseGeometry();; gGeoManager->SetUseParallelWorldNav(kTRUE);; }; TString cname;; cname = usepw ? ""cpw"" : ""cnopw"";; TCanvas *c = (TCanvas*)gROOT->GetListOfCanvases()->FindObject(cname);; if (c) c->cd();; else c = new TCanvas(cname, """",800,600);; top->Draw();; // top->Rando",MatchSource.WIKI,doc/master/parallel__world_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/parallel__world_8C.html
https://root.cern/doc/master/parallel__world_8C.html:2203,Energy Efficiency,sensor,sensor,2203,"m = new TGeoManager(""parallel_world"", ""Showcase for prioritized physical paths"");; TGeoMaterial *matV = new TGeoMaterial(""Vac"", 0,0,0);; TGeoMedium *medV = new TGeoMedium(""MEDVAC"",1,matV);; TGeoMaterial *matAl = new TGeoMaterial(""Al"", 26.98,13,2.7);; TGeoMedium *medAl = new TGeoMedium(""MEDAL"",2,matAl);; TGeoMaterial *matSi = new TGeoMaterial(""Si"", 28.085,14,2.329);; TGeoMedium *medSi = new TGeoMedium(""MEDSI"",3,matSi);; TGeoVolume *top = gGeoManager->MakeBox(""TOP"",medV,100,400,1000);; gGeoManager->SetTopVolume(top);; ; // Shape for the support block; TGeoBBox *sblock = new TGeoBBox(""sblock"", 20,10,2);; // The volume for the support; TGeoVolume *support = new TGeoVolume(""block"",sblock, medAl);; support->SetLineColor(kGreen);; ; // Shape for the sensor to be prioritized in case of overlap; TGeoBBox *ssensor = new TGeoBBox(""sensor"", 19,9,0.2);; // The volume for the sensor; TGeoVolume *sensor = new TGeoVolume(""sensor"",ssensor, medSi);; sensor->SetLineColor(kRed);; ; // Chip assembly of support+sensor; TGeoVolumeAssembly *chip = new TGeoVolumeAssembly(""chip"");; chip->AddNode(support, 1);; chip->AddNode(sensor,1, new TGeoTranslation(0,0,-2.1));; ; // A ladder that normally sags; TGeoBBox *sladder = new TGeoBBox(""sladder"", 20,300,5);; // The volume for the ladder; TGeoVolume *ladder = new TGeoVolume(""ladder"",sladder, medAl);; ladder->SetLineColor(kBlue);; ; // Add nodes; top->AddNode(ladder,1);; for (Int_t i=0; i<10; i++); top->AddNode(chip, i+1, new TGeoTranslation(0, -225.+50.*i, 10));; ; gGeoManager->CloseGeometry();; TGeoParallelWorld *pw = nullptr;; if (usepw) pw = gGeoManager->CreateParallelWorld(""priority_sensors"");; // Align chips; align();; if (usepw) {; if (useovlp) pw->AddOverlap(ladder);; pw->CloseGeometry();; gGeoManager->SetUseParallelWorldNav(kTRUE);; }; TString cname;; cname = usepw ? ""cpw"" : ""cnopw"";; TCanvas *c = (TCanvas*)gROOT->GetListOfCanvases()->FindObject(cname);; if (c) c->cd();; else c = new TCanvas(cname, """",800,600);; top->Draw();; // top->Rando",MatchSource.WIKI,doc/master/parallel__world_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/parallel__world_8C.html
https://root.cern/doc/master/parallel__world_8C.html:3102,Energy Efficiency,sensor,sensor,3102,"Box(""sensor"", 19,9,0.2);; // The volume for the sensor; TGeoVolume *sensor = new TGeoVolume(""sensor"",ssensor, medSi);; sensor->SetLineColor(kRed);; ; // Chip assembly of support+sensor; TGeoVolumeAssembly *chip = new TGeoVolumeAssembly(""chip"");; chip->AddNode(support, 1);; chip->AddNode(sensor,1, new TGeoTranslation(0,0,-2.1));; ; // A ladder that normally sags; TGeoBBox *sladder = new TGeoBBox(""sladder"", 20,300,5);; // The volume for the ladder; TGeoVolume *ladder = new TGeoVolume(""ladder"",sladder, medAl);; ladder->SetLineColor(kBlue);; ; // Add nodes; top->AddNode(ladder,1);; for (Int_t i=0; i<10; i++); top->AddNode(chip, i+1, new TGeoTranslation(0, -225.+50.*i, 10));; ; gGeoManager->CloseGeometry();; TGeoParallelWorld *pw = nullptr;; if (usepw) pw = gGeoManager->CreateParallelWorld(""priority_sensors"");; // Align chips; align();; if (usepw) {; if (useovlp) pw->AddOverlap(ladder);; pw->CloseGeometry();; gGeoManager->SetUseParallelWorldNav(kTRUE);; }; TString cname;; cname = usepw ? ""cpw"" : ""cnopw"";; TCanvas *c = (TCanvas*)gROOT->GetListOfCanvases()->FindObject(cname);; if (c) c->cd();; else c = new TCanvas(cname, """",800,600);; top->Draw();; // top->RandomRays(0,0,0,0,sensor->GetName());; // Track random ""particles"" coming from the block side and draw only the tracklets; // actually crossing one of the sensors. Note that some of the tracks coming; // from the outer side may see the full sensor, while the others only part of it.; TStopwatch timer;; timer.Start();; top->RandomRays(100000,0,0,-30,sensor->GetName());; timer.Stop();; timer.Print();; TView3D *view = (TView3D*)gPad->GetView();; if (view) {; view->SetParallel();; view->Side();; }; if (usepw) pw->PrintDetectedOverlaps();; }; ; //______________________________________________________________________________; void align(); {; // Aligning 2 sensors so they will overlap with the support. One sensor is positioned; // normally while the other using the shared matrix; TGeoPhysicalNode *node;; TGeoParallelWorld *pw =",MatchSource.WIKI,doc/master/parallel__world_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/parallel__world_8C.html
https://root.cern/doc/master/parallel__world_8C.html:3239,Energy Efficiency,sensor,sensors,3239,"Box(""sensor"", 19,9,0.2);; // The volume for the sensor; TGeoVolume *sensor = new TGeoVolume(""sensor"",ssensor, medSi);; sensor->SetLineColor(kRed);; ; // Chip assembly of support+sensor; TGeoVolumeAssembly *chip = new TGeoVolumeAssembly(""chip"");; chip->AddNode(support, 1);; chip->AddNode(sensor,1, new TGeoTranslation(0,0,-2.1));; ; // A ladder that normally sags; TGeoBBox *sladder = new TGeoBBox(""sladder"", 20,300,5);; // The volume for the ladder; TGeoVolume *ladder = new TGeoVolume(""ladder"",sladder, medAl);; ladder->SetLineColor(kBlue);; ; // Add nodes; top->AddNode(ladder,1);; for (Int_t i=0; i<10; i++); top->AddNode(chip, i+1, new TGeoTranslation(0, -225.+50.*i, 10));; ; gGeoManager->CloseGeometry();; TGeoParallelWorld *pw = nullptr;; if (usepw) pw = gGeoManager->CreateParallelWorld(""priority_sensors"");; // Align chips; align();; if (usepw) {; if (useovlp) pw->AddOverlap(ladder);; pw->CloseGeometry();; gGeoManager->SetUseParallelWorldNav(kTRUE);; }; TString cname;; cname = usepw ? ""cpw"" : ""cnopw"";; TCanvas *c = (TCanvas*)gROOT->GetListOfCanvases()->FindObject(cname);; if (c) c->cd();; else c = new TCanvas(cname, """",800,600);; top->Draw();; // top->RandomRays(0,0,0,0,sensor->GetName());; // Track random ""particles"" coming from the block side and draw only the tracklets; // actually crossing one of the sensors. Note that some of the tracks coming; // from the outer side may see the full sensor, while the others only part of it.; TStopwatch timer;; timer.Start();; top->RandomRays(100000,0,0,-30,sensor->GetName());; timer.Stop();; timer.Print();; TView3D *view = (TView3D*)gPad->GetView();; if (view) {; view->SetParallel();; view->Side();; }; if (usepw) pw->PrintDetectedOverlaps();; }; ; //______________________________________________________________________________; void align(); {; // Aligning 2 sensors so they will overlap with the support. One sensor is positioned; // normally while the other using the shared matrix; TGeoPhysicalNode *node;; TGeoParallelWorld *pw =",MatchSource.WIKI,doc/master/parallel__world_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/parallel__world_8C.html
https://root.cern/doc/master/parallel__world_8C.html:3325,Energy Efficiency,sensor,sensor,3325,"eoBBox(""sladder"", 20,300,5);; // The volume for the ladder; TGeoVolume *ladder = new TGeoVolume(""ladder"",sladder, medAl);; ladder->SetLineColor(kBlue);; ; // Add nodes; top->AddNode(ladder,1);; for (Int_t i=0; i<10; i++); top->AddNode(chip, i+1, new TGeoTranslation(0, -225.+50.*i, 10));; ; gGeoManager->CloseGeometry();; TGeoParallelWorld *pw = nullptr;; if (usepw) pw = gGeoManager->CreateParallelWorld(""priority_sensors"");; // Align chips; align();; if (usepw) {; if (useovlp) pw->AddOverlap(ladder);; pw->CloseGeometry();; gGeoManager->SetUseParallelWorldNav(kTRUE);; }; TString cname;; cname = usepw ? ""cpw"" : ""cnopw"";; TCanvas *c = (TCanvas*)gROOT->GetListOfCanvases()->FindObject(cname);; if (c) c->cd();; else c = new TCanvas(cname, """",800,600);; top->Draw();; // top->RandomRays(0,0,0,0,sensor->GetName());; // Track random ""particles"" coming from the block side and draw only the tracklets; // actually crossing one of the sensors. Note that some of the tracks coming; // from the outer side may see the full sensor, while the others only part of it.; TStopwatch timer;; timer.Start();; top->RandomRays(100000,0,0,-30,sensor->GetName());; timer.Stop();; timer.Print();; TView3D *view = (TView3D*)gPad->GetView();; if (view) {; view->SetParallel();; view->Side();; }; if (usepw) pw->PrintDetectedOverlaps();; }; ; //______________________________________________________________________________; void align(); {; // Aligning 2 sensors so they will overlap with the support. One sensor is positioned; // normally while the other using the shared matrix; TGeoPhysicalNode *node;; TGeoParallelWorld *pw = gGeoManager->GetParallelWorld();; Double_t sag;; for (Int_t i=0; i<10; i++) {; node = gGeoManager->MakePhysicalNode(TString::Format(""/TOP_1/chip_%d"",i+1));; sag = 8.-0.494*(i-4.5)*(i-4.5);; TGeoTranslation *tr = new TGeoTranslation(0., -225.+50.*i, 10-sag);; node->Align(tr);; if (pw) pw->AddNode(TString::Format(""/TOP_1/chip_%d"",i+1));; }; }; c#define c(i)Definition RSha256.hxx:101; Bool_",MatchSource.WIKI,doc/master/parallel__world_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/parallel__world_8C.html
https://root.cern/doc/master/parallel__world_8C.html:3434,Energy Efficiency,sensor,sensor,3434,"; ladder->SetLineColor(kBlue);; ; // Add nodes; top->AddNode(ladder,1);; for (Int_t i=0; i<10; i++); top->AddNode(chip, i+1, new TGeoTranslation(0, -225.+50.*i, 10));; ; gGeoManager->CloseGeometry();; TGeoParallelWorld *pw = nullptr;; if (usepw) pw = gGeoManager->CreateParallelWorld(""priority_sensors"");; // Align chips; align();; if (usepw) {; if (useovlp) pw->AddOverlap(ladder);; pw->CloseGeometry();; gGeoManager->SetUseParallelWorldNav(kTRUE);; }; TString cname;; cname = usepw ? ""cpw"" : ""cnopw"";; TCanvas *c = (TCanvas*)gROOT->GetListOfCanvases()->FindObject(cname);; if (c) c->cd();; else c = new TCanvas(cname, """",800,600);; top->Draw();; // top->RandomRays(0,0,0,0,sensor->GetName());; // Track random ""particles"" coming from the block side and draw only the tracklets; // actually crossing one of the sensors. Note that some of the tracks coming; // from the outer side may see the full sensor, while the others only part of it.; TStopwatch timer;; timer.Start();; top->RandomRays(100000,0,0,-30,sensor->GetName());; timer.Stop();; timer.Print();; TView3D *view = (TView3D*)gPad->GetView();; if (view) {; view->SetParallel();; view->Side();; }; if (usepw) pw->PrintDetectedOverlaps();; }; ; //______________________________________________________________________________; void align(); {; // Aligning 2 sensors so they will overlap with the support. One sensor is positioned; // normally while the other using the shared matrix; TGeoPhysicalNode *node;; TGeoParallelWorld *pw = gGeoManager->GetParallelWorld();; Double_t sag;; for (Int_t i=0; i<10; i++) {; node = gGeoManager->MakePhysicalNode(TString::Format(""/TOP_1/chip_%d"",i+1));; sag = 8.-0.494*(i-4.5)*(i-4.5);; TGeoTranslation *tr = new TGeoTranslation(0., -225.+50.*i, 10-sag);; node->Align(tr);; if (pw) pw->AddNode(TString::Format(""/TOP_1/chip_%d"",i+1));; }; }; c#define c(i)Definition RSha256.hxx:101; Bool_tbool Bool_tDefinition RtypesCore.h:63; Int_tint Int_tDefinition RtypesCore.h:45; Double_tdouble Double_tDefinition Rtyp",MatchSource.WIKI,doc/master/parallel__world_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/parallel__world_8C.html
https://root.cern/doc/master/parallel__world_8C.html:3742,Energy Efficiency,sensor,sensors,3742,"ParallelWorld *pw = nullptr;; if (usepw) pw = gGeoManager->CreateParallelWorld(""priority_sensors"");; // Align chips; align();; if (usepw) {; if (useovlp) pw->AddOverlap(ladder);; pw->CloseGeometry();; gGeoManager->SetUseParallelWorldNav(kTRUE);; }; TString cname;; cname = usepw ? ""cpw"" : ""cnopw"";; TCanvas *c = (TCanvas*)gROOT->GetListOfCanvases()->FindObject(cname);; if (c) c->cd();; else c = new TCanvas(cname, """",800,600);; top->Draw();; // top->RandomRays(0,0,0,0,sensor->GetName());; // Track random ""particles"" coming from the block side and draw only the tracklets; // actually crossing one of the sensors. Note that some of the tracks coming; // from the outer side may see the full sensor, while the others only part of it.; TStopwatch timer;; timer.Start();; top->RandomRays(100000,0,0,-30,sensor->GetName());; timer.Stop();; timer.Print();; TView3D *view = (TView3D*)gPad->GetView();; if (view) {; view->SetParallel();; view->Side();; }; if (usepw) pw->PrintDetectedOverlaps();; }; ; //______________________________________________________________________________; void align(); {; // Aligning 2 sensors so they will overlap with the support. One sensor is positioned; // normally while the other using the shared matrix; TGeoPhysicalNode *node;; TGeoParallelWorld *pw = gGeoManager->GetParallelWorld();; Double_t sag;; for (Int_t i=0; i<10; i++) {; node = gGeoManager->MakePhysicalNode(TString::Format(""/TOP_1/chip_%d"",i+1));; sag = 8.-0.494*(i-4.5)*(i-4.5);; TGeoTranslation *tr = new TGeoTranslation(0., -225.+50.*i, 10-sag);; node->Align(tr);; if (pw) pw->AddNode(TString::Format(""/TOP_1/chip_%d"",i+1));; }; }; c#define c(i)Definition RSha256.hxx:101; Bool_tbool Bool_tDefinition RtypesCore.h:63; Int_tint Int_tDefinition RtypesCore.h:45; Double_tdouble Double_tDefinition RtypesCore.h:59; kTRUEconstexpr Bool_t kTRUEDefinition RtypesCore.h:93; kRed@ kRedDefinition Rtypes.h:66; kGreen@ kGreenDefinition Rtypes.h:66; kBlue@ kBlueDefinition Rtypes.h:66; cnameOption_t Option_t TPoint",MatchSource.WIKI,doc/master/parallel__world_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/parallel__world_8C.html
https://root.cern/doc/master/parallel__world_8C.html:3793,Energy Efficiency,sensor,sensor,3793,"vas *c = (TCanvas*)gROOT->GetListOfCanvases()->FindObject(cname);; if (c) c->cd();; else c = new TCanvas(cname, """",800,600);; top->Draw();; // top->RandomRays(0,0,0,0,sensor->GetName());; // Track random ""particles"" coming from the block side and draw only the tracklets; // actually crossing one of the sensors. Note that some of the tracks coming; // from the outer side may see the full sensor, while the others only part of it.; TStopwatch timer;; timer.Start();; top->RandomRays(100000,0,0,-30,sensor->GetName());; timer.Stop();; timer.Print();; TView3D *view = (TView3D*)gPad->GetView();; if (view) {; view->SetParallel();; view->Side();; }; if (usepw) pw->PrintDetectedOverlaps();; }; ; //______________________________________________________________________________; void align(); {; // Aligning 2 sensors so they will overlap with the support. One sensor is positioned; // normally while the other using the shared matrix; TGeoPhysicalNode *node;; TGeoParallelWorld *pw = gGeoManager->GetParallelWorld();; Double_t sag;; for (Int_t i=0; i<10; i++) {; node = gGeoManager->MakePhysicalNode(TString::Format(""/TOP_1/chip_%d"",i+1));; sag = 8.-0.494*(i-4.5)*(i-4.5);; TGeoTranslation *tr = new TGeoTranslation(0., -225.+50.*i, 10-sag);; node->Align(tr);; if (pw) pw->AddNode(TString::Format(""/TOP_1/chip_%d"",i+1));; }; }; c#define c(i)Definition RSha256.hxx:101; Bool_tbool Bool_tDefinition RtypesCore.h:63; Int_tint Int_tDefinition RtypesCore.h:45; Double_tdouble Double_tDefinition RtypesCore.h:59; kTRUEconstexpr Bool_t kTRUEDefinition RtypesCore.h:93; kRed@ kRedDefinition Rtypes.h:66; kGreen@ kGreenDefinition Rtypes.h:66; kBlue@ kBlueDefinition Rtypes.h:66; cnameOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t Float_t Float_t Int_t Int_t UInt_t UInt_t Rectangle_t Int_t Int_t Window_t TString Int_t GCValues_t GetPrimarySelectio",MatchSource.WIKI,doc/master/parallel__world_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/parallel__world_8C.html
https://root.cern/doc/master/parallel__world_8C.html:7614,Performance,optimiz,optimization,7614,"elWorldTGeoParallelWorld * CreateParallelWorld(const char *name)Create a parallel world for prioritised navigation.Definition TGeoManager.cxx:4277; TGeoMaterialBase class describing materials.Definition TGeoMaterial.h:34; TGeoMediumMedia are used to store properties related to tracking and which are useful only when using geometry ...Definition TGeoMedium.h:23; TGeoParallelWorldBase class for a flat parallel geometry.Definition TGeoParallelWorld.h:23; TGeoParallelWorld::CloseGeometryBool_t CloseGeometry()The main geometry must be closed.Definition TGeoParallelWorld.cxx:165; TGeoParallelWorld::AddNodevoid AddNode(const char *path)Add a node normally to this world. Overlapping nodes not allowed.Definition TGeoParallelWorld.cxx:92; TGeoParallelWorld::PrintDetectedOverlapsInt_t PrintDetectedOverlaps() constPrint the overlaps which were detected during real tracking.Definition TGeoParallelWorld.cxx:135; TGeoParallelWorld::AddOverlapvoid AddOverlap(TGeoVolume *vol, Bool_t activate=kTRUE)To use this optimization, the user should declare the full list of volumes which may overlap with any...Definition TGeoParallelWorld.cxx:108; TGeoPhysicalNodePhysical nodes are the actual 'touchable' objects in the geometry, representing a path of positioned ...Definition TGeoPhysicalNode.h:35; TGeoPhysicalNode::AlignBool_t Align(TGeoMatrix *newmat=nullptr, TGeoShape *newshape=nullptr, Bool_t check=kFALSE, Double_t ovlp=0.001)Align a physical node with a new relative matrix/shape.Definition TGeoPhysicalNode.cxx:135; TGeoTranslationClass describing translations.Definition TGeoMatrix.h:116; TGeoVolumeAssemblyVolume assemblies.Definition TGeoVolume.h:316; TGeoVolumeAssembly::AddNodeTGeoNode * AddNode(TGeoVolume *vol, Int_t copy_no, TGeoMatrix *mat=nullptr, Option_t *option="""") overrideAdd a component to the assembly.Definition TGeoVolume.cxx:2978; TGeoVolumeTGeoVolume, TGeoVolumeMulti, TGeoVolumeAssembly are the volume classes.Definition TGeoVolume.h:43; TGeoVolume::RandomRaysvoid RandomRays(I",MatchSource.WIKI,doc/master/parallel__world_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/parallel__world_8C.html
https://root.cern/doc/master/parallel__world_8C.html:7450,Safety,detect,detected,7450,"cxx:3655; TGeoManager::SetUseParallelWorldNavvoid SetUseParallelWorldNav(Bool_t flag)Activate/deactivate usage of parallel world navigation.Definition TGeoManager.cxx:4288; TGeoManager::CreateParallelWorldTGeoParallelWorld * CreateParallelWorld(const char *name)Create a parallel world for prioritised navigation.Definition TGeoManager.cxx:4277; TGeoMaterialBase class describing materials.Definition TGeoMaterial.h:34; TGeoMediumMedia are used to store properties related to tracking and which are useful only when using geometry ...Definition TGeoMedium.h:23; TGeoParallelWorldBase class for a flat parallel geometry.Definition TGeoParallelWorld.h:23; TGeoParallelWorld::CloseGeometryBool_t CloseGeometry()The main geometry must be closed.Definition TGeoParallelWorld.cxx:165; TGeoParallelWorld::AddNodevoid AddNode(const char *path)Add a node normally to this world. Overlapping nodes not allowed.Definition TGeoParallelWorld.cxx:92; TGeoParallelWorld::PrintDetectedOverlapsInt_t PrintDetectedOverlaps() constPrint the overlaps which were detected during real tracking.Definition TGeoParallelWorld.cxx:135; TGeoParallelWorld::AddOverlapvoid AddOverlap(TGeoVolume *vol, Bool_t activate=kTRUE)To use this optimization, the user should declare the full list of volumes which may overlap with any...Definition TGeoParallelWorld.cxx:108; TGeoPhysicalNodePhysical nodes are the actual 'touchable' objects in the geometry, representing a path of positioned ...Definition TGeoPhysicalNode.h:35; TGeoPhysicalNode::AlignBool_t Align(TGeoMatrix *newmat=nullptr, TGeoShape *newshape=nullptr, Bool_t check=kFALSE, Double_t ovlp=0.001)Align a physical node with a new relative matrix/shape.Definition TGeoPhysicalNode.cxx:135; TGeoTranslationClass describing translations.Definition TGeoMatrix.h:116; TGeoVolumeAssemblyVolume assemblies.Definition TGeoVolume.h:316; TGeoVolumeAssembly::AddNodeTGeoNode * AddNode(TGeoVolume *vol, Int_t copy_no, TGeoMatrix *mat=nullptr, Option_t *option="""") overrideAdd a componen",MatchSource.WIKI,doc/master/parallel__world_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/parallel__world_8C.html
https://root.cern/doc/master/ParameterSettings_8cxx_source.html:1683,Availability,error,error,1683,"Error.h>; 16 ; 17namespace ROOT {; 18 ; 19namespace Fit {; 20 ; 21/// set a double side limit,; 22/// if low == up the parameter is fixed if low > up the limits are removed; 23/// The current parameter value should be within the given limits [low,up].; 24/// If the value is outside the limits, then a new parameter value is set to = (up+low)/2; 25void ParameterSettings::SetLimits(double low, double up); 26{; 27 ; 28 if (low > up) {; 29 RemoveLimits();; 30 return;; 31 }; 32 if (low == up && low == fValue) {; 33 Fix();; 34 return;; 35 }; 36 if (low > fValue || up < fValue) {; 37 MATH_INFO_MSG(""ParameterSettings"",; 38 ""lower/upper bounds outside current parameter value. The value will be set to (low+up)/2 "");; 39 fValue = 0.5 * (up + low);; 40 }; 41 fLowerLimit = low;; 42 fUpperLimit = up;; 43 fHasLowerLimit = true;; 44 fHasUpperLimit = true;; 45}; 46 ; 47} // end namespace Fit; 48 ; 49} // end namespace ROOT; Error.h; MATH_INFO_MSG#define MATH_INFO_MSG(loc, str)Pre-processor macro to report messages which can be configured to use ROOT error or simply an std::io...Definition Error.h:77; ParameterSettings.h; ROOT::Fit::ParameterSettings::RemoveLimitsvoid RemoveLimits()remove all limitDefinition ParameterSettings.h:140; ROOT::Fit::ParameterSettings::fLowerLimitdouble fLowerLimitlower parameter limitDefinition ParameterSettings.h:152; ROOT::Fit::ParameterSettings::fUpperLimitdouble fUpperLimitupper parameter limitDefinition ParameterSettings.h:153; ROOT::Fit::ParameterSettings::fHasUpperLimitbool fHasUpperLimitflag to control upper parameter limitDefinition ParameterSettings.h:155; ROOT::Fit::ParameterSettings::fHasLowerLimitbool fHasLowerLimitflag to control lower parameter limitDefinition ParameterSettings.h:154; ROOT::Fit::ParameterSettings::SetLimitsvoid SetLimits(double low, double up)set a double side limit, if low == up the parameter is fixed if low > up the limits are removed The c...Definition ParameterSettings.cxx:25; ROOT::Fit::ParameterSettings::fValuedouble fVa",MatchSource.WIKI,doc/master/ParameterSettings_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ParameterSettings_8cxx_source.html
https://root.cern/doc/master/ParameterSettings_8cxx_source.html:1638,Integrability,message,messages,1638,"Error.h>; 16 ; 17namespace ROOT {; 18 ; 19namespace Fit {; 20 ; 21/// set a double side limit,; 22/// if low == up the parameter is fixed if low > up the limits are removed; 23/// The current parameter value should be within the given limits [low,up].; 24/// If the value is outside the limits, then a new parameter value is set to = (up+low)/2; 25void ParameterSettings::SetLimits(double low, double up); 26{; 27 ; 28 if (low > up) {; 29 RemoveLimits();; 30 return;; 31 }; 32 if (low == up && low == fValue) {; 33 Fix();; 34 return;; 35 }; 36 if (low > fValue || up < fValue) {; 37 MATH_INFO_MSG(""ParameterSettings"",; 38 ""lower/upper bounds outside current parameter value. The value will be set to (low+up)/2 "");; 39 fValue = 0.5 * (up + low);; 40 }; 41 fLowerLimit = low;; 42 fUpperLimit = up;; 43 fHasLowerLimit = true;; 44 fHasUpperLimit = true;; 45}; 46 ; 47} // end namespace Fit; 48 ; 49} // end namespace ROOT; Error.h; MATH_INFO_MSG#define MATH_INFO_MSG(loc, str)Pre-processor macro to report messages which can be configured to use ROOT error or simply an std::io...Definition Error.h:77; ParameterSettings.h; ROOT::Fit::ParameterSettings::RemoveLimitsvoid RemoveLimits()remove all limitDefinition ParameterSettings.h:140; ROOT::Fit::ParameterSettings::fLowerLimitdouble fLowerLimitlower parameter limitDefinition ParameterSettings.h:152; ROOT::Fit::ParameterSettings::fUpperLimitdouble fUpperLimitupper parameter limitDefinition ParameterSettings.h:153; ROOT::Fit::ParameterSettings::fHasUpperLimitbool fHasUpperLimitflag to control upper parameter limitDefinition ParameterSettings.h:155; ROOT::Fit::ParameterSettings::fHasLowerLimitbool fHasLowerLimitflag to control lower parameter limitDefinition ParameterSettings.h:154; ROOT::Fit::ParameterSettings::SetLimitsvoid SetLimits(double low, double up)set a double side limit, if low == up the parameter is fixed if low > up the limits are removed The c...Definition ParameterSettings.cxx:25; ROOT::Fit::ParameterSettings::fValuedouble fVa",MatchSource.WIKI,doc/master/ParameterSettings_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ParameterSettings_8cxx_source.html
https://root.cern/doc/master/ParameterSettings_8cxx_source.html:1660,Modifiability,config,configured,1660,"Error.h>; 16 ; 17namespace ROOT {; 18 ; 19namespace Fit {; 20 ; 21/// set a double side limit,; 22/// if low == up the parameter is fixed if low > up the limits are removed; 23/// The current parameter value should be within the given limits [low,up].; 24/// If the value is outside the limits, then a new parameter value is set to = (up+low)/2; 25void ParameterSettings::SetLimits(double low, double up); 26{; 27 ; 28 if (low > up) {; 29 RemoveLimits();; 30 return;; 31 }; 32 if (low == up && low == fValue) {; 33 Fix();; 34 return;; 35 }; 36 if (low > fValue || up < fValue) {; 37 MATH_INFO_MSG(""ParameterSettings"",; 38 ""lower/upper bounds outside current parameter value. The value will be set to (low+up)/2 "");; 39 fValue = 0.5 * (up + low);; 40 }; 41 fLowerLimit = low;; 42 fUpperLimit = up;; 43 fHasLowerLimit = true;; 44 fHasUpperLimit = true;; 45}; 46 ; 47} // end namespace Fit; 48 ; 49} // end namespace ROOT; Error.h; MATH_INFO_MSG#define MATH_INFO_MSG(loc, str)Pre-processor macro to report messages which can be configured to use ROOT error or simply an std::io...Definition Error.h:77; ParameterSettings.h; ROOT::Fit::ParameterSettings::RemoveLimitsvoid RemoveLimits()remove all limitDefinition ParameterSettings.h:140; ROOT::Fit::ParameterSettings::fLowerLimitdouble fLowerLimitlower parameter limitDefinition ParameterSettings.h:152; ROOT::Fit::ParameterSettings::fUpperLimitdouble fUpperLimitupper parameter limitDefinition ParameterSettings.h:153; ROOT::Fit::ParameterSettings::fHasUpperLimitbool fHasUpperLimitflag to control upper parameter limitDefinition ParameterSettings.h:155; ROOT::Fit::ParameterSettings::fHasLowerLimitbool fHasLowerLimitflag to control lower parameter limitDefinition ParameterSettings.h:154; ROOT::Fit::ParameterSettings::SetLimitsvoid SetLimits(double low, double up)set a double side limit, if low == up the parameter is fixed if low > up the limits are removed The c...Definition ParameterSettings.cxx:25; ROOT::Fit::ParameterSettings::fValuedouble fVa",MatchSource.WIKI,doc/master/ParameterSettings_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ParameterSettings_8cxx_source.html
https://root.cern/doc/master/ParameterSettings_8cxx_source.html:1692,Usability,simpl,simply,1692,"Error.h>; 16 ; 17namespace ROOT {; 18 ; 19namespace Fit {; 20 ; 21/// set a double side limit,; 22/// if low == up the parameter is fixed if low > up the limits are removed; 23/// The current parameter value should be within the given limits [low,up].; 24/// If the value is outside the limits, then a new parameter value is set to = (up+low)/2; 25void ParameterSettings::SetLimits(double low, double up); 26{; 27 ; 28 if (low > up) {; 29 RemoveLimits();; 30 return;; 31 }; 32 if (low == up && low == fValue) {; 33 Fix();; 34 return;; 35 }; 36 if (low > fValue || up < fValue) {; 37 MATH_INFO_MSG(""ParameterSettings"",; 38 ""lower/upper bounds outside current parameter value. The value will be set to (low+up)/2 "");; 39 fValue = 0.5 * (up + low);; 40 }; 41 fLowerLimit = low;; 42 fUpperLimit = up;; 43 fHasLowerLimit = true;; 44 fHasUpperLimit = true;; 45}; 46 ; 47} // end namespace Fit; 48 ; 49} // end namespace ROOT; Error.h; MATH_INFO_MSG#define MATH_INFO_MSG(loc, str)Pre-processor macro to report messages which can be configured to use ROOT error or simply an std::io...Definition Error.h:77; ParameterSettings.h; ROOT::Fit::ParameterSettings::RemoveLimitsvoid RemoveLimits()remove all limitDefinition ParameterSettings.h:140; ROOT::Fit::ParameterSettings::fLowerLimitdouble fLowerLimitlower parameter limitDefinition ParameterSettings.h:152; ROOT::Fit::ParameterSettings::fUpperLimitdouble fUpperLimitupper parameter limitDefinition ParameterSettings.h:153; ROOT::Fit::ParameterSettings::fHasUpperLimitbool fHasUpperLimitflag to control upper parameter limitDefinition ParameterSettings.h:155; ROOT::Fit::ParameterSettings::fHasLowerLimitbool fHasLowerLimitflag to control lower parameter limitDefinition ParameterSettings.h:154; ROOT::Fit::ParameterSettings::SetLimitsvoid SetLimits(double low, double up)set a double side limit, if low == up the parameter is fixed if low > up the limits are removed The c...Definition ParameterSettings.cxx:25; ROOT::Fit::ParameterSettings::fValuedouble fVa",MatchSource.WIKI,doc/master/ParameterSettings_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ParameterSettings_8cxx_source.html
https://root.cern/doc/master/ParameterSettings_8h_source.html:3642,Deployability,release,release,3642,"alue(value);; 71 SetStepSize(step);; 72 }; 73 ; 74 /// set a limited parameter. The given value should be within the given limits [min,max]; 75 void Set(const std::string & name, double value, double step, double lower, double upper ) {; 76 SetName(name);; 77 SetValue(value);; 78 SetStepSize(step);; 79 SetLimits(lower,upper);; 80 }; 81 ; 82 /// set a fixed parameter; 83 void Set(const std::string & name, double value) {; 84 SetName(name);; 85 SetValue(value);; 86 Fix();; 87 }; 88 ; 89 /// return parameter value; 90 double Value() const { return fValue; }; 91 /// return step size; 92 double StepSize() const { return fStepSize; }; 93 /// return lower limit value; 94 double LowerLimit() const {return fLowerLimit;}; 95 /// return upper limit value; 96 double UpperLimit() const {return fUpperLimit;}; 97 /// check if is fixed; 98 bool IsFixed() const { return fFix; }; 99 /// check if parameter has lower limit; 100 bool HasLowerLimit() const {return fHasLowerLimit; }; 101 /// check if parameter has upper limit; 102 bool HasUpperLimit() const {return fHasUpperLimit; }; 103 /// check if is bound; 104 bool IsBound() const { return fHasLowerLimit || fHasUpperLimit; }; 105 /// check if is double bound (upper AND lower limit); 106 bool IsDoubleBound() const { return fHasLowerLimit && fHasUpperLimit; }; 107 /// return name; 108 const std::string & Name() const { return fName; }; 109 ; 110 /** interaction **/; 111 ; 112 /// set name; 113 void SetName(const std::string & name ) { fName = name; }; 114 ; 115 /// fix the parameter; 116 void Fix() {fFix = true;}; 117 /// release the parameter; 118 void Release() {fFix = false;}; 119 /// set the value; 120 void SetValue(double val) {fValue = val;}; 121 /// set the step size; 122 void SetStepSize(double err) {fStepSize = err;}; 123 void SetLimits(double low, double up);; 124 /// set a single upper limit; 125 void SetUpperLimit(double up) {; 126 fLowerLimit = 0.;; 127 fUpperLimit = up;; 128 fHasLowerLimit = false;; 129 fHasUpperLimit = tru",MatchSource.WIKI,doc/master/ParameterSettings_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ParameterSettings_8h_source.html
https://root.cern/doc/master/ParameterSettings_8h_source.html:5568,Deployability,release,release,5568,"inimizer); 151 bool fFix = false; ///< flag to control if parameter is fixed; 152 double fLowerLimit = 0.0; ///< lower parameter limit; 153 double fUpperLimit = 0.0; ///< upper parameter limit; 154 bool fHasLowerLimit = false; ///< flag to control lower parameter limit; 155 bool fHasUpperLimit = false; ///< flag to control upper parameter limit; 156 ; 157 std::string fName; ///< parameter name; 158 ; 159};; 160 ; 161 } // end namespace Fit; 162 ; 163} // end namespace ROOT; 164 ; 165 ; 166#endif /* ROOT_Fit_ParameterSettings */; valueOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void valueDefinition TGWin32VirtualXProxy.cxx:142; namechar name[80]Definition TGX11.cxx:110; ROOT::Fit::ParameterSettingsClass, describing value, limits and step size of the parameters Provides functionality also to set/re...Definition ParameterSettings.h:33; ROOT::Fit::ParameterSettings::Releasevoid Release()release the parameterDefinition ParameterSettings.h:118; ROOT::Fit::ParameterSettings::IsFixedbool IsFixed() constcheck if is fixedDefinition ParameterSettings.h:98; ROOT::Fit::ParameterSettings::HasUpperLimitbool HasUpperLimit() constcheck if parameter has upper limitDefinition ParameterSettings.h:102; ROOT::Fit::ParameterSettings::fFixbool fFixflag to control if parameter is fixedDefinition ParameterSettings.h:151; ROOT::Fit::ParameterSettings::ParameterSettingsParameterSettings(const std::string &name, double val, double err)constructor for unlimited named ParameterDefinition ParameterSettings.h:44; ROOT::Fit::ParameterSettings::ParameterSettingsParameterSettings()Default constructor.Definition ParameterSettings.h:40; ROOT::Fit::ParameterSettings::RemoveLimitsvoid RemoveLimits()remove all limitDefinition ParameterSettings.h:140; ROOT::Fit::ParameterSettings::SetValuevoid SetValue(double val)set the valueDefinition ParameterSettings.h:120; ROOT::Fit::ParameterSettings::LowerLimitd",MatchSource.WIKI,doc/master/ParameterSettings_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ParameterSettings_8h_source.html
https://root.cern/doc/master/ParamFunctor_8h_source.html:9764,Deployability,release,release,9764,"torTempl(FreeFunc f) :; 312 fImpl(new ParamFunctorHandler<ParamFunctorTempl<T>,FreeFunc>(f) ); 313 {; 314 }; 315 ; 316 // specialization used in TF1; 317 ParamFunctorTempl(const std::function<T(const T *f, const Double_t *param)> &func) :; 318 fImpl(new ParamFunctorHandler<ParamFunctorTempl<T>, const std::function<T(const T *f, const Double_t *param)>>(func)); 319 {; 320 }; 321 ; 322 /**; 323 Destructor (no operations); 324 */; 325 virtual ~ParamFunctorTempl () {; 326 if (fImpl) delete fImpl;; 327 }; 328 ; 329 /**; 330 Copy constructor; 331 */; 332 ParamFunctorTempl(const ParamFunctorTempl & rhs) :; 333 fImpl(nullptr); 334 {; 335// if (rhs.fImpl.get() != 0); 336// fImpl = std::unique_ptr<Impl>( (rhs.fImpl)->Clone() );; 337 if (rhs.fImpl) fImpl = rhs.fImpl->Clone();; 338 }; 339 ; 340 /**; 341 Assignment operator; 342 */; 343 ParamFunctorTempl & operator = (const ParamFunctorTempl & rhs) {; 344// ParamFunctor copy(rhs);; 345 // swap unique_ptr by hand; 346// Impl * p = fImpl.release();; 347// fImpl.reset(copy.fImpl.release());; 348// copy.fImpl.reset(p);; 349 ; 350 if(this != &rhs) {; 351 if (fImpl) delete fImpl;; 352 fImpl = nullptr;; 353 if (rhs.fImpl); 354 fImpl = rhs.fImpl->Clone();; 355 }; 356 return *this;; 357 }; 358 ; 359 void * GetImpl() { return (void *) fImpl; }; 360 ; 361 ; 362 T operator() ( T * x, double * p) {; 363 return (*fImpl)(x,p);; 364 }; 365 ; 366 T operator() (const T * x, const double * p) {; 367 return (*fImpl)(x,p);; 368 }; 369 ; 370 ; 371 bool Empty() const { return !fImpl; }; 372 ; 373 ; 374 void SetFunction(Impl * f) {; 375 fImpl = f;; 376 }; 377 ; 378private :; 379 ; 380 ; 381 //std::unique_ptr<Impl> fImpl;; 382 Impl * fImpl;; 383 ; 384 ; 385};; 386 ; 387 ; 388using ParamFunctor = ParamFunctorTempl<double>;; 389 ; 390 } // end namespace Math; 391 ; 392} // end namespace ROOT; 393 ; 394 ; 395#endif /* ROOT_Math_ParamFunctor */; f#define f(i)Definition RSha256.hxx:104; RtypesCore.h; pwinID h TVirtualViewer3D TVirtualGLPainter pDefinition TG",MatchSource.WIKI,doc/master/ParamFunctor_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ParamFunctor_8h_source.html
https://root.cern/doc/master/ParamFunctor_8h_source.html:9805,Deployability,release,release,9805,"amFunctorHandler<ParamFunctorTempl<T>,FreeFunc>(f) ); 313 {; 314 }; 315 ; 316 // specialization used in TF1; 317 ParamFunctorTempl(const std::function<T(const T *f, const Double_t *param)> &func) :; 318 fImpl(new ParamFunctorHandler<ParamFunctorTempl<T>, const std::function<T(const T *f, const Double_t *param)>>(func)); 319 {; 320 }; 321 ; 322 /**; 323 Destructor (no operations); 324 */; 325 virtual ~ParamFunctorTempl () {; 326 if (fImpl) delete fImpl;; 327 }; 328 ; 329 /**; 330 Copy constructor; 331 */; 332 ParamFunctorTempl(const ParamFunctorTempl & rhs) :; 333 fImpl(nullptr); 334 {; 335// if (rhs.fImpl.get() != 0); 336// fImpl = std::unique_ptr<Impl>( (rhs.fImpl)->Clone() );; 337 if (rhs.fImpl) fImpl = rhs.fImpl->Clone();; 338 }; 339 ; 340 /**; 341 Assignment operator; 342 */; 343 ParamFunctorTempl & operator = (const ParamFunctorTempl & rhs) {; 344// ParamFunctor copy(rhs);; 345 // swap unique_ptr by hand; 346// Impl * p = fImpl.release();; 347// fImpl.reset(copy.fImpl.release());; 348// copy.fImpl.reset(p);; 349 ; 350 if(this != &rhs) {; 351 if (fImpl) delete fImpl;; 352 fImpl = nullptr;; 353 if (rhs.fImpl); 354 fImpl = rhs.fImpl->Clone();; 355 }; 356 return *this;; 357 }; 358 ; 359 void * GetImpl() { return (void *) fImpl; }; 360 ; 361 ; 362 T operator() ( T * x, double * p) {; 363 return (*fImpl)(x,p);; 364 }; 365 ; 366 T operator() (const T * x, const double * p) {; 367 return (*fImpl)(x,p);; 368 }; 369 ; 370 ; 371 bool Empty() const { return !fImpl; }; 372 ; 373 ; 374 void SetFunction(Impl * f) {; 375 fImpl = f;; 376 }; 377 ; 378private :; 379 ; 380 ; 381 //std::unique_ptr<Impl> fImpl;; 382 Impl * fImpl;; 383 ; 384 ; 385};; 386 ; 387 ; 388using ParamFunctor = ParamFunctorTempl<double>;; 389 ; 390 } // end namespace Math; 391 ; 392} // end namespace ROOT; 393 ; 394 ; 395#endif /* ROOT_Math_ParamFunctor */; f#define f(i)Definition RSha256.hxx:104; RtypesCore.h; pwinID h TVirtualViewer3D TVirtualGLPainter pDefinition TGWin32VirtualGLProxy.cxx:51; operator()TRO",MatchSource.WIKI,doc/master/ParamFunctor_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ParamFunctor_8h_source.html
https://root.cern/doc/master/ParamFunctor_8h_source.html:1581,Integrability,wrap,wrapping,1581,"3 ; 4/**********************************************************************; 5 * *; 6 * Copyright (c) 2006 LCG ROOT Math Team, CERN/PH-SFT *; 7 * *; 8 * *; 9 **********************************************************************/; 10 ; 11// Header file for Functor classes.; 12// design is inspired by the Loki Functor; 13 ; 14#ifndef ROOT_Math_ParamFunctor; 15#define ROOT_Math_ParamFunctor; 16 ; 17// #ifndef ROOT_Math_IFunction; 18// #include ""Math/IFunction.h""; 19// #endif; 20 ; 21// #ifndef Root_Math_StaticCheck; 22// #include ""Math/StaticCheck.h""; 23// #endif; 24 ; 25//#include <memory>; 26 ; 27#include ""RtypesCore.h""; 28#include <functional>; 29#include <iostream>; 30 ; 31namespace ROOT {; 32 ; 33namespace Math {; 34 ; 35/**; 36 * \defgroup ParamFunctor_int N-D parametric functions; 37 * \brief Multi-dimensional parametric functions; 38 */; 39 ; 40/** class defining the signature for multi-dim parametric functions; 41 ; 42 @ingroup ParamFunctor_int; 43 */; 44template<class T>; 45class ParamFunctionBase {; 46 public:; 47 virtual ~ParamFunctionBase() {}; 48 virtual T operator() (const T * x, const double *p) = 0;; 49 virtual T operator() (T * x, double *p) = 0;; 50 virtual ParamFunctionBase * Clone() const = 0;; 51};; 52 ; 53 ; 54 ; 55/**; 56 ParamFunctor Handler class is responsible for wrapping any other functor and pointer to; 57 free C functions.; 58 It can be created from any function implementing the correct signature; 59 corresponding to the requested type; 60 ; 61 @ingroup ParamFunctor_int; 62 ; 63*/; 64 ; 65template<class ParentFunctor, class Func >; 66class ParamFunctorHandler : public ParentFunctor::Impl {; 67 ; 68 typedef typename ParentFunctor::EvalType EvalType;; 69 typedef typename ParentFunctor::Impl Base;; 70 ; 71public:; 72 ; 73 // constructor; 74 ParamFunctorHandler(const Func & fun) : fFunc(fun) {}; 75 ; 76 ; 77 virtual ~ParamFunctorHandler() {}; 78 ; 79 ; 80 // for 1D functions; 81 inline EvalType operator() (EvalType x, double *p) {; 82 retur",MatchSource.WIKI,doc/master/ParamFunctor_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ParamFunctor_8h_source.html
https://root.cern/doc/master/ParamFunctor_8h_source.html:7567,Integrability,wrap,wrap,7567,"61/**; 262 Param Functor class for Multidimensional functions.; 263 It is used to wrap in a very simple and convenient way; 264 any other C++ callable object (implementation double operator( const double *, const double * ) ); 265 or a member function with the correct signature,; 266 like Foo::EvalPar(const double *, const double *); 267 ; 268 @ingroup ParamFunc; 269 ; 270 */; 271 ; 272 ; 273template<class T>; 274class ParamFunctorTempl {; 275 ; 276 ; 277public:; 278 ; 279 typedef T EvalType;; 280 typedef ParamFunctionBase<T> Impl;; 281 ; 282 ; 283 /**; 284 Default constructor; 285 */; 286 ParamFunctorTempl () : fImpl(nullptr) {}; 287 ; 288 ; 289 /**; 290 construct from a pointer to member function (multi-dim type); 291 */; 292 template <class PtrObj, typename MemFn>; 293 ParamFunctorTempl(const PtrObj& p, MemFn memFn); 294 : fImpl(new ParamMemFunHandler<ParamFunctorTempl<T>, PtrObj, MemFn>(p, memFn)); 295 {}; 296 ; 297 ; 298 ; 299 /**; 300 construct from another generic Functor of multi-dimension; 301 */; 302 template <typename Func>; 303 explicit ParamFunctorTempl( const Func & f) :; 304 fImpl(new ParamFunctorHandler<ParamFunctorTempl<T>,Func>(f) ); 305 {}; 306 ; 307 ; 308 ; 309 // specialization used in TF1; 310 typedef T (* FreeFunc ) (T * , double *);; 311 ParamFunctorTempl(FreeFunc f) :; 312 fImpl(new ParamFunctorHandler<ParamFunctorTempl<T>,FreeFunc>(f) ); 313 {; 314 }; 315 ; 316 // specialization used in TF1; 317 ParamFunctorTempl(const std::function<T(const T *f, const Double_t *param)> &func) :; 318 fImpl(new ParamFunctorHandler<ParamFunctorTempl<T>, const std::function<T(const T *f, const Double_t *param)>>(func)); 319 {; 320 }; 321 ; 322 /**; 323 Destructor (no operations); 324 */; 325 virtual ~ParamFunctorTempl () {; 326 if (fImpl) delete fImpl;; 327 }; 328 ; 329 /**; 330 Copy constructor; 331 */; 332 ParamFunctorTempl(const ParamFunctorTempl & rhs) :; 333 fImpl(nullptr); 334 {; 335// if (rhs.fImpl.get() != 0); 336// fImpl = std::unique_ptr<Impl>( (rhs.f",MatchSource.WIKI,doc/master/ParamFunctor_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ParamFunctor_8h_source.html
https://root.cern/doc/master/ParamFunctor_8h_source.html:11376,Integrability,wrap,wrapping,11376,"id SetFunction(Impl * f) {; 375 fImpl = f;; 376 }; 377 ; 378private :; 379 ; 380 ; 381 //std::unique_ptr<Impl> fImpl;; 382 Impl * fImpl;; 383 ; 384 ; 385};; 386 ; 387 ; 388using ParamFunctor = ParamFunctorTempl<double>;; 389 ; 390 } // end namespace Math; 391 ; 392} // end namespace ROOT; 393 ; 394 ; 395#endif /* ROOT_Math_ParamFunctor */; f#define f(i)Definition RSha256.hxx:104; RtypesCore.h; pwinID h TVirtualViewer3D TVirtualGLPainter pDefinition TGWin32VirtualGLProxy.cxx:51; operator()TRObject operator()(const T1 &t1) constDefinition TRFunctionImport__oprtr.h:14; ROOT::Math::ParamFunctionBaseclass defining the signature for multi-dim parametric functionsDefinition ParamFunctor.h:45; ROOT::Math::ParamFunctionBase::operator()virtual T operator()(const T *x, const double *p)=0; ROOT::Math::ParamFunctionBase::~ParamFunctionBasevirtual ~ParamFunctionBase()Definition ParamFunctor.h:47; ROOT::Math::ParamFunctionBase::Clonevirtual ParamFunctionBase * Clone() const =0; ROOT::Math::ParamFunctorHandlerParamFunctor Handler class is responsible for wrapping any other functor and pointer to free C functi...Definition ParamFunctor.h:66; ROOT::Math::ParamFunctorHandler::fFuncFunc fFuncDefinition ParamFunctor.h:107; ROOT::Math::ParamFunctorHandler::operator()EvalType operator()(EvalType x, double *p)Definition ParamFunctor.h:81; ROOT::Math::ParamFunctorHandler::EvalTypeParentFunctor::EvalType EvalTypeDefinition ParamFunctor.h:68; ROOT::Math::ParamFunctorHandler::~ParamFunctorHandlervirtual ~ParamFunctorHandler()Definition ParamFunctor.h:77; ROOT::Math::ParamFunctorHandler::BaseParentFunctor::Impl BaseDefinition ParamFunctor.h:69; ROOT::Math::ParamFunctorHandler::ParamFunctorHandlerParamFunctorHandler(const Func &fun)Definition ParamFunctor.h:74; ROOT::Math::ParamFunctorHandler::CloneParamFunctorHandler * Clone() constDefinition ParamFunctor.h:100; ROOT::Math::ParamFunctorTemplParam Functor class for Multidimensional functions.Definition ParamFunctor.h:274; ROOT::Math::ParamFunctor",MatchSource.WIKI,doc/master/ParamFunctor_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ParamFunctor_8h_source.html
https://root.cern/doc/master/ParamFunctor_8h_source.html:7582,Usability,simpl,simple,7582,"61/**; 262 Param Functor class for Multidimensional functions.; 263 It is used to wrap in a very simple and convenient way; 264 any other C++ callable object (implementation double operator( const double *, const double * ) ); 265 or a member function with the correct signature,; 266 like Foo::EvalPar(const double *, const double *); 267 ; 268 @ingroup ParamFunc; 269 ; 270 */; 271 ; 272 ; 273template<class T>; 274class ParamFunctorTempl {; 275 ; 276 ; 277public:; 278 ; 279 typedef T EvalType;; 280 typedef ParamFunctionBase<T> Impl;; 281 ; 282 ; 283 /**; 284 Default constructor; 285 */; 286 ParamFunctorTempl () : fImpl(nullptr) {}; 287 ; 288 ; 289 /**; 290 construct from a pointer to member function (multi-dim type); 291 */; 292 template <class PtrObj, typename MemFn>; 293 ParamFunctorTempl(const PtrObj& p, MemFn memFn); 294 : fImpl(new ParamMemFunHandler<ParamFunctorTempl<T>, PtrObj, MemFn>(p, memFn)); 295 {}; 296 ; 297 ; 298 ; 299 /**; 300 construct from another generic Functor of multi-dimension; 301 */; 302 template <typename Func>; 303 explicit ParamFunctorTempl( const Func & f) :; 304 fImpl(new ParamFunctorHandler<ParamFunctorTempl<T>,Func>(f) ); 305 {}; 306 ; 307 ; 308 ; 309 // specialization used in TF1; 310 typedef T (* FreeFunc ) (T * , double *);; 311 ParamFunctorTempl(FreeFunc f) :; 312 fImpl(new ParamFunctorHandler<ParamFunctorTempl<T>,FreeFunc>(f) ); 313 {; 314 }; 315 ; 316 // specialization used in TF1; 317 ParamFunctorTempl(const std::function<T(const T *f, const Double_t *param)> &func) :; 318 fImpl(new ParamFunctorHandler<ParamFunctorTempl<T>, const std::function<T(const T *f, const Double_t *param)>>(func)); 319 {; 320 }; 321 ; 322 /**; 323 Destructor (no operations); 324 */; 325 virtual ~ParamFunctorTempl () {; 326 if (fImpl) delete fImpl;; 327 }; 328 ; 329 /**; 330 Copy constructor; 331 */; 332 ParamFunctorTempl(const ParamFunctorTempl & rhs) :; 333 fImpl(nullptr); 334 {; 335// if (rhs.fImpl.get() != 0); 336// fImpl = std::unique_ptr<Impl>( (rhs.f",MatchSource.WIKI,doc/master/ParamFunctor_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ParamFunctor_8h_source.html
https://root.cern/doc/master/parse__CSV__file__with__TTree__ReadStream_8py.html:3958,Safety,avoid,avoiding,3958,"the first line, strip the new lines; # and split it into a list along 'tab' boundaries; header_row = open(afile).readline().strip().split('\t'); # Create the branch descriptor; branch_descriptor = ':'.join([header_mapping_dictionary[row][0]+'/'+; type_mapping_dictionary[header_mapping_dictionary[row][1]]; for row in header_row]); #print(branch_descriptor); ; # Handling the input and output names. Using the same; # base name for the ROOT output file.; output_ROOT_file_name = os.path.splitext(afile)[0] + '.root'; output_file = ROOT.TFile(output_ROOT_file_name, 'recreate'); print(""Outputting %s -> %s"" % (afile, output_ROOT_file_name)); ; output_tree = ROOT.TTree(tree_name, tree_name); file_lines = open(afile).readlines(); ; # Clean the data entries: remove the first (header) row.; # Ensure empty strings are tagged as such since; # ROOT doesn't differentiate between different types; # of white space. Therefore, we change all of these; # entries to 'empty'. Also, avoiding any lines that begin; # with '#'; file_lines = ['\t'.join([val if (val.find(' ') == -1 and val != ''); else 'empty' for val in line.split('\t')]); for line in file_lines[1:] if line[0] != '#' ]; ; # Removing NaN, setting these entries to 0.0.; # Also joining the list of strings into one large string.; file_as_string = ('\n'.join(file_lines)).replace('NaN', str(0.0)); #print(file_as_string); ; # creating an istringstream to pass into ReadStream; istring = ROOT.istringstream(file_as_string); ; # Now read the stream; output_tree.ReadStream(istring, branch_descriptor); ; output_file.cd(); output_tree.Write(); ; ; if __name__ == '__main__':; if len(sys.argv) < 2:; print(""Usage: %s file_to_parse.dat"" % sys.argv[0]); sys.exit(1); parse_CSV_file_with_TTree_ReadStream(""example_tree"", sys.argv[1]); ; lenOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t Float",MatchSource.WIKI,doc/master/parse__CSV__file__with__TTree__ReadStream_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/parse__CSV__file__with__TTree__ReadStream_8py.html
https://root.cern/doc/master/PdfFuncMathMore_8h_source.html:2094,Performance,load,load,2094,"**********************************************/; 24 ; 25 ; 26#ifndef ROOT_Math_PdfFuncMathMore; 27#define ROOT_Math_PdfFuncMathMore; 28 ; 29namespace ROOT {; 30 namespace Math {; 31 ; 32 ; 33 /**; 34 ; 35 Probability density function of the non central \f$\chi^2\f$ distribution with \f$r\f$; 36 degrees of freedom and the noon-central parameter \f$\lambda\f$; 37 ; 38 \f[ p_r(x) = \frac{1}{\Gamma(r/2) 2^{r/2}} x^{r/2-1} e^{-x/2} \f]; 39 ; 40 for \f$x \geq 0\f$.; 41 For detailed description see; 42 <A HREF=""http://mathworld.wolfram.com/NoncentralChi-SquaredDistribution.html"">; 43 Mathworld</A>.; 44 ; 45 @ingroup PdfFunc; 46 ; 47 */; 48 ; 49 double noncentral_chisquared_pdf(double x, double r, double lambda);; 50 ; 51 } //end namespace Math; 52} // end namespace ROOT; 53 ; 54 ; 55// make a fake class to auto-load functions from MathMore; 56 ; 57namespace ROOT {; 58 namespace Math {; 59 ; 60 class MathMoreLib {; 61 ; 62 public:; 63 ; 64 // adding this method with force the auto-loading of the library; 65 static void Load();; 66 };; 67 ; 68 typedef MathMoreLib MathMoreLibrary; ; 69 }; 70 ; 71}; 72 ; 73 ; 74 ; 75#endif // ROOT_Math_PdfFuncMathMore; rOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t rDefinition TGWin32VirtualXProxy.cxx:168; ROOT::Math::MathMoreLibDefinition PdfFuncMathMore.h:60; ROOT::Math::MathMoreLib::Loadstatic void Load()Definition PdfFuncMathMore.cxx:73; ROOT::Math::noncentral_chisquared_pdfdouble noncentral_chisquared_pdf(double x, double r, double lambda)Probability density function of the non central distribution with degrees of freedom and the noon-c...Definition PdfFuncMathMore.cxx:22; xDouble_t x[n]Definition legend1.C:17; MathNamespace for new Math classes and functions.; ROOT::Math::MathMoreLibraryMathMoreLib MathMoreLibraryDefinition PdfFuncMathMore.h:68; ROOTtbb::task_arena is an alias o",MatchSource.WIKI,doc/master/PdfFuncMathMore_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/PdfFuncMathMore_8h_source.html
https://root.cern/doc/master/PdfFuncMathMore_8h_source.html:2266,Performance,load,loading,2266,"**********************************************/; 24 ; 25 ; 26#ifndef ROOT_Math_PdfFuncMathMore; 27#define ROOT_Math_PdfFuncMathMore; 28 ; 29namespace ROOT {; 30 namespace Math {; 31 ; 32 ; 33 /**; 34 ; 35 Probability density function of the non central \f$\chi^2\f$ distribution with \f$r\f$; 36 degrees of freedom and the noon-central parameter \f$\lambda\f$; 37 ; 38 \f[ p_r(x) = \frac{1}{\Gamma(r/2) 2^{r/2}} x^{r/2-1} e^{-x/2} \f]; 39 ; 40 for \f$x \geq 0\f$.; 41 For detailed description see; 42 <A HREF=""http://mathworld.wolfram.com/NoncentralChi-SquaredDistribution.html"">; 43 Mathworld</A>.; 44 ; 45 @ingroup PdfFunc; 46 ; 47 */; 48 ; 49 double noncentral_chisquared_pdf(double x, double r, double lambda);; 50 ; 51 } //end namespace Math; 52} // end namespace ROOT; 53 ; 54 ; 55// make a fake class to auto-load functions from MathMore; 56 ; 57namespace ROOT {; 58 namespace Math {; 59 ; 60 class MathMoreLib {; 61 ; 62 public:; 63 ; 64 // adding this method with force the auto-loading of the library; 65 static void Load();; 66 };; 67 ; 68 typedef MathMoreLib MathMoreLibrary; ; 69 }; 70 ; 71}; 72 ; 73 ; 74 ; 75#endif // ROOT_Math_PdfFuncMathMore; rOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t rDefinition TGWin32VirtualXProxy.cxx:168; ROOT::Math::MathMoreLibDefinition PdfFuncMathMore.h:60; ROOT::Math::MathMoreLib::Loadstatic void Load()Definition PdfFuncMathMore.cxx:73; ROOT::Math::noncentral_chisquared_pdfdouble noncentral_chisquared_pdf(double x, double r, double lambda)Probability density function of the non central distribution with degrees of freedom and the noon-c...Definition PdfFuncMathMore.cxx:22; xDouble_t x[n]Definition legend1.C:17; MathNamespace for new Math classes and functions.; ROOT::Math::MathMoreLibraryMathMoreLib MathMoreLibraryDefinition PdfFuncMathMore.h:68; ROOTtbb::task_arena is an alias o",MatchSource.WIKI,doc/master/PdfFuncMathMore_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/PdfFuncMathMore_8h_source.html
https://root.cern/doc/master/peaks_8C.html:7784,Energy Efficiency,schedul,scheduler,7784,"1.cxx:1439; TF1::GetParametervirtual Double_t GetParameter(Int_t ipar) constDefinition TF1.h:540; TH1F1-D histogram with a float per channel (see TH1 documentation)Definition TH1.h:622; TH1TH1 is the base class of all histogram classes in ROOT.Definition TH1.h:59; TRandom::RndmDouble_t Rndm() overrideMachine independent random number generator.Definition TRandom.cxx:559; TSpectrumAdvanced Spectra Processing.Definition TSpectrum.h:18; TSpectrum::Backgroundvirtual TH1 * Background(const TH1 *hist, Int_t niter=20, Option_t *option="""")One-dimensional background estimation function.Definition TSpectrum.cxx:145; TSpectrum::Searchvirtual Int_t Search(const TH1 *hist, Double_t sigma=2, Option_t *option="""", Double_t threshold=0.05)One-dimensional peak search function.Definition TSpectrum.cxx:259; TSpectrum::GetPositionXDouble_t * GetPositionX() constDefinition TSpectrum.h:58; TVirtualFitter::Fitterstatic TVirtualFitter * Fitter(TObject *obj, Int_t maxpar=25)Static function returning a pointer to the current fitter.Definition TVirtualFitter.cxx:159; sigmaconst Double_t sigmaDefinition h1analysisProxy.h:11; c1return c1Definition legend1.C:41; PyTorch_Generate_CNN_Model.fitfit(model, train_loader, val_loader, num_epochs, batch_size, optimizer, criterion, save_best, scheduler)Definition PyTorch_Generate_CNN_Model.py:34; TMVA_SOFIE_GNN_Parser.h2h2Definition TMVA_SOFIE_GNN_Parser.py:188; TMath::GausDouble_t Gaus(Double_t x, Double_t mean=0, Double_t sigma=1, Bool_t norm=kFALSE)Calculates a gaussian function with mean and sigma.Definition TMath.cxx:471; TMath::SqrtDouble_t Sqrt(Double_t x)Returns the square root of x.Definition TMath.h:662; TMath::AbsShort_t Abs(Short_t d)Returns the absolute value of parameter Short_t d.Definition TMathBase.h:123; TMath::TwoPiconstexpr Double_t TwoPi()Definition TMath.h:44; AuthorRene Brun ; Definition in file peaks.C. tutorialsspectrumpeaks.C. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:31 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/peaks_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/peaks_8C.html
https://root.cern/doc/master/peaks_8C.html:395,Integrability,inject,injected,395,". ROOT: tutorials/spectrum/peaks.C File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. peaks.C File ReferenceTutorials  Spectrum tutorials. Detailed Description; Illustrates how to find peaks in histograms. ; This script generates a random number of gaussian peaks on top of a linear background. The position of the peaks is found via TSpectrum and injected as initial values of parameters to make a global fit. The background is computed and drawn on top of the original histogram.; This script can fit ""peaks' heights"" or ""peaks' areas"" (comment out or uncomment the line which defines __PEAKS_C_FIT_AREAS__).; To execute this example, do (in ROOT 5 or ROOT 6):; root > .x peaks.C (generate 10 peaks by default); root > .x peaks.C++ (use the compiler); root > .x peaks.C++(30) (generates 30 peaks); xDouble_t x[n]Definition legend1.C:17; To execute only the first part of the script (without fitting) specify a negative value for the number of peaks, eg; root > .x peaks.C(-20); ; Found 9 candidate peaks to fit; Found 9 useful peaks to fit; Now fitting: Be patient; ****************************************; Minimizer is Minuit2 / Migrad; Chi2 = 596.686; NDf = 471; Edm = 1.7299e-05; NCalls = 1747; p0 = 527.684 +/- 2.02282 ; p1 = -0.395029 +/- 0.00304651 ; p2 = 634.668 +/- 20.672 ; p3 = 519.331 +/- 0.111412 ; p4 = 3.49861 +/- 0.109353 ; p5 = 664.735 +/- 18.7022 ; p6 = 319.147 +/- 0.131874 ; p7 = 4.69145 +/- 0.126752 ; p8 = 670.916 +/- 17.6455 ; p9 = 754.806 +/- 0.108202 ; p10 = 4.29739 +/- 0.101204 ; p11 = 669.613 +/- 20.0806 ; p12 = 475.964 +/- 0.113649 ; p13 = 3.89314 +/- 0.110985 ; p14 = 648.09 +/- 18.199 ; p15 = 989.666 +/- 0.0884478 ; p16 = 3.34535 +/- 0.0786714 ; p17 = 662.552 +/- 17.8619 ; p18 = 539.268 +/- 0.122694 ; p19 = 4.56069 +/- 0.113882 ; p20 = 659.417 +/- 16.1804 ; p21 = 948.476 +/- 0.101982 ; p22 = 4.41156 +/- 0.091998 ; p23 = 753.529 +/- 15.2593 ; p24 = 232.585 +/- 0.151403 ; p25 = 6.95019 +/- 0.122555 ; p26 = 645.477 +",MatchSource.WIKI,doc/master/peaks_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/peaks_8C.html
https://root.cern/doc/master/peaks_8C.html:7751,Performance,optimiz,optimizer,7751,"1.cxx:1439; TF1::GetParametervirtual Double_t GetParameter(Int_t ipar) constDefinition TF1.h:540; TH1F1-D histogram with a float per channel (see TH1 documentation)Definition TH1.h:622; TH1TH1 is the base class of all histogram classes in ROOT.Definition TH1.h:59; TRandom::RndmDouble_t Rndm() overrideMachine independent random number generator.Definition TRandom.cxx:559; TSpectrumAdvanced Spectra Processing.Definition TSpectrum.h:18; TSpectrum::Backgroundvirtual TH1 * Background(const TH1 *hist, Int_t niter=20, Option_t *option="""")One-dimensional background estimation function.Definition TSpectrum.cxx:145; TSpectrum::Searchvirtual Int_t Search(const TH1 *hist, Double_t sigma=2, Option_t *option="""", Double_t threshold=0.05)One-dimensional peak search function.Definition TSpectrum.cxx:259; TSpectrum::GetPositionXDouble_t * GetPositionX() constDefinition TSpectrum.h:58; TVirtualFitter::Fitterstatic TVirtualFitter * Fitter(TObject *obj, Int_t maxpar=25)Static function returning a pointer to the current fitter.Definition TVirtualFitter.cxx:159; sigmaconst Double_t sigmaDefinition h1analysisProxy.h:11; c1return c1Definition legend1.C:41; PyTorch_Generate_CNN_Model.fitfit(model, train_loader, val_loader, num_epochs, batch_size, optimizer, criterion, save_best, scheduler)Definition PyTorch_Generate_CNN_Model.py:34; TMVA_SOFIE_GNN_Parser.h2h2Definition TMVA_SOFIE_GNN_Parser.py:188; TMath::GausDouble_t Gaus(Double_t x, Double_t mean=0, Double_t sigma=1, Bool_t norm=kFALSE)Calculates a gaussian function with mean and sigma.Definition TMath.cxx:471; TMath::SqrtDouble_t Sqrt(Double_t x)Returns the square root of x.Definition TMath.h:662; TMath::AbsShort_t Abs(Short_t d)Returns the absolute value of parameter Short_t d.Definition TMathBase.h:123; TMath::TwoPiconstexpr Double_t TwoPi()Definition TMath.h:44; AuthorRene Brun ; Definition in file peaks.C. tutorialsspectrumpeaks.C. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:31 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/peaks_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/peaks_8C.html
https://root.cern/doc/master/peaks_8C.html:395,Security,inject,injected,395,". ROOT: tutorials/spectrum/peaks.C File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. peaks.C File ReferenceTutorials  Spectrum tutorials. Detailed Description; Illustrates how to find peaks in histograms. ; This script generates a random number of gaussian peaks on top of a linear background. The position of the peaks is found via TSpectrum and injected as initial values of parameters to make a global fit. The background is computed and drawn on top of the original histogram.; This script can fit ""peaks' heights"" or ""peaks' areas"" (comment out or uncomment the line which defines __PEAKS_C_FIT_AREAS__).; To execute this example, do (in ROOT 5 or ROOT 6):; root > .x peaks.C (generate 10 peaks by default); root > .x peaks.C++ (use the compiler); root > .x peaks.C++(30) (generates 30 peaks); xDouble_t x[n]Definition legend1.C:17; To execute only the first part of the script (without fitting) specify a negative value for the number of peaks, eg; root > .x peaks.C(-20); ; Found 9 candidate peaks to fit; Found 9 useful peaks to fit; Now fitting: Be patient; ****************************************; Minimizer is Minuit2 / Migrad; Chi2 = 596.686; NDf = 471; Edm = 1.7299e-05; NCalls = 1747; p0 = 527.684 +/- 2.02282 ; p1 = -0.395029 +/- 0.00304651 ; p2 = 634.668 +/- 20.672 ; p3 = 519.331 +/- 0.111412 ; p4 = 3.49861 +/- 0.109353 ; p5 = 664.735 +/- 18.7022 ; p6 = 319.147 +/- 0.131874 ; p7 = 4.69145 +/- 0.126752 ; p8 = 670.916 +/- 17.6455 ; p9 = 754.806 +/- 0.108202 ; p10 = 4.29739 +/- 0.101204 ; p11 = 669.613 +/- 20.0806 ; p12 = 475.964 +/- 0.113649 ; p13 = 3.89314 +/- 0.110985 ; p14 = 648.09 +/- 18.199 ; p15 = 989.666 +/- 0.0884478 ; p16 = 3.34535 +/- 0.0786714 ; p17 = 662.552 +/- 17.8619 ; p18 = 539.268 +/- 0.122694 ; p19 = 4.56069 +/- 0.113882 ; p20 = 659.417 +/- 16.1804 ; p21 = 948.476 +/- 0.101982 ; p22 = 4.41156 +/- 0.091998 ; p23 = 753.529 +/- 15.2593 ; p24 = 232.585 +/- 0.151403 ; p25 = 6.95019 +/- 0.122555 ; p26 = 645.477 +",MatchSource.WIKI,doc/master/peaks_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/peaks_8C.html
https://root.cern/doc/master/peaks_8C.html:2954,Testability,test,test,2954," ; p16 = 3.34535 +/- 0.0786714 ; p17 = 662.552 +/- 17.8619 ; p18 = 539.268 +/- 0.122694 ; p19 = 4.56069 +/- 0.113882 ; p20 = 659.417 +/- 16.1804 ; p21 = 948.476 +/- 0.101982 ; p22 = 4.41156 +/- 0.091998 ; p23 = 753.529 +/- 15.2593 ; p24 = 232.585 +/- 0.151403 ; p25 = 6.95019 +/- 0.122555 ; p26 = 645.477 +/- 17.9858 ; p27 = 286.947 +/- 0.140814 ; p28 = 4.98705 +/- 0.133049 ; . ; #include ""TCanvas.h""; #include ""TMath.h""; #include ""TH1.h""; #include ""TF1.h""; #include ""TRandom.h""; #include ""TSpectrum.h""; #include ""TVirtualFitter.h""; ; //; // Comment out the line below, if you want ""peaks' heights"".; // Uncomment the line below, if you want ""peaks' areas"".; //; // #define __PEAKS_C_FIT_AREAS__ 1 /* fit peaks' areas */; ; Int_t npeaks = 30;; Double_t fpeaks(Double_t *x, Double_t *par) {; Double_t result = par[0] + par[1]*x[0];; for (Int_t p=0;p<npeaks;p++) {; Double_t norm = par[3*p+2]; // ""height"" or ""area""; Double_t mean = par[3*p+3];; Double_t sigma = par[3*p+4];; #if defined(__PEAKS_C_FIT_AREAS__); norm /= sigma * (TMath::Sqrt(TMath::TwoPi())); // ""area""; #endif /* defined(__PEAKS_C_FIT_AREAS__) */; result += norm*TMath::Gaus(x[0],mean,sigma);; }; return result;; }; void peaks(Int_t np=10) {; npeaks = TMath::Abs(np);; TH1F *h = new TH1F(""h"",""test"",500,0,1000);; // Generate n peaks at random; Double_t par[3000];; par[0] = 0.8;; par[1] = -0.6/1000;; Int_t p;; for (p=0;p<npeaks;p++) {; par[3*p+2] = 1; // ""height""; par[3*p+3] = 10+gRandom->Rndm()*980; // ""mean""; par[3*p+4] = 3+2*gRandom->Rndm(); // ""sigma""; #if defined(__PEAKS_C_FIT_AREAS__); par[3*p+2] *= par[3*p+4] * (TMath::Sqrt(TMath::TwoPi())); // ""area""; #endif /* defined(__PEAKS_C_FIT_AREAS__) */; }; TF1 *f = new TF1(""f"",fpeaks,0,1000,2+3*npeaks);; f->SetNpx(1000);; f->SetParameters(par);; TCanvas *c1 = new TCanvas(""c1"",""c1"",10,10,1000,900);; c1->Divide(1,2);; c1->cd(1);; h->FillRandom(""f"",200000);; h->Draw();; TH1F *h2 = (TH1F*)h->Clone(""h2"");; // Use TSpectrum to find the peak candidates; TSpectrum *s = new TSpect",MatchSource.WIKI,doc/master/peaks_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/peaks_8C.html
https://root.cern/doc/master/piechart_8C.html:414,Testability,test,test,414,". ROOT: tutorials/graphics/piechart.C File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. piechart.C File ReferenceTutorials  Graphics tutorials. Detailed Description; Pie chart example. . ; void piechart(); {; Float_t vals[] = {.2,1.1,.6,.9,2.3};; Int_t colors[] = {2,3,4,5,6};; Int_t nvals = sizeof(vals)/sizeof(vals[0]);; ; TCanvas *cpie = new TCanvas(""cpie"",""TPie test"",700,700);; cpie->Divide(2,2);; ; TPie *pie1 = new TPie(""pie1"",; ""Pie with offset and no colors"",nvals,vals);; TPie *pie2 = new TPie(""pie2"",; ""Pie with radial labels"",nvals,vals,colors);; TPie *pie3 = new TPie(""pie3"",; ""Pie with tangential labels"",nvals,vals,colors);; TPie *pie4 = new TPie(""pie4"",; ""Pie with verbose labels"",nvals,vals,colors);; ; cpie->cd(1);; pie1->SetAngularOffset(30.);; pie1->SetEntryRadiusOffset( 4, 0.1);; pie1->SetRadius(.35);; pie1->Draw(""3d"");; ; cpie->cd(2);; pie2->SetEntryRadiusOffset(2,.05);; pie2->SetEntryLineColor(2,2);; pie2->SetEntryLineWidth(2,5);; pie2->SetEntryLineStyle(2,2);; pie2->SetEntryFillStyle(1,3030);; pie2->SetCircle(.5,.45,.3);; pie2->Draw(""rsc"");; ; cpie->cd(3);; pie3->SetY(.32);; pie3->GetSlice(0)->SetValue(.8);; pie3->GetSlice(1)->SetFillStyle(3031);; pie3->SetLabelsOffset(-.1);; pie3->Draw(""3d t nol"");; TLegend *pieleg = pie3->MakeLegend();; pieleg->SetY1(.56); pieleg->SetY2(.86);; ; cpie->cd(4);; pie4->SetRadius(.2);; pie4->SetLabelsOffset(.01);; pie4->SetLabelFormat(""#splitline{%val (%perc)}{%txt}"");; pie4->Draw(""nol <"");; }; Int_tint Int_tDefinition RtypesCore.h:45; Float_tfloat Float_tDefinition RtypesCore.h:57; colorsColor * colorsDefinition X3DBuffer.c:21; TAttFill::SetFillStylevirtual void SetFillStyle(Style_t fstyle)Set the fill area style.Definition TAttFill.h:39; TCanvasThe Canvas class.Definition TCanvas.h:23; TCanvas::cdTVirtualPad * cd(Int_t subpadnumber=0) overrideSet current canvas & pad.Definition TCanvas.cxx:719; TLegendThis class displays a legend box (TPaveText) containing several legend en",MatchSource.WIKI,doc/master/piechart_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/piechart_8C.html
https://root.cern/doc/master/Point2D_8h.html:327,Integrability,depend,dependency,327,". ROOT: math/genvector/inc/Math/Point2D.h File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. Point2D.h File Reference. #include ""Math/Point2Dfwd.h""; #include ""Math/GenVector/Cartesian2D.h""; #include ""Math/GenVector/Polar2D.h""; #include ""Math/GenVector/PositionVector2D.h"". Include dependency graph for Point2D.h:. This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead. mathgenvectorincMathPoint2D.h. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:21 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/Point2D_8h.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Point2D_8h.html
https://root.cern/doc/master/Point3Dfwd_8h_source.html:613,Deployability,update,update,613,". ROOT: math/genvector/inc/Math/Point3Dfwd.h Source File. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. Point3Dfwd.h. Go to the documentation of this file. 1// @(#)root/mathcore:$Id$; 2// Authors: W. Brown, M. Fischler, L. Moneta 2005; 3 ; 4 /**********************************************************************; 5 * *; 6 * Copyright (c) 2005 , LCG ROOT MathLib Team *; 7 * *; 8 * *; 9 **********************************************************************/; 10 ; 11// Header file Point3Dfwd; 12//; 13// Created by: Lorenzo Moneta at Mon May 30 18:12:14 2005; 14//; 15// Last update: Mon May 30 18:12:14 2005; 16//; 17#ifndef ROOT_Math_Point3Dfwd; 18#define ROOT_Math_Point3Dfwd 1; 19 ; 20// forward declareations of position vectors (Points) and type defs definitions; 21 ; 22namespace ROOT {; 23 ; 24 namespace Math {; 25 ; 26 template<class CoordSystem, class Tag> class PositionVector3D;; 27 ; 28 template<typename T> class Cartesian3D;; 29 template<typename T> class Cylindrical3D;; 30 template<typename T> class CylindricalEta3D;; 31 template<typename T> class Polar3D;; 32 ; 33 class DefaultCoordinateSystemTag;; 34 ; 35 /**; 36 3D Point based on the cartesian coordinates x,y,z in double precision; 37 */; 38 typedef PositionVector3D< Cartesian3D<double>, DefaultCoordinateSystemTag > XYZPoint;; 39 ; 40 /**; 41 3D Point based on the cartesian coordinates x,y,z in single precision; 42 */; 43 typedef PositionVector3D< Cartesian3D<float>, DefaultCoordinateSystemTag > XYZPointF;; 44 typedef XYZPoint XYZPointD;; 45 ; 46 /**; 47 3D Point based on the eta based cylindrical coordinates rho, eta, phi in double precision.; 48 */; 49 typedef PositionVector3D< CylindricalEta3D<double>, DefaultCoordinateSystemTag > RhoEtaPhiPoint;; 50 /**; 51 3D Point based on the eta based cylindrical coordinates rho, eta, phi in single precision.; 52 */; 53 typedef PositionVector3D< CylindricalEta3D<float>, DefaultCoordinateSystemTag > RhoEtaPhiPointF;; 54 typedef RhoEta",MatchSource.WIKI,doc/master/Point3Dfwd_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Point3Dfwd_8h_source.html
https://root.cern/doc/master/Point3D_8h.html:416,Integrability,depend,dependency,416,". ROOT: math/genvector/inc/Math/Point3D.h File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. Point3D.h File Reference. #include ""Math/Point3Dfwd.h""; #include ""Math/GenVector/Cartesian3D.h""; #include ""Math/GenVector/CylindricalEta3D.h""; #include ""Math/GenVector/Polar3D.h""; #include ""Math/GenVector/Cylindrical3D.h""; #include ""Math/GenVector/PositionVector3D.h"". Include dependency graph for Point3D.h:. This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead. mathgenvectorincMathPoint3D.h. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:21 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/Point3D_8h.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Point3D_8h.html
https://root.cern/doc/master/PoissonLikelihoodFCN_8h_source.html:6258,Availability,error,errors,6258,,MatchSource.WIKI,doc/master/PoissonLikelihoodFCN_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/PoissonLikelihoodFCN_8h_source.html
https://root.cern/doc/master/PoissonLikelihoodFCN_8h_source.html:9606,Availability,error,error,9606,"lass for the objective functions used in the fits It has a reference to the dat...Definition BasicFCN.h:40; ROOT::Fit::BasicFCN::SetDatavoid SetData(const std::shared_ptr< DataType > &data)Set the data pointer.Definition BasicFCN.h:98; ROOT::Fit::BasicFCN::ModelFunctionPtrstd::shared_ptr< IModelFunction > ModelFunctionPtr() constaccess to function pointerDefinition BasicFCN.h:81; ROOT::Fit::BasicFCN::SetModelFunctionvoid SetModelFunction(const std::shared_ptr< IModelFunction > &func)Set the function pointer.Definition BasicFCN.h:101; ROOT::Fit::BasicFCN::Datavirtual const DataType & Data() constaccess to const reference to the dataDefinition BasicFCN.h:72; ROOT::Fit::BasicFCN::DataPtrstd::shared_ptr< DataType > DataPtr() constaccess to data pointerDefinition BasicFCN.h:75; ROOT::Fit::BasicFCN::ModelFunctionvirtual const IModelFunction & ModelFunction() constaccess to const reference to the model functionDefinition BasicFCN.h:78; ROOT::Fit::BinDataClass describing the binned data sets : vectors of x coordinates, y values and optionally error on y ...Definition BinData.h:52; ROOT::Fit::PoissonLikelihoodFCNclass evaluating the log likelihood for binned Poisson likelihood fits it is template to distinguish ...Definition PoissonLikelihoodFCN.h:46; ROOT::Fit::PoissonLikelihoodFCN::NFitPointsvirtual unsigned int NFitPoints() constDefinition PoissonLikelihoodFCN.h:118; ROOT::Fit::PoissonLikelihoodFCN::IModelFunction::ROOT::Math::IParamMultiFunctionTempl< T > IModelFunctionDefinition PoissonLikelihoodFCN.h:55; ROOT::Fit::PoissonLikelihoodFCN::PoissonLikelihoodFCNPoissonLikelihoodFCN(const BinData &data, const IModelFunction &func, int weight=0, bool extended=true, const ::ROOT::EExecutionPolicy &executionPolicy=::ROOT::EExecutionPolicy::kSequential)Constructor from unbin data set and model function (pdf) managed by the users.Definition PoissonLikelihoodFCN.h:73; ROOT::Fit::PoissonLikelihoodFCN::DoDerivativevirtual double DoDerivative(const double *x, unsigned int icoord) con",MatchSource.WIKI,doc/master/PoissonLikelihoodFCN_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/PoissonLikelihoodFCN_8h_source.html
https://root.cern/doc/master/PoissonLikelihoodFCN_8h_source.html:6551,Integrability,interface,interface,6551,,MatchSource.WIKI,doc/master/PoissonLikelihoodFCN_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/PoissonLikelihoodFCN_8h_source.html
https://root.cern/doc/master/PoissonLikelihoodFCN_8h_source.html:11582,Integrability,interface,interface,11582,"d int icoord) constDefinition PoissonLikelihoodFCN.h:195; ROOT::Fit::PoissonLikelihoodFCN::BaseObjFunction::ROOT::Math::BasicFitMethodFunction< DerivFunType > BaseObjFunctionDefinition PoissonLikelihoodFCN.h:52; ROOT::Fit::PoissonLikelihoodFCN::PoissonLikelihoodFCNPoissonLikelihoodFCN(const PoissonLikelihoodFCN &f)Copy constructor.Definition PoissonLikelihoodFCN.h:91; ROOT::Fit::PoissonLikelihoodFCN::Clonevirtual BaseFunction * Clone() constclone the function (need to return Base for Windows)Definition PoissonLikelihoodFCN.h:115; ROOT::Fit::PoissonLikelihoodFCN::UseSumOfWeightSquarevoid UseSumOfWeightSquare(bool on=true)Definition PoissonLikelihoodFCN.h:173; ROOT::Fit::PoissonLikelihoodFCN::IsWeightedbool IsWeighted() constDefinition PoissonLikelihoodFCN.h:163; ROOT::Fit::PoissonLikelihoodFCN::~PoissonLikelihoodFCNvirtual ~PoissonLikelihoodFCN()Destructor (no operations)Definition PoissonLikelihoodFCN.h:86; ROOT::Fit::PoissonLikelihoodFCN::DoEvalvirtual double DoEval(const double *x) constEvaluation of the function (required by interface)Definition PoissonLikelihoodFCN.h:188; ROOT::Fit::PoissonLikelihoodFCN::fExecutionPolicy::ROOT::EExecutionPolicy fExecutionPolicyExecution policy.Definition PoissonLikelihoodFCN.h:210; ROOT::Fit::PoissonLikelihoodFCN::BaseFunctionBaseObjFunction::BaseFunction BaseFunctionDefinition PoissonLikelihoodFCN.h:53; ROOT::Fit::PoissonLikelihoodFCN::Gradientvirtual void Gradient(const double *x, double *g) constevaluate gradientDefinition PoissonLikelihoodFCN.h:127; ROOT::Fit::PoissonLikelihoodFCN::Type_tBaseObjFunction::Type_t Type_tDefinition PoissonLikelihoodFCN.h:56; ROOT::Fit::PoissonLikelihoodFCN::fIsExtendedbool fIsExtendedflag to indicate if is extended (when false is a Multinomial likelihood), default is trueDefinition PoissonLikelihoodFCN.h:203; ROOT::Fit::PoissonLikelihoodFCN::operator=PoissonLikelihoodFCN & operator=(const PoissonLikelihoodFCN &rhs)Assignment operator.Definition PoissonLikelihoodFCN.h:103; ROOT::Fit::PoissonLikeli",MatchSource.WIKI,doc/master/PoissonLikelihoodFCN_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/PoissonLikelihoodFCN_8h_source.html
https://root.cern/doc/master/PoissonLikelihoodFCN_8h_source.html:14863,Integrability,interface,interface,14863,"tion PoissonLikelihoodFCN.h:121; ROOT::Fit::PoissonLikelihoodFCN::Typevirtual BaseObjFunction::Type_t Type() constComputes the full Hessian.Definition PoissonLikelihoodFCN.h:161; ROOT::Math::BasicFitMethodFunction< DerivFunType >::Type_tType_tenumeration specifying the possible fit method typesDefinition FitMethodFunction.h:46; ROOT::Math::BasicFitMethodFunction< DerivFunType >::kPoissonLikelihood@ kPoissonLikelihoodDefinition FitMethodFunction.h:46; ROOT::Math::BasicFitMethodFunction< DerivFunType >::IsAGradFCNstatic bool IsAGradFCN()Static function to indicate if a function is supporting gradient.Definition FitMethodFunction.h:135; ROOT::Math::BasicFitMethodFunction< DerivFunType >::BaseFunctionFunctionType::BaseFunc BaseFunctionDefinition FitMethodFunction.h:43; ROOT::Math::BasicFitMethodFunction< DerivFunType >::UpdateNCallsvirtual void UpdateNCalls() constupdate number of callsDefinition FitMethodFunction.h:124; ROOT::Math::IParametricFunctionMultiDimTemplIParamFunction interface (abstract class) describing multi-dimensional parametric functions It is a d...Definition IParamFunction.h:108; double; xDouble_t x[n]Definition legend1.C:17; HFit::FitTFitResultPtr Fit(FitObject *h1, TF1 *f1, Foption_t &option, const ROOT::Math::MinimizerOptions &moption, const char *goption, ROOT::Fit::DataRange &range)Definition HFitImpl.cxx:133; ROOT::Fit::PoissonLLGradFunctionPoissonLikelihoodFCN< ROOT::Math::IMultiGradFunction, ROOT::Math::IParamMultiFunction > PoissonLLGradFunctionDefinition PoissonLikelihoodFCN.h:215; ROOT::Fit::PoissonLLFunctionPoissonLikelihoodFCN< ROOT::Math::IMultiGenFunction, ROOT::Math::IParamMultiFunction > PoissonLLFunctionDefinition PoissonLikelihoodFCN.h:214; ROOTtbb::task_arena is an alias of tbb::interface7::task_arena, which doesn't allow to forward declare tb...Definition EExecutionPolicy.hxx:4; ROOT::EExecutionPolicyEExecutionPolicyDefinition EExecutionPolicy.hxx:5; ROOT::EExecutionPolicy::kSequential@ kSequential; ROOT::Fit::FitUtil::Evaluate::Ev",MatchSource.WIKI,doc/master/PoissonLikelihoodFCN_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/PoissonLikelihoodFCN_8h_source.html
https://root.cern/doc/master/PoissonLikelihoodFCN_8h_source.html:2154,Modifiability,extend,extended,2154,"OT_Fit_FitUtilParallel; 28// #include ""Fit/FitUtilParallel.h""; 29// #endif; 30// #endif; 31 ; 32namespace ROOT {; 33 ; 34 namespace Fit {; 35 ; 36 ; 37//___________________________________________________________________________________; 38/**; 39 class evaluating the log likelihood; 40 for binned Poisson likelihood fits; 41 it is template to distinguish gradient and non-gradient case; 42 ; 43 @ingroup FitMethodFunc; 44*/; 45template<class DerivFunType, class ModelFunType = ROOT::Math::IParamMultiFunction>; 46class PoissonLikelihoodFCN : public BasicFCN<DerivFunType,ModelFunType,BinData> {; 47 ; 48public:; 49 typedef typename ModelFunType::BackendType T;; 50 typedef BasicFCN<DerivFunType,ModelFunType,BinData> BaseFCN;; 51 ; 52 typedef ::ROOT::Math::BasicFitMethodFunction<DerivFunType> BaseObjFunction;; 53 typedef typename BaseObjFunction::BaseFunction BaseFunction;; 54 ; 55 typedef ::ROOT::Math::IParamMultiFunctionTempl<T> IModelFunction;; 56 typedef typename BaseObjFunction::Type_t Type_t;; 57 ; 58 /**; 59 Constructor from unbin data set and model function (pdf); 60 */; 61 PoissonLikelihoodFCN (const std::shared_ptr<BinData> & data, const std::shared_ptr<IModelFunction> & func, int weight = 0, bool extended = true, const ::ROOT::EExecutionPolicy &executionPolicy = ::ROOT::EExecutionPolicy::kSequential ) :; 62 BaseFCN( data, func),; 63 fIsExtended(extended),; 64 fWeight(weight),; 65 fNEffPoints(0),; 66 fGrad ( std::vector<double> ( func->NPar() ) ),; 67 fExecutionPolicy(executionPolicy); 68 { }; 69 ; 70 /**; 71 Constructor from unbin data set and model function (pdf) managed by the users; 72 */; 73 PoissonLikelihoodFCN (const BinData & data, const IModelFunction & func, int weight = 0, bool extended = true, const ::ROOT::EExecutionPolicy &executionPolicy = ::ROOT::EExecutionPolicy::kSequential ) :; 74 BaseFCN(std::make_shared<BinData>(data), std::shared_ptr<IModelFunction>(dynamic_cast<IModelFunction*>(func.Clone() ) ) ),; 75 fIsExtended(extended),; 76 fWeight(weigh",MatchSource.WIKI,doc/master/PoissonLikelihoodFCN_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/PoissonLikelihoodFCN_8h_source.html
https://root.cern/doc/master/PoissonLikelihoodFCN_8h_source.html:2305,Modifiability,extend,extended,2305,"OT_Fit_FitUtilParallel; 28// #include ""Fit/FitUtilParallel.h""; 29// #endif; 30// #endif; 31 ; 32namespace ROOT {; 33 ; 34 namespace Fit {; 35 ; 36 ; 37//___________________________________________________________________________________; 38/**; 39 class evaluating the log likelihood; 40 for binned Poisson likelihood fits; 41 it is template to distinguish gradient and non-gradient case; 42 ; 43 @ingroup FitMethodFunc; 44*/; 45template<class DerivFunType, class ModelFunType = ROOT::Math::IParamMultiFunction>; 46class PoissonLikelihoodFCN : public BasicFCN<DerivFunType,ModelFunType,BinData> {; 47 ; 48public:; 49 typedef typename ModelFunType::BackendType T;; 50 typedef BasicFCN<DerivFunType,ModelFunType,BinData> BaseFCN;; 51 ; 52 typedef ::ROOT::Math::BasicFitMethodFunction<DerivFunType> BaseObjFunction;; 53 typedef typename BaseObjFunction::BaseFunction BaseFunction;; 54 ; 55 typedef ::ROOT::Math::IParamMultiFunctionTempl<T> IModelFunction;; 56 typedef typename BaseObjFunction::Type_t Type_t;; 57 ; 58 /**; 59 Constructor from unbin data set and model function (pdf); 60 */; 61 PoissonLikelihoodFCN (const std::shared_ptr<BinData> & data, const std::shared_ptr<IModelFunction> & func, int weight = 0, bool extended = true, const ::ROOT::EExecutionPolicy &executionPolicy = ::ROOT::EExecutionPolicy::kSequential ) :; 62 BaseFCN( data, func),; 63 fIsExtended(extended),; 64 fWeight(weight),; 65 fNEffPoints(0),; 66 fGrad ( std::vector<double> ( func->NPar() ) ),; 67 fExecutionPolicy(executionPolicy); 68 { }; 69 ; 70 /**; 71 Constructor from unbin data set and model function (pdf) managed by the users; 72 */; 73 PoissonLikelihoodFCN (const BinData & data, const IModelFunction & func, int weight = 0, bool extended = true, const ::ROOT::EExecutionPolicy &executionPolicy = ::ROOT::EExecutionPolicy::kSequential ) :; 74 BaseFCN(std::make_shared<BinData>(data), std::shared_ptr<IModelFunction>(dynamic_cast<IModelFunction*>(func.Clone() ) ) ),; 75 fIsExtended(extended),; 76 fWeight(weigh",MatchSource.WIKI,doc/master/PoissonLikelihoodFCN_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/PoissonLikelihoodFCN_8h_source.html
https://root.cern/doc/master/PoissonLikelihoodFCN_8h_source.html:2655,Modifiability,extend,extended,2655,"OT_Fit_FitUtilParallel; 28// #include ""Fit/FitUtilParallel.h""; 29// #endif; 30// #endif; 31 ; 32namespace ROOT {; 33 ; 34 namespace Fit {; 35 ; 36 ; 37//___________________________________________________________________________________; 38/**; 39 class evaluating the log likelihood; 40 for binned Poisson likelihood fits; 41 it is template to distinguish gradient and non-gradient case; 42 ; 43 @ingroup FitMethodFunc; 44*/; 45template<class DerivFunType, class ModelFunType = ROOT::Math::IParamMultiFunction>; 46class PoissonLikelihoodFCN : public BasicFCN<DerivFunType,ModelFunType,BinData> {; 47 ; 48public:; 49 typedef typename ModelFunType::BackendType T;; 50 typedef BasicFCN<DerivFunType,ModelFunType,BinData> BaseFCN;; 51 ; 52 typedef ::ROOT::Math::BasicFitMethodFunction<DerivFunType> BaseObjFunction;; 53 typedef typename BaseObjFunction::BaseFunction BaseFunction;; 54 ; 55 typedef ::ROOT::Math::IParamMultiFunctionTempl<T> IModelFunction;; 56 typedef typename BaseObjFunction::Type_t Type_t;; 57 ; 58 /**; 59 Constructor from unbin data set and model function (pdf); 60 */; 61 PoissonLikelihoodFCN (const std::shared_ptr<BinData> & data, const std::shared_ptr<IModelFunction> & func, int weight = 0, bool extended = true, const ::ROOT::EExecutionPolicy &executionPolicy = ::ROOT::EExecutionPolicy::kSequential ) :; 62 BaseFCN( data, func),; 63 fIsExtended(extended),; 64 fWeight(weight),; 65 fNEffPoints(0),; 66 fGrad ( std::vector<double> ( func->NPar() ) ),; 67 fExecutionPolicy(executionPolicy); 68 { }; 69 ; 70 /**; 71 Constructor from unbin data set and model function (pdf) managed by the users; 72 */; 73 PoissonLikelihoodFCN (const BinData & data, const IModelFunction & func, int weight = 0, bool extended = true, const ::ROOT::EExecutionPolicy &executionPolicy = ::ROOT::EExecutionPolicy::kSequential ) :; 74 BaseFCN(std::make_shared<BinData>(data), std::shared_ptr<IModelFunction>(dynamic_cast<IModelFunction*>(func.Clone() ) ) ),; 75 fIsExtended(extended),; 76 fWeight(weigh",MatchSource.WIKI,doc/master/PoissonLikelihoodFCN_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/PoissonLikelihoodFCN_8h_source.html
https://root.cern/doc/master/PoissonLikelihoodFCN_8h_source.html:2907,Modifiability,extend,extended,2907,"_t;; 57 ; 58 /**; 59 Constructor from unbin data set and model function (pdf); 60 */; 61 PoissonLikelihoodFCN (const std::shared_ptr<BinData> & data, const std::shared_ptr<IModelFunction> & func, int weight = 0, bool extended = true, const ::ROOT::EExecutionPolicy &executionPolicy = ::ROOT::EExecutionPolicy::kSequential ) :; 62 BaseFCN( data, func),; 63 fIsExtended(extended),; 64 fWeight(weight),; 65 fNEffPoints(0),; 66 fGrad ( std::vector<double> ( func->NPar() ) ),; 67 fExecutionPolicy(executionPolicy); 68 { }; 69 ; 70 /**; 71 Constructor from unbin data set and model function (pdf) managed by the users; 72 */; 73 PoissonLikelihoodFCN (const BinData & data, const IModelFunction & func, int weight = 0, bool extended = true, const ::ROOT::EExecutionPolicy &executionPolicy = ::ROOT::EExecutionPolicy::kSequential ) :; 74 BaseFCN(std::make_shared<BinData>(data), std::shared_ptr<IModelFunction>(dynamic_cast<IModelFunction*>(func.Clone() ) ) ),; 75 fIsExtended(extended),; 76 fWeight(weight),; 77 fNEffPoints(0),; 78 fGrad ( std::vector<double> ( func.NPar() ) ),; 79 fExecutionPolicy(executionPolicy); 80 { }; 81 ; 82 ; 83 /**; 84 Destructor (no operations); 85 */; 86 virtual ~PoissonLikelihoodFCN () {}; 87 ; 88 /**; 89 Copy constructor; 90 */; 91 PoissonLikelihoodFCN(const PoissonLikelihoodFCN & f) :; 92 BaseFCN(f.DataPtr(), f.ModelFunctionPtr() ),; 93 fIsExtended(f.fIsExtended ),; 94 fWeight( f.fWeight ),; 95 fNEffPoints( f.fNEffPoints ),; 96 fGrad( f.fGrad),; 97 fExecutionPolicy(f.fExecutionPolicy); 98 { }; 99 ; 100 /**; 101 Assignment operator; 102 */; 103 PoissonLikelihoodFCN & operator = (const PoissonLikelihoodFCN & rhs) {; 104 SetData(rhs.DataPtr() );; 105 SetModelFunction(rhs.ModelFunctionPtr() );; 106 fNEffPoints = rhs.fNEffPoints;; 107 fGrad = rhs.fGrad;; 108 fIsExtended = rhs.fIsExtended;; 109 fWeight = rhs.fWeight;; 110 fExecutionPolicy = rhs.fExecutionPolicy;; 111 }; 112 ; 113 ; 114 /// clone the function (need to return Base for Windows); 115 virtual BaseFunc",MatchSource.WIKI,doc/master/PoissonLikelihoodFCN_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/PoissonLikelihoodFCN_8h_source.html
https://root.cern/doc/master/PoissonLikelihoodFCN_8h_source.html:7075,Modifiability,extend,extended,7075,"ighted() const { return (fWeight != 0); }; 164 ; 165 // Use the weights in evaluating the likelihood; 166 void UseSumOfWeights() {; 167 if (fWeight == 0) return; // do nothing if it was not weighted; 168 fWeight = 1;; 169 }; 170 ; 171 // Use sum of the weight squared in evaluating the likelihood; 172 // (this is needed for calculating the errors); 173 void UseSumOfWeightSquare(bool on = true) {; 174 if (fWeight == 0) return; // do nothing if it was not weighted; 175 if (on) fWeight = 2;; 176 else fWeight = 1;; 177 }; 178 ; 179 ; 180protected:; 181 ; 182 ; 183private:; 184 ; 185 /**; 186 Evaluation of the function (required by interface); 187 */; 188 virtual double DoEval (const double * x) const {; 189 this->UpdateNCalls();; 190 return FitUtil::Evaluate<T>::EvalPoissonLogL(BaseFCN::ModelFunction(), BaseFCN::Data(), x, fWeight, fIsExtended,; 191 fNEffPoints, fExecutionPolicy);; 192 }; 193 ; 194 // for derivatives; 195 virtual double DoDerivative(const double * x, unsigned int icoord ) const {; 196 Gradient(x, &fGrad[0]);; 197 return fGrad[icoord];; 198 }; 199 ; 200 ; 201 //data member; 202 ; 203 bool fIsExtended; ///< flag to indicate if is extended (when false is a Multinomial likelihood), default is true; 204 int fWeight; ///< flag to indicate if needs to evaluate using weight or weight squared (default weight = 0); 205 ; 206 mutable unsigned int fNEffPoints; ///< number of effective points used in the fit; 207 ; 208 mutable std::vector<double> fGrad; ///< for derivatives; 209 ; 210 ::ROOT::EExecutionPolicy fExecutionPolicy; ///< Execution policy; 211};; 212 ; 213 // define useful typedef's; 214 typedef PoissonLikelihoodFCN<ROOT::Math::IMultiGenFunction, ROOT::Math::IParamMultiFunction> PoissonLLFunction;; 215 typedef PoissonLikelihoodFCN<ROOT::Math::IMultiGradFunction, ROOT::Math::IParamMultiFunction> PoissonLLGradFunction;; 216 ; 217 ; 218 } // end namespace Fit; 219 ; 220} // end namespace ROOT; 221 ; 222 ; 223#endif /* ROOT_Fit_PoissonLikelihoodFCN */; BasicFCN.",MatchSource.WIKI,doc/master/PoissonLikelihoodFCN_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/PoissonLikelihoodFCN_8h_source.html
https://root.cern/doc/master/PoissonLikelihoodFCN_8h_source.html:10224,Modifiability,extend,extended,10224,"::DataPtrstd::shared_ptr< DataType > DataPtr() constaccess to data pointerDefinition BasicFCN.h:75; ROOT::Fit::BasicFCN::ModelFunctionvirtual const IModelFunction & ModelFunction() constaccess to const reference to the model functionDefinition BasicFCN.h:78; ROOT::Fit::BinDataClass describing the binned data sets : vectors of x coordinates, y values and optionally error on y ...Definition BinData.h:52; ROOT::Fit::PoissonLikelihoodFCNclass evaluating the log likelihood for binned Poisson likelihood fits it is template to distinguish ...Definition PoissonLikelihoodFCN.h:46; ROOT::Fit::PoissonLikelihoodFCN::NFitPointsvirtual unsigned int NFitPoints() constDefinition PoissonLikelihoodFCN.h:118; ROOT::Fit::PoissonLikelihoodFCN::IModelFunction::ROOT::Math::IParamMultiFunctionTempl< T > IModelFunctionDefinition PoissonLikelihoodFCN.h:55; ROOT::Fit::PoissonLikelihoodFCN::PoissonLikelihoodFCNPoissonLikelihoodFCN(const BinData &data, const IModelFunction &func, int weight=0, bool extended=true, const ::ROOT::EExecutionPolicy &executionPolicy=::ROOT::EExecutionPolicy::kSequential)Constructor from unbin data set and model function (pdf) managed by the users.Definition PoissonLikelihoodFCN.h:73; ROOT::Fit::PoissonLikelihoodFCN::DoDerivativevirtual double DoDerivative(const double *x, unsigned int icoord) constDefinition PoissonLikelihoodFCN.h:195; ROOT::Fit::PoissonLikelihoodFCN::BaseObjFunction::ROOT::Math::BasicFitMethodFunction< DerivFunType > BaseObjFunctionDefinition PoissonLikelihoodFCN.h:52; ROOT::Fit::PoissonLikelihoodFCN::PoissonLikelihoodFCNPoissonLikelihoodFCN(const PoissonLikelihoodFCN &f)Copy constructor.Definition PoissonLikelihoodFCN.h:91; ROOT::Fit::PoissonLikelihoodFCN::Clonevirtual BaseFunction * Clone() constclone the function (need to return Base for Windows)Definition PoissonLikelihoodFCN.h:115; ROOT::Fit::PoissonLikelihoodFCN::UseSumOfWeightSquarevoid UseSumOfWeightSquare(bool on=true)Definition PoissonLikelihoodFCN.h:173; ROOT::Fit::PoissonLikelihoodFCN::Is",MatchSource.WIKI,doc/master/PoissonLikelihoodFCN_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/PoissonLikelihoodFCN_8h_source.html
https://root.cern/doc/master/PoissonLikelihoodFCN_8h_source.html:12244,Modifiability,extend,extended,12244,"bool IsWeighted() constDefinition PoissonLikelihoodFCN.h:163; ROOT::Fit::PoissonLikelihoodFCN::~PoissonLikelihoodFCNvirtual ~PoissonLikelihoodFCN()Destructor (no operations)Definition PoissonLikelihoodFCN.h:86; ROOT::Fit::PoissonLikelihoodFCN::DoEvalvirtual double DoEval(const double *x) constEvaluation of the function (required by interface)Definition PoissonLikelihoodFCN.h:188; ROOT::Fit::PoissonLikelihoodFCN::fExecutionPolicy::ROOT::EExecutionPolicy fExecutionPolicyExecution policy.Definition PoissonLikelihoodFCN.h:210; ROOT::Fit::PoissonLikelihoodFCN::BaseFunctionBaseObjFunction::BaseFunction BaseFunctionDefinition PoissonLikelihoodFCN.h:53; ROOT::Fit::PoissonLikelihoodFCN::Gradientvirtual void Gradient(const double *x, double *g) constevaluate gradientDefinition PoissonLikelihoodFCN.h:127; ROOT::Fit::PoissonLikelihoodFCN::Type_tBaseObjFunction::Type_t Type_tDefinition PoissonLikelihoodFCN.h:56; ROOT::Fit::PoissonLikelihoodFCN::fIsExtendedbool fIsExtendedflag to indicate if is extended (when false is a Multinomial likelihood), default is trueDefinition PoissonLikelihoodFCN.h:203; ROOT::Fit::PoissonLikelihoodFCN::operator=PoissonLikelihoodFCN & operator=(const PoissonLikelihoodFCN &rhs)Assignment operator.Definition PoissonLikelihoodFCN.h:103; ROOT::Fit::PoissonLikelihoodFCN::PoissonLikelihoodFCNPoissonLikelihoodFCN(const std::shared_ptr< BinData > &data, const std::shared_ptr< IModelFunction > &func, int weight=0, bool extended=true, const ::ROOT::EExecutionPolicy &executionPolicy=::ROOT::EExecutionPolicy::kSequential)Constructor from unbin data set and model function (pdf)Definition PoissonLikelihoodFCN.h:61; ROOT::Fit::PoissonLikelihoodFCN::fWeightint fWeightflag to indicate if needs to evaluate using weight or weight squared (default weight = 0)Definition PoissonLikelihoodFCN.h:204; ROOT::Fit::PoissonLikelihoodFCN::TModelFunType::BackendType TDefinition PoissonLikelihoodFCN.h:49; ROOT::Fit::PoissonLikelihoodFCN::fNEffPointsunsigned int fNEffPointsnumber of eff",MatchSource.WIKI,doc/master/PoissonLikelihoodFCN_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/PoissonLikelihoodFCN_8h_source.html
https://root.cern/doc/master/PoissonLikelihoodFCN_8h_source.html:12695,Modifiability,extend,extended,12695,"onPolicy fExecutionPolicyExecution policy.Definition PoissonLikelihoodFCN.h:210; ROOT::Fit::PoissonLikelihoodFCN::BaseFunctionBaseObjFunction::BaseFunction BaseFunctionDefinition PoissonLikelihoodFCN.h:53; ROOT::Fit::PoissonLikelihoodFCN::Gradientvirtual void Gradient(const double *x, double *g) constevaluate gradientDefinition PoissonLikelihoodFCN.h:127; ROOT::Fit::PoissonLikelihoodFCN::Type_tBaseObjFunction::Type_t Type_tDefinition PoissonLikelihoodFCN.h:56; ROOT::Fit::PoissonLikelihoodFCN::fIsExtendedbool fIsExtendedflag to indicate if is extended (when false is a Multinomial likelihood), default is trueDefinition PoissonLikelihoodFCN.h:203; ROOT::Fit::PoissonLikelihoodFCN::operator=PoissonLikelihoodFCN & operator=(const PoissonLikelihoodFCN &rhs)Assignment operator.Definition PoissonLikelihoodFCN.h:103; ROOT::Fit::PoissonLikelihoodFCN::PoissonLikelihoodFCNPoissonLikelihoodFCN(const std::shared_ptr< BinData > &data, const std::shared_ptr< IModelFunction > &func, int weight=0, bool extended=true, const ::ROOT::EExecutionPolicy &executionPolicy=::ROOT::EExecutionPolicy::kSequential)Constructor from unbin data set and model function (pdf)Definition PoissonLikelihoodFCN.h:61; ROOT::Fit::PoissonLikelihoodFCN::fWeightint fWeightflag to indicate if needs to evaluate using weight or weight squared (default weight = 0)Definition PoissonLikelihoodFCN.h:204; ROOT::Fit::PoissonLikelihoodFCN::TModelFunType::BackendType TDefinition PoissonLikelihoodFCN.h:49; ROOT::Fit::PoissonLikelihoodFCN::fNEffPointsunsigned int fNEffPointsnumber of effective points used in the fitDefinition PoissonLikelihoodFCN.h:206; ROOT::Fit::PoissonLikelihoodFCN::BaseFCNBasicFCN< DerivFunType, ModelFunType, BinData > BaseFCNDefinition PoissonLikelihoodFCN.h:50; ROOT::Fit::PoissonLikelihoodFCN::UseSumOfWeightsvoid UseSumOfWeights()Definition PoissonLikelihoodFCN.h:166; ROOT::Fit::PoissonLikelihoodFCN::fGradstd::vector< double > fGradfor derivativesDefinition PoissonLikelihoodFCN.h:208; ROOT::Fit::Poisson",MatchSource.WIKI,doc/master/PoissonLikelihoodFCN_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/PoissonLikelihoodFCN_8h_source.html
https://root.cern/doc/master/PoissonLikelihoodFCN_8h_source.html:16699,Modifiability,extend,extended,16699,"ramFunction.h:108; double; xDouble_t x[n]Definition legend1.C:17; HFit::FitTFitResultPtr Fit(FitObject *h1, TF1 *f1, Foption_t &option, const ROOT::Math::MinimizerOptions &moption, const char *goption, ROOT::Fit::DataRange &range)Definition HFitImpl.cxx:133; ROOT::Fit::PoissonLLGradFunctionPoissonLikelihoodFCN< ROOT::Math::IMultiGradFunction, ROOT::Math::IParamMultiFunction > PoissonLLGradFunctionDefinition PoissonLikelihoodFCN.h:215; ROOT::Fit::PoissonLLFunctionPoissonLikelihoodFCN< ROOT::Math::IMultiGenFunction, ROOT::Math::IParamMultiFunction > PoissonLLFunctionDefinition PoissonLikelihoodFCN.h:214; ROOTtbb::task_arena is an alias of tbb::interface7::task_arena, which doesn't allow to forward declare tb...Definition EExecutionPolicy.hxx:4; ROOT::EExecutionPolicyEExecutionPolicyDefinition EExecutionPolicy.hxx:5; ROOT::EExecutionPolicy::kSequential@ kSequential; ROOT::Fit::FitUtil::Evaluate::EvalPoissonBinPdfstatic double EvalPoissonBinPdf(const IModelFunctionTempl< double > &func, const BinData &data, const double *p, unsigned int i, double *g, double *h, bool hasGrad, bool fullHessian)evaluate the pdf (Poisson) contribution to the logl (return actually log of pdf) and its gradientDefinition FitUtil.h:1447; ROOT::Fit::FitUtil::Evaluate::EvalPoissonLogLGradientstatic void EvalPoissonLogLGradient(const IModelFunctionTempl< double > &func, const BinData &data, const double *p, double *g, unsigned int &nPoints, ::ROOT::EExecutionPolicy executionPolicy=::ROOT::EExecutionPolicy::kSequential, unsigned nChunks=0)Definition FitUtil.h:1456; ROOT::Fit::FitUtil::Evaluate::EvalPoissonLogLstatic double EvalPoissonLogL(const IModelFunctionTempl< double > &func, const BinData &data, const double *p, int iWeight, bool extended, unsigned int &nPoints, ::ROOT::EExecutionPolicy executionPolicy, unsigned nChunks=0)Definition FitUtil.h:1420. mathmathcoreincFitPoissonLikelihoodFCN.h. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:40:40 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/PoissonLikelihoodFCN_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/PoissonLikelihoodFCN_8h_source.html
https://root.cern/doc/master/PoissonLikelihoodFCN_8h_source.html:1204,Testability,log,log,1204,"OT_Fit_FitUtilParallel; 28// #include ""Fit/FitUtilParallel.h""; 29// #endif; 30// #endif; 31 ; 32namespace ROOT {; 33 ; 34 namespace Fit {; 35 ; 36 ; 37//___________________________________________________________________________________; 38/**; 39 class evaluating the log likelihood; 40 for binned Poisson likelihood fits; 41 it is template to distinguish gradient and non-gradient case; 42 ; 43 @ingroup FitMethodFunc; 44*/; 45template<class DerivFunType, class ModelFunType = ROOT::Math::IParamMultiFunction>; 46class PoissonLikelihoodFCN : public BasicFCN<DerivFunType,ModelFunType,BinData> {; 47 ; 48public:; 49 typedef typename ModelFunType::BackendType T;; 50 typedef BasicFCN<DerivFunType,ModelFunType,BinData> BaseFCN;; 51 ; 52 typedef ::ROOT::Math::BasicFitMethodFunction<DerivFunType> BaseObjFunction;; 53 typedef typename BaseObjFunction::BaseFunction BaseFunction;; 54 ; 55 typedef ::ROOT::Math::IParamMultiFunctionTempl<T> IModelFunction;; 56 typedef typename BaseObjFunction::Type_t Type_t;; 57 ; 58 /**; 59 Constructor from unbin data set and model function (pdf); 60 */; 61 PoissonLikelihoodFCN (const std::shared_ptr<BinData> & data, const std::shared_ptr<IModelFunction> & func, int weight = 0, bool extended = true, const ::ROOT::EExecutionPolicy &executionPolicy = ::ROOT::EExecutionPolicy::kSequential ) :; 62 BaseFCN( data, func),; 63 fIsExtended(extended),; 64 fWeight(weight),; 65 fNEffPoints(0),; 66 fGrad ( std::vector<double> ( func->NPar() ) ),; 67 fExecutionPolicy(executionPolicy); 68 { }; 69 ; 70 /**; 71 Constructor from unbin data set and model function (pdf) managed by the users; 72 */; 73 PoissonLikelihoodFCN (const BinData & data, const IModelFunction & func, int weight = 0, bool extended = true, const ::ROOT::EExecutionPolicy &executionPolicy = ::ROOT::EExecutionPolicy::kSequential ) :; 74 BaseFCN(std::make_shared<BinData>(data), std::shared_ptr<IModelFunction>(dynamic_cast<IModelFunction*>(func.Clone() ) ) ),; 75 fIsExtended(extended),; 76 fWeight(weigh",MatchSource.WIKI,doc/master/PoissonLikelihoodFCN_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/PoissonLikelihoodFCN_8h_source.html
https://root.cern/doc/master/PoissonLikelihoodFCN_8h_source.html:9697,Testability,log,log,9697,"t std::shared_ptr< DataType > &data)Set the data pointer.Definition BasicFCN.h:98; ROOT::Fit::BasicFCN::ModelFunctionPtrstd::shared_ptr< IModelFunction > ModelFunctionPtr() constaccess to function pointerDefinition BasicFCN.h:81; ROOT::Fit::BasicFCN::SetModelFunctionvoid SetModelFunction(const std::shared_ptr< IModelFunction > &func)Set the function pointer.Definition BasicFCN.h:101; ROOT::Fit::BasicFCN::Datavirtual const DataType & Data() constaccess to const reference to the dataDefinition BasicFCN.h:72; ROOT::Fit::BasicFCN::DataPtrstd::shared_ptr< DataType > DataPtr() constaccess to data pointerDefinition BasicFCN.h:75; ROOT::Fit::BasicFCN::ModelFunctionvirtual const IModelFunction & ModelFunction() constaccess to const reference to the model functionDefinition BasicFCN.h:78; ROOT::Fit::BinDataClass describing the binned data sets : vectors of x coordinates, y values and optionally error on y ...Definition BinData.h:52; ROOT::Fit::PoissonLikelihoodFCNclass evaluating the log likelihood for binned Poisson likelihood fits it is template to distinguish ...Definition PoissonLikelihoodFCN.h:46; ROOT::Fit::PoissonLikelihoodFCN::NFitPointsvirtual unsigned int NFitPoints() constDefinition PoissonLikelihoodFCN.h:118; ROOT::Fit::PoissonLikelihoodFCN::IModelFunction::ROOT::Math::IParamMultiFunctionTempl< T > IModelFunctionDefinition PoissonLikelihoodFCN.h:55; ROOT::Fit::PoissonLikelihoodFCN::PoissonLikelihoodFCNPoissonLikelihoodFCN(const BinData &data, const IModelFunction &func, int weight=0, bool extended=true, const ::ROOT::EExecutionPolicy &executionPolicy=::ROOT::EExecutionPolicy::kSequential)Constructor from unbin data set and model function (pdf) managed by the users.Definition PoissonLikelihoodFCN.h:73; ROOT::Fit::PoissonLikelihoodFCN::DoDerivativevirtual double DoDerivative(const double *x, unsigned int icoord) constDefinition PoissonLikelihoodFCN.h:195; ROOT::Fit::PoissonLikelihoodFCN::BaseObjFunction::ROOT::Math::BasicFitMethodFunction< DerivFunType > BaseObjFunct",MatchSource.WIKI,doc/master/PoissonLikelihoodFCN_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/PoissonLikelihoodFCN_8h_source.html
https://root.cern/doc/master/PoissonLikelihoodFCN_8h_source.html:16118,Testability,log,logl,16118,"ramFunction.h:108; double; xDouble_t x[n]Definition legend1.C:17; HFit::FitTFitResultPtr Fit(FitObject *h1, TF1 *f1, Foption_t &option, const ROOT::Math::MinimizerOptions &moption, const char *goption, ROOT::Fit::DataRange &range)Definition HFitImpl.cxx:133; ROOT::Fit::PoissonLLGradFunctionPoissonLikelihoodFCN< ROOT::Math::IMultiGradFunction, ROOT::Math::IParamMultiFunction > PoissonLLGradFunctionDefinition PoissonLikelihoodFCN.h:215; ROOT::Fit::PoissonLLFunctionPoissonLikelihoodFCN< ROOT::Math::IMultiGenFunction, ROOT::Math::IParamMultiFunction > PoissonLLFunctionDefinition PoissonLikelihoodFCN.h:214; ROOTtbb::task_arena is an alias of tbb::interface7::task_arena, which doesn't allow to forward declare tb...Definition EExecutionPolicy.hxx:4; ROOT::EExecutionPolicyEExecutionPolicyDefinition EExecutionPolicy.hxx:5; ROOT::EExecutionPolicy::kSequential@ kSequential; ROOT::Fit::FitUtil::Evaluate::EvalPoissonBinPdfstatic double EvalPoissonBinPdf(const IModelFunctionTempl< double > &func, const BinData &data, const double *p, unsigned int i, double *g, double *h, bool hasGrad, bool fullHessian)evaluate the pdf (Poisson) contribution to the logl (return actually log of pdf) and its gradientDefinition FitUtil.h:1447; ROOT::Fit::FitUtil::Evaluate::EvalPoissonLogLGradientstatic void EvalPoissonLogLGradient(const IModelFunctionTempl< double > &func, const BinData &data, const double *p, double *g, unsigned int &nPoints, ::ROOT::EExecutionPolicy executionPolicy=::ROOT::EExecutionPolicy::kSequential, unsigned nChunks=0)Definition FitUtil.h:1456; ROOT::Fit::FitUtil::Evaluate::EvalPoissonLogLstatic double EvalPoissonLogL(const IModelFunctionTempl< double > &func, const BinData &data, const double *p, int iWeight, bool extended, unsigned int &nPoints, ::ROOT::EExecutionPolicy executionPolicy, unsigned nChunks=0)Definition FitUtil.h:1420. mathmathcoreincFitPoissonLikelihoodFCN.h. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:40:40 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/PoissonLikelihoodFCN_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/PoissonLikelihoodFCN_8h_source.html
https://root.cern/doc/master/PoissonLikelihoodFCN_8h_source.html:16140,Testability,log,log,16140,"ramFunction.h:108; double; xDouble_t x[n]Definition legend1.C:17; HFit::FitTFitResultPtr Fit(FitObject *h1, TF1 *f1, Foption_t &option, const ROOT::Math::MinimizerOptions &moption, const char *goption, ROOT::Fit::DataRange &range)Definition HFitImpl.cxx:133; ROOT::Fit::PoissonLLGradFunctionPoissonLikelihoodFCN< ROOT::Math::IMultiGradFunction, ROOT::Math::IParamMultiFunction > PoissonLLGradFunctionDefinition PoissonLikelihoodFCN.h:215; ROOT::Fit::PoissonLLFunctionPoissonLikelihoodFCN< ROOT::Math::IMultiGenFunction, ROOT::Math::IParamMultiFunction > PoissonLLFunctionDefinition PoissonLikelihoodFCN.h:214; ROOTtbb::task_arena is an alias of tbb::interface7::task_arena, which doesn't allow to forward declare tb...Definition EExecutionPolicy.hxx:4; ROOT::EExecutionPolicyEExecutionPolicyDefinition EExecutionPolicy.hxx:5; ROOT::EExecutionPolicy::kSequential@ kSequential; ROOT::Fit::FitUtil::Evaluate::EvalPoissonBinPdfstatic double EvalPoissonBinPdf(const IModelFunctionTempl< double > &func, const BinData &data, const double *p, unsigned int i, double *g, double *h, bool hasGrad, bool fullHessian)evaluate the pdf (Poisson) contribution to the logl (return actually log of pdf) and its gradientDefinition FitUtil.h:1447; ROOT::Fit::FitUtil::Evaluate::EvalPoissonLogLGradientstatic void EvalPoissonLogLGradient(const IModelFunctionTempl< double > &func, const BinData &data, const double *p, double *g, unsigned int &nPoints, ::ROOT::EExecutionPolicy executionPolicy=::ROOT::EExecutionPolicy::kSequential, unsigned nChunks=0)Definition FitUtil.h:1456; ROOT::Fit::FitUtil::Evaluate::EvalPoissonLogLstatic double EvalPoissonLogL(const IModelFunctionTempl< double > &func, const BinData &data, const double *p, int iWeight, bool extended, unsigned int &nPoints, ::ROOT::EExecutionPolicy executionPolicy, unsigned nChunks=0)Definition FitUtil.h:1420. mathmathcoreincFitPoissonLikelihoodFCN.h. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:40:40 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/PoissonLikelihoodFCN_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/PoissonLikelihoodFCN_8h_source.html
https://root.cern/doc/master/polytest1_8C.html:286,Energy Efficiency,reduce,reduces,286,". ROOT: tutorials/graphics/polytest1.C File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. polytest1.C File ReferenceTutorials  Graphics tutorials. Detailed Description; This macro is testing the ""compacting"" algorithm in TPadPainter. ; It reduces the number of polygon's vertices using actual pixel coordinates. It's not really useful, but just to test that the resulting polygon is still reasonable. Initial number of points is 1000000, after ""compression"" it's 523904 (with default canvas size, before you tried to resize it) - so almost half of vertices were removed but you can still see the reasonable shape. If you resize a canvas to a smaller size, the number of vertices after compression can be something like 5000 and even less. It's easy to 'fool' this algorithm though in this particular case (ellipse is a kind of fringe case, you can easily have a sequence of almost unique vertices (at a pixel level).; ; //Includes for ACLiC.; #include <cassert>; #include <vector>; ; #include ""TRandom.h""; #include ""TCanvas.h""; #include ""TError.h""; #include ""Rtypes.h""; #include ""TNamed.h""; #include ""TMath.h""; ; class PolyTest1 : public TNamed, public TAttLine, public TAttFill {; public:; PolyTest1(unsigned nVertices);; ; void Paint(const Option_t *notUsed) override;; void Reset(unsigned nVertices);; ; private:; enum {; kNPointsDefault = 10000//minimal number of points.; };; ; std::vector<Double_t> fXs;; std::vector<Double_t> fYs;; };; ; //_____________________________________________________________; PolyTest1::PolyTest1(unsigned nVertices); : TNamed(""polygon_compression_test1"", ""polygon_compression_test1""); {; Reset(nVertices);; }; ; //_____________________________________________________________; void PolyTest1::Reset(unsigned nVertices); {; //Some canvas must already exist by this point.; assert(gPad != nullptr && ""Reset, gPad is null"");; //We need a gRandom to exist.; assert(gRandom != nullptr && ""Reset, gRandom is null"");; ; if (nV",MatchSource.WIKI,doc/master/polytest1_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/polytest1_8C.html
https://root.cern/doc/master/polytest1_8C.html:230,Testability,test,testing,230,". ROOT: tutorials/graphics/polytest1.C File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. polytest1.C File ReferenceTutorials  Graphics tutorials. Detailed Description; This macro is testing the ""compacting"" algorithm in TPadPainter. ; It reduces the number of polygon's vertices using actual pixel coordinates. It's not really useful, but just to test that the resulting polygon is still reasonable. Initial number of points is 1000000, after ""compression"" it's 523904 (with default canvas size, before you tried to resize it) - so almost half of vertices were removed but you can still see the reasonable shape. If you resize a canvas to a smaller size, the number of vertices after compression can be something like 5000 and even less. It's easy to 'fool' this algorithm though in this particular case (ellipse is a kind of fringe case, you can easily have a sequence of almost unique vertices (at a pixel level).; ; //Includes for ACLiC.; #include <cassert>; #include <vector>; ; #include ""TRandom.h""; #include ""TCanvas.h""; #include ""TError.h""; #include ""Rtypes.h""; #include ""TNamed.h""; #include ""TMath.h""; ; class PolyTest1 : public TNamed, public TAttLine, public TAttFill {; public:; PolyTest1(unsigned nVertices);; ; void Paint(const Option_t *notUsed) override;; void Reset(unsigned nVertices);; ; private:; enum {; kNPointsDefault = 10000//minimal number of points.; };; ; std::vector<Double_t> fXs;; std::vector<Double_t> fYs;; };; ; //_____________________________________________________________; PolyTest1::PolyTest1(unsigned nVertices); : TNamed(""polygon_compression_test1"", ""polygon_compression_test1""); {; Reset(nVertices);; }; ; //_____________________________________________________________; void PolyTest1::Reset(unsigned nVertices); {; //Some canvas must already exist by this point.; assert(gPad != nullptr && ""Reset, gPad is null"");; //We need a gRandom to exist.; assert(gRandom != nullptr && ""Reset, gRandom is null"");; ; if (nV",MatchSource.WIKI,doc/master/polytest1_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/polytest1_8C.html
https://root.cern/doc/master/polytest1_8C.html:395,Testability,test,test,395,". ROOT: tutorials/graphics/polytest1.C File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. polytest1.C File ReferenceTutorials  Graphics tutorials. Detailed Description; This macro is testing the ""compacting"" algorithm in TPadPainter. ; It reduces the number of polygon's vertices using actual pixel coordinates. It's not really useful, but just to test that the resulting polygon is still reasonable. Initial number of points is 1000000, after ""compression"" it's 523904 (with default canvas size, before you tried to resize it) - so almost half of vertices were removed but you can still see the reasonable shape. If you resize a canvas to a smaller size, the number of vertices after compression can be something like 5000 and even less. It's easy to 'fool' this algorithm though in this particular case (ellipse is a kind of fringe case, you can easily have a sequence of almost unique vertices (at a pixel level).; ; //Includes for ACLiC.; #include <cassert>; #include <vector>; ; #include ""TRandom.h""; #include ""TCanvas.h""; #include ""TError.h""; #include ""Rtypes.h""; #include ""TNamed.h""; #include ""TMath.h""; ; class PolyTest1 : public TNamed, public TAttLine, public TAttFill {; public:; PolyTest1(unsigned nVertices);; ; void Paint(const Option_t *notUsed) override;; void Reset(unsigned nVertices);; ; private:; enum {; kNPointsDefault = 10000//minimal number of points.; };; ; std::vector<Double_t> fXs;; std::vector<Double_t> fYs;; };; ; //_____________________________________________________________; PolyTest1::PolyTest1(unsigned nVertices); : TNamed(""polygon_compression_test1"", ""polygon_compression_test1""); {; Reset(nVertices);; }; ; //_____________________________________________________________; void PolyTest1::Reset(unsigned nVertices); {; //Some canvas must already exist by this point.; assert(gPad != nullptr && ""Reset, gPad is null"");; //We need a gRandom to exist.; assert(gRandom != nullptr && ""Reset, gRandom is null"");; ; if (nV",MatchSource.WIKI,doc/master/polytest1_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/polytest1_8C.html
https://root.cern/doc/master/polytest1_8C.html:1854,Testability,assert,assert,1854,"n easily have a sequence of almost unique vertices (at a pixel level).; ; //Includes for ACLiC.; #include <cassert>; #include <vector>; ; #include ""TRandom.h""; #include ""TCanvas.h""; #include ""TError.h""; #include ""Rtypes.h""; #include ""TNamed.h""; #include ""TMath.h""; ; class PolyTest1 : public TNamed, public TAttLine, public TAttFill {; public:; PolyTest1(unsigned nVertices);; ; void Paint(const Option_t *notUsed) override;; void Reset(unsigned nVertices);; ; private:; enum {; kNPointsDefault = 10000//minimal number of points.; };; ; std::vector<Double_t> fXs;; std::vector<Double_t> fYs;; };; ; //_____________________________________________________________; PolyTest1::PolyTest1(unsigned nVertices); : TNamed(""polygon_compression_test1"", ""polygon_compression_test1""); {; Reset(nVertices);; }; ; //_____________________________________________________________; void PolyTest1::Reset(unsigned nVertices); {; //Some canvas must already exist by this point.; assert(gPad != nullptr && ""Reset, gPad is null"");; //We need a gRandom to exist.; assert(gRandom != nullptr && ""Reset, gRandom is null"");; ; if (nVertices < kNPointsDefault) {; Warning(""Reset"", ""resetting nVertices parameter to %u"", unsigned(kNPointsDefault));; nVertices = kNPointsDefault;; }; ; fXs.resize(nVertices);; fYs.resize(nVertices);; ; Double_t xMin = 0., xMax = 0., yMin = 0., yMax = 0.;; gPad->GetRange(xMin, yMin, xMax, yMax);; assert(xMax - xMin > 0 && yMax - yMin > 0 && ""Reset, invalid canvas' ranges"");; ; const Double_t xCentre = xMin + 0.5 * (xMax - xMin);; const Double_t yCentre = yMin + 0.5 * (yMax - yMin);; ; const Double_t r = TMath::Min(xMax - xMin, yMax - yMin) * 0.8 / 2;; const Double_t angle = TMath::TwoPi() / (nVertices - 1);; ; for (unsigned i = 0; i < nVertices - 1; ++i) {; const Double_t currR = r + gRandom->Rndm() * r * 0.01;; fXs[i] = xCentre + currR * TMath::Cos(angle * i);; fYs[i] = yCentre + currR * TMath::Sin(angle * i);; }; ; fXs[nVertices - 1] = fXs[0];; fYs[nVertices - 1] = fYs[0];; }; ; /",MatchSource.WIKI,doc/master/polytest1_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/polytest1_8C.html
https://root.cern/doc/master/polytest1_8C.html:1936,Testability,assert,assert,1936,"ndom.h""; #include ""TCanvas.h""; #include ""TError.h""; #include ""Rtypes.h""; #include ""TNamed.h""; #include ""TMath.h""; ; class PolyTest1 : public TNamed, public TAttLine, public TAttFill {; public:; PolyTest1(unsigned nVertices);; ; void Paint(const Option_t *notUsed) override;; void Reset(unsigned nVertices);; ; private:; enum {; kNPointsDefault = 10000//minimal number of points.; };; ; std::vector<Double_t> fXs;; std::vector<Double_t> fYs;; };; ; //_____________________________________________________________; PolyTest1::PolyTest1(unsigned nVertices); : TNamed(""polygon_compression_test1"", ""polygon_compression_test1""); {; Reset(nVertices);; }; ; //_____________________________________________________________; void PolyTest1::Reset(unsigned nVertices); {; //Some canvas must already exist by this point.; assert(gPad != nullptr && ""Reset, gPad is null"");; //We need a gRandom to exist.; assert(gRandom != nullptr && ""Reset, gRandom is null"");; ; if (nVertices < kNPointsDefault) {; Warning(""Reset"", ""resetting nVertices parameter to %u"", unsigned(kNPointsDefault));; nVertices = kNPointsDefault;; }; ; fXs.resize(nVertices);; fYs.resize(nVertices);; ; Double_t xMin = 0., xMax = 0., yMin = 0., yMax = 0.;; gPad->GetRange(xMin, yMin, xMax, yMax);; assert(xMax - xMin > 0 && yMax - yMin > 0 && ""Reset, invalid canvas' ranges"");; ; const Double_t xCentre = xMin + 0.5 * (xMax - xMin);; const Double_t yCentre = yMin + 0.5 * (yMax - yMin);; ; const Double_t r = TMath::Min(xMax - xMin, yMax - yMin) * 0.8 / 2;; const Double_t angle = TMath::TwoPi() / (nVertices - 1);; ; for (unsigned i = 0; i < nVertices - 1; ++i) {; const Double_t currR = r + gRandom->Rndm() * r * 0.01;; fXs[i] = xCentre + currR * TMath::Cos(angle * i);; fYs[i] = yCentre + currR * TMath::Sin(angle * i);; }; ; fXs[nVertices - 1] = fXs[0];; fYs[nVertices - 1] = fYs[0];; }; ; //_____________________________________________________________; void PolyTest1::Paint(const Option_t * /*notUsed*/); {; assert(gPad != nullptr && ""Paint",MatchSource.WIKI,doc/master/polytest1_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/polytest1_8C.html
https://root.cern/doc/master/polytest1_8C.html:2296,Testability,assert,assert,2296,"signed nVertices);; ; private:; enum {; kNPointsDefault = 10000//minimal number of points.; };; ; std::vector<Double_t> fXs;; std::vector<Double_t> fYs;; };; ; //_____________________________________________________________; PolyTest1::PolyTest1(unsigned nVertices); : TNamed(""polygon_compression_test1"", ""polygon_compression_test1""); {; Reset(nVertices);; }; ; //_____________________________________________________________; void PolyTest1::Reset(unsigned nVertices); {; //Some canvas must already exist by this point.; assert(gPad != nullptr && ""Reset, gPad is null"");; //We need a gRandom to exist.; assert(gRandom != nullptr && ""Reset, gRandom is null"");; ; if (nVertices < kNPointsDefault) {; Warning(""Reset"", ""resetting nVertices parameter to %u"", unsigned(kNPointsDefault));; nVertices = kNPointsDefault;; }; ; fXs.resize(nVertices);; fYs.resize(nVertices);; ; Double_t xMin = 0., xMax = 0., yMin = 0., yMax = 0.;; gPad->GetRange(xMin, yMin, xMax, yMax);; assert(xMax - xMin > 0 && yMax - yMin > 0 && ""Reset, invalid canvas' ranges"");; ; const Double_t xCentre = xMin + 0.5 * (xMax - xMin);; const Double_t yCentre = yMin + 0.5 * (yMax - yMin);; ; const Double_t r = TMath::Min(xMax - xMin, yMax - yMin) * 0.8 / 2;; const Double_t angle = TMath::TwoPi() / (nVertices - 1);; ; for (unsigned i = 0; i < nVertices - 1; ++i) {; const Double_t currR = r + gRandom->Rndm() * r * 0.01;; fXs[i] = xCentre + currR * TMath::Cos(angle * i);; fYs[i] = yCentre + currR * TMath::Sin(angle * i);; }; ; fXs[nVertices - 1] = fXs[0];; fYs[nVertices - 1] = fYs[0];; }; ; //_____________________________________________________________; void PolyTest1::Paint(const Option_t * /*notUsed*/); {; assert(gPad != nullptr && ""Paint, gPad is null"");; ; TAttFill::Modify();; gPad->PaintFillArea((Int_t)fXs.size(), &fXs[0], &fYs[0]);; ; TAttLine::Modify();; gPad->PaintPolyLine((Int_t)fXs.size(), &fXs[0], &fYs[0]);; }; ; void polytest1(); {; TCanvas * const cnv = new TCanvas;; cnv->cd();; ; PolyTest1 * polygon = new Po",MatchSource.WIKI,doc/master/polytest1_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/polytest1_8C.html
https://root.cern/doc/master/polytest1_8C.html:3013,Testability,assert,assert,3013," gRandom to exist.; assert(gRandom != nullptr && ""Reset, gRandom is null"");; ; if (nVertices < kNPointsDefault) {; Warning(""Reset"", ""resetting nVertices parameter to %u"", unsigned(kNPointsDefault));; nVertices = kNPointsDefault;; }; ; fXs.resize(nVertices);; fYs.resize(nVertices);; ; Double_t xMin = 0., xMax = 0., yMin = 0., yMax = 0.;; gPad->GetRange(xMin, yMin, xMax, yMax);; assert(xMax - xMin > 0 && yMax - yMin > 0 && ""Reset, invalid canvas' ranges"");; ; const Double_t xCentre = xMin + 0.5 * (xMax - xMin);; const Double_t yCentre = yMin + 0.5 * (yMax - yMin);; ; const Double_t r = TMath::Min(xMax - xMin, yMax - yMin) * 0.8 / 2;; const Double_t angle = TMath::TwoPi() / (nVertices - 1);; ; for (unsigned i = 0; i < nVertices - 1; ++i) {; const Double_t currR = r + gRandom->Rndm() * r * 0.01;; fXs[i] = xCentre + currR * TMath::Cos(angle * i);; fYs[i] = yCentre + currR * TMath::Sin(angle * i);; }; ; fXs[nVertices - 1] = fXs[0];; fYs[nVertices - 1] = fYs[0];; }; ; //_____________________________________________________________; void PolyTest1::Paint(const Option_t * /*notUsed*/); {; assert(gPad != nullptr && ""Paint, gPad is null"");; ; TAttFill::Modify();; gPad->PaintFillArea((Int_t)fXs.size(), &fXs[0], &fYs[0]);; ; TAttLine::Modify();; gPad->PaintPolyLine((Int_t)fXs.size(), &fXs[0], &fYs[0]);; }; ; void polytest1(); {; TCanvas * const cnv = new TCanvas;; cnv->cd();; ; PolyTest1 * polygon = new PolyTest1(1000000);; polygon->SetLineColor(kBlue);; polygon->SetFillColor(kRed);; polygon->SetLineWidth(1);; polygon->Draw();//Attach a polygon to a canvas.; }; Int_tint Int_tDefinition RtypesCore.h:45; Double_tdouble Double_tDefinition RtypesCore.h:59; Option_tconst char Option_tDefinition RtypesCore.h:66; Rtypes.h; kRed@ kRedDefinition Rtypes.h:66; kBlue@ kBlueDefinition Rtypes.h:66; TCanvas.h; TError.h; Warningvoid Warning(const char *location, const char *msgfmt,...)Use this function in warning situations.Definition TError.cxx:229; rOption_t Option_t TPoint TPoint const char G",MatchSource.WIKI,doc/master/polytest1_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/polytest1_8C.html
https://root.cern/doc/master/polytest2_8C.html:288,Energy Efficiency,reduce,reduces,288,". ROOT: tutorials/graphics/polytest2.C File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. polytest2.C File ReferenceTutorials  Graphics tutorials. Detailed Description; ; This macro is testing the ""compacting"" algorithm in TPadPainter. ; It reduces the number of polygon's vertices using actual pixel coordinates. This macro is testing new ""compacting"" algorithm in TPadPainter (it reduces the number of polygon's vertices using actual pixel coordinates). In principle, this test case is what our histograms (fringe cases) are: ""saw-like"" polygon (bins == teeth).; ; //Includes for ACLiC.; #include <cassert>; #include <vector>; ; #include ""TRandom.h""; #include ""TCanvas.h""; #include ""Rtypes.h""; #include ""TNamed.h""; ; class PolyTest2 : public TNamed, public TAttLine, public TAttFill {; public:; PolyTest2();; ; void Paint(const Option_t *notUsed) override;; ; private:; enum TestSize {; kNSawPoints = 10000; };; ; //Part 1.; std::vector<Double_t> fXs1;; std::vector<Double_t> fYs1;; //Part 2.; ; std::vector<Double_t> fXs2;; std::vector<Double_t> fYs2;; };; ; //_____________________________________________________________; PolyTest2::PolyTest2(); : TNamed(""polygon_compression_test2"", ""polygon_compression_test2""); {; //Polygon 1, n of points is 10003, after 'compression' : 1897; //Polygon 2, n of points is 10003, after 'compression' : 2093; ; //Some canvas must already exist by this point.; assert(gPad != nullptr && ""PolyTest2, gPad is null"");; //We need a gRandom to exist.; assert(gRandom != nullptr && ""PolyTest2, gRandom is null"");; ; Double_t xMin = 0., xMax = 0., yMin = 0., yMax = 0.;; gPad->GetRange(xMin, yMin, xMax, yMax);; assert(xMax - xMin > 0 && yMax - yMin > 0 && ""PolyTest2, invalid canvas' ranges"");; ; ; // .(0/the last)--------.(1); // | /; // | \; // | /; // .(kNSawPoints + 1)--.(kNSawPoints); ; const unsigned nVertices = 3 + kNSawPoints;; ; {; //Polygon 1, ""vertical saw"":; fXs1.resize(nVertices);; fYs1.resize(nVertices);",MatchSource.WIKI,doc/master/polytest2_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/polytest2_8C.html
https://root.cern/doc/master/polytest2_8C.html:429,Energy Efficiency,reduce,reduces,429,". ROOT: tutorials/graphics/polytest2.C File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. polytest2.C File ReferenceTutorials  Graphics tutorials. Detailed Description; ; This macro is testing the ""compacting"" algorithm in TPadPainter. ; It reduces the number of polygon's vertices using actual pixel coordinates. This macro is testing new ""compacting"" algorithm in TPadPainter (it reduces the number of polygon's vertices using actual pixel coordinates). In principle, this test case is what our histograms (fringe cases) are: ""saw-like"" polygon (bins == teeth).; ; //Includes for ACLiC.; #include <cassert>; #include <vector>; ; #include ""TRandom.h""; #include ""TCanvas.h""; #include ""Rtypes.h""; #include ""TNamed.h""; ; class PolyTest2 : public TNamed, public TAttLine, public TAttFill {; public:; PolyTest2();; ; void Paint(const Option_t *notUsed) override;; ; private:; enum TestSize {; kNSawPoints = 10000; };; ; //Part 1.; std::vector<Double_t> fXs1;; std::vector<Double_t> fYs1;; //Part 2.; ; std::vector<Double_t> fXs2;; std::vector<Double_t> fYs2;; };; ; //_____________________________________________________________; PolyTest2::PolyTest2(); : TNamed(""polygon_compression_test2"", ""polygon_compression_test2""); {; //Polygon 1, n of points is 10003, after 'compression' : 1897; //Polygon 2, n of points is 10003, after 'compression' : 2093; ; //Some canvas must already exist by this point.; assert(gPad != nullptr && ""PolyTest2, gPad is null"");; //We need a gRandom to exist.; assert(gRandom != nullptr && ""PolyTest2, gRandom is null"");; ; Double_t xMin = 0., xMax = 0., yMin = 0., yMax = 0.;; gPad->GetRange(xMin, yMin, xMax, yMax);; assert(xMax - xMin > 0 && yMax - yMin > 0 && ""PolyTest2, invalid canvas' ranges"");; ; ; // .(0/the last)--------.(1); // | /; // | \; // | /; // .(kNSawPoints + 1)--.(kNSawPoints); ; const unsigned nVertices = 3 + kNSawPoints;; ; {; //Polygon 1, ""vertical saw"":; fXs1.resize(nVertices);; fYs1.resize(nVertices);",MatchSource.WIKI,doc/master/polytest2_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/polytest2_8C.html
https://root.cern/doc/master/polytest2_8C.html:232,Testability,test,testing,232,". ROOT: tutorials/graphics/polytest2.C File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. polytest2.C File ReferenceTutorials  Graphics tutorials. Detailed Description; ; This macro is testing the ""compacting"" algorithm in TPadPainter. ; It reduces the number of polygon's vertices using actual pixel coordinates. This macro is testing new ""compacting"" algorithm in TPadPainter (it reduces the number of polygon's vertices using actual pixel coordinates). In principle, this test case is what our histograms (fringe cases) are: ""saw-like"" polygon (bins == teeth).; ; //Includes for ACLiC.; #include <cassert>; #include <vector>; ; #include ""TRandom.h""; #include ""TCanvas.h""; #include ""Rtypes.h""; #include ""TNamed.h""; ; class PolyTest2 : public TNamed, public TAttLine, public TAttFill {; public:; PolyTest2();; ; void Paint(const Option_t *notUsed) override;; ; private:; enum TestSize {; kNSawPoints = 10000; };; ; //Part 1.; std::vector<Double_t> fXs1;; std::vector<Double_t> fYs1;; //Part 2.; ; std::vector<Double_t> fXs2;; std::vector<Double_t> fYs2;; };; ; //_____________________________________________________________; PolyTest2::PolyTest2(); : TNamed(""polygon_compression_test2"", ""polygon_compression_test2""); {; //Polygon 1, n of points is 10003, after 'compression' : 1897; //Polygon 2, n of points is 10003, after 'compression' : 2093; ; //Some canvas must already exist by this point.; assert(gPad != nullptr && ""PolyTest2, gPad is null"");; //We need a gRandom to exist.; assert(gRandom != nullptr && ""PolyTest2, gRandom is null"");; ; Double_t xMin = 0., xMax = 0., yMin = 0., yMax = 0.;; gPad->GetRange(xMin, yMin, xMax, yMax);; assert(xMax - xMin > 0 && yMax - yMin > 0 && ""PolyTest2, invalid canvas' ranges"");; ; ; // .(0/the last)--------.(1); // | /; // | \; // | /; // .(kNSawPoints + 1)--.(kNSawPoints); ; const unsigned nVertices = 3 + kNSawPoints;; ; {; //Polygon 1, ""vertical saw"":; fXs1.resize(nVertices);; fYs1.resize(nVertices);",MatchSource.WIKI,doc/master/polytest2_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/polytest2_8C.html
https://root.cern/doc/master/polytest2_8C.html:375,Testability,test,testing,375,". ROOT: tutorials/graphics/polytest2.C File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. polytest2.C File ReferenceTutorials  Graphics tutorials. Detailed Description; ; This macro is testing the ""compacting"" algorithm in TPadPainter. ; It reduces the number of polygon's vertices using actual pixel coordinates. This macro is testing new ""compacting"" algorithm in TPadPainter (it reduces the number of polygon's vertices using actual pixel coordinates). In principle, this test case is what our histograms (fringe cases) are: ""saw-like"" polygon (bins == teeth).; ; //Includes for ACLiC.; #include <cassert>; #include <vector>; ; #include ""TRandom.h""; #include ""TCanvas.h""; #include ""Rtypes.h""; #include ""TNamed.h""; ; class PolyTest2 : public TNamed, public TAttLine, public TAttFill {; public:; PolyTest2();; ; void Paint(const Option_t *notUsed) override;; ; private:; enum TestSize {; kNSawPoints = 10000; };; ; //Part 1.; std::vector<Double_t> fXs1;; std::vector<Double_t> fYs1;; //Part 2.; ; std::vector<Double_t> fXs2;; std::vector<Double_t> fYs2;; };; ; //_____________________________________________________________; PolyTest2::PolyTest2(); : TNamed(""polygon_compression_test2"", ""polygon_compression_test2""); {; //Polygon 1, n of points is 10003, after 'compression' : 1897; //Polygon 2, n of points is 10003, after 'compression' : 2093; ; //Some canvas must already exist by this point.; assert(gPad != nullptr && ""PolyTest2, gPad is null"");; //We need a gRandom to exist.; assert(gRandom != nullptr && ""PolyTest2, gRandom is null"");; ; Double_t xMin = 0., xMax = 0., yMin = 0., yMax = 0.;; gPad->GetRange(xMin, yMin, xMax, yMax);; assert(xMax - xMin > 0 && yMax - yMin > 0 && ""PolyTest2, invalid canvas' ranges"");; ; ; // .(0/the last)--------.(1); // | /; // | \; // | /; // .(kNSawPoints + 1)--.(kNSawPoints); ; const unsigned nVertices = 3 + kNSawPoints;; ; {; //Polygon 1, ""vertical saw"":; fXs1.resize(nVertices);; fYs1.resize(nVertices);",MatchSource.WIKI,doc/master/polytest2_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/polytest2_8C.html
https://root.cern/doc/master/polytest2_8C.html:522,Testability,test,test,522,". ROOT: tutorials/graphics/polytest2.C File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. polytest2.C File ReferenceTutorials  Graphics tutorials. Detailed Description; ; This macro is testing the ""compacting"" algorithm in TPadPainter. ; It reduces the number of polygon's vertices using actual pixel coordinates. This macro is testing new ""compacting"" algorithm in TPadPainter (it reduces the number of polygon's vertices using actual pixel coordinates). In principle, this test case is what our histograms (fringe cases) are: ""saw-like"" polygon (bins == teeth).; ; //Includes for ACLiC.; #include <cassert>; #include <vector>; ; #include ""TRandom.h""; #include ""TCanvas.h""; #include ""Rtypes.h""; #include ""TNamed.h""; ; class PolyTest2 : public TNamed, public TAttLine, public TAttFill {; public:; PolyTest2();; ; void Paint(const Option_t *notUsed) override;; ; private:; enum TestSize {; kNSawPoints = 10000; };; ; //Part 1.; std::vector<Double_t> fXs1;; std::vector<Double_t> fYs1;; //Part 2.; ; std::vector<Double_t> fXs2;; std::vector<Double_t> fYs2;; };; ; //_____________________________________________________________; PolyTest2::PolyTest2(); : TNamed(""polygon_compression_test2"", ""polygon_compression_test2""); {; //Polygon 1, n of points is 10003, after 'compression' : 1897; //Polygon 2, n of points is 10003, after 'compression' : 2093; ; //Some canvas must already exist by this point.; assert(gPad != nullptr && ""PolyTest2, gPad is null"");; //We need a gRandom to exist.; assert(gRandom != nullptr && ""PolyTest2, gRandom is null"");; ; Double_t xMin = 0., xMax = 0., yMin = 0., yMax = 0.;; gPad->GetRange(xMin, yMin, xMax, yMax);; assert(xMax - xMin > 0 && yMax - yMin > 0 && ""PolyTest2, invalid canvas' ranges"");; ; ; // .(0/the last)--------.(1); // | /; // | \; // | /; // .(kNSawPoints + 1)--.(kNSawPoints); ; const unsigned nVertices = 3 + kNSawPoints;; ; {; //Polygon 1, ""vertical saw"":; fXs1.resize(nVertices);; fYs1.resize(nVertices);",MatchSource.WIKI,doc/master/polytest2_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/polytest2_8C.html
https://root.cern/doc/master/polytest2_8C.html:1446,Testability,assert,assert,1446,"l coordinates). In principle, this test case is what our histograms (fringe cases) are: ""saw-like"" polygon (bins == teeth).; ; //Includes for ACLiC.; #include <cassert>; #include <vector>; ; #include ""TRandom.h""; #include ""TCanvas.h""; #include ""Rtypes.h""; #include ""TNamed.h""; ; class PolyTest2 : public TNamed, public TAttLine, public TAttFill {; public:; PolyTest2();; ; void Paint(const Option_t *notUsed) override;; ; private:; enum TestSize {; kNSawPoints = 10000; };; ; //Part 1.; std::vector<Double_t> fXs1;; std::vector<Double_t> fYs1;; //Part 2.; ; std::vector<Double_t> fXs2;; std::vector<Double_t> fYs2;; };; ; //_____________________________________________________________; PolyTest2::PolyTest2(); : TNamed(""polygon_compression_test2"", ""polygon_compression_test2""); {; //Polygon 1, n of points is 10003, after 'compression' : 1897; //Polygon 2, n of points is 10003, after 'compression' : 2093; ; //Some canvas must already exist by this point.; assert(gPad != nullptr && ""PolyTest2, gPad is null"");; //We need a gRandom to exist.; assert(gRandom != nullptr && ""PolyTest2, gRandom is null"");; ; Double_t xMin = 0., xMax = 0., yMin = 0., yMax = 0.;; gPad->GetRange(xMin, yMin, xMax, yMax);; assert(xMax - xMin > 0 && yMax - yMin > 0 && ""PolyTest2, invalid canvas' ranges"");; ; ; // .(0/the last)--------.(1); // | /; // | \; // | /; // .(kNSawPoints + 1)--.(kNSawPoints); ; const unsigned nVertices = 3 + kNSawPoints;; ; {; //Polygon 1, ""vertical saw"":; fXs1.resize(nVertices);; fYs1.resize(nVertices);; ; fXs1[0] = 0.;; fYs1[0] = 0.;; ; const Double_t w1 = 0.2 * (xMax - xMin);; const Double_t saw1ToothSize = 0.1 * w1;; const Double_t yStep = (yMax - yMin) / (kNSawPoints - 1);; ; for (unsigned i = 1; i <= kNSawPoints; ++i) {; fXs1[i] = w1 + gRandom->Rndm() * saw1ToothSize;; fYs1[i] = yMin + yStep * (i - 1);; }; ; fXs1[nVertices - 2] = 0.;; fYs1[nVertices - 2] = yMax;; //Let's close it.; fXs1[nVertices - 1] = fXs1[0];; fYs1[nVertices - 1] = fYs1[0];; ; }; ; //Polygon 2, ""horizonta",MatchSource.WIKI,doc/master/polytest2_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/polytest2_8C.html
https://root.cern/doc/master/polytest2_8C.html:1532,Testability,assert,assert,1532,"re: ""saw-like"" polygon (bins == teeth).; ; //Includes for ACLiC.; #include <cassert>; #include <vector>; ; #include ""TRandom.h""; #include ""TCanvas.h""; #include ""Rtypes.h""; #include ""TNamed.h""; ; class PolyTest2 : public TNamed, public TAttLine, public TAttFill {; public:; PolyTest2();; ; void Paint(const Option_t *notUsed) override;; ; private:; enum TestSize {; kNSawPoints = 10000; };; ; //Part 1.; std::vector<Double_t> fXs1;; std::vector<Double_t> fYs1;; //Part 2.; ; std::vector<Double_t> fXs2;; std::vector<Double_t> fYs2;; };; ; //_____________________________________________________________; PolyTest2::PolyTest2(); : TNamed(""polygon_compression_test2"", ""polygon_compression_test2""); {; //Polygon 1, n of points is 10003, after 'compression' : 1897; //Polygon 2, n of points is 10003, after 'compression' : 2093; ; //Some canvas must already exist by this point.; assert(gPad != nullptr && ""PolyTest2, gPad is null"");; //We need a gRandom to exist.; assert(gRandom != nullptr && ""PolyTest2, gRandom is null"");; ; Double_t xMin = 0., xMax = 0., yMin = 0., yMax = 0.;; gPad->GetRange(xMin, yMin, xMax, yMax);; assert(xMax - xMin > 0 && yMax - yMin > 0 && ""PolyTest2, invalid canvas' ranges"");; ; ; // .(0/the last)--------.(1); // | /; // | \; // | /; // .(kNSawPoints + 1)--.(kNSawPoints); ; const unsigned nVertices = 3 + kNSawPoints;; ; {; //Polygon 1, ""vertical saw"":; fXs1.resize(nVertices);; fYs1.resize(nVertices);; ; fXs1[0] = 0.;; fYs1[0] = 0.;; ; const Double_t w1 = 0.2 * (xMax - xMin);; const Double_t saw1ToothSize = 0.1 * w1;; const Double_t yStep = (yMax - yMin) / (kNSawPoints - 1);; ; for (unsigned i = 1; i <= kNSawPoints; ++i) {; fXs1[i] = w1 + gRandom->Rndm() * saw1ToothSize;; fYs1[i] = yMin + yStep * (i - 1);; }; ; fXs1[nVertices - 2] = 0.;; fYs1[nVertices - 2] = yMax;; //Let's close it.; fXs1[nVertices - 1] = fXs1[0];; fYs1[nVertices - 1] = fYs1[0];; ; }; ; //Polygon 2, ""horizontal saw"":; ; {; const Double_t x2Min = xMin + 0.25 * (xMax - xMin);; const Double_t h2 ",MatchSource.WIKI,doc/master/polytest2_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/polytest2_8C.html
https://root.cern/doc/master/polytest2_8C.html:1690,Testability,assert,assert,1690,"vas.h""; #include ""Rtypes.h""; #include ""TNamed.h""; ; class PolyTest2 : public TNamed, public TAttLine, public TAttFill {; public:; PolyTest2();; ; void Paint(const Option_t *notUsed) override;; ; private:; enum TestSize {; kNSawPoints = 10000; };; ; //Part 1.; std::vector<Double_t> fXs1;; std::vector<Double_t> fYs1;; //Part 2.; ; std::vector<Double_t> fXs2;; std::vector<Double_t> fYs2;; };; ; //_____________________________________________________________; PolyTest2::PolyTest2(); : TNamed(""polygon_compression_test2"", ""polygon_compression_test2""); {; //Polygon 1, n of points is 10003, after 'compression' : 1897; //Polygon 2, n of points is 10003, after 'compression' : 2093; ; //Some canvas must already exist by this point.; assert(gPad != nullptr && ""PolyTest2, gPad is null"");; //We need a gRandom to exist.; assert(gRandom != nullptr && ""PolyTest2, gRandom is null"");; ; Double_t xMin = 0., xMax = 0., yMin = 0., yMax = 0.;; gPad->GetRange(xMin, yMin, xMax, yMax);; assert(xMax - xMin > 0 && yMax - yMin > 0 && ""PolyTest2, invalid canvas' ranges"");; ; ; // .(0/the last)--------.(1); // | /; // | \; // | /; // .(kNSawPoints + 1)--.(kNSawPoints); ; const unsigned nVertices = 3 + kNSawPoints;; ; {; //Polygon 1, ""vertical saw"":; fXs1.resize(nVertices);; fYs1.resize(nVertices);; ; fXs1[0] = 0.;; fYs1[0] = 0.;; ; const Double_t w1 = 0.2 * (xMax - xMin);; const Double_t saw1ToothSize = 0.1 * w1;; const Double_t yStep = (yMax - yMin) / (kNSawPoints - 1);; ; for (unsigned i = 1; i <= kNSawPoints; ++i) {; fXs1[i] = w1 + gRandom->Rndm() * saw1ToothSize;; fYs1[i] = yMin + yStep * (i - 1);; }; ; fXs1[nVertices - 2] = 0.;; fYs1[nVertices - 2] = yMax;; //Let's close it.; fXs1[nVertices - 1] = fXs1[0];; fYs1[nVertices - 1] = fYs1[0];; ; }; ; //Polygon 2, ""horizontal saw"":; ; {; const Double_t x2Min = xMin + 0.25 * (xMax - xMin);; const Double_t h2 = 0.1 * (yMax - yMin);; const Double_t saw2ToothSize = 0.1 * h2;; const Double_t xStep = (xMax - x2Min) / (kNSawPoints - 1);; ; fXs2.resize(nV",MatchSource.WIKI,doc/master/polytest2_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/polytest2_8C.html
https://root.cern/doc/master/polytest2_8C.html:3167,Testability,assert,assert,3167,"_t yStep = (yMax - yMin) / (kNSawPoints - 1);; ; for (unsigned i = 1; i <= kNSawPoints; ++i) {; fXs1[i] = w1 + gRandom->Rndm() * saw1ToothSize;; fYs1[i] = yMin + yStep * (i - 1);; }; ; fXs1[nVertices - 2] = 0.;; fYs1[nVertices - 2] = yMax;; //Let's close it.; fXs1[nVertices - 1] = fXs1[0];; fYs1[nVertices - 1] = fYs1[0];; ; }; ; //Polygon 2, ""horizontal saw"":; ; {; const Double_t x2Min = xMin + 0.25 * (xMax - xMin);; const Double_t h2 = 0.1 * (yMax - yMin);; const Double_t saw2ToothSize = 0.1 * h2;; const Double_t xStep = (xMax - x2Min) / (kNSawPoints - 1);; ; fXs2.resize(nVertices);; fYs2.resize(nVertices);; ; fXs2[0] = x2Min;; fYs2[0] = 0.;; ; for (unsigned i = 1; i <= kNSawPoints; ++i) {; fXs2[i] = x2Min + xStep * i;; fYs2[i] = h2 + gRandom->Rndm() * saw2ToothSize;; }; ; fXs2[nVertices - 2] = xMax;; fYs2[nVertices - 2] = 0.;; fXs2[nVertices - 1] = fXs2[0];; fYs2[nVertices - 1] = fYs2[0];; }; }; ; //_____________________________________________________________; void PolyTest2::Paint(const Option_t * /*notUsed*/); {; assert(gPad != nullptr && ""Paint, gPad is null"");; ; SetFillColor(kGreen);; TAttFill::Modify();; gPad->PaintFillArea((Int_t)fXs1.size(), &fXs1[0], &fYs1[0]);; ; SetLineColor(kBlue);; TAttLine::Modify();; gPad->PaintPolyLine((Int_t)fXs1.size(), &fXs1[0], &fYs1[0]);; ; SetFillColor(kOrange);; TAttFill::Modify();; gPad->PaintFillArea((Int_t)fXs2.size(), &fXs2[0], &fYs2[0]);; ; SetLineColor(kMagenta);; TAttLine::Modify();; gPad->PaintPolyLine((Int_t)fXs2.size(), &fXs2[0], &fYs2[0]);; }; ; void polytest2(); {; TCanvas * const cnv = new TCanvas;; cnv->cd();; ; PolyTest2 * polygon = new PolyTest2;; polygon->Draw();//Attach a polygon to a canvas.; }; Int_tint Int_tDefinition RtypesCore.h:45; Double_tdouble Double_tDefinition RtypesCore.h:59; Option_tconst char Option_tDefinition RtypesCore.h:66; Rtypes.h; kOrange@ kOrangeDefinition Rtypes.h:67; kGreen@ kGreenDefinition Rtypes.h:66; kMagenta@ kMagentaDefinition Rtypes.h:66; kBlue@ kBlueDefinition Rtypes.h:66; TC",MatchSource.WIKI,doc/master/polytest2_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/polytest2_8C.html
https://root.cern/doc/master/portfolio_8C.html:19012,Deployability,install,installation,19012,"QP formulation.Definition TQpDataDens.h:63; TQpProbDensdense matrix problem formulationDefinition TQpProbDens.h:61; TQpProbDens::MakeVariablesTQpVar * MakeVariables(const TQpDataBase *data) overrideSetup the variables.Definition TQpProbDens.cxx:182; TQpProbDens::MakeDatavirtual TQpDataBase * MakeData(Double_t *c, Double_t *Q, Double_t *xlo, Bool_t *ixlo, Double_t *xup, Bool_t *ixup, Double_t *A, Double_t *bA, Double_t *C, Double_t *clo, Bool_t *iclo, Double_t *cup, Bool_t *icup)Setup the data.Definition TQpProbDens.cxx:80; TQpProbDens::MakeResidualsTQpResidual * MakeResiduals(const TQpDataBase *data) overrideSetup the residuals.Definition TQpProbDens.cxx:172; TQpResidualThe Residuals class calculates and stores the quantities that appear on the right-hand side of the li...Definition TQpResidual.h:62; TQpVarClass containing the variables for the general QP formulation.Definition TQpVar.h:60; TQpVar::fXTVectorD fXDefinition TQpVar.h:91; TROOT::GetTutorialDirstatic const TString & GetTutorialDir()Get the tutorials directory in the installation. Static utility function.Definition TROOT.cxx:3119; TStringBasic string class.Definition TString.h:139; TSystem::AccessPathNamevirtual Bool_t AccessPathName(const char *path, EAccessMode mode=kFileExists)Returns FALSE if one can access a file using the specified access mode.Definition TSystem.cxx:1296; TTreeA TTree represents a columnar dataset.Definition TTree.h:79; TTree::GetBranchvirtual TBranch * GetBranch(const char *name)Return pointer to the branch with the given name in this tree or its friends.Definition TTree.cxx:5294; TTree::SetBranchAddressvirtual Int_t SetBranchAddress(const char *bname, void *add, TBranch **ptr=nullptr)Change branch address, dealing with clone trees properly.Definition TTree.cxx:8385; TTree::GetEntriesvirtual Long64_t GetEntries() constDefinition TTree.h:463; TVectorT< Double_t >; c1return c1Definition legend1.C:41; xDouble_t x[n]Definition legend1.C:17; h1TH1F * h1Definition legend1.C:5; f1TF1 * f1",MatchSource.WIKI,doc/master/portfolio_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/portfolio_8C.html
https://root.cern/doc/master/portfolio_8C.html:20241,Energy Efficiency,power,power,20241,"ion TQpProbDens.cxx:172; TQpResidualThe Residuals class calculates and stores the quantities that appear on the right-hand side of the li...Definition TQpResidual.h:62; TQpVarClass containing the variables for the general QP formulation.Definition TQpVar.h:60; TQpVar::fXTVectorD fXDefinition TQpVar.h:91; TROOT::GetTutorialDirstatic const TString & GetTutorialDir()Get the tutorials directory in the installation. Static utility function.Definition TROOT.cxx:3119; TStringBasic string class.Definition TString.h:139; TSystem::AccessPathNamevirtual Bool_t AccessPathName(const char *path, EAccessMode mode=kFileExists)Returns FALSE if one can access a file using the specified access mode.Definition TSystem.cxx:1296; TTreeA TTree represents a columnar dataset.Definition TTree.h:79; TTree::GetBranchvirtual TBranch * GetBranch(const char *name)Return pointer to the branch with the given name in this tree or its friends.Definition TTree.cxx:5294; TTree::SetBranchAddressvirtual Int_t SetBranchAddress(const char *bname, void *add, TBranch **ptr=nullptr)Change branch address, dealing with clone trees properly.Definition TTree.cxx:8385; TTree::GetEntriesvirtual Long64_t GetEntries() constDefinition TTree.h:463; TVectorT< Double_t >; c1return c1Definition legend1.C:41; xDouble_t x[n]Definition legend1.C:17; h1TH1F * h1Definition legend1.C:5; f1TF1 * f1Definition legend1.C:11; TMVA_SOFIE_GNN_Parser.h2h2Definition TMVA_SOFIE_GNN_Parser.py:188; TMath::Cconstexpr Double_t C()Velocity of light in .Definition TMath.h:114; TMath::ExpDouble_t Exp(Double_t x)Returns the base-e exponential function of x, which is e raised to the power x.Definition TMath.h:709; TMath::SqrtDouble_t Sqrt(Double_t x)Returns the square root of x.Definition TMath.h:662; sumstatic uint64_t sum(uint64_t i)Definition Factory.cxx:2345; AuthorEddy Offermann ; Definition in file portfolio.C. tutorialsquadpportfolio.C. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:30 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/portfolio_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/portfolio_8C.html
https://root.cern/doc/master/portfolio_8C.html:1406,Modifiability,variab,variables,1406,".x portfolio.C+; or; gSystem->Load(""libQuadp"");; .L portFolio.C+; portfolio(); gSystemR__EXTERN TSystem * gSystemDefinition TSystem.h:561; TSystem::Loadvirtual int Load(const char *module, const char *entry="""", Bool_t system=kFALSE)Load a shared library.Definition TSystem.cxx:1857; Let's first review what we exactly mean by ""quadratic programming"" :; We want to minimize the following objective function :; \( c^T x + ( 1/2 ) x^T Q x \) wrt. the vector \( x \); \( c \) is a vector and \( Q \) a symmetric positive definite matrix; You might wonder what is so special about this objective which is quadratic in the unknowns, that can not be done by Minuit/Fumili . Well, we have in addition the following boundary conditions on \( x \):. \[; A x = b \\; clo \le C x \le cup \\; xlo \le x \le xup; \]. where A and C are arbitrary matrices and the rest are vectors; Not all these constraints have to be defined . Our example will only use \( xlo \), \( A \) and \( b \) Still, this could be handled by a general non-linear minimizer like Minuit by introducing so-called ""slack"" variables . However, quadp is tailored to objective functions not more complex than being quadratic . This allows usage of solving techniques which are even stable for problems involving for instance 500 variables, 100 inequality conditions and 50 equality conditions .; Enough said about quadratic programming, let's return to our example . Suppose, after a long day of doing physics, you have a look at your investments and realize that an early retirement is not possible, given the returns of your stocks . So what now ? ROOT to the rescue ...; In 1990 Harry Markowitz was awarded the Nobel prize for economics: "" his work provided new tools; for weighing the risks and rewards of different investments and for valuing corporate stocks and bonds"" . In plain English, he developed the tools to balance greed and fear, we want the maximum return with the minimum amount of risk. Our stock portfolio should be at the ""Effi",MatchSource.WIKI,doc/master/portfolio_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/portfolio_8C.html
https://root.cern/doc/master/portfolio_8C.html:1610,Modifiability,variab,variables,1610,"n TSystem.cxx:1857; Let's first review what we exactly mean by ""quadratic programming"" :; We want to minimize the following objective function :; \( c^T x + ( 1/2 ) x^T Q x \) wrt. the vector \( x \); \( c \) is a vector and \( Q \) a symmetric positive definite matrix; You might wonder what is so special about this objective which is quadratic in the unknowns, that can not be done by Minuit/Fumili . Well, we have in addition the following boundary conditions on \( x \):. \[; A x = b \\; clo \le C x \le cup \\; xlo \le x \le xup; \]. where A and C are arbitrary matrices and the rest are vectors; Not all these constraints have to be defined . Our example will only use \( xlo \), \( A \) and \( b \) Still, this could be handled by a general non-linear minimizer like Minuit by introducing so-called ""slack"" variables . However, quadp is tailored to objective functions not more complex than being quadratic . This allows usage of solving techniques which are even stable for problems involving for instance 500 variables, 100 inequality conditions and 50 equality conditions .; Enough said about quadratic programming, let's return to our example . Suppose, after a long day of doing physics, you have a look at your investments and realize that an early retirement is not possible, given the returns of your stocks . So what now ? ROOT to the rescue ...; In 1990 Harry Markowitz was awarded the Nobel prize for economics: "" his work provided new tools; for weighing the risks and rewards of different investments and for valuing corporate stocks and bonds"" . In plain English, he developed the tools to balance greed and fear, we want the maximum return with the minimum amount of risk. Our stock portfolio should be at the ""Efficient Frontier"". To quantify better the risk we are willing to take, we define a utility function \( U(x) \). It describes as a function of our total assets \( x \), our ""satisfaction"" . A common choice is \( 1-exp(-k*x) \) (the reason for the exponent will be c",MatchSource.WIKI,doc/master/portfolio_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/portfolio_8C.html
https://root.cern/doc/master/portfolio_8C.html:9057,Modifiability,variab,variable,9057,"t_t nrEqual = 1;; const Int_t nrInEqual = 0;; ; // flip the sign of the objective function because we want to maximize; TVectorD c = -1.*r;; TMatrixDSym Q = riskFactor*Covar;; ; // equality equation; TMatrixD A(nrEqual,nrVar); A = 1;; TVectorD b(nrEqual); b = 1;; ; // inequality equation; //; // - although not applicable in the current situation since nrInEqual = 0, one; // has to specify not only clo and cup but also an index vector iclo and icup,; // whose values are either 0 or 1 . If iclo[j] = 1, the lower boundary condition; // is active on x[j], etc. ...; ; TMatrixD C (nrInEqual,nrVar);; TVectorD clo (nrInEqual);; TVectorD cup (nrInEqual);; TVectorD iclo(nrInEqual);; TVectorD icup(nrInEqual);; ; // simple square boundary condition : 0 <= x_i, so only xlo is relevant .; // Like for clo and cup above, we have to define an index vector ixlo and ixup .; // Since each variable has the lower boundary, we can set the whole vector; // ixlo = 1; ; TVectorD xlo (nrVar); xlo = 0;; TVectorD xup (nrVar); xup = 0;; TVectorD ixlo(nrVar); ixlo = 1;; TVectorD ixup(nrVar); ixup = 0;; ; // setup the quadratic programming problem . Since a small number of variables are; // involved and ""Q"" has everywhere entries, we chose the dense version ""TQpProbDens"" .; // In case of a sparse formulation, simply replace all ""Dens"" by ""Sparse"" below and; // use TMatrixDSparse instead of TMatrixDSym and TMatrixD; ; TQpProbDens *qp = new TQpProbDens(nrVar,nrEqual,nrInEqual);; ; // stuff all the matrices/vectors defined above in the proper places; ; TQpDataDens *prob = (TQpDataDens *)qp->MakeData(c,Q,xlo,ixlo,xup,ixup,A,b,C,clo,iclo,cup,icup);; ; // setup the nrStock variables, vars->fX will contain the final solution; ; TQpVar *vars = qp->MakeVariables(prob);; TQpResidual *resid = qp->MakeResiduals(prob);; ; // Now we have to choose the method of solving, either TGondzioSolver or TMehrotraSolver; // The Gondzio method is more sophisticated and therefore numerically more involved; // If one want th",MatchSource.WIKI,doc/master/portfolio_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/portfolio_8C.html
https://root.cern/doc/master/portfolio_8C.html:9335,Modifiability,variab,variables,9335,"; TMatrixD A(nrEqual,nrVar); A = 1;; TVectorD b(nrEqual); b = 1;; ; // inequality equation; //; // - although not applicable in the current situation since nrInEqual = 0, one; // has to specify not only clo and cup but also an index vector iclo and icup,; // whose values are either 0 or 1 . If iclo[j] = 1, the lower boundary condition; // is active on x[j], etc. ...; ; TMatrixD C (nrInEqual,nrVar);; TVectorD clo (nrInEqual);; TVectorD cup (nrInEqual);; TVectorD iclo(nrInEqual);; TVectorD icup(nrInEqual);; ; // simple square boundary condition : 0 <= x_i, so only xlo is relevant .; // Like for clo and cup above, we have to define an index vector ixlo and ixup .; // Since each variable has the lower boundary, we can set the whole vector; // ixlo = 1; ; TVectorD xlo (nrVar); xlo = 0;; TVectorD xup (nrVar); xup = 0;; TVectorD ixlo(nrVar); ixlo = 1;; TVectorD ixup(nrVar); ixup = 0;; ; // setup the quadratic programming problem . Since a small number of variables are; // involved and ""Q"" has everywhere entries, we chose the dense version ""TQpProbDens"" .; // In case of a sparse formulation, simply replace all ""Dens"" by ""Sparse"" below and; // use TMatrixDSparse instead of TMatrixDSym and TMatrixD; ; TQpProbDens *qp = new TQpProbDens(nrVar,nrEqual,nrInEqual);; ; // stuff all the matrices/vectors defined above in the proper places; ; TQpDataDens *prob = (TQpDataDens *)qp->MakeData(c,Q,xlo,ixlo,xup,ixup,A,b,C,clo,iclo,cup,icup);; ; // setup the nrStock variables, vars->fX will contain the final solution; ; TQpVar *vars = qp->MakeVariables(prob);; TQpResidual *resid = qp->MakeResiduals(prob);; ; // Now we have to choose the method of solving, either TGondzioSolver or TMehrotraSolver; // The Gondzio method is more sophisticated and therefore numerically more involved; // If one want the Mehrotra method, simply replace ""Gondzio"" by ""Mehrotra"" .; ; TGondzioSolver *s = new TGondzioSolver(qp,prob);; const Int_t status = s->Solve(prob,vars,resid);; ; const TVectorD weight = vars->fX;",MatchSource.WIKI,doc/master/portfolio_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/portfolio_8C.html
https://root.cern/doc/master/portfolio_8C.html:9839,Modifiability,variab,variables,9839,"orD iclo(nrInEqual);; TVectorD icup(nrInEqual);; ; // simple square boundary condition : 0 <= x_i, so only xlo is relevant .; // Like for clo and cup above, we have to define an index vector ixlo and ixup .; // Since each variable has the lower boundary, we can set the whole vector; // ixlo = 1; ; TVectorD xlo (nrVar); xlo = 0;; TVectorD xup (nrVar); xup = 0;; TVectorD ixlo(nrVar); ixlo = 1;; TVectorD ixup(nrVar); ixup = 0;; ; // setup the quadratic programming problem . Since a small number of variables are; // involved and ""Q"" has everywhere entries, we chose the dense version ""TQpProbDens"" .; // In case of a sparse formulation, simply replace all ""Dens"" by ""Sparse"" below and; // use TMatrixDSparse instead of TMatrixDSym and TMatrixD; ; TQpProbDens *qp = new TQpProbDens(nrVar,nrEqual,nrInEqual);; ; // stuff all the matrices/vectors defined above in the proper places; ; TQpDataDens *prob = (TQpDataDens *)qp->MakeData(c,Q,xlo,ixlo,xup,ixup,A,b,C,clo,iclo,cup,icup);; ; // setup the nrStock variables, vars->fX will contain the final solution; ; TQpVar *vars = qp->MakeVariables(prob);; TQpResidual *resid = qp->MakeResiduals(prob);; ; // Now we have to choose the method of solving, either TGondzioSolver or TMehrotraSolver; // The Gondzio method is more sophisticated and therefore numerically more involved; // If one want the Mehrotra method, simply replace ""Gondzio"" by ""Mehrotra"" .; ; TGondzioSolver *s = new TGondzioSolver(qp,prob);; const Int_t status = s->Solve(prob,vars,resid);; ; const TVectorD weight = vars->fX;; ; delete qp; delete prob; delete vars; delete resid; delete s;; if (status != 0) {; cout << ""Could not solve this problem."" <<endl;; return TVectorD(nrStocks);; }; ; return weight;; }; #endif; ; //---------------------------------------------------------------------------; void portfolio(); {; const Int_t sDay = 20000809;; const Int_t eDay = 20040602;; ; const char *fname = ""stock.root"";; TFile *f = 0;; if (!gSystem->AccessPathName(fname)) {; f = TFile::Ope",MatchSource.WIKI,doc/master/portfolio_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/portfolio_8C.html
https://root.cern/doc/master/portfolio_8C.html:18176,Modifiability,variab,variables,18176,"finition TH1.h:405; TH1::SetYTitlevirtual void SetYTitle(const char *title)Definition TH1.h:420; TH1::SetBarWidthvirtual void SetBarWidth(Float_t width=0.5)Set the width of bars as fraction of the bin width for drawing mode ""B"".Definition TH1.h:365; TH1::SetStatsvirtual void SetStats(Bool_t stats=kTRUE)Set statistics option on/off.Definition TH1.cxx:8990; TLegendThis class displays a legend box (TPaveText) containing several legend entries.Definition TLegend.h:23; TLegend::AddEntryTLegendEntry * AddEntry(const TObject *obj, const char *label="""", Option_t *option=""lpf"")Add a new entry to this legend.Definition TLegend.cxx:320; TLegend::Drawvoid Draw(Option_t *option="""") overrideDraw this legend with its current attributes.Definition TLegend.cxx:425; TMatrixTSym< Double_t >; TMatrixT< Double_t >; TQpDataDensData for the dense QP formulation.Definition TQpDataDens.h:63; TQpProbDensdense matrix problem formulationDefinition TQpProbDens.h:61; TQpProbDens::MakeVariablesTQpVar * MakeVariables(const TQpDataBase *data) overrideSetup the variables.Definition TQpProbDens.cxx:182; TQpProbDens::MakeDatavirtual TQpDataBase * MakeData(Double_t *c, Double_t *Q, Double_t *xlo, Bool_t *ixlo, Double_t *xup, Bool_t *ixup, Double_t *A, Double_t *bA, Double_t *C, Double_t *clo, Bool_t *iclo, Double_t *cup, Bool_t *icup)Setup the data.Definition TQpProbDens.cxx:80; TQpProbDens::MakeResidualsTQpResidual * MakeResiduals(const TQpDataBase *data) overrideSetup the residuals.Definition TQpProbDens.cxx:172; TQpResidualThe Residuals class calculates and stores the quantities that appear on the right-hand side of the li...Definition TQpResidual.h:62; TQpVarClass containing the variables for the general QP formulation.Definition TQpVar.h:60; TQpVar::fXTVectorD fXDefinition TQpVar.h:91; TROOT::GetTutorialDirstatic const TString & GetTutorialDir()Get the tutorials directory in the installation. Static utility function.Definition TROOT.cxx:3119; TStringBasic string class.Definition TString.h:139; TSy",MatchSource.WIKI,doc/master/portfolio_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/portfolio_8C.html
https://root.cern/doc/master/portfolio_8C.html:18807,Modifiability,variab,variables,18807,"verrideDraw this legend with its current attributes.Definition TLegend.cxx:425; TMatrixTSym< Double_t >; TMatrixT< Double_t >; TQpDataDensData for the dense QP formulation.Definition TQpDataDens.h:63; TQpProbDensdense matrix problem formulationDefinition TQpProbDens.h:61; TQpProbDens::MakeVariablesTQpVar * MakeVariables(const TQpDataBase *data) overrideSetup the variables.Definition TQpProbDens.cxx:182; TQpProbDens::MakeDatavirtual TQpDataBase * MakeData(Double_t *c, Double_t *Q, Double_t *xlo, Bool_t *ixlo, Double_t *xup, Bool_t *ixup, Double_t *A, Double_t *bA, Double_t *C, Double_t *clo, Bool_t *iclo, Double_t *cup, Bool_t *icup)Setup the data.Definition TQpProbDens.cxx:80; TQpProbDens::MakeResidualsTQpResidual * MakeResiduals(const TQpDataBase *data) overrideSetup the residuals.Definition TQpProbDens.cxx:172; TQpResidualThe Residuals class calculates and stores the quantities that appear on the right-hand side of the li...Definition TQpResidual.h:62; TQpVarClass containing the variables for the general QP formulation.Definition TQpVar.h:60; TQpVar::fXTVectorD fXDefinition TQpVar.h:91; TROOT::GetTutorialDirstatic const TString & GetTutorialDir()Get the tutorials directory in the installation. Static utility function.Definition TROOT.cxx:3119; TStringBasic string class.Definition TString.h:139; TSystem::AccessPathNamevirtual Bool_t AccessPathName(const char *path, EAccessMode mode=kFileExists)Returns FALSE if one can access a file using the specified access mode.Definition TSystem.cxx:1296; TTreeA TTree represents a columnar dataset.Definition TTree.h:79; TTree::GetBranchvirtual TBranch * GetBranch(const char *name)Return pointer to the branch with the given name in this tree or its friends.Definition TTree.cxx:5294; TTree::SetBranchAddressvirtual Int_t SetBranchAddress(const char *bname, void *add, TBranch **ptr=nullptr)Change branch address, dealing with clone trees properly.Definition TTree.cxx:8385; TTree::GetEntriesvirtual Long64_t GetEntries() constDefinitio",MatchSource.WIKI,doc/master/portfolio_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/portfolio_8C.html
https://root.cern/doc/master/portfolio_8C.html:4913,Performance,optimiz,optimization,4913,"a stock; For 10 stocks we got the historical daily data for Sep-2000 to Jun-2004:. GE : General Electric Co; SUNW : Sun Microsystems Inc; QCOM : Qualcomm Inc; BRCM : Broadcom Corp; TYC : Tyco International Ltd; IBM : International Business Machines Corp; AMAT : Applied Materials Inc; C : Citigroup Inc; PFE : Pfizer Inc; HD : Home Depot Inc. We calculate the optimal portfolio for 2.0 and 10.0 .; Food for thought :; We assumed that the stock returns have a Normal distribution . Check this assumption by histogramming the stock returns !; We used for the expected return in the objective function, the flat average over a time period . Investment firms will put significant resources in improving the return prediction .; If you want to trade significant number of shares, several other considerations have to be taken into account :; If you are going to buy, you will drive the price up (so-called ""slippage"") . This can be taken into account by adding terms to the objective (Google for ""slippage optimization""); FTC regulations might have to be added to the inequality constraints. Investment firms do not want to be exposed to the ""market"" as defined by a broad index like the S&P and ""hedge"" this exposure away . A perfect hedge this can be added as an equality constrain, otherwise add an inequality constrain . ; stock daily daily w1 w2; symb return sdv ; GE : 1.001 0.022 0.000 0.134; SUNW : 1.004 0.047 0.676 0.145; QCOM : 1.001 0.039 0.000 0.000; BRCM : 1.003 0.056 0.179 0.035; TYC : 1.001 0.042 0.145 0.069; IBM : 1.001 0.023 0.000 0.096; AMAT : 1.001 0.040 0.000 0.000; C : 1.000 0.023 0.000 0.000; PFE : 1.000 0.019 0.000 0.424; HD : 1.001 0.029 0.000 0.098; ; #include ""Riostream.h""; #include ""TCanvas.h""; #include ""TFile.h""; #include ""TMath.h""; #include ""TTree.h""; #include ""TArrayF.h""; #include ""TH1.h""; #include ""TF1.h""; #include ""TLegend.h""; #include ""TSystem.h""; ; #include ""TMatrixD.h""; #include ""TMatrixDSym.h""; #include ""TVectorD.h""; #include ""TQpProbDens.h""; #include ""TGond",MatchSource.WIKI,doc/master/portfolio_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/portfolio_8C.html
https://root.cern/doc/master/portfolio_8C.html:2070,Safety,risk,risks,2070,"on \( x \):. \[; A x = b \\; clo \le C x \le cup \\; xlo \le x \le xup; \]. where A and C are arbitrary matrices and the rest are vectors; Not all these constraints have to be defined . Our example will only use \( xlo \), \( A \) and \( b \) Still, this could be handled by a general non-linear minimizer like Minuit by introducing so-called ""slack"" variables . However, quadp is tailored to objective functions not more complex than being quadratic . This allows usage of solving techniques which are even stable for problems involving for instance 500 variables, 100 inequality conditions and 50 equality conditions .; Enough said about quadratic programming, let's return to our example . Suppose, after a long day of doing physics, you have a look at your investments and realize that an early retirement is not possible, given the returns of your stocks . So what now ? ROOT to the rescue ...; In 1990 Harry Markowitz was awarded the Nobel prize for economics: "" his work provided new tools; for weighing the risks and rewards of different investments and for valuing corporate stocks and bonds"" . In plain English, he developed the tools to balance greed and fear, we want the maximum return with the minimum amount of risk. Our stock portfolio should be at the ""Efficient Frontier"". To quantify better the risk we are willing to take, we define a utility function \( U(x) \). It describes as a function of our total assets \( x \), our ""satisfaction"" . A common choice is \( 1-exp(-k*x) \) (the reason for the exponent will be clear later) . The parameter \( k \) is the risk-aversion factor . For small values of \( k \) the satisfaction is small for small values of \( x \); by increasing \( x \) the satisfaction can still be increased significantly . For large values of \( k \), \( U(x) \) increases rapidly to 1, there is no increase in satisfaction for additional dollars earned .; In summary :; small \( k \) ==> risk-loving investor; large \( k \) ==> risk-averse investor. Suppose we",MatchSource.WIKI,doc/master/portfolio_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/portfolio_8C.html
https://root.cern/doc/master/portfolio_8C.html:2281,Safety,risk,risk,2281,"ve to be defined . Our example will only use \( xlo \), \( A \) and \( b \) Still, this could be handled by a general non-linear minimizer like Minuit by introducing so-called ""slack"" variables . However, quadp is tailored to objective functions not more complex than being quadratic . This allows usage of solving techniques which are even stable for problems involving for instance 500 variables, 100 inequality conditions and 50 equality conditions .; Enough said about quadratic programming, let's return to our example . Suppose, after a long day of doing physics, you have a look at your investments and realize that an early retirement is not possible, given the returns of your stocks . So what now ? ROOT to the rescue ...; In 1990 Harry Markowitz was awarded the Nobel prize for economics: "" his work provided new tools; for weighing the risks and rewards of different investments and for valuing corporate stocks and bonds"" . In plain English, he developed the tools to balance greed and fear, we want the maximum return with the minimum amount of risk. Our stock portfolio should be at the ""Efficient Frontier"". To quantify better the risk we are willing to take, we define a utility function \( U(x) \). It describes as a function of our total assets \( x \), our ""satisfaction"" . A common choice is \( 1-exp(-k*x) \) (the reason for the exponent will be clear later) . The parameter \( k \) is the risk-aversion factor . For small values of \( k \) the satisfaction is small for small values of \( x \); by increasing \( x \) the satisfaction can still be increased significantly . For large values of \( k \), \( U(x) \) increases rapidly to 1, there is no increase in satisfaction for additional dollars earned .; In summary :; small \( k \) ==> risk-loving investor; large \( k \) ==> risk-averse investor. Suppose we have for nrStocks the historical daily returns \( r = closing_price(n) - closing_price(n-1) \). Define a vector \( x \) of length of \( nrStocks \), which contains t",MatchSource.WIKI,doc/master/portfolio_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/portfolio_8C.html
https://root.cern/doc/master/portfolio_8C.html:2369,Safety,risk,risk,2369,"called ""slack"" variables . However, quadp is tailored to objective functions not more complex than being quadratic . This allows usage of solving techniques which are even stable for problems involving for instance 500 variables, 100 inequality conditions and 50 equality conditions .; Enough said about quadratic programming, let's return to our example . Suppose, after a long day of doing physics, you have a look at your investments and realize that an early retirement is not possible, given the returns of your stocks . So what now ? ROOT to the rescue ...; In 1990 Harry Markowitz was awarded the Nobel prize for economics: "" his work provided new tools; for weighing the risks and rewards of different investments and for valuing corporate stocks and bonds"" . In plain English, he developed the tools to balance greed and fear, we want the maximum return with the minimum amount of risk. Our stock portfolio should be at the ""Efficient Frontier"". To quantify better the risk we are willing to take, we define a utility function \( U(x) \). It describes as a function of our total assets \( x \), our ""satisfaction"" . A common choice is \( 1-exp(-k*x) \) (the reason for the exponent will be clear later) . The parameter \( k \) is the risk-aversion factor . For small values of \( k \) the satisfaction is small for small values of \( x \); by increasing \( x \) the satisfaction can still be increased significantly . For large values of \( k \), \( U(x) \) increases rapidly to 1, there is no increase in satisfaction for additional dollars earned .; In summary :; small \( k \) ==> risk-loving investor; large \( k \) ==> risk-averse investor. Suppose we have for nrStocks the historical daily returns \( r = closing_price(n) - closing_price(n-1) \). Define a vector \( x \) of length of \( nrStocks \), which contains the fraction of our money invested in each stock . We can calculate the average daily return \( z \) of our portfolio and its variance using the portfolio covariance Covar",MatchSource.WIKI,doc/master/portfolio_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/portfolio_8C.html
https://root.cern/doc/master/portfolio_8C.html:2634,Safety,risk,risk-aversion,2634,"ality conditions and 50 equality conditions .; Enough said about quadratic programming, let's return to our example . Suppose, after a long day of doing physics, you have a look at your investments and realize that an early retirement is not possible, given the returns of your stocks . So what now ? ROOT to the rescue ...; In 1990 Harry Markowitz was awarded the Nobel prize for economics: "" his work provided new tools; for weighing the risks and rewards of different investments and for valuing corporate stocks and bonds"" . In plain English, he developed the tools to balance greed and fear, we want the maximum return with the minimum amount of risk. Our stock portfolio should be at the ""Efficient Frontier"". To quantify better the risk we are willing to take, we define a utility function \( U(x) \). It describes as a function of our total assets \( x \), our ""satisfaction"" . A common choice is \( 1-exp(-k*x) \) (the reason for the exponent will be clear later) . The parameter \( k \) is the risk-aversion factor . For small values of \( k \) the satisfaction is small for small values of \( x \); by increasing \( x \) the satisfaction can still be increased significantly . For large values of \( k \), \( U(x) \) increases rapidly to 1, there is no increase in satisfaction for additional dollars earned .; In summary :; small \( k \) ==> risk-loving investor; large \( k \) ==> risk-averse investor. Suppose we have for nrStocks the historical daily returns \( r = closing_price(n) - closing_price(n-1) \). Define a vector \( x \) of length of \( nrStocks \), which contains the fraction of our money invested in each stock . We can calculate the average daily return \( z \) of our portfolio and its variance using the portfolio covariance Covar :; \( z = r^T x \) and \( var = x^T Covar x \); Assuming that the daily returns have a Normal distribution, \( N(x) \), so will \( z \) with mean \( r^T x \) and variance \( x^T Covar x \); The expected value of the utility function is :",MatchSource.WIKI,doc/master/portfolio_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/portfolio_8C.html
https://root.cern/doc/master/portfolio_8C.html:2984,Safety,risk,risk-loving,2984,"bel prize for economics: "" his work provided new tools; for weighing the risks and rewards of different investments and for valuing corporate stocks and bonds"" . In plain English, he developed the tools to balance greed and fear, we want the maximum return with the minimum amount of risk. Our stock portfolio should be at the ""Efficient Frontier"". To quantify better the risk we are willing to take, we define a utility function \( U(x) \). It describes as a function of our total assets \( x \), our ""satisfaction"" . A common choice is \( 1-exp(-k*x) \) (the reason for the exponent will be clear later) . The parameter \( k \) is the risk-aversion factor . For small values of \( k \) the satisfaction is small for small values of \( x \); by increasing \( x \) the satisfaction can still be increased significantly . For large values of \( k \), \( U(x) \) increases rapidly to 1, there is no increase in satisfaction for additional dollars earned .; In summary :; small \( k \) ==> risk-loving investor; large \( k \) ==> risk-averse investor. Suppose we have for nrStocks the historical daily returns \( r = closing_price(n) - closing_price(n-1) \). Define a vector \( x \) of length of \( nrStocks \), which contains the fraction of our money invested in each stock . We can calculate the average daily return \( z \) of our portfolio and its variance using the portfolio covariance Covar :; \( z = r^T x \) and \( var = x^T Covar x \); Assuming that the daily returns have a Normal distribution, \( N(x) \), so will \( z \) with mean \( r^T x \) and variance \( x^T Covar x \); The expected value of the utility function is :. \[; E(u(x)) = Int (1-exp(-k*x) N(x) dx \\; = 1-exp(-k (r^T x - 0.5 k x^T Covar x) ) \\; \]. Its value is maximised by maximising \( r^T x -0.5 k x^T Covar x \) under the condition \( sum (x_i) = 1 \), meaning we want all our money invested and \( x_i \ge 0 \), we can not ""short"" a stock; For 10 stocks we got the historical daily data for Sep-2000 to Jun-2004:. GE ",MatchSource.WIKI,doc/master/portfolio_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/portfolio_8C.html
https://root.cern/doc/master/portfolio_8C.html:3024,Safety,risk,risk-averse,3024,"bel prize for economics: "" his work provided new tools; for weighing the risks and rewards of different investments and for valuing corporate stocks and bonds"" . In plain English, he developed the tools to balance greed and fear, we want the maximum return with the minimum amount of risk. Our stock portfolio should be at the ""Efficient Frontier"". To quantify better the risk we are willing to take, we define a utility function \( U(x) \). It describes as a function of our total assets \( x \), our ""satisfaction"" . A common choice is \( 1-exp(-k*x) \) (the reason for the exponent will be clear later) . The parameter \( k \) is the risk-aversion factor . For small values of \( k \) the satisfaction is small for small values of \( x \); by increasing \( x \) the satisfaction can still be increased significantly . For large values of \( k \), \( U(x) \) increases rapidly to 1, there is no increase in satisfaction for additional dollars earned .; In summary :; small \( k \) ==> risk-loving investor; large \( k \) ==> risk-averse investor. Suppose we have for nrStocks the historical daily returns \( r = closing_price(n) - closing_price(n-1) \). Define a vector \( x \) of length of \( nrStocks \), which contains the fraction of our money invested in each stock . We can calculate the average daily return \( z \) of our portfolio and its variance using the portfolio covariance Covar :; \( z = r^T x \) and \( var = x^T Covar x \); Assuming that the daily returns have a Normal distribution, \( N(x) \), so will \( z \) with mean \( r^T x \) and variance \( x^T Covar x \); The expected value of the utility function is :. \[; E(u(x)) = Int (1-exp(-k*x) N(x) dx \\; = 1-exp(-k (r^T x - 0.5 k x^T Covar x) ) \\; \]. Its value is maximised by maximising \( r^T x -0.5 k x^T Covar x \) under the condition \( sum (x_i) = 1 \), meaning we want all our money invested and \( x_i \ge 0 \), we can not ""short"" a stock; For 10 stocks we got the historical daily data for Sep-2000 to Jun-2004:. GE ",MatchSource.WIKI,doc/master/portfolio_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/portfolio_8C.html
https://root.cern/doc/master/portfolio_8C.html:4622,Safety,predict,prediction,4622,"cted value of the utility function is :. \[; E(u(x)) = Int (1-exp(-k*x) N(x) dx \\; = 1-exp(-k (r^T x - 0.5 k x^T Covar x) ) \\; \]. Its value is maximised by maximising \( r^T x -0.5 k x^T Covar x \) under the condition \( sum (x_i) = 1 \), meaning we want all our money invested and \( x_i \ge 0 \), we can not ""short"" a stock; For 10 stocks we got the historical daily data for Sep-2000 to Jun-2004:. GE : General Electric Co; SUNW : Sun Microsystems Inc; QCOM : Qualcomm Inc; BRCM : Broadcom Corp; TYC : Tyco International Ltd; IBM : International Business Machines Corp; AMAT : Applied Materials Inc; C : Citigroup Inc; PFE : Pfizer Inc; HD : Home Depot Inc. We calculate the optimal portfolio for 2.0 and 10.0 .; Food for thought :; We assumed that the stock returns have a Normal distribution . Check this assumption by histogramming the stock returns !; We used for the expected return in the objective function, the flat average over a time period . Investment firms will put significant resources in improving the return prediction .; If you want to trade significant number of shares, several other considerations have to be taken into account :; If you are going to buy, you will drive the price up (so-called ""slippage"") . This can be taken into account by adding terms to the objective (Google for ""slippage optimization""); FTC regulations might have to be added to the inequality constraints. Investment firms do not want to be exposed to the ""market"" as defined by a broad index like the S&P and ""hedge"" this exposure away . A perfect hedge this can be added as an equality constrain, otherwise add an inequality constrain . ; stock daily daily w1 w2; symb return sdv ; GE : 1.001 0.022 0.000 0.134; SUNW : 1.004 0.047 0.676 0.145; QCOM : 1.001 0.039 0.000 0.000; BRCM : 1.003 0.056 0.179 0.035; TYC : 1.001 0.042 0.145 0.069; IBM : 1.001 0.023 0.000 0.096; AMAT : 1.001 0.040 0.000 0.000; C : 1.000 0.023 0.000 0.000; PFE : 1.000 0.019 0.000 0.424; HD : 1.001 0.029 0.000 0.098; ; #in",MatchSource.WIKI,doc/master/portfolio_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/portfolio_8C.html
https://root.cern/doc/master/portfolio_8C.html:6595,Safety,risk,riskFactor,6595,"h""; #include ""TFile.h""; #include ""TMath.h""; #include ""TTree.h""; #include ""TArrayF.h""; #include ""TH1.h""; #include ""TF1.h""; #include ""TLegend.h""; #include ""TSystem.h""; ; #include ""TMatrixD.h""; #include ""TMatrixDSym.h""; #include ""TVectorD.h""; #include ""TQpProbDens.h""; #include ""TGondzioSolver.h""; ; const Int_t nrStocks = 10;; static const Char_t *stocks[] =; {""GE"",""SUNW"",""QCOM"",""BRCM"",""TYC"",""IBM"",""AMAT"",""C"",""PFE"",""HD""};; ; class TStockDaily {; public:; Int_t fDate;; Int_t fOpen; // 100*open_price; Int_t fHigh; // 100*high_price; Int_t fLow; // 100*low_price; Int_t fClose; // 100*close_price; Int_t fVol;; Int_t fCloseAdj; // 100*close_price adjusted for splits and dividend; ; TStockDaily() {; fDate = fVol = fOpen = fHigh = fLow = fClose = fCloseAdj = 0;; }; virtual ~TStockDaily() {}; ; ClassDef(TStockDaily,1); };; ; //---------------------------------------------------------------------------; Double_t RiskProfile(Double_t *x, Double_t *par) {; Double_t riskFactor = par[0];; return 1-TMath::Exp(-riskFactor*x[0]);; }; ; //---------------------------------------------------------------------------; TArrayF &StockReturn(TFile *f,const TString &name,Int_t sDay,Int_t eDay); {; TTree *tDaily = (TTree*)f->Get(name);; TStockDaily *data = 0;; tDaily->SetBranchAddress(""daily"",&data);; TBranch *b_closeAdj = tDaily->GetBranch(""fCloseAdj"");; TBranch *b_date = tDaily->GetBranch(""fDate"");; ; //read only the ""adjusted close"" branch for all entries; const Int_t nrEntries = (Int_t)tDaily->GetEntries();; TArrayF closeAdj(nrEntries);; for (Int_t i = 0; i < nrEntries; i++) {; b_date->GetEntry(i);; b_closeAdj->GetEntry(i);; if (data->fDate >= sDay && data->fDate <= eDay); closeAdj[i] = data->fCloseAdj/100.;; }; ; TArrayF *r = new TArrayF(nrEntries-1);; for (Int_t i = 1; i < nrEntries; i++); // (*r)[i-1] = closeAdj[i]-closeAdj[i-1];; (*r)[i-1] = closeAdj[i]/closeAdj[i-1];; ; return *r;; }; ; #ifndef __MAKECINT__; //---------------------------------------------------------------------------; T",MatchSource.WIKI,doc/master/portfolio_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/portfolio_8C.html
https://root.cern/doc/master/portfolio_8C.html:6638,Safety,risk,riskFactor,6638,"h""; #include ""TFile.h""; #include ""TMath.h""; #include ""TTree.h""; #include ""TArrayF.h""; #include ""TH1.h""; #include ""TF1.h""; #include ""TLegend.h""; #include ""TSystem.h""; ; #include ""TMatrixD.h""; #include ""TMatrixDSym.h""; #include ""TVectorD.h""; #include ""TQpProbDens.h""; #include ""TGondzioSolver.h""; ; const Int_t nrStocks = 10;; static const Char_t *stocks[] =; {""GE"",""SUNW"",""QCOM"",""BRCM"",""TYC"",""IBM"",""AMAT"",""C"",""PFE"",""HD""};; ; class TStockDaily {; public:; Int_t fDate;; Int_t fOpen; // 100*open_price; Int_t fHigh; // 100*high_price; Int_t fLow; // 100*low_price; Int_t fClose; // 100*close_price; Int_t fVol;; Int_t fCloseAdj; // 100*close_price adjusted for splits and dividend; ; TStockDaily() {; fDate = fVol = fOpen = fHigh = fLow = fClose = fCloseAdj = 0;; }; virtual ~TStockDaily() {}; ; ClassDef(TStockDaily,1); };; ; //---------------------------------------------------------------------------; Double_t RiskProfile(Double_t *x, Double_t *par) {; Double_t riskFactor = par[0];; return 1-TMath::Exp(-riskFactor*x[0]);; }; ; //---------------------------------------------------------------------------; TArrayF &StockReturn(TFile *f,const TString &name,Int_t sDay,Int_t eDay); {; TTree *tDaily = (TTree*)f->Get(name);; TStockDaily *data = 0;; tDaily->SetBranchAddress(""daily"",&data);; TBranch *b_closeAdj = tDaily->GetBranch(""fCloseAdj"");; TBranch *b_date = tDaily->GetBranch(""fDate"");; ; //read only the ""adjusted close"" branch for all entries; const Int_t nrEntries = (Int_t)tDaily->GetEntries();; TArrayF closeAdj(nrEntries);; for (Int_t i = 0; i < nrEntries; i++) {; b_date->GetEntry(i);; b_closeAdj->GetEntry(i);; if (data->fDate >= sDay && data->fDate <= eDay); closeAdj[i] = data->fCloseAdj/100.;; }; ; TArrayF *r = new TArrayF(nrEntries-1);; for (Int_t i = 1; i < nrEntries; i++); // (*r)[i-1] = closeAdj[i]-closeAdj[i-1];; (*r)[i-1] = closeAdj[i]/closeAdj[i-1];; ; return *r;; }; ; #ifndef __MAKECINT__; //---------------------------------------------------------------------------; T",MatchSource.WIKI,doc/master/portfolio_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/portfolio_8C.html
https://root.cern/doc/master/portfolio_8C.html:7662,Safety,risk,riskFactor,7662,"tDaily = (TTree*)f->Get(name);; TStockDaily *data = 0;; tDaily->SetBranchAddress(""daily"",&data);; TBranch *b_closeAdj = tDaily->GetBranch(""fCloseAdj"");; TBranch *b_date = tDaily->GetBranch(""fDate"");; ; //read only the ""adjusted close"" branch for all entries; const Int_t nrEntries = (Int_t)tDaily->GetEntries();; TArrayF closeAdj(nrEntries);; for (Int_t i = 0; i < nrEntries; i++) {; b_date->GetEntry(i);; b_closeAdj->GetEntry(i);; if (data->fDate >= sDay && data->fDate <= eDay); closeAdj[i] = data->fCloseAdj/100.;; }; ; TArrayF *r = new TArrayF(nrEntries-1);; for (Int_t i = 1; i < nrEntries; i++); // (*r)[i-1] = closeAdj[i]-closeAdj[i-1];; (*r)[i-1] = closeAdj[i]/closeAdj[i-1];; ; return *r;; }; ; #ifndef __MAKECINT__; //---------------------------------------------------------------------------; TVectorD OptimalInvest(Double_t riskFactor,TVectorD r,TMatrixDSym Covar); {; // what the quadratic programming package will do:; //; // minimize c^T x + ( 1/2 ) x^T Q x; // subject to A x = b; // clo <= C x <= cup; // xlo <= x <= xup; // what we want :; //; // maximize c^T x - k ( 1/2 ) x^T Q x; // subject to sum_x x_i = 1; // 0 <= x_i; ; // We have nrStocks weights to determine,; // 1 equality- and 0 inequality- equations (the simple square boundary; // condition (xlo <= x <= xup) does not count); ; const Int_t nrVar = nrStocks;; const Int_t nrEqual = 1;; const Int_t nrInEqual = 0;; ; // flip the sign of the objective function because we want to maximize; TVectorD c = -1.*r;; TMatrixDSym Q = riskFactor*Covar;; ; // equality equation; TMatrixD A(nrEqual,nrVar); A = 1;; TVectorD b(nrEqual); b = 1;; ; // inequality equation; //; // - although not applicable in the current situation since nrInEqual = 0, one; // has to specify not only clo and cup but also an index vector iclo and icup,; // whose values are either 0 or 1 . If iclo[j] = 1, the lower boundary condition; // is active on x[j], etc. ...; ; TMatrixD C (nrInEqual,nrVar);; TVectorD clo (nrInEqual);; TVectorD cup (nrInEqual",MatchSource.WIKI,doc/master/portfolio_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/portfolio_8C.html
https://root.cern/doc/master/portfolio_8C.html:8332,Safety,risk,riskFactor,8332,"Adj[i]/closeAdj[i-1];; ; return *r;; }; ; #ifndef __MAKECINT__; //---------------------------------------------------------------------------; TVectorD OptimalInvest(Double_t riskFactor,TVectorD r,TMatrixDSym Covar); {; // what the quadratic programming package will do:; //; // minimize c^T x + ( 1/2 ) x^T Q x; // subject to A x = b; // clo <= C x <= cup; // xlo <= x <= xup; // what we want :; //; // maximize c^T x - k ( 1/2 ) x^T Q x; // subject to sum_x x_i = 1; // 0 <= x_i; ; // We have nrStocks weights to determine,; // 1 equality- and 0 inequality- equations (the simple square boundary; // condition (xlo <= x <= xup) does not count); ; const Int_t nrVar = nrStocks;; const Int_t nrEqual = 1;; const Int_t nrInEqual = 0;; ; // flip the sign of the objective function because we want to maximize; TVectorD c = -1.*r;; TMatrixDSym Q = riskFactor*Covar;; ; // equality equation; TMatrixD A(nrEqual,nrVar); A = 1;; TVectorD b(nrEqual); b = 1;; ; // inequality equation; //; // - although not applicable in the current situation since nrInEqual = 0, one; // has to specify not only clo and cup but also an index vector iclo and icup,; // whose values are either 0 or 1 . If iclo[j] = 1, the lower boundary condition; // is active on x[j], etc. ...; ; TMatrixD C (nrInEqual,nrVar);; TVectorD clo (nrInEqual);; TVectorD cup (nrInEqual);; TVectorD iclo(nrInEqual);; TVectorD icup(nrInEqual);; ; // simple square boundary condition : 0 <= x_i, so only xlo is relevant .; // Like for clo and cup above, we have to define an index vector ixlo and ixup .; // Since each variable has the lower boundary, we can set the whole vector; // ixlo = 1; ; TVectorD xlo (nrVar); xlo = 0;; TVectorD xup (nrVar); xup = 0;; TVectorD ixlo(nrVar); ixlo = 1;; TVectorD ixup(nrVar); ixup = 0;; ; // setup the quadratic programming problem . Since a small number of variables are; // involved and ""Q"" has everywhere entries, we chose the dense version ""TQpProbDens"" .; // In case of a sparse formulation, simply replace",MatchSource.WIKI,doc/master/portfolio_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/portfolio_8C.html
https://root.cern/doc/master/portfolio_8C.html:12195,Safety,risk,risk,12195,"e));; }; if (!f) return;; ; TArrayF *data = new TArrayF[nrStocks];; for (Int_t i = 0; i < nrStocks; i++) {; const TString symbol = stocks[i];; data[i] = StockReturn(f,symbol,sDay,eDay);; }; ; const Int_t nrData = data[0].GetSize();; ; TVectorD r(nrStocks);; for (Int_t i = 0; i < nrStocks; i++); r[i] = data[i].GetSum()/nrData;; ; TMatrixDSym Covar(nrStocks);; for (Int_t i = 0; i < nrStocks; i++) {; for (Int_t j = 0; j <= i; j++) {; Double_t sum = 0.;; for (Int_t k = 0; k < nrData; k++) {; sum += (data[i][k] - r[i]) * (data[j][k] - r[j]);; }; Covar(i,j) = Covar(j,i) = sum/nrData;; }; }; ; const TVectorD weight1 = OptimalInvest(2.0,r,Covar);; const TVectorD weight2 = OptimalInvest(10.,r,Covar);; ; cout << ""stock daily daily w1 w2"" <<endl;; cout << ""symb return sdv "" <<endl;; for (Int_t i = 0; i < nrStocks; i++); printf(""%s\t: %.3f %.3f %.3f %.3f\n"",stocks[i],r[i],TMath::Sqrt(Covar[i][i]),weight1[i],weight2[i]);; ; TCanvas *c1 = new TCanvas(""c1"",""Portfolio Optimizations"",10,10,800,900);; c1->Divide(1,2);; ; // utility function / risk profile; ; c1->cd(1);; gPad->SetGridx();; gPad->SetGridy();; ; TF1 *f1 = new TF1(""f1"",RiskProfile,0,2.5,1);; f1->SetParameter(0,2.0);; f1->SetLineColor(49);; f1->Draw(""AC"");; f1->GetHistogram()->SetXTitle(""dollar"");; f1->GetHistogram()->SetYTitle(""utility"");; f1->GetHistogram()->SetMinimum(0.0);; f1->GetHistogram()->SetMaximum(1.0);; TF1 *f2 = new TF1(""f2"",RiskProfile,0,2.5,1);; f2->SetParameter(0,10.);; f2->SetLineColor(50);; f2->Draw(""CSAME"");; ; TLegend *legend1 = new TLegend(0.50,0.65,0.70,0.82);; legend1->AddEntry(f1,""1-exp(-2.0*x)"",""l"");; legend1->AddEntry(f2,""1-exp(-10.*x)"",""l"");; legend1->Draw();; ; // vertical bar chart of portfolio distribution; ; c1->cd(2);; TH1F *h1 = new TH1F(""h1"",""Portfolio Distribution"",nrStocks,0,0);; TH1F *h2 = new TH1F(""h2"",""Portfolio Distribution"",nrStocks,0,0);; h1->SetStats(0);; h1->SetFillColor(49);; h2->SetFillColor(50);; h1->SetBarWidth(0.45);; h1->SetBarOffset(0.1);; h2->SetBarWidth(0.4);; h2->SetBa",MatchSource.WIKI,doc/master/portfolio_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/portfolio_8C.html
https://root.cern/doc/master/portfolio_8C.html:13416,Safety,risk,risk,13416,"ity"");; f1->GetHistogram()->SetMinimum(0.0);; f1->GetHistogram()->SetMaximum(1.0);; TF1 *f2 = new TF1(""f2"",RiskProfile,0,2.5,1);; f2->SetParameter(0,10.);; f2->SetLineColor(50);; f2->Draw(""CSAME"");; ; TLegend *legend1 = new TLegend(0.50,0.65,0.70,0.82);; legend1->AddEntry(f1,""1-exp(-2.0*x)"",""l"");; legend1->AddEntry(f2,""1-exp(-10.*x)"",""l"");; legend1->Draw();; ; // vertical bar chart of portfolio distribution; ; c1->cd(2);; TH1F *h1 = new TH1F(""h1"",""Portfolio Distribution"",nrStocks,0,0);; TH1F *h2 = new TH1F(""h2"",""Portfolio Distribution"",nrStocks,0,0);; h1->SetStats(0);; h1->SetFillColor(49);; h2->SetFillColor(50);; h1->SetBarWidth(0.45);; h1->SetBarOffset(0.1);; h2->SetBarWidth(0.4);; h2->SetBarOffset(0.55);; for (Int_t i = 0; i < nrStocks; i++) {; h1->Fill(stocks[i],weight1[i]);; h2->Fill(stocks[i],weight2[i]);; }; ; h1->Draw(""BAR2 HIST"");; h2->Draw(""BAR2SAME HIST"");; ; TLegend *legend2 = new TLegend(0.50,0.65,0.70,0.82);; legend2->AddEntry(h1,""high risk"",""f"");; legend2->AddEntry(h2,""low risk"",""f"");; legend2->Draw();; }; b#define b(i)Definition RSha256.hxx:100; f#define f(i)Definition RSha256.hxx:104; c#define c(i)Definition RSha256.hxx:101; Riostream.h; Int_tint Int_tDefinition RtypesCore.h:45; Char_tchar Char_tDefinition RtypesCore.h:37; Double_tdouble Double_tDefinition RtypesCore.h:59; ClassDef#define ClassDef(name, id)Definition Rtypes.h:342; TArrayF.h; TCanvas.h; TF1.h; TFile.h; dataOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void dataDefinition TGWin32VirtualXProxy.cxx:104; rOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t rDefinition TGWin32VirtualXProxy.cxx:168; namechar name[80]Definition TGX11.cxx:110; TGondzioSolver.h; TH1.h; TLegend.h; TMath.h; TMatrixDSym.h; TMatrixD.h; TQpProbDens.h; Form",MatchSource.WIKI,doc/master/portfolio_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/portfolio_8C.html
https://root.cern/doc/master/portfolio_8C.html:13455,Safety,risk,risk,13455,"ity"");; f1->GetHistogram()->SetMinimum(0.0);; f1->GetHistogram()->SetMaximum(1.0);; TF1 *f2 = new TF1(""f2"",RiskProfile,0,2.5,1);; f2->SetParameter(0,10.);; f2->SetLineColor(50);; f2->Draw(""CSAME"");; ; TLegend *legend1 = new TLegend(0.50,0.65,0.70,0.82);; legend1->AddEntry(f1,""1-exp(-2.0*x)"",""l"");; legend1->AddEntry(f2,""1-exp(-10.*x)"",""l"");; legend1->Draw();; ; // vertical bar chart of portfolio distribution; ; c1->cd(2);; TH1F *h1 = new TH1F(""h1"",""Portfolio Distribution"",nrStocks,0,0);; TH1F *h2 = new TH1F(""h2"",""Portfolio Distribution"",nrStocks,0,0);; h1->SetStats(0);; h1->SetFillColor(49);; h2->SetFillColor(50);; h1->SetBarWidth(0.45);; h1->SetBarOffset(0.1);; h2->SetBarWidth(0.4);; h2->SetBarOffset(0.55);; for (Int_t i = 0; i < nrStocks; i++) {; h1->Fill(stocks[i],weight1[i]);; h2->Fill(stocks[i],weight2[i]);; }; ; h1->Draw(""BAR2 HIST"");; h2->Draw(""BAR2SAME HIST"");; ; TLegend *legend2 = new TLegend(0.50,0.65,0.70,0.82);; legend2->AddEntry(h1,""high risk"",""f"");; legend2->AddEntry(h2,""low risk"",""f"");; legend2->Draw();; }; b#define b(i)Definition RSha256.hxx:100; f#define f(i)Definition RSha256.hxx:104; c#define c(i)Definition RSha256.hxx:101; Riostream.h; Int_tint Int_tDefinition RtypesCore.h:45; Char_tchar Char_tDefinition RtypesCore.h:37; Double_tdouble Double_tDefinition RtypesCore.h:59; ClassDef#define ClassDef(name, id)Definition Rtypes.h:342; TArrayF.h; TCanvas.h; TF1.h; TFile.h; dataOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void dataDefinition TGWin32VirtualXProxy.cxx:104; rOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t rDefinition TGWin32VirtualXProxy.cxx:168; namechar name[80]Definition TGX11.cxx:110; TGondzioSolver.h; TH1.h; TLegend.h; TMath.h; TMatrixDSym.h; TMatrixD.h; TQpProbDens.h; Form",MatchSource.WIKI,doc/master/portfolio_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/portfolio_8C.html
https://root.cern/doc/master/portfolio_8C.html:16182,Safety,predict,predict,16182,"all=0)Read all leaves of entry and return total number of bytes read.Definition TBranch.cxx:1706; TCanvasThe Canvas class.Definition TCanvas.h:23; TF11-Dim function classDefinition TF1.h:233; TF1::GetHistogramvirtual TH1 * GetHistogram() constReturn a pointer to the histogram used to visualise the function Note that this histogram is managed ...Definition TF1.cxx:1584; TF1::Drawvoid Draw(Option_t *option="""") overrideDraw this function with its current attributes.Definition TF1.cxx:1333; TF1::SetParametervirtual void SetParameter(Int_t param, Double_t value)Definition TF1.h:667; TFileA ROOT file is an on-disk file, usually with extension .root, that stores objects in a file-system-li...Definition TFile.h:53; TFile::Openstatic TFile * Open(const char *name, Option_t *option="""", const char *ftitle="""", Int_t compress=ROOT::RCompressionSetting::EDefaults::kUseCompiledDefault, Int_t netopt=0)Create / open a file.Definition TFile.cxx:4089; TGondzioSolverDerived class of TQpSolverBase implementing Gondzio-correction version of Mehrotra's original predict...Definition TGondzioSolver.h:57; TGondzioSolver::SolveInt_t Solve(TQpDataBase *prob, TQpVar *iterate, TQpResidual *resid) overrideSolve the quadratic programming problem as formulated through prob, store the final solution in itera...Definition TGondzioSolver.cxx:129; TH1F1-D histogram with a float per channel (see TH1 documentation)Definition TH1.h:622; TH1::SetBarOffsetvirtual void SetBarOffset(Float_t offset=0.25)Set the bar offset as fraction of the bin width for drawing mode ""B"".Definition TH1.h:364; TH1::SetXTitlevirtual void SetXTitle(const char *title)Definition TH1.h:419; TH1::SetMaximumvirtual void SetMaximum(Double_t maximum=-1111)Definition TH1.h:404; TH1::Fillvirtual Int_t Fill(Double_t x)Increment bin with abscissa X by 1.Definition TH1.cxx:3344; TH1::Drawvoid Draw(Option_t *option="""") overrideDraw this histogram with options.Definition TH1.cxx:3066; TH1::SetMinimumvirtual void SetMinimum(Double_t minimum=-11",MatchSource.WIKI,doc/master/portfolio_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/portfolio_8C.html
https://root.cern/doc/master/portfolio_8C.html:5034,Security,expose,exposed,5034,"m Inc; BRCM : Broadcom Corp; TYC : Tyco International Ltd; IBM : International Business Machines Corp; AMAT : Applied Materials Inc; C : Citigroup Inc; PFE : Pfizer Inc; HD : Home Depot Inc. We calculate the optimal portfolio for 2.0 and 10.0 .; Food for thought :; We assumed that the stock returns have a Normal distribution . Check this assumption by histogramming the stock returns !; We used for the expected return in the objective function, the flat average over a time period . Investment firms will put significant resources in improving the return prediction .; If you want to trade significant number of shares, several other considerations have to be taken into account :; If you are going to buy, you will drive the price up (so-called ""slippage"") . This can be taken into account by adding terms to the objective (Google for ""slippage optimization""); FTC regulations might have to be added to the inequality constraints. Investment firms do not want to be exposed to the ""market"" as defined by a broad index like the S&P and ""hedge"" this exposure away . A perfect hedge this can be added as an equality constrain, otherwise add an inequality constrain . ; stock daily daily w1 w2; symb return sdv ; GE : 1.001 0.022 0.000 0.134; SUNW : 1.004 0.047 0.676 0.145; QCOM : 1.001 0.039 0.000 0.000; BRCM : 1.003 0.056 0.179 0.035; TYC : 1.001 0.042 0.145 0.069; IBM : 1.001 0.023 0.000 0.096; AMAT : 1.001 0.040 0.000 0.000; C : 1.000 0.023 0.000 0.000; PFE : 1.000 0.019 0.000 0.424; HD : 1.001 0.029 0.000 0.098; ; #include ""Riostream.h""; #include ""TCanvas.h""; #include ""TFile.h""; #include ""TMath.h""; #include ""TTree.h""; #include ""TArrayF.h""; #include ""TH1.h""; #include ""TF1.h""; #include ""TLegend.h""; #include ""TSystem.h""; ; #include ""TMatrixD.h""; #include ""TMatrixDSym.h""; #include ""TVectorD.h""; #include ""TQpProbDens.h""; #include ""TGondzioSolver.h""; ; const Int_t nrStocks = 10;; static const Char_t *stocks[] =; {""GE"",""SUNW"",""QCOM"",""BRCM"",""TYC"",""IBM"",""AMAT"",""C"",""PFE"",""HD""};; ; class TSto",MatchSource.WIKI,doc/master/portfolio_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/portfolio_8C.html
https://root.cern/doc/master/portfolio_8C.html:11043,Security,access,accessing,11043,"ndzioSolver or TMehrotraSolver; // The Gondzio method is more sophisticated and therefore numerically more involved; // If one want the Mehrotra method, simply replace ""Gondzio"" by ""Mehrotra"" .; ; TGondzioSolver *s = new TGondzioSolver(qp,prob);; const Int_t status = s->Solve(prob,vars,resid);; ; const TVectorD weight = vars->fX;; ; delete qp; delete prob; delete vars; delete resid; delete s;; if (status != 0) {; cout << ""Could not solve this problem."" <<endl;; return TVectorD(nrStocks);; }; ; return weight;; }; #endif; ; //---------------------------------------------------------------------------; void portfolio(); {; const Int_t sDay = 20000809;; const Int_t eDay = 20040602;; ; const char *fname = ""stock.root"";; TFile *f = 0;; if (!gSystem->AccessPathName(fname)) {; f = TFile::Open(fname);; } else if (!gSystem->AccessPathName(Form(""%s/quadp/%s"", TROOT::GetTutorialDir().Data(), fname))) {; f = TFile::Open(Form(""%s/quadp/%s"", TROOT::GetTutorialDir().Data(), fname));; } else {; printf(""accessing %s file from http://root.cern/files\n"",fname);; f = TFile::Open(Form(""http://root.cern/files/%s"",fname));; }; if (!f) return;; ; TArrayF *data = new TArrayF[nrStocks];; for (Int_t i = 0; i < nrStocks; i++) {; const TString symbol = stocks[i];; data[i] = StockReturn(f,symbol,sDay,eDay);; }; ; const Int_t nrData = data[0].GetSize();; ; TVectorD r(nrStocks);; for (Int_t i = 0; i < nrStocks; i++); r[i] = data[i].GetSum()/nrData;; ; TMatrixDSym Covar(nrStocks);; for (Int_t i = 0; i < nrStocks; i++) {; for (Int_t j = 0; j <= i; j++) {; Double_t sum = 0.;; for (Int_t k = 0; k < nrData; k++) {; sum += (data[i][k] - r[i]) * (data[j][k] - r[j]);; }; Covar(i,j) = Covar(j,i) = sum/nrData;; }; }; ; const TVectorD weight1 = OptimalInvest(2.0,r,Covar);; const TVectorD weight2 = OptimalInvest(10.,r,Covar);; ; cout << ""stock daily daily w1 w2"" <<endl;; cout << ""symb return sdv "" <<endl;; for (Int_t i = 0; i < nrStocks; i++); printf(""%s\t: %.3f %.3f %.3f %.3f\n"",stocks[i],r[i],TMath::Sqrt(Cova",MatchSource.WIKI,doc/master/portfolio_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/portfolio_8C.html
https://root.cern/doc/master/portfolio_8C.html:19254,Security,access,access,19254,"x:182; TQpProbDens::MakeDatavirtual TQpDataBase * MakeData(Double_t *c, Double_t *Q, Double_t *xlo, Bool_t *ixlo, Double_t *xup, Bool_t *ixup, Double_t *A, Double_t *bA, Double_t *C, Double_t *clo, Bool_t *iclo, Double_t *cup, Bool_t *icup)Setup the data.Definition TQpProbDens.cxx:80; TQpProbDens::MakeResidualsTQpResidual * MakeResiduals(const TQpDataBase *data) overrideSetup the residuals.Definition TQpProbDens.cxx:172; TQpResidualThe Residuals class calculates and stores the quantities that appear on the right-hand side of the li...Definition TQpResidual.h:62; TQpVarClass containing the variables for the general QP formulation.Definition TQpVar.h:60; TQpVar::fXTVectorD fXDefinition TQpVar.h:91; TROOT::GetTutorialDirstatic const TString & GetTutorialDir()Get the tutorials directory in the installation. Static utility function.Definition TROOT.cxx:3119; TStringBasic string class.Definition TString.h:139; TSystem::AccessPathNamevirtual Bool_t AccessPathName(const char *path, EAccessMode mode=kFileExists)Returns FALSE if one can access a file using the specified access mode.Definition TSystem.cxx:1296; TTreeA TTree represents a columnar dataset.Definition TTree.h:79; TTree::GetBranchvirtual TBranch * GetBranch(const char *name)Return pointer to the branch with the given name in this tree or its friends.Definition TTree.cxx:5294; TTree::SetBranchAddressvirtual Int_t SetBranchAddress(const char *bname, void *add, TBranch **ptr=nullptr)Change branch address, dealing with clone trees properly.Definition TTree.cxx:8385; TTree::GetEntriesvirtual Long64_t GetEntries() constDefinition TTree.h:463; TVectorT< Double_t >; c1return c1Definition legend1.C:41; xDouble_t x[n]Definition legend1.C:17; h1TH1F * h1Definition legend1.C:5; f1TF1 * f1Definition legend1.C:11; TMVA_SOFIE_GNN_Parser.h2h2Definition TMVA_SOFIE_GNN_Parser.py:188; TMath::Cconstexpr Double_t C()Velocity of light in .Definition TMath.h:114; TMath::ExpDouble_t Exp(Double_t x)Returns the base-e exponential function o",MatchSource.WIKI,doc/master/portfolio_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/portfolio_8C.html
https://root.cern/doc/master/portfolio_8C.html:19288,Security,access,access,19288,"x:182; TQpProbDens::MakeDatavirtual TQpDataBase * MakeData(Double_t *c, Double_t *Q, Double_t *xlo, Bool_t *ixlo, Double_t *xup, Bool_t *ixup, Double_t *A, Double_t *bA, Double_t *C, Double_t *clo, Bool_t *iclo, Double_t *cup, Bool_t *icup)Setup the data.Definition TQpProbDens.cxx:80; TQpProbDens::MakeResidualsTQpResidual * MakeResiduals(const TQpDataBase *data) overrideSetup the residuals.Definition TQpProbDens.cxx:172; TQpResidualThe Residuals class calculates and stores the quantities that appear on the right-hand side of the li...Definition TQpResidual.h:62; TQpVarClass containing the variables for the general QP formulation.Definition TQpVar.h:60; TQpVar::fXTVectorD fXDefinition TQpVar.h:91; TROOT::GetTutorialDirstatic const TString & GetTutorialDir()Get the tutorials directory in the installation. Static utility function.Definition TROOT.cxx:3119; TStringBasic string class.Definition TString.h:139; TSystem::AccessPathNamevirtual Bool_t AccessPathName(const char *path, EAccessMode mode=kFileExists)Returns FALSE if one can access a file using the specified access mode.Definition TSystem.cxx:1296; TTreeA TTree represents a columnar dataset.Definition TTree.h:79; TTree::GetBranchvirtual TBranch * GetBranch(const char *name)Return pointer to the branch with the given name in this tree or its friends.Definition TTree.cxx:5294; TTree::SetBranchAddressvirtual Int_t SetBranchAddress(const char *bname, void *add, TBranch **ptr=nullptr)Change branch address, dealing with clone trees properly.Definition TTree.cxx:8385; TTree::GetEntriesvirtual Long64_t GetEntries() constDefinition TTree.h:463; TVectorT< Double_t >; c1return c1Definition legend1.C:41; xDouble_t x[n]Definition legend1.C:17; h1TH1F * h1Definition legend1.C:5; f1TF1 * f1Definition legend1.C:11; TMVA_SOFIE_GNN_Parser.h2h2Definition TMVA_SOFIE_GNN_Parser.py:188; TMath::Cconstexpr Double_t C()Velocity of light in .Definition TMath.h:114; TMath::ExpDouble_t Exp(Double_t x)Returns the base-e exponential function o",MatchSource.WIKI,doc/master/portfolio_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/portfolio_8C.html
https://root.cern/doc/master/portfolio_8C.html:2590,Usability,clear,clear,2590,"ven stable for problems involving for instance 500 variables, 100 inequality conditions and 50 equality conditions .; Enough said about quadratic programming, let's return to our example . Suppose, after a long day of doing physics, you have a look at your investments and realize that an early retirement is not possible, given the returns of your stocks . So what now ? ROOT to the rescue ...; In 1990 Harry Markowitz was awarded the Nobel prize for economics: "" his work provided new tools; for weighing the risks and rewards of different investments and for valuing corporate stocks and bonds"" . In plain English, he developed the tools to balance greed and fear, we want the maximum return with the minimum amount of risk. Our stock portfolio should be at the ""Efficient Frontier"". To quantify better the risk we are willing to take, we define a utility function \( U(x) \). It describes as a function of our total assets \( x \), our ""satisfaction"" . A common choice is \( 1-exp(-k*x) \) (the reason for the exponent will be clear later) . The parameter \( k \) is the risk-aversion factor . For small values of \( k \) the satisfaction is small for small values of \( x \); by increasing \( x \) the satisfaction can still be increased significantly . For large values of \( k \), \( U(x) \) increases rapidly to 1, there is no increase in satisfaction for additional dollars earned .; In summary :; small \( k \) ==> risk-loving investor; large \( k \) ==> risk-averse investor. Suppose we have for nrStocks the historical daily returns \( r = closing_price(n) - closing_price(n-1) \). Define a vector \( x \) of length of \( nrStocks \), which contains the fraction of our money invested in each stock . We can calculate the average daily return \( z \) of our portfolio and its variance using the portfolio covariance Covar :; \( z = r^T x \) and \( var = x^T Covar x \); Assuming that the daily returns have a Normal distribution, \( N(x) \), so will \( z \) with mean \( r^T x \) and varia",MatchSource.WIKI,doc/master/portfolio_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/portfolio_8C.html
https://root.cern/doc/master/portfolio_8C.html:8062,Usability,simpl,simple,8062,"tDaily = (TTree*)f->Get(name);; TStockDaily *data = 0;; tDaily->SetBranchAddress(""daily"",&data);; TBranch *b_closeAdj = tDaily->GetBranch(""fCloseAdj"");; TBranch *b_date = tDaily->GetBranch(""fDate"");; ; //read only the ""adjusted close"" branch for all entries; const Int_t nrEntries = (Int_t)tDaily->GetEntries();; TArrayF closeAdj(nrEntries);; for (Int_t i = 0; i < nrEntries; i++) {; b_date->GetEntry(i);; b_closeAdj->GetEntry(i);; if (data->fDate >= sDay && data->fDate <= eDay); closeAdj[i] = data->fCloseAdj/100.;; }; ; TArrayF *r = new TArrayF(nrEntries-1);; for (Int_t i = 1; i < nrEntries; i++); // (*r)[i-1] = closeAdj[i]-closeAdj[i-1];; (*r)[i-1] = closeAdj[i]/closeAdj[i-1];; ; return *r;; }; ; #ifndef __MAKECINT__; //---------------------------------------------------------------------------; TVectorD OptimalInvest(Double_t riskFactor,TVectorD r,TMatrixDSym Covar); {; // what the quadratic programming package will do:; //; // minimize c^T x + ( 1/2 ) x^T Q x; // subject to A x = b; // clo <= C x <= cup; // xlo <= x <= xup; // what we want :; //; // maximize c^T x - k ( 1/2 ) x^T Q x; // subject to sum_x x_i = 1; // 0 <= x_i; ; // We have nrStocks weights to determine,; // 1 equality- and 0 inequality- equations (the simple square boundary; // condition (xlo <= x <= xup) does not count); ; const Int_t nrVar = nrStocks;; const Int_t nrEqual = 1;; const Int_t nrInEqual = 0;; ; // flip the sign of the objective function because we want to maximize; TVectorD c = -1.*r;; TMatrixDSym Q = riskFactor*Covar;; ; // equality equation; TMatrixD A(nrEqual,nrVar); A = 1;; TVectorD b(nrEqual); b = 1;; ; // inequality equation; //; // - although not applicable in the current situation since nrInEqual = 0, one; // has to specify not only clo and cup but also an index vector iclo and icup,; // whose values are either 0 or 1 . If iclo[j] = 1, the lower boundary condition; // is active on x[j], etc. ...; ; TMatrixD C (nrInEqual,nrVar);; TVectorD clo (nrInEqual);; TVectorD cup (nrInEqual",MatchSource.WIKI,doc/master/portfolio_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/portfolio_8C.html
https://root.cern/doc/master/portfolio_8C.html:8889,Usability,simpl,simple,8889,"o <= x <= xup; // what we want :; //; // maximize c^T x - k ( 1/2 ) x^T Q x; // subject to sum_x x_i = 1; // 0 <= x_i; ; // We have nrStocks weights to determine,; // 1 equality- and 0 inequality- equations (the simple square boundary; // condition (xlo <= x <= xup) does not count); ; const Int_t nrVar = nrStocks;; const Int_t nrEqual = 1;; const Int_t nrInEqual = 0;; ; // flip the sign of the objective function because we want to maximize; TVectorD c = -1.*r;; TMatrixDSym Q = riskFactor*Covar;; ; // equality equation; TMatrixD A(nrEqual,nrVar); A = 1;; TVectorD b(nrEqual); b = 1;; ; // inequality equation; //; // - although not applicable in the current situation since nrInEqual = 0, one; // has to specify not only clo and cup but also an index vector iclo and icup,; // whose values are either 0 or 1 . If iclo[j] = 1, the lower boundary condition; // is active on x[j], etc. ...; ; TMatrixD C (nrInEqual,nrVar);; TVectorD clo (nrInEqual);; TVectorD cup (nrInEqual);; TVectorD iclo(nrInEqual);; TVectorD icup(nrInEqual);; ; // simple square boundary condition : 0 <= x_i, so only xlo is relevant .; // Like for clo and cup above, we have to define an index vector ixlo and ixup .; // Since each variable has the lower boundary, we can set the whole vector; // ixlo = 1; ; TVectorD xlo (nrVar); xlo = 0;; TVectorD xup (nrVar); xup = 0;; TVectorD ixlo(nrVar); ixlo = 1;; TVectorD ixup(nrVar); ixup = 0;; ; // setup the quadratic programming problem . Since a small number of variables are; // involved and ""Q"" has everywhere entries, we chose the dense version ""TQpProbDens"" .; // In case of a sparse formulation, simply replace all ""Dens"" by ""Sparse"" below and; // use TMatrixDSparse instead of TMatrixDSym and TMatrixD; ; TQpProbDens *qp = new TQpProbDens(nrVar,nrEqual,nrInEqual);; ; // stuff all the matrices/vectors defined above in the proper places; ; TQpDataDens *prob = (TQpDataDens *)qp->MakeData(c,Q,xlo,ixlo,xup,ixup,A,b,C,clo,iclo,cup,icup);; ; // setup the nrStock variables, ",MatchSource.WIKI,doc/master/portfolio_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/portfolio_8C.html
https://root.cern/doc/master/portfolio_8C.html:9474,Usability,simpl,simply,9474,"orD iclo(nrInEqual);; TVectorD icup(nrInEqual);; ; // simple square boundary condition : 0 <= x_i, so only xlo is relevant .; // Like for clo and cup above, we have to define an index vector ixlo and ixup .; // Since each variable has the lower boundary, we can set the whole vector; // ixlo = 1; ; TVectorD xlo (nrVar); xlo = 0;; TVectorD xup (nrVar); xup = 0;; TVectorD ixlo(nrVar); ixlo = 1;; TVectorD ixup(nrVar); ixup = 0;; ; // setup the quadratic programming problem . Since a small number of variables are; // involved and ""Q"" has everywhere entries, we chose the dense version ""TQpProbDens"" .; // In case of a sparse formulation, simply replace all ""Dens"" by ""Sparse"" below and; // use TMatrixDSparse instead of TMatrixDSym and TMatrixD; ; TQpProbDens *qp = new TQpProbDens(nrVar,nrEqual,nrInEqual);; ; // stuff all the matrices/vectors defined above in the proper places; ; TQpDataDens *prob = (TQpDataDens *)qp->MakeData(c,Q,xlo,ixlo,xup,ixup,A,b,C,clo,iclo,cup,icup);; ; // setup the nrStock variables, vars->fX will contain the final solution; ; TQpVar *vars = qp->MakeVariables(prob);; TQpResidual *resid = qp->MakeResiduals(prob);; ; // Now we have to choose the method of solving, either TGondzioSolver or TMehrotraSolver; // The Gondzio method is more sophisticated and therefore numerically more involved; // If one want the Mehrotra method, simply replace ""Gondzio"" by ""Mehrotra"" .; ; TGondzioSolver *s = new TGondzioSolver(qp,prob);; const Int_t status = s->Solve(prob,vars,resid);; ; const TVectorD weight = vars->fX;; ; delete qp; delete prob; delete vars; delete resid; delete s;; if (status != 0) {; cout << ""Could not solve this problem."" <<endl;; return TVectorD(nrStocks);; }; ; return weight;; }; #endif; ; //---------------------------------------------------------------------------; void portfolio(); {; const Int_t sDay = 20000809;; const Int_t eDay = 20040602;; ; const char *fname = ""stock.root"";; TFile *f = 0;; if (!gSystem->AccessPathName(fname)) {; f = TFile::Ope",MatchSource.WIKI,doc/master/portfolio_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/portfolio_8C.html
https://root.cern/doc/master/portfolio_8C.html:10195,Usability,simpl,simply,10195,"orD iclo(nrInEqual);; TVectorD icup(nrInEqual);; ; // simple square boundary condition : 0 <= x_i, so only xlo is relevant .; // Like for clo and cup above, we have to define an index vector ixlo and ixup .; // Since each variable has the lower boundary, we can set the whole vector; // ixlo = 1; ; TVectorD xlo (nrVar); xlo = 0;; TVectorD xup (nrVar); xup = 0;; TVectorD ixlo(nrVar); ixlo = 1;; TVectorD ixup(nrVar); ixup = 0;; ; // setup the quadratic programming problem . Since a small number of variables are; // involved and ""Q"" has everywhere entries, we chose the dense version ""TQpProbDens"" .; // In case of a sparse formulation, simply replace all ""Dens"" by ""Sparse"" below and; // use TMatrixDSparse instead of TMatrixDSym and TMatrixD; ; TQpProbDens *qp = new TQpProbDens(nrVar,nrEqual,nrInEqual);; ; // stuff all the matrices/vectors defined above in the proper places; ; TQpDataDens *prob = (TQpDataDens *)qp->MakeData(c,Q,xlo,ixlo,xup,ixup,A,b,C,clo,iclo,cup,icup);; ; // setup the nrStock variables, vars->fX will contain the final solution; ; TQpVar *vars = qp->MakeVariables(prob);; TQpResidual *resid = qp->MakeResiduals(prob);; ; // Now we have to choose the method of solving, either TGondzioSolver or TMehrotraSolver; // The Gondzio method is more sophisticated and therefore numerically more involved; // If one want the Mehrotra method, simply replace ""Gondzio"" by ""Mehrotra"" .; ; TGondzioSolver *s = new TGondzioSolver(qp,prob);; const Int_t status = s->Solve(prob,vars,resid);; ; const TVectorD weight = vars->fX;; ; delete qp; delete prob; delete vars; delete resid; delete s;; if (status != 0) {; cout << ""Could not solve this problem."" <<endl;; return TVectorD(nrStocks);; }; ; return weight;; }; #endif; ; //---------------------------------------------------------------------------; void portfolio(); {; const Int_t sDay = 20000809;; const Int_t eDay = 20040602;; ; const char *fname = ""stock.root"";; TFile *f = 0;; if (!gSystem->AccessPathName(fname)) {; f = TFile::Ope",MatchSource.WIKI,doc/master/portfolio_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/portfolio_8C.html
https://root.cern/doc/master/principal_8py_source.html:986,Integrability,depend,dependent,986,". ROOT: tutorials/math/principal.py Source File. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. principal.py. Go to the documentation of this file. 1## \file; 2## \ingroup tutorial_math; 3## \notebook; 4## Principal Components Analysis (PCA) example; 5##; 6## Example of using TPrincipal as a stand alone class.; 7##; 8## I create n-dimensional data points, where c = trunc(n / 5) + 1; 9## are correlated with the rest n - c randomly distributed variables.; 10##; 11## Based on principal.C by Rene Brun and Christian Holm Christensen; 12##; 13## \macro_output; 14## \macro_code; 15##; 16## \authors Juan Fernando, Jaramillo Botero; 17 ; 18from ROOT import TPrincipal, gRandom, TBrowser, vector; 19 ; 20 ; 21n = 10; 22m = 10000; 23 ; 24c = int(n / 5) + 1; 25 ; 26print (""""""*************************************************; 27* Principal Component Analysis *; 28* *; 29* Number of variables: {0:4d} *; 30* Number of data points: {1:8d} *; 31* Number of dependent variables: {2:4d} *; 32* *; 33*************************************************"""""".format(n, m, c)); 34 ; 35# Initilase the TPrincipal object. Use the empty string for the; 36# final argument, if you don't wan't the covariance; 37# matrix. Normalising the covariance matrix is a good idea if your; 38# variables have different orders of magnitude.; 39principal = TPrincipal(n, ""ND""); 40 ; 41# Use a pseudo-random number generator; 42randomNum = gRandom; 43 ; 44# Make the m data-points; 45# Make a variable to hold our data; 46# Allocate memory for the data point; 47data = vector('double')(); 48for i in range(m):; 49 # First we create the un-correlated, random variables, according; 50 # to one of three distributions; 51 for j in range(n - c):; 52 if j % 3 == 0:; 53 data.push_back(randomNum.Gaus(5, 1)); 54 elif j % 3 == 1:; 55 data.push_back(randomNum.Poisson(8)); 56 else:; 57 data.push_back(randomNum.Exp(2)); 58 ; 59 # Then we create the correlated variables; 60 for j in range(c):; 61 data.push_b",MatchSource.WIKI,doc/master/principal_8py_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/principal_8py_source.html
https://root.cern/doc/master/principal_8py_source.html:480,Modifiability,variab,variables,480,". ROOT: tutorials/math/principal.py Source File. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. principal.py. Go to the documentation of this file. 1## \file; 2## \ingroup tutorial_math; 3## \notebook; 4## Principal Components Analysis (PCA) example; 5##; 6## Example of using TPrincipal as a stand alone class.; 7##; 8## I create n-dimensional data points, where c = trunc(n / 5) + 1; 9## are correlated with the rest n - c randomly distributed variables.; 10##; 11## Based on principal.C by Rene Brun and Christian Holm Christensen; 12##; 13## \macro_output; 14## \macro_code; 15##; 16## \authors Juan Fernando, Jaramillo Botero; 17 ; 18from ROOT import TPrincipal, gRandom, TBrowser, vector; 19 ; 20 ; 21n = 10; 22m = 10000; 23 ; 24c = int(n / 5) + 1; 25 ; 26print (""""""*************************************************; 27* Principal Component Analysis *; 28* *; 29* Number of variables: {0:4d} *; 30* Number of data points: {1:8d} *; 31* Number of dependent variables: {2:4d} *; 32* *; 33*************************************************"""""".format(n, m, c)); 34 ; 35# Initilase the TPrincipal object. Use the empty string for the; 36# final argument, if you don't wan't the covariance; 37# matrix. Normalising the covariance matrix is a good idea if your; 38# variables have different orders of magnitude.; 39principal = TPrincipal(n, ""ND""); 40 ; 41# Use a pseudo-random number generator; 42randomNum = gRandom; 43 ; 44# Make the m data-points; 45# Make a variable to hold our data; 46# Allocate memory for the data point; 47data = vector('double')(); 48for i in range(m):; 49 # First we create the un-correlated, random variables, according; 50 # to one of three distributions; 51 for j in range(n - c):; 52 if j % 3 == 0:; 53 data.push_back(randomNum.Gaus(5, 1)); 54 elif j % 3 == 1:; 55 data.push_back(randomNum.Poisson(8)); 56 else:; 57 data.push_back(randomNum.Exp(2)); 58 ; 59 # Then we create the correlated variables; 60 for j in range(c):; 61 data.push_b",MatchSource.WIKI,doc/master/principal_8py_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/principal_8py_source.html
https://root.cern/doc/master/principal_8py_source.html:914,Modifiability,variab,variables,914,". ROOT: tutorials/math/principal.py Source File. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. principal.py. Go to the documentation of this file. 1## \file; 2## \ingroup tutorial_math; 3## \notebook; 4## Principal Components Analysis (PCA) example; 5##; 6## Example of using TPrincipal as a stand alone class.; 7##; 8## I create n-dimensional data points, where c = trunc(n / 5) + 1; 9## are correlated with the rest n - c randomly distributed variables.; 10##; 11## Based on principal.C by Rene Brun and Christian Holm Christensen; 12##; 13## \macro_output; 14## \macro_code; 15##; 16## \authors Juan Fernando, Jaramillo Botero; 17 ; 18from ROOT import TPrincipal, gRandom, TBrowser, vector; 19 ; 20 ; 21n = 10; 22m = 10000; 23 ; 24c = int(n / 5) + 1; 25 ; 26print (""""""*************************************************; 27* Principal Component Analysis *; 28* *; 29* Number of variables: {0:4d} *; 30* Number of data points: {1:8d} *; 31* Number of dependent variables: {2:4d} *; 32* *; 33*************************************************"""""".format(n, m, c)); 34 ; 35# Initilase the TPrincipal object. Use the empty string for the; 36# final argument, if you don't wan't the covariance; 37# matrix. Normalising the covariance matrix is a good idea if your; 38# variables have different orders of magnitude.; 39principal = TPrincipal(n, ""ND""); 40 ; 41# Use a pseudo-random number generator; 42randomNum = gRandom; 43 ; 44# Make the m data-points; 45# Make a variable to hold our data; 46# Allocate memory for the data point; 47data = vector('double')(); 48for i in range(m):; 49 # First we create the un-correlated, random variables, according; 50 # to one of three distributions; 51 for j in range(n - c):; 52 if j % 3 == 0:; 53 data.push_back(randomNum.Gaus(5, 1)); 54 elif j % 3 == 1:; 55 data.push_back(randomNum.Poisson(8)); 56 else:; 57 data.push_back(randomNum.Exp(2)); 58 ; 59 # Then we create the correlated variables; 60 for j in range(c):; 61 data.push_b",MatchSource.WIKI,doc/master/principal_8py_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/principal_8py_source.html
https://root.cern/doc/master/principal_8py_source.html:996,Modifiability,variab,variables,996,". ROOT: tutorials/math/principal.py Source File. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. principal.py. Go to the documentation of this file. 1## \file; 2## \ingroup tutorial_math; 3## \notebook; 4## Principal Components Analysis (PCA) example; 5##; 6## Example of using TPrincipal as a stand alone class.; 7##; 8## I create n-dimensional data points, where c = trunc(n / 5) + 1; 9## are correlated with the rest n - c randomly distributed variables.; 10##; 11## Based on principal.C by Rene Brun and Christian Holm Christensen; 12##; 13## \macro_output; 14## \macro_code; 15##; 16## \authors Juan Fernando, Jaramillo Botero; 17 ; 18from ROOT import TPrincipal, gRandom, TBrowser, vector; 19 ; 20 ; 21n = 10; 22m = 10000; 23 ; 24c = int(n / 5) + 1; 25 ; 26print (""""""*************************************************; 27* Principal Component Analysis *; 28* *; 29* Number of variables: {0:4d} *; 30* Number of data points: {1:8d} *; 31* Number of dependent variables: {2:4d} *; 32* *; 33*************************************************"""""".format(n, m, c)); 34 ; 35# Initilase the TPrincipal object. Use the empty string for the; 36# final argument, if you don't wan't the covariance; 37# matrix. Normalising the covariance matrix is a good idea if your; 38# variables have different orders of magnitude.; 39principal = TPrincipal(n, ""ND""); 40 ; 41# Use a pseudo-random number generator; 42randomNum = gRandom; 43 ; 44# Make the m data-points; 45# Make a variable to hold our data; 46# Allocate memory for the data point; 47data = vector('double')(); 48for i in range(m):; 49 # First we create the un-correlated, random variables, according; 50 # to one of three distributions; 51 for j in range(n - c):; 52 if j % 3 == 0:; 53 data.push_back(randomNum.Gaus(5, 1)); 54 elif j % 3 == 1:; 55 data.push_back(randomNum.Poisson(8)); 56 else:; 57 data.push_back(randomNum.Exp(2)); 58 ; 59 # Then we create the correlated variables; 60 for j in range(c):; 61 data.push_b",MatchSource.WIKI,doc/master/principal_8py_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/principal_8py_source.html
https://root.cern/doc/master/principal_8py_source.html:1298,Modifiability,variab,variables,1298," 6## Example of using TPrincipal as a stand alone class.; 7##; 8## I create n-dimensional data points, where c = trunc(n / 5) + 1; 9## are correlated with the rest n - c randomly distributed variables.; 10##; 11## Based on principal.C by Rene Brun and Christian Holm Christensen; 12##; 13## \macro_output; 14## \macro_code; 15##; 16## \authors Juan Fernando, Jaramillo Botero; 17 ; 18from ROOT import TPrincipal, gRandom, TBrowser, vector; 19 ; 20 ; 21n = 10; 22m = 10000; 23 ; 24c = int(n / 5) + 1; 25 ; 26print (""""""*************************************************; 27* Principal Component Analysis *; 28* *; 29* Number of variables: {0:4d} *; 30* Number of data points: {1:8d} *; 31* Number of dependent variables: {2:4d} *; 32* *; 33*************************************************"""""".format(n, m, c)); 34 ; 35# Initilase the TPrincipal object. Use the empty string for the; 36# final argument, if you don't wan't the covariance; 37# matrix. Normalising the covariance matrix is a good idea if your; 38# variables have different orders of magnitude.; 39principal = TPrincipal(n, ""ND""); 40 ; 41# Use a pseudo-random number generator; 42randomNum = gRandom; 43 ; 44# Make the m data-points; 45# Make a variable to hold our data; 46# Allocate memory for the data point; 47data = vector('double')(); 48for i in range(m):; 49 # First we create the un-correlated, random variables, according; 50 # to one of three distributions; 51 for j in range(n - c):; 52 if j % 3 == 0:; 53 data.push_back(randomNum.Gaus(5, 1)); 54 elif j % 3 == 1:; 55 data.push_back(randomNum.Poisson(8)); 56 else:; 57 data.push_back(randomNum.Exp(2)); 58 ; 59 # Then we create the correlated variables; 60 for j in range(c):; 61 data.push_back(0); 62 for k in range(n - c - j):; 63 data[n - c + j] += data[k]; 64 ; 65 # Finally we're ready to add this datapoint to the PCA; 66 principal.AddRow(data.data()); 67 data.clear(); 68 ; 69# Do the actual analysis; 70principal.MakePrincipals(); 71 ; 72# Print out the result on; 73prin",MatchSource.WIKI,doc/master/principal_8py_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/principal_8py_source.html
https://root.cern/doc/master/principal_8py_source.html:1494,Modifiability,variab,variable,1494,"hristensen; 12##; 13## \macro_output; 14## \macro_code; 15##; 16## \authors Juan Fernando, Jaramillo Botero; 17 ; 18from ROOT import TPrincipal, gRandom, TBrowser, vector; 19 ; 20 ; 21n = 10; 22m = 10000; 23 ; 24c = int(n / 5) + 1; 25 ; 26print (""""""*************************************************; 27* Principal Component Analysis *; 28* *; 29* Number of variables: {0:4d} *; 30* Number of data points: {1:8d} *; 31* Number of dependent variables: {2:4d} *; 32* *; 33*************************************************"""""".format(n, m, c)); 34 ; 35# Initilase the TPrincipal object. Use the empty string for the; 36# final argument, if you don't wan't the covariance; 37# matrix. Normalising the covariance matrix is a good idea if your; 38# variables have different orders of magnitude.; 39principal = TPrincipal(n, ""ND""); 40 ; 41# Use a pseudo-random number generator; 42randomNum = gRandom; 43 ; 44# Make the m data-points; 45# Make a variable to hold our data; 46# Allocate memory for the data point; 47data = vector('double')(); 48for i in range(m):; 49 # First we create the un-correlated, random variables, according; 50 # to one of three distributions; 51 for j in range(n - c):; 52 if j % 3 == 0:; 53 data.push_back(randomNum.Gaus(5, 1)); 54 elif j % 3 == 1:; 55 data.push_back(randomNum.Poisson(8)); 56 else:; 57 data.push_back(randomNum.Exp(2)); 58 ; 59 # Then we create the correlated variables; 60 for j in range(c):; 61 data.push_back(0); 62 for k in range(n - c - j):; 63 data[n - c + j] += data[k]; 64 ; 65 # Finally we're ready to add this datapoint to the PCA; 66 principal.AddRow(data.data()); 67 data.clear(); 68 ; 69# Do the actual analysis; 70principal.MakePrincipals(); 71 ; 72# Print out the result on; 73principal.Print(); 74 ; 75# Test the PCA; 76principal.Test(); 77 ; 78# Make some histograms of the original, principal, residue, etc data; 79principal.MakeHistograms(); 80 ; 81# Make two functions to map between feature and pattern space; 82# Start a browser, so that we m",MatchSource.WIKI,doc/master/principal_8py_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/principal_8py_source.html
https://root.cern/doc/master/principal_8py_source.html:1659,Modifiability,variab,variables,1659,"hristensen; 12##; 13## \macro_output; 14## \macro_code; 15##; 16## \authors Juan Fernando, Jaramillo Botero; 17 ; 18from ROOT import TPrincipal, gRandom, TBrowser, vector; 19 ; 20 ; 21n = 10; 22m = 10000; 23 ; 24c = int(n / 5) + 1; 25 ; 26print (""""""*************************************************; 27* Principal Component Analysis *; 28* *; 29* Number of variables: {0:4d} *; 30* Number of data points: {1:8d} *; 31* Number of dependent variables: {2:4d} *; 32* *; 33*************************************************"""""".format(n, m, c)); 34 ; 35# Initilase the TPrincipal object. Use the empty string for the; 36# final argument, if you don't wan't the covariance; 37# matrix. Normalising the covariance matrix is a good idea if your; 38# variables have different orders of magnitude.; 39principal = TPrincipal(n, ""ND""); 40 ; 41# Use a pseudo-random number generator; 42randomNum = gRandom; 43 ; 44# Make the m data-points; 45# Make a variable to hold our data; 46# Allocate memory for the data point; 47data = vector('double')(); 48for i in range(m):; 49 # First we create the un-correlated, random variables, according; 50 # to one of three distributions; 51 for j in range(n - c):; 52 if j % 3 == 0:; 53 data.push_back(randomNum.Gaus(5, 1)); 54 elif j % 3 == 1:; 55 data.push_back(randomNum.Poisson(8)); 56 else:; 57 data.push_back(randomNum.Exp(2)); 58 ; 59 # Then we create the correlated variables; 60 for j in range(c):; 61 data.push_back(0); 62 for k in range(n - c - j):; 63 data[n - c + j] += data[k]; 64 ; 65 # Finally we're ready to add this datapoint to the PCA; 66 principal.AddRow(data.data()); 67 data.clear(); 68 ; 69# Do the actual analysis; 70principal.MakePrincipals(); 71 ; 72# Print out the result on; 73principal.Print(); 74 ; 75# Test the PCA; 76principal.Test(); 77 ; 78# Make some histograms of the original, principal, residue, etc data; 79principal.MakeHistograms(); 80 ; 81# Make two functions to map between feature and pattern space; 82# Start a browser, so that we m",MatchSource.WIKI,doc/master/principal_8py_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/principal_8py_source.html
https://root.cern/doc/master/principal_8py_source.html:1953,Modifiability,variab,variables,1953,"data points: {1:8d} *; 31* Number of dependent variables: {2:4d} *; 32* *; 33*************************************************"""""".format(n, m, c)); 34 ; 35# Initilase the TPrincipal object. Use the empty string for the; 36# final argument, if you don't wan't the covariance; 37# matrix. Normalising the covariance matrix is a good idea if your; 38# variables have different orders of magnitude.; 39principal = TPrincipal(n, ""ND""); 40 ; 41# Use a pseudo-random number generator; 42randomNum = gRandom; 43 ; 44# Make the m data-points; 45# Make a variable to hold our data; 46# Allocate memory for the data point; 47data = vector('double')(); 48for i in range(m):; 49 # First we create the un-correlated, random variables, according; 50 # to one of three distributions; 51 for j in range(n - c):; 52 if j % 3 == 0:; 53 data.push_back(randomNum.Gaus(5, 1)); 54 elif j % 3 == 1:; 55 data.push_back(randomNum.Poisson(8)); 56 else:; 57 data.push_back(randomNum.Exp(2)); 58 ; 59 # Then we create the correlated variables; 60 for j in range(c):; 61 data.push_back(0); 62 for k in range(n - c - j):; 63 data[n - c + j] += data[k]; 64 ; 65 # Finally we're ready to add this datapoint to the PCA; 66 principal.AddRow(data.data()); 67 data.clear(); 68 ; 69# Do the actual analysis; 70principal.MakePrincipals(); 71 ; 72# Print out the result on; 73principal.Print(); 74 ; 75# Test the PCA; 76principal.Test(); 77 ; 78# Make some histograms of the original, principal, residue, etc data; 79principal.MakeHistograms(); 80 ; 81# Make two functions to map between feature and pattern space; 82# Start a browser, so that we may browse the histograms generated; 83# above; 84principal.MakeCode(); 85b = TBrowser(""principalBrowser"", principal); formatOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t Float_t Float_t Int_t Int_t UInt_t UInt_t Rectangle_t Int_t ",MatchSource.WIKI,doc/master/principal_8py_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/principal_8py_source.html
https://root.cern/doc/master/principal_8py_source.html:2177,Usability,clear,clear,2177,"n't the covariance; 37# matrix. Normalising the covariance matrix is a good idea if your; 38# variables have different orders of magnitude.; 39principal = TPrincipal(n, ""ND""); 40 ; 41# Use a pseudo-random number generator; 42randomNum = gRandom; 43 ; 44# Make the m data-points; 45# Make a variable to hold our data; 46# Allocate memory for the data point; 47data = vector('double')(); 48for i in range(m):; 49 # First we create the un-correlated, random variables, according; 50 # to one of three distributions; 51 for j in range(n - c):; 52 if j % 3 == 0:; 53 data.push_back(randomNum.Gaus(5, 1)); 54 elif j % 3 == 1:; 55 data.push_back(randomNum.Poisson(8)); 56 else:; 57 data.push_back(randomNum.Exp(2)); 58 ; 59 # Then we create the correlated variables; 60 for j in range(c):; 61 data.push_back(0); 62 for k in range(n - c - j):; 63 data[n - c + j] += data[k]; 64 ; 65 # Finally we're ready to add this datapoint to the PCA; 66 principal.AddRow(data.data()); 67 data.clear(); 68 ; 69# Do the actual analysis; 70principal.MakePrincipals(); 71 ; 72# Print out the result on; 73principal.Print(); 74 ; 75# Test the PCA; 76principal.Test(); 77 ; 78# Make some histograms of the original, principal, residue, etc data; 79principal.MakeHistograms(); 80 ; 81# Make two functions to map between feature and pattern space; 82# Start a browser, so that we may browse the histograms generated; 83# above; 84principal.MakeCode(); 85b = TBrowser(""principalBrowser"", principal); formatOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t Float_t Float_t Int_t Int_t UInt_t UInt_t Rectangle_t Int_t Int_t Window_t TString Int_t GCValues_t GetPrimarySelectionOwner GetDisplay GetScreen GetColormap GetNativeEvent const char const char dpyName wid window const char font_name cursor keysym reg const char only_if_exist regb h Point_t winding char text con",MatchSource.WIKI,doc/master/principal_8py_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/principal_8py_source.html
https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html:5296,Availability,error,errors,5296,"./(n-1)) * std::exp(-alpha*alpha/2.);; 136 intpow = C - A /(n-1.) * std::pow(B-z,-n+1) ;; 137 }; 138 else {; 139 // for n=1 the primitive of 1/x is log(x); 140 intpow = -A * std::log( n / abs_alpha ) + A * std::log( B -z );; 141 }; 142 intgaus = sqrtpiover2*(1.+ROOT::Math::erf(abs_alpha*oneoversqrt2));; 143 }; 144 else; 145 {; 146 intgaus = ROOT::Math::gaussian_cdf_c(z, 1);; 147 intgaus *= sqrt2pi;; 148 intpow = 0; ; 149 }; 150 return sigma * (intgaus + intpow);; 151 }; 152 ; 153 ; 154 double exponential_cdf_c(double x, double lambda, double x0); 155 {; 156 if ((x-x0) < 0) return 1.0;; 157 else return std::exp(- lambda * (x-x0));; 158 }; 159 ; 160 ; 161 double exponential_cdf(double x, double lambda, double x0); 162 {; 163 if ((x-x0) < 0) return 0.0;; 164 else // use expm1 function to avoid errors at small x; 165 return - ROOT::Math::expm1( - lambda * (x-x0) ) ;; 166 }; 167 ; 168 ; 169 double fdistribution_cdf_c(double x, double n, double m, double x0); 170 {; 171 // f distribution is defined only for both n and m > 0; 172 if (n < 0 || m < 0) return std::numeric_limits<double>::quiet_NaN();; 173 ; 174 double z = m/(m + n*(x-x0));; 175 // fox z->1 and large a and b IB looses precision use complement function; 176 if (z > 0.9 && n > 1 && m > 1) return 1.- fdistribution_cdf(x,n,m,x0);; 177 ; 178 // for the complement use the fact that IB(x,a,b) = 1. - IB(1-x,b,a); 179 return ROOT::Math::inc_beta(m/(m + n*(x-x0)), .5*m, .5*n);; 180 }; 181 ; 182 ; 183 double fdistribution_cdf(double x, double n, double m, double x0); 184 {; 185 // f distribution is defined only for both n and m > 0; 186 if (n < 0 || m < 0); 187 return std::numeric_limits<double>::quiet_NaN();; 188 ; 189 double z = n*(x-x0)/(m + n*(x-x0));; 190 // fox z->1 and large a and b IB looses precision use complement function; 191 if (z > 0.9 && n > 1 && m > 1); 192 return 1. - fdistribution_cdf_c(x,n,m,x0);; 193 ; 194 return ROOT::Math::inc_beta(z, .5*n, .5*m);; 195 }; 196 ; 197 ; 198 double gamma_cdf_c(double x,",MatchSource.WIKI,doc/master/ProbFuncMathCore_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html
https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html:27164,Availability,error,error,27164," ROOT::Math::tdistribution_cdf_cdouble tdistribution_cdf_c(double x, double r, double x0=0)Complement of the cumulative distribution function of Student's t-distribution (upper tail).Definition ProbFuncMathCore.cxx:242; ROOT::Math::gamma_cdfdouble gamma_cdf(double x, double alpha, double theta, double x0=0)Cumulative distribution function of the gamma distribution (lower tail).Definition ProbFuncMathCore.cxx:204; ROOT::Math::exponential_cdfdouble exponential_cdf(double x, double lambda, double x0=0)Cumulative distribution function of the exponential distribution (lower tail).Definition ProbFuncMathCore.cxx:161; ROOT::Math::inc_gamma_cdouble inc_gamma_c(double a, double x)Calculates the normalized (regularized) upper incomplete gamma function (upper integral)Definition SpecFuncMathCore.cxx:103; ROOT::Math::inc_betadouble inc_beta(double x, double a, double b)Calculates the normalized (regularized) incomplete beta function.Definition SpecFuncMathCore.cxx:115; ROOT::Math::erfcdouble erfc(double x)Complementary error function.Definition SpecFuncMathCore.cxx:44; ROOT::Math::inc_gammadouble inc_gamma(double a, double x)Calculates the normalized (regularized) lower incomplete gamma function (lower integral)Definition SpecFuncMathCore.cxx:99; ROOT::Math::erfdouble erf(double x)Error function encountered in integrating the normal distribution.Definition SpecFuncMathCore.cxx:59; ROOT::Math::landau_xm1double landau_xm1(double x, double xi=1, double x0=0)First moment (mean) of the truncated Landau distribution.Definition ProbFuncMathCore.cxx:409; ROOT::Math::landau_xm2double landau_xm2(double x, double xi=1, double x0=0)Second moment of the truncated Landau distribution.Definition ProbFuncMathCore.cxx:489; sigmaconst Double_t sigmaDefinition h1analysisProxy.h:11; xDouble_t x[n]Definition legend1.C:17; nconst Int_t nDefinition legend1.C:16; MathNamespace for new Math classes and functions.; ROOT::Math::expm1double expm1(double x)exp(x) -1 with error cancellation when x is smallDe",MatchSource.WIKI,doc/master/ProbFuncMathCore_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html
https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html:28106,Availability,error,error,28106,"gral)Definition SpecFuncMathCore.cxx:103; ROOT::Math::inc_betadouble inc_beta(double x, double a, double b)Calculates the normalized (regularized) incomplete beta function.Definition SpecFuncMathCore.cxx:115; ROOT::Math::erfcdouble erfc(double x)Complementary error function.Definition SpecFuncMathCore.cxx:44; ROOT::Math::inc_gammadouble inc_gamma(double a, double x)Calculates the normalized (regularized) lower incomplete gamma function (lower integral)Definition SpecFuncMathCore.cxx:99; ROOT::Math::erfdouble erf(double x)Error function encountered in integrating the normal distribution.Definition SpecFuncMathCore.cxx:59; ROOT::Math::landau_xm1double landau_xm1(double x, double xi=1, double x0=0)First moment (mean) of the truncated Landau distribution.Definition ProbFuncMathCore.cxx:409; ROOT::Math::landau_xm2double landau_xm2(double x, double xi=1, double x0=0)Second moment of the truncated Landau distribution.Definition ProbFuncMathCore.cxx:489; sigmaconst Double_t sigmaDefinition h1analysisProxy.h:11; xDouble_t x[n]Definition legend1.C:17; nconst Int_t nDefinition legend1.C:16; MathNamespace for new Math classes and functions.; ROOT::Math::expm1double expm1(double x)exp(x) -1 with error cancellation when x is smallDefinition Math.h:110; ROOT::Math::sqrtVecExpr< UnaryOp< Sqrt< T >, VecExpr< A, T, D >, T >, T, D > sqrt(const VecExpr< A, T, D > &rhs)Definition UnaryOperators.h:281; ROOT::Math::kSqrt2static const double kSqrt2Definition ProbFuncMathCore.cxx:18; ROOT::Math::gaussian_cdf_cdouble gaussian_cdf_c(double x, double sigma=1, double x0=0)Alternative name for same function.Definition ProbFuncMathCore.h:463; ROOTtbb::task_arena is an alias of tbb::interface7::task_arena, which doesn't allow to forward declare tb...Definition EExecutionPolicy.hxx:4; v@ vDefinition rootcling_impl.cxx:3699; mTMarker mDefinition textangle.C:8. mathmathcoresrcProbFuncMathCore.cxx. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:40:41 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/ProbFuncMathCore_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html
https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html:27461,Deployability,integrat,integrating,27461,"e x0=0)Cumulative distribution function of the gamma distribution (lower tail).Definition ProbFuncMathCore.cxx:204; ROOT::Math::exponential_cdfdouble exponential_cdf(double x, double lambda, double x0=0)Cumulative distribution function of the exponential distribution (lower tail).Definition ProbFuncMathCore.cxx:161; ROOT::Math::inc_gamma_cdouble inc_gamma_c(double a, double x)Calculates the normalized (regularized) upper incomplete gamma function (upper integral)Definition SpecFuncMathCore.cxx:103; ROOT::Math::inc_betadouble inc_beta(double x, double a, double b)Calculates the normalized (regularized) incomplete beta function.Definition SpecFuncMathCore.cxx:115; ROOT::Math::erfcdouble erfc(double x)Complementary error function.Definition SpecFuncMathCore.cxx:44; ROOT::Math::inc_gammadouble inc_gamma(double a, double x)Calculates the normalized (regularized) lower incomplete gamma function (lower integral)Definition SpecFuncMathCore.cxx:99; ROOT::Math::erfdouble erf(double x)Error function encountered in integrating the normal distribution.Definition SpecFuncMathCore.cxx:59; ROOT::Math::landau_xm1double landau_xm1(double x, double xi=1, double x0=0)First moment (mean) of the truncated Landau distribution.Definition ProbFuncMathCore.cxx:409; ROOT::Math::landau_xm2double landau_xm2(double x, double xi=1, double x0=0)Second moment of the truncated Landau distribution.Definition ProbFuncMathCore.cxx:489; sigmaconst Double_t sigmaDefinition h1analysisProxy.h:11; xDouble_t x[n]Definition legend1.C:17; nconst Int_t nDefinition legend1.C:16; MathNamespace for new Math classes and functions.; ROOT::Math::expm1double expm1(double x)exp(x) -1 with error cancellation when x is smallDefinition Math.h:110; ROOT::Math::sqrtVecExpr< UnaryOp< Sqrt< T >, VecExpr< A, T, D >, T >, T, D > sqrt(const VecExpr< A, T, D > &rhs)Definition UnaryOperators.h:281; ROOT::Math::kSqrt2static const double kSqrt2Definition ProbFuncMathCore.cxx:18; ROOT::Math::gaussian_cdf_cdouble gaussian_cdf_c(double ",MatchSource.WIKI,doc/master/ProbFuncMathCore_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html
https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html:3402,Energy Efficiency,power,power-law,3402," 88 return std::numeric_limits<double>::quiet_NaN();; 89 }; 90 double abs_alpha = std::abs(alpha);; 91 double C = n/abs_alpha * 1./(n-1.) * std::exp(-alpha*alpha/2.);; 92 double D = std::sqrt(M_PI/2.)*(1.+ROOT::Math::erf(abs_alpha/std::sqrt(2.)));; 93 double totIntegral = sigma*(C+D);; 94 ; 95 double integral = crystalball_integral(x,alpha,n,sigma,mean); ; 96 return (alpha > 0) ? integral/totIntegral : 1. - (integral/totIntegral); ; 97 }; 98 double crystalball_integral(double x, double alpha, double n, double sigma, double mean); 99 {; 100 // compute the integral of the crystal ball function (ROOT::Math::crystalball_function); 101 // If alpha > 0 the integral is the right tail integral.; 102 // If alpha < 0 is the left tail integrals which are always finite for finite x. ; 103 // parameters:; 104 // alpha : is non equal to zero, define the # of sigma from which it becomes a power-law function (from mean-alpha*sigma); 105 // n > 1 : is integrer, is the power of the low tail; 106 // add a value xmin for cases when n <=1 the integral diverges ; 107 if (sigma == 0) return 0;; 108 if (alpha==0); 109 {; 110 MATH_ERROR_MSG(""crystalball_integral"",""CrystalBall function not defined at alpha=0"");; 111 return 0.;; 112 }; 113 bool useLog = (n == 1.0); ; 114 if (n<=0) MATH_WARN_MSG(""crystalball_integral"",""No physical meaning when n<=0"");; 115 ; 116 double z = (x-mean)/sigma;; 117 if (alpha < 0 ) z = -z;; 118 ; 119 double abs_alpha = std::abs(alpha);; 120 ; 121 //double D = *(1.+ROOT::Math::erf(abs_alpha/std::sqrt(2.)));; 122 //double N = 1./(sigma*(C+D));; 123 double intgaus = 0.;; 124 double intpow = 0.;; 125 ; 126 const double sqrtpiover2 = std::sqrt(M_PI/2.);; 127 const double sqrt2pi = std::sqrt( 2.*M_PI); ; 128 const double oneoversqrt2 = 1./sqrt(2.);; 129 if (z <= -abs_alpha); 130 {; 131 double A = std::pow(n/abs_alpha,n) * std::exp(-0.5 * alpha*alpha);; 132 double B = n/abs_alpha - abs_alpha;; 133 ; 134 if (!useLog) {; 135 double C = (n/abs_alpha) * (1./(n-1)) * std::exp(-",MatchSource.WIKI,doc/master/ProbFuncMathCore_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html
https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html:3481,Energy Efficiency,power,power,3481," 88 return std::numeric_limits<double>::quiet_NaN();; 89 }; 90 double abs_alpha = std::abs(alpha);; 91 double C = n/abs_alpha * 1./(n-1.) * std::exp(-alpha*alpha/2.);; 92 double D = std::sqrt(M_PI/2.)*(1.+ROOT::Math::erf(abs_alpha/std::sqrt(2.)));; 93 double totIntegral = sigma*(C+D);; 94 ; 95 double integral = crystalball_integral(x,alpha,n,sigma,mean); ; 96 return (alpha > 0) ? integral/totIntegral : 1. - (integral/totIntegral); ; 97 }; 98 double crystalball_integral(double x, double alpha, double n, double sigma, double mean); 99 {; 100 // compute the integral of the crystal ball function (ROOT::Math::crystalball_function); 101 // If alpha > 0 the integral is the right tail integral.; 102 // If alpha < 0 is the left tail integrals which are always finite for finite x. ; 103 // parameters:; 104 // alpha : is non equal to zero, define the # of sigma from which it becomes a power-law function (from mean-alpha*sigma); 105 // n > 1 : is integrer, is the power of the low tail; 106 // add a value xmin for cases when n <=1 the integral diverges ; 107 if (sigma == 0) return 0;; 108 if (alpha==0); 109 {; 110 MATH_ERROR_MSG(""crystalball_integral"",""CrystalBall function not defined at alpha=0"");; 111 return 0.;; 112 }; 113 bool useLog = (n == 1.0); ; 114 if (n<=0) MATH_WARN_MSG(""crystalball_integral"",""No physical meaning when n<=0"");; 115 ; 116 double z = (x-mean)/sigma;; 117 if (alpha < 0 ) z = -z;; 118 ; 119 double abs_alpha = std::abs(alpha);; 120 ; 121 //double D = *(1.+ROOT::Math::erf(abs_alpha/std::sqrt(2.)));; 122 //double N = 1./(sigma*(C+D));; 123 double intgaus = 0.;; 124 double intpow = 0.;; 125 ; 126 const double sqrtpiover2 = std::sqrt(M_PI/2.);; 127 const double sqrt2pi = std::sqrt( 2.*M_PI); ; 128 const double oneoversqrt2 = 1./sqrt(2.);; 129 if (z <= -abs_alpha); 130 {; 131 double A = std::pow(n/abs_alpha,n) * std::exp(-0.5 * alpha*alpha);; 132 double B = n/abs_alpha - abs_alpha;; 133 ; 134 if (!useLog) {; 135 double C = (n/abs_alpha) * (1./(n-1)) * std::exp(-",MatchSource.WIKI,doc/master/ProbFuncMathCore_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html
https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html:27461,Integrability,integrat,integrating,27461,"e x0=0)Cumulative distribution function of the gamma distribution (lower tail).Definition ProbFuncMathCore.cxx:204; ROOT::Math::exponential_cdfdouble exponential_cdf(double x, double lambda, double x0=0)Cumulative distribution function of the exponential distribution (lower tail).Definition ProbFuncMathCore.cxx:161; ROOT::Math::inc_gamma_cdouble inc_gamma_c(double a, double x)Calculates the normalized (regularized) upper incomplete gamma function (upper integral)Definition SpecFuncMathCore.cxx:103; ROOT::Math::inc_betadouble inc_beta(double x, double a, double b)Calculates the normalized (regularized) incomplete beta function.Definition SpecFuncMathCore.cxx:115; ROOT::Math::erfcdouble erfc(double x)Complementary error function.Definition SpecFuncMathCore.cxx:44; ROOT::Math::inc_gammadouble inc_gamma(double a, double x)Calculates the normalized (regularized) lower incomplete gamma function (lower integral)Definition SpecFuncMathCore.cxx:99; ROOT::Math::erfdouble erf(double x)Error function encountered in integrating the normal distribution.Definition SpecFuncMathCore.cxx:59; ROOT::Math::landau_xm1double landau_xm1(double x, double xi=1, double x0=0)First moment (mean) of the truncated Landau distribution.Definition ProbFuncMathCore.cxx:409; ROOT::Math::landau_xm2double landau_xm2(double x, double xi=1, double x0=0)Second moment of the truncated Landau distribution.Definition ProbFuncMathCore.cxx:489; sigmaconst Double_t sigmaDefinition h1analysisProxy.h:11; xDouble_t x[n]Definition legend1.C:17; nconst Int_t nDefinition legend1.C:16; MathNamespace for new Math classes and functions.; ROOT::Math::expm1double expm1(double x)exp(x) -1 with error cancellation when x is smallDefinition Math.h:110; ROOT::Math::sqrtVecExpr< UnaryOp< Sqrt< T >, VecExpr< A, T, D >, T >, T, D > sqrt(const VecExpr< A, T, D > &rhs)Definition UnaryOperators.h:281; ROOT::Math::kSqrt2static const double kSqrt2Definition ProbFuncMathCore.cxx:18; ROOT::Math::gaussian_cdf_cdouble gaussian_cdf_c(double ",MatchSource.WIKI,doc/master/ProbFuncMathCore_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html
https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html:5290,Safety,avoid,avoid,5290,"./(n-1)) * std::exp(-alpha*alpha/2.);; 136 intpow = C - A /(n-1.) * std::pow(B-z,-n+1) ;; 137 }; 138 else {; 139 // for n=1 the primitive of 1/x is log(x); 140 intpow = -A * std::log( n / abs_alpha ) + A * std::log( B -z );; 141 }; 142 intgaus = sqrtpiover2*(1.+ROOT::Math::erf(abs_alpha*oneoversqrt2));; 143 }; 144 else; 145 {; 146 intgaus = ROOT::Math::gaussian_cdf_c(z, 1);; 147 intgaus *= sqrt2pi;; 148 intpow = 0; ; 149 }; 150 return sigma * (intgaus + intpow);; 151 }; 152 ; 153 ; 154 double exponential_cdf_c(double x, double lambda, double x0); 155 {; 156 if ((x-x0) < 0) return 1.0;; 157 else return std::exp(- lambda * (x-x0));; 158 }; 159 ; 160 ; 161 double exponential_cdf(double x, double lambda, double x0); 162 {; 163 if ((x-x0) < 0) return 0.0;; 164 else // use expm1 function to avoid errors at small x; 165 return - ROOT::Math::expm1( - lambda * (x-x0) ) ;; 166 }; 167 ; 168 ; 169 double fdistribution_cdf_c(double x, double n, double m, double x0); 170 {; 171 // f distribution is defined only for both n and m > 0; 172 if (n < 0 || m < 0) return std::numeric_limits<double>::quiet_NaN();; 173 ; 174 double z = m/(m + n*(x-x0));; 175 // fox z->1 and large a and b IB looses precision use complement function; 176 if (z > 0.9 && n > 1 && m > 1) return 1.- fdistribution_cdf(x,n,m,x0);; 177 ; 178 // for the complement use the fact that IB(x,a,b) = 1. - IB(1-x,b,a); 179 return ROOT::Math::inc_beta(m/(m + n*(x-x0)), .5*m, .5*n);; 180 }; 181 ; 182 ; 183 double fdistribution_cdf(double x, double n, double m, double x0); 184 {; 185 // f distribution is defined only for both n and m > 0; 186 if (n < 0 || m < 0); 187 return std::numeric_limits<double>::quiet_NaN();; 188 ; 189 double z = n*(x-x0)/(m + n*(x-x0));; 190 // fox z->1 and large a and b IB looses precision use complement function; 191 if (z > 0.9 && n > 1 && m > 1); 192 return 1. - fdistribution_cdf_c(x,n,m,x0);; 193 ; 194 return ROOT::Math::inc_beta(z, .5*n, .5*m);; 195 }; 196 ; 197 ; 198 double gamma_cdf_c(double x,",MatchSource.WIKI,doc/master/ProbFuncMathCore_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html
https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html:4642,Testability,log,log,4642,"lball_integral"",""CrystalBall function not defined at alpha=0"");; 111 return 0.;; 112 }; 113 bool useLog = (n == 1.0); ; 114 if (n<=0) MATH_WARN_MSG(""crystalball_integral"",""No physical meaning when n<=0"");; 115 ; 116 double z = (x-mean)/sigma;; 117 if (alpha < 0 ) z = -z;; 118 ; 119 double abs_alpha = std::abs(alpha);; 120 ; 121 //double D = *(1.+ROOT::Math::erf(abs_alpha/std::sqrt(2.)));; 122 //double N = 1./(sigma*(C+D));; 123 double intgaus = 0.;; 124 double intpow = 0.;; 125 ; 126 const double sqrtpiover2 = std::sqrt(M_PI/2.);; 127 const double sqrt2pi = std::sqrt( 2.*M_PI); ; 128 const double oneoversqrt2 = 1./sqrt(2.);; 129 if (z <= -abs_alpha); 130 {; 131 double A = std::pow(n/abs_alpha,n) * std::exp(-0.5 * alpha*alpha);; 132 double B = n/abs_alpha - abs_alpha;; 133 ; 134 if (!useLog) {; 135 double C = (n/abs_alpha) * (1./(n-1)) * std::exp(-alpha*alpha/2.);; 136 intpow = C - A /(n-1.) * std::pow(B-z,-n+1) ;; 137 }; 138 else {; 139 // for n=1 the primitive of 1/x is log(x); 140 intpow = -A * std::log( n / abs_alpha ) + A * std::log( B -z );; 141 }; 142 intgaus = sqrtpiover2*(1.+ROOT::Math::erf(abs_alpha*oneoversqrt2));; 143 }; 144 else; 145 {; 146 intgaus = ROOT::Math::gaussian_cdf_c(z, 1);; 147 intgaus *= sqrt2pi;; 148 intpow = 0; ; 149 }; 150 return sigma * (intgaus + intpow);; 151 }; 152 ; 153 ; 154 double exponential_cdf_c(double x, double lambda, double x0); 155 {; 156 if ((x-x0) < 0) return 1.0;; 157 else return std::exp(- lambda * (x-x0));; 158 }; 159 ; 160 ; 161 double exponential_cdf(double x, double lambda, double x0); 162 {; 163 if ((x-x0) < 0) return 0.0;; 164 else // use expm1 function to avoid errors at small x; 165 return - ROOT::Math::expm1( - lambda * (x-x0) ) ;; 166 }; 167 ; 168 ; 169 double fdistribution_cdf_c(double x, double n, double m, double x0); 170 {; 171 // f distribution is defined only for both n and m > 0; 172 if (n < 0 || m < 0) return std::numeric_limits<double>::quiet_NaN();; 173 ; 174 double z = m/(m + n*(x-x0));; 175 // fox z->",MatchSource.WIKI,doc/master/ProbFuncMathCore_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html
https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html:4673,Testability,log,log,4673,"lball_integral"",""CrystalBall function not defined at alpha=0"");; 111 return 0.;; 112 }; 113 bool useLog = (n == 1.0); ; 114 if (n<=0) MATH_WARN_MSG(""crystalball_integral"",""No physical meaning when n<=0"");; 115 ; 116 double z = (x-mean)/sigma;; 117 if (alpha < 0 ) z = -z;; 118 ; 119 double abs_alpha = std::abs(alpha);; 120 ; 121 //double D = *(1.+ROOT::Math::erf(abs_alpha/std::sqrt(2.)));; 122 //double N = 1./(sigma*(C+D));; 123 double intgaus = 0.;; 124 double intpow = 0.;; 125 ; 126 const double sqrtpiover2 = std::sqrt(M_PI/2.);; 127 const double sqrt2pi = std::sqrt( 2.*M_PI); ; 128 const double oneoversqrt2 = 1./sqrt(2.);; 129 if (z <= -abs_alpha); 130 {; 131 double A = std::pow(n/abs_alpha,n) * std::exp(-0.5 * alpha*alpha);; 132 double B = n/abs_alpha - abs_alpha;; 133 ; 134 if (!useLog) {; 135 double C = (n/abs_alpha) * (1./(n-1)) * std::exp(-alpha*alpha/2.);; 136 intpow = C - A /(n-1.) * std::pow(B-z,-n+1) ;; 137 }; 138 else {; 139 // for n=1 the primitive of 1/x is log(x); 140 intpow = -A * std::log( n / abs_alpha ) + A * std::log( B -z );; 141 }; 142 intgaus = sqrtpiover2*(1.+ROOT::Math::erf(abs_alpha*oneoversqrt2));; 143 }; 144 else; 145 {; 146 intgaus = ROOT::Math::gaussian_cdf_c(z, 1);; 147 intgaus *= sqrt2pi;; 148 intpow = 0; ; 149 }; 150 return sigma * (intgaus + intpow);; 151 }; 152 ; 153 ; 154 double exponential_cdf_c(double x, double lambda, double x0); 155 {; 156 if ((x-x0) < 0) return 1.0;; 157 else return std::exp(- lambda * (x-x0));; 158 }; 159 ; 160 ; 161 double exponential_cdf(double x, double lambda, double x0); 162 {; 163 if ((x-x0) < 0) return 0.0;; 164 else // use expm1 function to avoid errors at small x; 165 return - ROOT::Math::expm1( - lambda * (x-x0) ) ;; 166 }; 167 ; 168 ; 169 double fdistribution_cdf_c(double x, double n, double m, double x0); 170 {; 171 // f distribution is defined only for both n and m > 0; 172 if (n < 0 || m < 0) return std::numeric_limits<double>::quiet_NaN();; 173 ; 174 double z = m/(m + n*(x-x0));; 175 // fox z->",MatchSource.WIKI,doc/master/ProbFuncMathCore_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html
https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html:4705,Testability,log,log,4705,"lball_integral"",""CrystalBall function not defined at alpha=0"");; 111 return 0.;; 112 }; 113 bool useLog = (n == 1.0); ; 114 if (n<=0) MATH_WARN_MSG(""crystalball_integral"",""No physical meaning when n<=0"");; 115 ; 116 double z = (x-mean)/sigma;; 117 if (alpha < 0 ) z = -z;; 118 ; 119 double abs_alpha = std::abs(alpha);; 120 ; 121 //double D = *(1.+ROOT::Math::erf(abs_alpha/std::sqrt(2.)));; 122 //double N = 1./(sigma*(C+D));; 123 double intgaus = 0.;; 124 double intpow = 0.;; 125 ; 126 const double sqrtpiover2 = std::sqrt(M_PI/2.);; 127 const double sqrt2pi = std::sqrt( 2.*M_PI); ; 128 const double oneoversqrt2 = 1./sqrt(2.);; 129 if (z <= -abs_alpha); 130 {; 131 double A = std::pow(n/abs_alpha,n) * std::exp(-0.5 * alpha*alpha);; 132 double B = n/abs_alpha - abs_alpha;; 133 ; 134 if (!useLog) {; 135 double C = (n/abs_alpha) * (1./(n-1)) * std::exp(-alpha*alpha/2.);; 136 intpow = C - A /(n-1.) * std::pow(B-z,-n+1) ;; 137 }; 138 else {; 139 // for n=1 the primitive of 1/x is log(x); 140 intpow = -A * std::log( n / abs_alpha ) + A * std::log( B -z );; 141 }; 142 intgaus = sqrtpiover2*(1.+ROOT::Math::erf(abs_alpha*oneoversqrt2));; 143 }; 144 else; 145 {; 146 intgaus = ROOT::Math::gaussian_cdf_c(z, 1);; 147 intgaus *= sqrt2pi;; 148 intpow = 0; ; 149 }; 150 return sigma * (intgaus + intpow);; 151 }; 152 ; 153 ; 154 double exponential_cdf_c(double x, double lambda, double x0); 155 {; 156 if ((x-x0) < 0) return 1.0;; 157 else return std::exp(- lambda * (x-x0));; 158 }; 159 ; 160 ; 161 double exponential_cdf(double x, double lambda, double x0); 162 {; 163 if ((x-x0) < 0) return 0.0;; 164 else // use expm1 function to avoid errors at small x; 165 return - ROOT::Math::expm1( - lambda * (x-x0) ) ;; 166 }; 167 ; 168 ; 169 double fdistribution_cdf_c(double x, double n, double m, double x0); 170 {; 171 // f distribution is defined only for both n and m > 0; 172 if (n < 0 || m < 0) return std::numeric_limits<double>::quiet_NaN();; 173 ; 174 double z = m/(m + n*(x-x0));; 175 // fox z->",MatchSource.WIKI,doc/master/ProbFuncMathCore_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html
https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html:6869,Testability,log,log,6869,"d b IB looses precision use complement function; 176 if (z > 0.9 && n > 1 && m > 1) return 1.- fdistribution_cdf(x,n,m,x0);; 177 ; 178 // for the complement use the fact that IB(x,a,b) = 1. - IB(1-x,b,a); 179 return ROOT::Math::inc_beta(m/(m + n*(x-x0)), .5*m, .5*n);; 180 }; 181 ; 182 ; 183 double fdistribution_cdf(double x, double n, double m, double x0); 184 {; 185 // f distribution is defined only for both n and m > 0; 186 if (n < 0 || m < 0); 187 return std::numeric_limits<double>::quiet_NaN();; 188 ; 189 double z = n*(x-x0)/(m + n*(x-x0));; 190 // fox z->1 and large a and b IB looses precision use complement function; 191 if (z > 0.9 && n > 1 && m > 1); 192 return 1. - fdistribution_cdf_c(x,n,m,x0);; 193 ; 194 return ROOT::Math::inc_beta(z, .5*n, .5*m);; 195 }; 196 ; 197 ; 198 double gamma_cdf_c(double x, double alpha, double theta, double x0); 199 {; 200 return ROOT::Math::inc_gamma_c(alpha, (x-x0)/theta);; 201 }; 202 ; 203 ; 204 double gamma_cdf(double x, double alpha, double theta, double x0); 205 {; 206 return ROOT::Math::inc_gamma(alpha, (x-x0)/theta);; 207 }; 208 ; 209 ; 210 double lognormal_cdf_c(double x, double m, double s, double x0); 211 {; 212 double z = (std::log((x-x0))-m)/(s*kSqrt2);; 213 if (z > 1.) return 0.5*ROOT::Math::erfc(z);; 214 else return 0.5*(1.0 - ROOT::Math::erf(z));; 215 }; 216 ; 217 ; 218 double lognormal_cdf(double x, double m, double s, double x0); 219 {; 220 double z = (std::log((x-x0))-m)/(s*kSqrt2);; 221 if (z < -1.) return 0.5*ROOT::Math::erfc(-z);; 222 else return 0.5*(1.0 + ROOT::Math::erf(z));; 223 }; 224 ; 225 ; 226 double normal_cdf_c(double x, double sigma, double x0); 227 {; 228 double z = (x-x0)/(sigma*kSqrt2);; 229 if (z > 1.) return 0.5*ROOT::Math::erfc(z);; 230 else return 0.5*(1.-ROOT::Math::erf(z));; 231 }; 232 ; 233 ; 234 double normal_cdf(double x, double sigma, double x0); 235 {; 236 double z = (x-x0)/(sigma*kSqrt2);; 237 if (z < -1.) return 0.5*ROOT::Math::erfc(-z);; 238 else return 0.5*(1.0 + ROOT::Math::erf(",MatchSource.WIKI,doc/master/ProbFuncMathCore_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html
https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html:7109,Testability,log,log,7109," is defined only for both n and m > 0; 186 if (n < 0 || m < 0); 187 return std::numeric_limits<double>::quiet_NaN();; 188 ; 189 double z = n*(x-x0)/(m + n*(x-x0));; 190 // fox z->1 and large a and b IB looses precision use complement function; 191 if (z > 0.9 && n > 1 && m > 1); 192 return 1. - fdistribution_cdf_c(x,n,m,x0);; 193 ; 194 return ROOT::Math::inc_beta(z, .5*n, .5*m);; 195 }; 196 ; 197 ; 198 double gamma_cdf_c(double x, double alpha, double theta, double x0); 199 {; 200 return ROOT::Math::inc_gamma_c(alpha, (x-x0)/theta);; 201 }; 202 ; 203 ; 204 double gamma_cdf(double x, double alpha, double theta, double x0); 205 {; 206 return ROOT::Math::inc_gamma(alpha, (x-x0)/theta);; 207 }; 208 ; 209 ; 210 double lognormal_cdf_c(double x, double m, double s, double x0); 211 {; 212 double z = (std::log((x-x0))-m)/(s*kSqrt2);; 213 if (z > 1.) return 0.5*ROOT::Math::erfc(z);; 214 else return 0.5*(1.0 - ROOT::Math::erf(z));; 215 }; 216 ; 217 ; 218 double lognormal_cdf(double x, double m, double s, double x0); 219 {; 220 double z = (std::log((x-x0))-m)/(s*kSqrt2);; 221 if (z < -1.) return 0.5*ROOT::Math::erfc(-z);; 222 else return 0.5*(1.0 + ROOT::Math::erf(z));; 223 }; 224 ; 225 ; 226 double normal_cdf_c(double x, double sigma, double x0); 227 {; 228 double z = (x-x0)/(sigma*kSqrt2);; 229 if (z > 1.) return 0.5*ROOT::Math::erfc(z);; 230 else return 0.5*(1.-ROOT::Math::erf(z));; 231 }; 232 ; 233 ; 234 double normal_cdf(double x, double sigma, double x0); 235 {; 236 double z = (x-x0)/(sigma*kSqrt2);; 237 if (z < -1.) return 0.5*ROOT::Math::erfc(-z);; 238 else return 0.5*(1.0 + ROOT::Math::erf(z));; 239 }; 240 ; 241 ; 242 double tdistribution_cdf_c(double x, double r, double x0); 243 {; 244 double p = x-x0;; 245 double sign = (p>0) ? 1. : -1;; 246 return .5 - .5*ROOT::Math::inc_beta(p*p/(r + p*p), .5, .5*r)*sign;; 247 }; 248 ; 249 ; 250 double tdistribution_cdf(double x, double r, double x0); 251 {; 252 double p = x-x0;; 253 double sign = (p>0) ? 1. : -1;; 254 return .5 + .",MatchSource.WIKI,doc/master/ProbFuncMathCore_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html
https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html:13111,Testability,log,log,13111,"74 {; 375 u = std::exp(-v-1);; 376 lan = (std::exp(-u)/std::sqrt(u))*(p1[0]+(p1[1]+(p1[2]+(p1[3]+p1[4]*v)*v)*v)*v)/; 377 (q1[0]+(q1[1]+(q1[2]+(q1[3]+q1[4]*v)*v)*v)*v);; 378 }; 379 else if (v < 1); 380 lan = (p2[0]+(p2[1]+(p2[2]+p2[3]*v)*v)*v)/(q2[0]+(q2[1]+(q2[2]+q2[3]*v)*v)*v);; 381 ; 382 else if (v < 4); 383 lan = (p3[0]+(p3[1]+(p3[2]+p3[3]*v)*v)*v)/(q3[0]+(q3[1]+(q3[2]+q3[3]*v)*v)*v);; 384 ; 385 else if (v < 12); 386 {; 387 u = 1./v;; 388 lan = (p4[0]+(p4[1]+(p4[2]+p4[3]*u)*u)*u)/(q4[0]+(q4[1]+(q4[2]+q4[3]*u)*u)*u);; 389 }; 390 else if (v < 50); 391 {; 392 u = 1./v;; 393 lan = (p5[0]+(p5[1]+(p5[2]+p5[3]*u)*u)*u)/(q5[0]+(q5[1]+(q5[2]+q5[3]*u)*u)*u);; 394 }; 395 else if (v < 300); 396 {; 397 u = 1./v;; 398 lan = (p6[0]+(p6[1]+(p6[2]+p6[3]*u)*u)*u)/(q6[0]+(q6[1]+(q6[2]+q6[3]*u)*u)*u);; 399 }; 400 else; 401 {; 402 u = 1./(v-v*std::log(v)/(v+1));; 403 lan = 1-(a2[1]+(a2[2]+a2[3]*u)*u)*u;; 404 }; 405 return lan;; 406 }; 407 ; 408 ; 409 double landau_xm1(double x, double xi, double x0); 410 {; 411 // implementation of first momentum of Landau distribution; 412 // translated from Cernlib (XM1LAN function) by Benno List; 413 ; 414 static double p1[5] = {-0.8949374280E+0, 0.4631783434E+0,-0.4053332915E-1,; 415 0.1580075560E-1,-0.3423874194E-2};; 416 static double q1[5] = { 1.0 , 0.1002930749E+0, 0.3575271633E-1,; 417 -0.1915882099E-2, 0.4811072364E-4};; 418 static double p2[5] = {-0.8933384046E+0, 0.1161296496E+0, 0.1200082940E+0,; 419 0.2185699725E-1, 0.2128892058E-2};; 420 static double q2[5] = { 1.0 , 0.4935531886E+0, 0.1066347067E+0,; 421 0.1250161833E-1, 0.5494243254E-3};; 422 static double p3[5] = {-0.8933322067E+0, 0.2339544896E+0, 0.8257653222E-1,; 423 0.1411226998E-1, 0.2892240953E-3};; 424 static double q3[5] = { 1.0 , 0.3616538408E+0, 0.6628026743E-1,; 425 0.4839298984E-2, 0.5248310361E-4};; 426 static double p4[4] = { 0.9358419425E+0, 0.6716831438E+2,-0.6765069077E+3,; 427 0.9026661865E+3};; 428 static double q4[4] = { 1.0 , 0.7752562854E+2,-0.5637811998E+3,; 4",MatchSource.WIKI,doc/master/ProbFuncMathCore_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html
https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html:15554,Testability,log,log,15554,"81296500E+1};; 436 static double a1[4] = { 0, -0.4583333333E+0, 0.6675347222E+0,; 437 -0.1641741416E+1};; 438 static double a2[5] = { 0, -0.1958333333E+1, 0.5563368056E+1,; 439 -0.2111352961E+2, 0.1006946266E+3};; 440 ; 441 double v = (x-x0)/xi;; 442 double xm1lan;; 443 if (v < -4.5); 444 {; 445 double u = std::exp(v+1);; 446 xm1lan = v-u*(1+(a2[1]+(a2[2]+(a2[3]+a2[4]*u)*u)*u)*u)/; 447 (1+(a1[1]+(a1[2]+a1[3]*u)*u)*u);; 448 }; 449 else if (v < -2); 450 {; 451 xm1lan = (p1[0]+(p1[1]+(p1[2]+(p1[3]+p1[4]*v)*v)*v)*v)/; 452 (q1[0]+(q1[1]+(q1[2]+(q1[3]+q1[4]*v)*v)*v)*v);; 453 }; 454 else if (v < 2); 455 {; 456 xm1lan = (p2[0]+(p2[1]+(p2[2]+(p2[3]+p2[4]*v)*v)*v)*v)/; 457 (q2[0]+(q2[1]+(q2[2]+(q2[3]+q2[4]*v)*v)*v)*v);; 458 }; 459 else if (v < 10); 460 {; 461 xm1lan = (p3[0]+(p3[1]+(p3[2]+(p3[3]+p3[4]*v)*v)*v)*v)/; 462 (q3[0]+(q3[1]+(q3[2]+(q3[3]+q3[4]*v)*v)*v)*v);; 463 }; 464 else if (v < 40); 465 {; 466 double u = 1/v;; 467 xm1lan = std::log(v)*(p4[0]+(p4[1]+(p4[2]+p4[3]*u)*u)*u)/; 468 (q4[0]+(q4[1]+(q4[2]+q4[3]*u)*u)*u);; 469 }; 470 else if (v < 200); 471 {; 472 double u = 1/v;; 473 xm1lan = std::log(v)*(p5[0]+(p5[1]+(p5[2]+p5[3]*u)*u)*u)/; 474 (q5[0]+(q5[1]+(q5[2]+q5[3]*u)*u)*u);; 475 }; 476 else; 477 {; 478 double u = v-v*std::log(v)/(v+1);; 479 v = 1/(u-u*(u+ std::log(u)-v)/(u+1));; 480 u = -std::log(v);; 481 xm1lan = (u+a0[0]+(-u+a0[1]+(a0[2]*u+a0[3]+(a0[4]*u+a0[5])*v)*v)*v)/; 482 (1-(1-(a0[2]+a0[4]*v)*v)*v);; 483 }; 484 return xm1lan*xi + x0;; 485 }; 486 ; 487 ; 488 ; 489 double landau_xm2(double x, double xi, double x0); 490 {; 491 // implementation of second momentum of Landau distribution; 492 // translated from Cernlib (XM2LAN function) by Benno List; 493 ; 494 static double p1[5] = { 0.1169837582E+1,-0.4834874539E+0, 0.4383774644E+0,; 495 0.3287175228E-2, 0.1879129206E-1};; 496 static double q1[5] = { 1.0 , 0.1795154326E+0, 0.4612795899E-1,; 497 0.2183459337E-2, 0.7226623623E-4};; 498 static double p2[5] = { 0.1157939823E+1,-0.3842809495E+0, 0.3317532899E+0,; 499",MatchSource.WIKI,doc/master/ProbFuncMathCore_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html
https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html:15717,Testability,log,log,15717,"81296500E+1};; 436 static double a1[4] = { 0, -0.4583333333E+0, 0.6675347222E+0,; 437 -0.1641741416E+1};; 438 static double a2[5] = { 0, -0.1958333333E+1, 0.5563368056E+1,; 439 -0.2111352961E+2, 0.1006946266E+3};; 440 ; 441 double v = (x-x0)/xi;; 442 double xm1lan;; 443 if (v < -4.5); 444 {; 445 double u = std::exp(v+1);; 446 xm1lan = v-u*(1+(a2[1]+(a2[2]+(a2[3]+a2[4]*u)*u)*u)*u)/; 447 (1+(a1[1]+(a1[2]+a1[3]*u)*u)*u);; 448 }; 449 else if (v < -2); 450 {; 451 xm1lan = (p1[0]+(p1[1]+(p1[2]+(p1[3]+p1[4]*v)*v)*v)*v)/; 452 (q1[0]+(q1[1]+(q1[2]+(q1[3]+q1[4]*v)*v)*v)*v);; 453 }; 454 else if (v < 2); 455 {; 456 xm1lan = (p2[0]+(p2[1]+(p2[2]+(p2[3]+p2[4]*v)*v)*v)*v)/; 457 (q2[0]+(q2[1]+(q2[2]+(q2[3]+q2[4]*v)*v)*v)*v);; 458 }; 459 else if (v < 10); 460 {; 461 xm1lan = (p3[0]+(p3[1]+(p3[2]+(p3[3]+p3[4]*v)*v)*v)*v)/; 462 (q3[0]+(q3[1]+(q3[2]+(q3[3]+q3[4]*v)*v)*v)*v);; 463 }; 464 else if (v < 40); 465 {; 466 double u = 1/v;; 467 xm1lan = std::log(v)*(p4[0]+(p4[1]+(p4[2]+p4[3]*u)*u)*u)/; 468 (q4[0]+(q4[1]+(q4[2]+q4[3]*u)*u)*u);; 469 }; 470 else if (v < 200); 471 {; 472 double u = 1/v;; 473 xm1lan = std::log(v)*(p5[0]+(p5[1]+(p5[2]+p5[3]*u)*u)*u)/; 474 (q5[0]+(q5[1]+(q5[2]+q5[3]*u)*u)*u);; 475 }; 476 else; 477 {; 478 double u = v-v*std::log(v)/(v+1);; 479 v = 1/(u-u*(u+ std::log(u)-v)/(u+1));; 480 u = -std::log(v);; 481 xm1lan = (u+a0[0]+(-u+a0[1]+(a0[2]*u+a0[3]+(a0[4]*u+a0[5])*v)*v)*v)/; 482 (1-(1-(a0[2]+a0[4]*v)*v)*v);; 483 }; 484 return xm1lan*xi + x0;; 485 }; 486 ; 487 ; 488 ; 489 double landau_xm2(double x, double xi, double x0); 490 {; 491 // implementation of second momentum of Landau distribution; 492 // translated from Cernlib (XM2LAN function) by Benno List; 493 ; 494 static double p1[5] = { 0.1169837582E+1,-0.4834874539E+0, 0.4383774644E+0,; 495 0.3287175228E-2, 0.1879129206E-1};; 496 static double q1[5] = { 1.0 , 0.1795154326E+0, 0.4612795899E-1,; 497 0.2183459337E-2, 0.7226623623E-4};; 498 static double p2[5] = { 0.1157939823E+1,-0.3842809495E+0, 0.3317532899E+0,; 499",MatchSource.WIKI,doc/master/ProbFuncMathCore_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html
https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html:15852,Testability,log,log,15852,"81296500E+1};; 436 static double a1[4] = { 0, -0.4583333333E+0, 0.6675347222E+0,; 437 -0.1641741416E+1};; 438 static double a2[5] = { 0, -0.1958333333E+1, 0.5563368056E+1,; 439 -0.2111352961E+2, 0.1006946266E+3};; 440 ; 441 double v = (x-x0)/xi;; 442 double xm1lan;; 443 if (v < -4.5); 444 {; 445 double u = std::exp(v+1);; 446 xm1lan = v-u*(1+(a2[1]+(a2[2]+(a2[3]+a2[4]*u)*u)*u)*u)/; 447 (1+(a1[1]+(a1[2]+a1[3]*u)*u)*u);; 448 }; 449 else if (v < -2); 450 {; 451 xm1lan = (p1[0]+(p1[1]+(p1[2]+(p1[3]+p1[4]*v)*v)*v)*v)/; 452 (q1[0]+(q1[1]+(q1[2]+(q1[3]+q1[4]*v)*v)*v)*v);; 453 }; 454 else if (v < 2); 455 {; 456 xm1lan = (p2[0]+(p2[1]+(p2[2]+(p2[3]+p2[4]*v)*v)*v)*v)/; 457 (q2[0]+(q2[1]+(q2[2]+(q2[3]+q2[4]*v)*v)*v)*v);; 458 }; 459 else if (v < 10); 460 {; 461 xm1lan = (p3[0]+(p3[1]+(p3[2]+(p3[3]+p3[4]*v)*v)*v)*v)/; 462 (q3[0]+(q3[1]+(q3[2]+(q3[3]+q3[4]*v)*v)*v)*v);; 463 }; 464 else if (v < 40); 465 {; 466 double u = 1/v;; 467 xm1lan = std::log(v)*(p4[0]+(p4[1]+(p4[2]+p4[3]*u)*u)*u)/; 468 (q4[0]+(q4[1]+(q4[2]+q4[3]*u)*u)*u);; 469 }; 470 else if (v < 200); 471 {; 472 double u = 1/v;; 473 xm1lan = std::log(v)*(p5[0]+(p5[1]+(p5[2]+p5[3]*u)*u)*u)/; 474 (q5[0]+(q5[1]+(q5[2]+q5[3]*u)*u)*u);; 475 }; 476 else; 477 {; 478 double u = v-v*std::log(v)/(v+1);; 479 v = 1/(u-u*(u+ std::log(u)-v)/(u+1));; 480 u = -std::log(v);; 481 xm1lan = (u+a0[0]+(-u+a0[1]+(a0[2]*u+a0[3]+(a0[4]*u+a0[5])*v)*v)*v)/; 482 (1-(1-(a0[2]+a0[4]*v)*v)*v);; 483 }; 484 return xm1lan*xi + x0;; 485 }; 486 ; 487 ; 488 ; 489 double landau_xm2(double x, double xi, double x0); 490 {; 491 // implementation of second momentum of Landau distribution; 492 // translated from Cernlib (XM2LAN function) by Benno List; 493 ; 494 static double p1[5] = { 0.1169837582E+1,-0.4834874539E+0, 0.4383774644E+0,; 495 0.3287175228E-2, 0.1879129206E-1};; 496 static double q1[5] = { 1.0 , 0.1795154326E+0, 0.4612795899E-1,; 497 0.2183459337E-2, 0.7226623623E-4};; 498 static double p2[5] = { 0.1157939823E+1,-0.3842809495E+0, 0.3317532899E+0,; 499",MatchSource.WIKI,doc/master/ProbFuncMathCore_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html
https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html:15891,Testability,log,log,15891,"81296500E+1};; 436 static double a1[4] = { 0, -0.4583333333E+0, 0.6675347222E+0,; 437 -0.1641741416E+1};; 438 static double a2[5] = { 0, -0.1958333333E+1, 0.5563368056E+1,; 439 -0.2111352961E+2, 0.1006946266E+3};; 440 ; 441 double v = (x-x0)/xi;; 442 double xm1lan;; 443 if (v < -4.5); 444 {; 445 double u = std::exp(v+1);; 446 xm1lan = v-u*(1+(a2[1]+(a2[2]+(a2[3]+a2[4]*u)*u)*u)*u)/; 447 (1+(a1[1]+(a1[2]+a1[3]*u)*u)*u);; 448 }; 449 else if (v < -2); 450 {; 451 xm1lan = (p1[0]+(p1[1]+(p1[2]+(p1[3]+p1[4]*v)*v)*v)*v)/; 452 (q1[0]+(q1[1]+(q1[2]+(q1[3]+q1[4]*v)*v)*v)*v);; 453 }; 454 else if (v < 2); 455 {; 456 xm1lan = (p2[0]+(p2[1]+(p2[2]+(p2[3]+p2[4]*v)*v)*v)*v)/; 457 (q2[0]+(q2[1]+(q2[2]+(q2[3]+q2[4]*v)*v)*v)*v);; 458 }; 459 else if (v < 10); 460 {; 461 xm1lan = (p3[0]+(p3[1]+(p3[2]+(p3[3]+p3[4]*v)*v)*v)*v)/; 462 (q3[0]+(q3[1]+(q3[2]+(q3[3]+q3[4]*v)*v)*v)*v);; 463 }; 464 else if (v < 40); 465 {; 466 double u = 1/v;; 467 xm1lan = std::log(v)*(p4[0]+(p4[1]+(p4[2]+p4[3]*u)*u)*u)/; 468 (q4[0]+(q4[1]+(q4[2]+q4[3]*u)*u)*u);; 469 }; 470 else if (v < 200); 471 {; 472 double u = 1/v;; 473 xm1lan = std::log(v)*(p5[0]+(p5[1]+(p5[2]+p5[3]*u)*u)*u)/; 474 (q5[0]+(q5[1]+(q5[2]+q5[3]*u)*u)*u);; 475 }; 476 else; 477 {; 478 double u = v-v*std::log(v)/(v+1);; 479 v = 1/(u-u*(u+ std::log(u)-v)/(u+1));; 480 u = -std::log(v);; 481 xm1lan = (u+a0[0]+(-u+a0[1]+(a0[2]*u+a0[3]+(a0[4]*u+a0[5])*v)*v)*v)/; 482 (1-(1-(a0[2]+a0[4]*v)*v)*v);; 483 }; 484 return xm1lan*xi + x0;; 485 }; 486 ; 487 ; 488 ; 489 double landau_xm2(double x, double xi, double x0); 490 {; 491 // implementation of second momentum of Landau distribution; 492 // translated from Cernlib (XM2LAN function) by Benno List; 493 ; 494 static double p1[5] = { 0.1169837582E+1,-0.4834874539E+0, 0.4383774644E+0,; 495 0.3287175228E-2, 0.1879129206E-1};; 496 static double q1[5] = { 1.0 , 0.1795154326E+0, 0.4612795899E-1,; 497 0.2183459337E-2, 0.7226623623E-4};; 498 static double p2[5] = { 0.1157939823E+1,-0.3842809495E+0, 0.3317532899E+0,; 499",MatchSource.WIKI,doc/master/ProbFuncMathCore_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html
https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html:15924,Testability,log,log,15924,"81296500E+1};; 436 static double a1[4] = { 0, -0.4583333333E+0, 0.6675347222E+0,; 437 -0.1641741416E+1};; 438 static double a2[5] = { 0, -0.1958333333E+1, 0.5563368056E+1,; 439 -0.2111352961E+2, 0.1006946266E+3};; 440 ; 441 double v = (x-x0)/xi;; 442 double xm1lan;; 443 if (v < -4.5); 444 {; 445 double u = std::exp(v+1);; 446 xm1lan = v-u*(1+(a2[1]+(a2[2]+(a2[3]+a2[4]*u)*u)*u)*u)/; 447 (1+(a1[1]+(a1[2]+a1[3]*u)*u)*u);; 448 }; 449 else if (v < -2); 450 {; 451 xm1lan = (p1[0]+(p1[1]+(p1[2]+(p1[3]+p1[4]*v)*v)*v)*v)/; 452 (q1[0]+(q1[1]+(q1[2]+(q1[3]+q1[4]*v)*v)*v)*v);; 453 }; 454 else if (v < 2); 455 {; 456 xm1lan = (p2[0]+(p2[1]+(p2[2]+(p2[3]+p2[4]*v)*v)*v)*v)/; 457 (q2[0]+(q2[1]+(q2[2]+(q2[3]+q2[4]*v)*v)*v)*v);; 458 }; 459 else if (v < 10); 460 {; 461 xm1lan = (p3[0]+(p3[1]+(p3[2]+(p3[3]+p3[4]*v)*v)*v)*v)/; 462 (q3[0]+(q3[1]+(q3[2]+(q3[3]+q3[4]*v)*v)*v)*v);; 463 }; 464 else if (v < 40); 465 {; 466 double u = 1/v;; 467 xm1lan = std::log(v)*(p4[0]+(p4[1]+(p4[2]+p4[3]*u)*u)*u)/; 468 (q4[0]+(q4[1]+(q4[2]+q4[3]*u)*u)*u);; 469 }; 470 else if (v < 200); 471 {; 472 double u = 1/v;; 473 xm1lan = std::log(v)*(p5[0]+(p5[1]+(p5[2]+p5[3]*u)*u)*u)/; 474 (q5[0]+(q5[1]+(q5[2]+q5[3]*u)*u)*u);; 475 }; 476 else; 477 {; 478 double u = v-v*std::log(v)/(v+1);; 479 v = 1/(u-u*(u+ std::log(u)-v)/(u+1));; 480 u = -std::log(v);; 481 xm1lan = (u+a0[0]+(-u+a0[1]+(a0[2]*u+a0[3]+(a0[4]*u+a0[5])*v)*v)*v)/; 482 (1-(1-(a0[2]+a0[4]*v)*v)*v);; 483 }; 484 return xm1lan*xi + x0;; 485 }; 486 ; 487 ; 488 ; 489 double landau_xm2(double x, double xi, double x0); 490 {; 491 // implementation of second momentum of Landau distribution; 492 // translated from Cernlib (XM2LAN function) by Benno List; 493 ; 494 static double p1[5] = { 0.1169837582E+1,-0.4834874539E+0, 0.4383774644E+0,; 495 0.3287175228E-2, 0.1879129206E-1};; 496 static double q1[5] = { 1.0 , 0.1795154326E+0, 0.4612795899E-1,; 497 0.2183459337E-2, 0.7226623623E-4};; 498 static double p2[5] = { 0.1157939823E+1,-0.3842809495E+0, 0.3317532899E+0,; 499",MatchSource.WIKI,doc/master/ProbFuncMathCore_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html
https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html:18905,Testability,log,log,18905," -0.1641741416E+1};; 519 static double a2[4] = {-0.1958333333E+1, 0.5563368056E+1,-0.2111352961E+2,; 520 0.1006946266E+3};; 521 static double a3[4] = {-1.0 , 0.4458333333E+1,-0.2116753472E+2,; 522 0.1163674359E+3};; 523 ; 524 double v = (x-x0)/xi;; 525 double xm2lan;; 526 if (v < -4.5); 527 {; 528 double u = std::exp(v+1);; 529 xm2lan = v*v-2*u*u*; 530 (v/u+a2[0]*v+a3[0]+(a2[1]*v+a3[1]+(a2[2]*v+a3[2]+; 531 (a2[3]*v+a3[3])*u)*u)*u)/; 532 (1+(a1[1]+(a1[2]+a1[3]*u)*u)*u);; 533 }; 534 else if (v < -2); 535 {; 536 xm2lan = (p1[0]+(p1[1]+(p1[2]+(p1[3]+p1[4]*v)*v)*v)*v)/; 537 (q1[0]+(q1[1]+(q1[2]+(q1[3]+q1[4]*v)*v)*v)*v);; 538 }; 539 else if (v < 2); 540 {; 541 xm2lan = (p2[0]+(p2[1]+(p2[2]+(p2[3]+p2[4]*v)*v)*v)*v)/; 542 (q2[0]+(q2[1]+(q2[2]+(q2[3]+q2[4]*v)*v)*v)*v);; 543 }; 544 else if (v < 5); 545 {; 546 double u = 1/v;; 547 xm2lan = v*(p3[0]+(p3[1]+(p3[2]+p3[3]*u)*u)*u)/; 548 (q3[0]+(q3[1]+(q3[2]+q3[3]*u)*u)*u);; 549 }; 550 else if (v < 50); 551 {; 552 double u = 1/v;; 553 xm2lan = v*(p4[0]+(p4[1]+(p4[2]+(p4[3]+p4[4]*u)*u)*u)*u)/; 554 (q4[0]+(q4[1]+(q4[2]+(q4[3]+q4[4]*u)*u)*u)*u);; 555 }; 556 else if (v < 200); 557 {; 558 double u = 1/v;; 559 xm2lan = v*(p5[0]+(p5[1]+(p5[2]+p5[3]*u)*u)*u)/; 560 (q5[0]+(q5[1]+(q5[2]+q5[3]*u)*u)*u);; 561 }; 562 else; 563 {; 564 double u = v-v*std::log(v)/(v+1);; 565 v = 1/(u-u*(u+log(u)-v)/(u+1));; 566 u = -std::log(v);; 567 xm2lan = (1/v+u*u+a0[0]+a0[1]*u+(-u*u+a0[2]*u+a0[3]+; 568 (a0[4]*u*u+a0[5]*u+a0[6])*v)*v)/(1-(1-a0[4]*v)*v);; 569 }; 570 if (x0 == 0) return xm2lan*xi*xi;; 571 double xm1lan = ROOT::Math::landau_xm1(x, xi, x0);; 572 return xm2lan*xi*xi + (2*xm1lan-x0)*x0;; 573 }; 574 ; 575} // namespace Math; 576} // namespace ROOT; 577 ; 578 ; 579 ; Error.h; MATH_ERROR_MSG#define MATH_ERROR_MSG(loc, str)Definition Error.h:83; MATH_WARN_MSG#define MATH_WARN_MSG(loc, str)Definition Error.h:80; Math.h; ProbFuncMathCore.h; b#define b(i)Definition RSha256.hxx:100; a#define a(i)Definition RSha256.hxx:99; M_PI#define M_PIDefinition Rotated.c",MatchSource.WIKI,doc/master/ProbFuncMathCore_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html
https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html:18938,Testability,log,log,18938," -0.1641741416E+1};; 519 static double a2[4] = {-0.1958333333E+1, 0.5563368056E+1,-0.2111352961E+2,; 520 0.1006946266E+3};; 521 static double a3[4] = {-1.0 , 0.4458333333E+1,-0.2116753472E+2,; 522 0.1163674359E+3};; 523 ; 524 double v = (x-x0)/xi;; 525 double xm2lan;; 526 if (v < -4.5); 527 {; 528 double u = std::exp(v+1);; 529 xm2lan = v*v-2*u*u*; 530 (v/u+a2[0]*v+a3[0]+(a2[1]*v+a3[1]+(a2[2]*v+a3[2]+; 531 (a2[3]*v+a3[3])*u)*u)*u)/; 532 (1+(a1[1]+(a1[2]+a1[3]*u)*u)*u);; 533 }; 534 else if (v < -2); 535 {; 536 xm2lan = (p1[0]+(p1[1]+(p1[2]+(p1[3]+p1[4]*v)*v)*v)*v)/; 537 (q1[0]+(q1[1]+(q1[2]+(q1[3]+q1[4]*v)*v)*v)*v);; 538 }; 539 else if (v < 2); 540 {; 541 xm2lan = (p2[0]+(p2[1]+(p2[2]+(p2[3]+p2[4]*v)*v)*v)*v)/; 542 (q2[0]+(q2[1]+(q2[2]+(q2[3]+q2[4]*v)*v)*v)*v);; 543 }; 544 else if (v < 5); 545 {; 546 double u = 1/v;; 547 xm2lan = v*(p3[0]+(p3[1]+(p3[2]+p3[3]*u)*u)*u)/; 548 (q3[0]+(q3[1]+(q3[2]+q3[3]*u)*u)*u);; 549 }; 550 else if (v < 50); 551 {; 552 double u = 1/v;; 553 xm2lan = v*(p4[0]+(p4[1]+(p4[2]+(p4[3]+p4[4]*u)*u)*u)*u)/; 554 (q4[0]+(q4[1]+(q4[2]+(q4[3]+q4[4]*u)*u)*u)*u);; 555 }; 556 else if (v < 200); 557 {; 558 double u = 1/v;; 559 xm2lan = v*(p5[0]+(p5[1]+(p5[2]+p5[3]*u)*u)*u)/; 560 (q5[0]+(q5[1]+(q5[2]+q5[3]*u)*u)*u);; 561 }; 562 else; 563 {; 564 double u = v-v*std::log(v)/(v+1);; 565 v = 1/(u-u*(u+log(u)-v)/(u+1));; 566 u = -std::log(v);; 567 xm2lan = (1/v+u*u+a0[0]+a0[1]*u+(-u*u+a0[2]*u+a0[3]+; 568 (a0[4]*u*u+a0[5]*u+a0[6])*v)*v)/(1-(1-a0[4]*v)*v);; 569 }; 570 if (x0 == 0) return xm2lan*xi*xi;; 571 double xm1lan = ROOT::Math::landau_xm1(x, xi, x0);; 572 return xm2lan*xi*xi + (2*xm1lan-x0)*x0;; 573 }; 574 ; 575} // namespace Math; 576} // namespace ROOT; 577 ; 578 ; 579 ; Error.h; MATH_ERROR_MSG#define MATH_ERROR_MSG(loc, str)Definition Error.h:83; MATH_WARN_MSG#define MATH_WARN_MSG(loc, str)Definition Error.h:80; Math.h; ProbFuncMathCore.h; b#define b(i)Definition RSha256.hxx:100; a#define a(i)Definition RSha256.hxx:99; M_PI#define M_PIDefinition Rotated.c",MatchSource.WIKI,doc/master/ProbFuncMathCore_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html
https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html:18971,Testability,log,log,18971," -0.1641741416E+1};; 519 static double a2[4] = {-0.1958333333E+1, 0.5563368056E+1,-0.2111352961E+2,; 520 0.1006946266E+3};; 521 static double a3[4] = {-1.0 , 0.4458333333E+1,-0.2116753472E+2,; 522 0.1163674359E+3};; 523 ; 524 double v = (x-x0)/xi;; 525 double xm2lan;; 526 if (v < -4.5); 527 {; 528 double u = std::exp(v+1);; 529 xm2lan = v*v-2*u*u*; 530 (v/u+a2[0]*v+a3[0]+(a2[1]*v+a3[1]+(a2[2]*v+a3[2]+; 531 (a2[3]*v+a3[3])*u)*u)*u)/; 532 (1+(a1[1]+(a1[2]+a1[3]*u)*u)*u);; 533 }; 534 else if (v < -2); 535 {; 536 xm2lan = (p1[0]+(p1[1]+(p1[2]+(p1[3]+p1[4]*v)*v)*v)*v)/; 537 (q1[0]+(q1[1]+(q1[2]+(q1[3]+q1[4]*v)*v)*v)*v);; 538 }; 539 else if (v < 2); 540 {; 541 xm2lan = (p2[0]+(p2[1]+(p2[2]+(p2[3]+p2[4]*v)*v)*v)*v)/; 542 (q2[0]+(q2[1]+(q2[2]+(q2[3]+q2[4]*v)*v)*v)*v);; 543 }; 544 else if (v < 5); 545 {; 546 double u = 1/v;; 547 xm2lan = v*(p3[0]+(p3[1]+(p3[2]+p3[3]*u)*u)*u)/; 548 (q3[0]+(q3[1]+(q3[2]+q3[3]*u)*u)*u);; 549 }; 550 else if (v < 50); 551 {; 552 double u = 1/v;; 553 xm2lan = v*(p4[0]+(p4[1]+(p4[2]+(p4[3]+p4[4]*u)*u)*u)*u)/; 554 (q4[0]+(q4[1]+(q4[2]+(q4[3]+q4[4]*u)*u)*u)*u);; 555 }; 556 else if (v < 200); 557 {; 558 double u = 1/v;; 559 xm2lan = v*(p5[0]+(p5[1]+(p5[2]+p5[3]*u)*u)*u)/; 560 (q5[0]+(q5[1]+(q5[2]+q5[3]*u)*u)*u);; 561 }; 562 else; 563 {; 564 double u = v-v*std::log(v)/(v+1);; 565 v = 1/(u-u*(u+log(u)-v)/(u+1));; 566 u = -std::log(v);; 567 xm2lan = (1/v+u*u+a0[0]+a0[1]*u+(-u*u+a0[2]*u+a0[3]+; 568 (a0[4]*u*u+a0[5]*u+a0[6])*v)*v)/(1-(1-a0[4]*v)*v);; 569 }; 570 if (x0 == 0) return xm2lan*xi*xi;; 571 double xm1lan = ROOT::Math::landau_xm1(x, xi, x0);; 572 return xm2lan*xi*xi + (2*xm1lan-x0)*x0;; 573 }; 574 ; 575} // namespace Math; 576} // namespace ROOT; 577 ; 578 ; 579 ; Error.h; MATH_ERROR_MSG#define MATH_ERROR_MSG(loc, str)Definition Error.h:83; MATH_WARN_MSG#define MATH_WARN_MSG(loc, str)Definition Error.h:80; Math.h; ProbFuncMathCore.h; b#define b(i)Definition RSha256.hxx:100; a#define a(i)Definition RSha256.hxx:99; M_PI#define M_PIDefinition Rotated.c",MatchSource.WIKI,doc/master/ProbFuncMathCore_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html
https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html:20938,Testability,log,lognormal,20938,"Point_t Rectangle_t WindowAttributes_t Float_t rDefinition TGWin32VirtualXProxy.cxx:168; double; ROOT::Math::poisson_cdfdouble poisson_cdf(unsigned int n, double mu)Cumulative distribution function of the Poisson distribution Lower tail of the integral of the poisso...Definition ProbFuncMathCore.cxx:284; ROOT::Math::crystalball_integraldouble crystalball_integral(double x, double alpha, double n, double sigma, double x0=0)Integral of the not-normalized Crystal Ball function.Definition ProbFuncMathCore.cxx:98; ROOT::Math::uniform_cdfdouble uniform_cdf(double x, double a, double b, double x0=0)Cumulative distribution function of the uniform (flat) distribution (lower tail).Definition ProbFuncMathCore.cxx:266; ROOT::Math::binomial_cdf_cdouble binomial_cdf_c(unsigned int k, double p, unsigned int n)Complement of the cumulative distribution function of the Binomial distribution.Definition ProbFuncMathCore.cxx:293; ROOT::Math::lognormal_cdfdouble lognormal_cdf(double x, double m, double s, double x0=0)Cumulative distribution function of the lognormal distribution (lower tail).Definition ProbFuncMathCore.cxx:218; ROOT::Math::cauchy_cdf_cdouble cauchy_cdf_c(double x, double b, double x0=0)Complement of the cumulative distribution function (upper tail) of the Cauchy distribution which is a...Definition ProbFuncMathCore.cxx:45; ROOT::Math::fdistribution_cdfdouble fdistribution_cdf(double x, double n, double m, double x0=0)Cumulative distribution function of the F-distribution (lower tail).Definition ProbFuncMathCore.cxx:183; ROOT::Math::binomial_cdfdouble binomial_cdf(unsigned int k, double p, unsigned int n)Cumulative distribution function of the Binomial distribution Lower tail of the integral of the binom...Definition ProbFuncMathCore.cxx:304; ROOT::Math::landau_cdfdouble landau_cdf(double x, double xi=1, double x0=0)Cumulative distribution function of the Landau distribution (lower tail).Definition ProbFuncMathCore.cxx:336; ROOT::Math::lognormal_cdf_cdouble lognormal_cdf_c",MatchSource.WIKI,doc/master/ProbFuncMathCore_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html
https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html:21989,Testability,log,lognormal,21989,"ion of the lognormal distribution (lower tail).Definition ProbFuncMathCore.cxx:218; ROOT::Math::cauchy_cdf_cdouble cauchy_cdf_c(double x, double b, double x0=0)Complement of the cumulative distribution function (upper tail) of the Cauchy distribution which is a...Definition ProbFuncMathCore.cxx:45; ROOT::Math::fdistribution_cdfdouble fdistribution_cdf(double x, double n, double m, double x0=0)Cumulative distribution function of the F-distribution (lower tail).Definition ProbFuncMathCore.cxx:183; ROOT::Math::binomial_cdfdouble binomial_cdf(unsigned int k, double p, unsigned int n)Cumulative distribution function of the Binomial distribution Lower tail of the integral of the binom...Definition ProbFuncMathCore.cxx:304; ROOT::Math::landau_cdfdouble landau_cdf(double x, double xi=1, double x0=0)Cumulative distribution function of the Landau distribution (lower tail).Definition ProbFuncMathCore.cxx:336; ROOT::Math::lognormal_cdf_cdouble lognormal_cdf_c(double x, double m, double s, double x0=0)Complement of the cumulative distribution function of the lognormal distribution (upper tail).Definition ProbFuncMathCore.cxx:210; ROOT::Math::uniform_cdf_cdouble uniform_cdf_c(double x, double a, double b, double x0=0)Complement of the cumulative distribution function of the uniform (flat) distribution (upper tail).Definition ProbFuncMathCore.cxx:258; ROOT::Math::fdistribution_cdf_cdouble fdistribution_cdf_c(double x, double n, double m, double x0=0)Complement of the cumulative distribution function of the F-distribution (upper tail).Definition ProbFuncMathCore.cxx:169; ROOT::Math::crystalball_cdf_cdouble crystalball_cdf_c(double x, double alpha, double n, double sigma, double x0=0)Complement of the Cumulative distribution for the Crystal Ball distribution.Definition ProbFuncMathCore.cxx:84; ROOT::Math::normal_cdf_cdouble normal_cdf_c(double x, double sigma=1, double x0=0)Complement of the cumulative distribution function of the normal (Gaussian) distribution (upper tail)...Definit",MatchSource.WIKI,doc/master/ProbFuncMathCore_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ProbFuncMathCore_8cxx_source.html
https://root.cern/doc/master/ProbFuncMathCore_8h_source.html:1362,Deployability,release,releases,1362,"05; 3 ; 4/**********************************************************************; 5 * *; 6 * Copyright (c) 2005 , LCG ROOT MathLib Team *; 7 * *; 8 * *; 9 **********************************************************************/; 10 ; 11#ifndef ROOT_Math_ProbFuncMathCore; 12#define ROOT_Math_ProbFuncMathCore; 13 ; 14 ; 15namespace ROOT {; 16namespace Math {; 17 ; 18 ; 19 /** @defgroup ProbFunc Cumulative Distribution Functions (CDF); 20 ; 21 @ingroup StatFunc; 22 ; 23 * Cumulative distribution functions of various distributions.; 24 * The functions with the extension <em>_cdf</em> calculate the; 25 * lower tail integral of the probability density function; 26 *; 27 * \f[ D(x) = \int_{-\infty}^{x} p(x') dx' \f]; 28 *; 29 * while those with the <em>_cdf_c</em> extension calculate the complement of; 30 * cumulative distribution function, called in statistics the survival; 31 * function.; 32 * It corresponds to the upper tail integral of the; 33 * probability density function; 34 *; 35 * \f[ D(x) = \int_{x}^{+\infty} p(x') dx' \f]; 36 *; 37 *; 38 * <strong>NOTE:</strong> In the old releases (< 5.14) the <em>_cdf</em> functions were called; 39 * <em>_quant</em> and the <em>_cdf_c</em> functions were called; 40 * <em>_prob</em>.; 41 * These names are currently kept for backward compatibility, but; 42 * their usage is deprecated.; 43 *; 44 * These functions are defined in the header file <em>Math/ProbFunc.h</em> or in the global one; 45 * including all statistical functions <em>Math/DistFunc.h</em>; 46 *; 47 */; 48 ; 49 ; 50 ; 51 /**; 52 ; 53 Complement of the cumulative distribution function of the beta distribution.; 54 Upper tail of the integral of the #beta_pdf; 55 ; 56 @ingroup ProbFunc; 57 ; 58 */; 59 ; 60 double beta_cdf_c(double x, double a, double b);; 61 ; 62 ; 63 ; 64 /**; 65 ; 66 Cumulative distribution function of the beta distribution; 67 Upper tail of the integral of the #beta_pdf; 68 ; 69 @ingroup ProbFunc; 70 ; 71 */; 72 ; 73 double beta_cdf(double x, double ",MatchSource.WIKI,doc/master/ProbFuncMathCore_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ProbFuncMathCore_8h_source.html
https://root.cern/doc/master/ProbFuncMathCore_8h_source.html:11062,Testability,log,log,11062,"9 */; 330 ; 331 double gamma_cdf_c(double x, double alpha, double theta, double x0 = 0);; 332 ; 333 ; 334 ; 335 ; 336 /**; 337 ; 338 Cumulative distribution function of the gamma distribution; 339 (lower tail).; 340 ; 341 \f[ D(x) = \int_{-\infty}^{x} {1 \over \Gamma(\alpha) \theta^{\alpha}} x'^{\alpha-1} e^{-x'/\theta} dx' \f]; 342 ; 343 For detailed description see; 344 <A HREF=""http://mathworld.wolfram.com/GammaDistribution.html"">; 345 Mathworld</A>. It is implemented using the incomplete gamma function, ROOT::Math::inc_gamma,; 346 from <A HREF=""http://www.netlib.org/cephes"">Cephes</A>; 347 ; 348 @ingroup ProbFunc; 349 ; 350 */; 351 ; 352 double gamma_cdf(double x, double alpha, double theta, double x0 = 0);; 353 ; 354 ; 355 ; 356 /**; 357 ; 358 Cumulative distribution function of the Landau; 359 distribution (lower tail).; 360 ; 361 \f[ D(x) = \int_{-\infty}^{x} p(x) dx \f]; 362 ; 363 where \f$p(x)\f$ is the Landau probability density function :; 364 \f[ p(x) = \frac{1}{\xi} \phi (\lambda) \f]; 365 with; 366 \f[ \phi(\lambda) = \frac{1}{2 \pi i}\int_{c-i\infty}^{c+i\infty} e^{\lambda s + s \log{s}} ds\f]; 367 with \f$\lambda = (x-x_0)/\xi\f$. For a detailed description see; 368 K.S. K&ouml;lbig and B. Schorr, A program package for the Landau distribution,; 369 <A HREF=""http://dx.doi.org/10.1016/0010-4655(84)90085-7"">Computer Phys. Comm. 31 (1984) 97-111</A>; 370 <A HREF=""http://dx.doi.org/10.1016/j.cpc.2008.03.002"">[Erratum-ibid. 178 (2008) 972]</A>.; 371 The same algorithms as in; 372 <A HREF=""https://cern-tex.web.cern.ch/cern-tex/shortwrupsdir/g110/top.html"">; 373 CERNLIB</A> (DISLAN) is used.; 374 ; 375 @param x The argument \f$x\f$; 376 @param xi The width parameter \f$\xi\f$; 377 @param x0 The location parameter \f$x_0\f$; 378 ; 379 @ingroup ProbFunc; 380 ; 381 */; 382 ; 383 double landau_cdf(double x, double xi = 1, double x0 = 0);; 384 ; 385 /**; 386 ; 387 Complement of the distribution function of the Landau; 388 distribution (upper tail).; 389 ; 390 \f[ ",MatchSource.WIKI,doc/master/ProbFuncMathCore_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ProbFuncMathCore_8h_source.html
https://root.cern/doc/master/ProbFuncMathCore_8h_source.html:12485,Testability,log,lognormal,12485,"ithms as in; 372 <A HREF=""https://cern-tex.web.cern.ch/cern-tex/shortwrupsdir/g110/top.html"">; 373 CERNLIB</A> (DISLAN) is used.; 374 ; 375 @param x The argument \f$x\f$; 376 @param xi The width parameter \f$\xi\f$; 377 @param x0 The location parameter \f$x_0\f$; 378 ; 379 @ingroup ProbFunc; 380 ; 381 */; 382 ; 383 double landau_cdf(double x, double xi = 1, double x0 = 0);; 384 ; 385 /**; 386 ; 387 Complement of the distribution function of the Landau; 388 distribution (upper tail).; 389 ; 390 \f[ D(x) = \int_{x}^{+\infty} p(x) dx \f]; 391 ; 392 where p(x) is the Landau probability density function.; 393 It is implemented simply as 1. - #landau_cdf; 394 ; 395 @param x The argument \f$x\f$; 396 @param xi The width parameter \f$\xi\f$; 397 @param x0 The location parameter \f$x_0\f$; 398 ; 399 @ingroup ProbFunc; 400 ; 401 */; 402 inline double landau_cdf_c(double x, double xi = 1, double x0 = 0) {; 403 return 1. - landau_cdf(x,xi,x0);; 404 }; 405 ; 406 /**; 407 ; 408 Complement of the cumulative distribution function of the lognormal distribution; 409 (upper tail).; 410 ; 411 \f[ D(x) = \int_{x}^{+\infty} {1 \over x' \sqrt{2 \pi s^2} } e^{-(\ln{x'} - m)^2/2 s^2} dx' \f]; 412 ; 413 For detailed description see; 414 <A HREF=""http://mathworld.wolfram.com/LogNormalDistribution.html"">; 415 Mathworld</A>.; 416 ; 417 @ingroup ProbFunc; 418 ; 419 */; 420 ; 421 double lognormal_cdf_c(double x, double m, double s, double x0 = 0);; 422 ; 423 ; 424 ; 425 ; 426 /**; 427 ; 428 Cumulative distribution function of the lognormal distribution; 429 (lower tail).; 430 ; 431 \f[ D(x) = \int_{-\infty}^{x} {1 \over x' \sqrt{2 \pi s^2} } e^{-(\ln{x'} - m)^2/2 s^2} dx' \f]; 432 ; 433 For detailed description see; 434 <A HREF=""http://mathworld.wolfram.com/LogNormalDistribution.html"">; 435 Mathworld</A>.; 436 ; 437 @ingroup ProbFunc; 438 ; 439 */; 440 ; 441 double lognormal_cdf(double x, double m, double s, double x0 = 0);; 442 ; 443 ; 444 ; 445 ; 446 /**; 447 ; 448 Complement of the cumulative ",MatchSource.WIKI,doc/master/ProbFuncMathCore_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ProbFuncMathCore_8h_source.html
https://root.cern/doc/master/ProbFuncMathCore_8h_source.html:12973,Testability,log,lognormal,12973," of the Landau; 388 distribution (upper tail).; 389 ; 390 \f[ D(x) = \int_{x}^{+\infty} p(x) dx \f]; 391 ; 392 where p(x) is the Landau probability density function.; 393 It is implemented simply as 1. - #landau_cdf; 394 ; 395 @param x The argument \f$x\f$; 396 @param xi The width parameter \f$\xi\f$; 397 @param x0 The location parameter \f$x_0\f$; 398 ; 399 @ingroup ProbFunc; 400 ; 401 */; 402 inline double landau_cdf_c(double x, double xi = 1, double x0 = 0) {; 403 return 1. - landau_cdf(x,xi,x0);; 404 }; 405 ; 406 /**; 407 ; 408 Complement of the cumulative distribution function of the lognormal distribution; 409 (upper tail).; 410 ; 411 \f[ D(x) = \int_{x}^{+\infty} {1 \over x' \sqrt{2 \pi s^2} } e^{-(\ln{x'} - m)^2/2 s^2} dx' \f]; 412 ; 413 For detailed description see; 414 <A HREF=""http://mathworld.wolfram.com/LogNormalDistribution.html"">; 415 Mathworld</A>.; 416 ; 417 @ingroup ProbFunc; 418 ; 419 */; 420 ; 421 double lognormal_cdf_c(double x, double m, double s, double x0 = 0);; 422 ; 423 ; 424 ; 425 ; 426 /**; 427 ; 428 Cumulative distribution function of the lognormal distribution; 429 (lower tail).; 430 ; 431 \f[ D(x) = \int_{-\infty}^{x} {1 \over x' \sqrt{2 \pi s^2} } e^{-(\ln{x'} - m)^2/2 s^2} dx' \f]; 432 ; 433 For detailed description see; 434 <A HREF=""http://mathworld.wolfram.com/LogNormalDistribution.html"">; 435 Mathworld</A>.; 436 ; 437 @ingroup ProbFunc; 438 ; 439 */; 440 ; 441 double lognormal_cdf(double x, double m, double s, double x0 = 0);; 442 ; 443 ; 444 ; 445 ; 446 /**; 447 ; 448 Complement of the cumulative distribution function of the normal (Gaussian); 449 distribution (upper tail).; 450 ; 451 \f[ D(x) = \int_{x}^{+\infty} {1 \over \sqrt{2 \pi \sigma^2}} e^{-x'^2 / 2\sigma^2} dx' \f]; 452 ; 453 For detailed description see; 454 <A HREF=""http://mathworld.wolfram.com/NormalDistribution.html"">; 455 Mathworld</A>.; 456 ; 457 @ingroup ProbFunc; 458 ; 459 */; 460 ; 461 double normal_cdf_c(double x, double sigma = 1, double x0 = 0);; 462 /// Alte",MatchSource.WIKI,doc/master/ProbFuncMathCore_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ProbFuncMathCore_8h_source.html
https://root.cern/doc/master/ProbFuncMathCore_8h_source.html:25592,Testability,log,lognormal,25592,"id char Point_t Rectangle_t WindowAttributes_t Float_t rDefinition TGWin32VirtualXProxy.cxx:168; ROOT::Math::poisson_cdfdouble poisson_cdf(unsigned int n, double mu)Cumulative distribution function of the Poisson distribution Lower tail of the integral of the poisso...Definition ProbFuncMathCore.cxx:284; ROOT::Math::crystalball_integraldouble crystalball_integral(double x, double alpha, double n, double sigma, double x0=0)Integral of the not-normalized Crystal Ball function.Definition ProbFuncMathCore.cxx:98; ROOT::Math::uniform_cdfdouble uniform_cdf(double x, double a, double b, double x0=0)Cumulative distribution function of the uniform (flat) distribution (lower tail).Definition ProbFuncMathCore.cxx:266; ROOT::Math::binomial_cdf_cdouble binomial_cdf_c(unsigned int k, double p, unsigned int n)Complement of the cumulative distribution function of the Binomial distribution.Definition ProbFuncMathCore.cxx:293; ROOT::Math::lognormal_cdfdouble lognormal_cdf(double x, double m, double s, double x0=0)Cumulative distribution function of the lognormal distribution (lower tail).Definition ProbFuncMathCore.cxx:218; ROOT::Math::cauchy_cdf_cdouble cauchy_cdf_c(double x, double b, double x0=0)Complement of the cumulative distribution function (upper tail) of the Cauchy distribution which is a...Definition ProbFuncMathCore.cxx:45; ROOT::Math::fdistribution_cdfdouble fdistribution_cdf(double x, double n, double m, double x0=0)Cumulative distribution function of the F-distribution (lower tail).Definition ProbFuncMathCore.cxx:183; ROOT::Math::binomial_cdfdouble binomial_cdf(unsigned int k, double p, unsigned int n)Cumulative distribution function of the Binomial distribution Lower tail of the integral of the binom...Definition ProbFuncMathCore.cxx:304; ROOT::Math::landau_cdfdouble landau_cdf(double x, double xi=1, double x0=0)Cumulative distribution function of the Landau distribution (lower tail).Definition ProbFuncMathCore.cxx:336; ROOT::Math::lognormal_cdf_cdouble lognormal_cdf_c",MatchSource.WIKI,doc/master/ProbFuncMathCore_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ProbFuncMathCore_8h_source.html
https://root.cern/doc/master/ProbFuncMathCore_8h_source.html:26643,Testability,log,lognormal,26643,"ion of the lognormal distribution (lower tail).Definition ProbFuncMathCore.cxx:218; ROOT::Math::cauchy_cdf_cdouble cauchy_cdf_c(double x, double b, double x0=0)Complement of the cumulative distribution function (upper tail) of the Cauchy distribution which is a...Definition ProbFuncMathCore.cxx:45; ROOT::Math::fdistribution_cdfdouble fdistribution_cdf(double x, double n, double m, double x0=0)Cumulative distribution function of the F-distribution (lower tail).Definition ProbFuncMathCore.cxx:183; ROOT::Math::binomial_cdfdouble binomial_cdf(unsigned int k, double p, unsigned int n)Cumulative distribution function of the Binomial distribution Lower tail of the integral of the binom...Definition ProbFuncMathCore.cxx:304; ROOT::Math::landau_cdfdouble landau_cdf(double x, double xi=1, double x0=0)Cumulative distribution function of the Landau distribution (lower tail).Definition ProbFuncMathCore.cxx:336; ROOT::Math::lognormal_cdf_cdouble lognormal_cdf_c(double x, double m, double s, double x0=0)Complement of the cumulative distribution function of the lognormal distribution (upper tail).Definition ProbFuncMathCore.cxx:210; ROOT::Math::uniform_cdf_cdouble uniform_cdf_c(double x, double a, double b, double x0=0)Complement of the cumulative distribution function of the uniform (flat) distribution (upper tail).Definition ProbFuncMathCore.cxx:258; ROOT::Math::fdistribution_cdf_cdouble fdistribution_cdf_c(double x, double n, double m, double x0=0)Complement of the cumulative distribution function of the F-distribution (upper tail).Definition ProbFuncMathCore.cxx:169; ROOT::Math::crystalball_cdf_cdouble crystalball_cdf_c(double x, double alpha, double n, double sigma, double x0=0)Complement of the Cumulative distribution for the Crystal Ball distribution.Definition ProbFuncMathCore.cxx:84; ROOT::Math::normal_cdf_cdouble normal_cdf_c(double x, double sigma=1, double x0=0)Complement of the cumulative distribution function of the normal (Gaussian) distribution (upper tail)...Definit",MatchSource.WIKI,doc/master/ProbFuncMathCore_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ProbFuncMathCore_8h_source.html
https://root.cern/doc/master/ProbFuncMathCore_8h_source.html:12078,Usability,simpl,simply,12078,"\f]; 367 with \f$\lambda = (x-x_0)/\xi\f$. For a detailed description see; 368 K.S. K&ouml;lbig and B. Schorr, A program package for the Landau distribution,; 369 <A HREF=""http://dx.doi.org/10.1016/0010-4655(84)90085-7"">Computer Phys. Comm. 31 (1984) 97-111</A>; 370 <A HREF=""http://dx.doi.org/10.1016/j.cpc.2008.03.002"">[Erratum-ibid. 178 (2008) 972]</A>.; 371 The same algorithms as in; 372 <A HREF=""https://cern-tex.web.cern.ch/cern-tex/shortwrupsdir/g110/top.html"">; 373 CERNLIB</A> (DISLAN) is used.; 374 ; 375 @param x The argument \f$x\f$; 376 @param xi The width parameter \f$\xi\f$; 377 @param x0 The location parameter \f$x_0\f$; 378 ; 379 @ingroup ProbFunc; 380 ; 381 */; 382 ; 383 double landau_cdf(double x, double xi = 1, double x0 = 0);; 384 ; 385 /**; 386 ; 387 Complement of the distribution function of the Landau; 388 distribution (upper tail).; 389 ; 390 \f[ D(x) = \int_{x}^{+\infty} p(x) dx \f]; 391 ; 392 where p(x) is the Landau probability density function.; 393 It is implemented simply as 1. - #landau_cdf; 394 ; 395 @param x The argument \f$x\f$; 396 @param xi The width parameter \f$\xi\f$; 397 @param x0 The location parameter \f$x_0\f$; 398 ; 399 @ingroup ProbFunc; 400 ; 401 */; 402 inline double landau_cdf_c(double x, double xi = 1, double x0 = 0) {; 403 return 1. - landau_cdf(x,xi,x0);; 404 }; 405 ; 406 /**; 407 ; 408 Complement of the cumulative distribution function of the lognormal distribution; 409 (upper tail).; 410 ; 411 \f[ D(x) = \int_{x}^{+\infty} {1 \over x' \sqrt{2 \pi s^2} } e^{-(\ln{x'} - m)^2/2 s^2} dx' \f]; 412 ; 413 For detailed description see; 414 <A HREF=""http://mathworld.wolfram.com/LogNormalDistribution.html"">; 415 Mathworld</A>.; 416 ; 417 @ingroup ProbFunc; 418 ; 419 */; 420 ; 421 double lognormal_cdf_c(double x, double m, double s, double x0 = 0);; 422 ; 423 ; 424 ; 425 ; 426 /**; 427 ; 428 Cumulative distribution function of the lognormal distribution; 429 (lower tail).; 430 ; 431 \f[ D(x) = \int_{-\infty}^{x} {1 \over x' \sqr",MatchSource.WIKI,doc/master/ProbFuncMathCore_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ProbFuncMathCore_8h_source.html
https://root.cern/doc/master/Prototype_8cxx.html:311,Integrability,depend,dependency,311,". ROOT: tmva/sofie/src/Prototype.cxx File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. Functions ; Prototype.cxx File Reference. #include <memory>; #include ""TMVA/RModel.hxx""; #include ""TMVA/RModelParser_ONNX.hxx""; #include <cctype>; #include <algorithm>. Include dependency graph for Prototype.cxx:. This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead. Functions; intmain (); . Function Documentation. main(). int main ; (; ). Definition at line 12 of file Prototype.cxx. tmvasofiesrcPrototype.cxx. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:25 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/Prototype_8cxx.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Prototype_8cxx.html
https://root.cern/doc/master/pstable_8C.html:5570,Usability,simpl,simple,5570,"; t.DrawText(xc1,y,text);; sprintf(text,""`%s"",symbol[i]);; t.DrawText(xc2,y,text);; sprintf(text,""'%s"",symbol[i]);; t.DrawText(xc3,y,text);; sprintf(text,""~%s"",symbol[i]);; t.DrawText(xc4,y,text);; y -= dy;; }; }; h#define h(i)Definition RSha256.hxx:106; Bool_tbool Bool_tDefinition RtypesCore.h:63; Int_tint Int_tDefinition RtypesCore.h:45; Float_tfloat Float_tDefinition RtypesCore.h:57; wwinID wDefinition TGWin32VirtualGLProxy.cxx:39; valueOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void valueDefinition TGWin32VirtualXProxy.cxx:142; x2Option_t Option_t TPoint TPoint const char x2Definition TGWin32VirtualXProxy.cxx:70; x1Option_t Option_t TPoint TPoint const char x1Definition TGWin32VirtualXProxy.cxx:70; y2Option_t Option_t TPoint TPoint const char y2Definition TGWin32VirtualXProxy.cxx:70; textOption_t Option_t TPoint TPoint const char textDefinition TGWin32VirtualXProxy.cxx:68; y1Option_t Option_t TPoint TPoint const char y1Definition TGWin32VirtualXProxy.cxx:70; TCanvasThe Canvas class.Definition TCanvas.h:23; TLineUse the TLine constructor to create a simple line.Definition TLine.h:22; TLine::DrawLinevirtual TLine * DrawLine(Double_t x1, Double_t y1, Double_t x2, Double_t y2)Draw this line with new coordinates.Definition TLine.cxx:103; TTextBase class for several text objects.Definition TText.h:22; TText::DrawTextvirtual TText * DrawText(Double_t x, Double_t y, const char *text)Draw this text with new coordinates.Definition TText.cxx:176; lineTLine * lineDefinition entrylistblock_figure1.C:235; yDouble_t y[n]Definition legend1.C:17; c1return c1Definition legend1.C:41; nconst Int_t nDefinition legend1.C:16; c2return c2Definition legend2.C:14; c3return c3Definition legend3.C:15; AuthorOlivier Couet ; Definition in file pstable.C. tutorialsgraphicspstable.C. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:29 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/pstable_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pstable_8C.html
https://root.cern/doc/master/psview_8C.html:336,Deployability,install,install,336,". ROOT: tutorials/graphics/psview.C File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. psview.C File ReferenceTutorials  Graphics tutorials. Detailed Description; An example how to display PS, EPS, PDF files in canvas. ; To load a PS file in a TCanvas, the ghostscript program needs to be install.; On most unix systems it is installed by default.; On Windows it has to be installed from http://pages.cs.wisc.edu/~ghost/ also the place where gswin32c.exe sits should be added in the PATH. One way to do it is:; Start the Control Panel; Double click on System 3, Open the ""Advanced"" tab; Click on the ""Environment Variables"" button; Find ""Path"" in ""System variable list"", click on it.; Click on the ""Edit"" button.; In the ""Variable value"" field add the path of gswin32c (after a "";"") it should be something like: ""C:\Program Files\gs\gs8.13\bin""; click ""OK"" as much as needed. ; #include ""TROOT.h""; #include ""TCanvas.h""; #include ""TImage.h""; ; void psview(); {; // set to batch mode -> do not display graphics; gROOT->SetBatch(1);; ; // create a PostScript file; TString dir = gROOT->GetTutorialDir();; dir.Append(""/graphics/feynman.C"");; gROOT->Macro(dir);; gPad->Print(""feynman.eps"");; ; // back to graphics mode; gROOT->SetBatch(0);; ; // create an image from PS file; TImage *ps = TImage::Open(""feynman.eps"");; ; if (!ps) {; printf(""GhostScript (gs) program must be installed\n"");; return;; }; ; new TCanvas(""psexam"", ""Example how to display PS file in canvas"", 600, 400);; TLatex *tex = new TLatex(0.06,0.9,""The picture below has been loaded from a PS file:"");; tex->Draw();; ; TPad *eps = new TPad(""eps"", ""eps"", 0., 0., 1., 0.75);; eps->Draw();; eps->cd();; ps->Draw(""xxx"");; }; TCanvas.h; TImage.h; TROOT.h; gROOT#define gROOTDefinition TROOT.h:406; gPad#define gPadDefinition TVirtualPad.h:308; TCanvasThe Canvas class.Definition TCanvas.h:23; TImageAn abstract interface to image processing library.Definition TImage.h:29; TImage::Openstatic TIma",MatchSource.WIKI,doc/master/psview_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/psview_8C.html
https://root.cern/doc/master/psview_8C.html:373,Deployability,install,installed,373,". ROOT: tutorials/graphics/psview.C File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. psview.C File ReferenceTutorials  Graphics tutorials. Detailed Description; An example how to display PS, EPS, PDF files in canvas. ; To load a PS file in a TCanvas, the ghostscript program needs to be install.; On most unix systems it is installed by default.; On Windows it has to be installed from http://pages.cs.wisc.edu/~ghost/ also the place where gswin32c.exe sits should be added in the PATH. One way to do it is:; Start the Control Panel; Double click on System 3, Open the ""Advanced"" tab; Click on the ""Environment Variables"" button; Find ""Path"" in ""System variable list"", click on it.; Click on the ""Edit"" button.; In the ""Variable value"" field add the path of gswin32c (after a "";"") it should be something like: ""C:\Program Files\gs\gs8.13\bin""; click ""OK"" as much as needed. ; #include ""TROOT.h""; #include ""TCanvas.h""; #include ""TImage.h""; ; void psview(); {; // set to batch mode -> do not display graphics; gROOT->SetBatch(1);; ; // create a PostScript file; TString dir = gROOT->GetTutorialDir();; dir.Append(""/graphics/feynman.C"");; gROOT->Macro(dir);; gPad->Print(""feynman.eps"");; ; // back to graphics mode; gROOT->SetBatch(0);; ; // create an image from PS file; TImage *ps = TImage::Open(""feynman.eps"");; ; if (!ps) {; printf(""GhostScript (gs) program must be installed\n"");; return;; }; ; new TCanvas(""psexam"", ""Example how to display PS file in canvas"", 600, 400);; TLatex *tex = new TLatex(0.06,0.9,""The picture below has been loaded from a PS file:"");; tex->Draw();; ; TPad *eps = new TPad(""eps"", ""eps"", 0., 0., 1., 0.75);; eps->Draw();; eps->cd();; ps->Draw(""xxx"");; }; TCanvas.h; TImage.h; TROOT.h; gROOT#define gROOTDefinition TROOT.h:406; gPad#define gPadDefinition TVirtualPad.h:308; TCanvasThe Canvas class.Definition TCanvas.h:23; TImageAn abstract interface to image processing library.Definition TImage.h:29; TImage::Openstatic TIma",MatchSource.WIKI,doc/master/psview_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/psview_8C.html
https://root.cern/doc/master/psview_8C.html:420,Deployability,install,installed,420,". ROOT: tutorials/graphics/psview.C File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. psview.C File ReferenceTutorials  Graphics tutorials. Detailed Description; An example how to display PS, EPS, PDF files in canvas. ; To load a PS file in a TCanvas, the ghostscript program needs to be install.; On most unix systems it is installed by default.; On Windows it has to be installed from http://pages.cs.wisc.edu/~ghost/ also the place where gswin32c.exe sits should be added in the PATH. One way to do it is:; Start the Control Panel; Double click on System 3, Open the ""Advanced"" tab; Click on the ""Environment Variables"" button; Find ""Path"" in ""System variable list"", click on it.; Click on the ""Edit"" button.; In the ""Variable value"" field add the path of gswin32c (after a "";"") it should be something like: ""C:\Program Files\gs\gs8.13\bin""; click ""OK"" as much as needed. ; #include ""TROOT.h""; #include ""TCanvas.h""; #include ""TImage.h""; ; void psview(); {; // set to batch mode -> do not display graphics; gROOT->SetBatch(1);; ; // create a PostScript file; TString dir = gROOT->GetTutorialDir();; dir.Append(""/graphics/feynman.C"");; gROOT->Macro(dir);; gPad->Print(""feynman.eps"");; ; // back to graphics mode; gROOT->SetBatch(0);; ; // create an image from PS file; TImage *ps = TImage::Open(""feynman.eps"");; ; if (!ps) {; printf(""GhostScript (gs) program must be installed\n"");; return;; }; ; new TCanvas(""psexam"", ""Example how to display PS file in canvas"", 600, 400);; TLatex *tex = new TLatex(0.06,0.9,""The picture below has been loaded from a PS file:"");; tex->Draw();; ; TPad *eps = new TPad(""eps"", ""eps"", 0., 0., 1., 0.75);; eps->Draw();; eps->cd();; ps->Draw(""xxx"");; }; TCanvas.h; TImage.h; TROOT.h; gROOT#define gROOTDefinition TROOT.h:406; gPad#define gPadDefinition TVirtualPad.h:308; TCanvasThe Canvas class.Definition TCanvas.h:23; TImageAn abstract interface to image processing library.Definition TImage.h:29; TImage::Openstatic TIma",MatchSource.WIKI,doc/master/psview_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/psview_8C.html
https://root.cern/doc/master/psview_8C.html:1416,Deployability,install,installed,1416,"isc.edu/~ghost/ also the place where gswin32c.exe sits should be added in the PATH. One way to do it is:; Start the Control Panel; Double click on System 3, Open the ""Advanced"" tab; Click on the ""Environment Variables"" button; Find ""Path"" in ""System variable list"", click on it.; Click on the ""Edit"" button.; In the ""Variable value"" field add the path of gswin32c (after a "";"") it should be something like: ""C:\Program Files\gs\gs8.13\bin""; click ""OK"" as much as needed. ; #include ""TROOT.h""; #include ""TCanvas.h""; #include ""TImage.h""; ; void psview(); {; // set to batch mode -> do not display graphics; gROOT->SetBatch(1);; ; // create a PostScript file; TString dir = gROOT->GetTutorialDir();; dir.Append(""/graphics/feynman.C"");; gROOT->Macro(dir);; gPad->Print(""feynman.eps"");; ; // back to graphics mode; gROOT->SetBatch(0);; ; // create an image from PS file; TImage *ps = TImage::Open(""feynman.eps"");; ; if (!ps) {; printf(""GhostScript (gs) program must be installed\n"");; return;; }; ; new TCanvas(""psexam"", ""Example how to display PS file in canvas"", 600, 400);; TLatex *tex = new TLatex(0.06,0.9,""The picture below has been loaded from a PS file:"");; tex->Draw();; ; TPad *eps = new TPad(""eps"", ""eps"", 0., 0., 1., 0.75);; eps->Draw();; eps->cd();; ps->Draw(""xxx"");; }; TCanvas.h; TImage.h; TROOT.h; gROOT#define gROOTDefinition TROOT.h:406; gPad#define gPadDefinition TVirtualPad.h:308; TCanvasThe Canvas class.Definition TCanvas.h:23; TImageAn abstract interface to image processing library.Definition TImage.h:29; TImage::Openstatic TImage * Open(const char *file, EImageFileTypes type=kUnknown)Open a specified image file.Definition TImage.cxx:118; TLatexTo draw Mathematical Formula.Definition TLatex.h:18; TObject::Drawvirtual void Draw(Option_t *option="""")Default Draw method for all objects.Definition TObject.cxx:280; TPadThe most important graphics class in the ROOT system.Definition TPad.h:28; TPad::cdTVirtualPad * cd(Int_t subpadnumber=0) overrideSet Current pad.Definition TPa",MatchSource.WIKI,doc/master/psview_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/psview_8C.html
https://root.cern/doc/master/psview_8C.html:1916,Integrability,interface,interface,1916,""" as much as needed. ; #include ""TROOT.h""; #include ""TCanvas.h""; #include ""TImage.h""; ; void psview(); {; // set to batch mode -> do not display graphics; gROOT->SetBatch(1);; ; // create a PostScript file; TString dir = gROOT->GetTutorialDir();; dir.Append(""/graphics/feynman.C"");; gROOT->Macro(dir);; gPad->Print(""feynman.eps"");; ; // back to graphics mode; gROOT->SetBatch(0);; ; // create an image from PS file; TImage *ps = TImage::Open(""feynman.eps"");; ; if (!ps) {; printf(""GhostScript (gs) program must be installed\n"");; return;; }; ; new TCanvas(""psexam"", ""Example how to display PS file in canvas"", 600, 400);; TLatex *tex = new TLatex(0.06,0.9,""The picture below has been loaded from a PS file:"");; tex->Draw();; ; TPad *eps = new TPad(""eps"", ""eps"", 0., 0., 1., 0.75);; eps->Draw();; eps->cd();; ps->Draw(""xxx"");; }; TCanvas.h; TImage.h; TROOT.h; gROOT#define gROOTDefinition TROOT.h:406; gPad#define gPadDefinition TVirtualPad.h:308; TCanvasThe Canvas class.Definition TCanvas.h:23; TImageAn abstract interface to image processing library.Definition TImage.h:29; TImage::Openstatic TImage * Open(const char *file, EImageFileTypes type=kUnknown)Open a specified image file.Definition TImage.cxx:118; TLatexTo draw Mathematical Formula.Definition TLatex.h:18; TObject::Drawvirtual void Draw(Option_t *option="""")Default Draw method for all objects.Definition TObject.cxx:280; TPadThe most important graphics class in the ROOT system.Definition TPad.h:28; TPad::cdTVirtualPad * cd(Int_t subpadnumber=0) overrideSet Current pad.Definition TPad.cxx:693; TPad::Drawvoid Draw(Option_t *option="""") overrideDraw Pad in Current pad (re-parent pad if necessary).Definition TPad.cxx:1364; TStringBasic string class.Definition TString.h:139; TString::AppendTString & Append(const char *cs)Definition TString.h:572; AuthorValeriy Onoutchin ; Definition in file psview.C. tutorialsgraphicspsview.C. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:29 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/psview_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/psview_8C.html
https://root.cern/doc/master/psview_8C.html:702,Modifiability,variab,variable,702,". ROOT: tutorials/graphics/psview.C File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. psview.C File ReferenceTutorials  Graphics tutorials. Detailed Description; An example how to display PS, EPS, PDF files in canvas. ; To load a PS file in a TCanvas, the ghostscript program needs to be install.; On most unix systems it is installed by default.; On Windows it has to be installed from http://pages.cs.wisc.edu/~ghost/ also the place where gswin32c.exe sits should be added in the PATH. One way to do it is:; Start the Control Panel; Double click on System 3, Open the ""Advanced"" tab; Click on the ""Environment Variables"" button; Find ""Path"" in ""System variable list"", click on it.; Click on the ""Edit"" button.; In the ""Variable value"" field add the path of gswin32c (after a "";"") it should be something like: ""C:\Program Files\gs\gs8.13\bin""; click ""OK"" as much as needed. ; #include ""TROOT.h""; #include ""TCanvas.h""; #include ""TImage.h""; ; void psview(); {; // set to batch mode -> do not display graphics; gROOT->SetBatch(1);; ; // create a PostScript file; TString dir = gROOT->GetTutorialDir();; dir.Append(""/graphics/feynman.C"");; gROOT->Macro(dir);; gPad->Print(""feynman.eps"");; ; // back to graphics mode; gROOT->SetBatch(0);; ; // create an image from PS file; TImage *ps = TImage::Open(""feynman.eps"");; ; if (!ps) {; printf(""GhostScript (gs) program must be installed\n"");; return;; }; ; new TCanvas(""psexam"", ""Example how to display PS file in canvas"", 600, 400);; TLatex *tex = new TLatex(0.06,0.9,""The picture below has been loaded from a PS file:"");; tex->Draw();; ; TPad *eps = new TPad(""eps"", ""eps"", 0., 0., 1., 0.75);; eps->Draw();; eps->cd();; ps->Draw(""xxx"");; }; TCanvas.h; TImage.h; TROOT.h; gROOT#define gROOTDefinition TROOT.h:406; gPad#define gPadDefinition TVirtualPad.h:308; TCanvasThe Canvas class.Definition TCanvas.h:23; TImageAn abstract interface to image processing library.Definition TImage.h:29; TImage::Openstatic TIma",MatchSource.WIKI,doc/master/psview_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/psview_8C.html
https://root.cern/doc/master/psview_8C.html:271,Performance,load,load,271,". ROOT: tutorials/graphics/psview.C File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. psview.C File ReferenceTutorials  Graphics tutorials. Detailed Description; An example how to display PS, EPS, PDF files in canvas. ; To load a PS file in a TCanvas, the ghostscript program needs to be install.; On most unix systems it is installed by default.; On Windows it has to be installed from http://pages.cs.wisc.edu/~ghost/ also the place where gswin32c.exe sits should be added in the PATH. One way to do it is:; Start the Control Panel; Double click on System 3, Open the ""Advanced"" tab; Click on the ""Environment Variables"" button; Find ""Path"" in ""System variable list"", click on it.; Click on the ""Edit"" button.; In the ""Variable value"" field add the path of gswin32c (after a "";"") it should be something like: ""C:\Program Files\gs\gs8.13\bin""; click ""OK"" as much as needed. ; #include ""TROOT.h""; #include ""TCanvas.h""; #include ""TImage.h""; ; void psview(); {; // set to batch mode -> do not display graphics; gROOT->SetBatch(1);; ; // create a PostScript file; TString dir = gROOT->GetTutorialDir();; dir.Append(""/graphics/feynman.C"");; gROOT->Macro(dir);; gPad->Print(""feynman.eps"");; ; // back to graphics mode; gROOT->SetBatch(0);; ; // create an image from PS file; TImage *ps = TImage::Open(""feynman.eps"");; ; if (!ps) {; printf(""GhostScript (gs) program must be installed\n"");; return;; }; ; new TCanvas(""psexam"", ""Example how to display PS file in canvas"", 600, 400);; TLatex *tex = new TLatex(0.06,0.9,""The picture below has been loaded from a PS file:"");; tex->Draw();; ; TPad *eps = new TPad(""eps"", ""eps"", 0., 0., 1., 0.75);; eps->Draw();; eps->cd();; ps->Draw(""xxx"");; }; TCanvas.h; TImage.h; TROOT.h; gROOT#define gROOTDefinition TROOT.h:406; gPad#define gPadDefinition TVirtualPad.h:308; TCanvasThe Canvas class.Definition TCanvas.h:23; TImageAn abstract interface to image processing library.Definition TImage.h:29; TImage::Openstatic TIma",MatchSource.WIKI,doc/master/psview_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/psview_8C.html
https://root.cern/doc/master/psview_8C.html:1586,Performance,load,loaded,1586,"en the ""Advanced"" tab; Click on the ""Environment Variables"" button; Find ""Path"" in ""System variable list"", click on it.; Click on the ""Edit"" button.; In the ""Variable value"" field add the path of gswin32c (after a "";"") it should be something like: ""C:\Program Files\gs\gs8.13\bin""; click ""OK"" as much as needed. ; #include ""TROOT.h""; #include ""TCanvas.h""; #include ""TImage.h""; ; void psview(); {; // set to batch mode -> do not display graphics; gROOT->SetBatch(1);; ; // create a PostScript file; TString dir = gROOT->GetTutorialDir();; dir.Append(""/graphics/feynman.C"");; gROOT->Macro(dir);; gPad->Print(""feynman.eps"");; ; // back to graphics mode; gROOT->SetBatch(0);; ; // create an image from PS file; TImage *ps = TImage::Open(""feynman.eps"");; ; if (!ps) {; printf(""GhostScript (gs) program must be installed\n"");; return;; }; ; new TCanvas(""psexam"", ""Example how to display PS file in canvas"", 600, 400);; TLatex *tex = new TLatex(0.06,0.9,""The picture below has been loaded from a PS file:"");; tex->Draw();; ; TPad *eps = new TPad(""eps"", ""eps"", 0., 0., 1., 0.75);; eps->Draw();; eps->cd();; ps->Draw(""xxx"");; }; TCanvas.h; TImage.h; TROOT.h; gROOT#define gROOTDefinition TROOT.h:406; gPad#define gPadDefinition TVirtualPad.h:308; TCanvasThe Canvas class.Definition TCanvas.h:23; TImageAn abstract interface to image processing library.Definition TImage.h:29; TImage::Openstatic TImage * Open(const char *file, EImageFileTypes type=kUnknown)Open a specified image file.Definition TImage.cxx:118; TLatexTo draw Mathematical Formula.Definition TLatex.h:18; TObject::Drawvirtual void Draw(Option_t *option="""")Default Draw method for all objects.Definition TObject.cxx:280; TPadThe most important graphics class in the ROOT system.Definition TPad.h:28; TPad::cdTVirtualPad * cd(Int_t subpadnumber=0) overrideSet Current pad.Definition TPad.cxx:693; TPad::Drawvoid Draw(Option_t *option="""") overrideDraw Pad in Current pad (re-parent pad if necessary).Definition TPad.cxx:1364; TStringBasic string ",MatchSource.WIKI,doc/master/psview_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/psview_8C.html
https://root.cern/doc/master/PyMethodBase_8cxx_source.html:6963,Availability,alive,alive,6963,") {; 177 Log << kFATAL << ""Can't init global namespace"" << Endl;; 178 Log << Endl;; 179 }; 180 Py_INCREF(fGlobalNS);; 181 ; 182 #if PY_MAJOR_VERSION < 3; 183 //preparing objects for eval; 184 PyObject *bName = PyUnicode_FromString(""__builtin__"");; 185 // Import the file as a Python module.; 186 // returns a new reference; 187 fModuleBuiltin = PyImport_Import(bName);; 188 if (!fModuleBuiltin) {; 189 Log << kFATAL << ""Can't import __builtin__"" << Endl;; 190 Log << Endl;; 191 }; 192 #else; 193 //preparing objects for eval; 194 PyObject *bName = PyUnicode_FromString(""builtins"");; 195 // Import the file as a Python module.; 196 fModuleBuiltin = PyImport_Import(bName);; 197 if (!fModuleBuiltin) {; 198 Log << kFATAL << ""Can't import builtins"" << Endl;; 199 Log << Endl;; 200 }; 201 #endif; 202 ; 203 // note mDict is a borrowed reference; 204 PyObject *mDict = PyModule_GetDict(fModuleBuiltin);; 205 fEval = PyDict_GetItemString(mDict, ""eval"");; 206 fOpen = PyDict_GetItemString(mDict, ""open"");; 207 // fEval and fOpen are borrowed referencers and we need to keep them alive; 208 if (fEval) Py_INCREF(fEval);; 209 if (fOpen) Py_INCREF(fOpen);; 210 ; 211 // bName is a new reference (from PyUnicode_FromString); 212 Py_DECREF(bName);; 213 ; 214 //preparing objects for pickle; 215 PyObject *pName = PyUnicode_FromString(""pickle"");; 216 // Import the file as a Python module.; 217 // return object is a new reference !; 218 fModulePickle = PyImport_Import(pName);; 219 if (!fModulePickle) {; 220 Log << kFATAL << ""Can't import pickle"" << Endl;; 221 Log << Endl;; 222 }; 223 PyObject *pDict = PyModule_GetDict(fModulePickle);; 224 // note the following return objects are borrowed references; 225 fPickleDumps = PyDict_GetItemString(pDict, ""dump"");; 226 fPickleLoads = PyDict_GetItemString(pDict, ""load"");; 227 if (fPickleDumps) Py_INCREF(fPickleDumps);; 228 if (fPickleLoads) Py_INCREF(fPickleLoads);; 229 ; 230 Py_DECREF(pName);; 231}; 232 ; 233//////////////////////////////////////////////////////",MatchSource.WIKI,doc/master/PyMethodBase_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/PyMethodBase_8cxx_source.html
https://root.cern/doc/master/PyMethodBase_8cxx_source.html:10756,Availability,error,errorMessage,10756,,MatchSource.WIKI,doc/master/PyMethodBase_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/PyMethodBase_8cxx_source.html
https://root.cern/doc/master/PyMethodBase_8cxx_source.html:10960,Availability,error,error,10960,,MatchSource.WIKI,doc/master/PyMethodBase_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/PyMethodBase_8cxx_source.html
https://root.cern/doc/master/PyMethodBase_8cxx_source.html:11159,Availability,error,errorMessage,11159,"),""rb"");; 298 PyObject *file = PyObject_CallObject(fOpen,file_arg);; 299 if(!file) return 1;; 300 ; 301 // Load object from file using pickle; 302 PyObject *model_arg = Py_BuildValue(""(O)"", file);; 303 *obj = PyObject_CallObject(fPickleLoads , model_arg);; 304 if(!obj) return 2;; 305 ; 306 Py_DECREF(file_arg);; 307 Py_DECREF(file);; 308 Py_DECREF(model_arg);; 309 ; 310 return 0;; 311}; 312 ; 313///////////////////////////////////////////////////////////////////////////////; 314/// Execute Python code from string; 315///; 316/// \param[in] code Python code as string; 317/// \param[in] errorMessage Error message which shall be shown if the execution fails; 318/// \param[in] start Start symbol; 319///; 320/// Helper function to run python code from string in local namespace with; 321/// error handling; 322/// `start` defines the start symbol defined in PyRun_String (Py_eval_input,; 323/// Py_single_input, Py_file_input); 324 ; 325void PyMethodBase::PyRunString(TString code, TString errorMessage, int start) {; 326 //std::cout << ""Run: >> "" << code << std::endl;; 327 fPyReturn = PyRun_String(code, start, fGlobalNS, fLocalNS);; 328 if (!fPyReturn) {; 329 Log() << kWARNING << ""Failed to run python code: "" << code << Endl;; 330 Log() << kWARNING << ""Python error message:"" << Endl;; 331 PyErr_Print();; 332 Log() << kFATAL << errorMessage << Endl;; 333 }; 334}; 335 ; 336///////////////////////////////////////////////////////////////////////////////; 337/// Execute Python code from string; 338///; 339/// \param[in] code Python code as string; 340/// \param[in] globalNS Global Namespace for Python Session; 341/// \param[in] localNS Local Namespace for Python Session; 342///; 343/// Overloaded static Helper function to run python code; 344/// from string and throw runtime error if the Python session; 345/// is unable to execute the code; 346 ; 347void PyMethodBase::PyRunString(TString code, PyObject *globalNS, PyObject *localNS){; 348 PyObject *fPyReturn = PyRun_String(code, Py_s",MatchSource.WIKI,doc/master/PyMethodBase_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/PyMethodBase_8cxx_source.html
https://root.cern/doc/master/PyMethodBase_8cxx_source.html:11434,Availability,error,error,11434,"turn 2;; 305 ; 306 Py_DECREF(file_arg);; 307 Py_DECREF(file);; 308 Py_DECREF(model_arg);; 309 ; 310 return 0;; 311}; 312 ; 313///////////////////////////////////////////////////////////////////////////////; 314/// Execute Python code from string; 315///; 316/// \param[in] code Python code as string; 317/// \param[in] errorMessage Error message which shall be shown if the execution fails; 318/// \param[in] start Start symbol; 319///; 320/// Helper function to run python code from string in local namespace with; 321/// error handling; 322/// `start` defines the start symbol defined in PyRun_String (Py_eval_input,; 323/// Py_single_input, Py_file_input); 324 ; 325void PyMethodBase::PyRunString(TString code, TString errorMessage, int start) {; 326 //std::cout << ""Run: >> "" << code << std::endl;; 327 fPyReturn = PyRun_String(code, start, fGlobalNS, fLocalNS);; 328 if (!fPyReturn) {; 329 Log() << kWARNING << ""Failed to run python code: "" << code << Endl;; 330 Log() << kWARNING << ""Python error message:"" << Endl;; 331 PyErr_Print();; 332 Log() << kFATAL << errorMessage << Endl;; 333 }; 334}; 335 ; 336///////////////////////////////////////////////////////////////////////////////; 337/// Execute Python code from string; 338///; 339/// \param[in] code Python code as string; 340/// \param[in] globalNS Global Namespace for Python Session; 341/// \param[in] localNS Local Namespace for Python Session; 342///; 343/// Overloaded static Helper function to run python code; 344/// from string and throw runtime error if the Python session; 345/// is unable to execute the code; 346 ; 347void PyMethodBase::PyRunString(TString code, PyObject *globalNS, PyObject *localNS){; 348 PyObject *fPyReturn = PyRun_String(code, Py_single_input, globalNS, localNS);; 349 if (!fPyReturn) {; 350 std::cout<<""\nPython error message:\n"";; 351 PyErr_Print();; 352 throw std::runtime_error(""\nFailed to run python code: ""+code);; 353 }; 354}; 355 ; 356//////////////////////////////////////////////////////////",MatchSource.WIKI,doc/master/PyMethodBase_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/PyMethodBase_8cxx_source.html
https://root.cern/doc/master/PyMethodBase_8cxx_source.html:11503,Availability,error,errorMessage,11503,"CREF(model_arg);; 309 ; 310 return 0;; 311}; 312 ; 313///////////////////////////////////////////////////////////////////////////////; 314/// Execute Python code from string; 315///; 316/// \param[in] code Python code as string; 317/// \param[in] errorMessage Error message which shall be shown if the execution fails; 318/// \param[in] start Start symbol; 319///; 320/// Helper function to run python code from string in local namespace with; 321/// error handling; 322/// `start` defines the start symbol defined in PyRun_String (Py_eval_input,; 323/// Py_single_input, Py_file_input); 324 ; 325void PyMethodBase::PyRunString(TString code, TString errorMessage, int start) {; 326 //std::cout << ""Run: >> "" << code << std::endl;; 327 fPyReturn = PyRun_String(code, start, fGlobalNS, fLocalNS);; 328 if (!fPyReturn) {; 329 Log() << kWARNING << ""Failed to run python code: "" << code << Endl;; 330 Log() << kWARNING << ""Python error message:"" << Endl;; 331 PyErr_Print();; 332 Log() << kFATAL << errorMessage << Endl;; 333 }; 334}; 335 ; 336///////////////////////////////////////////////////////////////////////////////; 337/// Execute Python code from string; 338///; 339/// \param[in] code Python code as string; 340/// \param[in] globalNS Global Namespace for Python Session; 341/// \param[in] localNS Local Namespace for Python Session; 342///; 343/// Overloaded static Helper function to run python code; 344/// from string and throw runtime error if the Python session; 345/// is unable to execute the code; 346 ; 347void PyMethodBase::PyRunString(TString code, PyObject *globalNS, PyObject *localNS){; 348 PyObject *fPyReturn = PyRun_String(code, Py_single_input, globalNS, localNS);; 349 if (!fPyReturn) {; 350 std::cout<<""\nPython error message:\n"";; 351 PyErr_Print();; 352 throw std::runtime_error(""\nFailed to run python code: ""+code);; 353 }; 354}; 355 ; 356///////////////////////////////////////////////////////////////////////////////; 357/// Returns `const char*` from Python string in",MatchSource.WIKI,doc/master/PyMethodBase_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/PyMethodBase_8cxx_source.html
https://root.cern/doc/master/PyMethodBase_8cxx_source.html:11955,Availability,error,error,11955,"/ error handling; 322/// `start` defines the start symbol defined in PyRun_String (Py_eval_input,; 323/// Py_single_input, Py_file_input); 324 ; 325void PyMethodBase::PyRunString(TString code, TString errorMessage, int start) {; 326 //std::cout << ""Run: >> "" << code << std::endl;; 327 fPyReturn = PyRun_String(code, start, fGlobalNS, fLocalNS);; 328 if (!fPyReturn) {; 329 Log() << kWARNING << ""Failed to run python code: "" << code << Endl;; 330 Log() << kWARNING << ""Python error message:"" << Endl;; 331 PyErr_Print();; 332 Log() << kFATAL << errorMessage << Endl;; 333 }; 334}; 335 ; 336///////////////////////////////////////////////////////////////////////////////; 337/// Execute Python code from string; 338///; 339/// \param[in] code Python code as string; 340/// \param[in] globalNS Global Namespace for Python Session; 341/// \param[in] localNS Local Namespace for Python Session; 342///; 343/// Overloaded static Helper function to run python code; 344/// from string and throw runtime error if the Python session; 345/// is unable to execute the code; 346 ; 347void PyMethodBase::PyRunString(TString code, PyObject *globalNS, PyObject *localNS){; 348 PyObject *fPyReturn = PyRun_String(code, Py_single_input, globalNS, localNS);; 349 if (!fPyReturn) {; 350 std::cout<<""\nPython error message:\n"";; 351 PyErr_Print();; 352 throw std::runtime_error(""\nFailed to run python code: ""+code);; 353 }; 354}; 355 ; 356///////////////////////////////////////////////////////////////////////////////; 357/// Returns `const char*` from Python string in PyObject; 358///; 359/// \param[in] string Python String object; 360/// \return String representation in `const char*`; 361 ; 362const char* PyMethodBase::PyStringAsString(PyObject* string){; 363 PyObject* encodedString = PyUnicode_AsUTF8String(string);; 364 const char* cstring = PyBytes_AsString(encodedString);; 365 return cstring;; 366}; 367 ; 368//////////////////////////////////////////////////////////////////////////////////; 369/// \brie",MatchSource.WIKI,doc/master/PyMethodBase_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/PyMethodBase_8cxx_source.html
https://root.cern/doc/master/PyMethodBase_8cxx_source.html:12248,Availability,error,error,12248,"rn = PyRun_String(code, start, fGlobalNS, fLocalNS);; 328 if (!fPyReturn) {; 329 Log() << kWARNING << ""Failed to run python code: "" << code << Endl;; 330 Log() << kWARNING << ""Python error message:"" << Endl;; 331 PyErr_Print();; 332 Log() << kFATAL << errorMessage << Endl;; 333 }; 334}; 335 ; 336///////////////////////////////////////////////////////////////////////////////; 337/// Execute Python code from string; 338///; 339/// \param[in] code Python code as string; 340/// \param[in] globalNS Global Namespace for Python Session; 341/// \param[in] localNS Local Namespace for Python Session; 342///; 343/// Overloaded static Helper function to run python code; 344/// from string and throw runtime error if the Python session; 345/// is unable to execute the code; 346 ; 347void PyMethodBase::PyRunString(TString code, PyObject *globalNS, PyObject *localNS){; 348 PyObject *fPyReturn = PyRun_String(code, Py_single_input, globalNS, localNS);; 349 if (!fPyReturn) {; 350 std::cout<<""\nPython error message:\n"";; 351 PyErr_Print();; 352 throw std::runtime_error(""\nFailed to run python code: ""+code);; 353 }; 354}; 355 ; 356///////////////////////////////////////////////////////////////////////////////; 357/// Returns `const char*` from Python string in PyObject; 358///; 359/// \param[in] string Python String object; 360/// \return String representation in `const char*`; 361 ; 362const char* PyMethodBase::PyStringAsString(PyObject* string){; 363 PyObject* encodedString = PyUnicode_AsUTF8String(string);; 364 const char* cstring = PyBytes_AsString(encodedString);; 365 return cstring;; 366}; 367 ; 368//////////////////////////////////////////////////////////////////////////////////; 369/// \brief Utility function which retrieves and returns the values of the Tuple; 370/// object as a vector of size_t; 371///; 372/// \param[in] tupleObject Python Tuple object; 373/// \return vector of tuple members; 374 ; 375std::vector<size_t> PyMethodBase::GetDataFromTuple(PyObject* tupleObject){; ",MatchSource.WIKI,doc/master/PyMethodBase_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/PyMethodBase_8cxx_source.html
https://root.cern/doc/master/PyMethodBase_8cxx_source.html:14507,Availability,error,error,14507,"yTuple_Size(tupleObject);++tupleIter){; 378 auto itemObj = PyTuple_GetItem(tupleObject,tupleIter);; 379 if (itemObj == Py_None); 380 tupleVec.push_back(0); // case shape is for example (None,2,3); 381 else; 382 tupleVec.push_back((size_t)PyLong_AsLong(itemObj));; 383 }; 384 return tupleVec;; 385}; 386 ; 387//////////////////////////////////////////////////////////////////////////////////; 388/// \brief Utility function which retrieves and returns the values of the List; 389/// object as a vector of size_t; 390///; 391/// \param[in] listObject Python List object; 392/// \return vector of list members; 393 ; 394std::vector<size_t> PyMethodBase::GetDataFromList(PyObject* listObject){; 395 std::vector<size_t>listVec;; 396 for(Py_ssize_t listIter=0; listIter<PyList_Size(listObject);++listIter){; 397 listVec.push_back((size_t)PyLong_AsLong(PyList_GetItem(listObject,listIter)));; 398 }; 399 return listVec;; 400}; 401 ; 402//////////////////////////////////////////////////////////////////////////////////; 403/// \brief Utility function which checks if a given key is present in a Python; 404/// dictionary object and returns the associated value or throws runtime; 405/// error.; 406///; 407/// \param[in] listObject Python Dict object; 408/// \return Associated value PyObject; 409PyObject *PyMethodBase::GetValueFromDict(PyObject *dict, const char *key); 410{; 411 return PyDict_GetItemWithError(dict, PyUnicode_FromString(key));; 412}; PyBytes_AsString#define PyBytes_AsStringDefinition CPyCppyy.h:64; DataSetInfo.h; DataSet.h; MsgLogger.h; PyMethodBase.h; PyObject_object PyObjectDefinition PyMethodBase.h:43; Py_single_input#define Py_single_inputDefinition PyMethodBase.h:44; Results.h; kFALSEconstexpr Bool_t kFALSEDefinition RtypesCore.h:94; kTRUEconstexpr Bool_t kTRUEDefinition RtypesCore.h:93; ClassImp#define ClassImp(name)Definition Rtypes.h:382; resultOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign",MatchSource.WIKI,doc/master/PyMethodBase_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/PyMethodBase_8cxx_source.html
https://root.cern/doc/master/PyMethodBase_8cxx_source.html:19081,Availability,error,errorMessage,19081,"ckleLoadsDefinition PyMethodBase.h:130; TMVA::PyMethodBase::~PyMethodBasevirtual ~PyMethodBase()Definition PyMethodBase.cxx:120; TMVA::PyMethodBase::fGlobalNSstatic PyObject * fGlobalNSDefinition PyMethodBase.h:133; TMVA::PyMethodBase::fModulePicklestatic PyObject * fModulePickleDefinition PyMethodBase.h:128; TMVA::PyMethodBase::fModuleBuiltinstatic PyObject * fModuleBuiltinDefinition PyMethodBase.h:123; TMVA::PyMethodBase::PyMethodBasePyMethodBase(const TString &jobName, Types::EMVA methodType, const TString &methodTitle, DataSetInfo &dsi, const TString &theOption="""")Definition PyMethodBase.cxx:84; TMVA::PyMethodBase::fEvalstatic PyObject * fEvalDefinition PyMethodBase.h:124; TMVA::PyMethodBase::GetValueFromDictstatic PyObject * GetValueFromDict(PyObject *dict, const char *key)Utility function which checks if a given key is present in a Python dictionary object and returns the...Definition PyMethodBase.cxx:409; TMVA::PyMethodBase::PyRunStringvoid PyRunString(TString code, TString errorMessage=""Failed to run python code"", int start=256)Execute Python code from string.Definition PyMethodBase.cxx:325; TMVA::PyMethodBase::fLocalNSPyObject * fLocalNSDefinition PyMethodBase.h:134; TMVA::Tools::LogMsgLogger & Log() constDefinition Tools.h:228; TMVA::Types::EMVAEMVADefinition Types.h:76; TStringBasic string class.Definition TString.h:139; TString::Dataconst char * Data() constDefinition TString.h:376; TString::ReplaceAllTString & ReplaceAll(const TString &s1, const TString &s2)Definition TString.h:704; TString::IsNullBool_t IsNull() constDefinition TString.h:414; TSystem::GetFromPipevirtual TString GetFromPipe(const char *command)Execute command and return output in TString.Definition TSystem.cxx:680; int; TMVAcreate variable transformationsDefinition GeneticMinimizer.h:22; TMVA::Python_ExecutableTString Python_Executable()Function to find current Python executable used by ROOT If ""Python3"" is installed,...Definition PyMethodBase.cxx:43; TMVA::gToolsTools & gTools(); TMVA::",MatchSource.WIKI,doc/master/PyMethodBase_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/PyMethodBase_8cxx_source.html
https://root.cern/doc/master/PyMethodBase_8cxx_source.html:420,Deployability,integrat,integrated,420,". ROOT: tmva/pymva/src/PyMethodBase.cxx Source File. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. PyMethodBase.cxx. Go to the documentation of this file. 1// @(#)root/tmva/pymva $Id$; 2// Authors: Omar Zapata, Lorenzo Moneta, Sergei Gleyzer 2015, Stefan Wunsch 2017; 3 ; 4/**********************************************************************************; 5 * Project: TMVA - a Root-integrated toolkit for multivariate data analysis *; 6 * Package: TMVA *; 7 * Class : PyMethodBase *; 8 * *; 9 * Description: *; 10 * Virtual base class for all MVA method based on python *; 11 * *; 12 **********************************************************************************/; 13 ; 14#include <Python.h> // Needs to be included first to avoid redefinition of _POSIX_C_SOURCE; 15#include <TMVA/PyMethodBase.h>; 16 ; 17#include ""TMVA/DataSet.h""; 18#include ""TMVA/DataSetInfo.h""; 19#include ""TMVA/MsgLogger.h""; 20#include ""TMVA/Results.h""; 21#include ""TMVA/Timer.h""; 22#include ""TMVA/Tools.h""; 23 ; 24#include ""TSystem.h""; 25 ; 26#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION; 27#include <numpy/arrayobject.h>; 28 ; 29using namespace TMVA;; 30 ; 31namespace TMVA {; 32namespace Internal {; 33class PyGILRAII {; 34 PyGILState_STATE m_GILState;; 35 ; 36public:; 37 PyGILRAII() : m_GILState(PyGILState_Ensure()) {}; 38 ~PyGILRAII() { PyGILState_Release(m_GILState); }; 39};; 40} // namespace Internal; 41 ; 42/// get current Python executable used by ROOT; 43TString Python_Executable() {; 44 TString python_version = gSystem->GetFromPipe(""root-config --python-version"");; 45 if (python_version.IsNull()) {; 46 TMVA::gTools().Log() << kFATAL << ""Can't find a valid Python version used to build ROOT"" << Endl;; 47 return nullptr;; 48 }; 49#ifdef _MSC_VER; 50 // on Windows there is a space before the version and the executable is python.exe; 51 // for both versions of Python; 52 python_version.ReplaceAll("" "", """");; 53 if (python_version[0] == '2' || python_version[0] == ",MatchSource.WIKI,doc/master/PyMethodBase_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/PyMethodBase_8cxx_source.html
https://root.cern/doc/master/PyMethodBase_8cxx_source.html:20005,Deployability,install,installed,20005,"MethodBase.h:133; TMVA::PyMethodBase::fModulePicklestatic PyObject * fModulePickleDefinition PyMethodBase.h:128; TMVA::PyMethodBase::fModuleBuiltinstatic PyObject * fModuleBuiltinDefinition PyMethodBase.h:123; TMVA::PyMethodBase::PyMethodBasePyMethodBase(const TString &jobName, Types::EMVA methodType, const TString &methodTitle, DataSetInfo &dsi, const TString &theOption="""")Definition PyMethodBase.cxx:84; TMVA::PyMethodBase::fEvalstatic PyObject * fEvalDefinition PyMethodBase.h:124; TMVA::PyMethodBase::GetValueFromDictstatic PyObject * GetValueFromDict(PyObject *dict, const char *key)Utility function which checks if a given key is present in a Python dictionary object and returns the...Definition PyMethodBase.cxx:409; TMVA::PyMethodBase::PyRunStringvoid PyRunString(TString code, TString errorMessage=""Failed to run python code"", int start=256)Execute Python code from string.Definition PyMethodBase.cxx:325; TMVA::PyMethodBase::fLocalNSPyObject * fLocalNSDefinition PyMethodBase.h:134; TMVA::Tools::LogMsgLogger & Log() constDefinition Tools.h:228; TMVA::Types::EMVAEMVADefinition Types.h:76; TStringBasic string class.Definition TString.h:139; TString::Dataconst char * Data() constDefinition TString.h:376; TString::ReplaceAllTString & ReplaceAll(const TString &s1, const TString &s2)Definition TString.h:704; TString::IsNullBool_t IsNull() constDefinition TString.h:414; TSystem::GetFromPipevirtual TString GetFromPipe(const char *command)Execute command and return output in TString.Definition TSystem.cxx:680; int; TMVAcreate variable transformationsDefinition GeneticMinimizer.h:22; TMVA::Python_ExecutableTString Python_Executable()Function to find current Python executable used by ROOT If ""Python3"" is installed,...Definition PyMethodBase.cxx:43; TMVA::gToolsTools & gTools(); TMVA::EndlMsgLogger & Endl(MsgLogger &ml)Definition MsgLogger.h:148. tmvapymvasrcPyMethodBase.cxx. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:40:56 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/PyMethodBase_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/PyMethodBase_8cxx_source.html
https://root.cern/doc/master/PyMethodBase_8cxx_source.html:420,Integrability,integrat,integrated,420,". ROOT: tmva/pymva/src/PyMethodBase.cxx Source File. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. PyMethodBase.cxx. Go to the documentation of this file. 1// @(#)root/tmva/pymva $Id$; 2// Authors: Omar Zapata, Lorenzo Moneta, Sergei Gleyzer 2015, Stefan Wunsch 2017; 3 ; 4/**********************************************************************************; 5 * Project: TMVA - a Root-integrated toolkit for multivariate data analysis *; 6 * Package: TMVA *; 7 * Class : PyMethodBase *; 8 * *; 9 * Description: *; 10 * Virtual base class for all MVA method based on python *; 11 * *; 12 **********************************************************************************/; 13 ; 14#include <Python.h> // Needs to be included first to avoid redefinition of _POSIX_C_SOURCE; 15#include <TMVA/PyMethodBase.h>; 16 ; 17#include ""TMVA/DataSet.h""; 18#include ""TMVA/DataSetInfo.h""; 19#include ""TMVA/MsgLogger.h""; 20#include ""TMVA/Results.h""; 21#include ""TMVA/Timer.h""; 22#include ""TMVA/Tools.h""; 23 ; 24#include ""TSystem.h""; 25 ; 26#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION; 27#include <numpy/arrayobject.h>; 28 ; 29using namespace TMVA;; 30 ; 31namespace TMVA {; 32namespace Internal {; 33class PyGILRAII {; 34 PyGILState_STATE m_GILState;; 35 ; 36public:; 37 PyGILRAII() : m_GILState(PyGILState_Ensure()) {}; 38 ~PyGILRAII() { PyGILState_Release(m_GILState); }; 39};; 40} // namespace Internal; 41 ; 42/// get current Python executable used by ROOT; 43TString Python_Executable() {; 44 TString python_version = gSystem->GetFromPipe(""root-config --python-version"");; 45 if (python_version.IsNull()) {; 46 TMVA::gTools().Log() << kFATAL << ""Can't find a valid Python version used to build ROOT"" << Endl;; 47 return nullptr;; 48 }; 49#ifdef _MSC_VER; 50 // on Windows there is a space before the version and the executable is python.exe; 51 // for both versions of Python; 52 python_version.ReplaceAll("" "", """");; 53 if (python_version[0] == '2' || python_version[0] == ",MatchSource.WIKI,doc/master/PyMethodBase_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/PyMethodBase_8cxx_source.html
https://root.cern/doc/master/PyMethodBase_8cxx_source.html:10775,Integrability,message,message,10775,,MatchSource.WIKI,doc/master/PyMethodBase_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/PyMethodBase_8cxx_source.html
https://root.cern/doc/master/PyMethodBase_8cxx_source.html:11440,Integrability,message,message,11440,"; 305 ; 306 Py_DECREF(file_arg);; 307 Py_DECREF(file);; 308 Py_DECREF(model_arg);; 309 ; 310 return 0;; 311}; 312 ; 313///////////////////////////////////////////////////////////////////////////////; 314/// Execute Python code from string; 315///; 316/// \param[in] code Python code as string; 317/// \param[in] errorMessage Error message which shall be shown if the execution fails; 318/// \param[in] start Start symbol; 319///; 320/// Helper function to run python code from string in local namespace with; 321/// error handling; 322/// `start` defines the start symbol defined in PyRun_String (Py_eval_input,; 323/// Py_single_input, Py_file_input); 324 ; 325void PyMethodBase::PyRunString(TString code, TString errorMessage, int start) {; 326 //std::cout << ""Run: >> "" << code << std::endl;; 327 fPyReturn = PyRun_String(code, start, fGlobalNS, fLocalNS);; 328 if (!fPyReturn) {; 329 Log() << kWARNING << ""Failed to run python code: "" << code << Endl;; 330 Log() << kWARNING << ""Python error message:"" << Endl;; 331 PyErr_Print();; 332 Log() << kFATAL << errorMessage << Endl;; 333 }; 334}; 335 ; 336///////////////////////////////////////////////////////////////////////////////; 337/// Execute Python code from string; 338///; 339/// \param[in] code Python code as string; 340/// \param[in] globalNS Global Namespace for Python Session; 341/// \param[in] localNS Local Namespace for Python Session; 342///; 343/// Overloaded static Helper function to run python code; 344/// from string and throw runtime error if the Python session; 345/// is unable to execute the code; 346 ; 347void PyMethodBase::PyRunString(TString code, PyObject *globalNS, PyObject *localNS){; 348 PyObject *fPyReturn = PyRun_String(code, Py_single_input, globalNS, localNS);; 349 if (!fPyReturn) {; 350 std::cout<<""\nPython error message:\n"";; 351 PyErr_Print();; 352 throw std::runtime_error(""\nFailed to run python code: ""+code);; 353 }; 354}; 355 ; 356/////////////////////////////////////////////////////////////////",MatchSource.WIKI,doc/master/PyMethodBase_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/PyMethodBase_8cxx_source.html
https://root.cern/doc/master/PyMethodBase_8cxx_source.html:12254,Integrability,message,message,12254,"Run_String(code, start, fGlobalNS, fLocalNS);; 328 if (!fPyReturn) {; 329 Log() << kWARNING << ""Failed to run python code: "" << code << Endl;; 330 Log() << kWARNING << ""Python error message:"" << Endl;; 331 PyErr_Print();; 332 Log() << kFATAL << errorMessage << Endl;; 333 }; 334}; 335 ; 336///////////////////////////////////////////////////////////////////////////////; 337/// Execute Python code from string; 338///; 339/// \param[in] code Python code as string; 340/// \param[in] globalNS Global Namespace for Python Session; 341/// \param[in] localNS Local Namespace for Python Session; 342///; 343/// Overloaded static Helper function to run python code; 344/// from string and throw runtime error if the Python session; 345/// is unable to execute the code; 346 ; 347void PyMethodBase::PyRunString(TString code, PyObject *globalNS, PyObject *localNS){; 348 PyObject *fPyReturn = PyRun_String(code, Py_single_input, globalNS, localNS);; 349 if (!fPyReturn) {; 350 std::cout<<""\nPython error message:\n"";; 351 PyErr_Print();; 352 throw std::runtime_error(""\nFailed to run python code: ""+code);; 353 }; 354}; 355 ; 356///////////////////////////////////////////////////////////////////////////////; 357/// Returns `const char*` from Python string in PyObject; 358///; 359/// \param[in] string Python String object; 360/// \return String representation in `const char*`; 361 ; 362const char* PyMethodBase::PyStringAsString(PyObject* string){; 363 PyObject* encodedString = PyUnicode_AsUTF8String(string);; 364 const char* cstring = PyBytes_AsString(encodedString);; 365 return cstring;; 366}; 367 ; 368//////////////////////////////////////////////////////////////////////////////////; 369/// \brief Utility function which retrieves and returns the values of the Tuple; 370/// object as a vector of size_t; 371///; 372/// \param[in] tupleObject Python Tuple object; 373/// \return vector of tuple members; 374 ; 375std::vector<size_t> PyMethodBase::GetDataFromTuple(PyObject* tupleObject){; 376 std",MatchSource.WIKI,doc/master/PyMethodBase_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/PyMethodBase_8cxx_source.html
https://root.cern/doc/master/PyMethodBase_8cxx_source.html:1573,Modifiability,config,config,1573,"***********; 5 * Project: TMVA - a Root-integrated toolkit for multivariate data analysis *; 6 * Package: TMVA *; 7 * Class : PyMethodBase *; 8 * *; 9 * Description: *; 10 * Virtual base class for all MVA method based on python *; 11 * *; 12 **********************************************************************************/; 13 ; 14#include <Python.h> // Needs to be included first to avoid redefinition of _POSIX_C_SOURCE; 15#include <TMVA/PyMethodBase.h>; 16 ; 17#include ""TMVA/DataSet.h""; 18#include ""TMVA/DataSetInfo.h""; 19#include ""TMVA/MsgLogger.h""; 20#include ""TMVA/Results.h""; 21#include ""TMVA/Timer.h""; 22#include ""TMVA/Tools.h""; 23 ; 24#include ""TSystem.h""; 25 ; 26#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION; 27#include <numpy/arrayobject.h>; 28 ; 29using namespace TMVA;; 30 ; 31namespace TMVA {; 32namespace Internal {; 33class PyGILRAII {; 34 PyGILState_STATE m_GILState;; 35 ; 36public:; 37 PyGILRAII() : m_GILState(PyGILState_Ensure()) {}; 38 ~PyGILRAII() { PyGILState_Release(m_GILState); }; 39};; 40} // namespace Internal; 41 ; 42/// get current Python executable used by ROOT; 43TString Python_Executable() {; 44 TString python_version = gSystem->GetFromPipe(""root-config --python-version"");; 45 if (python_version.IsNull()) {; 46 TMVA::gTools().Log() << kFATAL << ""Can't find a valid Python version used to build ROOT"" << Endl;; 47 return nullptr;; 48 }; 49#ifdef _MSC_VER; 50 // on Windows there is a space before the version and the executable is python.exe; 51 // for both versions of Python; 52 python_version.ReplaceAll("" "", """");; 53 if (python_version[0] == '2' || python_version[0] == '3'); 54 return ""python"";; 55#endif; 56 if (python_version[0] == '2'); 57 return ""python"";; 58 else if (python_version[0] == '3'); 59 return ""python3"";; 60 ; 61 TMVA::gTools().Log() << kFATAL << ""Invalid Python version used to build ROOT : "" << python_version << Endl;; 62 return nullptr;; 63}; 64 ; 65} // namespace TMVA; 66 ; 67ClassImp(PyMethodBase);; 68 ; 69// NOTE: Introduce",MatchSource.WIKI,doc/master/PyMethodBase_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/PyMethodBase_8cxx_source.html
https://root.cern/doc/master/PyMethodBase_8cxx_source.html:5281,Modifiability,variab,variables,5281,"////////////////////////////////////////; 128/// Evaluate Python code; 129///; 130/// \param[in] code Python code as string; 131/// \return Python object from evaluation of code line; 132///; 133/// Take a Python code as input and evaluate it in the local namespace. Then,; 134/// return the result as Python object.; 135 ; 136PyObject *PyMethodBase::Eval(TString code); 137{; 138 if(!PyIsInitialized()) PyInitialize();; 139 PyObject *pycode = Py_BuildValue(""(sOO)"", code.Data(), fGlobalNS, fLocalNS);; 140 PyObject *result = PyObject_CallObject(fEval, pycode);; 141 Py_DECREF(pycode);; 142 return result;; 143}; 144 ; 145///////////////////////////////////////////////////////////////////////////////; 146/// Initialize Python interpreter; 147///; 148/// NOTE: We introduce a shared global namespace `fGlobalNS`, but using; 149/// a private local namespace `fLocalNS`. This prohibits the interference; 150/// of instances of the same method with the same factory, e.g., by overriding; 151/// variables in the same local namespace.; 152 ; 153void PyMethodBase::PyInitialize(); 154{; 155 TMVA::MsgLogger Log;; 156 ; 157 bool pyIsInitialized = PyIsInitialized();; 158 if (!pyIsInitialized) {; 159 Py_Initialize();; 160 }; 161 ; 162 TMVA::Internal::PyGILRAII raii;; 163 if (!pyIsInitialized) {; 164 _import_array();; 165 }; 166 ; 167 // note fMain is a borrowed reference; 168 fMain = PyImport_AddModule(""__main__"");; 169 if (!fMain) {; 170 Log << kFATAL << ""Can't import __main__"" << Endl;; 171 Log << Endl;; 172 }; 173 Py_INCREF(fMain);; 174 ; 175 fGlobalNS = PyModule_GetDict(fMain);; 176 if (!fGlobalNS) {; 177 Log << kFATAL << ""Can't init global namespace"" << Endl;; 178 Log << Endl;; 179 }; 180 Py_INCREF(fGlobalNS);; 181 ; 182 #if PY_MAJOR_VERSION < 3; 183 //preparing objects for eval; 184 PyObject *bName = PyUnicode_FromString(""__builtin__"");; 185 // Import the file as a Python module.; 186 // returns a new reference; 187 fModuleBuiltin = PyImport_Import(bName);; 188 if (!fModuleBuiltin) {;",MatchSource.WIKI,doc/master/PyMethodBase_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/PyMethodBase_8cxx_source.html
https://root.cern/doc/master/PyMethodBase_8cxx_source.html:19825,Modifiability,variab,variable,19825,"MethodBase.h:133; TMVA::PyMethodBase::fModulePicklestatic PyObject * fModulePickleDefinition PyMethodBase.h:128; TMVA::PyMethodBase::fModuleBuiltinstatic PyObject * fModuleBuiltinDefinition PyMethodBase.h:123; TMVA::PyMethodBase::PyMethodBasePyMethodBase(const TString &jobName, Types::EMVA methodType, const TString &methodTitle, DataSetInfo &dsi, const TString &theOption="""")Definition PyMethodBase.cxx:84; TMVA::PyMethodBase::fEvalstatic PyObject * fEvalDefinition PyMethodBase.h:124; TMVA::PyMethodBase::GetValueFromDictstatic PyObject * GetValueFromDict(PyObject *dict, const char *key)Utility function which checks if a given key is present in a Python dictionary object and returns the...Definition PyMethodBase.cxx:409; TMVA::PyMethodBase::PyRunStringvoid PyRunString(TString code, TString errorMessage=""Failed to run python code"", int start=256)Execute Python code from string.Definition PyMethodBase.cxx:325; TMVA::PyMethodBase::fLocalNSPyObject * fLocalNSDefinition PyMethodBase.h:134; TMVA::Tools::LogMsgLogger & Log() constDefinition Tools.h:228; TMVA::Types::EMVAEMVADefinition Types.h:76; TStringBasic string class.Definition TString.h:139; TString::Dataconst char * Data() constDefinition TString.h:376; TString::ReplaceAllTString & ReplaceAll(const TString &s1, const TString &s2)Definition TString.h:704; TString::IsNullBool_t IsNull() constDefinition TString.h:414; TSystem::GetFromPipevirtual TString GetFromPipe(const char *command)Execute command and return output in TString.Definition TSystem.cxx:680; int; TMVAcreate variable transformationsDefinition GeneticMinimizer.h:22; TMVA::Python_ExecutableTString Python_Executable()Function to find current Python executable used by ROOT If ""Python3"" is installed,...Definition PyMethodBase.cxx:43; TMVA::gToolsTools & gTools(); TMVA::EndlMsgLogger & Endl(MsgLogger &ml)Definition MsgLogger.h:148. tmvapymvasrcPyMethodBase.cxx. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:40:56 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/PyMethodBase_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/PyMethodBase_8cxx_source.html
https://root.cern/doc/master/PyMethodBase_8cxx_source.html:7689,Performance,load,load,7689,"(""pickle"");; 216 // Import the file as a Python module.; 217 // return object is a new reference !; 218 fModulePickle = PyImport_Import(pName);; 219 if (!fModulePickle) {; 220 Log << kFATAL << ""Can't import pickle"" << Endl;; 221 Log << Endl;; 222 }; 223 PyObject *pDict = PyModule_GetDict(fModulePickle);; 224 // note the following return objects are borrowed references; 225 fPickleDumps = PyDict_GetItemString(pDict, ""dump"");; 226 fPickleLoads = PyDict_GetItemString(pDict, ""load"");; 227 if (fPickleDumps) Py_INCREF(fPickleDumps);; 228 if (fPickleLoads) Py_INCREF(fPickleLoads);; 229 ; 230 Py_DECREF(pName);; 231}; 232 ; 233///////////////////////////////////////////////////////////////////////////////; 234// Finalize Python interpreter; 235 ; 236void PyMethodBase::PyFinalize(); 237{; 238 if (fEval) Py_DECREF(fEval);; 239 if (fOpen) Py_DECREF(fOpen);; 240 if (fModuleBuiltin) Py_DECREF(fModuleBuiltin);; 241 if (fPickleDumps) Py_DECREF(fPickleDumps);; 242 if (fPickleLoads) Py_DECREF(fPickleLoads);; 243 if(fMain) Py_DECREF(fMain);//objects fGlobalNS and fLocalNS will be free here; 244 if (fGlobalNS) Py_DECREF(fGlobalNS);; 245 Py_Finalize();; 246}; 247 ; 248///////////////////////////////////////////////////////////////////////////////; 249/// Check Python interpreter initialization status; 250///; 251/// \return Boolean whether interpreter is initialized; 252 ; 253int PyMethodBase::PyIsInitialized(); 254{; 255 if (!Py_IsInitialized()) return kFALSE;; 256 if (!fEval) return kFALSE;; 257 if (!fModuleBuiltin) return kFALSE;; 258 if (!fPickleDumps) return kFALSE;; 259 if (!fPickleLoads) return kFALSE;; 260 return kTRUE;; 261}; 262 ; 263///////////////////////////////////////////////////////////////////////////////; 264/// Serialize Python object; 265///; 266/// \param[in] path Path where object is written to file; 267/// \param[in] obj Python object; 268///; 269/// The input Python object is serialized and written to a file. The Python; 270/// module `pickle` is used to do so.; ",MatchSource.WIKI,doc/master/PyMethodBase_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/PyMethodBase_8cxx_source.html
https://root.cern/doc/master/PyMethodBase_8cxx_source.html:9977,Performance,load,loaded,9977,"return kFALSE;; 259 if (!fPickleLoads) return kFALSE;; 260 return kTRUE;; 261}; 262 ; 263///////////////////////////////////////////////////////////////////////////////; 264/// Serialize Python object; 265///; 266/// \param[in] path Path where object is written to file; 267/// \param[in] obj Python object; 268///; 269/// The input Python object is serialized and written to a file. The Python; 270/// module `pickle` is used to do so.; 271 ; 272void PyMethodBase::Serialize(TString path, PyObject *obj); 273{; 274 if(!PyIsInitialized()) PyInitialize();; 275 ; 276 PyObject *file_arg = Py_BuildValue(""(ss)"", path.Data(),""wb"");; 277 PyObject *file = PyObject_CallObject(fOpen,file_arg);; 278 PyObject *model_arg = Py_BuildValue(""(OO)"", obj,file);; 279 PyObject *model_data = PyObject_CallObject(fPickleDumps , model_arg);; 280 ; 281 Py_DECREF(file_arg);; 282 Py_DECREF(file);; 283 Py_DECREF(model_arg);; 284 Py_DECREF(model_data);; 285}; 286 ; 287///////////////////////////////////////////////////////////////////////////////; 288/// Unserialize Python object; 289///; 290/// \param[in] path Path to serialized Python object; 291/// \param[in] obj Python object where the unserialized Python object is loaded; 292/// \return Error code; 293 ; 294Int_t PyMethodBase::UnSerialize(TString path, PyObject **obj); 295{; 296 // Load file; 297 PyObject *file_arg = Py_BuildValue(""(ss)"", path.Data(),""rb"");; 298 PyObject *file = PyObject_CallObject(fOpen,file_arg);; 299 if(!file) return 1;; 300 ; 301 // Load object from file using pickle; 302 PyObject *model_arg = Py_BuildValue(""(O)"", file);; 303 *obj = PyObject_CallObject(fPickleLoads , model_arg);; 304 if(!obj) return 2;; 305 ; 306 Py_DECREF(file_arg);; 307 Py_DECREF(file);; 308 Py_DECREF(model_arg);; 309 ; 310 return 0;; 311}; 312 ; 313///////////////////////////////////////////////////////////////////////////////; 314/// Execute Python code from string; 315///; 316/// \param[in] code Python code as string; 317/// \param[in] errorMessage Error",MatchSource.WIKI,doc/master/PyMethodBase_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/PyMethodBase_8cxx_source.html
https://root.cern/doc/master/PyMethodBase_8cxx_source.html:767,Safety,avoid,avoid,767,". ROOT: tmva/pymva/src/PyMethodBase.cxx Source File. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. PyMethodBase.cxx. Go to the documentation of this file. 1// @(#)root/tmva/pymva $Id$; 2// Authors: Omar Zapata, Lorenzo Moneta, Sergei Gleyzer 2015, Stefan Wunsch 2017; 3 ; 4/**********************************************************************************; 5 * Project: TMVA - a Root-integrated toolkit for multivariate data analysis *; 6 * Package: TMVA *; 7 * Class : PyMethodBase *; 8 * *; 9 * Description: *; 10 * Virtual base class for all MVA method based on python *; 11 * *; 12 **********************************************************************************/; 13 ; 14#include <Python.h> // Needs to be included first to avoid redefinition of _POSIX_C_SOURCE; 15#include <TMVA/PyMethodBase.h>; 16 ; 17#include ""TMVA/DataSet.h""; 18#include ""TMVA/DataSetInfo.h""; 19#include ""TMVA/MsgLogger.h""; 20#include ""TMVA/Results.h""; 21#include ""TMVA/Timer.h""; 22#include ""TMVA/Tools.h""; 23 ; 24#include ""TSystem.h""; 25 ; 26#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION; 27#include <numpy/arrayobject.h>; 28 ; 29using namespace TMVA;; 30 ; 31namespace TMVA {; 32namespace Internal {; 33class PyGILRAII {; 34 PyGILState_STATE m_GILState;; 35 ; 36public:; 37 PyGILRAII() : m_GILState(PyGILState_Ensure()) {}; 38 ~PyGILRAII() { PyGILState_Release(m_GILState); }; 39};; 40} // namespace Internal; 41 ; 42/// get current Python executable used by ROOT; 43TString Python_Executable() {; 44 TString python_version = gSystem->GetFromPipe(""root-config --python-version"");; 45 if (python_version.IsNull()) {; 46 TMVA::gTools().Log() << kFATAL << ""Can't find a valid Python version used to build ROOT"" << Endl;; 47 return nullptr;; 48 }; 49#ifdef _MSC_VER; 50 // on Windows there is a space before the version and the executable is python.exe; 51 // for both versions of Python; 52 python_version.ReplaceAll("" "", """");; 53 if (python_version[0] == '2' || python_version[0] == ",MatchSource.WIKI,doc/master/PyMethodBase_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/PyMethodBase_8cxx_source.html
https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py.html:1184,Integrability,inject,injecting,1184,"No Matches. Namespaces ; pyroot002_pythonizationDecorator.py File ReferenceTutorials  PyRoot tutorials. Detailed Description; This tutorial shows how to use the @pythonization decorator to add extra behaviour to C++ user classes that are used from Python via PyROOT. ; ; import ROOT; from ROOT import pythonization; ; # Let's first define a new C++ class. In this tutorial, we will see how we can; # ""pythonize"" this class, i.e. how we can add some extra behaviour to it to; # make it more pythonic or easier to use from Python.; #; # Note: In this example, the class is defined dynamically for demonstration; # purposes, but it could also be a C++ class defined in some library or header.; # For more information about loading C++ user code to be used from Python with; # PyROOT, please see:; # https://root.cern.ch/manual/python/#loading-user-libraries-and-just-in-time-compilation-jitting; ROOT.gInterpreter.Declare('''; class MyClass {};; '''); ; # Next, we define a pythonizor function: the function that will be responsible; # for injecting new behaviour in our C++ class `MyClass`.; #; # To convert a given Python function into a pythonizor, we need to decorate it; # with the @pythonization decorator. Such decorator allows us to define which; # which class we want to pythonize by providing its class name and its; # namespace (if the latter is not specified, it defaults to the global; # namespace, i.e. '::').; #; # The decorated function - the pythonizor - must accept either one or two; # parameters:; # 1. The class to be pythonized (proxy object where new behaviour can be; # injected); # 2. The fully-qualified name of that class (optional).; #; # Let's see all this with a simple example. Suppose I would like to define how; # `MyClass` objects are represented as a string in Python (i.e. what would be; # shown when I print that object). For that purpose, I can define the following; # pythonizor function. There are two important things to be noted here:; # - The @pythonization de",MatchSource.WIKI,doc/master/pyroot002__pythonizationDecorator_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py.html
https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py.html:1738,Integrability,inject,injected,1738,"class is defined dynamically for demonstration; # purposes, but it could also be a C++ class defined in some library or header.; # For more information about loading C++ user code to be used from Python with; # PyROOT, please see:; # https://root.cern.ch/manual/python/#loading-user-libraries-and-just-in-time-compilation-jitting; ROOT.gInterpreter.Declare('''; class MyClass {};; '''); ; # Next, we define a pythonizor function: the function that will be responsible; # for injecting new behaviour in our C++ class `MyClass`.; #; # To convert a given Python function into a pythonizor, we need to decorate it; # with the @pythonization decorator. Such decorator allows us to define which; # which class we want to pythonize by providing its class name and its; # namespace (if the latter is not specified, it defaults to the global; # namespace, i.e. '::').; #; # The decorated function - the pythonizor - must accept either one or two; # parameters:; # 1. The class to be pythonized (proxy object where new behaviour can be; # injected); # 2. The fully-qualified name of that class (optional).; #; # Let's see all this with a simple example. Suppose I would like to define how; # `MyClass` objects are represented as a string in Python (i.e. what would be; # shown when I print that object). For that purpose, I can define the following; # pythonizor function. There are two important things to be noted here:; # - The @pythonization decorator has one argument that specifies our target; # class is `MyClass`.; # - The pythonizor function `pythonizor_of_myclass` provides and injects a new; # implementation for `__str__`, the mechanism that Python provides to define; # how to represent objects as strings. This new implementation; # always returns the string ""This is a MyClass object"".; @pythonization('MyClass'); def pythonizor_of_myclass(klass):; klass.__str__ = lambda o : 'This is a MyClass object'; ; # Once we have defined our pythonizor function, let's see it in action.; # We will now use",MatchSource.WIKI,doc/master/pyroot002__pythonizationDecorator_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py.html
https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py.html:2287,Integrability,inject,injects,2287," # with the @pythonization decorator. Such decorator allows us to define which; # which class we want to pythonize by providing its class name and its; # namespace (if the latter is not specified, it defaults to the global; # namespace, i.e. '::').; #; # The decorated function - the pythonizor - must accept either one or two; # parameters:; # 1. The class to be pythonized (proxy object where new behaviour can be; # injected); # 2. The fully-qualified name of that class (optional).; #; # Let's see all this with a simple example. Suppose I would like to define how; # `MyClass` objects are represented as a string in Python (i.e. what would be; # shown when I print that object). For that purpose, I can define the following; # pythonizor function. There are two important things to be noted here:; # - The @pythonization decorator has one argument that specifies our target; # class is `MyClass`.; # - The pythonizor function `pythonizor_of_myclass` provides and injects a new; # implementation for `__str__`, the mechanism that Python provides to define; # how to represent objects as strings. This new implementation; # always returns the string ""This is a MyClass object"".; @pythonization('MyClass'); def pythonizor_of_myclass(klass):; klass.__str__ = lambda o : 'This is a MyClass object'; ; # Once we have defined our pythonizor function, let's see it in action.; # We will now use the `MyClass` class for the first time from Python: we will; # create a new instance of that class. At this moment, the pythonizor will; # execute and modify the class - pythonizors are always lazily run when a given; # class is used for the first time from a Python script.; my_object = ROOT.MyClass(); ; # Since the pythonizor already executed, we should now see the new behaviour.; # For that purpose, let's print `my_object` (should show ""This is a MyClass; # object"").; print(my_object); ; # The previous example is just a simple one, but there are many ways in which a; # class can be pythonized. Typic",MatchSource.WIKI,doc/master/pyroot002__pythonizationDecorator_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py.html
https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py.html:8615,Integrability,inject,inject,8615,"ike so:; @pythonization('FirstClass'); @pythonization('SecondClass', ns='NS'); def pythonizor_for_first_and_second(klass, name):; print('Executed for class ' + name); ; # If we now access both classes, we should see that the pythonizor runs twice.; f = ROOT.FirstClass(); s = ROOT.NS.SecondClass(); ; # So far we have seen how pythonizations can be registered for classes that; # have not been used yet. We have discussed how, in that case, the pythonizor; # functions are executed lazily when their target class/es are used for the; # first time in the application.; # However, it can also happen that our target class/es have already been; # accessed by the time we register a pythonization. In such a scenario, the; # pythonizor is applied immediately (at registration time) to the target; # class/es.; ; # Let's see an example of what was just explained. We will define a new class; # and immediately create an object of that class. We can check how the object; # still does not have a new attribute `pythonized` that we are going to inject; # in the next step.; ROOT.gInterpreter.Declare('''; class MyClass2 {};; '''); o = ROOT.MyClass2(); try:; print(o.pythonized); except AttributeError:; print(""Object has not been pythonized yet!""); ; # After that, we will register a pythonization for `MyClass2`. Since the class; # has already been used, the pythonization will happen right away.; @pythonization('MyClass2'); def pythonizor_for_myclass2(klass):; klass.pythonized = True; ; # Now our object does have the `pythonized` attribute:; print(o.pythonized) # prints True; formatOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t Float_t Float_t Int_t Int_t UInt_t UInt_t Rectangle_t Int_t Int_t Window_t TString Int_t GCValues_t GetPrimarySelectionOwner GetDisplay GetScreen GetColormap GetNativeEvent const char const char dpyName wid wind",MatchSource.WIKI,doc/master/pyroot002__pythonizationDecorator_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py.html
https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py.html:867,Performance,load,loading,867,". ROOT: tutorials/pyroot/pyroot002_pythonizationDecorator.py File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. Namespaces ; pyroot002_pythonizationDecorator.py File ReferenceTutorials  PyRoot tutorials. Detailed Description; This tutorial shows how to use the @pythonization decorator to add extra behaviour to C++ user classes that are used from Python via PyROOT. ; ; import ROOT; from ROOT import pythonization; ; # Let's first define a new C++ class. In this tutorial, we will see how we can; # ""pythonize"" this class, i.e. how we can add some extra behaviour to it to; # make it more pythonic or easier to use from Python.; #; # Note: In this example, the class is defined dynamically for demonstration; # purposes, but it could also be a C++ class defined in some library or header.; # For more information about loading C++ user code to be used from Python with; # PyROOT, please see:; # https://root.cern.ch/manual/python/#loading-user-libraries-and-just-in-time-compilation-jitting; ROOT.gInterpreter.Declare('''; class MyClass {};; '''); ; # Next, we define a pythonizor function: the function that will be responsible; # for injecting new behaviour in our C++ class `MyClass`.; #; # To convert a given Python function into a pythonizor, we need to decorate it; # with the @pythonization decorator. Such decorator allows us to define which; # which class we want to pythonize by providing its class name and its; # namespace (if the latter is not specified, it defaults to the global; # namespace, i.e. '::').; #; # The decorated function - the pythonizor - must accept either one or two; # parameters:; # 1. The class to be pythonized (proxy object where new behaviour can be; # injected); # 2. The fully-qualified name of that class (optional).; #; # Let's see all this with a simple example. Suppose I would like to define how; # `MyClass` objects are represented as a string in Python (i.e. what would be; # shown when I print that object)",MatchSource.WIKI,doc/master/pyroot002__pythonizationDecorator_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py.html
https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py.html:979,Performance,load,loading-user-libraries-and-just-in-time-compilation-jitting,979,"OOT: tutorials/pyroot/pyroot002_pythonizationDecorator.py File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. Namespaces ; pyroot002_pythonizationDecorator.py File ReferenceTutorials  PyRoot tutorials. Detailed Description; This tutorial shows how to use the @pythonization decorator to add extra behaviour to C++ user classes that are used from Python via PyROOT. ; ; import ROOT; from ROOT import pythonization; ; # Let's first define a new C++ class. In this tutorial, we will see how we can; # ""pythonize"" this class, i.e. how we can add some extra behaviour to it to; # make it more pythonic or easier to use from Python.; #; # Note: In this example, the class is defined dynamically for demonstration; # purposes, but it could also be a C++ class defined in some library or header.; # For more information about loading C++ user code to be used from Python with; # PyROOT, please see:; # https://root.cern.ch/manual/python/#loading-user-libraries-and-just-in-time-compilation-jitting; ROOT.gInterpreter.Declare('''; class MyClass {};; '''); ; # Next, we define a pythonizor function: the function that will be responsible; # for injecting new behaviour in our C++ class `MyClass`.; #; # To convert a given Python function into a pythonizor, we need to decorate it; # with the @pythonization decorator. Such decorator allows us to define which; # which class we want to pythonize by providing its class name and its; # namespace (if the latter is not specified, it defaults to the global; # namespace, i.e. '::').; #; # The decorated function - the pythonizor - must accept either one or two; # parameters:; # 1. The class to be pythonized (proxy object where new behaviour can be; # injected); # 2. The fully-qualified name of that class (optional).; #; # Let's see all this with a simple example. Suppose I would like to define how; # `MyClass` objects are represented as a string in Python (i.e. what would be; # shown when I print that object). ",MatchSource.WIKI,doc/master/pyroot002__pythonizationDecorator_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py.html
https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py.html:1184,Security,inject,injecting,1184,"No Matches. Namespaces ; pyroot002_pythonizationDecorator.py File ReferenceTutorials  PyRoot tutorials. Detailed Description; This tutorial shows how to use the @pythonization decorator to add extra behaviour to C++ user classes that are used from Python via PyROOT. ; ; import ROOT; from ROOT import pythonization; ; # Let's first define a new C++ class. In this tutorial, we will see how we can; # ""pythonize"" this class, i.e. how we can add some extra behaviour to it to; # make it more pythonic or easier to use from Python.; #; # Note: In this example, the class is defined dynamically for demonstration; # purposes, but it could also be a C++ class defined in some library or header.; # For more information about loading C++ user code to be used from Python with; # PyROOT, please see:; # https://root.cern.ch/manual/python/#loading-user-libraries-and-just-in-time-compilation-jitting; ROOT.gInterpreter.Declare('''; class MyClass {};; '''); ; # Next, we define a pythonizor function: the function that will be responsible; # for injecting new behaviour in our C++ class `MyClass`.; #; # To convert a given Python function into a pythonizor, we need to decorate it; # with the @pythonization decorator. Such decorator allows us to define which; # which class we want to pythonize by providing its class name and its; # namespace (if the latter is not specified, it defaults to the global; # namespace, i.e. '::').; #; # The decorated function - the pythonizor - must accept either one or two; # parameters:; # 1. The class to be pythonized (proxy object where new behaviour can be; # injected); # 2. The fully-qualified name of that class (optional).; #; # Let's see all this with a simple example. Suppose I would like to define how; # `MyClass` objects are represented as a string in Python (i.e. what would be; # shown when I print that object). For that purpose, I can define the following; # pythonizor function. There are two important things to be noted here:; # - The @pythonization de",MatchSource.WIKI,doc/master/pyroot002__pythonizationDecorator_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py.html
https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py.html:1738,Security,inject,injected,1738,"class is defined dynamically for demonstration; # purposes, but it could also be a C++ class defined in some library or header.; # For more information about loading C++ user code to be used from Python with; # PyROOT, please see:; # https://root.cern.ch/manual/python/#loading-user-libraries-and-just-in-time-compilation-jitting; ROOT.gInterpreter.Declare('''; class MyClass {};; '''); ; # Next, we define a pythonizor function: the function that will be responsible; # for injecting new behaviour in our C++ class `MyClass`.; #; # To convert a given Python function into a pythonizor, we need to decorate it; # with the @pythonization decorator. Such decorator allows us to define which; # which class we want to pythonize by providing its class name and its; # namespace (if the latter is not specified, it defaults to the global; # namespace, i.e. '::').; #; # The decorated function - the pythonizor - must accept either one or two; # parameters:; # 1. The class to be pythonized (proxy object where new behaviour can be; # injected); # 2. The fully-qualified name of that class (optional).; #; # Let's see all this with a simple example. Suppose I would like to define how; # `MyClass` objects are represented as a string in Python (i.e. what would be; # shown when I print that object). For that purpose, I can define the following; # pythonizor function. There are two important things to be noted here:; # - The @pythonization decorator has one argument that specifies our target; # class is `MyClass`.; # - The pythonizor function `pythonizor_of_myclass` provides and injects a new; # implementation for `__str__`, the mechanism that Python provides to define; # how to represent objects as strings. This new implementation; # always returns the string ""This is a MyClass object"".; @pythonization('MyClass'); def pythonizor_of_myclass(klass):; klass.__str__ = lambda o : 'This is a MyClass object'; ; # Once we have defined our pythonizor function, let's see it in action.; # We will now use",MatchSource.WIKI,doc/master/pyroot002__pythonizationDecorator_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py.html
https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py.html:2287,Security,inject,injects,2287," # with the @pythonization decorator. Such decorator allows us to define which; # which class we want to pythonize by providing its class name and its; # namespace (if the latter is not specified, it defaults to the global; # namespace, i.e. '::').; #; # The decorated function - the pythonizor - must accept either one or two; # parameters:; # 1. The class to be pythonized (proxy object where new behaviour can be; # injected); # 2. The fully-qualified name of that class (optional).; #; # Let's see all this with a simple example. Suppose I would like to define how; # `MyClass` objects are represented as a string in Python (i.e. what would be; # shown when I print that object). For that purpose, I can define the following; # pythonizor function. There are two important things to be noted here:; # - The @pythonization decorator has one argument that specifies our target; # class is `MyClass`.; # - The pythonizor function `pythonizor_of_myclass` provides and injects a new; # implementation for `__str__`, the mechanism that Python provides to define; # how to represent objects as strings. This new implementation; # always returns the string ""This is a MyClass object"".; @pythonization('MyClass'); def pythonizor_of_myclass(klass):; klass.__str__ = lambda o : 'This is a MyClass object'; ; # Once we have defined our pythonizor function, let's see it in action.; # We will now use the `MyClass` class for the first time from Python: we will; # create a new instance of that class. At this moment, the pythonizor will; # execute and modify the class - pythonizors are always lazily run when a given; # class is used for the first time from a Python script.; my_object = ROOT.MyClass(); ; # Since the pythonizor already executed, we should now see the new behaviour.; # For that purpose, let's print `my_object` (should show ""This is a MyClass; # object"").; print(my_object); ; # The previous example is just a simple one, but there are many ways in which a; # class can be pythonized. Typic",MatchSource.WIKI,doc/master/pyroot002__pythonizationDecorator_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py.html
https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py.html:7758,Security,access,access,7758," instance using regular expressions.; @pythonization('pair<', ns='std', is_prefix=True); def pair_pythonizor(klass, name):; print('Pythonizing class ' + name); ; # The pythonizor above will be applied to any instantiation of `std::pair` - we; # can see this with the print we did inside the pythonizor.; # Note that we could use the `name` parameter to e.g. further filter which; # particular instantiations we would like to pythonize.; p1 = ROOT.std.pair['int','int'](1,2) # prints 'Pythonizing class std::pair<int,int>'; p2 = ROOT.std.pair['int','double'](1,2.) # prints 'Pythonizing class std::pair<int,double>'; ; # Note that, to pythonize multiple classes in different namespaces, we can; # stack multiple @pythonization decorators. For example, if we define these; # classes:; ROOT.gInterpreter.Declare('''; class FirstClass {};; namespace NS {; class SecondClass {};; }; '''); ; # We can pythonize both of them with a single pythonizor function like so:; @pythonization('FirstClass'); @pythonization('SecondClass', ns='NS'); def pythonizor_for_first_and_second(klass, name):; print('Executed for class ' + name); ; # If we now access both classes, we should see that the pythonizor runs twice.; f = ROOT.FirstClass(); s = ROOT.NS.SecondClass(); ; # So far we have seen how pythonizations can be registered for classes that; # have not been used yet. We have discussed how, in that case, the pythonizor; # functions are executed lazily when their target class/es are used for the; # first time in the application.; # However, it can also happen that our target class/es have already been; # accessed by the time we register a pythonization. In such a scenario, the; # pythonizor is applied immediately (at registration time) to the target; # class/es.; ; # Let's see an example of what was just explained. We will define a new class; # and immediately create an object of that class. We can check how the object; # still does not have a new attribute `pythonized` that we are going to inject; # ",MatchSource.WIKI,doc/master/pyroot002__pythonizationDecorator_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py.html
https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py.html:8221,Security,access,accessed,8221,"ing class std::pair<int,double>'; ; # Note that, to pythonize multiple classes in different namespaces, we can; # stack multiple @pythonization decorators. For example, if we define these; # classes:; ROOT.gInterpreter.Declare('''; class FirstClass {};; namespace NS {; class SecondClass {};; }; '''); ; # We can pythonize both of them with a single pythonizor function like so:; @pythonization('FirstClass'); @pythonization('SecondClass', ns='NS'); def pythonizor_for_first_and_second(klass, name):; print('Executed for class ' + name); ; # If we now access both classes, we should see that the pythonizor runs twice.; f = ROOT.FirstClass(); s = ROOT.NS.SecondClass(); ; # So far we have seen how pythonizations can be registered for classes that; # have not been used yet. We have discussed how, in that case, the pythonizor; # functions are executed lazily when their target class/es are used for the; # first time in the application.; # However, it can also happen that our target class/es have already been; # accessed by the time we register a pythonization. In such a scenario, the; # pythonizor is applied immediately (at registration time) to the target; # class/es.; ; # Let's see an example of what was just explained. We will define a new class; # and immediately create an object of that class. We can check how the object; # still does not have a new attribute `pythonized` that we are going to inject; # in the next step.; ROOT.gInterpreter.Declare('''; class MyClass2 {};; '''); o = ROOT.MyClass2(); try:; print(o.pythonized); except AttributeError:; print(""Object has not been pythonized yet!""); ; # After that, we will register a pythonization for `MyClass2`. Since the class; # has already been used, the pythonization will happen right away.; @pythonization('MyClass2'); def pythonizor_for_myclass2(klass):; klass.pythonized = True; ; # Now our object does have the `pythonized` attribute:; print(o.pythonized) # prints True; formatOption_t Option_t TPoint TPoint const char GetTex",MatchSource.WIKI,doc/master/pyroot002__pythonizationDecorator_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py.html
https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py.html:8615,Security,inject,inject,8615,"ike so:; @pythonization('FirstClass'); @pythonization('SecondClass', ns='NS'); def pythonizor_for_first_and_second(klass, name):; print('Executed for class ' + name); ; # If we now access both classes, we should see that the pythonizor runs twice.; f = ROOT.FirstClass(); s = ROOT.NS.SecondClass(); ; # So far we have seen how pythonizations can be registered for classes that; # have not been used yet. We have discussed how, in that case, the pythonizor; # functions are executed lazily when their target class/es are used for the; # first time in the application.; # However, it can also happen that our target class/es have already been; # accessed by the time we register a pythonization. In such a scenario, the; # pythonizor is applied immediately (at registration time) to the target; # class/es.; ; # Let's see an example of what was just explained. We will define a new class; # and immediately create an object of that class. We can check how the object; # still does not have a new attribute `pythonized` that we are going to inject; # in the next step.; ROOT.gInterpreter.Declare('''; class MyClass2 {};; '''); o = ROOT.MyClass2(); try:; print(o.pythonized); except AttributeError:; print(""Object has not been pythonized yet!""); ; # After that, we will register a pythonization for `MyClass2`. Since the class; # has already been used, the pythonization will happen right away.; @pythonization('MyClass2'); def pythonizor_for_myclass2(klass):; klass.pythonized = True; ; # Now our object does have the `pythonized` attribute:; print(o.pythonized) # prints True; formatOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t Float_t Float_t Int_t Int_t UInt_t UInt_t Rectangle_t Int_t Int_t Window_t TString Int_t GCValues_t GetPrimarySelectionOwner GetDisplay GetScreen GetColormap GetNativeEvent const char const char dpyName wid wind",MatchSource.WIKI,doc/master/pyroot002__pythonizationDecorator_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py.html
https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py.html:1837,Usability,simpl,simple,1837," header.; # For more information about loading C++ user code to be used from Python with; # PyROOT, please see:; # https://root.cern.ch/manual/python/#loading-user-libraries-and-just-in-time-compilation-jitting; ROOT.gInterpreter.Declare('''; class MyClass {};; '''); ; # Next, we define a pythonizor function: the function that will be responsible; # for injecting new behaviour in our C++ class `MyClass`.; #; # To convert a given Python function into a pythonizor, we need to decorate it; # with the @pythonization decorator. Such decorator allows us to define which; # which class we want to pythonize by providing its class name and its; # namespace (if the latter is not specified, it defaults to the global; # namespace, i.e. '::').; #; # The decorated function - the pythonizor - must accept either one or two; # parameters:; # 1. The class to be pythonized (proxy object where new behaviour can be; # injected); # 2. The fully-qualified name of that class (optional).; #; # Let's see all this with a simple example. Suppose I would like to define how; # `MyClass` objects are represented as a string in Python (i.e. what would be; # shown when I print that object). For that purpose, I can define the following; # pythonizor function. There are two important things to be noted here:; # - The @pythonization decorator has one argument that specifies our target; # class is `MyClass`.; # - The pythonizor function `pythonizor_of_myclass` provides and injects a new; # implementation for `__str__`, the mechanism that Python provides to define; # how to represent objects as strings. This new implementation; # always returns the string ""This is a MyClass object"".; @pythonization('MyClass'); def pythonizor_of_myclass(klass):; klass.__str__ = lambda o : 'This is a MyClass object'; ; # Once we have defined our pythonizor function, let's see it in action.; # We will now use the `MyClass` class for the first time from Python: we will; # create a new instance of that class. At this moment, t",MatchSource.WIKI,doc/master/pyroot002__pythonizationDecorator_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py.html
https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py.html:3239,Usability,simpl,simple,3239,"n `pythonizor_of_myclass` provides and injects a new; # implementation for `__str__`, the mechanism that Python provides to define; # how to represent objects as strings. This new implementation; # always returns the string ""This is a MyClass object"".; @pythonization('MyClass'); def pythonizor_of_myclass(klass):; klass.__str__ = lambda o : 'This is a MyClass object'; ; # Once we have defined our pythonizor function, let's see it in action.; # We will now use the `MyClass` class for the first time from Python: we will; # create a new instance of that class. At this moment, the pythonizor will; # execute and modify the class - pythonizors are always lazily run when a given; # class is used for the first time from a Python script.; my_object = ROOT.MyClass(); ; # Since the pythonizor already executed, we should now see the new behaviour.; # For that purpose, let's print `my_object` (should show ""This is a MyClass; # object"").; print(my_object); ; # The previous example is just a simple one, but there are many ways in which a; # class can be pythonized. Typical examples are the redefinition of dunder; # methods (e.g. `__iter__` and `__next__` to make your objects iterable from; # Python). If you need some inspiration, many ROOT classes are pythonized in; # the way we just saw; their pythonizations can be seen at:; # https://github.com/root-project/root/tree/master/bindings/pyroot/pythonizations/python/ROOT/pythonization; ; # The @pythonization decorator offers a few more options when it comes to; # matching classes that you want to pythonize. We saw that we can match a; # single class, but we can also specify a list of classes to pythonize.; #; # The following code defines a couple of new classes:; ROOT.gInterpreter.Declare('''; namespace NS {; class Class1 {};; class Class2 {};; }; '''); ; # Note that these classes belong to the `NS` namespace. As mentioned above, the; # @pythonization decorator accepts a parameter with the namespace of the class; # or classes to be pyt",MatchSource.WIKI,doc/master/pyroot002__pythonizationDecorator_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py.html
https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py_source.html:1356,Integrability,inject,injecting,1356,"hows how to use the `@pythonization` decorator to add extra; 5## behaviour to C++ user classes that are used from Python via PyROOT.; 6##; 7## \macro_code; 8## \macro_output; 9##; 10## \date November 2021; 11## \author Enric Tejedor; 12 ; 13import ROOT; 14from ROOT import pythonization; 15 ; 16# Let's first define a new C++ class. In this tutorial, we will see how we can; 17# ""pythonize"" this class, i.e. how we can add some extra behaviour to it to; 18# make it more pythonic or easier to use from Python.; 19#; 20# Note: In this example, the class is defined dynamically for demonstration; 21# purposes, but it could also be a C++ class defined in some library or header.; 22# For more information about loading C++ user code to be used from Python with; 23# PyROOT, please see:; 24# https://root.cern.ch/manual/python/#loading-user-libraries-and-just-in-time-compilation-jitting; 25ROOT.gInterpreter.Declare('''; 26class MyClass {};; 27'''); 28 ; 29# Next, we define a pythonizor function: the function that will be responsible; 30# for injecting new behaviour in our C++ class `MyClass`.; 31#; 32# To convert a given Python function into a pythonizor, we need to decorate it; 33# with the @pythonization decorator. Such decorator allows us to define which; 34# which class we want to pythonize by providing its class name and its; 35# namespace (if the latter is not specified, it defaults to the global; 36# namespace, i.e. '::').; 37#; 38# The decorated function - the pythonizor - must accept either one or two; 39# parameters:; 40# 1. The class to be pythonized (proxy object where new behaviour can be; 41# injected); 42# 2. The fully-qualified name of that class (optional).; 43#; 44# Let's see all this with a simple example. Suppose I would like to define how; 45# `MyClass` objects are represented as a string in Python (i.e. what would be; 46# shown when I print that object). For that purpose, I can define the following; 47# pythonizor function. There are two important things to b",MatchSource.WIKI,doc/master/pyroot002__pythonizationDecorator_8py_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py_source.html
https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py_source.html:1932,Integrability,inject,injected,1932,"ion; 21# purposes, but it could also be a C++ class defined in some library or header.; 22# For more information about loading C++ user code to be used from Python with; 23# PyROOT, please see:; 24# https://root.cern.ch/manual/python/#loading-user-libraries-and-just-in-time-compilation-jitting; 25ROOT.gInterpreter.Declare('''; 26class MyClass {};; 27'''); 28 ; 29# Next, we define a pythonizor function: the function that will be responsible; 30# for injecting new behaviour in our C++ class `MyClass`.; 31#; 32# To convert a given Python function into a pythonizor, we need to decorate it; 33# with the @pythonization decorator. Such decorator allows us to define which; 34# which class we want to pythonize by providing its class name and its; 35# namespace (if the latter is not specified, it defaults to the global; 36# namespace, i.e. '::').; 37#; 38# The decorated function - the pythonizor - must accept either one or two; 39# parameters:; 40# 1. The class to be pythonized (proxy object where new behaviour can be; 41# injected); 42# 2. The fully-qualified name of that class (optional).; 43#; 44# Let's see all this with a simple example. Suppose I would like to define how; 45# `MyClass` objects are represented as a string in Python (i.e. what would be; 46# shown when I print that object). For that purpose, I can define the following; 47# pythonizor function. There are two important things to be noted here:; 48# - The @pythonization decorator has one argument that specifies our target; 49# class is `MyClass`.; 50# - The pythonizor function `pythonizor_of_myclass` provides and injects a new; 51# implementation for `__str__`, the mechanism that Python provides to define; 52# how to represent objects as strings. This new implementation; 53# always returns the string ""This is a MyClass object"".; 54@pythonization('MyClass'); 55def pythonizor_of_myclass(klass):; 56 klass.__str__ = lambda o : 'This is a MyClass object'; 57 ; 58# Once we have defined our pythonizor function, let's ",MatchSource.WIKI,doc/master/pyroot002__pythonizationDecorator_8py_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py_source.html
https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py_source.html:2499,Integrability,inject,injects,2499,"r. Such decorator allows us to define which; 34# which class we want to pythonize by providing its class name and its; 35# namespace (if the latter is not specified, it defaults to the global; 36# namespace, i.e. '::').; 37#; 38# The decorated function - the pythonizor - must accept either one or two; 39# parameters:; 40# 1. The class to be pythonized (proxy object where new behaviour can be; 41# injected); 42# 2. The fully-qualified name of that class (optional).; 43#; 44# Let's see all this with a simple example. Suppose I would like to define how; 45# `MyClass` objects are represented as a string in Python (i.e. what would be; 46# shown when I print that object). For that purpose, I can define the following; 47# pythonizor function. There are two important things to be noted here:; 48# - The @pythonization decorator has one argument that specifies our target; 49# class is `MyClass`.; 50# - The pythonizor function `pythonizor_of_myclass` provides and injects a new; 51# implementation for `__str__`, the mechanism that Python provides to define; 52# how to represent objects as strings. This new implementation; 53# always returns the string ""This is a MyClass object"".; 54@pythonization('MyClass'); 55def pythonizor_of_myclass(klass):; 56 klass.__str__ = lambda o : 'This is a MyClass object'; 57 ; 58# Once we have defined our pythonizor function, let's see it in action.; 59# We will now use the `MyClass` class for the first time from Python: we will; 60# create a new instance of that class. At this moment, the pythonizor will; 61# execute and modify the class - pythonizors are always lazily run when a given; 62# class is used for the first time from a Python script.; 63my_object = ROOT.MyClass(); 64 ; 65# Since the pythonizor already executed, we should now see the new behaviour.; 66# For that purpose, let's print `my_object` (should show ""This is a MyClass; 67# object"").; 68print(my_object); 69 ; 70# The previous example is just a simple one, but there are many ways i",MatchSource.WIKI,doc/master/pyroot002__pythonizationDecorator_8py_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py_source.html
https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py_source.html:9201,Integrability,inject,inject,9201,"Class', ns='NS'); 164def pythonizor_for_first_and_second(klass, name):; 165 print('Executed for class ' + name); 166 ; 167# If we now access both classes, we should see that the pythonizor runs twice.; 168f = ROOT.FirstClass(); 169s = ROOT.NS.SecondClass(); 170 ; 171# So far we have seen how pythonizations can be registered for classes that; 172# have not been used yet. We have discussed how, in that case, the pythonizor; 173# functions are executed lazily when their target class/es are used for the; 174# first time in the application.; 175# However, it can also happen that our target class/es have already been; 176# accessed by the time we register a pythonization. In such a scenario, the; 177# pythonizor is applied immediately (at registration time) to the target; 178# class/es.; 179 ; 180# Let's see an example of what was just explained. We will define a new class; 181# and immediately create an object of that class. We can check how the object; 182# still does not have a new attribute `pythonized` that we are going to inject; 183# in the next step.; 184ROOT.gInterpreter.Declare('''; 185class MyClass2 {};; 186'''); 187o = ROOT.MyClass2(); 188try:; 189 print(o.pythonized); 190except AttributeError:; 191 print(""Object has not been pythonized yet!""); 192 ; 193# After that, we will register a pythonization for `MyClass2`. Since the class; 194# has already been used, the pythonization will happen right away.; 195@pythonization('MyClass2'); 196def pythonizor_for_myclass2(klass):; 197 klass.pythonized = True; 198 ; 199# Now our object does have the `pythonized` attribute:; 200print(o.pythonized) # prints True; formatOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t Float_t Float_t Int_t Int_t UInt_t UInt_t Rectangle_t Int_t Int_t Window_t TString Int_t GCValues_t GetPrimarySelectionOwner GetDisplay GetScreen GetCol",MatchSource.WIKI,doc/master/pyroot002__pythonizationDecorator_8py_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py_source.html
https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py_source.html:1022,Performance,load,loading,1022,"rator.py Source File. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. pyroot002_pythonizationDecorator.py. Go to the documentation of this file. 1## \file; 2## \ingroup tutorial_pyroot; 3## \notebook -nodraw; 4## This tutorial shows how to use the `@pythonization` decorator to add extra; 5## behaviour to C++ user classes that are used from Python via PyROOT.; 6##; 7## \macro_code; 8## \macro_output; 9##; 10## \date November 2021; 11## \author Enric Tejedor; 12 ; 13import ROOT; 14from ROOT import pythonization; 15 ; 16# Let's first define a new C++ class. In this tutorial, we will see how we can; 17# ""pythonize"" this class, i.e. how we can add some extra behaviour to it to; 18# make it more pythonic or easier to use from Python.; 19#; 20# Note: In this example, the class is defined dynamically for demonstration; 21# purposes, but it could also be a C++ class defined in some library or header.; 22# For more information about loading C++ user code to be used from Python with; 23# PyROOT, please see:; 24# https://root.cern.ch/manual/python/#loading-user-libraries-and-just-in-time-compilation-jitting; 25ROOT.gInterpreter.Declare('''; 26class MyClass {};; 27'''); 28 ; 29# Next, we define a pythonizor function: the function that will be responsible; 30# for injecting new behaviour in our C++ class `MyClass`.; 31#; 32# To convert a given Python function into a pythonizor, we need to decorate it; 33# with the @pythonization decorator. Such decorator allows us to define which; 34# which class we want to pythonize by providing its class name and its; 35# namespace (if the latter is not specified, it defaults to the global; 36# namespace, i.e. '::').; 37#; 38# The decorated function - the pythonizor - must accept either one or two; 39# parameters:; 40# 1. The class to be pythonized (proxy object where new behaviour can be; 41# injected); 42# 2. The fully-qualified name of that class (optional).; 43#; 44# Let's see all this with a simple example.",MatchSource.WIKI,doc/master/pyroot002__pythonizationDecorator_8py_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py_source.html
https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py_source.html:1138,Performance,load,loading-user-libraries-and-just-in-time-compilation-jitting,1138,"2_pythonizationDecorator.py. Go to the documentation of this file. 1## \file; 2## \ingroup tutorial_pyroot; 3## \notebook -nodraw; 4## This tutorial shows how to use the `@pythonization` decorator to add extra; 5## behaviour to C++ user classes that are used from Python via PyROOT.; 6##; 7## \macro_code; 8## \macro_output; 9##; 10## \date November 2021; 11## \author Enric Tejedor; 12 ; 13import ROOT; 14from ROOT import pythonization; 15 ; 16# Let's first define a new C++ class. In this tutorial, we will see how we can; 17# ""pythonize"" this class, i.e. how we can add some extra behaviour to it to; 18# make it more pythonic or easier to use from Python.; 19#; 20# Note: In this example, the class is defined dynamically for demonstration; 21# purposes, but it could also be a C++ class defined in some library or header.; 22# For more information about loading C++ user code to be used from Python with; 23# PyROOT, please see:; 24# https://root.cern.ch/manual/python/#loading-user-libraries-and-just-in-time-compilation-jitting; 25ROOT.gInterpreter.Declare('''; 26class MyClass {};; 27'''); 28 ; 29# Next, we define a pythonizor function: the function that will be responsible; 30# for injecting new behaviour in our C++ class `MyClass`.; 31#; 32# To convert a given Python function into a pythonizor, we need to decorate it; 33# with the @pythonization decorator. Such decorator allows us to define which; 34# which class we want to pythonize by providing its class name and its; 35# namespace (if the latter is not specified, it defaults to the global; 36# namespace, i.e. '::').; 37#; 38# The decorated function - the pythonizor - must accept either one or two; 39# parameters:; 40# 1. The class to be pythonized (proxy object where new behaviour can be; 41# injected); 42# 2. The fully-qualified name of that class (optional).; 43#; 44# Let's see all this with a simple example. Suppose I would like to define how; 45# `MyClass` objects are represented as a string in Python (i.e. what wou",MatchSource.WIKI,doc/master/pyroot002__pythonizationDecorator_8py_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py_source.html
https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py_source.html:1356,Security,inject,injecting,1356,"hows how to use the `@pythonization` decorator to add extra; 5## behaviour to C++ user classes that are used from Python via PyROOT.; 6##; 7## \macro_code; 8## \macro_output; 9##; 10## \date November 2021; 11## \author Enric Tejedor; 12 ; 13import ROOT; 14from ROOT import pythonization; 15 ; 16# Let's first define a new C++ class. In this tutorial, we will see how we can; 17# ""pythonize"" this class, i.e. how we can add some extra behaviour to it to; 18# make it more pythonic or easier to use from Python.; 19#; 20# Note: In this example, the class is defined dynamically for demonstration; 21# purposes, but it could also be a C++ class defined in some library or header.; 22# For more information about loading C++ user code to be used from Python with; 23# PyROOT, please see:; 24# https://root.cern.ch/manual/python/#loading-user-libraries-and-just-in-time-compilation-jitting; 25ROOT.gInterpreter.Declare('''; 26class MyClass {};; 27'''); 28 ; 29# Next, we define a pythonizor function: the function that will be responsible; 30# for injecting new behaviour in our C++ class `MyClass`.; 31#; 32# To convert a given Python function into a pythonizor, we need to decorate it; 33# with the @pythonization decorator. Such decorator allows us to define which; 34# which class we want to pythonize by providing its class name and its; 35# namespace (if the latter is not specified, it defaults to the global; 36# namespace, i.e. '::').; 37#; 38# The decorated function - the pythonizor - must accept either one or two; 39# parameters:; 40# 1. The class to be pythonized (proxy object where new behaviour can be; 41# injected); 42# 2. The fully-qualified name of that class (optional).; 43#; 44# Let's see all this with a simple example. Suppose I would like to define how; 45# `MyClass` objects are represented as a string in Python (i.e. what would be; 46# shown when I print that object). For that purpose, I can define the following; 47# pythonizor function. There are two important things to b",MatchSource.WIKI,doc/master/pyroot002__pythonizationDecorator_8py_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py_source.html
https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py_source.html:1932,Security,inject,injected,1932,"ion; 21# purposes, but it could also be a C++ class defined in some library or header.; 22# For more information about loading C++ user code to be used from Python with; 23# PyROOT, please see:; 24# https://root.cern.ch/manual/python/#loading-user-libraries-and-just-in-time-compilation-jitting; 25ROOT.gInterpreter.Declare('''; 26class MyClass {};; 27'''); 28 ; 29# Next, we define a pythonizor function: the function that will be responsible; 30# for injecting new behaviour in our C++ class `MyClass`.; 31#; 32# To convert a given Python function into a pythonizor, we need to decorate it; 33# with the @pythonization decorator. Such decorator allows us to define which; 34# which class we want to pythonize by providing its class name and its; 35# namespace (if the latter is not specified, it defaults to the global; 36# namespace, i.e. '::').; 37#; 38# The decorated function - the pythonizor - must accept either one or two; 39# parameters:; 40# 1. The class to be pythonized (proxy object where new behaviour can be; 41# injected); 42# 2. The fully-qualified name of that class (optional).; 43#; 44# Let's see all this with a simple example. Suppose I would like to define how; 45# `MyClass` objects are represented as a string in Python (i.e. what would be; 46# shown when I print that object). For that purpose, I can define the following; 47# pythonizor function. There are two important things to be noted here:; 48# - The @pythonization decorator has one argument that specifies our target; 49# class is `MyClass`.; 50# - The pythonizor function `pythonizor_of_myclass` provides and injects a new; 51# implementation for `__str__`, the mechanism that Python provides to define; 52# how to represent objects as strings. This new implementation; 53# always returns the string ""This is a MyClass object"".; 54@pythonization('MyClass'); 55def pythonizor_of_myclass(klass):; 56 klass.__str__ = lambda o : 'This is a MyClass object'; 57 ; 58# Once we have defined our pythonizor function, let's ",MatchSource.WIKI,doc/master/pyroot002__pythonizationDecorator_8py_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py_source.html
https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py_source.html:2499,Security,inject,injects,2499,"r. Such decorator allows us to define which; 34# which class we want to pythonize by providing its class name and its; 35# namespace (if the latter is not specified, it defaults to the global; 36# namespace, i.e. '::').; 37#; 38# The decorated function - the pythonizor - must accept either one or two; 39# parameters:; 40# 1. The class to be pythonized (proxy object where new behaviour can be; 41# injected); 42# 2. The fully-qualified name of that class (optional).; 43#; 44# Let's see all this with a simple example. Suppose I would like to define how; 45# `MyClass` objects are represented as a string in Python (i.e. what would be; 46# shown when I print that object). For that purpose, I can define the following; 47# pythonizor function. There are two important things to be noted here:; 48# - The @pythonization decorator has one argument that specifies our target; 49# class is `MyClass`.; 50# - The pythonizor function `pythonizor_of_myclass` provides and injects a new; 51# implementation for `__str__`, the mechanism that Python provides to define; 52# how to represent objects as strings. This new implementation; 53# always returns the string ""This is a MyClass object"".; 54@pythonization('MyClass'); 55def pythonizor_of_myclass(klass):; 56 klass.__str__ = lambda o : 'This is a MyClass object'; 57 ; 58# Once we have defined our pythonizor function, let's see it in action.; 59# We will now use the `MyClass` class for the first time from Python: we will; 60# create a new instance of that class. At this moment, the pythonizor will; 61# execute and modify the class - pythonizors are always lazily run when a given; 62# class is used for the first time from a Python script.; 63my_object = ROOT.MyClass(); 64 ; 65# Since the pythonizor already executed, we should now see the new behaviour.; 66# For that purpose, let's print `my_object` (should show ""This is a MyClass; 67# object"").; 68print(my_object); 69 ; 70# The previous example is just a simple one, but there are many ways i",MatchSource.WIKI,doc/master/pyroot002__pythonizationDecorator_8py_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py_source.html
https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py_source.html:8297,Security,access,access,8297,"td', is_prefix=True); 141def pair_pythonizor(klass, name):; 142 print('Pythonizing class ' + name); 143 ; 144# The pythonizor above will be applied to any instantiation of `std::pair` - we; 145# can see this with the print we did inside the pythonizor.; 146# Note that we could use the `name` parameter to e.g. further filter which; 147# particular instantiations we would like to pythonize.; 148p1 = ROOT.std.pair['int','int'](1,2) # prints 'Pythonizing class std::pair<int,int>'; 149p2 = ROOT.std.pair['int','double'](1,2.) # prints 'Pythonizing class std::pair<int,double>'; 150 ; 151# Note that, to pythonize multiple classes in different namespaces, we can; 152# stack multiple @pythonization decorators. For example, if we define these; 153# classes:; 154ROOT.gInterpreter.Declare('''; 155class FirstClass {};; 156namespace NS {; 157 class SecondClass {};; 158}; 159'''); 160 ; 161# We can pythonize both of them with a single pythonizor function like so:; 162@pythonization('FirstClass'); 163@pythonization('SecondClass', ns='NS'); 164def pythonizor_for_first_and_second(klass, name):; 165 print('Executed for class ' + name); 166 ; 167# If we now access both classes, we should see that the pythonizor runs twice.; 168f = ROOT.FirstClass(); 169s = ROOT.NS.SecondClass(); 170 ; 171# So far we have seen how pythonizations can be registered for classes that; 172# have not been used yet. We have discussed how, in that case, the pythonizor; 173# functions are executed lazily when their target class/es are used for the; 174# first time in the application.; 175# However, it can also happen that our target class/es have already been; 176# accessed by the time we register a pythonization. In such a scenario, the; 177# pythonizor is applied immediately (at registration time) to the target; 178# class/es.; 179 ; 180# Let's see an example of what was just explained. We will define a new class; 181# and immediately create an object of that class. We can check how the object; 182# still does ",MatchSource.WIKI,doc/master/pyroot002__pythonizationDecorator_8py_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py_source.html
https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py_source.html:8788,Security,access,accessed,8788,"s in different namespaces, we can; 152# stack multiple @pythonization decorators. For example, if we define these; 153# classes:; 154ROOT.gInterpreter.Declare('''; 155class FirstClass {};; 156namespace NS {; 157 class SecondClass {};; 158}; 159'''); 160 ; 161# We can pythonize both of them with a single pythonizor function like so:; 162@pythonization('FirstClass'); 163@pythonization('SecondClass', ns='NS'); 164def pythonizor_for_first_and_second(klass, name):; 165 print('Executed for class ' + name); 166 ; 167# If we now access both classes, we should see that the pythonizor runs twice.; 168f = ROOT.FirstClass(); 169s = ROOT.NS.SecondClass(); 170 ; 171# So far we have seen how pythonizations can be registered for classes that; 172# have not been used yet. We have discussed how, in that case, the pythonizor; 173# functions are executed lazily when their target class/es are used for the; 174# first time in the application.; 175# However, it can also happen that our target class/es have already been; 176# accessed by the time we register a pythonization. In such a scenario, the; 177# pythonizor is applied immediately (at registration time) to the target; 178# class/es.; 179 ; 180# Let's see an example of what was just explained. We will define a new class; 181# and immediately create an object of that class. We can check how the object; 182# still does not have a new attribute `pythonized` that we are going to inject; 183# in the next step.; 184ROOT.gInterpreter.Declare('''; 185class MyClass2 {};; 186'''); 187o = ROOT.MyClass2(); 188try:; 189 print(o.pythonized); 190except AttributeError:; 191 print(""Object has not been pythonized yet!""); 192 ; 193# After that, we will register a pythonization for `MyClass2`. Since the class; 194# has already been used, the pythonization will happen right away.; 195@pythonization('MyClass2'); 196def pythonizor_for_myclass2(klass):; 197 klass.pythonized = True; 198 ; 199# Now our object does have the `pythonized` attribute:; 200print(o.p",MatchSource.WIKI,doc/master/pyroot002__pythonizationDecorator_8py_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py_source.html
https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py_source.html:9201,Security,inject,inject,9201,"Class', ns='NS'); 164def pythonizor_for_first_and_second(klass, name):; 165 print('Executed for class ' + name); 166 ; 167# If we now access both classes, we should see that the pythonizor runs twice.; 168f = ROOT.FirstClass(); 169s = ROOT.NS.SecondClass(); 170 ; 171# So far we have seen how pythonizations can be registered for classes that; 172# have not been used yet. We have discussed how, in that case, the pythonizor; 173# functions are executed lazily when their target class/es are used for the; 174# first time in the application.; 175# However, it can also happen that our target class/es have already been; 176# accessed by the time we register a pythonization. In such a scenario, the; 177# pythonizor is applied immediately (at registration time) to the target; 178# class/es.; 179 ; 180# Let's see an example of what was just explained. We will define a new class; 181# and immediately create an object of that class. We can check how the object; 182# still does not have a new attribute `pythonized` that we are going to inject; 183# in the next step.; 184ROOT.gInterpreter.Declare('''; 185class MyClass2 {};; 186'''); 187o = ROOT.MyClass2(); 188try:; 189 print(o.pythonized); 190except AttributeError:; 191 print(""Object has not been pythonized yet!""); 192 ; 193# After that, we will register a pythonization for `MyClass2`. Since the class; 194# has already been used, the pythonization will happen right away.; 195@pythonization('MyClass2'); 196def pythonizor_for_myclass2(klass):; 197 klass.pythonized = True; 198 ; 199# Now our object does have the `pythonized` attribute:; 200print(o.pythonized) # prints True; formatOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t Float_t Float_t Int_t Int_t UInt_t UInt_t Rectangle_t Int_t Int_t Window_t TString Int_t GCValues_t GetPrimarySelectionOwner GetDisplay GetScreen GetCol",MatchSource.WIKI,doc/master/pyroot002__pythonizationDecorator_8py_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py_source.html
https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py_source.html:2037,Usability,simpl,simple,2037,"ing C++ user code to be used from Python with; 23# PyROOT, please see:; 24# https://root.cern.ch/manual/python/#loading-user-libraries-and-just-in-time-compilation-jitting; 25ROOT.gInterpreter.Declare('''; 26class MyClass {};; 27'''); 28 ; 29# Next, we define a pythonizor function: the function that will be responsible; 30# for injecting new behaviour in our C++ class `MyClass`.; 31#; 32# To convert a given Python function into a pythonizor, we need to decorate it; 33# with the @pythonization decorator. Such decorator allows us to define which; 34# which class we want to pythonize by providing its class name and its; 35# namespace (if the latter is not specified, it defaults to the global; 36# namespace, i.e. '::').; 37#; 38# The decorated function - the pythonizor - must accept either one or two; 39# parameters:; 40# 1. The class to be pythonized (proxy object where new behaviour can be; 41# injected); 42# 2. The fully-qualified name of that class (optional).; 43#; 44# Let's see all this with a simple example. Suppose I would like to define how; 45# `MyClass` objects are represented as a string in Python (i.e. what would be; 46# shown when I print that object). For that purpose, I can define the following; 47# pythonizor function. There are two important things to be noted here:; 48# - The @pythonization decorator has one argument that specifies our target; 49# class is `MyClass`.; 50# - The pythonizor function `pythonizor_of_myclass` provides and injects a new; 51# implementation for `__str__`, the mechanism that Python provides to define; 52# how to represent objects as strings. This new implementation; 53# always returns the string ""This is a MyClass object"".; 54@pythonization('MyClass'); 55def pythonizor_of_myclass(klass):; 56 klass.__str__ = lambda o : 'This is a MyClass object'; 57 ; 58# Once we have defined our pythonizor function, let's see it in action.; 59# We will now use the `MyClass` class for the first time from Python: we will; 60# create a new insta",MatchSource.WIKI,doc/master/pyroot002__pythonizationDecorator_8py_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py_source.html
https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py_source.html:3495,Usability,simpl,simple,3495,"ects a new; 51# implementation for `__str__`, the mechanism that Python provides to define; 52# how to represent objects as strings. This new implementation; 53# always returns the string ""This is a MyClass object"".; 54@pythonization('MyClass'); 55def pythonizor_of_myclass(klass):; 56 klass.__str__ = lambda o : 'This is a MyClass object'; 57 ; 58# Once we have defined our pythonizor function, let's see it in action.; 59# We will now use the `MyClass` class for the first time from Python: we will; 60# create a new instance of that class. At this moment, the pythonizor will; 61# execute and modify the class - pythonizors are always lazily run when a given; 62# class is used for the first time from a Python script.; 63my_object = ROOT.MyClass(); 64 ; 65# Since the pythonizor already executed, we should now see the new behaviour.; 66# For that purpose, let's print `my_object` (should show ""This is a MyClass; 67# object"").; 68print(my_object); 69 ; 70# The previous example is just a simple one, but there are many ways in which a; 71# class can be pythonized. Typical examples are the redefinition of dunder; 72# methods (e.g. `__iter__` and `__next__` to make your objects iterable from; 73# Python). If you need some inspiration, many ROOT classes are pythonized in; 74# the way we just saw; their pythonizations can be seen at:; 75# https://github.com/root-project/root/tree/master/bindings/pyroot/pythonizations/python/ROOT/pythonization; 76 ; 77# The @pythonization decorator offers a few more options when it comes to; 78# matching classes that you want to pythonize. We saw that we can match a; 79# single class, but we can also specify a list of classes to pythonize.; 80#; 81# The following code defines a couple of new classes:; 82ROOT.gInterpreter.Declare('''; 83namespace NS {; 84 class Class1 {};; 85 class Class2 {};; 86}; 87'''); 88 ; 89# Note that these classes belong to the `NS` namespace. As mentioned above, the; 90# @pythonization decorator accepts a parameter with the",MatchSource.WIKI,doc/master/pyroot002__pythonizationDecorator_8py_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pyroot002__pythonizationDecorator_8py_source.html
https://root.cern/doc/master/pyroot003__prettyPrinting_8py.html:488,Energy Efficiency,power,powered,488,". ROOT: tutorials/pyroot/pyroot003_prettyPrinting.py File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. Namespaces ; pyroot003_prettyPrinting.py File ReferenceTutorials  PyRoot tutorials. Detailed Description; This tutorial illustrates the pretty printing feature of PyROOT, which reveals the content of the object if a string representation is requested, e.g., by Python's print statement. ; The printing behaves similar to the ROOT prompt powered by the C++ interpreter cling.; ; import ROOT; ; # Create an object with PyROOT; obj = ROOT.std.vector(""int"")(3); for i in range(obj.size()):; obj[i] = i; ; # Print the object, which reveals the content. Note that `print` calls the special; # method `__str__` of the object internally.; print(obj); ; # The output can be retrieved as string by any function that triggers the `__str__`; # special method of the object, e.g., `str` or `format`.; print(str(obj)); print(""{}"".format(obj)); ; # Note that the interactive Python prompt does not call `__str__`, it calls; # `__repr__`, which implements a formal and unique string representation of; # the object.; print(repr(obj)); obj; ; # The print output behaves similar to the ROOT prompt, e.g., here for a ROOT histogram.; hist = ROOT.TH1F(""name"", ""title"", 10, 0, 1); print(hist); ; # If cling cannot produce any nice representation for the class, we fall back to a; # ""<ClassName at address>"" format, which is what `__repr__` returns; ROOT.gInterpreter.Declare('class MyClass {};'); m = ROOT.MyClass(); print(m); print(str(m) == repr(m)); ; formatOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t Float_t Float_t Int_t Int_t UInt_t UInt_t Rectangle_t Int_t Int_t Window_t TString Int_t GCValues_t GetPrimarySelectionOwner GetDisplay GetScreen GetColormap GetNativeEvent const char const char dpyNam",MatchSource.WIKI,doc/master/pyroot003__prettyPrinting_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pyroot003__prettyPrinting_8py.html
https://root.cern/doc/master/pyroot004__NumbaDeclare_8py.html:846,Availability,avail,available,846,". ROOT: tutorials/pyroot/pyroot004_NumbaDeclare.py File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. Namespaces ; pyroot004_NumbaDeclare.py File ReferenceTutorials  PyRoot tutorials. Detailed Description; This tutorial illustrates how PyROOT supports declaring C++ callables from Python callables making them, for example, usable with RDataFrame. ; The feature uses the numba Python package for just-in-time compilation of the Python callable and supports fundamental types and ROOT::RVec thereof.; ; import ROOT; ; # To mark a Python callable to be used from C++, you have to use the decorator; # provided by PyROOT passing the C++ types of the input arguments and the return; # value.; @ROOT.Numba.Declare(['float', 'int'], 'float'); def pypow(x, y):; return x**y; ; # The Python callable is now available from C++ in the Numba namespace.; # For example, we can use it from the interpreter.; ROOT.gInterpreter.ProcessLine('cout << ""2^3 = "" << Numba::pypow(2, 3) << endl;'); ; # Or we can use the callable as well within a RDataFrame workflow.; data = ROOT.RDataFrame(4).Define('x', '(float)rdfentry_')\; .Define('x_pow3', 'Numba::pypow(x, 3)')\; .AsNumpy(); ; print('pypow({}, 3) = {}'.format(data['x'], data['x_pow3'])); ; # ROOT uses the numba Python package to create C++ functions from python ones.; # We support as input and return types of the callable fundamental types and; # ROOT::RVec thereof. See the following callable computing the power of the; # elements in an array.; @ROOT.Numba.Declare(['RVecF', 'int'], 'RVecF'); def pypowarray(x, y):; return x**y; ; ROOT.gInterpreter.ProcessLine('''; ROOT::RVecF x = {0, 1, 2, 3};; cout << ""pypowarray("" << x << "", 3) = "" << Numba::pypowarray(x, 3) << endl;; '''); ; # and now with RDataFrame; s = ROOT.RDataFrame(1).Define('x', 'ROOT::RVecF{1,2,3}')\; .Define('x2', 'Numba::pypowarray(x, 2)')\; .Sum('x2') # 1 + 4 + 9 == 14; print('sum(pypowarray({ 1, 2, 3 }, 2)) = ', s.GetValue()); formatOption",MatchSource.WIKI,doc/master/pyroot004__NumbaDeclare_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pyroot004__NumbaDeclare_8py.html
https://root.cern/doc/master/pyroot004__NumbaDeclare_8py.html:1495,Energy Efficiency,power,power,1495,"nd supports fundamental types and ROOT::RVec thereof.; ; import ROOT; ; # To mark a Python callable to be used from C++, you have to use the decorator; # provided by PyROOT passing the C++ types of the input arguments and the return; # value.; @ROOT.Numba.Declare(['float', 'int'], 'float'); def pypow(x, y):; return x**y; ; # The Python callable is now available from C++ in the Numba namespace.; # For example, we can use it from the interpreter.; ROOT.gInterpreter.ProcessLine('cout << ""2^3 = "" << Numba::pypow(2, 3) << endl;'); ; # Or we can use the callable as well within a RDataFrame workflow.; data = ROOT.RDataFrame(4).Define('x', '(float)rdfentry_')\; .Define('x_pow3', 'Numba::pypow(x, 3)')\; .AsNumpy(); ; print('pypow({}, 3) = {}'.format(data['x'], data['x_pow3'])); ; # ROOT uses the numba Python package to create C++ functions from python ones.; # We support as input and return types of the callable fundamental types and; # ROOT::RVec thereof. See the following callable computing the power of the; # elements in an array.; @ROOT.Numba.Declare(['RVecF', 'int'], 'RVecF'); def pypowarray(x, y):; return x**y; ; ROOT.gInterpreter.ProcessLine('''; ROOT::RVecF x = {0, 1, 2, 3};; cout << ""pypowarray("" << x << "", 3) = "" << Numba::pypowarray(x, 3) << endl;; '''); ; # and now with RDataFrame; s = ROOT.RDataFrame(1).Define('x', 'ROOT::RVecF{1,2,3}')\; .Define('x2', 'Numba::pypowarray(x, 2)')\; .Sum('x2') # 1 + 4 + 9 == 14; print('sum(pypowarray({ 1, 2, 3 }, 2)) = ', s.GetValue()); formatOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t Float_t Float_t Int_t Int_t UInt_t UInt_t Rectangle_t Int_t Int_t Window_t TString Int_t GCValues_t GetPrimarySelectionOwner GetDisplay GetScreen GetColormap GetNativeEvent const char const char dpyName wid window const char font_name cursor keysym reg const char only_if_exist regb h Poin",MatchSource.WIKI,doc/master/pyroot004__NumbaDeclare_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pyroot004__NumbaDeclare_8py.html
https://root.cern/doc/master/pyroot004__NumbaDeclare_8py.html:2885,Integrability,interface,interface,2885,"m python ones.; # We support as input and return types of the callable fundamental types and; # ROOT::RVec thereof. See the following callable computing the power of the; # elements in an array.; @ROOT.Numba.Declare(['RVecF', 'int'], 'RVecF'); def pypowarray(x, y):; return x**y; ; ROOT.gInterpreter.ProcessLine('''; ROOT::RVecF x = {0, 1, 2, 3};; cout << ""pypowarray("" << x << "", 3) = "" << Numba::pypowarray(x, 3) << endl;; '''); ; # and now with RDataFrame; s = ROOT.RDataFrame(1).Define('x', 'ROOT::RVecF{1,2,3}')\; .Define('x2', 'Numba::pypowarray(x, 2)')\; .Sum('x2') # 1 + 4 + 9 == 14; print('sum(pypowarray({ 1, 2, 3 }, 2)) = ', s.GetValue()); formatOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t Float_t Float_t Int_t Int_t UInt_t UInt_t Rectangle_t Int_t Int_t Window_t TString Int_t GCValues_t GetPrimarySelectionOwner GetDisplay GetScreen GetColormap GetNativeEvent const char const char dpyName wid window const char font_name cursor keysym reg const char only_if_exist regb h Point_t winding char text const char depth char const char Int_t count const char ColorStruct_t color const char Pixmap_t Pixmap_t PictureAttributes_t attr const char char ret_data h unsigned char height h Atom_t Int_t ULong_t ULong_t unsigned char prop_list Atom_t Atom_t Atom_t Time_t formatDefinition TGWin32VirtualXProxy.cxx:249; ROOT::RDataFrameROOT's RDataFrame offers a modern, high-level interface for analysis of data stored in TTree ,...Definition RDataFrame.hxx:41; 2^3 = 8; pypowarray({ 0, 1, 2, 3 }, 3) = { 0, 1, 8, 27 }; pypow([0. 1. 2. 3.], 3) = [ 0. 1. 8. 27.]; sum(pypowarray({ 1, 2, 3 }, 2)) = 14.0; DateMarch 2020 ; AuthorStefan Wunsch ; Definition in file pyroot004_NumbaDeclare.py. tutorialspyrootpyroot004_NumbaDeclare.py. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:30 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/pyroot004__NumbaDeclare_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pyroot004__NumbaDeclare_8py.html
https://root.cern/doc/master/pyroot004__NumbaDeclare_8py.html:371,Usability,usab,usable,371,". ROOT: tutorials/pyroot/pyroot004_NumbaDeclare.py File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. Namespaces ; pyroot004_NumbaDeclare.py File ReferenceTutorials  PyRoot tutorials. Detailed Description; This tutorial illustrates how PyROOT supports declaring C++ callables from Python callables making them, for example, usable with RDataFrame. ; The feature uses the numba Python package for just-in-time compilation of the Python callable and supports fundamental types and ROOT::RVec thereof.; ; import ROOT; ; # To mark a Python callable to be used from C++, you have to use the decorator; # provided by PyROOT passing the C++ types of the input arguments and the return; # value.; @ROOT.Numba.Declare(['float', 'int'], 'float'); def pypow(x, y):; return x**y; ; # The Python callable is now available from C++ in the Numba namespace.; # For example, we can use it from the interpreter.; ROOT.gInterpreter.ProcessLine('cout << ""2^3 = "" << Numba::pypow(2, 3) << endl;'); ; # Or we can use the callable as well within a RDataFrame workflow.; data = ROOT.RDataFrame(4).Define('x', '(float)rdfentry_')\; .Define('x_pow3', 'Numba::pypow(x, 3)')\; .AsNumpy(); ; print('pypow({}, 3) = {}'.format(data['x'], data['x_pow3'])); ; # ROOT uses the numba Python package to create C++ functions from python ones.; # We support as input and return types of the callable fundamental types and; # ROOT::RVec thereof. See the following callable computing the power of the; # elements in an array.; @ROOT.Numba.Declare(['RVecF', 'int'], 'RVecF'); def pypowarray(x, y):; return x**y; ; ROOT.gInterpreter.ProcessLine('''; ROOT::RVecF x = {0, 1, 2, 3};; cout << ""pypowarray("" << x << "", 3) = "" << Numba::pypowarray(x, 3) << endl;; '''); ; # and now with RDataFrame; s = ROOT.RDataFrame(1).Define('x', 'ROOT::RVecF{1,2,3}')\; .Define('x2', 'Numba::pypowarray(x, 2)')\; .Sum('x2') # 1 + 4 + 9 == 14; print('sum(pypowarray({ 1, 2, 3 }, 2)) = ', s.GetValue()); formatOption",MatchSource.WIKI,doc/master/pyroot004__NumbaDeclare_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pyroot004__NumbaDeclare_8py.html
https://root.cern/doc/master/pyroot004__NumbaDeclare_8py_source.html:1009,Availability,avail,available,1009,". ROOT: tutorials/pyroot/pyroot004_NumbaDeclare.py Source File. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. pyroot004_NumbaDeclare.py. Go to the documentation of this file. 1## \file; 2## \ingroup tutorial_pyroot; 3## \notebook -nodraw; 4## This tutorial illustrates how PyROOT supports declaring C++ callables from; 5## Python callables making them, for example, usable with RDataFrame. The feature; 6## uses the numba Python package for just-in-time compilation of the Python callable; 7## and supports fundamental types and ROOT::RVec thereof.; 8##; 9## \macro_code; 10## \macro_output; 11##; 12## \date March 2020; 13## \author Stefan Wunsch; 14 ; 15import ROOT; 16 ; 17# To mark a Python callable to be used from C++, you have to use the decorator; 18# provided by PyROOT passing the C++ types of the input arguments and the return; 19# value.; 20@ROOT.Numba.Declare(['float', 'int'], 'float'); 21def pypow(x, y):; 22 return x**y; 23 ; 24# The Python callable is now available from C++ in the Numba namespace.; 25# For example, we can use it from the interpreter.; 26ROOT.gInterpreter.ProcessLine('cout << ""2^3 = "" << Numba::pypow(2, 3) << endl;'); 27 ; 28# Or we can use the callable as well within a RDataFrame workflow.; 29data = ROOT.RDataFrame(4).Define('x', '(float)rdfentry_')\; 30 .Define('x_pow3', 'Numba::pypow(x, 3)')\; 31 .AsNumpy(); 32 ; 33print('pypow({}, 3) = {}'.format(data['x'], data['x_pow3'])); 34 ; 35# ROOT uses the numba Python package to create C++ functions from python ones.; 36# We support as input and return types of the callable fundamental types and; 37# ROOT::RVec thereof. See the following callable computing the power of the; 38# elements in an array.; 39@ROOT.Numba.Declare(['RVecF', 'int'], 'RVecF'); 40def pypowarray(x, y):; 41 return x**y; 42 ; 43ROOT.gInterpreter.ProcessLine('''; 44ROOT::RVecF x = {0, 1, 2, 3};; 45cout << ""pypowarray("" << x << "", 3) = "" << Numba::pypowarray(x, 3) << endl;; 46'''); 47 ; 48# and now w",MatchSource.WIKI,doc/master/pyroot004__NumbaDeclare_8py_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pyroot004__NumbaDeclare_8py_source.html
https://root.cern/doc/master/pyroot004__NumbaDeclare_8py_source.html:1689,Energy Efficiency,power,power,1689,"; 15import ROOT; 16 ; 17# To mark a Python callable to be used from C++, you have to use the decorator; 18# provided by PyROOT passing the C++ types of the input arguments and the return; 19# value.; 20@ROOT.Numba.Declare(['float', 'int'], 'float'); 21def pypow(x, y):; 22 return x**y; 23 ; 24# The Python callable is now available from C++ in the Numba namespace.; 25# For example, we can use it from the interpreter.; 26ROOT.gInterpreter.ProcessLine('cout << ""2^3 = "" << Numba::pypow(2, 3) << endl;'); 27 ; 28# Or we can use the callable as well within a RDataFrame workflow.; 29data = ROOT.RDataFrame(4).Define('x', '(float)rdfentry_')\; 30 .Define('x_pow3', 'Numba::pypow(x, 3)')\; 31 .AsNumpy(); 32 ; 33print('pypow({}, 3) = {}'.format(data['x'], data['x_pow3'])); 34 ; 35# ROOT uses the numba Python package to create C++ functions from python ones.; 36# We support as input and return types of the callable fundamental types and; 37# ROOT::RVec thereof. See the following callable computing the power of the; 38# elements in an array.; 39@ROOT.Numba.Declare(['RVecF', 'int'], 'RVecF'); 40def pypowarray(x, y):; 41 return x**y; 42 ; 43ROOT.gInterpreter.ProcessLine('''; 44ROOT::RVecF x = {0, 1, 2, 3};; 45cout << ""pypowarray("" << x << "", 3) = "" << Numba::pypowarray(x, 3) << endl;; 46'''); 47 ; 48# and now with RDataFrame; 49s = ROOT.RDataFrame(1).Define('x', 'ROOT::RVecF{1,2,3}')\; 50 .Define('x2', 'Numba::pypowarray(x, 2)')\; 51 .Sum('x2') # 1 + 4 + 9 == 14; 52print('sum(pypowarray({ 1, 2, 3 }, 2)) = ', s.GetValue()); formatOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t Float_t Float_t Int_t Int_t UInt_t UInt_t Rectangle_t Int_t Int_t Window_t TString Int_t GCValues_t GetPrimarySelectionOwner GetDisplay GetScreen GetColormap GetNativeEvent const char const char dpyName wid window const char font_name cursor keysym reg co",MatchSource.WIKI,doc/master/pyroot004__NumbaDeclare_8py_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pyroot004__NumbaDeclare_8py_source.html
https://root.cern/doc/master/pyroot004__NumbaDeclare_8py_source.html:3114,Integrability,interface,interface,3114,"_pow3', 'Numba::pypow(x, 3)')\; 31 .AsNumpy(); 32 ; 33print('pypow({}, 3) = {}'.format(data['x'], data['x_pow3'])); 34 ; 35# ROOT uses the numba Python package to create C++ functions from python ones.; 36# We support as input and return types of the callable fundamental types and; 37# ROOT::RVec thereof. See the following callable computing the power of the; 38# elements in an array.; 39@ROOT.Numba.Declare(['RVecF', 'int'], 'RVecF'); 40def pypowarray(x, y):; 41 return x**y; 42 ; 43ROOT.gInterpreter.ProcessLine('''; 44ROOT::RVecF x = {0, 1, 2, 3};; 45cout << ""pypowarray("" << x << "", 3) = "" << Numba::pypowarray(x, 3) << endl;; 46'''); 47 ; 48# and now with RDataFrame; 49s = ROOT.RDataFrame(1).Define('x', 'ROOT::RVecF{1,2,3}')\; 50 .Define('x2', 'Numba::pypowarray(x, 2)')\; 51 .Sum('x2') # 1 + 4 + 9 == 14; 52print('sum(pypowarray({ 1, 2, 3 }, 2)) = ', s.GetValue()); formatOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t Float_t Float_t Int_t Int_t UInt_t UInt_t Rectangle_t Int_t Int_t Window_t TString Int_t GCValues_t GetPrimarySelectionOwner GetDisplay GetScreen GetColormap GetNativeEvent const char const char dpyName wid window const char font_name cursor keysym reg const char only_if_exist regb h Point_t winding char text const char depth char const char Int_t count const char ColorStruct_t color const char Pixmap_t Pixmap_t PictureAttributes_t attr const char char ret_data h unsigned char height h Atom_t Int_t ULong_t ULong_t unsigned char prop_list Atom_t Atom_t Atom_t Time_t formatDefinition TGWin32VirtualXProxy.cxx:249; ROOT::RDataFrameROOT's RDataFrame offers a modern, high-level interface for analysis of data stored in TTree ,...Definition RDataFrame.hxx:41. tutorialspyrootpyroot004_NumbaDeclare.py. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:10 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/pyroot004__NumbaDeclare_8py_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pyroot004__NumbaDeclare_8py_source.html
https://root.cern/doc/master/pyroot004__NumbaDeclare_8py_source.html:401,Usability,usab,usable,401,". ROOT: tutorials/pyroot/pyroot004_NumbaDeclare.py Source File. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. pyroot004_NumbaDeclare.py. Go to the documentation of this file. 1## \file; 2## \ingroup tutorial_pyroot; 3## \notebook -nodraw; 4## This tutorial illustrates how PyROOT supports declaring C++ callables from; 5## Python callables making them, for example, usable with RDataFrame. The feature; 6## uses the numba Python package for just-in-time compilation of the Python callable; 7## and supports fundamental types and ROOT::RVec thereof.; 8##; 9## \macro_code; 10## \macro_output; 11##; 12## \date March 2020; 13## \author Stefan Wunsch; 14 ; 15import ROOT; 16 ; 17# To mark a Python callable to be used from C++, you have to use the decorator; 18# provided by PyROOT passing the C++ types of the input arguments and the return; 19# value.; 20@ROOT.Numba.Declare(['float', 'int'], 'float'); 21def pypow(x, y):; 22 return x**y; 23 ; 24# The Python callable is now available from C++ in the Numba namespace.; 25# For example, we can use it from the interpreter.; 26ROOT.gInterpreter.ProcessLine('cout << ""2^3 = "" << Numba::pypow(2, 3) << endl;'); 27 ; 28# Or we can use the callable as well within a RDataFrame workflow.; 29data = ROOT.RDataFrame(4).Define('x', '(float)rdfentry_')\; 30 .Define('x_pow3', 'Numba::pypow(x, 3)')\; 31 .AsNumpy(); 32 ; 33print('pypow({}, 3) = {}'.format(data['x'], data['x_pow3'])); 34 ; 35# ROOT uses the numba Python package to create C++ functions from python ones.; 36# We support as input and return types of the callable fundamental types and; 37# ROOT::RVec thereof. See the following callable computing the power of the; 38# elements in an array.; 39@ROOT.Numba.Declare(['RVecF', 'int'], 'RVecF'); 40def pypowarray(x, y):; 41 return x**y; 42 ; 43ROOT.gInterpreter.ProcessLine('''; 44ROOT::RVecF x = {0, 1, 2, 3};; 45cout << ""pypowarray("" << x << "", 3) = "" << Numba::pypowarray(x, 3) << endl;; 46'''); 47 ; 48# and now w",MatchSource.WIKI,doc/master/pyroot004__NumbaDeclare_8py_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pyroot004__NumbaDeclare_8py_source.html
https://root.cern/doc/master/pyroot005__tfile__context__manager_8py.html:2871,Availability,alive,alive,2871,"e file; print(""Histogram '{}' is attached to: '{}'.\n"".format(histo_2.GetName(), histo_2.GetDirectory().GetName())); # Before exiting the context, objects can be written to the file; f.WriteObject(histo_2, ""my_histogram""); ; # When the TFile.Close method is called, the current directory is automatically; # set again to ROOT.gROOT. Objects that were attached to the file inside the; # context are automatically deleted and made 'None' when the file is closed.; print(""Status after the first TFile context manager:""); print("" Current directory: '{}'."".format(ROOT.gDirectory.GetName())); print("" Accessing 'histo_2' gives: '{}'.\n"".format(histo_2)); ; # Also reading data from a TFile can be done in a context manager. Information; # stored in the objects of the file can be queried and used inside the context.; # After the context, the objects are not usable anymore because the file is; # automatically closed. This means you should use this pattern as a quick way; # to get information or modify objects from a certain file, without needing to; # keep the histograms alive afterwards.; with TFile.Open(""pyroot005_file_1.root"", ""read"") as f:; # Retrieve histogram using the name given to f.WriteObject in the previous; # with statement; histo_2_fromfile = f[""my_histogram""]; print(""Retrieved '{}' histogram from file '{}'.\n"".format(histo_2_fromfile.GetName(), f.GetName())); ; # Cleanup the file created for this tutorial; os.remove(""pyroot005_file_1.root""); formatOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t Float_t Float_t Int_t Int_t UInt_t UInt_t Rectangle_t Int_t Int_t Window_t TString Int_t GCValues_t GetPrimarySelectionOwner GetDisplay GetScreen GetColormap GetNativeEvent const char const char dpyName wid window const char font_name cursor keysym reg const char only_if_exist regb h Point_t winding char text const char d",MatchSource.WIKI,doc/master/pyroot005__tfile__context__manager_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pyroot005__tfile__context__manager_8py.html
https://root.cern/doc/master/pyroot005__tfile__context__manager_8py.html:2654,Usability,usab,usable,2654,"n file; print(""Current directory: '{}'.\n"".format(ROOT.gDirectory.GetName())); # And the created histogram is automatically attached to the file; print(""Histogram '{}' is attached to: '{}'.\n"".format(histo_2.GetName(), histo_2.GetDirectory().GetName())); # Before exiting the context, objects can be written to the file; f.WriteObject(histo_2, ""my_histogram""); ; # When the TFile.Close method is called, the current directory is automatically; # set again to ROOT.gROOT. Objects that were attached to the file inside the; # context are automatically deleted and made 'None' when the file is closed.; print(""Status after the first TFile context manager:""); print("" Current directory: '{}'."".format(ROOT.gDirectory.GetName())); print("" Accessing 'histo_2' gives: '{}'.\n"".format(histo_2)); ; # Also reading data from a TFile can be done in a context manager. Information; # stored in the objects of the file can be queried and used inside the context.; # After the context, the objects are not usable anymore because the file is; # automatically closed. This means you should use this pattern as a quick way; # to get information or modify objects from a certain file, without needing to; # keep the histograms alive afterwards.; with TFile.Open(""pyroot005_file_1.root"", ""read"") as f:; # Retrieve histogram using the name given to f.WriteObject in the previous; # with statement; histo_2_fromfile = f[""my_histogram""]; print(""Retrieved '{}' histogram from file '{}'.\n"".format(histo_2_fromfile.GetName(), f.GetName())); ; # Cleanup the file created for this tutorial; os.remove(""pyroot005_file_1.root""); formatOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t Float_t Float_t Int_t Int_t UInt_t UInt_t Rectangle_t Int_t Int_t Window_t TString Int_t GCValues_t GetPrimarySelectionOwner GetDisplay GetScreen GetColormap GetNativeEvent const char ",MatchSource.WIKI,doc/master/pyroot005__tfile__context__manager_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pyroot005__tfile__context__manager_8py.html
https://root.cern/doc/master/pyroot006__tcontext__context__manager_8py.html:1427,Availability,avail,available,1427," with how TFile works, so it is suggested to also take a look at the pyroot005 tutorial.; import os; ; import ROOT; from ROOT import TDirectory, TFile; ; # Sometimes it is useful to have multiple open files at once. In such cases,; # the current directory will always be the file that was open last.; file_1 = TFile(""pyroot006_file_1.root"", ""recreate""); file_2 = TFile(""pyroot006_file_2.root"", ""recreate""); print(""Current directory: '{}'.\n"".format(ROOT.gDirectory.GetName())); # Changing directory into another file can be safely done through a TContext; # context manager.; with TDirectory.TContext(file_1):; # Inside the statement, the current directory is file_1; print(""Current directory: '{}'.\n"".format(ROOT.gDirectory.GetName())); histo_1 = ROOT.TH1F(""histo_1"", ""histo_1"", 10, 0, 10); file_1.WriteObject(histo_1, ""my_histogram""); ; # After the context, the current directory is restored back to file_2. Also, the; # two files are kept open. This means that objects read, written or modified; # inside the context are still available afterwards.; print(""Current directory: '{}'.\n"".format(ROOT.gDirectory.GetName())); if file_1.IsOpen() and file_2.IsOpen():; print(""'{}' and '{}' are open.\n"".format(file_1.GetName(), file_2.GetName())); ; # TContext and TFile context managers can also be used in conjunction, allowing; # for safely:; # - Opening a file, creating, modifying, writing and reading objects in it.; # - Closing the file, storing it on disk.; # - Restoring the previous value of gDirectory to the latest file opened before; # this context, rather than to the global ROOT.gROOT; # Remember that the TContext must be initialized before the TFile, otherwise the; # current directory would already be set to the file opened for this context.; with TDirectory.TContext(), TFile(""pyroot006_file_3.root"", ""recreate"") as f:; print(""Current directory: '{}'.\n"".format(ROOT.gDirectory.GetName())); histo_2 = ROOT.TH1F(""histo_2"", ""histo_2"", 10, 0, 10); f.WriteObject(histo_2, ""another_histog",MatchSource.WIKI,doc/master/pyroot006__tcontext__context__manager_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pyroot006__tcontext__context__manager_8py.html
https://root.cern/doc/master/pyroot006__tcontext__context__manager_8py.html:920,Safety,safe,safely,920,". ROOT: tutorials/pyroot/pyroot006_tcontext_context_manager.py File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. Namespaces ; pyroot006_tcontext_context_manager.py File ReferenceTutorials  PyRoot tutorials. Detailed Description; This tutorial demonstrates the usage of the TContext class as a Python context manager. ; This functionality is related with how TFile works, so it is suggested to also take a look at the pyroot005 tutorial.; import os; ; import ROOT; from ROOT import TDirectory, TFile; ; # Sometimes it is useful to have multiple open files at once. In such cases,; # the current directory will always be the file that was open last.; file_1 = TFile(""pyroot006_file_1.root"", ""recreate""); file_2 = TFile(""pyroot006_file_2.root"", ""recreate""); print(""Current directory: '{}'.\n"".format(ROOT.gDirectory.GetName())); # Changing directory into another file can be safely done through a TContext; # context manager.; with TDirectory.TContext(file_1):; # Inside the statement, the current directory is file_1; print(""Current directory: '{}'.\n"".format(ROOT.gDirectory.GetName())); histo_1 = ROOT.TH1F(""histo_1"", ""histo_1"", 10, 0, 10); file_1.WriteObject(histo_1, ""my_histogram""); ; # After the context, the current directory is restored back to file_2. Also, the; # two files are kept open. This means that objects read, written or modified; # inside the context are still available afterwards.; print(""Current directory: '{}'.\n"".format(ROOT.gDirectory.GetName())); if file_1.IsOpen() and file_2.IsOpen():; print(""'{}' and '{}' are open.\n"".format(file_1.GetName(), file_2.GetName())); ; # TContext and TFile context managers can also be used in conjunction, allowing; # for safely:; # - Opening a file, creating, modifying, writing and reading objects in it.; # - Closing the file, storing it on disk.; # - Restoring the previous value of gDirectory to the latest file opened before; # this context, rather than to the global ROOT.gROOT; # Remem",MatchSource.WIKI,doc/master/pyroot006__tcontext__context__manager_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pyroot006__tcontext__context__manager_8py.html
https://root.cern/doc/master/pyroot006__tcontext__context__manager_8py.html:1730,Safety,safe,safely,1730,"6_file_1.root"", ""recreate""); file_2 = TFile(""pyroot006_file_2.root"", ""recreate""); print(""Current directory: '{}'.\n"".format(ROOT.gDirectory.GetName())); # Changing directory into another file can be safely done through a TContext; # context manager.; with TDirectory.TContext(file_1):; # Inside the statement, the current directory is file_1; print(""Current directory: '{}'.\n"".format(ROOT.gDirectory.GetName())); histo_1 = ROOT.TH1F(""histo_1"", ""histo_1"", 10, 0, 10); file_1.WriteObject(histo_1, ""my_histogram""); ; # After the context, the current directory is restored back to file_2. Also, the; # two files are kept open. This means that objects read, written or modified; # inside the context are still available afterwards.; print(""Current directory: '{}'.\n"".format(ROOT.gDirectory.GetName())); if file_1.IsOpen() and file_2.IsOpen():; print(""'{}' and '{}' are open.\n"".format(file_1.GetName(), file_2.GetName())); ; # TContext and TFile context managers can also be used in conjunction, allowing; # for safely:; # - Opening a file, creating, modifying, writing and reading objects in it.; # - Closing the file, storing it on disk.; # - Restoring the previous value of gDirectory to the latest file opened before; # this context, rather than to the global ROOT.gROOT; # Remember that the TContext must be initialized before the TFile, otherwise the; # current directory would already be set to the file opened for this context.; with TDirectory.TContext(), TFile(""pyroot006_file_3.root"", ""recreate"") as f:; print(""Current directory: '{}'.\n"".format(ROOT.gDirectory.GetName())); histo_2 = ROOT.TH1F(""histo_2"", ""histo_2"", 10, 0, 10); f.WriteObject(histo_2, ""another_histogram""); ; print(""Current directory: '{}'.\n"".format(ROOT.gDirectory.GetName())); ; # Cleanup the files created for this tutorial; file_1.Close();; file_2.Close();; for i in range(1, 4):; os.remove(""pyroot006_file_{}.root"".format(i)); formatOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor ",MatchSource.WIKI,doc/master/pyroot006__tcontext__context__manager_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/pyroot006__tcontext__context__manager_8py.html
https://root.cern/doc/master/QuasiRandom_8h_source.html:1436,Deployability,update,update,1436,"; 11 * of the License, or (at your option) any later version. *; 12 * *; 13 * This library is distributed in the hope that it will be useful, *; 14 * but WITHOUT ANY WARRANTY; without even the implied warranty of *; 15 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU *; 16 * General Public License for more details. *; 17 * *; 18 * You should have received a copy of the GNU General Public License *; 19 * along with this library (see file COPYING); if not, write *; 20 * to the Free Software Foundation, Inc., 59 Temple Place, Suite *; 21 * 330, Boston, MA 02111-1307 USA, or contact the author. *; 22 * *; 23 **********************************************************************/; 24 ; 25// Header file for class GSLRandom; 26//; 27// Created by: moneta at Sun Nov 21 16:26:03 2004; 28//; 29// Last update: Sun Nov 21 16:26:03 2004; 30//; 31#ifndef ROOT_Math_QuasiRandom; 32#define ROOT_Math_QuasiRandom; 33 ; 34#include <string>; 35 ; 36/**; 37 @defgroup QuasiRandom QuasiRandom number generators and distributions; 38 Classes for generating QuasiRandom numbers and based on GSL ; 39 @ingroup Random; 40 @ingroup MathMore; 41*/; 42 ; 43 ; 44 ; 45namespace ROOT {; 46namespace Math {; 47 ; 48 ; 49//_____________________________________________________________________________________; 50/**; 51 User class for MathMore random numbers template on the Engine type.; 52 The API of this class followed that of the class ROOT::Math::Random; 53 It must be implemented using as Engine one of the derived classes of; 54 ROOT::Math::GSLQuasiRandomEngine, like ROOT::Math::GSLQrngSobol; 55 ; 56 @ingroup QuasiRandom; 57 ; 58*/; 59template < class Engine>; 60class QuasiRandom {; 61 ; 62public:; 63 ; 64 ; 65 /**; 66 Create a QuasiRandom generator. Use default engine constructor.; 67 Engine will be initialized via Initialize() function in order to; 68 allocate resources; 69 */; 70 QuasiRandom(unsigned int dimension = 1) {; 71 fEngine.Initialize(dimension);; 72 }; 73 ; 74 ; 75 /**; 76",MatchSource.WIKI,doc/master/QuasiRandom_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/QuasiRandom_8h_source.html
https://root.cern/doc/master/QuasiRandom_8h_source.html:2481,Energy Efficiency,allocate,allocate,2481,"ROOT_Math_QuasiRandom; 32#define ROOT_Math_QuasiRandom; 33 ; 34#include <string>; 35 ; 36/**; 37 @defgroup QuasiRandom QuasiRandom number generators and distributions; 38 Classes for generating QuasiRandom numbers and based on GSL ; 39 @ingroup Random; 40 @ingroup MathMore; 41*/; 42 ; 43 ; 44 ; 45namespace ROOT {; 46namespace Math {; 47 ; 48 ; 49//_____________________________________________________________________________________; 50/**; 51 User class for MathMore random numbers template on the Engine type.; 52 The API of this class followed that of the class ROOT::Math::Random; 53 It must be implemented using as Engine one of the derived classes of; 54 ROOT::Math::GSLQuasiRandomEngine, like ROOT::Math::GSLQrngSobol; 55 ; 56 @ingroup QuasiRandom; 57 ; 58*/; 59template < class Engine>; 60class QuasiRandom {; 61 ; 62public:; 63 ; 64 ; 65 /**; 66 Create a QuasiRandom generator. Use default engine constructor.; 67 Engine will be initialized via Initialize() function in order to; 68 allocate resources; 69 */; 70 QuasiRandom(unsigned int dimension = 1) {; 71 fEngine.Initialize(dimension);; 72 }; 73 ; 74 ; 75 /**; 76 Create a QuasiRandom generator based on a provided generic engine.; 77 Engine will be initialized via Initialize() function in order to; 78 allocate resources; 79 */; 80 explicit QuasiRandom(const Engine & e, unsigned int dimension = 1) : fEngine(e) {; 81 fEngine.Initialize(dimension);; 82 }; 83 ; 84 /**; 85 Destructor: call Terminate() function of engine to free any; 86 allocated resource; 87 */; 88 ~QuasiRandom() {; 89 fEngine.Terminate();; 90 }; 91 ; 92 /**; 93 Generate next quasi random numbers points; 94 */; 95 bool Next(double * x) {; 96 return fEngine(x);; 97 }; 98 ; 99 /**; 100 Generate next quasi random numbers point (1 - dimension); 101 */; 102 double Next() {; 103 return fEngine();; 104 }; 105 ; 106 /**; 107 Generate quasi random numbers between ]0,1[; 108 0 and 1 are excluded; 109 Function to be compatible with ROOT TRandom compatibility; 110 */;",MatchSource.WIKI,doc/master/QuasiRandom_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/QuasiRandom_8h_source.html
https://root.cern/doc/master/QuasiRandom_8h_source.html:2756,Energy Efficiency,allocate,allocate,2756," 45namespace ROOT {; 46namespace Math {; 47 ; 48 ; 49//_____________________________________________________________________________________; 50/**; 51 User class for MathMore random numbers template on the Engine type.; 52 The API of this class followed that of the class ROOT::Math::Random; 53 It must be implemented using as Engine one of the derived classes of; 54 ROOT::Math::GSLQuasiRandomEngine, like ROOT::Math::GSLQrngSobol; 55 ; 56 @ingroup QuasiRandom; 57 ; 58*/; 59template < class Engine>; 60class QuasiRandom {; 61 ; 62public:; 63 ; 64 ; 65 /**; 66 Create a QuasiRandom generator. Use default engine constructor.; 67 Engine will be initialized via Initialize() function in order to; 68 allocate resources; 69 */; 70 QuasiRandom(unsigned int dimension = 1) {; 71 fEngine.Initialize(dimension);; 72 }; 73 ; 74 ; 75 /**; 76 Create a QuasiRandom generator based on a provided generic engine.; 77 Engine will be initialized via Initialize() function in order to; 78 allocate resources; 79 */; 80 explicit QuasiRandom(const Engine & e, unsigned int dimension = 1) : fEngine(e) {; 81 fEngine.Initialize(dimension);; 82 }; 83 ; 84 /**; 85 Destructor: call Terminate() function of engine to free any; 86 allocated resource; 87 */; 88 ~QuasiRandom() {; 89 fEngine.Terminate();; 90 }; 91 ; 92 /**; 93 Generate next quasi random numbers points; 94 */; 95 bool Next(double * x) {; 96 return fEngine(x);; 97 }; 98 ; 99 /**; 100 Generate next quasi random numbers point (1 - dimension); 101 */; 102 double Next() {; 103 return fEngine();; 104 }; 105 ; 106 /**; 107 Generate quasi random numbers between ]0,1[; 108 0 and 1 are excluded; 109 Function to be compatible with ROOT TRandom compatibility; 110 */; 111 double Rndm() {; 112 return fEngine();; 113 }; 114 ; 115 /**; 116 skip the next n number and jumb directly to the current state + n; 117 */; 118 bool Skip(unsigned int n) {; 119 return fEngine.Skip(n);; 120 }; 121 /**; 122 Generate an array of random numbers between ]0,1[; 123 Function to ",MatchSource.WIKI,doc/master/QuasiRandom_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/QuasiRandom_8h_source.html
https://root.cern/doc/master/QuasiRandom_8h_source.html:2990,Energy Efficiency,allocate,allocated,2990,"numbers template on the Engine type.; 52 The API of this class followed that of the class ROOT::Math::Random; 53 It must be implemented using as Engine one of the derived classes of; 54 ROOT::Math::GSLQuasiRandomEngine, like ROOT::Math::GSLQrngSobol; 55 ; 56 @ingroup QuasiRandom; 57 ; 58*/; 59template < class Engine>; 60class QuasiRandom {; 61 ; 62public:; 63 ; 64 ; 65 /**; 66 Create a QuasiRandom generator. Use default engine constructor.; 67 Engine will be initialized via Initialize() function in order to; 68 allocate resources; 69 */; 70 QuasiRandom(unsigned int dimension = 1) {; 71 fEngine.Initialize(dimension);; 72 }; 73 ; 74 ; 75 /**; 76 Create a QuasiRandom generator based on a provided generic engine.; 77 Engine will be initialized via Initialize() function in order to; 78 allocate resources; 79 */; 80 explicit QuasiRandom(const Engine & e, unsigned int dimension = 1) : fEngine(e) {; 81 fEngine.Initialize(dimension);; 82 }; 83 ; 84 /**; 85 Destructor: call Terminate() function of engine to free any; 86 allocated resource; 87 */; 88 ~QuasiRandom() {; 89 fEngine.Terminate();; 90 }; 91 ; 92 /**; 93 Generate next quasi random numbers points; 94 */; 95 bool Next(double * x) {; 96 return fEngine(x);; 97 }; 98 ; 99 /**; 100 Generate next quasi random numbers point (1 - dimension); 101 */; 102 double Next() {; 103 return fEngine();; 104 }; 105 ; 106 /**; 107 Generate quasi random numbers between ]0,1[; 108 0 and 1 are excluded; 109 Function to be compatible with ROOT TRandom compatibility; 110 */; 111 double Rndm() {; 112 return fEngine();; 113 }; 114 ; 115 /**; 116 skip the next n number and jumb directly to the current state + n; 117 */; 118 bool Skip(unsigned int n) {; 119 return fEngine.Skip(n);; 120 }; 121 /**; 122 Generate an array of random numbers between ]0,1[; 123 Function to preserve ROOT Trandom compatibility; 124 The array will be filled as x1,y1,z1,....x2,y2,z2,...; 125 */; 126 bool RndmArray(int n, double * array) {; 127 return fEngine.GenerateArray(ar",MatchSource.WIKI,doc/master/QuasiRandom_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/QuasiRandom_8h_source.html
https://root.cern/doc/master/QuasiRandom_8h_source.html:5825,Energy Efficiency,allocate,allocated,5825," ; 177 ; 178typedef QuasiRandom<ROOT::Math::GSLQRngSobol> QuasiRandomSobol;; 179typedef QuasiRandom<ROOT::Math::GSLQRngNiederreiter2> QuasiRandomNiederreiter;; 180 ; 181} // namespace Math; 182} // namespace ROOT; 183 ; 184 ; 185#endif /* ROOT_Math_QuasiRandom */; 186 ; 187 ; 188 ; GSLQuasiRandom.h; e#define e(i)Definition RSha256.hxx:103; ROOT::Math::QuasiRandomUser class for MathMore random numbers template on the Engine type.Definition QuasiRandom.h:60; ROOT::Math::QuasiRandom::QuasiRandomQuasiRandom(unsigned int dimension=1)Create a QuasiRandom generator.Definition QuasiRandom.h:70; ROOT::Math::QuasiRandom::Nextbool Next(double *x)Generate next quasi random numbers points.Definition QuasiRandom.h:95; ROOT::Math::QuasiRandom::fEngineEngine fEngineDefinition QuasiRandom.h:160; ROOT::Math::QuasiRandom::Skipbool Skip(unsigned int n)skip the next n number and jumb directly to the current state + nDefinition QuasiRandom.h:118; ROOT::Math::QuasiRandom::~QuasiRandom~QuasiRandom()Destructor: call Terminate() function of engine to free any allocated resource.Definition QuasiRandom.h:88; ROOT::Math::QuasiRandom::Namestd::string Name() constReturn the name of the generator.Definition QuasiRandom.h:154; ROOT::Math::QuasiRandom::Nextdouble Next()Generate next quasi random numbers point (1 - dimension)Definition QuasiRandom.h:102; ROOT::Math::QuasiRandom::RndmArraybool RndmArray(int n, double *array)Generate an array of random numbers between ]0,1[ Function to preserve ROOT Trandom compatibility The...Definition QuasiRandom.h:126; ROOT::Math::QuasiRandom::Rndmdouble Rndm()Generate quasi random numbers between ]0,1[ 0 and 1 are excluded Function to be compatible with ROOT ...Definition QuasiRandom.h:111; ROOT::Math::QuasiRandom::Typestd::string Type() constReturn the type (name) of the used generator.Definition QuasiRandom.h:133; ROOT::Math::QuasiRandom::EngineSizeunsigned int EngineSize() constReturn the size of the generator state.Definition QuasiRandom.h:140; ROOT::Math::Quas",MatchSource.WIKI,doc/master/QuasiRandom_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/QuasiRandom_8h_source.html
https://root.cern/doc/master/QuaternionXaxial_8cxx_source.html:718,Deployability,update,update,718,". ROOT: math/genvector/src/QuaternionXaxial.cxx Source File. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. QuaternionXaxial.cxx. Go to the documentation of this file. 1// @(#)root/mathcore:$Id$; 2// Authors: W. Brown, M. Fischler, L. Moneta 2005; 3 ; 4 /**********************************************************************; 5 * *; 6 * Copyright (c) 2005 , LCG ROOT FNAL MathLib Team *; 7 * *; 8 * *; 9 **********************************************************************/; 10 ; 11// Implementation file for quaternion times other non-axial rotations.; 12// Decoupled from main Quaternion implementations.; 13//; 14// Created by: Mark Fischler Tues July 19, 2005; 15//; 16// Last update: $Id$; 17//; 18#include ""Math/GenVector/Quaternion.h""; 19 ; 20namespace ROOT {; 21 ; 22namespace Math {; 23 ; 24 ; 25// Although the same technique would work with axial rotations,; 26// we know that two of the four quaternion components will be zero,; 27// and we exploit that knowledge:; 28 ; 29Quaternion Quaternion::operator * (const RotationX & rx) const {; 30 // combination with a RotationX; 31 Quaternion q(rx);; 32 return Quaternion (; 33 U()*q.U() - I()*q.I(); 34 , I()*q.U() + U()*q.I(); 35 , J()*q.U() + K()*q.I(); 36 , K()*q.U() - J()*q.I(); 37 );; 38}; 39 ; 40Quaternion Quaternion::operator * (const RotationY & ry) const {; 41 // combination with a RotationY; 42 Quaternion q(ry);; 43 return Quaternion (; 44 U()*q.U() - J()*q.J(); 45 , I()*q.U() - K()*q.J(); 46 , J()*q.U() + U()*q.J(); 47 , K()*q.U() + I()*q.J(); 48 );; 49}; 50 ; 51Quaternion Quaternion::operator * (const RotationZ & rz) const {; 52 // combination with a RotationZ; 53 Quaternion q(rz);; 54 return Quaternion (; 55 U()*q.U() - K()*q.K(); 56 , I()*q.U() + J()*q.K(); 57 , J()*q.U() - I()*q.K(); 58 , K()*q.U() + U()*q.K(); 59 );; 60}; 61 ; 62Quaternion; 63operator * ( RotationX const & r, Quaternion const & q ) {; 64 return Quaternion(r) * q; // TODO: improve performance; 65}; 66 ; 67Qua",MatchSource.WIKI,doc/master/QuaternionXaxial_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/QuaternionXaxial_8cxx_source.html
https://root.cern/doc/master/QuaternionXaxial_8cxx_source.html:1973,Performance,perform,performance,1973," 30 // combination with a RotationX; 31 Quaternion q(rx);; 32 return Quaternion (; 33 U()*q.U() - I()*q.I(); 34 , I()*q.U() + U()*q.I(); 35 , J()*q.U() + K()*q.I(); 36 , K()*q.U() - J()*q.I(); 37 );; 38}; 39 ; 40Quaternion Quaternion::operator * (const RotationY & ry) const {; 41 // combination with a RotationY; 42 Quaternion q(ry);; 43 return Quaternion (; 44 U()*q.U() - J()*q.J(); 45 , I()*q.U() - K()*q.J(); 46 , J()*q.U() + U()*q.J(); 47 , K()*q.U() + I()*q.J(); 48 );; 49}; 50 ; 51Quaternion Quaternion::operator * (const RotationZ & rz) const {; 52 // combination with a RotationZ; 53 Quaternion q(rz);; 54 return Quaternion (; 55 U()*q.U() - K()*q.K(); 56 , I()*q.U() + J()*q.K(); 57 , J()*q.U() - I()*q.K(); 58 , K()*q.U() + U()*q.K(); 59 );; 60}; 61 ; 62Quaternion; 63operator * ( RotationX const & r, Quaternion const & q ) {; 64 return Quaternion(r) * q; // TODO: improve performance; 65}; 66 ; 67Quaternion; 68operator * ( RotationY const & r, Quaternion const & q ) {; 69 return Quaternion(r) * q; // TODO: improve performance; 70}; 71 ; 72Quaternion; 73operator * ( RotationZ const & r, Quaternion const & q ) {; 74 return Quaternion(r) * q; // TODO: improve performance; 75}; 76 ; 77 ; 78} //namespace Math; 79} //namespace ROOT; Quaternion.h; rOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t rDefinition TGWin32VirtualXProxy.cxx:168; qfloat * qDefinition THbookFile.cxx:89; ROOT::Math::QuaternionRotation class with the (3D) rotation represented by a unit quaternion (u, i, j, k).Definition Quaternion.h:49; ROOT::Math::Quaternion::QuaternionQuaternion()Default constructor (identity rotation)Definition Quaternion.h:60; ROOT::Math::Quaternion::UScalar U() constAccess to the four quaternion components: U() is the coefficient of the identity Pauli matrix,...Definition Quaternion.h:167; ROOT::Math::Quaternion::operator*",MatchSource.WIKI,doc/master/QuaternionXaxial_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/QuaternionXaxial_8cxx_source.html
https://root.cern/doc/master/QuaternionXaxial_8cxx_source.html:2118,Performance,perform,performance,2118," 30 // combination with a RotationX; 31 Quaternion q(rx);; 32 return Quaternion (; 33 U()*q.U() - I()*q.I(); 34 , I()*q.U() + U()*q.I(); 35 , J()*q.U() + K()*q.I(); 36 , K()*q.U() - J()*q.I(); 37 );; 38}; 39 ; 40Quaternion Quaternion::operator * (const RotationY & ry) const {; 41 // combination with a RotationY; 42 Quaternion q(ry);; 43 return Quaternion (; 44 U()*q.U() - J()*q.J(); 45 , I()*q.U() - K()*q.J(); 46 , J()*q.U() + U()*q.J(); 47 , K()*q.U() + I()*q.J(); 48 );; 49}; 50 ; 51Quaternion Quaternion::operator * (const RotationZ & rz) const {; 52 // combination with a RotationZ; 53 Quaternion q(rz);; 54 return Quaternion (; 55 U()*q.U() - K()*q.K(); 56 , I()*q.U() + J()*q.K(); 57 , J()*q.U() - I()*q.K(); 58 , K()*q.U() + U()*q.K(); 59 );; 60}; 61 ; 62Quaternion; 63operator * ( RotationX const & r, Quaternion const & q ) {; 64 return Quaternion(r) * q; // TODO: improve performance; 65}; 66 ; 67Quaternion; 68operator * ( RotationY const & r, Quaternion const & q ) {; 69 return Quaternion(r) * q; // TODO: improve performance; 70}; 71 ; 72Quaternion; 73operator * ( RotationZ const & r, Quaternion const & q ) {; 74 return Quaternion(r) * q; // TODO: improve performance; 75}; 76 ; 77 ; 78} //namespace Math; 79} //namespace ROOT; Quaternion.h; rOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t rDefinition TGWin32VirtualXProxy.cxx:168; qfloat * qDefinition THbookFile.cxx:89; ROOT::Math::QuaternionRotation class with the (3D) rotation represented by a unit quaternion (u, i, j, k).Definition Quaternion.h:49; ROOT::Math::Quaternion::QuaternionQuaternion()Default constructor (identity rotation)Definition Quaternion.h:60; ROOT::Math::Quaternion::UScalar U() constAccess to the four quaternion components: U() is the coefficient of the identity Pauli matrix,...Definition Quaternion.h:167; ROOT::Math::Quaternion::operator*",MatchSource.WIKI,doc/master/QuaternionXaxial_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/QuaternionXaxial_8cxx_source.html
https://root.cern/doc/master/QuaternionXaxial_8cxx_source.html:2263,Performance,perform,performance,2263," 30 // combination with a RotationX; 31 Quaternion q(rx);; 32 return Quaternion (; 33 U()*q.U() - I()*q.I(); 34 , I()*q.U() + U()*q.I(); 35 , J()*q.U() + K()*q.I(); 36 , K()*q.U() - J()*q.I(); 37 );; 38}; 39 ; 40Quaternion Quaternion::operator * (const RotationY & ry) const {; 41 // combination with a RotationY; 42 Quaternion q(ry);; 43 return Quaternion (; 44 U()*q.U() - J()*q.J(); 45 , I()*q.U() - K()*q.J(); 46 , J()*q.U() + U()*q.J(); 47 , K()*q.U() + I()*q.J(); 48 );; 49}; 50 ; 51Quaternion Quaternion::operator * (const RotationZ & rz) const {; 52 // combination with a RotationZ; 53 Quaternion q(rz);; 54 return Quaternion (; 55 U()*q.U() - K()*q.K(); 56 , I()*q.U() + J()*q.K(); 57 , J()*q.U() - I()*q.K(); 58 , K()*q.U() + U()*q.K(); 59 );; 60}; 61 ; 62Quaternion; 63operator * ( RotationX const & r, Quaternion const & q ) {; 64 return Quaternion(r) * q; // TODO: improve performance; 65}; 66 ; 67Quaternion; 68operator * ( RotationY const & r, Quaternion const & q ) {; 69 return Quaternion(r) * q; // TODO: improve performance; 70}; 71 ; 72Quaternion; 73operator * ( RotationZ const & r, Quaternion const & q ) {; 74 return Quaternion(r) * q; // TODO: improve performance; 75}; 76 ; 77 ; 78} //namespace Math; 79} //namespace ROOT; Quaternion.h; rOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t rDefinition TGWin32VirtualXProxy.cxx:168; qfloat * qDefinition THbookFile.cxx:89; ROOT::Math::QuaternionRotation class with the (3D) rotation represented by a unit quaternion (u, i, j, k).Definition Quaternion.h:49; ROOT::Math::Quaternion::QuaternionQuaternion()Default constructor (identity rotation)Definition Quaternion.h:60; ROOT::Math::Quaternion::UScalar U() constAccess to the four quaternion components: U() is the coefficient of the identity Pauli matrix,...Definition Quaternion.h:167; ROOT::Math::Quaternion::operator*",MatchSource.WIKI,doc/master/QuaternionXaxial_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/QuaternionXaxial_8cxx_source.html
https://root.cern/doc/master/Quaternion_8cxx_source.html:659,Deployability,update,update,659,". ROOT: math/genvector/src/Quaternion.cxx Source File. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. Quaternion.cxx. Go to the documentation of this file. 1// @(#)root/mathcore:$Id$; 2// Authors: W. Brown, M. Fischler, L. Moneta 2005; 3 ; 4 /**********************************************************************; 5 * *; 6 * Copyright (c) 2005 , LCG ROOT FNAL MathLib Team *; 7 * *; 8 * *; 9 **********************************************************************/; 10 ; 11// Implementation file for rotation in 3 dimensions, represented by quaternion; 12//; 13// Created by: Mark Fischler Thurs June 9 2005; 14//; 15// Last update: $Id$; 16//; 17#include ""Math/GenVector/Quaternion.h""; 18 ; 19#include <cmath>; 20 ; 21#include ""Math/GenVector/Cartesian3D.h""; 22#include ""Math/GenVector/DisplacementVector3D.h""; 23 ; 24#include ""Math/GenVector/Rotation3Dfwd.h""; 25#include ""Math/GenVector/AxisAnglefwd.h""; 26#include ""Math/GenVector/EulerAnglesfwd.h""; 27 ; 28namespace ROOT {; 29 ; 30namespace Math {; 31 ; 32// ========== Constructors and Assignment =====================; 33 ; 34void Quaternion::Rectify(); 35{; 36 ; 37 // The vector should be a unit vector, and the first element should be; 38 // non-negative (though negative fU quaternions would work just fine,; 39 // being isomorphic to a quaternion with positive fU).; 40 ; 41 if ( fU < 0 ) {; 42 fU = - fU; fI = - fI; fJ = - fJ; fK = - fK;; 43 }; 44 ; 45 Scalar a = 1.0 / std::sqrt(fU*fU + fI*fI + fJ*fJ + fK*fK);; 46 fU *= a;; 47 fI *= a;; 48 fJ *= a;; 49 fK *= a;; 50 ; 51} // Rectify(); 52 ; 53 ; 54// ========== Operations =====================; 55 ; 56// DisplacementVector3D< Cartesian3D<double> >; 57// Quaternion::operator() (const DisplacementVector3D< Cartesian3D<double> > & v) const; 58// {; 59// // apply to a 3D Vector; 60// }; 61 ; 62// Quaternion Quaternion::operator * (const Quaternion & q) const {; 63// // combination of rotations; 64// return Quaternion (; 65// fU*q.fU - fI*q.fI - fJ*q.",MatchSource.WIKI,doc/master/Quaternion_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Quaternion_8cxx_source.html
https://root.cern/doc/master/RadioNuclides_8C.html:2836,Integrability,depend,depending,2836,"d an element to the mixture using fraction by weight Check if the element is already definedDefinition TGeoMaterial.cxx:869; Once defined, one can retrieve the time evolution for the radioactive materials/mixtures by using one of the 2 methods:; void TGeoMaterial::FillMaterialEvolution(TObjArray *population,; Double_t precision=0.001); TGeoMaterial::FillMaterialEvolutionvirtual void FillMaterialEvolution(TObjArray *population, Double_t precision=0.001)Fills a user array with all the elements deriving from the possible decay of the top element composin...Definition TGeoMaterial.cxx:742; TObjArrayAn array of TObjects.Definition TObjArray.h:31; To use this method, one has to provide an empty TObjArray object that will be filled with all elements coming from the decay chain of the initial radionuclides contained by the material/mixture. The precision represent the cumulative branching ratio for which decay products are still considered. The POPULATION list may contain stable elements as well as radionuclides, depending on the initial elements. To test if an element is a radionuclide:; Bool_t TGeoElement::IsRadioNuclide() const; Bool_tbool Bool_tDefinition RtypesCore.h:63; TGeoElement::IsRadioNuclidevirtual Bool_t IsRadioNuclide() constDefinition TGeoElement.h:82; All radionuclides in the output population list have attached objects that represent the time evolution of their fraction of nuclei with respect to the top radionuclide in the decay chain. These objects (Bateman solutions) can be retrieved and drawn:; TGeoBatemanSol *TGeoElementRN::Ratio();; void TGeoBatemanSol::Draw();; TGeoBatemanSolDefinition TGeoElement.h:286; TGeoBatemanSol::Drawvoid Draw(Option_t *option="""") overrideDraw the solution of Bateman equation versus time.Definition TGeoElement.cxx:1612; TGeoElementRN::RatioTGeoBatemanSol * Ratio() constDefinition TGeoElement.h:188; Another method allows to create the evolution of a given radioactive material/mixture at a given moment in time:; TGeoMaterial::Deca",MatchSource.WIKI,doc/master/RadioNuclides_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RadioNuclides_8C.html
https://root.cern/doc/master/RadioNuclides_8C.html:499,Performance,load,loaded,499,". ROOT: tutorials/geom/RadioNuclides.C File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. RadioNuclides.C File ReferenceTutorials  Geometry tutorials. Detailed Description; Macro that demonstrates usage of radioactive elements/materials/mixtures with TGeo package. ; A radionuclide (TGeoElementRN) derives from the class TGeoElement and provides additional information related to its radioactive properties and decay modes.; The radionuclides table is loaded on demand by any call:; TGeoElementRN *TGeoElementTable::GetElementRN(Int_t atomic_number,; Int_t atomic_charge,; Int_t isomeric_number); Int_tint Int_tDefinition RtypesCore.h:45; TGeoElementRNClass representing a radionuclidevoid TGeoManager::SetDefaultRootUnits() { if ( fgDefaultUnits == kRo...Definition TGeoElement.h:132; TGeoElementTable::GetElementRNTGeoElementRN * GetElementRN(Int_t ENDFcode) constRetrieve a radionuclide by ENDF code.Definition TGeoElement.cxx:1368; The isomeric number is optional and the default value is 0.; To create a radioactive material based on a radionuclide, one should use the constructor:; TGeoMaterial(const char *name, TGeoElement *elem, Double_t density); Double_tdouble Double_tDefinition RtypesCore.h:59; namechar name[80]Definition TGX11.cxx:110; TGeoElementBase class for chemical elements.Definition TGeoElement.h:36; TGeoMaterialBase class describing materials.Definition TGeoMaterial.h:34; To create a radioactive mixture, one can use radionuclides as well as stable elements:; TGeoMixture(const char *name, Int_t nelements, Double_t density);; TGeoMixture::AddElement(TGeoElement *elem, Double_t weight_fraction);; TGeoMixtureMixtures of elements.Definition TGeoMaterial.h:159; TGeoMixture::AddElementvoid AddElement(Double_t a, Double_t z, Double_t weight)add an element to the mixture using fraction by weight Check if the element is already definedDefinition TGeoMaterial.cxx:869; Once defined, one can retrieve the time evolution for the rad",MatchSource.WIKI,doc/master/RadioNuclides_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RadioNuclides_8C.html
https://root.cern/doc/master/RadioNuclides_8C.html:2874,Testability,test,test,2874,"x:869; Once defined, one can retrieve the time evolution for the radioactive materials/mixtures by using one of the 2 methods:; void TGeoMaterial::FillMaterialEvolution(TObjArray *population,; Double_t precision=0.001); TGeoMaterial::FillMaterialEvolutionvirtual void FillMaterialEvolution(TObjArray *population, Double_t precision=0.001)Fills a user array with all the elements deriving from the possible decay of the top element composin...Definition TGeoMaterial.cxx:742; TObjArrayAn array of TObjects.Definition TObjArray.h:31; To use this method, one has to provide an empty TObjArray object that will be filled with all elements coming from the decay chain of the initial radionuclides contained by the material/mixture. The precision represent the cumulative branching ratio for which decay products are still considered. The POPULATION list may contain stable elements as well as radionuclides, depending on the initial elements. To test if an element is a radionuclide:; Bool_t TGeoElement::IsRadioNuclide() const; Bool_tbool Bool_tDefinition RtypesCore.h:63; TGeoElement::IsRadioNuclidevirtual Bool_t IsRadioNuclide() constDefinition TGeoElement.h:82; All radionuclides in the output population list have attached objects that represent the time evolution of their fraction of nuclei with respect to the top radionuclide in the decay chain. These objects (Bateman solutions) can be retrieved and drawn:; TGeoBatemanSol *TGeoElementRN::Ratio();; void TGeoBatemanSol::Draw();; TGeoBatemanSolDefinition TGeoElement.h:286; TGeoBatemanSol::Drawvoid Draw(Option_t *option="""") overrideDraw the solution of Bateman equation versus time.Definition TGeoElement.cxx:1612; TGeoElementRN::RatioTGeoBatemanSol * Ratio() constDefinition TGeoElement.h:188; Another method allows to create the evolution of a given radioactive material/mixture at a given moment in time:; TGeoMaterial::DecayMaterial(Double_t time, Double_t precision=0.001); TGeoMaterial::DecayMaterialvirtual TGeoMaterial * DecayMaterial(D",MatchSource.WIKI,doc/master/RadioNuclides_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RadioNuclides_8C.html
https://root.cern/doc/master/RadioNuclides_8C.html:4377,Testability,log,logx,4377," versus time.Definition TGeoElement.cxx:1612; TGeoElementRN::RatioTGeoBatemanSol * Ratio() constDefinition TGeoElement.h:188; Another method allows to create the evolution of a given radioactive material/mixture at a given moment in time:; TGeoMaterial::DecayMaterial(Double_t time, Double_t precision=0.001); TGeoMaterial::DecayMaterialvirtual TGeoMaterial * DecayMaterial(Double_t time, Double_t precision=0.001)Create the material representing the decay product of this material at a given time.Definition TGeoMaterial.cxx:671; The method will create the mixture that result from the decay of a initial material/mixture at TIME, while all resulting elements having a fractional weight less than PRECISION are excluded. ; void DrawPopulation(TObjArray *vect, TCanvas *can, Double_t tmin=0.,; Double_t tmax=0., Bool_t logx=kFALSE);; ; void RadioNuclides(); {; TGeoManager *geom = new TGeoManager("""","""");; TGeoElementTable *table = gGeoManager->GetElementTable();; TGeoElementRN *c14 = table->GetElementRN(14,6);; TGeoElementRN *el1 = table->GetElementRN(53,20);; TGeoElementRN *el2 = table->GetElementRN(78,38);; // Radioactive material; TGeoMaterial *mat = new TGeoMaterial(""C14"", c14, 1.3);; printf(""___________________________________________________________\n"");; printf(""Radioactive material:\n"");; mat->Print();; Double_t time = 1.5e11; // seconds; TGeoMaterial *decaymat = mat->DecayMaterial(time);; printf(""Radioactive material evolution after %g years:\n"", time/3.1536e7);; decaymat->Print();; //Radioactive mixture; TGeoMixture *mix = new TGeoMixture(""mix"", 2, 7.3);; mix->AddElement(el1, 0.35);; mix->AddElement(el2, 0.65);; printf(""___________________________________________________________\n"");; printf(""Radioactive mixture:\n"");; mix->Print();; time = 1000.;; decaymat = mix->DecayMaterial(time);; printf(""Radioactive mixture evolution after %g seconds:\n"", time);; decaymat->Print();; TObjArray *vect = new TObjArray();; TCanvas *c1 = new TCanvas(""c1"",""C14 decay"", 800,600);; c1->Set",MatchSource.WIKI,doc/master/RadioNuclides_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RadioNuclides_8C.html
https://root.cern/doc/master/RadioNuclides_8C.html:10304,Testability,log,logx,10304,"tFillStyle(1001);; arrow->SetLineWidth(2);; arrow->SetAngle(30);; arrow->Draw();; arrow = new TArrow(0.653714,0.074215,2.41863,0.0213142,0.02,"">"");; arrow->SetFillColor(1);; arrow->SetFillStyle(1001);; arrow->SetLineWidth(2);; arrow->SetAngle(30);; arrow->Draw();; arrow = new TArrow(5.58256,0.00953882,10.6235,0.00629343,0.02,"">"");; arrow->SetFillColor(1);; arrow->SetFillStyle(1001);; arrow->SetLineWidth(2);; arrow->SetAngle(30);; arrow->Draw();; arrow = new TArrow(22.0271,0.601935,22.9926,0.218812,0.02,"">"");; arrow->SetFillColor(1);; arrow->SetFillStyle(1001);; arrow->SetLineWidth(2);; arrow->SetAngle(30);; arrow->Draw();; arrow = new TArrow(27.2962,0.102084,36.8557,0.045686,0.02,"">"");; arrow->SetFillColor(1);; arrow->SetFillStyle(1001);; arrow->SetLineWidth(2);; arrow->SetAngle(30);; arrow->Draw();; }; ; void DrawPopulation(TObjArray *vect, TCanvas *can, Double_t tmin,; Double_t tmax, Bool_t logx); {; Int_t n = vect->GetEntriesFast();; TGeoElementRN *elem;; TGeoBatemanSol *sol;; can->SetLogy();; ; if (logx) can->SetLogx();; ; ; for (Int_t i=0; i<n; i++) {; TGeoElement *el = (TGeoElement*)vect->At(i);; if (!el->IsRadioNuclide()) continue;; TGeoElementRN *elem = (TGeoElementRN *)el;; TGeoBatemanSol *sol = elem->Ratio();; if (sol) {; sol->SetLineColor(1+(i%9));; sol->SetLineWidth(2);; if (tmax>0.) sol->SetRange(tmin,tmax);; if (i==0) {; sol->Draw();; TF1 *func = (TF1*)can->FindObject(; Form(""conc%s"",sol->GetElement()->GetName()));; if (func) {; if (!strcmp(can->GetName(),""c1"")) func->SetTitle(; ""Concentration of C14 derived elements;time[s];Ni/N0(C14)"");; else func->SetTitle(; ""Concentration of elements derived from mixture Ca53+Sr78;\; time[s];Ni/N0(Ca53)"");; }; }; else sol->Draw(""SAME"");; }; }; }; kFALSEconstexpr Bool_t kFALSEDefinition RtypesCore.h:94; kTRUEconstexpr Bool_t kTRUEDefinition RtypesCore.h:93; gGeoManagerR__EXTERN TGeoManager * gGeoManagerDefinition TGeoManager.h:608; Formchar * Form(const char *fmt,...)Formats a string in a circular formatting buffer.D",MatchSource.WIKI,doc/master/RadioNuclides_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RadioNuclides_8C.html
https://root.cern/doc/master/RadioNuclides_8C.html:10416,Testability,log,logx,10416,"tFillStyle(1001);; arrow->SetLineWidth(2);; arrow->SetAngle(30);; arrow->Draw();; arrow = new TArrow(0.653714,0.074215,2.41863,0.0213142,0.02,"">"");; arrow->SetFillColor(1);; arrow->SetFillStyle(1001);; arrow->SetLineWidth(2);; arrow->SetAngle(30);; arrow->Draw();; arrow = new TArrow(5.58256,0.00953882,10.6235,0.00629343,0.02,"">"");; arrow->SetFillColor(1);; arrow->SetFillStyle(1001);; arrow->SetLineWidth(2);; arrow->SetAngle(30);; arrow->Draw();; arrow = new TArrow(22.0271,0.601935,22.9926,0.218812,0.02,"">"");; arrow->SetFillColor(1);; arrow->SetFillStyle(1001);; arrow->SetLineWidth(2);; arrow->SetAngle(30);; arrow->Draw();; arrow = new TArrow(27.2962,0.102084,36.8557,0.045686,0.02,"">"");; arrow->SetFillColor(1);; arrow->SetFillStyle(1001);; arrow->SetLineWidth(2);; arrow->SetAngle(30);; arrow->Draw();; }; ; void DrawPopulation(TObjArray *vect, TCanvas *can, Double_t tmin,; Double_t tmax, Bool_t logx); {; Int_t n = vect->GetEntriesFast();; TGeoElementRN *elem;; TGeoBatemanSol *sol;; can->SetLogy();; ; if (logx) can->SetLogx();; ; ; for (Int_t i=0; i<n; i++) {; TGeoElement *el = (TGeoElement*)vect->At(i);; if (!el->IsRadioNuclide()) continue;; TGeoElementRN *elem = (TGeoElementRN *)el;; TGeoBatemanSol *sol = elem->Ratio();; if (sol) {; sol->SetLineColor(1+(i%9));; sol->SetLineWidth(2);; if (tmax>0.) sol->SetRange(tmin,tmax);; if (i==0) {; sol->Draw();; TF1 *func = (TF1*)can->FindObject(; Form(""conc%s"",sol->GetElement()->GetName()));; if (func) {; if (!strcmp(can->GetName(),""c1"")) func->SetTitle(; ""Concentration of C14 derived elements;time[s];Ni/N0(C14)"");; else func->SetTitle(; ""Concentration of elements derived from mixture Ca53+Sr78;\; time[s];Ni/N0(Ca53)"");; }; }; else sol->Draw(""SAME"");; }; }; }; kFALSEconstexpr Bool_t kFALSEDefinition RtypesCore.h:94; kTRUEconstexpr Bool_t kTRUEDefinition RtypesCore.h:93; gGeoManagerR__EXTERN TGeoManager * gGeoManagerDefinition TGeoManager.h:608; Formchar * Form(const char *fmt,...)Formats a string in a circular formatting buffer.D",MatchSource.WIKI,doc/master/RadioNuclides_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RadioNuclides_8C.html
https://root.cern/doc/master/RArrowDS_8hxx_source.html:3469,Integrability,interface,interface,3469,"nst char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t Float_t Float_t Int_t Int_t UInt_t UInt_t Rectangle_t Int_t Int_t Window_t TString Int_t GCValues_t GetPrimarySelectionOwner GetDisplay GetScreen GetColormap GetNativeEvent const char const char dpyName wid window const char font_name cursor keysym reg const char only_if_exist regb h Point_t winding char text const char depth char const char Int_t count const char ColorStruct_t color const char Pixmap_t Pixmap_t PictureAttributes_t attr const char char ret_data h unsigned char height h Atom_t Int_t ULong_t ULong_t unsigned char prop_list Atom_t Atom_t Atom_t Time_t typeDefinition TGWin32VirtualXProxy.cxx:249; namechar name[80]Definition TGX11.cxx:110; ROOT::Internal::RDF::TValueGetterHelper class which keeps track for each slot where to get the entry.Definition RArrowDS.cxx:204; ROOT::RDF::RArrowDSRDataFrame data source class to interface with Apache Arrow.Definition RArrowDS.hxx:30; ROOT::RDF::RArrowDS::GetEntryRangesstd::vector< std::pair< ULong64_t, ULong64_t > > GetEntryRanges() finalReturn ranges of entries to distribute to tasks.Definition RArrowDS.cxx:469; ROOT::RDF::RArrowDS::SetNSlotsvoid SetNSlots(unsigned int nSlots) finalInform RDataSource of the number of processing slots (i.e.Definition RArrowDS.cxx:554; ROOT::RDF::RArrowDS::~RArrowDS~RArrowDS()Destructor.Definition RArrowDS.cxx:460; ROOT::RDF::RArrowDS::fNSlotssize_t fNSlotsDefinition RArrowDS.hxx:35; ROOT::RDF::RArrowDS::HasColumnbool HasColumn(std::string_view colName) const finalChecks if the dataset has a certain column.Definition RArrowDS.cxx:493; ROOT::RDF::RArrowDS::InitSlotvoid InitSlot(unsigned int slot, ULong64_t firstEntry) finalConvenience method called at the start of the data processing associated to a slot.Definition RArrowDS.cxx:511; ROOT::RDF::RArrowDS::GetLabelstd::string GetLabel() finalReturn a string represen",MatchSource.WIKI,doc/master/RArrowDS_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RArrowDS_8hxx_source.html
https://root.cern/doc/master/RArrowDS_8hxx_source.html:6229,Integrability,interface,interface,6229,"exDefinition RArrowDS.hxx:37; ROOT::RDF::RArrowDS::GetTypeNamestd::string GetTypeName(std::string_view colName) const finalType of a column as a string, e.g.Definition RArrowDS.cxx:475; ROOT::RDF::RArrowDS::GetColumnReadersImplstd::vector< void * > GetColumnReadersImpl(std::string_view name, const std::type_info &type) finalThis needs to return a pointer to the pointer each value getter will point to.Definition RArrowDS.cxx:570; ROOT::RDF::RArrowDS::fValueGettersstd::vector< std::unique_ptr< ROOT::Internal::RDF::TValueGetter > > fValueGettersDefinition RArrowDS.hxx:38; ROOT::RDF::RArrowDS::SetEntrybool SetEntry(unsigned int slot, ULong64_t entry) finalAdvance the ""cursors"" returned by GetColumnReaders to the selected entry for a particular slot.Definition RArrowDS.cxx:502; ROOT::RDF::RArrowDS::fColumnNamesstd::vector< std::string > fColumnNamesDefinition RArrowDS.hxx:34; ROOT::RDF::RArrowDS::fEntryRangesstd::vector< std::pair< ULong64_t, ULong64_t > > fEntryRangesDefinition RArrowDS.hxx:33; ROOT::RDF::RArrowDS::GetColumnNamesconst std::vector< std::string > & GetColumnNames() const finalReturns a reference to the collection of the dataset's column names.Definition RArrowDS.cxx:464; ROOT::RDF::RDataSourceRDataSource defines an API that RDataFrame can use to read arbitrary data formats.Definition RDataSource.hxx:109; ROOT::RDataFrameROOT's RDataFrame offers a modern, high-level interface for analysis of data stored in TTree ,...Definition RDataFrame.hxx:41; ROOT::RDF::FromArrowRDataFrame FromArrow(std::shared_ptr< arrow::Table > table, std::vector< std::string > const &columnNames)Factory method to create a Apache Arrow RDataFrame.Definition RArrowDS.cxx:606; ROOTtbb::task_arena is an alias of tbb::interface7::task_arena, which doesn't allow to forward declare tb...Definition EExecutionPolicy.hxx:4; arrowDefinition RArrowDS.hxx:17. treedataframeincROOTRArrowDS.hxx. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:02 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/RArrowDS_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RArrowDS_8hxx_source.html
https://root.cern/doc/master/ratioplot1_8C.html:235,Usability,simpl,simple,235,". ROOT: tutorials/hist/ratioplot1.C File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. ratioplot1.C File ReferenceTutorials  Histograms tutorials. Detailed Description; Example creating a simple ratio plot of two histograms using the pois division option. ; Two histograms are set up and filled with random numbers. The constructor of TRatioPlot takes the two histograms, name and title for the object, drawing options for the histograms (hist and E in this case) and a drawing option for the output graph. The histograms drawing options can be changed with SetH1DrawOpt and SetH2DrawOpt. ; void ratioplot1() {; gStyle->SetOptStat(0);; auto C = new TCanvas(""C"", ""A ratio example"");; auto h1 = new TH1D(""h1"", ""TRatioPlot Example; x; y"", 50, 0, 10);; auto h2 = new TH1D(""h2"", ""h2"", 50, 0, 10);; auto f1 = new TF1(""f1"", ""exp(- x/[0] )"");; f1->SetParameter(0, 3);; h1->FillRandom(""f1"", 1900);; h2->FillRandom(""f1"", 2000);; h1->Sumw2();; h2->Scale(1.9 / 2.);; h2->SetLineColor(kRed);; ; // Create and draw the ratio plot; auto rp = new TRatioPlot(h1, h2);; C->SetTicks(0, 1);; rp->Draw();; rp->GetLowYaxis()->SetNdivisions(505);; ; // Add a legend to the ratio plot; rp->GetUpperPad()->cd();; TLegend *legend = new TLegend(0.3,0.7,0.7,0.85);; legend->AddEntry(""h1"",""First histogram"",""l"");; legend->AddEntry(""h2"",""Second histogram"",""le"");; legend->Draw();; }; kRed@ kRedDefinition Rtypes.h:66; gStyleR__EXTERN TStyle * gStyleDefinition TStyle.h:436; TCanvasThe Canvas class.Definition TCanvas.h:23; TF11-Dim function classDefinition TF1.h:233; TF1::SetParametervirtual void SetParameter(Int_t param, Double_t value)Definition TF1.h:667; TH1D1-D histogram with a double per channel (see TH1 documentation)Definition TH1.h:670; TH1::FillRandomvirtual void FillRandom(const char *fname, Int_t ntimes=5000, TRandom *rng=nullptr)Fill histogram following distribution in function fname.Definition TH1.cxx:3519; TH1::Sumw2virtual void Sumw2(Bool_t flag=kTRUE)Create s",MatchSource.WIKI,doc/master/ratioplot1_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ratioplot1_8C.html
https://root.cern/doc/master/ratioplot1_8py.html:250,Usability,simpl,simple,250,". ROOT: tutorials/hist/ratioplot1.py File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. Namespaces ; ratioplot1.py File ReferenceTutorials  Histograms tutorials. Detailed Description; Example creating a simple ratio plot of two histograms using the pois division option. ; Two histograms are set up and filled with random numbers. The constructor of TRatioPlot takes the to histograms, name and title for the object, drawing options for the histograms (hist and E in this case) and a drawing option for the output graph. Inspired by the tutorial of Paul Gessinger. ; import ROOT; ; ROOT.gStyle.SetOptStat(0); ; c1 = ROOT.TCanvas(""c1"", ""A ratio example""); h1 = ROOT.TH1D(""h1"", ""h1"", 50, 0, 10); h2 = ROOT.TH1D(""h2"", ""h2"", 50, 0, 10); f1 = ROOT.TF1(""f1"", ""exp(- x/[0] )""); f1.SetParameter(0,3); ; h1.FillRandom(""f1"",1900); h2.FillRandom(""f1"", 2000); h1.Sumw2(); h2.Scale(1.9/2.); ; h1.GetXaxis().SetTitle(""x""); h1.GetYaxis().SetTitle(""y""); ; rp = ROOT.TRatioPlot(h1,h2); ; c1.SetTicks(0,1); rp.GetLowYaxis().SetNdivisions(505); c1.Update(); c1.Draw(); rp.Draw(); ; AuthorAlberto Ferro ; Definition in file ratioplot1.py. tutorialshistratioplot1.py. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:29 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/ratioplot1_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ratioplot1_8py.html
https://root.cern/doc/master/ratioplot2_8C.html:717,Usability,simpl,simple,717,". ROOT: tutorials/hist/ratioplot2.C File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. ratioplot2.C File ReferenceTutorials  Histograms tutorials. Detailed Description; Example of a fit residual plot. ; Creates a histogram filled with random numbers from a gaussian distribution and fits it with a standard gaussian function. The result is passed to the TRatioPlot constructor. Additionally, after calling TRatioPlot::Draw the upper and lower y axis titles are modified. Confidence interval bands are automatically drawn on the bottom (but can be disabled by draw option nobands). ; void ratioplot2() {; gStyle->SetOptStat(0);; auto c1 = new TCanvas(""c1"", ""fit residual simple"");; auto h1 = new TH1D(""h1"", ""h1"", 50, -5, 5);; h1->FillRandom(""gaus"", 2000);; h1->Fit(""gaus"", ""0"");; h1->GetXaxis()->SetTitle(""x"");; auto rp1 = new TRatioPlot(h1);; rp1->Draw();; rp1->GetLowerRefYaxis()->SetTitle(""ratio"");; rp1->GetUpperRefYaxis()->SetTitle(""entries"");; }; gStyleR__EXTERN TStyle * gStyleDefinition TStyle.h:436; TCanvasThe Canvas class.Definition TCanvas.h:23; TH1D1-D histogram with a double per channel (see TH1 documentation)Definition TH1.h:670; TH1::GetXaxisTAxis * GetXaxis()Definition TH1.h:324; TH1::FillRandomvirtual void FillRandom(const char *fname, Int_t ntimes=5000, TRandom *rng=nullptr)Fill histogram following distribution in function fname.Definition TH1.cxx:3519; TH1::Fitvirtual TFitResultPtr Fit(const char *formula, Option_t *option="""", Option_t *goption="""", Double_t xmin=0, Double_t xmax=0)Fit histogram with function fname.Definition TH1.cxx:3898; TNamed::SetTitlevirtual void SetTitle(const char *title="""")Set the title of the TNamed.Definition TNamed.cxx:164; TRatioPlotClass for displaying ratios, differences and fit residuals.Definition TRatioPlot.h:43; TStyle::SetOptStatvoid SetOptStat(Int_t stat=1)The type of information printed in the histogram statistics box can be selected via the parameter mod...Definition TStyle.cxx:16",MatchSource.WIKI,doc/master/ratioplot2_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ratioplot2_8C.html
https://root.cern/doc/master/ratioplot2_8py.html:773,Usability,simpl,simple,773,". ROOT: tutorials/hist/ratioplot2.py File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. Namespaces ; ratioplot2.py File ReferenceTutorials  Histograms tutorials. Detailed Description; Example of a fit residual plot. ; Creates a histogram filled with random numbers from a gaussian distribution and fits it with a standard gaussian function. The result is passed to the TRatioPlot constructor. Additionally, after calling TRatioPlot::Draw the upper and lower y axis titles are modified. Confidence interval bands are automatically drawn on the bottom (but can be disabled by draw option nobands). Inspired by the tutorial of Paul Gessinger. . ; import ROOT; ; ROOT.gStyle.SetOptStat(0); ; c1 = ROOT.TCanvas(""c1"", ""fit residual simple""); h1 = ROOT.TH1D(""h1"", ""h1"", 50, -5, 5); ; h1.FillRandom(""gaus"", 2000); h1.Fit(""gaus""); h1.GetXaxis().SetTitle(""x""); ; rp1 = ROOT.TRatioPlot(h1); rp1.Draw(); rp1.GetLowerRefYaxis().SetTitle(""ratio""); rp1.GetUpperRefYaxis().SetTitle(""entries""); ; c1.Update(); ; AuthorAlberto Ferro ; Definition in file ratioplot2.py. tutorialshistratioplot2.py. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:29 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/ratioplot2_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ratioplot2_8py.html
https://root.cern/doc/master/ratioplot3_8C.html:514,Usability,simpl,simple,514,". ROOT: tutorials/hist/ratioplot3.C File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. ratioplot3.C File ReferenceTutorials  Histograms tutorials. Detailed Description; Example which shows how you can get the graph of the lower plot and set the y axis range for it. ; Since the lower plot is not created until TRatioPlot::Draw is called, you can only use the method afterwards. ; void ratioplot3() {; gStyle->SetOptStat(0);; auto c1 = new TCanvas(""c1"", ""fit residual simple"");; c1->SetLogy();; auto h1 = new TH1D(""h1"", ""h1"", 50, -5, 5);; h1->FillRandom(""gaus"", 2000);; h1->Fit(""gaus"", ""0"");; h1->SetMinimum(0.001);; h1->GetXaxis()->SetTitle(""x"");; h1->GetYaxis()->SetTitle(""y"");; auto rp1 = new TRatioPlot(h1);; rp1->Draw();; rp1->GetLowerRefGraph()->SetMinimum(-2);; rp1->GetLowerRefGraph()->SetMaximum(2);; }; gStyleR__EXTERN TStyle * gStyleDefinition TStyle.h:436; TCanvasThe Canvas class.Definition TCanvas.h:23; TH1D1-D histogram with a double per channel (see TH1 documentation)Definition TH1.h:670; TH1::GetXaxisTAxis * GetXaxis()Definition TH1.h:324; TH1::FillRandomvirtual void FillRandom(const char *fname, Int_t ntimes=5000, TRandom *rng=nullptr)Fill histogram following distribution in function fname.Definition TH1.cxx:3519; TH1::Fitvirtual TFitResultPtr Fit(const char *formula, Option_t *option="""", Option_t *goption="""", Double_t xmin=0, Double_t xmax=0)Fit histogram with function fname.Definition TH1.cxx:3898; TH1::GetYaxisTAxis * GetYaxis()Definition TH1.h:325; TH1::SetMinimumvirtual void SetMinimum(Double_t minimum=-1111)Definition TH1.h:405; TNamed::SetTitlevirtual void SetTitle(const char *title="""")Set the title of the TNamed.Definition TNamed.cxx:164; TRatioPlotClass for displaying ratios, differences and fit residuals.Definition TRatioPlot.h:43; TStyle::SetOptStatvoid SetOptStat(Int_t stat=1)The type of information printed in the histogram statistics box can be selected via the parameter mod...Definition TStyle.cxx:1640;",MatchSource.WIKI,doc/master/ratioplot3_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ratioplot3_8C.html
https://root.cern/doc/master/ratioplot3_8py.html:566,Usability,simpl,simple,566,". ROOT: tutorials/hist/ratioplot3.py File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. Namespaces ; ratioplot3.py File ReferenceTutorials  Histograms tutorials. Detailed Description; Example which shows how you can get the graph of the lower plot and set the y axis range for it. ; Since the lower plot is not created until TRatioPlot::Draw is called, you can only use the method afterwards. Inspired by the tutorial of Paul Gessinger. ; import ROOT; ; ROOT.gStyle.SetOptStat(0); c1 = ROOT.TCanvas(""c1"", ""fit residual simple""); c1.SetLogy(); ; h1 = ROOT.TH1D(""h1"", ""h1"", 50, -5, 5); h1.FillRandom(""gaus"", 2000); h1.Fit(""gaus""); h1.SetMinimum(0.001); h1.GetXaxis().SetTitle(""x""); h1.GetYaxis().SetTitle(""y""); ; rp1 = ROOT.TRatioPlot(h1); rp1.Draw(); rp1.GetLowerRefGraph().SetMinimum(-2); rp1.GetLowerRefGraph().SetMaximum(2); ; c1.Update(); AuthorAlberto Ferro ; Definition in file ratioplot3.py. tutorialshistratioplot3.py. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:29 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/ratioplot3_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ratioplot3_8py.html
https://root.cern/doc/master/ratioplot4_8C.html:523,Usability,simpl,simple,523,". ROOT: tutorials/hist/ratioplot4.C File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. ratioplot4.C File ReferenceTutorials  Histograms tutorials. Detailed Description; Example that shows custom dashed lines on the lower plot, specified by a vector of floats. ; By default, dashed lines are drawn at certain points. You can either disable them, or specify where you want them to appear. ; void ratioplot4() {; gStyle->SetOptStat(0);; auto c1 = new TCanvas(""c1"", ""fit residual simple"");; auto h1 = new TH1D(""h1"", ""h1"", 50, -5, 5);; h1->FillRandom(""gaus"", 2000);; h1->Fit(""gaus"", ""0"");; h1->GetXaxis()->SetTitle(""x"");; h1->GetYaxis()->SetTitle(""y"");; auto rp1 = new TRatioPlot(h1);; std::vector<double> lines = {-3, -2, -1, 0, 1, 2, 3};; rp1->SetGridlines(lines);; rp1->Draw();; rp1->GetLowerRefGraph()->SetMinimum(-4);; rp1->GetLowerRefGraph()->SetMaximum(4);; }; gStyleR__EXTERN TStyle * gStyleDefinition TStyle.h:436; TCanvasThe Canvas class.Definition TCanvas.h:23; TH1D1-D histogram with a double per channel (see TH1 documentation)Definition TH1.h:670; TH1::GetXaxisTAxis * GetXaxis()Definition TH1.h:324; TH1::FillRandomvirtual void FillRandom(const char *fname, Int_t ntimes=5000, TRandom *rng=nullptr)Fill histogram following distribution in function fname.Definition TH1.cxx:3519; TH1::Fitvirtual TFitResultPtr Fit(const char *formula, Option_t *option="""", Option_t *goption="""", Double_t xmin=0, Double_t xmax=0)Fit histogram with function fname.Definition TH1.cxx:3898; TH1::GetYaxisTAxis * GetYaxis()Definition TH1.h:325; TNamed::SetTitlevirtual void SetTitle(const char *title="""")Set the title of the TNamed.Definition TNamed.cxx:164; TRatioPlotClass for displaying ratios, differences and fit residuals.Definition TRatioPlot.h:43; TStyle::SetOptStatvoid SetOptStat(Int_t stat=1)The type of information printed in the histogram statistics box can be selected via the parameter mod...Definition TStyle.cxx:1640; c1return c1Definition legend1.C:",MatchSource.WIKI,doc/master/ratioplot4_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ratioplot4_8C.html
https://root.cern/doc/master/ratioplot4_8py.html:577,Usability,simpl,simple,577,". ROOT: tutorials/hist/ratioplot4.py File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. Namespaces ; ratioplot4.py File ReferenceTutorials  Histograms tutorials. Detailed Description; Example that shows custom dashed lines on the lower plot, specified by a vector of floats. ; By default, dashed lines are drawn at certain points. You can either disable them, or specify where you want them to appear. Inspired by the tutorial of Paul Gessinger. ; import ROOT; ; ROOT.gStyle.SetOptStat(0); ; c1 = ROOT.TCanvas(""c1"", ""fit residual simple""); h1 = ROOT.TH1D(""h1"", ""h1"", 50, -5, 5); h1.FillRandom(""gaus"", 2000); h1.Fit(""gaus""); h1.GetXaxis().SetTitle(""x""); h1.GetYaxis().SetTitle(""y""); ; rp1 = ROOT.TRatioPlot(h1); ; lines = ROOT.std.vector('double')(); for i in range(-3,4):lines.push_back(i); rp1.SetGridlines(lines); ; rp1.Draw(); rp1.GetLowerRefGraph().SetMinimum(-4); rp1.GetLowerRefGraph().SetMaximum(4); ; c1.Update(); AuthorAlberto Ferro ; Definition in file ratioplot4.py. tutorialshistratioplot4.py. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:29 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/ratioplot4_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ratioplot4_8py.html
https://root.cern/doc/master/ratioplot5_8C.html:447,Usability,simpl,simple,447,". ROOT: tutorials/hist/ratioplot5.C File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. ratioplot5.C File ReferenceTutorials  Histograms tutorials. Detailed Description; Example that shows how you can set the colors of the confidence interval bands by using the method TRatioPlot::SetConfidenceIntervalColors. . ; void ratioplot5() {; gStyle->SetOptStat(0);; auto c1 = new TCanvas(""c1"", ""fit residual simple"");; auto h1 = new TH1D(""h1"", ""h1"", 50, -5, 5);; h1->FillRandom(""gaus"", 2000);; h1->Fit(""gaus"",""0"");; h1->GetXaxis()->SetTitle(""x"");; h1->GetYaxis()->SetTitle(""y"");; auto rp1 = new TRatioPlot(h1);; rp1->SetConfidenceIntervalColors(kBlue, kRed);; rp1->Draw();; }; kRed@ kRedDefinition Rtypes.h:66; kBlue@ kBlueDefinition Rtypes.h:66; gStyleR__EXTERN TStyle * gStyleDefinition TStyle.h:436; TCanvasThe Canvas class.Definition TCanvas.h:23; TH1D1-D histogram with a double per channel (see TH1 documentation)Definition TH1.h:670; TH1::GetXaxisTAxis * GetXaxis()Definition TH1.h:324; TH1::FillRandomvirtual void FillRandom(const char *fname, Int_t ntimes=5000, TRandom *rng=nullptr)Fill histogram following distribution in function fname.Definition TH1.cxx:3519; TH1::Fitvirtual TFitResultPtr Fit(const char *formula, Option_t *option="""", Option_t *goption="""", Double_t xmin=0, Double_t xmax=0)Fit histogram with function fname.Definition TH1.cxx:3898; TH1::GetYaxisTAxis * GetYaxis()Definition TH1.h:325; TNamed::SetTitlevirtual void SetTitle(const char *title="""")Set the title of the TNamed.Definition TNamed.cxx:164; TRatioPlotClass for displaying ratios, differences and fit residuals.Definition TRatioPlot.h:43; TStyle::SetOptStatvoid SetOptStat(Int_t stat=1)The type of information printed in the histogram statistics box can be selected via the parameter mod...Definition TStyle.cxx:1640; c1return c1Definition legend1.C:41; h1TH1F * h1Definition legend1.C:5; ratioplot5Definition ratioplot5.py:1; AuthorPaul Gessinger ; Definition in file ratio",MatchSource.WIKI,doc/master/ratioplot5_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ratioplot5_8C.html
https://root.cern/doc/master/ratioplot5_8py.html:501,Usability,simpl,simple,501,". ROOT: tutorials/hist/ratioplot5.py File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. Namespaces ; ratioplot5.py File ReferenceTutorials  Histograms tutorials. Detailed Description; Example that shows how you can set the colors of the confidence interval bands by using the method TRatioPlot::SetConfidenceIntervalColors. ; Inspired by the tutorial of Paul Gessinger. ; import ROOT; ; ROOT.gStyle.SetOptStat(0); ; c1 = ROOT.TCanvas(""c1"", ""fit residual simple""); h1 = ROOT.TH1D(""h1"", ""h1"", 50, -5, 5); h1.FillRandom(""gaus"", 2000); h1.Fit(""gaus""); h1.GetXaxis().SetTitle(""x""); h1.GetYaxis().SetTitle(""y""); ; rp1 = ROOT.TRatioPlot(h1); rp1.SetConfidenceIntervalColors(ROOT.kBlue, ROOT.kRed); rp1.Draw(); c1.Update(); AuthorAlberto Ferro ; Definition in file ratioplot5.py. tutorialshistratioplot5.py. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:29 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/ratioplot5_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ratioplot5_8py.html
https://root.cern/doc/master/ratioplot6_8C.html:458,Usability,simpl,simple,458,". ROOT: tutorials/hist/ratioplot6.C File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. ratioplot6.C File ReferenceTutorials  Histograms tutorials. Detailed Description; Example showing a fit residual plot, where the separation margin has been set to 0. ; The last label of the lower plot's y axis is hidden automatically. ; void ratioplot6() {; gStyle->SetOptStat(0);; auto c1 = new TCanvas(""c1"", ""fit residual simple"");; gPad->SetFrameFillStyle(0);; auto h1 = new TH1D(""h1"", ""h1"", 50, -5, 5);; h1->FillRandom(""gaus"", 5000);; TFitResultPtr fitres = h1->Fit(""gaus"", ""S0"");; h1->Sumw2();; h1->GetXaxis()->SetTitle(""x"");; h1->GetYaxis()->SetTitle(""y"");; auto rp1 = new TRatioPlot(h1, ""errfunc"");; rp1->SetGraphDrawOpt(""L"");; rp1->SetSeparationMargin(0.0);; rp1->Draw();; rp1->GetLowerRefGraph()->SetMinimum(-2);; rp1->GetLowerRefGraph()->SetMaximum(2);; }; gStyleR__EXTERN TStyle * gStyleDefinition TStyle.h:436; gPad#define gPadDefinition TVirtualPad.h:308; TCanvasThe Canvas class.Definition TCanvas.h:23; TFitResultPtrProvides an indirection to the TFitResult class and with a semantics identical to a TFitResult pointe...Definition TFitResultPtr.h:32; TH1D1-D histogram with a double per channel (see TH1 documentation)Definition TH1.h:670; TH1::GetXaxisTAxis * GetXaxis()Definition TH1.h:324; TH1::FillRandomvirtual void FillRandom(const char *fname, Int_t ntimes=5000, TRandom *rng=nullptr)Fill histogram following distribution in function fname.Definition TH1.cxx:3519; TH1::Fitvirtual TFitResultPtr Fit(const char *formula, Option_t *option="""", Option_t *goption="""", Double_t xmin=0, Double_t xmax=0)Fit histogram with function fname.Definition TH1.cxx:3898; TH1::GetYaxisTAxis * GetYaxis()Definition TH1.h:325; TH1::Sumw2virtual void Sumw2(Bool_t flag=kTRUE)Create structure to store sum of squares of weights.Definition TH1.cxx:9020; TNamed::SetTitlevirtual void SetTitle(const char *title="""")Set the title of the TNamed.Definition TNamed.cxx:164;",MatchSource.WIKI,doc/master/ratioplot6_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ratioplot6_8C.html
https://root.cern/doc/master/ratioplot6_8py.html:512,Usability,simpl,simple,512,". ROOT: tutorials/hist/ratioplot6.py File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. Namespaces ; ratioplot6.py File ReferenceTutorials  Histograms tutorials. Detailed Description; Example showing a fit residual plot, where the separation margin has been set to 0. ; The last label of the lower plot's y axis is hidden automatically. Inspired by the tutorial of Paul Gessinger. ; import ROOT; ; ROOT.gStyle.SetOptStat(0); ; c1 = ROOT.TCanvas(""c1"", ""fit residual simple""); ROOT.gPad.SetFrameFillStyle(0); ; h1 = ROOT.TH1D(""h1"", ""h1"", 50, -5, 5); h1.FillRandom(""gaus"", 5000); h1.Fit(""gaus"", ""S""); ; h1.Sumw2(); h1.GetXaxis().SetTitle(""x""); h1.GetYaxis().SetTitle(""y""); ; rp1 = ROOT.TRatioPlot(h1, ""errfunc""); rp1.SetGraphDrawOpt(""L""); rp1.SetSeparationMargin(0.0); rp1.Draw(); rp1.GetLowerRefGraph().SetMinimum(-2); rp1.GetLowerRefGraph().SetMaximum(2); ; c1.Update(); AuthorAlberto Ferro ; Definition in file ratioplot6.py. tutorialshistratioplot6.py. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:29 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/ratioplot6_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ratioplot6_8py.html
https://root.cern/doc/master/ratioplotOld_8C.html:1646,Safety,avoid,avoid,1646,"booking time using the convention ""Hist_title ; X_title ; Y_title""; TH1F *h1 = new TH1F(""h1"", ""Two gaussian plots and their ratio;x title; h1 and h2 gaussian histograms"", 100, -5, 5);; TH1F *h2 = new TH1F(""h2"", ""h2"", 100, -5, 5);; h1->FillRandom(""gaus"");; h2->FillRandom(""gaus"");; ; // Define the Canvas; TCanvas *c = new TCanvas(""c"", ""canvas"", 800, 800);; ; // Upper plot will be in pad1; TPad *pad1 = new TPad(""pad1"", ""pad1"", 0, 0.3, 1, 1.0);; pad1->SetBottomMargin(0); // Upper and lower plot are joined; pad1->SetGridx(); // Vertical grid; pad1->Draw(); // Draw the upper pad: pad1; pad1->cd(); // pad1 becomes the current pad; h1->SetStats(0); // No statistics on upper plot; h1->Draw(); // Draw h1; h2->Draw(""same""); // Draw h2 on top of h1; ; #if ROOT_VERSION_CODE >= ROOT_VERSION(6,8,0); // Avoid the first label (0) to be clipped.; TAxis *axis = h1->GetYaxis();; axis->ChangeLabel(1, -1, -1, -1, -1, -1, "" "");; axis->SetLabelFont(43); // Absolute font size in pixel (precision 3); axis->SetLabelSize(15);; #else; // Do not draw the Y axis label on the upper plot and redraw a small; // axis instead, in order to avoid the first label (0) to be clipped.; h1->GetYaxis()->SetLabelSize(0.);; TGaxis *axis = new TGaxis( -5, 20, -5, 220, 20,220,510,"""");; axis->SetLabelFont(43); // Absolute font size in pixel (precision 3); axis->SetLabelSize(15);; axis->Draw();; #endif; ; // lower plot will be in pad; c->cd(); // Go back to the main canvas before defining pad2; TPad *pad2 = new TPad(""pad2"", ""pad2"", 0, 0.05, 1, 0.3);; pad2->SetTopMargin(0);; pad2->SetBottomMargin(0.2);; pad2->SetGridx(); // vertical grid; pad2->Draw();; pad2->cd(); // pad2 becomes the current pad; ; // Define the ratio plot; TH1F *h3 = (TH1F*)h1->Clone(""h3"");; h3->SetLineColor(kBlack);; h3->SetMinimum(0.8); // Define Y ..; h3->SetMaximum(1.35); // .. range; h3->Sumw2();; h3->SetStats(0); // No statistics on lower plot; h3->Divide(h2);; h3->SetMarkerStyle(21);; h3->Draw(""ep""); // Draw the ratio plot; ; // h1 settings",MatchSource.WIKI,doc/master/ratioplotOld_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ratioplotOld_8C.html
https://root.cern/doc/master/ratioplot_8py.html:1126,Availability,error,errors,1126,"hing...; No Matches. Namespaces ; ratioplot.py File ReferenceTutorials  PyRoot tutorials. Detailed Description; Display two histograms and their ratio. ; This program illustrates how to plot two histograms and their ratio on the same canvas. Original macro by Olivier Couet.; ; from ROOT import TCanvas, TColor, TGaxis, TH1F, TPad; from ROOT import kBlack, kBlue, kRed; ; ; def createH1():; h1 = TH1F(""h1"", (""Two gaussian plots and their ratio; x title; h1 and h2""; "" histograms""), 100, -5, 5); h1.SetLineColor(kBlue+1); h1.SetLineWidth(2); h1.FillRandom(""gaus""); h1.GetYaxis().SetTitleSize(20); h1.GetYaxis().SetTitleFont(43); h1.GetYaxis().SetTitleOffset(1.55); h1.SetStats(0); return h1; ; ; def createH2():; h2 = TH1F(""h2"", ""h2"", 100, -5, 5); h2.FillRandom(""gaus""); h2.SetLineColor(kRed); h2.SetLineWidth(2); return h2; ; ; def createRatio(h1, h2):; h3 = h1.Clone(""h3""); h3.SetLineColor(kBlack); h3.SetMarkerStyle(21); h3.SetTitle(""""); h3.SetMinimum(0.8); h3.SetMaximum(1.35); # Set up plot for markers and errors; h3.Sumw2(); h3.SetStats(0); h3.Divide(h2); ; # Adjust y-axis settings; y = h3.GetYaxis(); y.SetTitle(""ratio h1/h2 ""); y.SetNdivisions(505); y.SetTitleSize(20); y.SetTitleFont(43); y.SetTitleOffset(1.55); y.SetLabelFont(43); y.SetLabelSize(15); ; # Adjust x-axis settings; x = h3.GetXaxis(); x.SetTitleSize(20); x.SetTitleFont(43); x.SetTitleOffset(4.0); x.SetLabelFont(43); x.SetLabelSize(15); ; return h3; ; ; def createCanvasPads():; c = TCanvas(""c"", ""canvas"", 800, 800); # Upper histogram plot is pad1; pad1 = TPad(""pad1"", ""pad1"", 0, 0.3, 1, 1.0); pad1.SetBottomMargin(0) # joins upper and lower plot; pad1.SetGridx(); pad1.Draw(); # Lower ratio plot is pad2; c.cd() # returns to main canvas before defining pad2; pad2 = TPad(""pad2"", ""pad2"", 0, 0.05, 1, 0.3); pad2.SetTopMargin(0) # joins upper and lower plot; pad2.SetBottomMargin(0.2); pad2.SetGridx(); pad2.Draw(); ; return c, pad1, pad2; ; ; def ratioplot():; # create required parts; h1 = createH1(); h2 = createH2(); h3 =",MatchSource.WIKI,doc/master/ratioplot_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ratioplot_8py.html
https://root.cern/doc/master/ratioplot_8py.html:2237,Safety,avoid,avoid,2237," h3.SetMaximum(1.35); # Set up plot for markers and errors; h3.Sumw2(); h3.SetStats(0); h3.Divide(h2); ; # Adjust y-axis settings; y = h3.GetYaxis(); y.SetTitle(""ratio h1/h2 ""); y.SetNdivisions(505); y.SetTitleSize(20); y.SetTitleFont(43); y.SetTitleOffset(1.55); y.SetLabelFont(43); y.SetLabelSize(15); ; # Adjust x-axis settings; x = h3.GetXaxis(); x.SetTitleSize(20); x.SetTitleFont(43); x.SetTitleOffset(4.0); x.SetLabelFont(43); x.SetLabelSize(15); ; return h3; ; ; def createCanvasPads():; c = TCanvas(""c"", ""canvas"", 800, 800); # Upper histogram plot is pad1; pad1 = TPad(""pad1"", ""pad1"", 0, 0.3, 1, 1.0); pad1.SetBottomMargin(0) # joins upper and lower plot; pad1.SetGridx(); pad1.Draw(); # Lower ratio plot is pad2; c.cd() # returns to main canvas before defining pad2; pad2 = TPad(""pad2"", ""pad2"", 0, 0.05, 1, 0.3); pad2.SetTopMargin(0) # joins upper and lower plot; pad2.SetBottomMargin(0.2); pad2.SetGridx(); pad2.Draw(); ; return c, pad1, pad2; ; ; def ratioplot():; # create required parts; h1 = createH1(); h2 = createH2(); h3 = createRatio(h1, h2); c, pad1, pad2 = createCanvasPads(); ; # draw everything; pad1.cd(); h1.Draw(); h2.Draw(""same""); # to avoid clipping the bottom zero, redraw a small axis; h1.GetYaxis().SetLabelSize(0.0); axis = TGaxis(-5, 20, -5, 220, 20, 220, 510, """"); axis.SetLabelFont(43); axis.SetLabelSize(15); axis.Draw(); pad2.cd(); h3.Draw(""ep""); ; # To hold window open when running from command line; # text = raw_input(); ; ; if __name__ == ""__main__"":; ratioplot(); TCanvasThe Canvas class.Definition TCanvas.h:23; TGaxisThe axis painter class.Definition TGaxis.h:24; TH1F1-D histogram with a float per channel (see TH1 documentation)Definition TH1.h:622; TPadThe most important graphics class in the ROOT system.Definition TPad.h:28; ratioplotDefinition ratioplot.py:1; AuthorMichael Moran ; Definition in file ratioplot.py. tutorialspyrootratioplot.py. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:30 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/ratioplot_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/ratioplot_8py.html
https://root.cern/doc/master/RBatchGenerator__PyTorch_8py.html:1300,Performance,optimiz,optimizer,1300,"ROOT dataset into a basic PyTorch workflow. ; ; import torch; import ROOT; ; tree_name = ""sig_tree""; file_name = ""http://root.cern/files/Higgs_data.root""; ; batch_size = 128; chunk_size = 5_000; ; target = ""Type""; ; # Returns two generators that return training and validation batches; # as PyTorch tensors.; gen_train, gen_validation = ROOT.TMVA.Experimental.CreatePyTorchGenerators(; tree_name,; file_name,; batch_size,; chunk_size,; target=target,; validation_split=0.3,; ); ; # Get a list of the columns used for training; input_columns = gen_train.train_columns; num_features = len(input_columns); ; ; def calc_accuracy(targets, pred):; return torch.sum(targets == pred.round()) / pred.size(0); ; ; # Initialize PyTorch model; model = torch.nn.Sequential(; torch.nn.Linear(num_features, 300),; torch.nn.Tanh(),; torch.nn.Linear(300, 300),; torch.nn.Tanh(),; torch.nn.Linear(300, 300),; torch.nn.Tanh(),; torch.nn.Linear(300, 1),; torch.nn.Sigmoid(),; ); loss_fn = torch.nn.MSELoss(reduction=""mean""); optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9); ; ; # Loop through the training set and train model; for i, (x_train, y_train) in enumerate(gen_train):; # Make prediction and calculate loss; pred = model(x_train).view(-1); loss = loss_fn(pred, y_train); ; # improve model; model.zero_grad(); loss.backward(); optimizer.step(); ; # Calculate accuracy; accuracy = calc_accuracy(y_train, pred); ; print(f""Training => accuracy: {accuracy}""); ; #################################################################; # Validation; #################################################################; ; # Evaluate the model on the validation set; for i, (x_train, y_train) in enumerate(gen_validation):; # Make prediction and calculate accuracy; pred = model(x_train).view(-1); accuracy = calc_accuracy(y_train, pred); ; print(f""Validation => accuracy: {accuracy}""); lenOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle G",MatchSource.WIKI,doc/master/RBatchGenerator__PyTorch_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RBatchGenerator__PyTorch_8py.html
https://root.cern/doc/master/RBatchGenerator__PyTorch_8py.html:1633,Performance,optimiz,optimizer,1633,"ROOT.TMVA.Experimental.CreatePyTorchGenerators(; tree_name,; file_name,; batch_size,; chunk_size,; target=target,; validation_split=0.3,; ); ; # Get a list of the columns used for training; input_columns = gen_train.train_columns; num_features = len(input_columns); ; ; def calc_accuracy(targets, pred):; return torch.sum(targets == pred.round()) / pred.size(0); ; ; # Initialize PyTorch model; model = torch.nn.Sequential(; torch.nn.Linear(num_features, 300),; torch.nn.Tanh(),; torch.nn.Linear(300, 300),; torch.nn.Tanh(),; torch.nn.Linear(300, 300),; torch.nn.Tanh(),; torch.nn.Linear(300, 1),; torch.nn.Sigmoid(),; ); loss_fn = torch.nn.MSELoss(reduction=""mean""); optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9); ; ; # Loop through the training set and train model; for i, (x_train, y_train) in enumerate(gen_train):; # Make prediction and calculate loss; pred = model(x_train).view(-1); loss = loss_fn(pred, y_train); ; # improve model; model.zero_grad(); loss.backward(); optimizer.step(); ; # Calculate accuracy; accuracy = calc_accuracy(y_train, pred); ; print(f""Training => accuracy: {accuracy}""); ; #################################################################; # Validation; #################################################################; ; # Evaluate the model on the validation set; for i, (x_train, y_train) in enumerate(gen_validation):; # Make prediction and calculate accuracy; pred = model(x_train).view(-1); accuracy = calc_accuracy(y_train, pred); ; print(f""Validation => accuracy: {accuracy}""); lenOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t Float_t Float_t Int_t Int_t UInt_t UInt_t Rectangle_t Int_t Int_t Window_t TString Int_t GCValues_t GetPrimarySelectionOwner GetDisplay GetScreen GetColormap GetNativeEvent const char const char dpyName wid window const char font_name cursor ",MatchSource.WIKI,doc/master/RBatchGenerator__PyTorch_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RBatchGenerator__PyTorch_8py.html
https://root.cern/doc/master/RBatchGenerator__PyTorch_8py.html:1484,Safety,predict,prediction,1484,"batch_size = 128; chunk_size = 5_000; ; target = ""Type""; ; # Returns two generators that return training and validation batches; # as PyTorch tensors.; gen_train, gen_validation = ROOT.TMVA.Experimental.CreatePyTorchGenerators(; tree_name,; file_name,; batch_size,; chunk_size,; target=target,; validation_split=0.3,; ); ; # Get a list of the columns used for training; input_columns = gen_train.train_columns; num_features = len(input_columns); ; ; def calc_accuracy(targets, pred):; return torch.sum(targets == pred.round()) / pred.size(0); ; ; # Initialize PyTorch model; model = torch.nn.Sequential(; torch.nn.Linear(num_features, 300),; torch.nn.Tanh(),; torch.nn.Linear(300, 300),; torch.nn.Tanh(),; torch.nn.Linear(300, 300),; torch.nn.Tanh(),; torch.nn.Linear(300, 1),; torch.nn.Sigmoid(),; ); loss_fn = torch.nn.MSELoss(reduction=""mean""); optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9); ; ; # Loop through the training set and train model; for i, (x_train, y_train) in enumerate(gen_train):; # Make prediction and calculate loss; pred = model(x_train).view(-1); loss = loss_fn(pred, y_train); ; # improve model; model.zero_grad(); loss.backward(); optimizer.step(); ; # Calculate accuracy; accuracy = calc_accuracy(y_train, pred); ; print(f""Training => accuracy: {accuracy}""); ; #################################################################; # Validation; #################################################################; ; # Evaluate the model on the validation set; for i, (x_train, y_train) in enumerate(gen_validation):; # Make prediction and calculate accuracy; pred = model(x_train).view(-1); accuracy = calc_accuracy(y_train, pred); ; print(f""Validation => accuracy: {accuracy}""); lenOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t Float_t Float_t Int_t Int_t UInt_t UInt_t Rectangle_t Int_t Int",MatchSource.WIKI,doc/master/RBatchGenerator__PyTorch_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RBatchGenerator__PyTorch_8py.html
https://root.cern/doc/master/RBatchGenerator__PyTorch_8py.html:2022,Safety,predict,prediction,2022,"; num_features = len(input_columns); ; ; def calc_accuracy(targets, pred):; return torch.sum(targets == pred.round()) / pred.size(0); ; ; # Initialize PyTorch model; model = torch.nn.Sequential(; torch.nn.Linear(num_features, 300),; torch.nn.Tanh(),; torch.nn.Linear(300, 300),; torch.nn.Tanh(),; torch.nn.Linear(300, 300),; torch.nn.Tanh(),; torch.nn.Linear(300, 1),; torch.nn.Sigmoid(),; ); loss_fn = torch.nn.MSELoss(reduction=""mean""); optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9); ; ; # Loop through the training set and train model; for i, (x_train, y_train) in enumerate(gen_train):; # Make prediction and calculate loss; pred = model(x_train).view(-1); loss = loss_fn(pred, y_train); ; # improve model; model.zero_grad(); loss.backward(); optimizer.step(); ; # Calculate accuracy; accuracy = calc_accuracy(y_train, pred); ; print(f""Training => accuracy: {accuracy}""); ; #################################################################; # Validation; #################################################################; ; # Evaluate the model on the validation set; for i, (x_train, y_train) in enumerate(gen_validation):; # Make prediction and calculate accuracy; pred = model(x_train).view(-1); accuracy = calc_accuracy(y_train, pred); ; print(f""Validation => accuracy: {accuracy}""); lenOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t Float_t Float_t Int_t Int_t UInt_t UInt_t Rectangle_t Int_t Int_t Window_t TString Int_t GCValues_t GetPrimarySelectionOwner GetDisplay GetScreen GetColormap GetNativeEvent const char const char dpyName wid window const char font_name cursor keysym reg const char only_if_exist regb h Point_t winding char text const char depth char const char Int_t count const char ColorStruct_t color const char Pixmap_t Pixmap_t PictureAttributes_t attr const char char ret_data h uns",MatchSource.WIKI,doc/master/RBatchGenerator__PyTorch_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RBatchGenerator__PyTorch_8py.html
https://root.cern/doc/master/RBatchGenerator__PyTorch_8py.html:561,Security,validat,validation,561,". ROOT: tutorials/tmva/RBatchGenerator_PyTorch.py File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. Namespaces ; RBatchGenerator_PyTorch.py File ReferenceTutorials  TMVA tutorials. Detailed Description; Example of getting batches of events from a ROOT dataset into a basic PyTorch workflow. ; ; import torch; import ROOT; ; tree_name = ""sig_tree""; file_name = ""http://root.cern/files/Higgs_data.root""; ; batch_size = 128; chunk_size = 5_000; ; target = ""Type""; ; # Returns two generators that return training and validation batches; # as PyTorch tensors.; gen_train, gen_validation = ROOT.TMVA.Experimental.CreatePyTorchGenerators(; tree_name,; file_name,; batch_size,; chunk_size,; target=target,; validation_split=0.3,; ); ; # Get a list of the columns used for training; input_columns = gen_train.train_columns; num_features = len(input_columns); ; ; def calc_accuracy(targets, pred):; return torch.sum(targets == pred.round()) / pred.size(0); ; ; # Initialize PyTorch model; model = torch.nn.Sequential(; torch.nn.Linear(num_features, 300),; torch.nn.Tanh(),; torch.nn.Linear(300, 300),; torch.nn.Tanh(),; torch.nn.Linear(300, 300),; torch.nn.Tanh(),; torch.nn.Linear(300, 1),; torch.nn.Sigmoid(),; ); loss_fn = torch.nn.MSELoss(reduction=""mean""); optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9); ; ; # Loop through the training set and train model; for i, (x_train, y_train) in enumerate(gen_train):; # Make prediction and calculate loss; pred = model(x_train).view(-1); loss = loss_fn(pred, y_train); ; # improve model; model.zero_grad(); loss.backward(); optimizer.step(); ; # Calculate accuracy; accuracy = calc_accuracy(y_train, pred); ; print(f""Training => accuracy: {accuracy}""); ; #################################################################; # Validation; #################################################################; ; # Evaluate the model on the validation set; for i, (x_train, y_train) in enumerate(gen_",MatchSource.WIKI,doc/master/RBatchGenerator__PyTorch_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RBatchGenerator__PyTorch_8py.html
https://root.cern/doc/master/RBatchGenerator__PyTorch_8py.html:1942,Security,validat,validation,1942,"; num_features = len(input_columns); ; ; def calc_accuracy(targets, pred):; return torch.sum(targets == pred.round()) / pred.size(0); ; ; # Initialize PyTorch model; model = torch.nn.Sequential(; torch.nn.Linear(num_features, 300),; torch.nn.Tanh(),; torch.nn.Linear(300, 300),; torch.nn.Tanh(),; torch.nn.Linear(300, 300),; torch.nn.Tanh(),; torch.nn.Linear(300, 1),; torch.nn.Sigmoid(),; ); loss_fn = torch.nn.MSELoss(reduction=""mean""); optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9); ; ; # Loop through the training set and train model; for i, (x_train, y_train) in enumerate(gen_train):; # Make prediction and calculate loss; pred = model(x_train).view(-1); loss = loss_fn(pred, y_train); ; # improve model; model.zero_grad(); loss.backward(); optimizer.step(); ; # Calculate accuracy; accuracy = calc_accuracy(y_train, pred); ; print(f""Training => accuracy: {accuracy}""); ; #################################################################; # Validation; #################################################################; ; # Evaluate the model on the validation set; for i, (x_train, y_train) in enumerate(gen_validation):; # Make prediction and calculate accuracy; pred = model(x_train).view(-1); accuracy = calc_accuracy(y_train, pred); ; print(f""Validation => accuracy: {accuracy}""); lenOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t Float_t Float_t Int_t Int_t UInt_t UInt_t Rectangle_t Int_t Int_t Window_t TString Int_t GCValues_t GetPrimarySelectionOwner GetDisplay GetScreen GetColormap GetNativeEvent const char const char dpyName wid window const char font_name cursor keysym reg const char only_if_exist regb h Point_t winding char text const char depth char const char Int_t count const char ColorStruct_t color const char Pixmap_t Pixmap_t PictureAttributes_t attr const char char ret_data h uns",MatchSource.WIKI,doc/master/RBatchGenerator__PyTorch_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RBatchGenerator__PyTorch_8py.html
https://root.cern/doc/master/RBatchGenerator__TensorFlow_8py.html:1120,Modifiability,layers,layers,1120," Searching...; No Matches. Namespaces ; RBatchGenerator_TensorFlow.py File ReferenceTutorials  TMVA tutorials. Detailed Description; Example of getting batches of events from a ROOT dataset into a basic TensorFlow workflow. ; ; import tensorflow as tf; import ROOT; ; tree_name = ""sig_tree""; file_name = ""http://root.cern/files/Higgs_data.root""; ; batch_size = 128; chunk_size = 5_000; ; target = ""Type""; ; # Returns two TF.Dataset for training and validation batches.; ds_train, ds_valid = ROOT.TMVA.Experimental.CreateTFDatasets(; tree_name,; file_name,; batch_size,; chunk_size,; validation_split=0.3,; target=target,; ); ; # Get a list of the columns used for training; input_columns = ds_train.train_columns; num_features = len(input_columns); ; ##############################################################################; # AI example; ##############################################################################; ; # Define TensorFlow model; model = tf.keras.Sequential(; [; tf.keras.layers.Dense(; 300, activation=tf.nn.tanh, input_shape=(num_features,); ), # input shape required; tf.keras.layers.Dense(300, activation=tf.nn.tanh),; tf.keras.layers.Dense(300, activation=tf.nn.tanh),; tf.keras.layers.Dense(1, activation=tf.nn.sigmoid),; ]; ); loss_fn = tf.keras.losses.BinaryCrossentropy(); model.compile(optimizer=""adam"", loss=loss_fn, metrics=[""accuracy""]); ; # Train model; model.fit(ds_train, validation_data=ds_valid, epochs=2); lenOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t Float_t Float_t Int_t Int_t UInt_t UInt_t Rectangle_t Int_t Int_t Window_t TString Int_t GCValues_t GetPrimarySelectionOwner GetDisplay GetScreen GetColormap GetNativeEvent const char const char dpyName wid window const char font_name cursor keysym reg const char only_if_exist regb h Point_t winding char text const char depth char const ",MatchSource.WIKI,doc/master/RBatchGenerator__TensorFlow_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RBatchGenerator__TensorFlow_8py.html
https://root.cern/doc/master/RBatchGenerator__TensorFlow_8py.html:1228,Modifiability,layers,layers,1228,"ls. Detailed Description; Example of getting batches of events from a ROOT dataset into a basic TensorFlow workflow. ; ; import tensorflow as tf; import ROOT; ; tree_name = ""sig_tree""; file_name = ""http://root.cern/files/Higgs_data.root""; ; batch_size = 128; chunk_size = 5_000; ; target = ""Type""; ; # Returns two TF.Dataset for training and validation batches.; ds_train, ds_valid = ROOT.TMVA.Experimental.CreateTFDatasets(; tree_name,; file_name,; batch_size,; chunk_size,; validation_split=0.3,; target=target,; ); ; # Get a list of the columns used for training; input_columns = ds_train.train_columns; num_features = len(input_columns); ; ##############################################################################; # AI example; ##############################################################################; ; # Define TensorFlow model; model = tf.keras.Sequential(; [; tf.keras.layers.Dense(; 300, activation=tf.nn.tanh, input_shape=(num_features,); ), # input shape required; tf.keras.layers.Dense(300, activation=tf.nn.tanh),; tf.keras.layers.Dense(300, activation=tf.nn.tanh),; tf.keras.layers.Dense(1, activation=tf.nn.sigmoid),; ]; ); loss_fn = tf.keras.losses.BinaryCrossentropy(); model.compile(optimizer=""adam"", loss=loss_fn, metrics=[""accuracy""]); ; # Train model; model.fit(ds_train, validation_data=ds_valid, epochs=2); lenOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t Float_t Float_t Int_t Int_t UInt_t UInt_t Rectangle_t Int_t Int_t Window_t TString Int_t GCValues_t GetPrimarySelectionOwner GetDisplay GetScreen GetColormap GetNativeEvent const char const char dpyName wid window const char font_name cursor keysym reg const char only_if_exist regb h Point_t winding char text const char depth char const char Int_t count const char ColorStruct_t color const char Pixmap_t Pixmap_t PictureAttributes_t attr const ",MatchSource.WIKI,doc/master/RBatchGenerator__TensorFlow_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RBatchGenerator__TensorFlow_8py.html
https://root.cern/doc/master/RBatchGenerator__TensorFlow_8py.html:1280,Modifiability,layers,layers,1280," of events from a ROOT dataset into a basic TensorFlow workflow. ; ; import tensorflow as tf; import ROOT; ; tree_name = ""sig_tree""; file_name = ""http://root.cern/files/Higgs_data.root""; ; batch_size = 128; chunk_size = 5_000; ; target = ""Type""; ; # Returns two TF.Dataset for training and validation batches.; ds_train, ds_valid = ROOT.TMVA.Experimental.CreateTFDatasets(; tree_name,; file_name,; batch_size,; chunk_size,; validation_split=0.3,; target=target,; ); ; # Get a list of the columns used for training; input_columns = ds_train.train_columns; num_features = len(input_columns); ; ##############################################################################; # AI example; ##############################################################################; ; # Define TensorFlow model; model = tf.keras.Sequential(; [; tf.keras.layers.Dense(; 300, activation=tf.nn.tanh, input_shape=(num_features,); ), # input shape required; tf.keras.layers.Dense(300, activation=tf.nn.tanh),; tf.keras.layers.Dense(300, activation=tf.nn.tanh),; tf.keras.layers.Dense(1, activation=tf.nn.sigmoid),; ]; ); loss_fn = tf.keras.losses.BinaryCrossentropy(); model.compile(optimizer=""adam"", loss=loss_fn, metrics=[""accuracy""]); ; # Train model; model.fit(ds_train, validation_data=ds_valid, epochs=2); lenOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t Float_t Float_t Int_t Int_t UInt_t UInt_t Rectangle_t Int_t Int_t Window_t TString Int_t GCValues_t GetPrimarySelectionOwner GetDisplay GetScreen GetColormap GetNativeEvent const char const char dpyName wid window const char font_name cursor keysym reg const char only_if_exist regb h Point_t winding char text const char depth char const char Int_t count const char ColorStruct_t color const char Pixmap_t Pixmap_t PictureAttributes_t attr const char char ret_data h unsigned char height h Atom_t I",MatchSource.WIKI,doc/master/RBatchGenerator__TensorFlow_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RBatchGenerator__TensorFlow_8py.html
https://root.cern/doc/master/RBatchGenerator__TensorFlow_8py.html:1332,Modifiability,layers,layers,1332,"ow workflow. ; ; import tensorflow as tf; import ROOT; ; tree_name = ""sig_tree""; file_name = ""http://root.cern/files/Higgs_data.root""; ; batch_size = 128; chunk_size = 5_000; ; target = ""Type""; ; # Returns two TF.Dataset for training and validation batches.; ds_train, ds_valid = ROOT.TMVA.Experimental.CreateTFDatasets(; tree_name,; file_name,; batch_size,; chunk_size,; validation_split=0.3,; target=target,; ); ; # Get a list of the columns used for training; input_columns = ds_train.train_columns; num_features = len(input_columns); ; ##############################################################################; # AI example; ##############################################################################; ; # Define TensorFlow model; model = tf.keras.Sequential(; [; tf.keras.layers.Dense(; 300, activation=tf.nn.tanh, input_shape=(num_features,); ), # input shape required; tf.keras.layers.Dense(300, activation=tf.nn.tanh),; tf.keras.layers.Dense(300, activation=tf.nn.tanh),; tf.keras.layers.Dense(1, activation=tf.nn.sigmoid),; ]; ); loss_fn = tf.keras.losses.BinaryCrossentropy(); model.compile(optimizer=""adam"", loss=loss_fn, metrics=[""accuracy""]); ; # Train model; model.fit(ds_train, validation_data=ds_valid, epochs=2); lenOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t Float_t Float_t Int_t Int_t UInt_t UInt_t Rectangle_t Int_t Int_t Window_t TString Int_t GCValues_t GetPrimarySelectionOwner GetDisplay GetScreen GetColormap GetNativeEvent const char const char dpyName wid window const char font_name cursor keysym reg const char only_if_exist regb h Point_t winding char text const char depth char const char Int_t count const char ColorStruct_t color const char Pixmap_t Pixmap_t PictureAttributes_t attr const char char ret_data h unsigned char height h Atom_t Int_t ULong_t ULong_t unsigned char prop_list Atom_t ",MatchSource.WIKI,doc/master/RBatchGenerator__TensorFlow_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RBatchGenerator__TensorFlow_8py.html
https://root.cern/doc/master/RBatchGenerator__TensorFlow_8py.html:1444,Performance,optimiz,optimizer,1444,"ize = 128; chunk_size = 5_000; ; target = ""Type""; ; # Returns two TF.Dataset for training and validation batches.; ds_train, ds_valid = ROOT.TMVA.Experimental.CreateTFDatasets(; tree_name,; file_name,; batch_size,; chunk_size,; validation_split=0.3,; target=target,; ); ; # Get a list of the columns used for training; input_columns = ds_train.train_columns; num_features = len(input_columns); ; ##############################################################################; # AI example; ##############################################################################; ; # Define TensorFlow model; model = tf.keras.Sequential(; [; tf.keras.layers.Dense(; 300, activation=tf.nn.tanh, input_shape=(num_features,); ), # input shape required; tf.keras.layers.Dense(300, activation=tf.nn.tanh),; tf.keras.layers.Dense(300, activation=tf.nn.tanh),; tf.keras.layers.Dense(1, activation=tf.nn.sigmoid),; ]; ); loss_fn = tf.keras.losses.BinaryCrossentropy(); model.compile(optimizer=""adam"", loss=loss_fn, metrics=[""accuracy""]); ; # Train model; model.fit(ds_train, validation_data=ds_valid, epochs=2); lenOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t Float_t Float_t Int_t Int_t UInt_t UInt_t Rectangle_t Int_t Int_t Window_t TString Int_t GCValues_t GetPrimarySelectionOwner GetDisplay GetScreen GetColormap GetNativeEvent const char const char dpyName wid window const char font_name cursor keysym reg const char only_if_exist regb h Point_t winding char text const char depth char const char Int_t count const char ColorStruct_t color const char Pixmap_t Pixmap_t PictureAttributes_t attr const char char ret_data h unsigned char height h Atom_t Int_t ULong_t ULong_t unsigned char prop_list Atom_t Atom_t Atom_t Time_t UChar_t lenDefinition TGWin32VirtualXProxy.cxx:249; Epoch 1/2; ; 1/Unknown - 9s 9s/step - loss: 0.5945 - accuracy: 0.7656",MatchSource.WIKI,doc/master/RBatchGenerator__TensorFlow_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RBatchGenerator__TensorFlow_8py.html
https://root.cern/doc/master/RBatchGenerator__TensorFlow_8py.html:573,Security,validat,validation,573,". ROOT: tutorials/tmva/RBatchGenerator_TensorFlow.py File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. Namespaces ; RBatchGenerator_TensorFlow.py File ReferenceTutorials  TMVA tutorials. Detailed Description; Example of getting batches of events from a ROOT dataset into a basic TensorFlow workflow. ; ; import tensorflow as tf; import ROOT; ; tree_name = ""sig_tree""; file_name = ""http://root.cern/files/Higgs_data.root""; ; batch_size = 128; chunk_size = 5_000; ; target = ""Type""; ; # Returns two TF.Dataset for training and validation batches.; ds_train, ds_valid = ROOT.TMVA.Experimental.CreateTFDatasets(; tree_name,; file_name,; batch_size,; chunk_size,; validation_split=0.3,; target=target,; ); ; # Get a list of the columns used for training; input_columns = ds_train.train_columns; num_features = len(input_columns); ; ##############################################################################; # AI example; ##############################################################################; ; # Define TensorFlow model; model = tf.keras.Sequential(; [; tf.keras.layers.Dense(; 300, activation=tf.nn.tanh, input_shape=(num_features,); ), # input shape required; tf.keras.layers.Dense(300, activation=tf.nn.tanh),; tf.keras.layers.Dense(300, activation=tf.nn.tanh),; tf.keras.layers.Dense(1, activation=tf.nn.sigmoid),; ]; ); loss_fn = tf.keras.losses.BinaryCrossentropy(); model.compile(optimizer=""adam"", loss=loss_fn, metrics=[""accuracy""]); ; # Train model; model.fit(ds_train, validation_data=ds_valid, epochs=2); lenOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t Float_t Float_t Int_t Int_t UInt_t UInt_t Rectangle_t Int_t Int_t Window_t TString Int_t GCValues_t GetPrimarySelectionOwner GetDisplay GetScreen GetColormap GetNativeEvent const char const char dpyName wid window co",MatchSource.WIKI,doc/master/RBatchGenerator__TensorFlow_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RBatchGenerator__TensorFlow_8py.html
https://root.cern/doc/master/RBrowserData_8cxx_source.html:4947,Availability,error,error,4947,"ue);; 124 comp->Add(files);; 125 // if there are any open files, make them visible by default; 126 if (elem_files->GetNumChilds() > 0); 127 seldir = {};; 128 }; 129 ; 130 SetTopElement(comp);; 131 ; 132 SetWorkingPath(seldir);; 133}; 134 ; 135/////////////////////////////////////////////////////////////////////; 136/// Reset all data correspondent to last request; 137 ; 138void RBrowserData::ResetLastRequestData(bool with_element); 139{; 140 fLastAllChilds = false;; 141 fLastSortedItems.clear();; 142 fLastSortMethod.clear();; 143 fLastItems.clear();; 144 if (with_element) {; 145 fLastPath.clear();; 146 fLastElement.reset();; 147 }; 148}; 149 ; 150/////////////////////////////////////////////////////////////////////////; 151/// Decompose path to elements; 152/// Returns array of names for each element in the path, first element either ""/"" or "".""; 153/// If returned array empty - it is error; 154 ; 155Browsable::RElementPath_t RBrowserData::DecomposePath(const std::string &strpath, bool relative_to_work_element); 156{; 157 Browsable::RElementPath_t arr;; 158 if (relative_to_work_element) arr = fWorkingPath;; 159 ; 160 if (strpath.empty()); 161 return arr;; 162 ; 163 auto arr2 = Browsable::RElement::ParsePath(strpath);; 164 arr.insert(arr.end(), arr2.begin(), arr2.end());; 165 return arr;; 166}; 167 ; 168/////////////////////////////////////////////////////////////////////////; 169/// Process browser request; 170 ; 171bool RBrowserData::ProcessBrowserRequest(const RBrowserRequest &request, RBrowserReply &reply); 172{; 173 auto path = fWorkingPath;; 174 path.insert(path.end(), request.path.begin(), request.path.end());; 175 ; 176 if ((path != fLastPath) || !fLastElement) {; 177 ; 178 auto elem = GetSubElement(path);; 179 if (!elem) return false;; 180 ; 181 ResetLastRequestData(true);; 182 ; 183 fLastPath = path;; 184 fLastElement = std::move(elem);; 185 ; 186 fLastElement->cd(); // set element active; 187 } else if (request.reload) {; 188 // only reload items from elemen",MatchSource.WIKI,doc/master/RBrowserData_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RBrowserData_8cxx_source.html
https://root.cern/doc/master/RBrowserData_8cxx_source.html:14841,Deployability,configurat,configuration,14841,"lementPath_t &path1, const RElementPath_t &path2)Compare two paths, Returns number of elements matches in both paths.Definition RElement.cxx:145; ROOT::Browsable::RElement::ParsePathstatic RElementPath_t ParsePath(const std::string &str)Parse string path to produce RElementPath_t One should avoid to use string pathes as much as possible...Definition RElement.cxx:116; ROOT::Browsable::RItemRepresentation of single item in the browser.Definition RItem.hxx:23; ROOT::Browsable::RProvider::Browsestatic std::shared_ptr< RElement > Browse(std::unique_ptr< RHolder > &obj)Create browsable element for the object Created element may take ownership over the object.Definition RProvider.cxx:273; ROOT::Browsable::RSysFile::ProvideTopEntriesstatic RElementPath_t ProvideTopEntries(std::shared_ptr< RGroup > &comp, const std::string &workdir="""")Provide top entries for file system On windows it is list of existing drivers, on Linux it is ""File s...Definition RSysFile.cxx:533; ROOT::Experimental::RLogChannelA log configuration for a channel, e.g.Definition RLogger.hxx:101; ROOT::RBrowserDataCleanupDefinition RBrowserData.cxx:43; ROOT::RBrowserDataCleanup::fDataRBrowserData & fDataDefinition RBrowserData.cxx:45; ROOT::RBrowserDataCleanup::RBrowserDataCleanupRBrowserDataCleanup(RBrowserData &_data)Definition RBrowserData.cxx:48; ROOT::RBrowserDataCleanup::RecursiveRemovevoid RecursiveRemove(TObject *obj) overrideRecursively remove this object from a list.Definition RBrowserData.cxx:50; ROOT::RBrowserDataWay to browse (hopefully) everything in ROOT.Definition RBrowserData.hxx:37; ROOT::RBrowserData::SetTopElementvoid SetTopElement(std::shared_ptr< Browsable::RElement > elem)set top element for browsingDefinition RBrowserData.cxx:88; ROOT::RBrowserData::fLastSortedItemsstd::vector< const Browsable::RItem * > fLastSortedItems! sorted child items, used in requestsDefinition RBrowserData.hxx:51; ROOT::RBrowserData::fWorkingPathBrowsable::RElementPath_t fWorkingPath! path showed in BreadcrumbDef",MatchSource.WIKI,doc/master/RBrowserData_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RBrowserData_8cxx_source.html
https://root.cern/doc/master/RBrowserData_8cxx_source.html:14841,Modifiability,config,configuration,14841,"lementPath_t &path1, const RElementPath_t &path2)Compare two paths, Returns number of elements matches in both paths.Definition RElement.cxx:145; ROOT::Browsable::RElement::ParsePathstatic RElementPath_t ParsePath(const std::string &str)Parse string path to produce RElementPath_t One should avoid to use string pathes as much as possible...Definition RElement.cxx:116; ROOT::Browsable::RItemRepresentation of single item in the browser.Definition RItem.hxx:23; ROOT::Browsable::RProvider::Browsestatic std::shared_ptr< RElement > Browse(std::unique_ptr< RHolder > &obj)Create browsable element for the object Created element may take ownership over the object.Definition RProvider.cxx:273; ROOT::Browsable::RSysFile::ProvideTopEntriesstatic RElementPath_t ProvideTopEntries(std::shared_ptr< RGroup > &comp, const std::string &workdir="""")Provide top entries for file system On windows it is list of existing drivers, on Linux it is ""File s...Definition RSysFile.cxx:533; ROOT::Experimental::RLogChannelA log configuration for a channel, e.g.Definition RLogger.hxx:101; ROOT::RBrowserDataCleanupDefinition RBrowserData.cxx:43; ROOT::RBrowserDataCleanup::fDataRBrowserData & fDataDefinition RBrowserData.cxx:45; ROOT::RBrowserDataCleanup::RBrowserDataCleanupRBrowserDataCleanup(RBrowserData &_data)Definition RBrowserData.cxx:48; ROOT::RBrowserDataCleanup::RecursiveRemovevoid RecursiveRemove(TObject *obj) overrideRecursively remove this object from a list.Definition RBrowserData.cxx:50; ROOT::RBrowserDataWay to browse (hopefully) everything in ROOT.Definition RBrowserData.hxx:37; ROOT::RBrowserData::SetTopElementvoid SetTopElement(std::shared_ptr< Browsable::RElement > elem)set top element for browsingDefinition RBrowserData.cxx:88; ROOT::RBrowserData::fLastSortedItemsstd::vector< const Browsable::RItem * > fLastSortedItems! sorted child items, used in requestsDefinition RBrowserData.hxx:51; ROOT::RBrowserData::fWorkingPathBrowsable::RElementPath_t fWorkingPath! path showed in BreadcrumbDef",MatchSource.WIKI,doc/master/RBrowserData_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RBrowserData_8cxx_source.html
https://root.cern/doc/master/RBrowserData_8cxx_source.html:9779,Performance,cache,cached,9779,"ply data; 268 ; 269std::string RBrowserData::ProcessRequest(const RBrowserRequest &request); 270{; 271 if (request.lastcycle < 0); 272 gEnv->SetValue(""WebGui.LastCycle"", ""no"");; 273 else if (request.lastcycle > 0); 274 gEnv->SetValue(""WebGui.LastCycle"", ""yes"");; 275 ; 276 RBrowserReply reply;; 277 ; 278 reply.path = request.path;; 279 reply.first = 0;; 280 reply.nchilds = 0;; 281 ; 282 ProcessBrowserRequest(request, reply);; 283 ; 284 return TBufferJSON::ToJSON(&reply, TBufferJSON::kSkipTypeInfo + TBufferJSON::kNoSpaces).Data();; 285}; 286 ; 287/////////////////////////////////////////////////////////////////////////; 288/// Returns element with path, specified as string; 289 ; 290std::shared_ptr<Browsable::RElement> RBrowserData::GetElement(const std::string &str); 291{; 292 auto path = DecomposePath(str, true);; 293 ; 294 return GetSubElement(path);; 295}; 296 ; 297/////////////////////////////////////////////////////////////////////////; 298/// Returns element with path, specified as Browsable::RElementPath_t; 299 ; 300std::shared_ptr<Browsable::RElement> RBrowserData::GetElementFromTop(const Browsable::RElementPath_t &path); 301{; 302 return GetSubElement(path);; 303}; 304 ; 305/////////////////////////////////////////////////////////////////////////; 306/// Returns sub-element starting from top, using cached data; 307 ; 308std::shared_ptr<Browsable::RElement> RBrowserData::GetSubElement(const Browsable::RElementPath_t &path); 309{; 310 if (path.empty()); 311 return fTopElement;; 312 ; 313 // validate cache - removes no longer actual elements; 314 RemoveFromCache(nullptr);; 315 ; 316 // first check direct match in cache; 317 for (auto &entry : fCache); 318 if (entry.first == path); 319 return entry.second;; 320 ; 321 // find best possible entry in cache; 322 int pos = 0;; 323 auto elem = fTopElement;; 324 ; 325 for (auto &entry : fCache) {; 326 if (entry.first.size() >= path.size()); 327 continue;; 328 ; 329 auto comp = Browsable::RElement::ComparePaths(path, ent",MatchSource.WIKI,doc/master/RBrowserData_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RBrowserData_8cxx_source.html
https://root.cern/doc/master/RBrowserData_8cxx_source.html:9982,Performance,cache,cache,9982,"//////////////////////////////////////; 288/// Returns element with path, specified as string; 289 ; 290std::shared_ptr<Browsable::RElement> RBrowserData::GetElement(const std::string &str); 291{; 292 auto path = DecomposePath(str, true);; 293 ; 294 return GetSubElement(path);; 295}; 296 ; 297/////////////////////////////////////////////////////////////////////////; 298/// Returns element with path, specified as Browsable::RElementPath_t; 299 ; 300std::shared_ptr<Browsable::RElement> RBrowserData::GetElementFromTop(const Browsable::RElementPath_t &path); 301{; 302 return GetSubElement(path);; 303}; 304 ; 305/////////////////////////////////////////////////////////////////////////; 306/// Returns sub-element starting from top, using cached data; 307 ; 308std::shared_ptr<Browsable::RElement> RBrowserData::GetSubElement(const Browsable::RElementPath_t &path); 309{; 310 if (path.empty()); 311 return fTopElement;; 312 ; 313 // validate cache - removes no longer actual elements; 314 RemoveFromCache(nullptr);; 315 ; 316 // first check direct match in cache; 317 for (auto &entry : fCache); 318 if (entry.first == path); 319 return entry.second;; 320 ; 321 // find best possible entry in cache; 322 int pos = 0;; 323 auto elem = fTopElement;; 324 ; 325 for (auto &entry : fCache) {; 326 if (entry.first.size() >= path.size()); 327 continue;; 328 ; 329 auto comp = Browsable::RElement::ComparePaths(path, entry.first);; 330 ; 331 if ((comp > pos) && (comp == (int) entry.first.size())) {; 332 pos = comp;; 333 elem = entry.second;; 334 }; 335 }; 336 ; 337 while (pos < (int) path.size()) {; 338 std::string subname = path[pos];; 339 int indx = Browsable::RElement::ExtractItemIndex(subname);; 340 ; 341 auto iter = elem->GetChildsIter();; 342 if (!iter); 343 return nullptr;; 344 ; 345 if (!iter->Find(subname, indx)) {; 346 if (indx < 0); 347 return nullptr;; 348 iter = elem->GetChildsIter();; 349 if (!iter || !iter->Find(subname)); 350 return nullptr;; 351 }; 352 ; 353 elem = iter->GetElem",MatchSource.WIKI,doc/master/RBrowserData_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RBrowserData_8cxx_source.html
https://root.cern/doc/master/RBrowserData_8cxx_source.html:10097,Performance,cache,cache,10097,"//////////////////////////////////////; 288/// Returns element with path, specified as string; 289 ; 290std::shared_ptr<Browsable::RElement> RBrowserData::GetElement(const std::string &str); 291{; 292 auto path = DecomposePath(str, true);; 293 ; 294 return GetSubElement(path);; 295}; 296 ; 297/////////////////////////////////////////////////////////////////////////; 298/// Returns element with path, specified as Browsable::RElementPath_t; 299 ; 300std::shared_ptr<Browsable::RElement> RBrowserData::GetElementFromTop(const Browsable::RElementPath_t &path); 301{; 302 return GetSubElement(path);; 303}; 304 ; 305/////////////////////////////////////////////////////////////////////////; 306/// Returns sub-element starting from top, using cached data; 307 ; 308std::shared_ptr<Browsable::RElement> RBrowserData::GetSubElement(const Browsable::RElementPath_t &path); 309{; 310 if (path.empty()); 311 return fTopElement;; 312 ; 313 // validate cache - removes no longer actual elements; 314 RemoveFromCache(nullptr);; 315 ; 316 // first check direct match in cache; 317 for (auto &entry : fCache); 318 if (entry.first == path); 319 return entry.second;; 320 ; 321 // find best possible entry in cache; 322 int pos = 0;; 323 auto elem = fTopElement;; 324 ; 325 for (auto &entry : fCache) {; 326 if (entry.first.size() >= path.size()); 327 continue;; 328 ; 329 auto comp = Browsable::RElement::ComparePaths(path, entry.first);; 330 ; 331 if ((comp > pos) && (comp == (int) entry.first.size())) {; 332 pos = comp;; 333 elem = entry.second;; 334 }; 335 }; 336 ; 337 while (pos < (int) path.size()) {; 338 std::string subname = path[pos];; 339 int indx = Browsable::RElement::ExtractItemIndex(subname);; 340 ; 341 auto iter = elem->GetChildsIter();; 342 if (!iter); 343 return nullptr;; 344 ; 345 if (!iter->Find(subname, indx)) {; 346 if (indx < 0); 347 return nullptr;; 348 iter = elem->GetChildsIter();; 349 if (!iter || !iter->Find(subname)); 350 return nullptr;; 351 }; 352 ; 353 elem = iter->GetElem",MatchSource.WIKI,doc/master/RBrowserData_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RBrowserData_8cxx_source.html
https://root.cern/doc/master/RBrowserData_8cxx_source.html:10233,Performance,cache,cache,10233,"h(str, true);; 293 ; 294 return GetSubElement(path);; 295}; 296 ; 297/////////////////////////////////////////////////////////////////////////; 298/// Returns element with path, specified as Browsable::RElementPath_t; 299 ; 300std::shared_ptr<Browsable::RElement> RBrowserData::GetElementFromTop(const Browsable::RElementPath_t &path); 301{; 302 return GetSubElement(path);; 303}; 304 ; 305/////////////////////////////////////////////////////////////////////////; 306/// Returns sub-element starting from top, using cached data; 307 ; 308std::shared_ptr<Browsable::RElement> RBrowserData::GetSubElement(const Browsable::RElementPath_t &path); 309{; 310 if (path.empty()); 311 return fTopElement;; 312 ; 313 // validate cache - removes no longer actual elements; 314 RemoveFromCache(nullptr);; 315 ; 316 // first check direct match in cache; 317 for (auto &entry : fCache); 318 if (entry.first == path); 319 return entry.second;; 320 ; 321 // find best possible entry in cache; 322 int pos = 0;; 323 auto elem = fTopElement;; 324 ; 325 for (auto &entry : fCache) {; 326 if (entry.first.size() >= path.size()); 327 continue;; 328 ; 329 auto comp = Browsable::RElement::ComparePaths(path, entry.first);; 330 ; 331 if ((comp > pos) && (comp == (int) entry.first.size())) {; 332 pos = comp;; 333 elem = entry.second;; 334 }; 335 }; 336 ; 337 while (pos < (int) path.size()) {; 338 std::string subname = path[pos];; 339 int indx = Browsable::RElement::ExtractItemIndex(subname);; 340 ; 341 auto iter = elem->GetChildsIter();; 342 if (!iter); 343 return nullptr;; 344 ; 345 if (!iter->Find(subname, indx)) {; 346 if (indx < 0); 347 return nullptr;; 348 iter = elem->GetChildsIter();; 349 if (!iter || !iter->Find(subname)); 350 return nullptr;; 351 }; 352 ; 353 elem = iter->GetElement();; 354 ; 355 if (!elem); 356 return nullptr;; 357 ; 358 auto subpath = path;; 359 subpath.resize(pos+1);; 360 fCache.emplace_back(subpath, elem);; 361 pos++; // switch to next element; 362 }; 363 ; 364 return elem;; 365}",MatchSource.WIKI,doc/master/RBrowserData_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RBrowserData_8cxx_source.html
https://root.cern/doc/master/RBrowserData_8cxx_source.html:11379,Performance,cache,cache,11379,"(auto &entry : fCache) {; 326 if (entry.first.size() >= path.size()); 327 continue;; 328 ; 329 auto comp = Browsable::RElement::ComparePaths(path, entry.first);; 330 ; 331 if ((comp > pos) && (comp == (int) entry.first.size())) {; 332 pos = comp;; 333 elem = entry.second;; 334 }; 335 }; 336 ; 337 while (pos < (int) path.size()) {; 338 std::string subname = path[pos];; 339 int indx = Browsable::RElement::ExtractItemIndex(subname);; 340 ; 341 auto iter = elem->GetChildsIter();; 342 if (!iter); 343 return nullptr;; 344 ; 345 if (!iter->Find(subname, indx)) {; 346 if (indx < 0); 347 return nullptr;; 348 iter = elem->GetChildsIter();; 349 if (!iter || !iter->Find(subname)); 350 return nullptr;; 351 }; 352 ; 353 elem = iter->GetElement();; 354 ; 355 if (!elem); 356 return nullptr;; 357 ; 358 auto subpath = path;; 359 subpath.resize(pos+1);; 360 fCache.emplace_back(subpath, elem);; 361 pos++; // switch to next element; 362 }; 363 ; 364 return elem;; 365}; 366 ; 367/////////////////////////////////////////////////////////////////////////; 368/// Clear internal objects cache; 369 ; 370void RBrowserData::ClearCache(); 371{; 372 fCache.clear();; 373}; 374 ; 375/////////////////////////////////////////////////////////////////////////; 376/// Remove object from cache; 377/// If nullptr specified - removes no-longer-valid elements; 378/// Returns true if any element was removed; 379 ; 380bool RBrowserData::RemoveFromCache(void *obj); 381{; 382 unsigned pos = 0;; 383 ; 384 bool isany = false;; 385 ; 386 while (pos < fCache.size()) {; 387 if (obj ? !fCache[pos].second->IsObject(obj) : fCache[pos].second->CheckValid()) {; 388 pos++;; 389 continue;; 390 }; 391 ; 392 isany = true;; 393 auto path = fCache[pos].first;; 394 fCache.erase(fCache.begin() + pos);; 395 if (RemoveFromCache(path)); 396 pos = 0; // start scan from the beginning; 397 }; 398 ; 399 return isany;; 400}; 401 ; 402/////////////////////////////////////////////////////////////////////////; 403/// Remove path (and all sub",MatchSource.WIKI,doc/master/RBrowserData_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RBrowserData_8cxx_source.html
https://root.cern/doc/master/RBrowserData_8cxx_source.html:11571,Performance,cache,cache,11571,"td::string subname = path[pos];; 339 int indx = Browsable::RElement::ExtractItemIndex(subname);; 340 ; 341 auto iter = elem->GetChildsIter();; 342 if (!iter); 343 return nullptr;; 344 ; 345 if (!iter->Find(subname, indx)) {; 346 if (indx < 0); 347 return nullptr;; 348 iter = elem->GetChildsIter();; 349 if (!iter || !iter->Find(subname)); 350 return nullptr;; 351 }; 352 ; 353 elem = iter->GetElement();; 354 ; 355 if (!elem); 356 return nullptr;; 357 ; 358 auto subpath = path;; 359 subpath.resize(pos+1);; 360 fCache.emplace_back(subpath, elem);; 361 pos++; // switch to next element; 362 }; 363 ; 364 return elem;; 365}; 366 ; 367/////////////////////////////////////////////////////////////////////////; 368/// Clear internal objects cache; 369 ; 370void RBrowserData::ClearCache(); 371{; 372 fCache.clear();; 373}; 374 ; 375/////////////////////////////////////////////////////////////////////////; 376/// Remove object from cache; 377/// If nullptr specified - removes no-longer-valid elements; 378/// Returns true if any element was removed; 379 ; 380bool RBrowserData::RemoveFromCache(void *obj); 381{; 382 unsigned pos = 0;; 383 ; 384 bool isany = false;; 385 ; 386 while (pos < fCache.size()) {; 387 if (obj ? !fCache[pos].second->IsObject(obj) : fCache[pos].second->CheckValid()) {; 388 pos++;; 389 continue;; 390 }; 391 ; 392 isany = true;; 393 auto path = fCache[pos].first;; 394 fCache.erase(fCache.begin() + pos);; 395 if (RemoveFromCache(path)); 396 pos = 0; // start scan from the beginning; 397 }; 398 ; 399 return isany;; 400}; 401 ; 402/////////////////////////////////////////////////////////////////////////; 403/// Remove path (and all sub-paths) from cache; 404/// Returns true if any element was removed; 405 ; 406bool RBrowserData::RemoveFromCache(const Browsable::RElementPath_t &path); 407{; 408 if (path.size() == 0); 409 return false;; 410 ; 411 bool isany = false;; 412 unsigned pos = 0;; 413 while (pos < fCache.size()) {; 414 if (Browsable::RElement::ComparePaths(pat",MatchSource.WIKI,doc/master/RBrowserData_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RBrowserData_8cxx_source.html
https://root.cern/doc/master/RBrowserData_8cxx_source.html:12316,Performance,cache,cache,12316," 366 ; 367/////////////////////////////////////////////////////////////////////////; 368/// Clear internal objects cache; 369 ; 370void RBrowserData::ClearCache(); 371{; 372 fCache.clear();; 373}; 374 ; 375/////////////////////////////////////////////////////////////////////////; 376/// Remove object from cache; 377/// If nullptr specified - removes no-longer-valid elements; 378/// Returns true if any element was removed; 379 ; 380bool RBrowserData::RemoveFromCache(void *obj); 381{; 382 unsigned pos = 0;; 383 ; 384 bool isany = false;; 385 ; 386 while (pos < fCache.size()) {; 387 if (obj ? !fCache[pos].second->IsObject(obj) : fCache[pos].second->CheckValid()) {; 388 pos++;; 389 continue;; 390 }; 391 ; 392 isany = true;; 393 auto path = fCache[pos].first;; 394 fCache.erase(fCache.begin() + pos);; 395 if (RemoveFromCache(path)); 396 pos = 0; // start scan from the beginning; 397 }; 398 ; 399 return isany;; 400}; 401 ; 402/////////////////////////////////////////////////////////////////////////; 403/// Remove path (and all sub-paths) from cache; 404/// Returns true if any element was removed; 405 ; 406bool RBrowserData::RemoveFromCache(const Browsable::RElementPath_t &path); 407{; 408 if (path.size() == 0); 409 return false;; 410 ; 411 bool isany = false;; 412 unsigned pos = 0;; 413 while (pos < fCache.size()) {; 414 if (Browsable::RElement::ComparePaths(path, fCache[pos].first) == (int) path.size()) {; 415 fCache.erase(fCache.begin() + pos);; 416 isany = true;; 417 } else {; 418 pos++;; 419 }; 420 }; 421 return isany;; 422}; RBrowserData.hxx; RGroup.hxx; RLevelIter.hxx; RLogger.hxx; RProvider.hxx; b#define b(i)Definition RSha256.hxx:100; a#define a(i)Definition RSha256.hxx:99; RSysFile.hxx; RWrapper.hxx; kFALSEconstexpr Bool_t kFALSEDefinition RtypesCore.h:94; TBufferJSON.h; TEnv.h; gEnvR__EXTERN TEnv * gEnvDefinition TEnv.h:170; TFolder.h; idOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign ",MatchSource.WIKI,doc/master/RBrowserData_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RBrowserData_8cxx_source.html
https://root.cern/doc/master/RBrowserData_8cxx_source.html:15948,Performance,cache,cache,15948,"serData.cxx:43; ROOT::RBrowserDataCleanup::fDataRBrowserData & fDataDefinition RBrowserData.cxx:45; ROOT::RBrowserDataCleanup::RBrowserDataCleanupRBrowserDataCleanup(RBrowserData &_data)Definition RBrowserData.cxx:48; ROOT::RBrowserDataCleanup::RecursiveRemovevoid RecursiveRemove(TObject *obj) overrideRecursively remove this object from a list.Definition RBrowserData.cxx:50; ROOT::RBrowserDataWay to browse (hopefully) everything in ROOT.Definition RBrowserData.hxx:37; ROOT::RBrowserData::SetTopElementvoid SetTopElement(std::shared_ptr< Browsable::RElement > elem)set top element for browsingDefinition RBrowserData.cxx:88; ROOT::RBrowserData::fLastSortedItemsstd::vector< const Browsable::RItem * > fLastSortedItems! sorted child items, used in requestsDefinition RBrowserData.hxx:51; ROOT::RBrowserData::fWorkingPathBrowsable::RElementPath_t fWorkingPath! path showed in BreadcrumbDefinition RBrowserData.hxx:43; ROOT::RBrowserData::RemoveFromCachebool RemoveFromCache(void *obj)Remove object from cache If nullptr specified - removes no-longer-valid elements Returns true if any ...Definition RBrowserData.cxx:380; ROOT::RBrowserData::GetSubElementstd::shared_ptr< Browsable::RElement > GetSubElement(const Browsable::RElementPath_t &path)Returns sub-element starting from top, using cached data.Definition RBrowserData.cxx:308; ROOT::RBrowserData::fCachestd::vector< std::pair< Browsable::RElementPath_t, std::shared_ptr< Browsable::RElement > > > fCache! already requested elementsDefinition RBrowserData.hxx:45; ROOT::RBrowserData::fCleanupHandlestd::unique_ptr< TObject > fCleanupHandle! cleanup handle for RecursiveRemoveDefinition RBrowserData.hxx:54; ROOT::RBrowserData::DecomposePathBrowsable::RElementPath_t DecomposePath(const std::string &path, bool relative_to_work_element)Decompose path to elements Returns array of names for each element in the path, first element either ...Definition RBrowserData.cxx:155; ROOT::RBrowserData::fLastAllChildsbool fLastAllChilds! if all chlds w",MatchSource.WIKI,doc/master/RBrowserData_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RBrowserData_8cxx_source.html
https://root.cern/doc/master/RBrowserData_8cxx_source.html:16235,Performance,cache,cached,16235,".cxx:48; ROOT::RBrowserDataCleanup::RecursiveRemovevoid RecursiveRemove(TObject *obj) overrideRecursively remove this object from a list.Definition RBrowserData.cxx:50; ROOT::RBrowserDataWay to browse (hopefully) everything in ROOT.Definition RBrowserData.hxx:37; ROOT::RBrowserData::SetTopElementvoid SetTopElement(std::shared_ptr< Browsable::RElement > elem)set top element for browsingDefinition RBrowserData.cxx:88; ROOT::RBrowserData::fLastSortedItemsstd::vector< const Browsable::RItem * > fLastSortedItems! sorted child items, used in requestsDefinition RBrowserData.hxx:51; ROOT::RBrowserData::fWorkingPathBrowsable::RElementPath_t fWorkingPath! path showed in BreadcrumbDefinition RBrowserData.hxx:43; ROOT::RBrowserData::RemoveFromCachebool RemoveFromCache(void *obj)Remove object from cache If nullptr specified - removes no-longer-valid elements Returns true if any ...Definition RBrowserData.cxx:380; ROOT::RBrowserData::GetSubElementstd::shared_ptr< Browsable::RElement > GetSubElement(const Browsable::RElementPath_t &path)Returns sub-element starting from top, using cached data.Definition RBrowserData.cxx:308; ROOT::RBrowserData::fCachestd::vector< std::pair< Browsable::RElementPath_t, std::shared_ptr< Browsable::RElement > > > fCache! already requested elementsDefinition RBrowserData.hxx:45; ROOT::RBrowserData::fCleanupHandlestd::unique_ptr< TObject > fCleanupHandle! cleanup handle for RecursiveRemoveDefinition RBrowserData.hxx:54; ROOT::RBrowserData::DecomposePathBrowsable::RElementPath_t DecomposePath(const std::string &path, bool relative_to_work_element)Decompose path to elements Returns array of names for each element in the path, first element either ...Definition RBrowserData.cxx:155; ROOT::RBrowserData::fLastAllChildsbool fLastAllChilds! if all chlds were extractedDefinition RBrowserData.hxx:50; ROOT::RBrowserData::~RBrowserDatavirtual ~RBrowserData()Destructor.Definition RBrowserData.cxx:78; ROOT::RBrowserData::ProcessBrowserRequestbool ProcessBrowserReque",MatchSource.WIKI,doc/master/RBrowserData_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RBrowserData_8cxx_source.html
https://root.cern/doc/master/RBrowserData_8cxx_source.html:17678,Performance,cache,cache,17678,"Browsable::RElementPath_t DecomposePath(const std::string &path, bool relative_to_work_element)Decompose path to elements Returns array of names for each element in the path, first element either ...Definition RBrowserData.cxx:155; ROOT::RBrowserData::fLastAllChildsbool fLastAllChilds! if all chlds were extractedDefinition RBrowserData.hxx:50; ROOT::RBrowserData::~RBrowserDatavirtual ~RBrowserData()Destructor.Definition RBrowserData.cxx:78; ROOT::RBrowserData::ProcessBrowserRequestbool ProcessBrowserRequest(const RBrowserRequest &request, RBrowserReply &reply)Process browser request.Definition RBrowserData.cxx:171; ROOT::RBrowserData::GetElementFromTopstd::shared_ptr< Browsable::RElement > GetElementFromTop(const Browsable::RElementPath_t &path)Returns element with path, specified as Browsable::RElementPath_t.Definition RBrowserData.cxx:300; ROOT::RBrowserData::fLastSortMethodstd::string fLastSortMethod! last sort methodDefinition RBrowserData.hxx:52; ROOT::RBrowserData::ClearCachevoid ClearCache()Clear internal objects cache.Definition RBrowserData.cxx:370; ROOT::RBrowserData::ProcessRequeststd::string ProcessRequest(const RBrowserRequest &request)Process browser request, returns string with JSON of RBrowserReply data.Definition RBrowserData.cxx:269; ROOT::RBrowserData::fLastItemsstd::vector< std::unique_ptr< Browsable::RItem > > fLastItems! created browser items - used in requestsDefinition RBrowserData.hxx:49; ROOT::RBrowserData::fLastPathBrowsable::RElementPath_t fLastPath! path to last used elementDefinition RBrowserData.hxx:47; ROOT::RBrowserData::SetWorkingPathvoid SetWorkingPath(const Browsable::RElementPath_t &path)set working directory relative to top elementDefinition RBrowserData.cxx:98; ROOT::RBrowserData::fTopElementstd::shared_ptr< Browsable::RElement > fTopElement! top elementDefinition RBrowserData.hxx:41; ROOT::RBrowserData::GetElementstd::shared_ptr< Browsable::RElement > GetElement(const std::string &str)Returns element with path, specified as st",MatchSource.WIKI,doc/master/RBrowserData_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RBrowserData_8cxx_source.html
https://root.cern/doc/master/RBrowserData_8cxx_source.html:14125,Safety,avoid,avoid,14125,"v.h; gEnvR__EXTERN TEnv * gEnvDefinition TEnv.h:170; TFolder.h; idOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize idDefinition TGWin32VirtualXProxy.cxx:94; TObjectHolder.hxx; TROOT.h; gROOTMutexR__EXTERN TVirtualMutex * gROOTMutexDefinition TROOT.h:63; gROOT#define gROOTDefinition TROOT.h:406; R__LOCKGUARD#define R__LOCKGUARD(mutex)Definition TVirtualMutex.h:95; ROOT::Browsable::RElement::ExtractItemIndexstatic int ExtractItemIndex(std::string &name)Extract index from name Index coded by client with ###<indx>$$$ suffix Such coding used by browser to...Definition RElement.cxx:178; ROOT::Browsable::RElement::ComparePathsstatic int ComparePaths(const RElementPath_t &path1, const RElementPath_t &path2)Compare two paths, Returns number of elements matches in both paths.Definition RElement.cxx:145; ROOT::Browsable::RElement::ParsePathstatic RElementPath_t ParsePath(const std::string &str)Parse string path to produce RElementPath_t One should avoid to use string pathes as much as possible...Definition RElement.cxx:116; ROOT::Browsable::RItemRepresentation of single item in the browser.Definition RItem.hxx:23; ROOT::Browsable::RProvider::Browsestatic std::shared_ptr< RElement > Browse(std::unique_ptr< RHolder > &obj)Create browsable element for the object Created element may take ownership over the object.Definition RProvider.cxx:273; ROOT::Browsable::RSysFile::ProvideTopEntriesstatic RElementPath_t ProvideTopEntries(std::shared_ptr< RGroup > &comp, const std::string &workdir="""")Provide top entries for file system On windows it is list of existing drivers, on Linux it is ""File s...Definition RSysFile.cxx:533; ROOT::Experimental::RLogChannelA log configuration for a channel, e.g.Definition RLogger.hxx:101; ROOT::RBrowserDataCleanupDefinition RBrowserData.cxx:43; ROOT::RBrowserDataCleanup::fDataRBrowserData & fDataDefinition RBrowserData.cxx:45; ROOT::RBrowserDataCleanup::R",MatchSource.WIKI,doc/master/RBrowserData_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RBrowserData_8cxx_source.html
https://root.cern/doc/master/RBrowserData_8cxx_source.html:9973,Security,validat,validate,9973,"//////////////////////////////////////; 288/// Returns element with path, specified as string; 289 ; 290std::shared_ptr<Browsable::RElement> RBrowserData::GetElement(const std::string &str); 291{; 292 auto path = DecomposePath(str, true);; 293 ; 294 return GetSubElement(path);; 295}; 296 ; 297/////////////////////////////////////////////////////////////////////////; 298/// Returns element with path, specified as Browsable::RElementPath_t; 299 ; 300std::shared_ptr<Browsable::RElement> RBrowserData::GetElementFromTop(const Browsable::RElementPath_t &path); 301{; 302 return GetSubElement(path);; 303}; 304 ; 305/////////////////////////////////////////////////////////////////////////; 306/// Returns sub-element starting from top, using cached data; 307 ; 308std::shared_ptr<Browsable::RElement> RBrowserData::GetSubElement(const Browsable::RElementPath_t &path); 309{; 310 if (path.empty()); 311 return fTopElement;; 312 ; 313 // validate cache - removes no longer actual elements; 314 RemoveFromCache(nullptr);; 315 ; 316 // first check direct match in cache; 317 for (auto &entry : fCache); 318 if (entry.first == path); 319 return entry.second;; 320 ; 321 // find best possible entry in cache; 322 int pos = 0;; 323 auto elem = fTopElement;; 324 ; 325 for (auto &entry : fCache) {; 326 if (entry.first.size() >= path.size()); 327 continue;; 328 ; 329 auto comp = Browsable::RElement::ComparePaths(path, entry.first);; 330 ; 331 if ((comp > pos) && (comp == (int) entry.first.size())) {; 332 pos = comp;; 333 elem = entry.second;; 334 }; 335 }; 336 ; 337 while (pos < (int) path.size()) {; 338 std::string subname = path[pos];; 339 int indx = Browsable::RElement::ExtractItemIndex(subname);; 340 ; 341 auto iter = elem->GetChildsIter();; 342 if (!iter); 343 return nullptr;; 344 ; 345 if (!iter->Find(subname, indx)) {; 346 if (indx < 0); 347 return nullptr;; 348 iter = elem->GetChildsIter();; 349 if (!iter || !iter->Find(subname)); 350 return nullptr;; 351 }; 352 ; 353 elem = iter->GetElem",MatchSource.WIKI,doc/master/RBrowserData_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RBrowserData_8cxx_source.html
https://root.cern/doc/master/RBrowserData_8cxx_source.html:14837,Testability,log,log,14837,"lementPath_t &path1, const RElementPath_t &path2)Compare two paths, Returns number of elements matches in both paths.Definition RElement.cxx:145; ROOT::Browsable::RElement::ParsePathstatic RElementPath_t ParsePath(const std::string &str)Parse string path to produce RElementPath_t One should avoid to use string pathes as much as possible...Definition RElement.cxx:116; ROOT::Browsable::RItemRepresentation of single item in the browser.Definition RItem.hxx:23; ROOT::Browsable::RProvider::Browsestatic std::shared_ptr< RElement > Browse(std::unique_ptr< RHolder > &obj)Create browsable element for the object Created element may take ownership over the object.Definition RProvider.cxx:273; ROOT::Browsable::RSysFile::ProvideTopEntriesstatic RElementPath_t ProvideTopEntries(std::shared_ptr< RGroup > &comp, const std::string &workdir="""")Provide top entries for file system On windows it is list of existing drivers, on Linux it is ""File s...Definition RSysFile.cxx:533; ROOT::Experimental::RLogChannelA log configuration for a channel, e.g.Definition RLogger.hxx:101; ROOT::RBrowserDataCleanupDefinition RBrowserData.cxx:43; ROOT::RBrowserDataCleanup::fDataRBrowserData & fDataDefinition RBrowserData.cxx:45; ROOT::RBrowserDataCleanup::RBrowserDataCleanupRBrowserDataCleanup(RBrowserData &_data)Definition RBrowserData.cxx:48; ROOT::RBrowserDataCleanup::RecursiveRemovevoid RecursiveRemove(TObject *obj) overrideRecursively remove this object from a list.Definition RBrowserData.cxx:50; ROOT::RBrowserDataWay to browse (hopefully) everything in ROOT.Definition RBrowserData.hxx:37; ROOT::RBrowserData::SetTopElementvoid SetTopElement(std::shared_ptr< Browsable::RElement > elem)set top element for browsingDefinition RBrowserData.cxx:88; ROOT::RBrowserData::fLastSortedItemsstd::vector< const Browsable::RItem * > fLastSortedItems! sorted child items, used in requestsDefinition RBrowserData.hxx:51; ROOT::RBrowserData::fWorkingPathBrowsable::RElementPath_t fWorkingPath! path showed in BreadcrumbDef",MatchSource.WIKI,doc/master/RBrowserData_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RBrowserData_8cxx_source.html
https://root.cern/doc/master/RBrowserData_8cxx_source.html:4542,Usability,clear,clear,4542,"15 auto elem_root = Browsable::RProvider::Browse(rootfold);; 116 if (elem_root); 117 comp->Add(std::make_shared<Browsable::RWrapper>(""root"", elem_root));; 118 ; 119 std::unique_ptr<Browsable::RHolder> rootfiles = std::make_unique<Browsable::TObjectHolder>(gROOT->GetListOfFiles(), kFALSE);; 120 auto elem_files = Browsable::RProvider::Browse(rootfiles);; 121 if (elem_files) {; 122 auto files = std::make_shared<Browsable::RWrapper>(""ROOT Files"", elem_files);; 123 files->SetExpandByDefault(true);; 124 comp->Add(files);; 125 // if there are any open files, make them visible by default; 126 if (elem_files->GetNumChilds() > 0); 127 seldir = {};; 128 }; 129 ; 130 SetTopElement(comp);; 131 ; 132 SetWorkingPath(seldir);; 133}; 134 ; 135/////////////////////////////////////////////////////////////////////; 136/// Reset all data correspondent to last request; 137 ; 138void RBrowserData::ResetLastRequestData(bool with_element); 139{; 140 fLastAllChilds = false;; 141 fLastSortedItems.clear();; 142 fLastSortMethod.clear();; 143 fLastItems.clear();; 144 if (with_element) {; 145 fLastPath.clear();; 146 fLastElement.reset();; 147 }; 148}; 149 ; 150/////////////////////////////////////////////////////////////////////////; 151/// Decompose path to elements; 152/// Returns array of names for each element in the path, first element either ""/"" or "".""; 153/// If returned array empty - it is error; 154 ; 155Browsable::RElementPath_t RBrowserData::DecomposePath(const std::string &strpath, bool relative_to_work_element); 156{; 157 Browsable::RElementPath_t arr;; 158 if (relative_to_work_element) arr = fWorkingPath;; 159 ; 160 if (strpath.empty()); 161 return arr;; 162 ; 163 auto arr2 = Browsable::RElement::ParsePath(strpath);; 164 arr.insert(arr.end(), arr2.begin(), arr2.end());; 165 return arr;; 166}; 167 ; 168/////////////////////////////////////////////////////////////////////////; 169/// Process browser request; 170 ; 171bool RBrowserData::ProcessBrowserRequest(const RBrowserRequest &requ",MatchSource.WIKI,doc/master/RBrowserData_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RBrowserData_8cxx_source.html
https://root.cern/doc/master/RBrowserData_8cxx_source.html:4572,Usability,clear,clear,4572,"le::RProvider::Browse(rootfold);; 116 if (elem_root); 117 comp->Add(std::make_shared<Browsable::RWrapper>(""root"", elem_root));; 118 ; 119 std::unique_ptr<Browsable::RHolder> rootfiles = std::make_unique<Browsable::TObjectHolder>(gROOT->GetListOfFiles(), kFALSE);; 120 auto elem_files = Browsable::RProvider::Browse(rootfiles);; 121 if (elem_files) {; 122 auto files = std::make_shared<Browsable::RWrapper>(""ROOT Files"", elem_files);; 123 files->SetExpandByDefault(true);; 124 comp->Add(files);; 125 // if there are any open files, make them visible by default; 126 if (elem_files->GetNumChilds() > 0); 127 seldir = {};; 128 }; 129 ; 130 SetTopElement(comp);; 131 ; 132 SetWorkingPath(seldir);; 133}; 134 ; 135/////////////////////////////////////////////////////////////////////; 136/// Reset all data correspondent to last request; 137 ; 138void RBrowserData::ResetLastRequestData(bool with_element); 139{; 140 fLastAllChilds = false;; 141 fLastSortedItems.clear();; 142 fLastSortMethod.clear();; 143 fLastItems.clear();; 144 if (with_element) {; 145 fLastPath.clear();; 146 fLastElement.reset();; 147 }; 148}; 149 ; 150/////////////////////////////////////////////////////////////////////////; 151/// Decompose path to elements; 152/// Returns array of names for each element in the path, first element either ""/"" or "".""; 153/// If returned array empty - it is error; 154 ; 155Browsable::RElementPath_t RBrowserData::DecomposePath(const std::string &strpath, bool relative_to_work_element); 156{; 157 Browsable::RElementPath_t arr;; 158 if (relative_to_work_element) arr = fWorkingPath;; 159 ; 160 if (strpath.empty()); 161 return arr;; 162 ; 163 auto arr2 = Browsable::RElement::ParsePath(strpath);; 164 arr.insert(arr.end(), arr2.begin(), arr2.end());; 165 return arr;; 166}; 167 ; 168/////////////////////////////////////////////////////////////////////////; 169/// Process browser request; 170 ; 171bool RBrowserData::ProcessBrowserRequest(const RBrowserRequest &request, RBrowserReply &reply); ",MatchSource.WIKI,doc/master/RBrowserData_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RBrowserData_8cxx_source.html
https://root.cern/doc/master/RBrowserData_8cxx_source.html:4597,Usability,clear,clear,4597," if (elem_root); 117 comp->Add(std::make_shared<Browsable::RWrapper>(""root"", elem_root));; 118 ; 119 std::unique_ptr<Browsable::RHolder> rootfiles = std::make_unique<Browsable::TObjectHolder>(gROOT->GetListOfFiles(), kFALSE);; 120 auto elem_files = Browsable::RProvider::Browse(rootfiles);; 121 if (elem_files) {; 122 auto files = std::make_shared<Browsable::RWrapper>(""ROOT Files"", elem_files);; 123 files->SetExpandByDefault(true);; 124 comp->Add(files);; 125 // if there are any open files, make them visible by default; 126 if (elem_files->GetNumChilds() > 0); 127 seldir = {};; 128 }; 129 ; 130 SetTopElement(comp);; 131 ; 132 SetWorkingPath(seldir);; 133}; 134 ; 135/////////////////////////////////////////////////////////////////////; 136/// Reset all data correspondent to last request; 137 ; 138void RBrowserData::ResetLastRequestData(bool with_element); 139{; 140 fLastAllChilds = false;; 141 fLastSortedItems.clear();; 142 fLastSortMethod.clear();; 143 fLastItems.clear();; 144 if (with_element) {; 145 fLastPath.clear();; 146 fLastElement.reset();; 147 }; 148}; 149 ; 150/////////////////////////////////////////////////////////////////////////; 151/// Decompose path to elements; 152/// Returns array of names for each element in the path, first element either ""/"" or "".""; 153/// If returned array empty - it is error; 154 ; 155Browsable::RElementPath_t RBrowserData::DecomposePath(const std::string &strpath, bool relative_to_work_element); 156{; 157 Browsable::RElementPath_t arr;; 158 if (relative_to_work_element) arr = fWorkingPath;; 159 ; 160 if (strpath.empty()); 161 return arr;; 162 ; 163 auto arr2 = Browsable::RElement::ParsePath(strpath);; 164 arr.insert(arr.end(), arr2.begin(), arr2.end());; 165 return arr;; 166}; 167 ; 168/////////////////////////////////////////////////////////////////////////; 169/// Process browser request; 170 ; 171bool RBrowserData::ProcessBrowserRequest(const RBrowserRequest &request, RBrowserReply &reply); 172{; 173 auto path = fWorkingPath;; ",MatchSource.WIKI,doc/master/RBrowserData_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RBrowserData_8cxx_source.html
https://root.cern/doc/master/RBrowserData_8cxx_source.html:4646,Usability,clear,clear,4646,"ke_shared<Browsable::RWrapper>(""root"", elem_root));; 118 ; 119 std::unique_ptr<Browsable::RHolder> rootfiles = std::make_unique<Browsable::TObjectHolder>(gROOT->GetListOfFiles(), kFALSE);; 120 auto elem_files = Browsable::RProvider::Browse(rootfiles);; 121 if (elem_files) {; 122 auto files = std::make_shared<Browsable::RWrapper>(""ROOT Files"", elem_files);; 123 files->SetExpandByDefault(true);; 124 comp->Add(files);; 125 // if there are any open files, make them visible by default; 126 if (elem_files->GetNumChilds() > 0); 127 seldir = {};; 128 }; 129 ; 130 SetTopElement(comp);; 131 ; 132 SetWorkingPath(seldir);; 133}; 134 ; 135/////////////////////////////////////////////////////////////////////; 136/// Reset all data correspondent to last request; 137 ; 138void RBrowserData::ResetLastRequestData(bool with_element); 139{; 140 fLastAllChilds = false;; 141 fLastSortedItems.clear();; 142 fLastSortMethod.clear();; 143 fLastItems.clear();; 144 if (with_element) {; 145 fLastPath.clear();; 146 fLastElement.reset();; 147 }; 148}; 149 ; 150/////////////////////////////////////////////////////////////////////////; 151/// Decompose path to elements; 152/// Returns array of names for each element in the path, first element either ""/"" or "".""; 153/// If returned array empty - it is error; 154 ; 155Browsable::RElementPath_t RBrowserData::DecomposePath(const std::string &strpath, bool relative_to_work_element); 156{; 157 Browsable::RElementPath_t arr;; 158 if (relative_to_work_element) arr = fWorkingPath;; 159 ; 160 if (strpath.empty()); 161 return arr;; 162 ; 163 auto arr2 = Browsable::RElement::ParsePath(strpath);; 164 arr.insert(arr.end(), arr2.begin(), arr2.end());; 165 return arr;; 166}; 167 ; 168/////////////////////////////////////////////////////////////////////////; 169/// Process browser request; 170 ; 171bool RBrowserData::ProcessBrowserRequest(const RBrowserRequest &request, RBrowserReply &reply); 172{; 173 auto path = fWorkingPath;; 174 path.insert(path.end(), request.pa",MatchSource.WIKI,doc/master/RBrowserData_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RBrowserData_8cxx_source.html
https://root.cern/doc/master/RBrowserData_8cxx_source.html:6546,Usability,clear,clear,6546," RBrowserReply &reply); 172{; 173 auto path = fWorkingPath;; 174 path.insert(path.end(), request.path.begin(), request.path.end());; 175 ; 176 if ((path != fLastPath) || !fLastElement) {; 177 ; 178 auto elem = GetSubElement(path);; 179 if (!elem) return false;; 180 ; 181 ResetLastRequestData(true);; 182 ; 183 fLastPath = path;; 184 fLastElement = std::move(elem);; 185 ; 186 fLastElement->cd(); // set element active; 187 } else if (request.reload) {; 188 // only reload items from element, not need to reset element itself; 189 ResetLastRequestData(false);; 190 }; 191 ; 192 // when request childs, always try to make elements; 193 if (fLastItems.empty()) {; 194 ; 195 auto iter = fLastElement->GetChildsIter();; 196 ; 197 if (!iter) return false;; 198 int id = 0;; 199 fLastAllChilds = true;; 200 ; 201 while (iter->Next() && fLastAllChilds) {; 202 fLastItems.emplace_back(iter->CreateItem());; 203 if (id++ > 10000); 204 fLastAllChilds = false;; 205 }; 206 ; 207 fLastSortedItems.clear();; 208 fLastSortMethod.clear();; 209 }; 210 ; 211 // create sorted array; 212 if ((fLastSortedItems.size() != fLastItems.size()) ||; 213 (fLastSortMethod != request.sort) ||; 214 (fLastSortReverse != request.reverse)) {; 215 fLastSortedItems.resize(fLastItems.size(), nullptr);; 216 int id = 0;; 217 if (request.sort.empty()) {; 218 // no sorting, just move all folders up; 219 for (auto &item : fLastItems); 220 if (item->IsFolder()); 221 fLastSortedItems[id++] = item.get();; 222 for (auto &item : fLastItems); 223 if (!item->IsFolder()); 224 fLastSortedItems[id++] = item.get();; 225 } else {; 226 // copy items; 227 for (auto &item : fLastItems); 228 fLastSortedItems[id++] = item.get();; 229 ; 230 if (request.sort != ""unsorted""); 231 std::sort(fLastSortedItems.begin(), fLastSortedItems.end(),; 232 [request](const Browsable::RItem *a, const Browsable::RItem *b) { return a ? a->Compare(b, request.sort) : !b; });; 233 }; 234 ; 235 if (request.reverse); 236 std::reverse(fLastSortedItems.begin(), fLast",MatchSource.WIKI,doc/master/RBrowserData_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RBrowserData_8cxx_source.html
https://root.cern/doc/master/RBrowserData_8cxx_source.html:6576,Usability,clear,clear,6576,"gPath;; 174 path.insert(path.end(), request.path.begin(), request.path.end());; 175 ; 176 if ((path != fLastPath) || !fLastElement) {; 177 ; 178 auto elem = GetSubElement(path);; 179 if (!elem) return false;; 180 ; 181 ResetLastRequestData(true);; 182 ; 183 fLastPath = path;; 184 fLastElement = std::move(elem);; 185 ; 186 fLastElement->cd(); // set element active; 187 } else if (request.reload) {; 188 // only reload items from element, not need to reset element itself; 189 ResetLastRequestData(false);; 190 }; 191 ; 192 // when request childs, always try to make elements; 193 if (fLastItems.empty()) {; 194 ; 195 auto iter = fLastElement->GetChildsIter();; 196 ; 197 if (!iter) return false;; 198 int id = 0;; 199 fLastAllChilds = true;; 200 ; 201 while (iter->Next() && fLastAllChilds) {; 202 fLastItems.emplace_back(iter->CreateItem());; 203 if (id++ > 10000); 204 fLastAllChilds = false;; 205 }; 206 ; 207 fLastSortedItems.clear();; 208 fLastSortMethod.clear();; 209 }; 210 ; 211 // create sorted array; 212 if ((fLastSortedItems.size() != fLastItems.size()) ||; 213 (fLastSortMethod != request.sort) ||; 214 (fLastSortReverse != request.reverse)) {; 215 fLastSortedItems.resize(fLastItems.size(), nullptr);; 216 int id = 0;; 217 if (request.sort.empty()) {; 218 // no sorting, just move all folders up; 219 for (auto &item : fLastItems); 220 if (item->IsFolder()); 221 fLastSortedItems[id++] = item.get();; 222 for (auto &item : fLastItems); 223 if (!item->IsFolder()); 224 fLastSortedItems[id++] = item.get();; 225 } else {; 226 // copy items; 227 for (auto &item : fLastItems); 228 fLastSortedItems[id++] = item.get();; 229 ; 230 if (request.sort != ""unsorted""); 231 std::sort(fLastSortedItems.begin(), fLastSortedItems.end(),; 232 [request](const Browsable::RItem *a, const Browsable::RItem *b) { return a ? a->Compare(b, request.sort) : !b; });; 233 }; 234 ; 235 if (request.reverse); 236 std::reverse(fLastSortedItems.begin(), fLastSortedItems.end());; 237 ; 238 fLastSortMethod = reque",MatchSource.WIKI,doc/master/RBrowserData_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RBrowserData_8cxx_source.html
https://root.cern/doc/master/RBrowserData_8cxx_source.html:11445,Usability,clear,clear,11445,"td::string subname = path[pos];; 339 int indx = Browsable::RElement::ExtractItemIndex(subname);; 340 ; 341 auto iter = elem->GetChildsIter();; 342 if (!iter); 343 return nullptr;; 344 ; 345 if (!iter->Find(subname, indx)) {; 346 if (indx < 0); 347 return nullptr;; 348 iter = elem->GetChildsIter();; 349 if (!iter || !iter->Find(subname)); 350 return nullptr;; 351 }; 352 ; 353 elem = iter->GetElement();; 354 ; 355 if (!elem); 356 return nullptr;; 357 ; 358 auto subpath = path;; 359 subpath.resize(pos+1);; 360 fCache.emplace_back(subpath, elem);; 361 pos++; // switch to next element; 362 }; 363 ; 364 return elem;; 365}; 366 ; 367/////////////////////////////////////////////////////////////////////////; 368/// Clear internal objects cache; 369 ; 370void RBrowserData::ClearCache(); 371{; 372 fCache.clear();; 373}; 374 ; 375/////////////////////////////////////////////////////////////////////////; 376/// Remove object from cache; 377/// If nullptr specified - removes no-longer-valid elements; 378/// Returns true if any element was removed; 379 ; 380bool RBrowserData::RemoveFromCache(void *obj); 381{; 382 unsigned pos = 0;; 383 ; 384 bool isany = false;; 385 ; 386 while (pos < fCache.size()) {; 387 if (obj ? !fCache[pos].second->IsObject(obj) : fCache[pos].second->CheckValid()) {; 388 pos++;; 389 continue;; 390 }; 391 ; 392 isany = true;; 393 auto path = fCache[pos].first;; 394 fCache.erase(fCache.begin() + pos);; 395 if (RemoveFromCache(path)); 396 pos = 0; // start scan from the beginning; 397 }; 398 ; 399 return isany;; 400}; 401 ; 402/////////////////////////////////////////////////////////////////////////; 403/// Remove path (and all sub-paths) from cache; 404/// Returns true if any element was removed; 405 ; 406bool RBrowserData::RemoveFromCache(const Browsable::RElementPath_t &path); 407{; 408 if (path.size() == 0); 409 return false;; 410 ; 411 bool isany = false;; 412 unsigned pos = 0;; 413 while (pos < fCache.size()) {; 414 if (Browsable::RElement::ComparePaths(pat",MatchSource.WIKI,doc/master/RBrowserData_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RBrowserData_8cxx_source.html
https://root.cern/doc/master/RCanvas_8cxx_source.html:3905,Availability,avail,available,3905,"/////////////////////////////////////////////////////////////; 87/// Create new canvas instance; 88 ; 89std::shared_ptr<ROOT::Experimental::RCanvas> ROOT::Experimental::RCanvas::Create(const std::string &title); 90{; 91 auto pCanvas = std::make_shared<RCanvas>();; 92 pCanvas->SetTitle(title);; 93 {; 94 std::lock_guard<std::mutex> grd(GetHeldCanvasesMutex());; 95 GetHeldCanvases().emplace_back(pCanvas);; 96 }; 97 ; 98 return pCanvas;; 99}; 100 ; 101//////////////////////////////////////////////////////////////////////////; 102/// Create new display for the canvas; 103/// The parameter `where` specifies which program could be used for display creation; 104/// Possible values:; 105///; 106/// - `cef` Chromium Embeded Framework, local display, local communication; 107/// - `qt5` Qt5 WebEngine (when running via rootqt5), local display, local communication; 108/// - `browser` default system web-browser, communication via random http port from range 8800 - 9800; 109/// - `<prog>` any program name which will be started instead of default browser, like firefox or /usr/bin/opera; 110/// one could also specify $url in program name, which will be replaced with canvas URL; 111/// - `native` either any available local display or default browser; 112///; 113/// Canvas can be displayed in several different places; 114 ; 115void ROOT::Experimental::RCanvas::Show(const std::string &where); 116{; 117 fShown = true;; 118 ; 119 // Do not display canvas in batch mode; 120 if (gROOT->IsWebDisplayBatch()); 121 return;; 122 ; 123 if (fPainter) {; 124 bool isany = (fPainter->NumDisplays() > 0);; 125 ; 126 if (!where.empty()); 127 fPainter->NewDisplay(where);; 128 ; 129 if (isany) return;; 130 }; 131 ; 132 if (!fModified); 133 fModified = 1; // 0 is special value, means no changes and no drawings; 134 ; 135 if (!fPainter); 136 fPainter = Internal::RVirtualCanvasPainter::Create(*this);; 137 ; 138 if (fPainter) {; 139 fPainter->NewDisplay(where);; 140 fPainter->CanvasUpdated(fModified, true, nul",MatchSource.WIKI,doc/master/RCanvas_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RCanvas_8cxx_source.html
https://root.cern/doc/master/RCanvas_8cxx_source.html:10678,Availability,mask,mask,10678,"4//////////////////////////////////////////////////////////////////////////; 295/// To resolve problem with storing of shared pointers; 296/// Call this method when reading canvas from the file; 297/// Can be called many times - after reinitialization of shared pointers no changes will be performed; 298 ; 299void ROOT::Experimental::RCanvas::ResolveSharedPtrs(); 300{; 301 Internal::RIOSharedVector_t vect;; 302 ; 303 CollectShared(vect);; 304 ; 305 for (unsigned n = 0; n < vect.size(); ++n) {; 306 if (vect[n]->HasShared() || !vect[n]->GetIOPtr()) continue;; 307 ; 308 auto shrd_ptr = vect[n]->MakeShared();; 309 ; 310 for (auto n2 = n+1; n2 < vect.size(); ++n2) {; 311 if (vect[n2]->GetIOPtr() == vect[n]->GetIOPtr()) {; 312 if (vect[n2]->HasShared()); 313 R__LOG_ERROR(GPadLog()) << ""FATAL Shared pointer for same IO ptr already exists"";; 314 else; 315 vect[n2]->SetShared(shrd_ptr);; 316 }; 317 }; 318 ; 319 }; 320}; 321 ; 322 ; 323/////////////////////////////////////////////////////////////////////////////////////////////////; 324/// Apply attributes changes to the drawable; 325/// Return mask with actions which were really applied; 326 ; 327std::unique_ptr<ROOT::Experimental::RDrawableReply> ROOT::Experimental::RChangeAttrRequest::Process(); 328{; 329 // suppress all changes coming from non-main connection; 330 if (!GetContext().IsMainConn()); 331 return nullptr;; 332 ; 333 auto canv = const_cast<ROOT::Experimental::RCanvas *>(GetContext().GetCanvas());; 334 if (!canv) return nullptr;; 335 ; 336 if ((ids.size() != names.size()) || (ids.size() != values.size())) {; 337 R__LOG_ERROR(GPadLog()) << ""Mismatch of arrays size in RChangeAttrRequest"";; 338 return nullptr;; 339 }; 340 ; 341 Version_t vers = 0;; 342 ; 343 for(int indx = 0; indx < (int) ids.size(); indx++) {; 344 if (ids[indx] == ""canvas"") {; 345 if (canv->GetAttrMap().Change(names[indx], values[indx].get())) {; 346 if (!vers) vers = canv->IncModified();; 347 canv->SetDrawableVersion(vers);; 348 }; 349 } else {; 35",MatchSource.WIKI,doc/master/RCanvas_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RCanvas_8cxx_source.html
https://root.cern/doc/master/RCanvas_8cxx_source.html:16307,Availability,mask,mask,16307,"cModified()Definition RCanvas.hxx:82; ROOT::Experimental::RCanvas::GetUIDstd::string GetUID() constReturn unique identifier for the canvas Used in iPython display.Definition RCanvas.cxx:199; ROOT::Experimental::RCanvas::CreateJSONstd::string CreateJSON()Provide JSON which can be used for offline display.Definition RCanvas.cxx:211; ROOT::Experimental::RCanvas::Createstatic std::shared_ptr< RCanvas > Create(const std::string &title)Create new canvas instance.Definition RCanvas.cxx:89; ROOT::Experimental::RCanvas::ClearOnClosevoid ClearOnClose(const std::shared_ptr< void > &handle)Set handle which will be cleared when connection is closed.Definition RCanvas.cxx:239; ROOT::Experimental::RCanvas::Updatevoid Update(bool async=false, CanvasCallback_t callback=nullptr)update drawingDefinition RCanvas.cxx:78; ROOT::Experimental::RCanvas::Hidevoid Hide()Hide all canvas displays.Definition RCanvas.cxx:171; ROOT::Experimental::RChangeAttrRequest::Processstd::unique_ptr< RDrawableReply > Process() overrideApply attributes changes to the drawable Return mask with actions which were really applied.Definition RCanvas.cxx:327; TStringBasic string class.Definition TString.h:139; TString::Dataconst char * Data() constDefinition TString.h:376; TString::HashUInt_t Hash(ECaseCompare cmp=kExact) constReturn hash value.Definition TString.cxx:677; TString::Formatstatic TString Format(const char *fmt,...)Static method which formats a string using a printf style format descriptor and return a TString.Definition TString.cxx:2378; int; nconst Int_t nDefinition legend1.C:16; ROOT::Experimental::Internal::RIOSharedVector_tstd::vector< RIOSharedBase * > RIOSharedVector_tDefinition RDrawable.hxx:52; ROOT::Experimental::CanvasCallback_tstd::function< void(bool)> CanvasCallback_tDefinition RVirtualCanvasPainter.hxx:22; ROOT::Experimental::GPadLogRLogChannel & GPadLog()Log channel for GPad diagnostics.Definition RAttrBase.cxx:17. graf2dgpadv7srcRCanvas.cxx. ROOT master - Reference Guide Generated on T",MatchSource.WIKI,doc/master/RCanvas_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RCanvas_8cxx_source.html
https://root.cern/doc/master/RCanvas_8cxx_source.html:11870,Deployability,update,update,11870,"; 328{; 329 // suppress all changes coming from non-main connection; 330 if (!GetContext().IsMainConn()); 331 return nullptr;; 332 ; 333 auto canv = const_cast<ROOT::Experimental::RCanvas *>(GetContext().GetCanvas());; 334 if (!canv) return nullptr;; 335 ; 336 if ((ids.size() != names.size()) || (ids.size() != values.size())) {; 337 R__LOG_ERROR(GPadLog()) << ""Mismatch of arrays size in RChangeAttrRequest"";; 338 return nullptr;; 339 }; 340 ; 341 Version_t vers = 0;; 342 ; 343 for(int indx = 0; indx < (int) ids.size(); indx++) {; 344 if (ids[indx] == ""canvas"") {; 345 if (canv->GetAttrMap().Change(names[indx], values[indx].get())) {; 346 if (!vers) vers = canv->IncModified();; 347 canv->SetDrawableVersion(vers);; 348 }; 349 } else {; 350 auto drawable = canv->FindPrimitiveByDisplayId(ids[indx]);; 351 if (drawable && drawable->GetAttrMap().Change(names[indx], values[indx].get())) {; 352 if (!vers) vers = canv->IncModified();; 353 drawable->SetDrawableVersion(vers);; 354 }; 355 }; 356 }; 357 ; 358 fNeedUpdate = (vers > 0) && update;; 359 ; 360 return nullptr; // no need for any reply; 361}; 362 ; RCanvas.hxx; RLogger.hxx; R__LOG_ERROR#define R__LOG_ERROR(...)Definition RLogger.hxx:362; updatestatic void update(gsl_integration_workspace *workspace, double a1, double b1, double area1, double error1, double a2, double b2, double area2, double error2)Definition RooAdaptiveGaussKronrodIntegrator1D.cxx:633; Version_tshort Version_tDefinition RtypesCore.h:65; filenameOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t Float_t Float_t Int_t Int_t UInt_t UInt_t Rectangle_t Int_t Int_t Window_t TString Int_t GCValues_t GetPrimarySelectionOwner GetDisplay GetScreen GetColormap GetNativeEvent const char const char dpyName wid window const char font_name cursor keysym reg const char only_if_exist regb h Point_t winding char text",MatchSource.WIKI,doc/master/RCanvas_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RCanvas_8cxx_source.html
https://root.cern/doc/master/RCanvas_8cxx_source.html:12034,Deployability,update,updatestatic,12034,"size() != values.size())) {; 337 R__LOG_ERROR(GPadLog()) << ""Mismatch of arrays size in RChangeAttrRequest"";; 338 return nullptr;; 339 }; 340 ; 341 Version_t vers = 0;; 342 ; 343 for(int indx = 0; indx < (int) ids.size(); indx++) {; 344 if (ids[indx] == ""canvas"") {; 345 if (canv->GetAttrMap().Change(names[indx], values[indx].get())) {; 346 if (!vers) vers = canv->IncModified();; 347 canv->SetDrawableVersion(vers);; 348 }; 349 } else {; 350 auto drawable = canv->FindPrimitiveByDisplayId(ids[indx]);; 351 if (drawable && drawable->GetAttrMap().Change(names[indx], values[indx].get())) {; 352 if (!vers) vers = canv->IncModified();; 353 drawable->SetDrawableVersion(vers);; 354 }; 355 }; 356 }; 357 ; 358 fNeedUpdate = (vers > 0) && update;; 359 ; 360 return nullptr; // no need for any reply; 361}; 362 ; RCanvas.hxx; RLogger.hxx; R__LOG_ERROR#define R__LOG_ERROR(...)Definition RLogger.hxx:362; updatestatic void update(gsl_integration_workspace *workspace, double a1, double b1, double area1, double error1, double a2, double b2, double area2, double error2)Definition RooAdaptiveGaussKronrodIntegrator1D.cxx:633; Version_tshort Version_tDefinition RtypesCore.h:65; filenameOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t Float_t Float_t Int_t Int_t UInt_t UInt_t Rectangle_t Int_t Int_t Window_t TString Int_t GCValues_t GetPrimarySelectionOwner GetDisplay GetScreen GetColormap GetNativeEvent const char const char dpyName wid window const char font_name cursor keysym reg const char only_if_exist regb h Point_t winding char text const char depth char const char Int_t count const char ColorStruct_t color const char filenameDefinition TGWin32VirtualXProxy.cxx:232; widthOption_t Option_t widthDefinition TGWin32VirtualXProxy.cxx:56; heightOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLi",MatchSource.WIKI,doc/master/RCanvas_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RCanvas_8cxx_source.html
https://root.cern/doc/master/RCanvas_8cxx_source.html:12052,Deployability,update,update,12052,"size() != values.size())) {; 337 R__LOG_ERROR(GPadLog()) << ""Mismatch of arrays size in RChangeAttrRequest"";; 338 return nullptr;; 339 }; 340 ; 341 Version_t vers = 0;; 342 ; 343 for(int indx = 0; indx < (int) ids.size(); indx++) {; 344 if (ids[indx] == ""canvas"") {; 345 if (canv->GetAttrMap().Change(names[indx], values[indx].get())) {; 346 if (!vers) vers = canv->IncModified();; 347 canv->SetDrawableVersion(vers);; 348 }; 349 } else {; 350 auto drawable = canv->FindPrimitiveByDisplayId(ids[indx]);; 351 if (drawable && drawable->GetAttrMap().Change(names[indx], values[indx].get())) {; 352 if (!vers) vers = canv->IncModified();; 353 drawable->SetDrawableVersion(vers);; 354 }; 355 }; 356 }; 357 ; 358 fNeedUpdate = (vers > 0) && update;; 359 ; 360 return nullptr; // no need for any reply; 361}; 362 ; RCanvas.hxx; RLogger.hxx; R__LOG_ERROR#define R__LOG_ERROR(...)Definition RLogger.hxx:362; updatestatic void update(gsl_integration_workspace *workspace, double a1, double b1, double area1, double error1, double a2, double b2, double area2, double error2)Definition RooAdaptiveGaussKronrodIntegrator1D.cxx:633; Version_tshort Version_tDefinition RtypesCore.h:65; filenameOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t Float_t Float_t Int_t Int_t UInt_t UInt_t Rectangle_t Int_t Int_t Window_t TString Int_t GCValues_t GetPrimarySelectionOwner GetDisplay GetScreen GetColormap GetNativeEvent const char const char dpyName wid window const char font_name cursor keysym reg const char only_if_exist regb h Point_t winding char text const char depth char const char Int_t count const char ColorStruct_t color const char filenameDefinition TGWin32VirtualXProxy.cxx:232; widthOption_t Option_t widthDefinition TGWin32VirtualXProxy.cxx:56; heightOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLi",MatchSource.WIKI,doc/master/RCanvas_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RCanvas_8cxx_source.html
https://root.cern/doc/master/RCanvas_8cxx_source.html:16022,Deployability,update,update,16022," Call this method when reading canvas from the file...Definition RCanvas.cxx:299; ROOT::Experimental::RCanvas::Runvoid Run(double tm=0.)Run canvas functionality for given time (in seconds)Definition RCanvas.cxx:285; ROOT::Experimental::RCanvas::IncModifieduint64_t IncModified()Definition RCanvas.hxx:82; ROOT::Experimental::RCanvas::GetUIDstd::string GetUID() constReturn unique identifier for the canvas Used in iPython display.Definition RCanvas.cxx:199; ROOT::Experimental::RCanvas::CreateJSONstd::string CreateJSON()Provide JSON which can be used for offline display.Definition RCanvas.cxx:211; ROOT::Experimental::RCanvas::Createstatic std::shared_ptr< RCanvas > Create(const std::string &title)Create new canvas instance.Definition RCanvas.cxx:89; ROOT::Experimental::RCanvas::ClearOnClosevoid ClearOnClose(const std::shared_ptr< void > &handle)Set handle which will be cleared when connection is closed.Definition RCanvas.cxx:239; ROOT::Experimental::RCanvas::Updatevoid Update(bool async=false, CanvasCallback_t callback=nullptr)update drawingDefinition RCanvas.cxx:78; ROOT::Experimental::RCanvas::Hidevoid Hide()Hide all canvas displays.Definition RCanvas.cxx:171; ROOT::Experimental::RChangeAttrRequest::Processstd::unique_ptr< RDrawableReply > Process() overrideApply attributes changes to the drawable Return mask with actions which were really applied.Definition RCanvas.cxx:327; TStringBasic string class.Definition TString.h:139; TString::Dataconst char * Data() constDefinition TString.h:376; TString::HashUInt_t Hash(ECaseCompare cmp=kExact) constReturn hash value.Definition TString.cxx:677; TString::Formatstatic TString Format(const char *fmt,...)Static method which formats a string using a printf style format descriptor and return a TString.Definition TString.cxx:2378; int; nconst Int_t nDefinition legend1.C:16; ROOT::Experimental::Internal::RIOSharedVector_tstd::vector< RIOSharedBase * > RIOSharedVector_tDefinition RDrawable.hxx:52; ROOT::Experimental::CanvasCallback_tst",MatchSource.WIKI,doc/master/RCanvas_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RCanvas_8cxx_source.html
https://root.cern/doc/master/RCanvas_8cxx_source.html:13482,Modifiability,plugin,plugin,13482,"GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t Float_t Float_t Int_t Int_t UInt_t UInt_t Rectangle_t Int_t Int_t Window_t TString Int_t GCValues_t GetPrimarySelectionOwner GetDisplay GetScreen GetColormap GetNativeEvent const char const char dpyName wid window const char font_name cursor keysym reg const char only_if_exist regb h Point_t winding char text const char depth char const char Int_t count const char ColorStruct_t color const char filenameDefinition TGWin32VirtualXProxy.cxx:232; widthOption_t Option_t widthDefinition TGWin32VirtualXProxy.cxx:56; heightOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t heightDefinition TGWin32VirtualXProxy.cxx:164; TList.h; TROOT.h; gROOT#define gROOTDefinition TROOT.h:406; TString.h; ROOT::Experimental::Internal::RVirtualCanvasPainter::Createstatic std::unique_ptr< RVirtualCanvasPainter > Create(RCanvas &canv)Loads the plugin that implements this class.Definition RVirtualCanvasPainter.cxx:42; ROOT::Experimental::RCanvasA window's topmost RPad.Definition RCanvas.hxx:47; ROOT::Experimental::RCanvas::GetCanvasesstatic const std::vector< std::shared_ptr< RCanvas > > GetCanvases()Returns list of created canvases.Definition RCanvas.cxx:45; ROOT::Experimental::RCanvas::ReleaseHeldCanvasesstatic void ReleaseHeldCanvases()Release list of held canvases pointers If no other shared pointers exists on the canvas,...Definition RCanvas.cxx:56; ROOT::Experimental::RCanvas::SaveAsbool SaveAs(const std::string &filename)Save canvas in image file.Definition RCanvas.cxx:181; ROOT::Experimental::RCanvas::GetWindowUrlstd::string GetWindowUrl(bool remote)Returns window URL which can be used for connection.Definition RCanvas.cxx:159; ROOT::Experimental::RCanvas::IsModifiedbool IsModified() constReturns true is canvas was modified since last painting.Definition RCanvas.cxx",MatchSource.WIKI,doc/master/RCanvas_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RCanvas_8cxx_source.html
https://root.cern/doc/master/RCanvas_8cxx_source.html:8383,Performance,perform,performed,8383,"Experimental::RCanvas::Remove(); 226{; 227 std::lock_guard<std::mutex> grd(GetHeldCanvasesMutex());; 228 auto &held = GetHeldCanvases();; 229 auto indx = held.size();; 230 while (indx-- > 0) {; 231 if (held[indx].get() == this); 232 held.erase(held.begin() + indx);; 233 }; 234}; 235 ; 236//////////////////////////////////////////////////////////////////////////////////////////////; 237/// Set handle which will be cleared when connection is closed; 238 ; 239void ROOT::Experimental::RCanvas::ClearOnClose(const std::shared_ptr<void> &handle); 240{; 241 if (fPainter); 242 fPainter->SetClearOnClose(handle);; 243}; 244 ; 245//////////////////////////////////////////////////////////////////////////; 246/// Run canvas functionality for the given time (in seconds); 247/// Used to process canvas-related actions in the appropriate thread context.; 248/// Must be regularly called when canvas created and used in extra thread.; 249/// Time parameter specifies minimal execution time in seconds - if default value 0 is used,; 250/// just all pending actions will be performed.; 251/// When canvas is not yet displayed - just performs sleep for given time interval.; 252///; 253/// Example of usage:; 254///; 255/// ~~~ {.cpp}; 256/// void draw_canvas(bool &run_loop, std::make_shared<RH1D> hist); 257/// {; 258/// auto canvas = RCanvas::Create(""Canvas title"");; 259/// canvas->Draw(hist)->SetLineColor(RColor::kBlue);; 260/// canvas->Show();; 261/// while (run_loop) {; 262/// pHist->Fill(1);; 263/// canvas->Modified();; 264/// canvas->Update();; 265/// canvas->Run(0.1); // process canvas events; 266/// }; 267///; 268/// canvas->Remove();; 269/// }; 270///; 271/// int main(); 272/// {; 273/// RAxisConfig xaxis(100, -10., 10.);; 274/// auto pHist = std::make_shared<RH1D>(xaxis);; 275/// bool run_loop = true;; 276///; 277/// std::thread thrd(draw_canvas, run_loop, pHist);; 278/// std::this_thread::sleep_for(std::chrono::seconds(100));; 279/// run_loop = false;; 280/// thrd.join();; 281/// retur",MatchSource.WIKI,doc/master/RCanvas_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RCanvas_8cxx_source.html
https://root.cern/doc/master/RCanvas_8cxx_source.html:8442,Performance,perform,performs,8442,"etHeldCanvases();; 229 auto indx = held.size();; 230 while (indx-- > 0) {; 231 if (held[indx].get() == this); 232 held.erase(held.begin() + indx);; 233 }; 234}; 235 ; 236//////////////////////////////////////////////////////////////////////////////////////////////; 237/// Set handle which will be cleared when connection is closed; 238 ; 239void ROOT::Experimental::RCanvas::ClearOnClose(const std::shared_ptr<void> &handle); 240{; 241 if (fPainter); 242 fPainter->SetClearOnClose(handle);; 243}; 244 ; 245//////////////////////////////////////////////////////////////////////////; 246/// Run canvas functionality for the given time (in seconds); 247/// Used to process canvas-related actions in the appropriate thread context.; 248/// Must be regularly called when canvas created and used in extra thread.; 249/// Time parameter specifies minimal execution time in seconds - if default value 0 is used,; 250/// just all pending actions will be performed.; 251/// When canvas is not yet displayed - just performs sleep for given time interval.; 252///; 253/// Example of usage:; 254///; 255/// ~~~ {.cpp}; 256/// void draw_canvas(bool &run_loop, std::make_shared<RH1D> hist); 257/// {; 258/// auto canvas = RCanvas::Create(""Canvas title"");; 259/// canvas->Draw(hist)->SetLineColor(RColor::kBlue);; 260/// canvas->Show();; 261/// while (run_loop) {; 262/// pHist->Fill(1);; 263/// canvas->Modified();; 264/// canvas->Update();; 265/// canvas->Run(0.1); // process canvas events; 266/// }; 267///; 268/// canvas->Remove();; 269/// }; 270///; 271/// int main(); 272/// {; 273/// RAxisConfig xaxis(100, -10., 10.);; 274/// auto pHist = std::make_shared<RH1D>(xaxis);; 275/// bool run_loop = true;; 276///; 277/// std::thread thrd(draw_canvas, run_loop, pHist);; 278/// std::this_thread::sleep_for(std::chrono::seconds(100));; 279/// run_loop = false;; 280/// thrd.join();; 281/// return 0;; 282/// }; 283/// ~~~; 284 ; 285void ROOT::Experimental::RCanvas::Run(double tm); 286{; 287 if (fPainter) {; 288 ",MatchSource.WIKI,doc/master/RCanvas_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RCanvas_8cxx_source.html
https://root.cern/doc/master/RCanvas_8cxx_source.html:9867,Performance,perform,performed,9867," 259/// canvas->Draw(hist)->SetLineColor(RColor::kBlue);; 260/// canvas->Show();; 261/// while (run_loop) {; 262/// pHist->Fill(1);; 263/// canvas->Modified();; 264/// canvas->Update();; 265/// canvas->Run(0.1); // process canvas events; 266/// }; 267///; 268/// canvas->Remove();; 269/// }; 270///; 271/// int main(); 272/// {; 273/// RAxisConfig xaxis(100, -10., 10.);; 274/// auto pHist = std::make_shared<RH1D>(xaxis);; 275/// bool run_loop = true;; 276///; 277/// std::thread thrd(draw_canvas, run_loop, pHist);; 278/// std::this_thread::sleep_for(std::chrono::seconds(100));; 279/// run_loop = false;; 280/// thrd.join();; 281/// return 0;; 282/// }; 283/// ~~~; 284 ; 285void ROOT::Experimental::RCanvas::Run(double tm); 286{; 287 if (fPainter) {; 288 fPainter->Run(tm);; 289 } else if (tm>0) {; 290 std::this_thread::sleep_for(std::chrono::milliseconds(int(tm*1000)));; 291 }; 292}; 293 ; 294//////////////////////////////////////////////////////////////////////////; 295/// To resolve problem with storing of shared pointers; 296/// Call this method when reading canvas from the file; 297/// Can be called many times - after reinitialization of shared pointers no changes will be performed; 298 ; 299void ROOT::Experimental::RCanvas::ResolveSharedPtrs(); 300{; 301 Internal::RIOSharedVector_t vect;; 302 ; 303 CollectShared(vect);; 304 ; 305 for (unsigned n = 0; n < vect.size(); ++n) {; 306 if (vect[n]->HasShared() || !vect[n]->GetIOPtr()) continue;; 307 ; 308 auto shrd_ptr = vect[n]->MakeShared();; 309 ; 310 for (auto n2 = n+1; n2 < vect.size(); ++n2) {; 311 if (vect[n2]->GetIOPtr() == vect[n]->GetIOPtr()) {; 312 if (vect[n2]->HasShared()); 313 R__LOG_ERROR(GPadLog()) << ""FATAL Shared pointer for same IO ptr already exists"";; 314 else; 315 vect[n2]->SetShared(shrd_ptr);; 316 }; 317 }; 318 ; 319 }; 320}; 321 ; 322 ; 323/////////////////////////////////////////////////////////////////////////////////////////////////; 324/// Apply attributes changes to the drawable; 325/// Return m",MatchSource.WIKI,doc/master/RCanvas_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RCanvas_8cxx_source.html
https://root.cern/doc/master/RCanvas_8cxx_source.html:6564,Security,hash,hash,6564,"::RCanvas::GetWindowUrl(bool remote); 160{; 161 if (fPainter); 162 return fPainter->GetWindowUrl(remote);; 163 ; 164 return """";; 165}; 166 ; 167 ; 168//////////////////////////////////////////////////////////////////////////; 169/// Hide all canvas displays; 170 ; 171void ROOT::Experimental::RCanvas::Hide(); 172{; 173 if (fPainter); 174 fPainter = nullptr;; 175}; 176 ; 177//////////////////////////////////////////////////////////////////////////; 178/// Create image file for the canvas; 179/// Supported SVG (extension .svg), JPEG (extension .jpg or .jpeg), PNG (extension .png) or JSON (extension .json); 180 ; 181bool ROOT::Experimental::RCanvas::SaveAs(const std::string &filename); 182{; 183 if (!fPainter); 184 fPainter = Internal::RVirtualCanvasPainter::Create(*this);; 185 ; 186 if (!fPainter); 187 return false;; 188 ; 189 int width = GetWidth();; 190 int height = GetHeight();; 191 ; 192 return fPainter->ProduceBatchOutput(filename, width > 1 ? width : 800, height > 1 ? height : 600);; 193}; 194 ; 195//////////////////////////////////////////////////////////////////////////; 196/// Return unique identifier for the canvas; 197/// Used in iPython display; 198 ; 199std::string ROOT::Experimental::RCanvas::GetUID() const; 200{; 201 const void *ptr = this;; 202 auto hash = TString::Hash(&ptr, sizeof(void*));; 203 TString fmt = TString::Format(""rcanv_%x"", hash);; 204 return fmt.Data();; 205}; 206 ; 207//////////////////////////////////////////////////////////////////////////; 208/// Create JSON data for the canvas; 209/// Can be used of offline display with JSROOT; 210 ; 211std::string ROOT::Experimental::RCanvas::CreateJSON(); 212{; 213 if (!fPainter); 214 fPainter = Internal::RVirtualCanvasPainter::Create(*this);; 215 ; 216 if (!fPainter); 217 return """";; 218 ; 219 return fPainter->ProduceJSON();; 220}; 221 ; 222//////////////////////////////////////////////////////////////////////////; 223/// Remove canvas from global canvas lists, will be destroyed once last shared_p",MatchSource.WIKI,doc/master/RCanvas_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RCanvas_8cxx_source.html
https://root.cern/doc/master/RCanvas_8cxx_source.html:6654,Security,hash,hash,6654,"::RCanvas::GetWindowUrl(bool remote); 160{; 161 if (fPainter); 162 return fPainter->GetWindowUrl(remote);; 163 ; 164 return """";; 165}; 166 ; 167 ; 168//////////////////////////////////////////////////////////////////////////; 169/// Hide all canvas displays; 170 ; 171void ROOT::Experimental::RCanvas::Hide(); 172{; 173 if (fPainter); 174 fPainter = nullptr;; 175}; 176 ; 177//////////////////////////////////////////////////////////////////////////; 178/// Create image file for the canvas; 179/// Supported SVG (extension .svg), JPEG (extension .jpg or .jpeg), PNG (extension .png) or JSON (extension .json); 180 ; 181bool ROOT::Experimental::RCanvas::SaveAs(const std::string &filename); 182{; 183 if (!fPainter); 184 fPainter = Internal::RVirtualCanvasPainter::Create(*this);; 185 ; 186 if (!fPainter); 187 return false;; 188 ; 189 int width = GetWidth();; 190 int height = GetHeight();; 191 ; 192 return fPainter->ProduceBatchOutput(filename, width > 1 ? width : 800, height > 1 ? height : 600);; 193}; 194 ; 195//////////////////////////////////////////////////////////////////////////; 196/// Return unique identifier for the canvas; 197/// Used in iPython display; 198 ; 199std::string ROOT::Experimental::RCanvas::GetUID() const; 200{; 201 const void *ptr = this;; 202 auto hash = TString::Hash(&ptr, sizeof(void*));; 203 TString fmt = TString::Format(""rcanv_%x"", hash);; 204 return fmt.Data();; 205}; 206 ; 207//////////////////////////////////////////////////////////////////////////; 208/// Create JSON data for the canvas; 209/// Can be used of offline display with JSROOT; 210 ; 211std::string ROOT::Experimental::RCanvas::CreateJSON(); 212{; 213 if (!fPainter); 214 fPainter = Internal::RVirtualCanvasPainter::Create(*this);; 215 ; 216 if (!fPainter); 217 return """";; 218 ; 219 return fPainter->ProduceJSON();; 220}; 221 ; 222//////////////////////////////////////////////////////////////////////////; 223/// Remove canvas from global canvas lists, will be destroyed once last shared_p",MatchSource.WIKI,doc/master/RCanvas_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RCanvas_8cxx_source.html
https://root.cern/doc/master/RCanvas_8cxx_source.html:16557,Security,hash,hash,16557,"anvas::GetUIDstd::string GetUID() constReturn unique identifier for the canvas Used in iPython display.Definition RCanvas.cxx:199; ROOT::Experimental::RCanvas::CreateJSONstd::string CreateJSON()Provide JSON which can be used for offline display.Definition RCanvas.cxx:211; ROOT::Experimental::RCanvas::Createstatic std::shared_ptr< RCanvas > Create(const std::string &title)Create new canvas instance.Definition RCanvas.cxx:89; ROOT::Experimental::RCanvas::ClearOnClosevoid ClearOnClose(const std::shared_ptr< void > &handle)Set handle which will be cleared when connection is closed.Definition RCanvas.cxx:239; ROOT::Experimental::RCanvas::Updatevoid Update(bool async=false, CanvasCallback_t callback=nullptr)update drawingDefinition RCanvas.cxx:78; ROOT::Experimental::RCanvas::Hidevoid Hide()Hide all canvas displays.Definition RCanvas.cxx:171; ROOT::Experimental::RChangeAttrRequest::Processstd::unique_ptr< RDrawableReply > Process() overrideApply attributes changes to the drawable Return mask with actions which were really applied.Definition RCanvas.cxx:327; TStringBasic string class.Definition TString.h:139; TString::Dataconst char * Data() constDefinition TString.h:376; TString::HashUInt_t Hash(ECaseCompare cmp=kExact) constReturn hash value.Definition TString.cxx:677; TString::Formatstatic TString Format(const char *fmt,...)Static method which formats a string using a printf style format descriptor and return a TString.Definition TString.cxx:2378; int; nconst Int_t nDefinition legend1.C:16; ROOT::Experimental::Internal::RIOSharedVector_tstd::vector< RIOSharedBase * > RIOSharedVector_tDefinition RDrawable.hxx:52; ROOT::Experimental::CanvasCallback_tstd::function< void(bool)> CanvasCallback_tDefinition RVirtualCanvasPainter.hxx:22; ROOT::Experimental::GPadLogRLogChannel & GPadLog()Log channel for GPad diagnostics.Definition RAttrBase.cxx:17. graf2dgpadv7srcRCanvas.cxx. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:40:18 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/RCanvas_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RCanvas_8cxx_source.html
https://root.cern/doc/master/RCanvas_8cxx_source.html:7735,Usability,clear,cleared,7735,"; 210 ; 211std::string ROOT::Experimental::RCanvas::CreateJSON(); 212{; 213 if (!fPainter); 214 fPainter = Internal::RVirtualCanvasPainter::Create(*this);; 215 ; 216 if (!fPainter); 217 return """";; 218 ; 219 return fPainter->ProduceJSON();; 220}; 221 ; 222//////////////////////////////////////////////////////////////////////////; 223/// Remove canvas from global canvas lists, will be destroyed once last shared_ptr is disappear; 224 ; 225void ROOT::Experimental::RCanvas::Remove(); 226{; 227 std::lock_guard<std::mutex> grd(GetHeldCanvasesMutex());; 228 auto &held = GetHeldCanvases();; 229 auto indx = held.size();; 230 while (indx-- > 0) {; 231 if (held[indx].get() == this); 232 held.erase(held.begin() + indx);; 233 }; 234}; 235 ; 236//////////////////////////////////////////////////////////////////////////////////////////////; 237/// Set handle which will be cleared when connection is closed; 238 ; 239void ROOT::Experimental::RCanvas::ClearOnClose(const std::shared_ptr<void> &handle); 240{; 241 if (fPainter); 242 fPainter->SetClearOnClose(handle);; 243}; 244 ; 245//////////////////////////////////////////////////////////////////////////; 246/// Run canvas functionality for the given time (in seconds); 247/// Used to process canvas-related actions in the appropriate thread context.; 248/// Must be regularly called when canvas created and used in extra thread.; 249/// Time parameter specifies minimal execution time in seconds - if default value 0 is used,; 250/// just all pending actions will be performed.; 251/// When canvas is not yet displayed - just performs sleep for given time interval.; 252///; 253/// Example of usage:; 254///; 255/// ~~~ {.cpp}; 256/// void draw_canvas(bool &run_loop, std::make_shared<RH1D> hist); 257/// {; 258/// auto canvas = RCanvas::Create(""Canvas title"");; 259/// canvas->Draw(hist)->SetLineColor(RColor::kBlue);; 260/// canvas->Show();; 261/// while (run_loop) {; 262/// pHist->Fill(1);; 263/// canvas->Modified();; 264/// canvas->Update();; 2",MatchSource.WIKI,doc/master/RCanvas_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RCanvas_8cxx_source.html
https://root.cern/doc/master/RCanvas_8cxx_source.html:15861,Usability,clear,cleared,15861,"ed_ptr will be removed.Definition RCanvas.cxx:225; ROOT::Experimental::RCanvas::ResolveSharedPtrsvoid ResolveSharedPtrs()To resolve problem with storing of shared pointers Call this method when reading canvas from the file...Definition RCanvas.cxx:299; ROOT::Experimental::RCanvas::Runvoid Run(double tm=0.)Run canvas functionality for given time (in seconds)Definition RCanvas.cxx:285; ROOT::Experimental::RCanvas::IncModifieduint64_t IncModified()Definition RCanvas.hxx:82; ROOT::Experimental::RCanvas::GetUIDstd::string GetUID() constReturn unique identifier for the canvas Used in iPython display.Definition RCanvas.cxx:199; ROOT::Experimental::RCanvas::CreateJSONstd::string CreateJSON()Provide JSON which can be used for offline display.Definition RCanvas.cxx:211; ROOT::Experimental::RCanvas::Createstatic std::shared_ptr< RCanvas > Create(const std::string &title)Create new canvas instance.Definition RCanvas.cxx:89; ROOT::Experimental::RCanvas::ClearOnClosevoid ClearOnClose(const std::shared_ptr< void > &handle)Set handle which will be cleared when connection is closed.Definition RCanvas.cxx:239; ROOT::Experimental::RCanvas::Updatevoid Update(bool async=false, CanvasCallback_t callback=nullptr)update drawingDefinition RCanvas.cxx:78; ROOT::Experimental::RCanvas::Hidevoid Hide()Hide all canvas displays.Definition RCanvas.cxx:171; ROOT::Experimental::RChangeAttrRequest::Processstd::unique_ptr< RDrawableReply > Process() overrideApply attributes changes to the drawable Return mask with actions which were really applied.Definition RCanvas.cxx:327; TStringBasic string class.Definition TString.h:139; TString::Dataconst char * Data() constDefinition TString.h:376; TString::HashUInt_t Hash(ECaseCompare cmp=kExact) constReturn hash value.Definition TString.cxx:677; TString::Formatstatic TString Format(const char *fmt,...)Static method which formats a string using a printf style format descriptor and return a TString.Definition TString.cxx:2378; int; nconst Int_t nDefinition lege",MatchSource.WIKI,doc/master/RCanvas_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RCanvas_8cxx_source.html
https://root.cern/doc/master/RCanvas_8hxx_source.html:14986,Availability,mask,mask,14986,"RCanvas.hxx:27; ROOT::Experimental::RChangeAttrRequest::namesstd::vector< std::string > namesarray of attribute namesDefinition RCanvas.hxx:26; ROOT::Experimental::RChangeAttrRequest::idsstd::vector< std::string > idsarray of idsDefinition RCanvas.hxx:25; ROOT::Experimental::RChangeAttrRequest::~RChangeAttrRequest~RChangeAttrRequest() override=default; ROOT::Experimental::RChangeAttrRequest::NeedCanvasUpdatebool NeedCanvasUpdate() const overrideDefinition RCanvas.hxx:36; ROOT::Experimental::RChangeAttrRequest::RChangeAttrRequestRChangeAttrRequest()=default; ROOT::Experimental::RChangeAttrRequest::fNeedUpdatebool fNeedUpdate! is canvas update requiredDefinition RCanvas.hxx:29; ROOT::Experimental::RChangeAttrRequest::operator=RChangeAttrRequest & operator=(const RChangeAttrRequest &)=delete; ROOT::Experimental::RChangeAttrRequest::updatebool updateupdate canvas at the endDefinition RCanvas.hxx:28; ROOT::Experimental::RChangeAttrRequest::Processstd::unique_ptr< RDrawableReply > Process() overrideApply attributes changes to the drawable Return mask with actions which were really applied.Definition RCanvas.cxx:327; ROOT::Experimental::RChangeAttrRequest::RChangeAttrRequestRChangeAttrRequest(const RChangeAttrRequest &)=delete; ROOT::Experimental::RDrawableRequestBase class for requests which can be submitted from the clients.Definition RDrawableRequest.hxx:50; ROOT::Experimental::RDrawable::Version_tuint64_t Version_tDefinition RDrawable.hxx:123; ROOT::Experimental::RPadBaseBase class for graphic containers for RDrawable-s.Definition RPadBase.hxx:37; ROOT::Experimental::RPadBase::SetDrawableVersionvoid SetDrawableVersion(Version_t vers) overrideAssign drawable version - for pad itself and all primitives.Definition RPadBase.cxx:238; ROOT::Experimental::CanvasCallback_tstd::function< void(bool)> CanvasCallback_tDefinition RVirtualCanvasPainter.hxx:22; ROOTtbb::task_arena is an alias of tbb::interface7::task_arena, which doesn't allow to forward declare tb...Definition EExecu",MatchSource.WIKI,doc/master/RCanvas_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RCanvas_8hxx_source.html
https://root.cern/doc/master/RCanvas_8hxx_source.html:1142,Deployability,update,update,1142,"**************************************************; 2 * Copyright (C) 1995-2015, Rene Brun and Fons Rademakers. *; 3 * All rights reserved. *; 4 * *; 5 * For the licensing terms see $ROOTSYS/LICENSE. *; 6 * For the list of contributors see $ROOTSYS/README/CREDITS. *; 7 *************************************************************************/; 8 ; 9#ifndef ROOT7_RCanvas; 10#define ROOT7_RCanvas; 11 ; 12#include ""ROOT/RPadBase.hxx""; 13#include ""ROOT/RVirtualCanvasPainter.hxx""; 14#include ""ROOT/RDrawableRequest.hxx""; 15 ; 16#include <memory>; 17#include <string>; 18#include <vector>; 19#include <list>; 20 ; 21namespace ROOT {; 22namespace Experimental {; 23 ; 24class RChangeAttrRequest : public RDrawableRequest {; 25 std::vector<std::string> ids; ///< array of ids; 26 std::vector<std::string> names; ///< array of attribute names; 27 std::vector<std::unique_ptr<RAttrMap::Value_t>> values; ///< array of values; 28 bool update{true}; ///< update canvas at the end; 29 bool fNeedUpdate{false}; ///<! is canvas update required; 30 RChangeAttrRequest(const RChangeAttrRequest &) = delete;; 31 RChangeAttrRequest& operator=(const RChangeAttrRequest &) = delete;; 32public:; 33 RChangeAttrRequest() = default; // for I/O; 34 ~RChangeAttrRequest() override = default;; 35 std::unique_ptr<RDrawableReply> Process() override;; 36 bool NeedCanvasUpdate() const override { return fNeedUpdate; }; 37};; 38 ; 39/** \class RCanvas; 40\ingroup GpadROOT7; 41\brief A window's topmost `RPad`.; 42\author Axel Naumann <axel@cern.ch>; 43\date 2015-07-08; 44\warning This is part of the ROOT 7 prototype! It will change without notice. It might trigger earthquakes. Feedback is welcome!; 45*/; 46 ; 47class RCanvas: public RPadBase {; 48friend class RPadBase; /// use for ID generation; 49friend class RCanvasPainter; /// used for primitives drawing; 50friend class RChangeAttrRequest; /// to apply attributes changes; 51private:; 52 /// Title of the canvas.; 53 std::string fTitle;; 54 ; 55 /// Width of the c",MatchSource.WIKI,doc/master/RCanvas_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RCanvas_8hxx_source.html
https://root.cern/doc/master/RCanvas_8hxx_source.html:1161,Deployability,update,update,1161,"**************************************************; 2 * Copyright (C) 1995-2015, Rene Brun and Fons Rademakers. *; 3 * All rights reserved. *; 4 * *; 5 * For the licensing terms see $ROOTSYS/LICENSE. *; 6 * For the list of contributors see $ROOTSYS/README/CREDITS. *; 7 *************************************************************************/; 8 ; 9#ifndef ROOT7_RCanvas; 10#define ROOT7_RCanvas; 11 ; 12#include ""ROOT/RPadBase.hxx""; 13#include ""ROOT/RVirtualCanvasPainter.hxx""; 14#include ""ROOT/RDrawableRequest.hxx""; 15 ; 16#include <memory>; 17#include <string>; 18#include <vector>; 19#include <list>; 20 ; 21namespace ROOT {; 22namespace Experimental {; 23 ; 24class RChangeAttrRequest : public RDrawableRequest {; 25 std::vector<std::string> ids; ///< array of ids; 26 std::vector<std::string> names; ///< array of attribute names; 27 std::vector<std::unique_ptr<RAttrMap::Value_t>> values; ///< array of values; 28 bool update{true}; ///< update canvas at the end; 29 bool fNeedUpdate{false}; ///<! is canvas update required; 30 RChangeAttrRequest(const RChangeAttrRequest &) = delete;; 31 RChangeAttrRequest& operator=(const RChangeAttrRequest &) = delete;; 32public:; 33 RChangeAttrRequest() = default; // for I/O; 34 ~RChangeAttrRequest() override = default;; 35 std::unique_ptr<RDrawableReply> Process() override;; 36 bool NeedCanvasUpdate() const override { return fNeedUpdate; }; 37};; 38 ; 39/** \class RCanvas; 40\ingroup GpadROOT7; 41\brief A window's topmost `RPad`.; 42\author Axel Naumann <axel@cern.ch>; 43\date 2015-07-08; 44\warning This is part of the ROOT 7 prototype! It will change without notice. It might trigger earthquakes. Feedback is welcome!; 45*/; 46 ; 47class RCanvas: public RPadBase {; 48friend class RPadBase; /// use for ID generation; 49friend class RCanvasPainter; /// used for primitives drawing; 50friend class RChangeAttrRequest; /// to apply attributes changes; 51private:; 52 /// Title of the canvas.; 53 std::string fTitle;; 54 ; 55 /// Width of the c",MatchSource.WIKI,doc/master/RCanvas_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RCanvas_8hxx_source.html
https://root.cern/doc/master/RCanvas_8hxx_source.html:1231,Deployability,update,update,1231,"**************************************************; 2 * Copyright (C) 1995-2015, Rene Brun and Fons Rademakers. *; 3 * All rights reserved. *; 4 * *; 5 * For the licensing terms see $ROOTSYS/LICENSE. *; 6 * For the list of contributors see $ROOTSYS/README/CREDITS. *; 7 *************************************************************************/; 8 ; 9#ifndef ROOT7_RCanvas; 10#define ROOT7_RCanvas; 11 ; 12#include ""ROOT/RPadBase.hxx""; 13#include ""ROOT/RVirtualCanvasPainter.hxx""; 14#include ""ROOT/RDrawableRequest.hxx""; 15 ; 16#include <memory>; 17#include <string>; 18#include <vector>; 19#include <list>; 20 ; 21namespace ROOT {; 22namespace Experimental {; 23 ; 24class RChangeAttrRequest : public RDrawableRequest {; 25 std::vector<std::string> ids; ///< array of ids; 26 std::vector<std::string> names; ///< array of attribute names; 27 std::vector<std::unique_ptr<RAttrMap::Value_t>> values; ///< array of values; 28 bool update{true}; ///< update canvas at the end; 29 bool fNeedUpdate{false}; ///<! is canvas update required; 30 RChangeAttrRequest(const RChangeAttrRequest &) = delete;; 31 RChangeAttrRequest& operator=(const RChangeAttrRequest &) = delete;; 32public:; 33 RChangeAttrRequest() = default; // for I/O; 34 ~RChangeAttrRequest() override = default;; 35 std::unique_ptr<RDrawableReply> Process() override;; 36 bool NeedCanvasUpdate() const override { return fNeedUpdate; }; 37};; 38 ; 39/** \class RCanvas; 40\ingroup GpadROOT7; 41\brief A window's topmost `RPad`.; 42\author Axel Naumann <axel@cern.ch>; 43\date 2015-07-08; 44\warning This is part of the ROOT 7 prototype! It will change without notice. It might trigger earthquakes. Feedback is welcome!; 45*/; 46 ; 47class RCanvas: public RPadBase {; 48friend class RPadBase; /// use for ID generation; 49friend class RCanvasPainter; /// used for primitives drawing; 50friend class RChangeAttrRequest; /// to apply attributes changes; 51private:; 52 /// Title of the canvas.; 53 std::string fTitle;; 54 ; 55 /// Width of the c",MatchSource.WIKI,doc/master/RCanvas_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RCanvas_8hxx_source.html
https://root.cern/doc/master/RCanvas_8hxx_source.html:5452,Deployability,update,updated,5452,"eight; 114 int GetHeight() const { return fHeight; }; 115 ; 116 /// Display the canvas.; 117 void Show(const std::string &where = """");; 118 ; 119 /// returns true if Show() method was called; 120 bool IsShown() const { return fShown; }; 121 ; 122 /// clear IsShown() flag; 123 void ClearShown() { fShown = false; }; 124 ; 125 /// Returns window name used to display canvas; 126 std::string GetWindowAddr() const;; 127 ; 128 /// Returns window URL which can be used for connection; 129 std::string GetWindowUrl(bool remote);; 130 ; 131 /// Hide all canvas displays; 132 void Hide();; 133 ; 134 /// Remove canvas from global canvas lists, will be destroyed when shared_ptr will be removed; 135 void Remove();; 136 ; 137 /// Insert panel into the canvas, canvas should be shown at this moment; 138 template <class PANEL>; 139 bool AddPanel(std::shared_ptr<PANEL> &panel); 140 {; 141 if (!fPainter) return false;; 142 return fPainter->AddPanel(panel->GetWindow());; 143 }; 144 ; 145 /// Get modify counter; 146 uint64_t GetModified() const { return fModified; }; 147 ; 148 // Set newest version to all primitives; 149 void Modified() { SetDrawableVersion(IncModified()); }; 150 ; 151 /// Set newest version to specified drawable; 152 void Modified(std::shared_ptr<RDrawable> drawable); 153 {; 154 // TODO: may be check that drawable belong to the canvas; 155 if (drawable); 156 drawable->SetDrawableVersion(IncModified());; 157 }; 158 ; 159 // Return if canvas was modified and not yet updated; 160 bool IsModified() const;; 161 ; 162 /// update drawing; 163 void Update(bool async = false, CanvasCallback_t callback = nullptr);; 164 ; 165 /// returns true if Update() method was called; 166 bool IsUpdated() const { return fUpdated; }; 167 ; 168 /// clear IsUpdated() flag; 169 void ClearUpdated() { fUpdated = false; }; 170 ; 171 /// Run canvas functionality for given time (in seconds); 172 void Run(double tm = 0.);; 173 ; 174 /// Save canvas in image file; 175 bool SaveAs(const std::string &filenam",MatchSource.WIKI,doc/master/RCanvas_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RCanvas_8hxx_source.html
https://root.cern/doc/master/RCanvas_8hxx_source.html:5505,Deployability,update,update,5505,"eight; 114 int GetHeight() const { return fHeight; }; 115 ; 116 /// Display the canvas.; 117 void Show(const std::string &where = """");; 118 ; 119 /// returns true if Show() method was called; 120 bool IsShown() const { return fShown; }; 121 ; 122 /// clear IsShown() flag; 123 void ClearShown() { fShown = false; }; 124 ; 125 /// Returns window name used to display canvas; 126 std::string GetWindowAddr() const;; 127 ; 128 /// Returns window URL which can be used for connection; 129 std::string GetWindowUrl(bool remote);; 130 ; 131 /// Hide all canvas displays; 132 void Hide();; 133 ; 134 /// Remove canvas from global canvas lists, will be destroyed when shared_ptr will be removed; 135 void Remove();; 136 ; 137 /// Insert panel into the canvas, canvas should be shown at this moment; 138 template <class PANEL>; 139 bool AddPanel(std::shared_ptr<PANEL> &panel); 140 {; 141 if (!fPainter) return false;; 142 return fPainter->AddPanel(panel->GetWindow());; 143 }; 144 ; 145 /// Get modify counter; 146 uint64_t GetModified() const { return fModified; }; 147 ; 148 // Set newest version to all primitives; 149 void Modified() { SetDrawableVersion(IncModified()); }; 150 ; 151 /// Set newest version to specified drawable; 152 void Modified(std::shared_ptr<RDrawable> drawable); 153 {; 154 // TODO: may be check that drawable belong to the canvas; 155 if (drawable); 156 drawable->SetDrawableVersion(IncModified());; 157 }; 158 ; 159 // Return if canvas was modified and not yet updated; 160 bool IsModified() const;; 161 ; 162 /// update drawing; 163 void Update(bool async = false, CanvasCallback_t callback = nullptr);; 164 ; 165 /// returns true if Update() method was called; 166 bool IsUpdated() const { return fUpdated; }; 167 ; 168 /// clear IsUpdated() flag; 169 void ClearUpdated() { fUpdated = false; }; 170 ; 171 /// Run canvas functionality for given time (in seconds); 172 void Run(double tm = 0.);; 173 ; 174 /// Save canvas in image file; 175 bool SaveAs(const std::string &filenam",MatchSource.WIKI,doc/master/RCanvas_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RCanvas_8hxx_source.html
https://root.cern/doc/master/RCanvas_8hxx_source.html:14573,Deployability,update,update,14573,dvoid ClearUpdated()clear IsUpdated() flagDefinition RCanvas.hxx:169; ROOT::Experimental::RCanvas::~RCanvas~RCanvas() override=default; ROOT::Experimental::RCanvas::Hidevoid Hide()Hide all canvas displays.Definition RCanvas.cxx:171; ROOT::Experimental::RChangeAttrRequestDefinition RCanvas.hxx:24; ROOT::Experimental::RChangeAttrRequest::valuesstd::vector< std::unique_ptr< RAttrMap::Value_t > > valuesarray of valuesDefinition RCanvas.hxx:27; ROOT::Experimental::RChangeAttrRequest::namesstd::vector< std::string > namesarray of attribute namesDefinition RCanvas.hxx:26; ROOT::Experimental::RChangeAttrRequest::idsstd::vector< std::string > idsarray of idsDefinition RCanvas.hxx:25; ROOT::Experimental::RChangeAttrRequest::~RChangeAttrRequest~RChangeAttrRequest() override=default; ROOT::Experimental::RChangeAttrRequest::NeedCanvasUpdatebool NeedCanvasUpdate() const overrideDefinition RCanvas.hxx:36; ROOT::Experimental::RChangeAttrRequest::RChangeAttrRequestRChangeAttrRequest()=default; ROOT::Experimental::RChangeAttrRequest::fNeedUpdatebool fNeedUpdate! is canvas update requiredDefinition RCanvas.hxx:29; ROOT::Experimental::RChangeAttrRequest::operator=RChangeAttrRequest & operator=(const RChangeAttrRequest &)=delete; ROOT::Experimental::RChangeAttrRequest::updatebool updateupdate canvas at the endDefinition RCanvas.hxx:28; ROOT::Experimental::RChangeAttrRequest::Processstd::unique_ptr< RDrawableReply > Process() overrideApply attributes changes to the drawable Return mask with actions which were really applied.Definition RCanvas.cxx:327; ROOT::Experimental::RChangeAttrRequest::RChangeAttrRequestRChangeAttrRequest(const RChangeAttrRequest &)=delete; ROOT::Experimental::RDrawableRequestBase class for requests which can be submitted from the clients.Definition RDrawableRequest.hxx:50; ROOT::Experimental::RDrawable::Version_tuint64_t Version_tDefinition RDrawable.hxx:123; ROOT::Experimental::RPadBaseBase class for graphic containers for RDrawable-s.Definition RPadBase.hxx:37; RO,MatchSource.WIKI,doc/master/RCanvas_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RCanvas_8hxx_source.html
https://root.cern/doc/master/RCanvas_8hxx_source.html:14771,Deployability,update,updatebool,14771,Canvas.cxx:171; ROOT::Experimental::RChangeAttrRequestDefinition RCanvas.hxx:24; ROOT::Experimental::RChangeAttrRequest::valuesstd::vector< std::unique_ptr< RAttrMap::Value_t > > valuesarray of valuesDefinition RCanvas.hxx:27; ROOT::Experimental::RChangeAttrRequest::namesstd::vector< std::string > namesarray of attribute namesDefinition RCanvas.hxx:26; ROOT::Experimental::RChangeAttrRequest::idsstd::vector< std::string > idsarray of idsDefinition RCanvas.hxx:25; ROOT::Experimental::RChangeAttrRequest::~RChangeAttrRequest~RChangeAttrRequest() override=default; ROOT::Experimental::RChangeAttrRequest::NeedCanvasUpdatebool NeedCanvasUpdate() const overrideDefinition RCanvas.hxx:36; ROOT::Experimental::RChangeAttrRequest::RChangeAttrRequestRChangeAttrRequest()=default; ROOT::Experimental::RChangeAttrRequest::fNeedUpdatebool fNeedUpdate! is canvas update requiredDefinition RCanvas.hxx:29; ROOT::Experimental::RChangeAttrRequest::operator=RChangeAttrRequest & operator=(const RChangeAttrRequest &)=delete; ROOT::Experimental::RChangeAttrRequest::updatebool updateupdate canvas at the endDefinition RCanvas.hxx:28; ROOT::Experimental::RChangeAttrRequest::Processstd::unique_ptr< RDrawableReply > Process() overrideApply attributes changes to the drawable Return mask with actions which were really applied.Definition RCanvas.cxx:327; ROOT::Experimental::RChangeAttrRequest::RChangeAttrRequestRChangeAttrRequest(const RChangeAttrRequest &)=delete; ROOT::Experimental::RDrawableRequestBase class for requests which can be submitted from the clients.Definition RDrawableRequest.hxx:50; ROOT::Experimental::RDrawable::Version_tuint64_t Version_tDefinition RDrawable.hxx:123; ROOT::Experimental::RPadBaseBase class for graphic containers for RDrawable-s.Definition RPadBase.hxx:37; ROOT::Experimental::RPadBase::SetDrawableVersionvoid SetDrawableVersion(Version_t vers) overrideAssign drawable version - for pad itself and all primitives.Definition RPadBase.cxx:238; ROOT::Experimental::CanvasCallbac,MatchSource.WIKI,doc/master/RCanvas_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RCanvas_8hxx_source.html
https://root.cern/doc/master/RCanvas_8hxx_source.html:14782,Deployability,update,updateupdate,14782,Canvas.cxx:171; ROOT::Experimental::RChangeAttrRequestDefinition RCanvas.hxx:24; ROOT::Experimental::RChangeAttrRequest::valuesstd::vector< std::unique_ptr< RAttrMap::Value_t > > valuesarray of valuesDefinition RCanvas.hxx:27; ROOT::Experimental::RChangeAttrRequest::namesstd::vector< std::string > namesarray of attribute namesDefinition RCanvas.hxx:26; ROOT::Experimental::RChangeAttrRequest::idsstd::vector< std::string > idsarray of idsDefinition RCanvas.hxx:25; ROOT::Experimental::RChangeAttrRequest::~RChangeAttrRequest~RChangeAttrRequest() override=default; ROOT::Experimental::RChangeAttrRequest::NeedCanvasUpdatebool NeedCanvasUpdate() const overrideDefinition RCanvas.hxx:36; ROOT::Experimental::RChangeAttrRequest::RChangeAttrRequestRChangeAttrRequest()=default; ROOT::Experimental::RChangeAttrRequest::fNeedUpdatebool fNeedUpdate! is canvas update requiredDefinition RCanvas.hxx:29; ROOT::Experimental::RChangeAttrRequest::operator=RChangeAttrRequest & operator=(const RChangeAttrRequest &)=delete; ROOT::Experimental::RChangeAttrRequest::updatebool updateupdate canvas at the endDefinition RCanvas.hxx:28; ROOT::Experimental::RChangeAttrRequest::Processstd::unique_ptr< RDrawableReply > Process() overrideApply attributes changes to the drawable Return mask with actions which were really applied.Definition RCanvas.cxx:327; ROOT::Experimental::RChangeAttrRequest::RChangeAttrRequestRChangeAttrRequest(const RChangeAttrRequest &)=delete; ROOT::Experimental::RDrawableRequestBase class for requests which can be submitted from the clients.Definition RDrawableRequest.hxx:50; ROOT::Experimental::RDrawable::Version_tuint64_t Version_tDefinition RDrawable.hxx:123; ROOT::Experimental::RPadBaseBase class for graphic containers for RDrawable-s.Definition RPadBase.hxx:37; ROOT::Experimental::RPadBase::SetDrawableVersionvoid SetDrawableVersion(Version_t vers) overrideAssign drawable version - for pad itself and all primitives.Definition RPadBase.cxx:238; ROOT::Experimental::CanvasCallbac,MatchSource.WIKI,doc/master/RCanvas_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RCanvas_8hxx_source.html
https://root.cern/doc/master/RCanvas_8hxx_source.html:4221,Usability,clear,clear,4221,"eight; 114 int GetHeight() const { return fHeight; }; 115 ; 116 /// Display the canvas.; 117 void Show(const std::string &where = """");; 118 ; 119 /// returns true if Show() method was called; 120 bool IsShown() const { return fShown; }; 121 ; 122 /// clear IsShown() flag; 123 void ClearShown() { fShown = false; }; 124 ; 125 /// Returns window name used to display canvas; 126 std::string GetWindowAddr() const;; 127 ; 128 /// Returns window URL which can be used for connection; 129 std::string GetWindowUrl(bool remote);; 130 ; 131 /// Hide all canvas displays; 132 void Hide();; 133 ; 134 /// Remove canvas from global canvas lists, will be destroyed when shared_ptr will be removed; 135 void Remove();; 136 ; 137 /// Insert panel into the canvas, canvas should be shown at this moment; 138 template <class PANEL>; 139 bool AddPanel(std::shared_ptr<PANEL> &panel); 140 {; 141 if (!fPainter) return false;; 142 return fPainter->AddPanel(panel->GetWindow());; 143 }; 144 ; 145 /// Get modify counter; 146 uint64_t GetModified() const { return fModified; }; 147 ; 148 // Set newest version to all primitives; 149 void Modified() { SetDrawableVersion(IncModified()); }; 150 ; 151 /// Set newest version to specified drawable; 152 void Modified(std::shared_ptr<RDrawable> drawable); 153 {; 154 // TODO: may be check that drawable belong to the canvas; 155 if (drawable); 156 drawable->SetDrawableVersion(IncModified());; 157 }; 158 ; 159 // Return if canvas was modified and not yet updated; 160 bool IsModified() const;; 161 ; 162 /// update drawing; 163 void Update(bool async = false, CanvasCallback_t callback = nullptr);; 164 ; 165 /// returns true if Update() method was called; 166 bool IsUpdated() const { return fUpdated; }; 167 ; 168 /// clear IsUpdated() flag; 169 void ClearUpdated() { fUpdated = false; }; 170 ; 171 /// Run canvas functionality for given time (in seconds); 172 void Run(double tm = 0.);; 173 ; 174 /// Save canvas in image file; 175 bool SaveAs(const std::string &filenam",MatchSource.WIKI,doc/master/RCanvas_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RCanvas_8hxx_source.html
https://root.cern/doc/master/RCanvas_8hxx_source.html:5717,Usability,clear,clear,5717,"eight; 114 int GetHeight() const { return fHeight; }; 115 ; 116 /// Display the canvas.; 117 void Show(const std::string &where = """");; 118 ; 119 /// returns true if Show() method was called; 120 bool IsShown() const { return fShown; }; 121 ; 122 /// clear IsShown() flag; 123 void ClearShown() { fShown = false; }; 124 ; 125 /// Returns window name used to display canvas; 126 std::string GetWindowAddr() const;; 127 ; 128 /// Returns window URL which can be used for connection; 129 std::string GetWindowUrl(bool remote);; 130 ; 131 /// Hide all canvas displays; 132 void Hide();; 133 ; 134 /// Remove canvas from global canvas lists, will be destroyed when shared_ptr will be removed; 135 void Remove();; 136 ; 137 /// Insert panel into the canvas, canvas should be shown at this moment; 138 template <class PANEL>; 139 bool AddPanel(std::shared_ptr<PANEL> &panel); 140 {; 141 if (!fPainter) return false;; 142 return fPainter->AddPanel(panel->GetWindow());; 143 }; 144 ; 145 /// Get modify counter; 146 uint64_t GetModified() const { return fModified; }; 147 ; 148 // Set newest version to all primitives; 149 void Modified() { SetDrawableVersion(IncModified()); }; 150 ; 151 /// Set newest version to specified drawable; 152 void Modified(std::shared_ptr<RDrawable> drawable); 153 {; 154 // TODO: may be check that drawable belong to the canvas; 155 if (drawable); 156 drawable->SetDrawableVersion(IncModified());; 157 }; 158 ; 159 // Return if canvas was modified and not yet updated; 160 bool IsModified() const;; 161 ; 162 /// update drawing; 163 void Update(bool async = false, CanvasCallback_t callback = nullptr);; 164 ; 165 /// returns true if Update() method was called; 166 bool IsUpdated() const { return fUpdated; }; 167 ; 168 /// clear IsUpdated() flag; 169 void ClearUpdated() { fUpdated = false; }; 170 ; 171 /// Run canvas functionality for given time (in seconds); 172 void Run(double tm = 0.);; 173 ; 174 /// Save canvas in image file; 175 bool SaveAs(const std::string &filenam",MatchSource.WIKI,doc/master/RCanvas_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RCanvas_8hxx_source.html
https://root.cern/doc/master/RCanvas_8hxx_source.html:12304,Usability,clear,clear,12304,"vas.cxx:199; ROOT::Experimental::RCanvas::CreateJSONstd::string CreateJSON()Provide JSON which can be used for offline display.Definition RCanvas.cxx:211; ROOT::Experimental::RCanvas::SetHeightvoid SetHeight(int height)Set canvas height.Definition RCanvas.hxx:108; ROOT::Experimental::RCanvas::IsShownbool IsShown() constreturns true if Show() method was calledDefinition RCanvas.hxx:120; ROOT::Experimental::RCanvas::fPainterstd::unique_ptr< Internal::RVirtualCanvasPainter > fPainterThe painter of this canvas, bootstrapping the graphics connection.Definition RCanvas.hxx:67; ROOT::Experimental::RCanvas::fWidthint fWidthWidth of the canvas in pixels.Definition RCanvas.hxx:56; ROOT::Experimental::RCanvas::fUpdatedbool fUpdatedindicate if Update() method was called beforeDefinition RCanvas.hxx:73; ROOT::Experimental::RCanvas::Createstatic std::shared_ptr< RCanvas > Create(const std::string &title)Create new canvas instance.Definition RCanvas.cxx:89; ROOT::Experimental::RCanvas::ClearShownvoid ClearShown()clear IsShown() flagDefinition RCanvas.hxx:123; ROOT::Experimental::RCanvas::ClearOnClosevoid ClearOnClose(const std::shared_ptr< void > &handle)Set handle which will be cleared when connection is closed.Definition RCanvas.cxx:239; ROOT::Experimental::RCanvas::SetWidthvoid SetWidth(int width)Set canvas width.Definition RCanvas.hxx:105; ROOT::Experimental::RCanvas::GetCanvasconst RCanvas * GetCanvas() const overrideAccess to the top-most canvas, if any (const version).Definition RCanvas.hxx:92; ROOT::Experimental::RCanvas::RCanvasRCanvas()Create a temporary RCanvas; for long-lived ones please use Create().Definition RCanvas.hxx:88; ROOT::Experimental::RCanvas::Modifiedvoid Modified(std::shared_ptr< RDrawable > drawable)Set newest version to specified drawable.Definition RCanvas.hxx:152; ROOT::Experimental::RCanvas::Modifiedvoid Modified()Definition RCanvas.hxx:149; ROOT::Experimental::RCanvas::GetWidthint GetWidth() constGet canvas width.Definition RCanvas.hxx:111; ROOT::Exp",MatchSource.WIKI,doc/master/RCanvas_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RCanvas_8hxx_source.html
https://root.cern/doc/master/RCanvas_8hxx_source.html:12474,Usability,clear,cleared,12474,"ion RCanvas.cxx:211; ROOT::Experimental::RCanvas::SetHeightvoid SetHeight(int height)Set canvas height.Definition RCanvas.hxx:108; ROOT::Experimental::RCanvas::IsShownbool IsShown() constreturns true if Show() method was calledDefinition RCanvas.hxx:120; ROOT::Experimental::RCanvas::fPainterstd::unique_ptr< Internal::RVirtualCanvasPainter > fPainterThe painter of this canvas, bootstrapping the graphics connection.Definition RCanvas.hxx:67; ROOT::Experimental::RCanvas::fWidthint fWidthWidth of the canvas in pixels.Definition RCanvas.hxx:56; ROOT::Experimental::RCanvas::fUpdatedbool fUpdatedindicate if Update() method was called beforeDefinition RCanvas.hxx:73; ROOT::Experimental::RCanvas::Createstatic std::shared_ptr< RCanvas > Create(const std::string &title)Create new canvas instance.Definition RCanvas.cxx:89; ROOT::Experimental::RCanvas::ClearShownvoid ClearShown()clear IsShown() flagDefinition RCanvas.hxx:123; ROOT::Experimental::RCanvas::ClearOnClosevoid ClearOnClose(const std::shared_ptr< void > &handle)Set handle which will be cleared when connection is closed.Definition RCanvas.cxx:239; ROOT::Experimental::RCanvas::SetWidthvoid SetWidth(int width)Set canvas width.Definition RCanvas.hxx:105; ROOT::Experimental::RCanvas::GetCanvasconst RCanvas * GetCanvas() const overrideAccess to the top-most canvas, if any (const version).Definition RCanvas.hxx:92; ROOT::Experimental::RCanvas::RCanvasRCanvas()Create a temporary RCanvas; for long-lived ones please use Create().Definition RCanvas.hxx:88; ROOT::Experimental::RCanvas::Modifiedvoid Modified(std::shared_ptr< RDrawable > drawable)Set newest version to specified drawable.Definition RCanvas.hxx:152; ROOT::Experimental::RCanvas::Modifiedvoid Modified()Definition RCanvas.hxx:149; ROOT::Experimental::RCanvas::GetWidthint GetWidth() constGet canvas width.Definition RCanvas.hxx:111; ROOT::Experimental::RCanvas::AddPanelbool AddPanel(std::shared_ptr< PANEL > &panel)Insert panel into the canvas, canvas should be shown at this",MatchSource.WIKI,doc/master/RCanvas_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RCanvas_8hxx_source.html
https://root.cern/doc/master/RCanvas_8hxx_source.html:13522,Usability,clear,clear,13522,"Definition RCanvas.cxx:239; ROOT::Experimental::RCanvas::SetWidthvoid SetWidth(int width)Set canvas width.Definition RCanvas.hxx:105; ROOT::Experimental::RCanvas::GetCanvasconst RCanvas * GetCanvas() const overrideAccess to the top-most canvas, if any (const version).Definition RCanvas.hxx:92; ROOT::Experimental::RCanvas::RCanvasRCanvas()Create a temporary RCanvas; for long-lived ones please use Create().Definition RCanvas.hxx:88; ROOT::Experimental::RCanvas::Modifiedvoid Modified(std::shared_ptr< RDrawable > drawable)Set newest version to specified drawable.Definition RCanvas.hxx:152; ROOT::Experimental::RCanvas::Modifiedvoid Modified()Definition RCanvas.hxx:149; ROOT::Experimental::RCanvas::GetWidthint GetWidth() constGet canvas width.Definition RCanvas.hxx:111; ROOT::Experimental::RCanvas::AddPanelbool AddPanel(std::shared_ptr< PANEL > &panel)Insert panel into the canvas, canvas should be shown at this moment.Definition RCanvas.hxx:139; ROOT::Experimental::RCanvas::ClearUpdatedvoid ClearUpdated()clear IsUpdated() flagDefinition RCanvas.hxx:169; ROOT::Experimental::RCanvas::~RCanvas~RCanvas() override=default; ROOT::Experimental::RCanvas::Hidevoid Hide()Hide all canvas displays.Definition RCanvas.cxx:171; ROOT::Experimental::RChangeAttrRequestDefinition RCanvas.hxx:24; ROOT::Experimental::RChangeAttrRequest::valuesstd::vector< std::unique_ptr< RAttrMap::Value_t > > valuesarray of valuesDefinition RCanvas.hxx:27; ROOT::Experimental::RChangeAttrRequest::namesstd::vector< std::string > namesarray of attribute namesDefinition RCanvas.hxx:26; ROOT::Experimental::RChangeAttrRequest::idsstd::vector< std::string > idsarray of idsDefinition RCanvas.hxx:25; ROOT::Experimental::RChangeAttrRequest::~RChangeAttrRequest~RChangeAttrRequest() override=default; ROOT::Experimental::RChangeAttrRequest::NeedCanvasUpdatebool NeedCanvasUpdate() const overrideDefinition RCanvas.hxx:36; ROOT::Experimental::RChangeAttrRequest::RChangeAttrRequestRChangeAttrRequest()=default; ROOT::Experime",MatchSource.WIKI,doc/master/RCanvas_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RCanvas_8hxx_source.html
https://root.cern/doc/master/RColor_8hxx_source.html:3631,Energy Efficiency,green,green,3631," rgb[2]); }; 81 ; 82 /** Set r/g/b components of color */; 83 void SetRGB(uint8_t r, uint8_t g, uint8_t b);; 84 ; 85 /** Set r/g/b/a components of color, a is integer between 0..255 */; 86 void SetRGBA(uint8_t r, uint8_t g, uint8_t b, uint8_t alpha);; 87 ; 88 /** Set alpha as value from range 0..255 */; 89 void SetAlpha(uint8_t alpha);; 90 ; 91 /** Set alpha as float value from range 0..1 */; 92 void SetAlphaFloat(float alpha); 93 {; 94 if (alpha <= 0.); 95 SetAlpha(0);; 96 else if (alpha >= 1.); 97 SetAlpha(255);; 98 else; 99 SetAlpha((uint8_t)(alpha * 255));; 100 }; 101 ; 102 /** Returns true if color alpha (opacity) was specified */; 103 bool HasAlpha() const { return IsRGBA(); }; 104 ; 105 /** Returns color as RGBA array, trying also convert color name into RGBA value */; 106 std::vector<uint8_t> AsRGBA() const;; 107 ; 108 /** Returns red color component 0..255 */; 109 uint8_t GetRed() const; 110 {; 111 auto rgba = AsRGBA();; 112 return rgba.size() > 2 ? rgba[0] : 0;; 113 }; 114 ; 115 /** Returns green color component 0..255 */; 116 uint8_t GetGreen() const; 117 {; 118 auto rgba = AsRGBA();; 119 return rgba.size() > 2 ? rgba[1] : 0;; 120 }; 121 ; 122 /** Returns blue color component 0..255 */; 123 uint8_t GetBlue() const; 124 {; 125 auto rgba = AsRGBA();; 126 return rgba.size() > 2 ? rgba[2] : 0;; 127 }; 128 ; 129 /** Returns color alpha (opacity) as uint8_t 0..255 */; 130 uint8_t GetAlpha() const; 131 {; 132 auto rgba = AsRGBA();; 133 return rgba.size() > 3 ? rgba[3] : 0xFF;; 134 }; 135 ; 136 /** Returns color alpha (opacity) as float from 0..1 */; 137 float GetAlphaFloat() const; 138 {; 139 return GetAlpha() / 255.;; 140 }; 141 ; 142 /** Set color as plain SVG name like ""white"" or ""lightblue"" */; 143 bool SetName(const std::string &name); 144 {; 145 fColor = name;; 146 if (!IsName()) {; 147 Clear();; 148 return false;; 149 }; 150 return true;; 151 }; 152 ; 153 void SetOrdinal(float val);; 154 float GetOrdinal() const;; 155 ; 156 /** Returns color as it stored ",MatchSource.WIKI,doc/master/RColor_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RColor_8hxx_source.html
https://root.cern/doc/master/RColor_8hxx_source.html:12543,Energy Efficiency,green,green,12543,"ition RColor.hxx:183; ROOT::Experimental::RColor::kBlackstatic R__DLLEXPORT constexpr RGB_t kBlackDefinition RColor.hxx:178; ROOT::Experimental::RColor::IsNamebool IsName() constReturns true if color specified as name.Definition RColor.cxx:75; ROOT::Experimental::RColor::kTealstatic R__DLLEXPORT constexpr RGB_t kTealDefinition RColor.hxx:187; ROOT::Experimental::RColor::kAquastatic R__DLLEXPORT constexpr RGB_t kAquaDefinition RColor.hxx:181; ROOT::Experimental::RColor::RColorRColor(uint8_t r, uint8_t g, uint8_t b)Construct color with provided r,g,b values.Definition RColor.hxx:53; ROOT::Experimental::RColor::SetColorvoid SetColor(const std::string &col)Set color as string.Definition RColor.hxx:160; ROOT::Experimental::RColor::kTransparentstatic R__DLLEXPORT constexpr float kTransparentDefinition RColor.hxx:194; ROOT::Experimental::RColor::AsStringconst std::string & AsString() constReturns color as it stored as string.Definition RColor.hxx:157; ROOT::Experimental::RColor::GetGreenuint8_t GetGreen() constReturns green color component 0..255.Definition RColor.hxx:116; ROOT::Experimental::RColor::GetAlphauint8_t GetAlpha() constReturns color alpha (opacity) as uint8_t 0..255.Definition RColor.hxx:130; ROOT::Experimental::RColor::kBluestatic R__DLLEXPORT constexpr RGB_t kBlueDefinition RColor.hxx:186; ROOT::Experimental::RColor::RColorRColor()=default; ROOT::Experimental::RColor::kNavystatic R__DLLEXPORT constexpr RGB_t kNavyDefinition RColor.hxx:185; ROOT::Experimental::RColor::AsHexstd::string AsHex(bool with_alpha=false) constReturns color value in hex format like ""66FF66"" - without any prefix Alpha parameter can be optionall...Definition RColor.cxx:275; ROOT::Experimental::RColor::Clearvoid Clear()Definition RColor.hxx:171; ROOT::Experimental::RColor::kOlivestatic R__DLLEXPORT constexpr RGB_t kOliveDefinition RColor.hxx:188; ROOT::Experimental::RColor::GetOrdinalfloat GetOrdinal() constReturn ordinal value, which was set before with SetOrdinal() call.Definition RColo",MatchSource.WIKI,doc/master/RColor_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RColor_8hxx_source.html
https://root.cern/doc/master/RColor_8hxx_source.html:819,Integrability,interface,interface,819,". ROOT: graf2d/gpadv7/inc/ROOT/RColor.hxx Source File. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. RColor.hxx. Go to the documentation of this file. 1/*************************************************************************; 2 * Copyright (C) 1995-2020, Rene Brun and Fons Rademakers. *; 3 * All rights reserved. *; 4 * *; 5 * For the licensing terms see $ROOTSYS/LICENSE. *; 6 * For the list of contributors see $ROOTSYS/README/CREDITS. *; 7 *************************************************************************/; 8 ; 9#ifndef ROOT7_RColor; 10#define ROOT7_RColor; 11 ; 12#include <cstdint>; 13#include <vector>; 14#include <string>; 15#include <array>; 16#include <DllImport.h>; 17 ; 18namespace ROOT {; 19namespace Experimental {; 20 ; 21// TODO: see also imagemagick's C++ interface for RColor operations!; 22// https://www.imagemagick.org/api/magick++-classes.php; 23 ; 24/** \class RColor; 25\ingroup GpadROOT7; 26\brief The color class; 27\author Axel Naumann <axel@cern.ch>; 28\author Sergey Linev <S.Linev@gsi.de>; 29\date 2017-09-26; 30\warning This is part of the ROOT 7 prototype! It will change without notice. It might trigger earthquakes. Feedback is welcome!; 31*/; 32 ; 33class RColor {; 34 ; 35 using RGB_t = std::array<uint8_t, 3>;; 36 ; 37private:; 38 ; 39 std::string fColor; ///< string representation of color; 40 ; 41 static std::string toHex(uint8_t v);; 42 ; 43 static std::vector<uint8_t> ConvertNameToRGB(const std::string &name);; 44 ; 45 bool SetRGBHex(const std::string &hex);; 46 bool SetAlphaHex(const std::string &hex);; 47 ; 48public:; 49 ; 50 RColor() = default;; 51 ; 52 /** Construct color with provided r,g,b values */; 53 RColor(uint8_t r, uint8_t g, uint8_t b) { SetRGB(r, g, b); }; 54 ; 55 /** Construct color with provided r,g,b and alpha values */; 56 RColor(uint8_t r, uint8_t g, uint8_t b, float alpha); 57 {; 58 SetRGBA(r, g, b, alpha);; 59 }; 60 ; 61 /** Construct color with provided RGB_t value */; 62 RColor(",MatchSource.WIKI,doc/master/RColor_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RColor_8hxx_source.html
https://root.cern/doc/master/RColor_8hxx_source.html:5223,Usability,clear,clear,5223,"turn the Hue, Light, Saturation (HLS) definition of this RColor */; 163 bool GetHLS(float &hue, float &light, float &satur) const;; 164 ; 165 /** Set the Red Green and Blue (RGB) values from the Hue, Light, Saturation (HLS). */; 166 void SetHLS(float hue, float light, float satur);; 167 ; 168 std::string AsHex(bool with_alpha = false) const;; 169 std::string AsSVG() const;; 170 ; 171 void Clear(); 172 {; 173 fColor.clear();; 174 }; 175 ; 176 static const RColor &AutoColor();; 177 ; 178 R__DLLEXPORT static constexpr RGB_t kBlack{{0, 0, 0}};; 179 R__DLLEXPORT static constexpr RGB_t kGreen{{0, 0x80, 0}};; 180 R__DLLEXPORT static constexpr RGB_t kLime{{0, 0xFF, 0}};; 181 R__DLLEXPORT static constexpr RGB_t kAqua{{0, 0xFF, 0xFF}};; 182 R__DLLEXPORT static constexpr RGB_t kPurple{{0x80, 0, 0x80}};; 183 R__DLLEXPORT static constexpr RGB_t kGrey{{0x80, 0x80, 0x80}};; 184 R__DLLEXPORT static constexpr RGB_t kFuchsia{{0xFF, 0, 0xFF}};; 185 R__DLLEXPORT static constexpr RGB_t kNavy{{0, 0, 0x80}};; 186 R__DLLEXPORT static constexpr RGB_t kBlue{{0, 0, 0xff}};; 187 R__DLLEXPORT static constexpr RGB_t kTeal{{0, 0x80, 0x80}};; 188 R__DLLEXPORT static constexpr RGB_t kOlive{{0x80, 0x80, 0}};; 189 R__DLLEXPORT static constexpr RGB_t kSilver{{0xc0, 0xc0, 0xc0}};; 190 R__DLLEXPORT static constexpr RGB_t kMaroon{{0x80, 0, 0}};; 191 R__DLLEXPORT static constexpr RGB_t kRed{{0xff, 0, 0}};; 192 R__DLLEXPORT static constexpr RGB_t kYellow{{0xff, 0xff, 0}};; 193 R__DLLEXPORT static constexpr RGB_t kWhite{{0xff, 0xff, 0xff}};; 194 R__DLLEXPORT static constexpr float kTransparent{0.};; 195 R__DLLEXPORT static constexpr float kSemiTransparent{0.5};; 196 R__DLLEXPORT static constexpr float kOpaque{1.};; 197 ; 198 friend bool operator==(const RColor &lhs, const RColor &rhs); 199 {; 200 if (lhs.fColor == rhs.fColor) return true;; 201 ; 202 auto l = lhs.AsRGBA();; 203 auto r = rhs.AsRGBA();; 204 ; 205 return !l.empty() && (l == r);; 206 }; 207};; 208 ; 209} // namespace Experimental; 210} // namesp",MatchSource.WIKI,doc/master/RColor_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RColor_8hxx_source.html
https://root.cern/doc/master/RConfig_8hxx.html:238,Integrability,depend,dependency,238,". ROOT: core/foundation/inc/ROOT/RConfig.hxx File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. Macros ; RConfig.hxx File Reference. #include ""../RVersion.h""; #include ""RConfigure.h"". Include dependency graph for RConfig.hxx:. This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead. This graph shows which files directly or indirectly include this file:. This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead. Macros; #define_NAME1_(name)name; ; #define_NAME2_(name1, name2)_NAME1_(name1)name2; ; #define_NAME3_(name1, name2, name3)_NAME2_(name1,name2)name3; ; #define_QUOTE_(name)""name""; ; #define_R__DEPRECATED_634(REASON)_R__DEPRECATED_LATER(REASON); ; #define_R__DEPRECATED_636(REASON)_R__DEPRECATED_LATER(REASON); ; #define_R__DEPRECATED_700(REASON)_R__DEPRECATED_LATER(REASON); ; #define_R__DEPRECATED_LATER(REASON); ; #define_R__JOIN3_(F, X, Y)_NAME3_(F,X,Y); ; #define_R__JOIN_(X, Y)_NAME2_(X,Y); ; #define_R__UNIQUE_(X)_R__JOIN_(X,__LINE__); ; #define_R__UNIQUE_DICT_(X)_R__JOIN3_(R__DICTIONARY_FILENAME,X,__LINE__); ; #define_R_DEPRECATED_REMOVE_NOW(REASON)__attribute__((REMOVE_THIS_NOW)); ; #defineR__ALWAYS_INLINEinline; ; #defineR__ALWAYS_SUGGEST_ALTERNATIVE(ALTERNATIVE) _R__DEPRECATED_LATER(""There is a superior alternative: "" ALTERNATIVE); ; #defineR__ANSISTREAM/* ANSI C++ Standard Library conformant */; ; #defineR__DEPRECATED(MAJOR, MINOR, REASON) _R__JOIN3_(_R__DEPRECATED_,MAJOR,MINOR)(""will be removed in ROOT v"" #MAJOR ""."" #MINOR "": "" REASON); ; #defineR__HIDDEN; ; #defineR__INTENTIONALLY_UNINIT_BEGIN; ; #defineR__INTENTIONALLY_UNINIT_END; ; #defineR__likely(expr)expr; ; #defineR__NEVER_INLINEinline; ; #defineR__SIZEDDELETE; ; #defineR__SSTREAM/* use sstream or strstream header */; ; #defineR__SUGGEST_ALTERNATIVE(ALTERNATIVE); ; #defineR__unlikely(expr)ex",MatchSource.WIKI,doc/master/RConfig_8hxx.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RConfig_8hxx.html
https://root.cern/doc/master/RConfig_8hxx_source.html:1446,Availability,error,error,1446,"/; 2 ; 3/*************************************************************************; 4 * Copyright (C) 1995-2002, Rene Brun and Fons Rademakers. *; 5 * All rights reserved. *; 6 * *; 7 * For the licensing terms see $ROOTSYS/LICENSE. *; 8 * For the list of contributors see $ROOTSYS/README/CREDITS. *; 9 *************************************************************************/; 10 ; 11#ifndef ROOT_RConfig; 12#define ROOT_RConfig; 13 ; 14/*************************************************************************; 15 * *; 16 * RConfig *; 17 * *; 18 * Defines used by ROOT. *; 19 * *; 20 *************************************************************************/; 21 ; 22#include ""../RVersion.h""; 23#include ""RConfigure.h""; 24 ; 25 ; 26/*---- new C++ features ------------------------------------------------------*/; 27 ; 28#if defined __has_feature; 29# if __has_feature(modules); 30# define R__CXXMODULES; 31# endif; 32#endif; 33 ; 34#define R__USE_SHADOW_CLASS; 35 ; 36/* Now required, thus defined by default for backward compatibility */; 37#define R__ANSISTREAM /* ANSI C++ Standard Library conformant */; 38#define R__SSTREAM /* use sstream or strstream header */; 39 ; 40#if defined(_MSC_VER); 41# if (_MSC_VER < 1910); 42# error ""ROOT requires Visual Studio 2017 or higher.""; 43# else; 44# define R__NULLPTR; 45# endif; 46#else; 47#if defined(__cplusplus) && (__cplusplus < 201703L); 48#error ""ROOT requires support for C++17 or higher.""; 49# if defined(__GNUC__) || defined(__clang__); 50#error ""Pass `-std=c++17` as compiler argument.""; 51# endif; 52# endif; 53#endif; 54 ; 55/*---- machines --------------------------------------------------------------*/; 56 ; 57#ifdef __hpux; 58 /* R__HPUX10 or R__HPUX11 is determined in the Makefile */; 59# define R__HPUX; 60# define R__UNIX; 61# define ANSICPP; 62# ifdef __LP64__; 63# define R__B64; 64# endif; 65# ifdef R__HPUX10; 66# define NEED_SNPRINTF; 67# endif; 68#endif; 69 ; 70#ifdef _AIX; 71# define R__AIX; 72# define R__UNIX; 73# define",MatchSource.WIKI,doc/master/RConfig_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RConfig_8hxx_source.html
https://root.cern/doc/master/RConfig_8hxx_source.html:1610,Availability,error,error,1610,"************/; 10 ; 11#ifndef ROOT_RConfig; 12#define ROOT_RConfig; 13 ; 14/*************************************************************************; 15 * *; 16 * RConfig *; 17 * *; 18 * Defines used by ROOT. *; 19 * *; 20 *************************************************************************/; 21 ; 22#include ""../RVersion.h""; 23#include ""RConfigure.h""; 24 ; 25 ; 26/*---- new C++ features ------------------------------------------------------*/; 27 ; 28#if defined __has_feature; 29# if __has_feature(modules); 30# define R__CXXMODULES; 31# endif; 32#endif; 33 ; 34#define R__USE_SHADOW_CLASS; 35 ; 36/* Now required, thus defined by default for backward compatibility */; 37#define R__ANSISTREAM /* ANSI C++ Standard Library conformant */; 38#define R__SSTREAM /* use sstream or strstream header */; 39 ; 40#if defined(_MSC_VER); 41# if (_MSC_VER < 1910); 42# error ""ROOT requires Visual Studio 2017 or higher.""; 43# else; 44# define R__NULLPTR; 45# endif; 46#else; 47#if defined(__cplusplus) && (__cplusplus < 201703L); 48#error ""ROOT requires support for C++17 or higher.""; 49# if defined(__GNUC__) || defined(__clang__); 50#error ""Pass `-std=c++17` as compiler argument.""; 51# endif; 52# endif; 53#endif; 54 ; 55/*---- machines --------------------------------------------------------------*/; 56 ; 57#ifdef __hpux; 58 /* R__HPUX10 or R__HPUX11 is determined in the Makefile */; 59# define R__HPUX; 60# define R__UNIX; 61# define ANSICPP; 62# ifdef __LP64__; 63# define R__B64; 64# endif; 65# ifdef R__HPUX10; 66# define NEED_SNPRINTF; 67# endif; 68#endif; 69 ; 70#ifdef _AIX; 71# define R__AIX; 72# define R__UNIX; 73# define ANSICPP; 74# define R__SEEK64; 75# define NEED_STRCASECMP; 76#endif; 77 ; 78#if defined(__linux) || defined(__linux__); 79# ifndef linux; 80# define linux; 81# endif; 82#endif; 83 ; 84#if defined(__CYGWIN__) && defined(__GNUC__); 85# ifndef linux; 86# define linux; 87# endif; 88# ifndef R__WINGCC; 89# define R__WINGCC; 90# endif; 91#endif; 92 ; 93#if defined(_",MatchSource.WIKI,doc/master/RConfig_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RConfig_8hxx_source.html
https://root.cern/doc/master/RConfig_8hxx_source.html:1713,Availability,error,error,1713,"*****************; 15 * *; 16 * RConfig *; 17 * *; 18 * Defines used by ROOT. *; 19 * *; 20 *************************************************************************/; 21 ; 22#include ""../RVersion.h""; 23#include ""RConfigure.h""; 24 ; 25 ; 26/*---- new C++ features ------------------------------------------------------*/; 27 ; 28#if defined __has_feature; 29# if __has_feature(modules); 30# define R__CXXMODULES; 31# endif; 32#endif; 33 ; 34#define R__USE_SHADOW_CLASS; 35 ; 36/* Now required, thus defined by default for backward compatibility */; 37#define R__ANSISTREAM /* ANSI C++ Standard Library conformant */; 38#define R__SSTREAM /* use sstream or strstream header */; 39 ; 40#if defined(_MSC_VER); 41# if (_MSC_VER < 1910); 42# error ""ROOT requires Visual Studio 2017 or higher.""; 43# else; 44# define R__NULLPTR; 45# endif; 46#else; 47#if defined(__cplusplus) && (__cplusplus < 201703L); 48#error ""ROOT requires support for C++17 or higher.""; 49# if defined(__GNUC__) || defined(__clang__); 50#error ""Pass `-std=c++17` as compiler argument.""; 51# endif; 52# endif; 53#endif; 54 ; 55/*---- machines --------------------------------------------------------------*/; 56 ; 57#ifdef __hpux; 58 /* R__HPUX10 or R__HPUX11 is determined in the Makefile */; 59# define R__HPUX; 60# define R__UNIX; 61# define ANSICPP; 62# ifdef __LP64__; 63# define R__B64; 64# endif; 65# ifdef R__HPUX10; 66# define NEED_SNPRINTF; 67# endif; 68#endif; 69 ; 70#ifdef _AIX; 71# define R__AIX; 72# define R__UNIX; 73# define ANSICPP; 74# define R__SEEK64; 75# define NEED_STRCASECMP; 76#endif; 77 ; 78#if defined(__linux) || defined(__linux__); 79# ifndef linux; 80# define linux; 81# endif; 82#endif; 83 ; 84#if defined(__CYGWIN__) && defined(__GNUC__); 85# ifndef linux; 86# define linux; 87# endif; 88# ifndef R__WINGCC; 89# define R__WINGCC; 90# endif; 91#endif; 92 ; 93#if defined(__sun) && !(defined(linux) || defined(__FCC_VERSION)); 94# ifdef __SVR4; 95# define R__SOLARIS; 96# define R__SEEK64; 97# define ANS",MatchSource.WIKI,doc/master/RConfig_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RConfig_8hxx_source.html
https://root.cern/doc/master/RConfig_8hxx_source.html:9368,Availability,error,error,9368,,MatchSource.WIKI,doc/master/RConfig_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RConfig_8hxx_source.html
https://root.cern/doc/master/RConfig_8hxx_source.html:16364,Availability,error,error,16364,"INE; 547#define R__ALWAYS_INLINE inline __attribute__((always_inline)); 548#else; 549#if defined(_MSC_VER); 550#define R__ALWAYS_INLINE __forceinline; 551#else; 552#define R__ALWAYS_INLINE inline; 553#endif; 554#endif; 555 ; 556// See also https://nemequ.github.io/hedley/api-reference.html#HEDLEY_NEVER_INLINE; 557// for other platforms.; 558#ifdef R__HAS_ATTRIBUTE_NOINLINE; 559#define R__NEVER_INLINE inline __attribute__((noinline)); 560#else; 561#if defined(_MSC_VER); 562#define R__NEVER_INLINE inline __declspec(noinline); 563#else; 564#define R__NEVER_INLINE inline; 565#endif; 566#endif; 567 ; 568/*---- unlikely / likely expressions -----------------------------------------*/; 569// These are meant to use in cases like:; 570// if (R__unlikely(expression)) { ... }; 571// in performance-critical sections. R__unlikely / R__likely provide hints to; 572// the compiler code generation to heavily optimize one side of a conditional,; 573// causing the other branch to have a heavy performance cost.; 574//; 575// It is best to use this for conditionals that test for rare error cases or; 576// backward compatibility code.; 577 ; 578#if (__GNUC__ >= 3) || defined(__INTEL_COMPILER); 579#if !defined(R__unlikely); 580 #define R__unlikely(expr) __builtin_expect(!!(expr), 0); 581#endif; 582#if !defined(R__likely); 583 #define R__likely(expr) __builtin_expect(!!(expr), 1); 584#endif; 585#else; 586 #define R__unlikely(expr) expr; 587 #define R__likely(expr) expr; 588#endif; 589 ; 590// Setting this define causes ROOT to keep statistics about memory buffer allocation; 591// time within the TTree. Given that this is a ""hot-path"", we provide a mechanism; 592// for enabling / disabling this at compile time by developers; default is disabled.; 593#ifndef R__TRACK_BASKET_ALLOC_TIME; 594//#define R__TRACK_BASKET_ALLOC_TIME 1; 595#endif; 596 ; 597#endif. corefoundationincROOTRConfig.hxx. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:40:10 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/RConfig_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RConfig_8hxx_source.html
https://root.cern/doc/master/RConfig_8hxx_source.html:16070,Performance,perform,performance-critical,16070,"UNINIT_END \; 539 R__DO_PRAGMA(GCC diagnostic pop); 540#else; 541# define R__INTENTIONALLY_UNINIT_BEGIN; 542# define R__INTENTIONALLY_UNINIT_END; 543 ; 544#endif; 545 ; 546#ifdef R__HAS_ATTRIBUTE_ALWAYS_INLINE; 547#define R__ALWAYS_INLINE inline __attribute__((always_inline)); 548#else; 549#if defined(_MSC_VER); 550#define R__ALWAYS_INLINE __forceinline; 551#else; 552#define R__ALWAYS_INLINE inline; 553#endif; 554#endif; 555 ; 556// See also https://nemequ.github.io/hedley/api-reference.html#HEDLEY_NEVER_INLINE; 557// for other platforms.; 558#ifdef R__HAS_ATTRIBUTE_NOINLINE; 559#define R__NEVER_INLINE inline __attribute__((noinline)); 560#else; 561#if defined(_MSC_VER); 562#define R__NEVER_INLINE inline __declspec(noinline); 563#else; 564#define R__NEVER_INLINE inline; 565#endif; 566#endif; 567 ; 568/*---- unlikely / likely expressions -----------------------------------------*/; 569// These are meant to use in cases like:; 570// if (R__unlikely(expression)) { ... }; 571// in performance-critical sections. R__unlikely / R__likely provide hints to; 572// the compiler code generation to heavily optimize one side of a conditional,; 573// causing the other branch to have a heavy performance cost.; 574//; 575// It is best to use this for conditionals that test for rare error cases or; 576// backward compatibility code.; 577 ; 578#if (__GNUC__ >= 3) || defined(__INTEL_COMPILER); 579#if !defined(R__unlikely); 580 #define R__unlikely(expr) __builtin_expect(!!(expr), 0); 581#endif; 582#if !defined(R__likely); 583 #define R__likely(expr) __builtin_expect(!!(expr), 1); 584#endif; 585#else; 586 #define R__unlikely(expr) expr; 587 #define R__likely(expr) expr; 588#endif; 589 ; 590// Setting this define causes ROOT to keep statistics about memory buffer allocation; 591// time within the TTree. Given that this is a ""hot-path"", we provide a mechanism; 592// for enabling / disabling this at compile time by developers; default is disabled.; 593#ifndef R__TRACK_BASKET_ALLOC_TIME; 594/",MatchSource.WIKI,doc/master/RConfig_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RConfig_8hxx_source.html
https://root.cern/doc/master/RConfig_8hxx_source.html:16189,Performance,optimiz,optimize,16189,"R__INTENTIONALLY_UNINIT_END; 543 ; 544#endif; 545 ; 546#ifdef R__HAS_ATTRIBUTE_ALWAYS_INLINE; 547#define R__ALWAYS_INLINE inline __attribute__((always_inline)); 548#else; 549#if defined(_MSC_VER); 550#define R__ALWAYS_INLINE __forceinline; 551#else; 552#define R__ALWAYS_INLINE inline; 553#endif; 554#endif; 555 ; 556// See also https://nemequ.github.io/hedley/api-reference.html#HEDLEY_NEVER_INLINE; 557// for other platforms.; 558#ifdef R__HAS_ATTRIBUTE_NOINLINE; 559#define R__NEVER_INLINE inline __attribute__((noinline)); 560#else; 561#if defined(_MSC_VER); 562#define R__NEVER_INLINE inline __declspec(noinline); 563#else; 564#define R__NEVER_INLINE inline; 565#endif; 566#endif; 567 ; 568/*---- unlikely / likely expressions -----------------------------------------*/; 569// These are meant to use in cases like:; 570// if (R__unlikely(expression)) { ... }; 571// in performance-critical sections. R__unlikely / R__likely provide hints to; 572// the compiler code generation to heavily optimize one side of a conditional,; 573// causing the other branch to have a heavy performance cost.; 574//; 575// It is best to use this for conditionals that test for rare error cases or; 576// backward compatibility code.; 577 ; 578#if (__GNUC__ >= 3) || defined(__INTEL_COMPILER); 579#if !defined(R__unlikely); 580 #define R__unlikely(expr) __builtin_expect(!!(expr), 0); 581#endif; 582#if !defined(R__likely); 583 #define R__likely(expr) __builtin_expect(!!(expr), 1); 584#endif; 585#else; 586 #define R__unlikely(expr) expr; 587 #define R__likely(expr) expr; 588#endif; 589 ; 590// Setting this define causes ROOT to keep statistics about memory buffer allocation; 591// time within the TTree. Given that this is a ""hot-path"", we provide a mechanism; 592// for enabling / disabling this at compile time by developers; default is disabled.; 593#ifndef R__TRACK_BASKET_ALLOC_TIME; 594//#define R__TRACK_BASKET_ALLOC_TIME 1; 595#endif; 596 ; 597#endif. corefoundationincROOTRConfig.hxx. ROOT master - R",MatchSource.WIKI,doc/master/RConfig_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RConfig_8hxx_source.html
https://root.cern/doc/master/RConfig_8hxx_source.html:16273,Performance,perform,performance,16273,"R__INTENTIONALLY_UNINIT_END; 543 ; 544#endif; 545 ; 546#ifdef R__HAS_ATTRIBUTE_ALWAYS_INLINE; 547#define R__ALWAYS_INLINE inline __attribute__((always_inline)); 548#else; 549#if defined(_MSC_VER); 550#define R__ALWAYS_INLINE __forceinline; 551#else; 552#define R__ALWAYS_INLINE inline; 553#endif; 554#endif; 555 ; 556// See also https://nemequ.github.io/hedley/api-reference.html#HEDLEY_NEVER_INLINE; 557// for other platforms.; 558#ifdef R__HAS_ATTRIBUTE_NOINLINE; 559#define R__NEVER_INLINE inline __attribute__((noinline)); 560#else; 561#if defined(_MSC_VER); 562#define R__NEVER_INLINE inline __declspec(noinline); 563#else; 564#define R__NEVER_INLINE inline; 565#endif; 566#endif; 567 ; 568/*---- unlikely / likely expressions -----------------------------------------*/; 569// These are meant to use in cases like:; 570// if (R__unlikely(expression)) { ... }; 571// in performance-critical sections. R__unlikely / R__likely provide hints to; 572// the compiler code generation to heavily optimize one side of a conditional,; 573// causing the other branch to have a heavy performance cost.; 574//; 575// It is best to use this for conditionals that test for rare error cases or; 576// backward compatibility code.; 577 ; 578#if (__GNUC__ >= 3) || defined(__INTEL_COMPILER); 579#if !defined(R__unlikely); 580 #define R__unlikely(expr) __builtin_expect(!!(expr), 0); 581#endif; 582#if !defined(R__likely); 583 #define R__likely(expr) __builtin_expect(!!(expr), 1); 584#endif; 585#else; 586 #define R__unlikely(expr) expr; 587 #define R__likely(expr) expr; 588#endif; 589 ; 590// Setting this define causes ROOT to keep statistics about memory buffer allocation; 591// time within the TTree. Given that this is a ""hot-path"", we provide a mechanism; 592// for enabling / disabling this at compile time by developers; default is disabled.; 593#ifndef R__TRACK_BASKET_ALLOC_TIME; 594//#define R__TRACK_BASKET_ALLOC_TIME 1; 595#endif; 596 ; 597#endif. corefoundationincROOTRConfig.hxx. ROOT master - R",MatchSource.WIKI,doc/master/RConfig_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RConfig_8hxx_source.html
https://root.cern/doc/master/RConfig_8hxx_source.html:13991,Safety,avoid,avoid,13991,"as R__DEPRECATED(6,04, ""Not threadsafe; use TFoo::Bar()."") */; 504#define R__DEPRECATED(MAJOR, MINOR, REASON) \; 505 _R__JOIN3_(_R__DEPRECATED_,MAJOR,MINOR)(""will be removed in ROOT v"" #MAJOR ""."" #MINOR "": "" REASON); 506 ; 507/* Mechanisms to advise users to avoid legacy functions and classes that will not be removed */; 508#if defined R__SUGGEST_NEW_INTERFACE; 509# define R__SUGGEST_ALTERNATIVE(ALTERNATIVE) \; 510 _R__DEPRECATED_LATER(""There is a superior alternative: "" ALTERNATIVE); 511#else; 512# define R__SUGGEST_ALTERNATIVE(ALTERNATIVE); 513#endif; 514 ; 515#define R__ALWAYS_SUGGEST_ALTERNATIVE(ALTERNATIVE) \; 516 _R__DEPRECATED_LATER(""There is a superior alternative: "" ALTERNATIVE); 517 ; 518 ; 519 ; 520/*---- misc ------------------------------------------------------------------*/; 521 ; 522#ifdef R__GNU; 523# define SafeDelete(p) { if (p) { delete p; p = nullptr; } }; 524#else; 525# define SafeDelete(p) { delete p; p = nullptr; }; 526#endif; 527 ; 528#ifdef __FAST_MATH__; 529#define R__FAST_MATH; 530#endif; 531 ; 532#if (__GNUC__ >= 7); 533#define R__DO_PRAGMA(x) _Pragma (#x); 534# define R__INTENTIONALLY_UNINIT_BEGIN \; 535 R__DO_PRAGMA(GCC diagnostic push) \; 536 R__DO_PRAGMA(GCC diagnostic ignored ""-Wmaybe-uninitialized"") \; 537 R__DO_PRAGMA(GCC diagnostic ignored ""-Wuninitialized""); 538# define R__INTENTIONALLY_UNINIT_END \; 539 R__DO_PRAGMA(GCC diagnostic pop); 540#else; 541# define R__INTENTIONALLY_UNINIT_BEGIN; 542# define R__INTENTIONALLY_UNINIT_END; 543 ; 544#endif; 545 ; 546#ifdef R__HAS_ATTRIBUTE_ALWAYS_INLINE; 547#define R__ALWAYS_INLINE inline __attribute__((always_inline)); 548#else; 549#if defined(_MSC_VER); 550#define R__ALWAYS_INLINE __forceinline; 551#else; 552#define R__ALWAYS_INLINE inline; 553#endif; 554#endif; 555 ; 556// See also https://nemequ.github.io/hedley/api-reference.html#HEDLEY_NEVER_INLINE; 557// for other platforms.; 558#ifdef R__HAS_ATTRIBUTE_NOINLINE; 559#define R__NEVER_INLINE inline __attribute__((noinline)); 560#else; 5",MatchSource.WIKI,doc/master/RConfig_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RConfig_8hxx_source.html
https://root.cern/doc/master/RConfig_8hxx_source.html:16350,Testability,test,test,16350,"INE; 547#define R__ALWAYS_INLINE inline __attribute__((always_inline)); 548#else; 549#if defined(_MSC_VER); 550#define R__ALWAYS_INLINE __forceinline; 551#else; 552#define R__ALWAYS_INLINE inline; 553#endif; 554#endif; 555 ; 556// See also https://nemequ.github.io/hedley/api-reference.html#HEDLEY_NEVER_INLINE; 557// for other platforms.; 558#ifdef R__HAS_ATTRIBUTE_NOINLINE; 559#define R__NEVER_INLINE inline __attribute__((noinline)); 560#else; 561#if defined(_MSC_VER); 562#define R__NEVER_INLINE inline __declspec(noinline); 563#else; 564#define R__NEVER_INLINE inline; 565#endif; 566#endif; 567 ; 568/*---- unlikely / likely expressions -----------------------------------------*/; 569// These are meant to use in cases like:; 570// if (R__unlikely(expression)) { ... }; 571// in performance-critical sections. R__unlikely / R__likely provide hints to; 572// the compiler code generation to heavily optimize one side of a conditional,; 573// causing the other branch to have a heavy performance cost.; 574//; 575// It is best to use this for conditionals that test for rare error cases or; 576// backward compatibility code.; 577 ; 578#if (__GNUC__ >= 3) || defined(__INTEL_COMPILER); 579#if !defined(R__unlikely); 580 #define R__unlikely(expr) __builtin_expect(!!(expr), 0); 581#endif; 582#if !defined(R__likely); 583 #define R__likely(expr) __builtin_expect(!!(expr), 1); 584#endif; 585#else; 586 #define R__unlikely(expr) expr; 587 #define R__likely(expr) expr; 588#endif; 589 ; 590// Setting this define causes ROOT to keep statistics about memory buffer allocation; 591// time within the TTree. Given that this is a ""hot-path"", we provide a mechanism; 592// for enabling / disabling this at compile time by developers; default is disabled.; 593#ifndef R__TRACK_BASKET_ALLOC_TIME; 594//#define R__TRACK_BASKET_ALLOC_TIME 1; 595#endif; 596 ; 597#endif. corefoundationincROOTRConfig.hxx. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:40:10 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/RConfig_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RConfig_8hxx_source.html
https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html:6196,Availability,error,error,6196,"ommand.substr( 0, endsymbol ) );; 148 result[""source""] = membervalue;; 149 result[""target""] = membervalue;; 150 command = TSchemaRuleProcessor::Trim( command.substr( endsymbol+1 ) );; 151 }; 152 }; 153 }; 154 ; 155 //-----------------------------------------------------------------------; 156 // Process the input until there are no characters left; 157 //////////////////////////////////////////////////////////////////////////; 158 ; 159 while( !command.empty() ) {; 160 //--------------------------------------------------------------------; 161 // Find key token; 162 ///////////////////////////////////////////////////////////////////////; 163 ; 164 std::string::size_type pos = command.find( '=' );; 165 ; 166 //--------------------------------------------------------------------; 167 // No equality sign found - no keys left; 168 ///////////////////////////////////////////////////////////////////////; 169 ; 170 if( pos == std::string::npos ) {; 171 error_string = ""Parsing error, no key found!"";; 172 return false;; 173 }; 174 ; 175 //--------------------------------------------------------------------; 176 // The key was found - process the arguments; 177 ///////////////////////////////////////////////////////////////////////; 178 ; 179 std::string key = TSchemaRuleProcessor::Trim( command.substr( 0, pos ) );; 180 command = TSchemaRuleProcessor::Trim( command.substr( pos+1 ) );; 181 ; 182 //--------------------------------------------------------------------; 183 // Nothing left to be processed; 184 ///////////////////////////////////////////////////////////////////////; 185 ; 186 if( command.size() < 1 ) {; 187 error_string = ""Parsing error, wrond or no value specified for key: "" + key;; 188 return false;; 189 }; 190 ; 191 Bool_t hasquote = command[0] == '""';; 192 ; 193 //--------------------------------------------------------------------; 194 // Processing code tag: ""{ code }""; 195 ///////////////////////////////////////////////////////////////////////; 196 ; 197 if(",MatchSource.WIKI,doc/master/RConversionRuleParser_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html
https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html:6872,Availability,error,error,6872,"///////////////////////////////////; 169 ; 170 if( pos == std::string::npos ) {; 171 error_string = ""Parsing error, no key found!"";; 172 return false;; 173 }; 174 ; 175 //--------------------------------------------------------------------; 176 // The key was found - process the arguments; 177 ///////////////////////////////////////////////////////////////////////; 178 ; 179 std::string key = TSchemaRuleProcessor::Trim( command.substr( 0, pos ) );; 180 command = TSchemaRuleProcessor::Trim( command.substr( pos+1 ) );; 181 ; 182 //--------------------------------------------------------------------; 183 // Nothing left to be processed; 184 ///////////////////////////////////////////////////////////////////////; 185 ; 186 if( command.size() < 1 ) {; 187 error_string = ""Parsing error, wrond or no value specified for key: "" + key;; 188 return false;; 189 }; 190 ; 191 Bool_t hasquote = command[0] == '""';; 192 ; 193 //--------------------------------------------------------------------; 194 // Processing code tag: ""{ code }""; 195 ///////////////////////////////////////////////////////////////////////; 196 ; 197 if( key == ""code"" ) {; 198 // Cleaning of the input command:; 199 // - Trim whitespaces at the borders; 200 // - Get the inner command (i.e. the part between quotes); 201 // - Trim whitespaces again; 202 // - Stitch back together; 203 auto clean_command = [](const std::string &c) {; 204 auto first_trim = TSchemaRuleProcessor::Trim(c);; 205 auto inner_command =; 206 first_trim.substr(first_trim.find_first_of('""') + 1, first_trim.find_last_of('""') - 1);; 207 auto second_trim = TSchemaRuleProcessor::Trim(inner_command);; 208 return '""' + second_trim + '""';; 209 };; 210 command = clean_command(command);; 211 ; 212 if( command[1] != '{' ) {; 213 error_string = ""Parsing error while processing key: code\n"";; 214 error_string += ""Expected \""{ at the beginning of the value."";; 215 return false;; 216 }; 217 l = command.find( ""}\"""" );; 218 if( l == std::string::npos ) {; 219 er",MatchSource.WIKI,doc/master/RConversionRuleParser_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html
https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html:7882,Availability,error,error,7882,"186 if( command.size() < 1 ) {; 187 error_string = ""Parsing error, wrond or no value specified for key: "" + key;; 188 return false;; 189 }; 190 ; 191 Bool_t hasquote = command[0] == '""';; 192 ; 193 //--------------------------------------------------------------------; 194 // Processing code tag: ""{ code }""; 195 ///////////////////////////////////////////////////////////////////////; 196 ; 197 if( key == ""code"" ) {; 198 // Cleaning of the input command:; 199 // - Trim whitespaces at the borders; 200 // - Get the inner command (i.e. the part between quotes); 201 // - Trim whitespaces again; 202 // - Stitch back together; 203 auto clean_command = [](const std::string &c) {; 204 auto first_trim = TSchemaRuleProcessor::Trim(c);; 205 auto inner_command =; 206 first_trim.substr(first_trim.find_first_of('""') + 1, first_trim.find_last_of('""') - 1);; 207 auto second_trim = TSchemaRuleProcessor::Trim(inner_command);; 208 return '""' + second_trim + '""';; 209 };; 210 command = clean_command(command);; 211 ; 212 if( command[1] != '{' ) {; 213 error_string = ""Parsing error while processing key: code\n"";; 214 error_string += ""Expected \""{ at the beginning of the value."";; 215 return false;; 216 }; 217 l = command.find( ""}\"""" );; 218 if( l == std::string::npos ) {; 219 error_string = ""Parsing error while processing key: \"""" + key + ""\""\n"";; 220 error_string += ""Expected }\"" at the end of the value."";; 221 return false;; 222 }; 223 auto rawCode = command.substr( 2, l-2 );; 224 RemoveEscapeSequences(rawCode);; 225 result[key] = rawCode;; 226 ++l;; 227 }; 228 //--------------------------------------------------------------------; 229 // Processing normal tag: ""value""; 230 ///////////////////////////////////////////////////////////////////////; 231 ; 232 else {; 233 if( hasquote) {; 234 l = command.find( '""', 1 );; 235 if (l == std::string::npos ) {; 236 error_string = ""\nParsing error while processing key: \"""" + key + ""\""\n"";; 237 error_string += ""Expected \"" at the end of the value."";",MatchSource.WIKI,doc/master/RConversionRuleParser_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html
https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html:8110,Availability,error,error,8110,"95 ///////////////////////////////////////////////////////////////////////; 196 ; 197 if( key == ""code"" ) {; 198 // Cleaning of the input command:; 199 // - Trim whitespaces at the borders; 200 // - Get the inner command (i.e. the part between quotes); 201 // - Trim whitespaces again; 202 // - Stitch back together; 203 auto clean_command = [](const std::string &c) {; 204 auto first_trim = TSchemaRuleProcessor::Trim(c);; 205 auto inner_command =; 206 first_trim.substr(first_trim.find_first_of('""') + 1, first_trim.find_last_of('""') - 1);; 207 auto second_trim = TSchemaRuleProcessor::Trim(inner_command);; 208 return '""' + second_trim + '""';; 209 };; 210 command = clean_command(command);; 211 ; 212 if( command[1] != '{' ) {; 213 error_string = ""Parsing error while processing key: code\n"";; 214 error_string += ""Expected \""{ at the beginning of the value."";; 215 return false;; 216 }; 217 l = command.find( ""}\"""" );; 218 if( l == std::string::npos ) {; 219 error_string = ""Parsing error while processing key: \"""" + key + ""\""\n"";; 220 error_string += ""Expected }\"" at the end of the value."";; 221 return false;; 222 }; 223 auto rawCode = command.substr( 2, l-2 );; 224 RemoveEscapeSequences(rawCode);; 225 result[key] = rawCode;; 226 ++l;; 227 }; 228 //--------------------------------------------------------------------; 229 // Processing normal tag: ""value""; 230 ///////////////////////////////////////////////////////////////////////; 231 ; 232 else {; 233 if( hasquote) {; 234 l = command.find( '""', 1 );; 235 if (l == std::string::npos ) {; 236 error_string = ""\nParsing error while processing key: \"""" + key + ""\""\n"";; 237 error_string += ""Expected \"" at the end of the value."";; 238 return false;; 239 }; 240 result[key] = command.substr( 1, l-1 );; 241 } else {; 242 l = command.find(' ', 1);; 243 if (l == std::string::npos) l = command.size();; 244 result[key] = command.substr( 0, l );; 245 }; 246 }; 247 ; 248 //--------------------------------------------------------------------; 2",MatchSource.WIKI,doc/master/RConversionRuleParser_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html
https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html:8705,Availability,error,error,8705,"inner_command);; 208 return '""' + second_trim + '""';; 209 };; 210 command = clean_command(command);; 211 ; 212 if( command[1] != '{' ) {; 213 error_string = ""Parsing error while processing key: code\n"";; 214 error_string += ""Expected \""{ at the beginning of the value."";; 215 return false;; 216 }; 217 l = command.find( ""}\"""" );; 218 if( l == std::string::npos ) {; 219 error_string = ""Parsing error while processing key: \"""" + key + ""\""\n"";; 220 error_string += ""Expected }\"" at the end of the value."";; 221 return false;; 222 }; 223 auto rawCode = command.substr( 2, l-2 );; 224 RemoveEscapeSequences(rawCode);; 225 result[key] = rawCode;; 226 ++l;; 227 }; 228 //--------------------------------------------------------------------; 229 // Processing normal tag: ""value""; 230 ///////////////////////////////////////////////////////////////////////; 231 ; 232 else {; 233 if( hasquote) {; 234 l = command.find( '""', 1 );; 235 if (l == std::string::npos ) {; 236 error_string = ""\nParsing error while processing key: \"""" + key + ""\""\n"";; 237 error_string += ""Expected \"" at the end of the value."";; 238 return false;; 239 }; 240 result[key] = command.substr( 1, l-1 );; 241 } else {; 242 l = command.find(' ', 1);; 243 if (l == std::string::npos) l = command.size();; 244 result[key] = command.substr( 0, l );; 245 }; 246 }; 247 ; 248 //--------------------------------------------------------------------; 249 // Everything went ok; 250 ///////////////////////////////////////////////////////////////////////; 251 ; 252 if( l == command.size() ); 253 break;; 254 command = command.substr( l+1 );; 255 }; 256 std::map<std::string, std::string>::const_iterator it1;; 257 it1 = result.find(""oldtype"");; 258 if ( it1 != result.end() ) {; 259 std::map<std::string, std::string>::const_iterator it2;; 260 it2 = result.find(""source"");; 261 if ( it2 != result.end() ) {; 262 result[""source""] = it1->second + "" "" + it2->second;; 263 }; 264 }; 265 if ( result.find(""version"") == result.end() && result.find(""ch",MatchSource.WIKI,doc/master/RConversionRuleParser_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html
https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html:18294,Availability,down,down,18294,"9 /// Check if given rule contains references to valid data members; 460 ; 461 Bool_t HasValidDataMembers(SchemaRuleMap_t& rule,; 462 MembersTypeMap_t& members,; 463 std::string& error_string); 464 {; 465 std::list<std::string> mem;; 466 std::list<std::string>::iterator it;; 467 // MembersMap_t::iterator rIt;; 468 ; 469 TSchemaRuleProcessor::SplitList( rule[""target""], mem );; 470 ; 471 //-----------------------------------------------------------------------; 472 // Loop over the data members; 473 //////////////////////////////////////////////////////////////////////////; 474 ; 475 for( it = mem.begin(); it != mem.end(); ++it ) {; 476 if( members.find( *it ) == members.end() ) {; 477 error_string += ""IO rule for class "" + rule[""targetClass""]; 478 + "" data member: "" + *it + "" was specified as a ""; 479 ""target in the rule but doesn't seem to appear in ""; 480 ""target class\n"";; 481 return false;; 482 }; 483 }; 484 return true;; 485 }; 486 ; 487 /////////////////////////////////////////////////////////////////////////////; 488 /// Write down the sources; 489 ; 490 static void WriteAutoVariables( const std::list<std::string>& target,; 491 const SourceTypeList_t& source,; 492 MembersTypeMap_t& members,; 493 std::string& className, std::string& mappedName,; 494 std::ostream& output ); 495 {; 496 if (!source.empty()) {; 497 Bool_t start = true;; 498 SourceTypeList_t::const_iterator it;; 499 ; 500 //--------------------------------------------------------------------; 501 // Write IDs and check if we should generate the onfile structure; 502 // this is done if the type was declared; 503 ///////////////////////////////////////////////////////////////////////; 504 ; 505 Bool_t generateOnFile = false;; 506 output << ""#if 0"" << std::endl; // this is to be removed later; 507 for( it = source.begin(); it != source.end(); ++it ) {; 508 output << "" "";; 509 output << ""static Int_t id_"" << it->second << "" = oldObj->GetId("";; 510 output << ""\"""" << it->second << ""\"");"" << std::endl;; 51",MatchSource.WIKI,doc/master/RConversionRuleParser_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html
https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html:23107,Availability,down,down,23107,"/////////////////////////////; 589 ; 590 for( it = source.begin(); it != source.end(); ++it ) {; 591 output << "" "";; 592 output << ""static Long_t offset_Onfile_"" << mappedName;; 593 output << ""_"" << it->second << "" = oldObj->GetClass()->GetDataMemberOffset(\"""";; 594 output << it->second << ""\"");\n"";; 595 }; 596 output << "" "" << ""char *onfile_add = (char*)oldObj->GetObject();\n"";; 597 output << "" "" << mappedName << ""_Onfile onfile(\n"";; 598 ; 599 for( start = true, it = source.begin(); it != source.end(); ++it ) {; 600 if( it->first.fType == """" ); 601 continue;; 602 ; 603 if( !start ); 604 output << "",\n"";; 605 ; 606 else; 607 start = false;; 608 ; 609 output << "" "";; 610 output << ""*("";; 611 if (it->first.fDimensions.size() == 0) {; 612 output << it->first.fType;; 613 } else {; 614 output << mappedName << ""_Onfile::onfile_"" << it->second << ""_t"";; 615 }; 616 output << ""*)(onfile_add+offset_Onfile_"";; 617 output << mappedName << ""_"" << it->second << "")"";; 618 }; 619 output << "" );\n\n"";; 620 }; 621 }; 622 ; 623 //-----------------------------------------------------------------------; 624 // Write down the targets; 625 //////////////////////////////////////////////////////////////////////////; 626 ; 627 if( !target.empty() ) {; 628 output << "" static TClassRef cls(\"""";; 629 output << className << ""\"");"" << std::endl;; 630 ; 631 std::list<std::string>::const_iterator it;; 632 for( it = target.begin(); it != target.end(); ++it ) {; 633 Internal::TSchemaType memData = members[*it];; 634 output << "" static Long_t offset_"" << *it << "" = "";; 635 output << ""cls->GetDataMemberOffset(\"""" << *it << ""\"");"";; 636 output << std::endl;; 637 if (memData.fDimensions.size()) {; 638 output << "" typedef "" << memData.fType << "" "" << *it << ""_t"" << memData.fDimensions << "";"" << std::endl;; 639 output << "" "" << *it << ""_t& "" << *it << "" = "";; 640 output << ""*("" << *it << ""_t *)(target+offset_"" << *it;; 641 output << "");"" << std::endl;; 642 } else {; 643 output << "" "" << memData.fType << ""&",MatchSource.WIKI,doc/master/RConversionRuleParser_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html
https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html:29992,Availability,down,down,29992,,MatchSource.WIKI,doc/master/RConversionRuleParser_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html
https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html:40363,Availability,down,down,40363,"const std::string &source, std::pair< Int_t, Int_t > &result)Definition TSchemaRuleProcessor.h:158; ROOT::Internal::TSchemaRuleProcessor::SplitListstatic void SplitList(const std::string &source, std::list< std::string > &result, char delimiter=',')Definition TSchemaRuleProcessor.h:26; ROOT::Internal::MembersMap_tstd::map< std::string, std::string > MembersMap_tDefinition TSchemaType.h:20; ROOT::Minuit2::GradientParameterSpace::Internal@ Internal; ROOTtbb::task_arena is an alias of tbb::interface7::task_arena, which doesn't allow to forward declare tb...Definition EExecutionPolicy.hxx:4; ROOT::SourceTypeList_tstd::list< std::pair< ROOT::Internal::TSchemaType, std::string > > SourceTypeList_tDefinition RConversionRuleParser.cxx:51; ROOT::SchemaRuleClassMap_tstd::map< std::string, std::list< SchemaRuleMap_t > > SchemaRuleClassMap_tDefinition RConversionRuleParser.h:23; ROOT::WriteAutoVariablesstatic void WriteAutoVariables(const std::list< std::string > &target, const SourceTypeList_t &source, MembersTypeMap_t &members, std::string &className, std::string &mappedName, std::ostream &output)Write down the sources.Definition RConversionRuleParser.cxx:490; ROOT::FindEndSymbolstatic std::string::size_type FindEndSymbol(std::string &command)Definition RConversionRuleParser.cxx:62; ROOT::StrReplacestatic void StrReplace(std::string &proc, const std::string &pat, const std::string &tr)Replace all accurances of given string with other string.Definition RConversionRuleParser.cxx:757; ROOT::ProcessReadPragmavoid ProcessReadPragma(const char *args, std::string &error_string)I am being called when a read pragma is encountered.Definition RConversionRuleParser.cxx:899; ROOT::WriteSchemaListvoid WriteSchemaList(std::list< SchemaRuleMap_t > &rules, const std::string &listName, std::ostream &output)Write schema rules.Definition RConversionRuleParser.cxx:779; ROOT::MembersTypeMap_tstd::map< std::string, ROOT::Internal::TSchemaType > MembersTypeMap_tDefinition RConversionRuleParser.h:27; ",MatchSource.WIKI,doc/master/RConversionRuleParser_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html
https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html:26008,Integrability,message,message,26008,"; 661 //-----------------------------------------------------------------------; 662 // Create the function name; 663 //////////////////////////////////////////////////////////////////////////; 664 ; 665 std::ostringstream func;; 666 func << ""read_"" << mappedName << ""_"" << index;; 667 rule[""funcname""] = func.str();; 668 ; 669 //-----------------------------------------------------------------------; 670 // Write the header; 671 //////////////////////////////////////////////////////////////////////////; 672 ; 673 output << "" static void "" << func.str();; 674 output << ""( char* target, TVirtualObject *oldObj )"" << std::endl;; 675 output << "" {"" << std::endl;; 676 output << "" //--- Automatically generated variables ---"" << std::endl;; 677 ; 678 //-----------------------------------------------------------------------; 679 // Write the automatically generated variables; 680 //////////////////////////////////////////////////////////////////////////; 681 ; 682 std::list<std::pair<ROOT::Internal::TSchemaType,std::string> > source;; 683 std::list<std::string> target;; 684 TSchemaRuleProcessor::SplitDeclaration( rule[""source""], source );; 685 TSchemaRuleProcessor::SplitList( rule[""target""], target );; 686 ; 687 WriteAutoVariables( target, source, members, className, mappedName, output );; 688 output << "" "" << className << ""* newObj = ("" << className;; 689 output << ""*)target;"" << std::endl;; 690 output << "" // Supress warning message.\n"";; 691 output << "" "" << ""(void)oldObj;\n\n"";; 692 output << "" "" << ""(void)newObj;\n\n"";; 693 ; 694 //-----------------------------------------------------------------------; 695 // Write the user's code; 696 //////////////////////////////////////////////////////////////////////////; 697 ; 698 output << "" //--- User's code ---"" << std::endl;; 699 output << "" "" << rule[""code""] << std::endl;; 700 output << "" }"" << std::endl;; 701 }; 702 ; 703 ; 704 /////////////////////////////////////////////////////////////////////////////; 705 /// Write the co",MatchSource.WIKI,doc/master/RConversionRuleParser_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html
https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html:1828,Modifiability,variab,variables,1828,"lgorithm>; 21#include <iostream>; 22#include <map>; 23#include <sstream>; 24#include <string>; 25#include <utility>; 26#include <vector>; 27 ; 28namespace {; 29 static void RemoveEscapeSequences(std::string& rawString); 30 {; 31 const std::vector<std::pair<std::string, std::string>> subPairs { {""\\\\"",""\\""},; 32 {""\\\"""",""\""""},; 33 {""\\\'"",""\'""}};; 34 size_t start_pos = 0;; 35 for (auto const & subPair : subPairs){; 36 start_pos = 0;; 37 auto from = subPair.first;; 38 auto to = subPair.second;; 39 while((start_pos = rawString.find(from, start_pos)) != std::string::npos) {; 40 rawString.replace(start_pos, from.length(), to);; 41 start_pos += to.length();; 42 }; 43 }; 44 }; 45}; 46 ; 47namespace ROOT; 48{; 49 using namespace Internal;; 50 ; 51 typedef std::list<std::pair<ROOT::Internal::TSchemaType,std::string> > SourceTypeList_t;; 52 ; 53 //--------------------------------------------------------------------------; 54 // Allocate global variables; 55 /////////////////////////////////////////////////////////////////////////////; 56 ; 57 SchemaRuleClassMap_t gReadRules;; 58 SchemaRuleClassMap_t gReadRawRules;; 59 ; 60 static Bool_t ValidateRule( const std::map<std::string, std::string>& rule, std::string &error_string );; 61 ; 62 static std::string::size_type FindEndSymbol(std::string &command); 63 {; 64 // Find the end of a symbol.; 65 ; 66 if (command.length() == 0) return std::string::npos;; 67 std::string::size_type cursor;; 68 unsigned int level = 0;; 69 for (cursor = 0 ; cursor < command.length(); ++cursor); 70 {; 71 switch( command[cursor] ) {; 72 case ' ':; 73 case '\t':; 74 case '\r':; 75 case '=': if (level==0) {; 76 std::string::size_type sub_cursor = cursor;; 77 while( isspace(command[sub_cursor]) ) {; 78 ++sub_cursor;; 79 }; 80 if ( command[sub_cursor] == '=' ) {; 81 return sub_cursor;; 82 } else {; 83 return cursor;; 84 }; 85 } else {; 86 break;; 87 }; 88 case '<': ++level; break;; 89 case '>': if (level==0) { return std::string::npos; }; 90 --level; break;",MatchSource.WIKI,doc/master/RConversionRuleParser_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html
https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html:25279,Modifiability,variab,variables,25279,"; 661 //-----------------------------------------------------------------------; 662 // Create the function name; 663 //////////////////////////////////////////////////////////////////////////; 664 ; 665 std::ostringstream func;; 666 func << ""read_"" << mappedName << ""_"" << index;; 667 rule[""funcname""] = func.str();; 668 ; 669 //-----------------------------------------------------------------------; 670 // Write the header; 671 //////////////////////////////////////////////////////////////////////////; 672 ; 673 output << "" static void "" << func.str();; 674 output << ""( char* target, TVirtualObject *oldObj )"" << std::endl;; 675 output << "" {"" << std::endl;; 676 output << "" //--- Automatically generated variables ---"" << std::endl;; 677 ; 678 //-----------------------------------------------------------------------; 679 // Write the automatically generated variables; 680 //////////////////////////////////////////////////////////////////////////; 681 ; 682 std::list<std::pair<ROOT::Internal::TSchemaType,std::string> > source;; 683 std::list<std::string> target;; 684 TSchemaRuleProcessor::SplitDeclaration( rule[""source""], source );; 685 TSchemaRuleProcessor::SplitList( rule[""target""], target );; 686 ; 687 WriteAutoVariables( target, source, members, className, mappedName, output );; 688 output << "" "" << className << ""* newObj = ("" << className;; 689 output << ""*)target;"" << std::endl;; 690 output << "" // Supress warning message.\n"";; 691 output << "" "" << ""(void)oldObj;\n\n"";; 692 output << "" "" << ""(void)newObj;\n\n"";; 693 ; 694 //-----------------------------------------------------------------------; 695 // Write the user's code; 696 //////////////////////////////////////////////////////////////////////////; 697 ; 698 output << "" //--- User's code ---"" << std::endl;; 699 output << "" "" << rule[""code""] << std::endl;; 700 output << "" }"" << std::endl;; 701 }; 702 ; 703 ; 704 /////////////////////////////////////////////////////////////////////////////; 705 /// Write the co",MatchSource.WIKI,doc/master/RConversionRuleParser_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html
https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html:25435,Modifiability,variab,variables,25435,"; 661 //-----------------------------------------------------------------------; 662 // Create the function name; 663 //////////////////////////////////////////////////////////////////////////; 664 ; 665 std::ostringstream func;; 666 func << ""read_"" << mappedName << ""_"" << index;; 667 rule[""funcname""] = func.str();; 668 ; 669 //-----------------------------------------------------------------------; 670 // Write the header; 671 //////////////////////////////////////////////////////////////////////////; 672 ; 673 output << "" static void "" << func.str();; 674 output << ""( char* target, TVirtualObject *oldObj )"" << std::endl;; 675 output << "" {"" << std::endl;; 676 output << "" //--- Automatically generated variables ---"" << std::endl;; 677 ; 678 //-----------------------------------------------------------------------; 679 // Write the automatically generated variables; 680 //////////////////////////////////////////////////////////////////////////; 681 ; 682 std::list<std::pair<ROOT::Internal::TSchemaType,std::string> > source;; 683 std::list<std::string> target;; 684 TSchemaRuleProcessor::SplitDeclaration( rule[""source""], source );; 685 TSchemaRuleProcessor::SplitList( rule[""target""], target );; 686 ; 687 WriteAutoVariables( target, source, members, className, mappedName, output );; 688 output << "" "" << className << ""* newObj = ("" << className;; 689 output << ""*)target;"" << std::endl;; 690 output << "" // Supress warning message.\n"";; 691 output << "" "" << ""(void)oldObj;\n\n"";; 692 output << "" "" << ""(void)newObj;\n\n"";; 693 ; 694 //-----------------------------------------------------------------------; 695 // Write the user's code; 696 //////////////////////////////////////////////////////////////////////////; 697 ; 698 output << "" //--- User's code ---"" << std::endl;; 699 output << "" "" << rule[""code""] << std::endl;; 700 output << "" }"" << std::endl;; 701 }; 702 ; 703 ; 704 /////////////////////////////////////////////////////////////////////////////; 705 /// Write the co",MatchSource.WIKI,doc/master/RConversionRuleParser_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html
https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html:27627,Modifiability,variab,variables,27627,"1 ; 722 //-----------------------------------------------------------------------; 723 // Write the header; 724 //////////////////////////////////////////////////////////////////////////; 725 ; 726 output << "" static void "" << func.str();; 727 output << ""( char* target, TBuffer &b )"" << std::endl;; 728 output << "" {"" << std::endl;; 729 output << ""#if 0"" << std::endl;; 730 output << "" //--- Automatically generated variables ---"" << std::endl;; 731 ; 732 //-----------------------------------------------------------------------; 733 // Write the automatically generated variables; 734 //////////////////////////////////////////////////////////////////////////; 735 ; 736 std::list<std::pair<ROOT::Internal::TSchemaType,std::string> > source;; 737 std::list<std::string> target;; 738 TSchemaRuleProcessor::SplitList( rule[""target""], target );; 739 ; 740 WriteAutoVariables( target, source, members, className, mappedName, output );; 741 output << "" "" << className << ""* newObj = ("" << className;; 742 output << ""*)target;"" << std::endl << std::endl;; 743 ; 744 //-----------------------------------------------------------------------; 745 // Write the user's code; 746 //////////////////////////////////////////////////////////////////////////; 747 ; 748 output << "" //--- User's code ---"" << std::endl;; 749 output << rule[""code""] << std::endl;; 750 output << ""#endif"" << std::endl;; 751 output << "" }"" << std::endl;; 752 }; 753 ; 754 /////////////////////////////////////////////////////////////////////////////; 755 /// Replace all accurances of given string with other string; 756 ; 757 static void StrReplace( std::string& proc, const std::string& pat,; 758 const std::string& tr ); 759 {; 760 std::string::size_type it = 0;; 761 std::string::size_type s = pat.size();; 762 std::string::size_type tr_len= tr.size();; 763 ; 764 if( s == 0 ) return;; 765 ; 766 while( 1 ) {; 767 it = proc.find( pat, it );; 768 if( it == std::string::npos ); 769 break;; 770 ; 771 proc.replace( it, s, tr );; 772",MatchSource.WIKI,doc/master/RConversionRuleParser_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html
https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html:27783,Modifiability,variab,variables,27783,"1 ; 722 //-----------------------------------------------------------------------; 723 // Write the header; 724 //////////////////////////////////////////////////////////////////////////; 725 ; 726 output << "" static void "" << func.str();; 727 output << ""( char* target, TBuffer &b )"" << std::endl;; 728 output << "" {"" << std::endl;; 729 output << ""#if 0"" << std::endl;; 730 output << "" //--- Automatically generated variables ---"" << std::endl;; 731 ; 732 //-----------------------------------------------------------------------; 733 // Write the automatically generated variables; 734 //////////////////////////////////////////////////////////////////////////; 735 ; 736 std::list<std::pair<ROOT::Internal::TSchemaType,std::string> > source;; 737 std::list<std::string> target;; 738 TSchemaRuleProcessor::SplitList( rule[""target""], target );; 739 ; 740 WriteAutoVariables( target, source, members, className, mappedName, output );; 741 output << "" "" << className << ""* newObj = ("" << className;; 742 output << ""*)target;"" << std::endl << std::endl;; 743 ; 744 //-----------------------------------------------------------------------; 745 // Write the user's code; 746 //////////////////////////////////////////////////////////////////////////; 747 ; 748 output << "" //--- User's code ---"" << std::endl;; 749 output << rule[""code""] << std::endl;; 750 output << ""#endif"" << std::endl;; 751 output << "" }"" << std::endl;; 752 }; 753 ; 754 /////////////////////////////////////////////////////////////////////////////; 755 /// Replace all accurances of given string with other string; 756 ; 757 static void StrReplace( std::string& proc, const std::string& pat,; 758 const std::string& tr ); 759 {; 760 std::string::size_type it = 0;; 761 std::string::size_type s = pat.size();; 762 std::string::size_type tr_len= tr.size();; 763 ; 764 if( s == 0 ) return;; 765 ; 766 while( 1 ) {; 767 it = proc.find( pat, it );; 768 if( it == std::string::npos ); 769 break;; 770 ; 771 proc.replace( it, s, tr );; 772",MatchSource.WIKI,doc/master/RConversionRuleParser_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html
https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html:9715,Security,checksum,checksum,9715,"ssing key: \"""" + key + ""\""\n"";; 237 error_string += ""Expected \"" at the end of the value."";; 238 return false;; 239 }; 240 result[key] = command.substr( 1, l-1 );; 241 } else {; 242 l = command.find(' ', 1);; 243 if (l == std::string::npos) l = command.size();; 244 result[key] = command.substr( 0, l );; 245 }; 246 }; 247 ; 248 //--------------------------------------------------------------------; 249 // Everything went ok; 250 ///////////////////////////////////////////////////////////////////////; 251 ; 252 if( l == command.size() ); 253 break;; 254 command = command.substr( l+1 );; 255 }; 256 std::map<std::string, std::string>::const_iterator it1;; 257 it1 = result.find(""oldtype"");; 258 if ( it1 != result.end() ) {; 259 std::map<std::string, std::string>::const_iterator it2;; 260 it2 = result.find(""source"");; 261 if ( it2 != result.end() ) {; 262 result[""source""] = it1->second + "" "" + it2->second;; 263 }; 264 }; 265 if ( result.find(""version"") == result.end() && result.find(""checksum"") == result.end() ) {; 266 result[""version""] = ""[1-]"";; 267 }; 268 ; 269 //------------------------------------------------------------------------; 270 // ""include"" tag. Replace "";"" with "","" for backwards compatibility with; 271 // ROOT5; 272 //////////////////////////////////////////////////////////////////////////; 273 ; 274 auto const includeKeyName = ""include"";; 275 auto includeTag = result.find(includeKeyName);; 276 if (includeTag != result.end()){; 277 auto & includeTagValue = includeTag->second;; 278 std::replace_if (includeTagValue.begin(),; 279 includeTagValue.end(),; 280 [](char c){ return c == ';';},; 281 ',');; 282 result[includeKeyName] = includeTagValue;; 283 }; 284 ; 285 return ValidateRule( result, error_string);; 286 }; 287 ; 288 /////////////////////////////////////////////////////////////////////////////; 289 /// Validate if the user specified rules are correct; 290 ; 291 static Bool_t ValidateRule( const std::map<std::string, std::string>& rule, std::string &error",MatchSource.WIKI,doc/master/RConversionRuleParser_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html
https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html:11914,Security,checksum,checksum,11914," name; 295 //////////////////////////////////////////////////////////////////////////; 296 ; 297 std::map<std::string, std::string>::const_iterator it1, it2;; 298 std::list<std::string> lst;; 299 ; 300 it1 = rule.find( ""targetClass"" );; 301 if( it1 == rule.end() ) {; 302 error_string = ""You always have to specify the targetClass "";; 303 error_string += ""when specyfying an IO rule"";; 304 return false;; 305 }; 306 ; 307 std::string className = TSchemaRuleProcessor::Trim( it1->second );; 308 std::string warning = ""IO rule for class "" + className;; 309 ; 310 //-----------------------------------------------------------------------; 311 // Check if we have the source tag; 312 //////////////////////////////////////////////////////////////////////////; 313 ; 314 it1 = rule.find( ""sourceClass"" );; 315 if( it1 == rule.end()); 316 {; 317 error_string = warning + "" - sourceClass parameter is missing"";; 318 return false;; 319 }; 320 ; 321 //-----------------------------------------------------------------------; 322 // Check if we have either version or checksum specified; 323 //////////////////////////////////////////////////////////////////////////; 324 ; 325 it1 = rule.find( ""version"" );; 326 it2 = rule.find( ""checksum"" );; 327 if( it1 == rule.end() && it2 == rule.end() ) {; 328 error_string = warning + "" - you need to specify either version or "";; 329 error_string += ""checksum"";; 330 return false;; 331 }; 332 ; 333 //-----------------------------------------------------------------------; 334 // Check if the checksum has been set to right value; 335 //////////////////////////////////////////////////////////////////////////; 336 ; 337 if( it2 != rule.end() ) {; 338 if( it2->second.size() < 2 || it2->second[0] != '[' ||; 339 it2->second[it2->second.size()-1] != ']' ) {; 340 error_string = warning + "" - a comma separated list of ints"";; 341 error_string += "" enclosed in square brackets expected"";; 342 error_string += "" as a value of checksum parameter"";; 343 return false;; 344",MatchSource.WIKI,doc/master/RConversionRuleParser_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html
https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html:12077,Security,checksum,checksum,12077,";; 301 if( it1 == rule.end() ) {; 302 error_string = ""You always have to specify the targetClass "";; 303 error_string += ""when specyfying an IO rule"";; 304 return false;; 305 }; 306 ; 307 std::string className = TSchemaRuleProcessor::Trim( it1->second );; 308 std::string warning = ""IO rule for class "" + className;; 309 ; 310 //-----------------------------------------------------------------------; 311 // Check if we have the source tag; 312 //////////////////////////////////////////////////////////////////////////; 313 ; 314 it1 = rule.find( ""sourceClass"" );; 315 if( it1 == rule.end()); 316 {; 317 error_string = warning + "" - sourceClass parameter is missing"";; 318 return false;; 319 }; 320 ; 321 //-----------------------------------------------------------------------; 322 // Check if we have either version or checksum specified; 323 //////////////////////////////////////////////////////////////////////////; 324 ; 325 it1 = rule.find( ""version"" );; 326 it2 = rule.find( ""checksum"" );; 327 if( it1 == rule.end() && it2 == rule.end() ) {; 328 error_string = warning + "" - you need to specify either version or "";; 329 error_string += ""checksum"";; 330 return false;; 331 }; 332 ; 333 //-----------------------------------------------------------------------; 334 // Check if the checksum has been set to right value; 335 //////////////////////////////////////////////////////////////////////////; 336 ; 337 if( it2 != rule.end() ) {; 338 if( it2->second.size() < 2 || it2->second[0] != '[' ||; 339 it2->second[it2->second.size()-1] != ']' ) {; 340 error_string = warning + "" - a comma separated list of ints"";; 341 error_string += "" enclosed in square brackets expected"";; 342 error_string += "" as a value of checksum parameter"";; 343 return false;; 344 }; 345 ; 346 TSchemaRuleProcessor::SplitList( it2->second.substr( 1, it2->second.size()-2 ),; 347 lst );; 348 if( lst.empty() ) {; 349 error_string += warning + "" - the list of checksums is empty\n"";; 350 }; 351 ; 352 for( const auto&",MatchSource.WIKI,doc/master/RConversionRuleParser_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html
https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html:12239,Security,checksum,checksum,12239," it1->second );; 308 std::string warning = ""IO rule for class "" + className;; 309 ; 310 //-----------------------------------------------------------------------; 311 // Check if we have the source tag; 312 //////////////////////////////////////////////////////////////////////////; 313 ; 314 it1 = rule.find( ""sourceClass"" );; 315 if( it1 == rule.end()); 316 {; 317 error_string = warning + "" - sourceClass parameter is missing"";; 318 return false;; 319 }; 320 ; 321 //-----------------------------------------------------------------------; 322 // Check if we have either version or checksum specified; 323 //////////////////////////////////////////////////////////////////////////; 324 ; 325 it1 = rule.find( ""version"" );; 326 it2 = rule.find( ""checksum"" );; 327 if( it1 == rule.end() && it2 == rule.end() ) {; 328 error_string = warning + "" - you need to specify either version or "";; 329 error_string += ""checksum"";; 330 return false;; 331 }; 332 ; 333 //-----------------------------------------------------------------------; 334 // Check if the checksum has been set to right value; 335 //////////////////////////////////////////////////////////////////////////; 336 ; 337 if( it2 != rule.end() ) {; 338 if( it2->second.size() < 2 || it2->second[0] != '[' ||; 339 it2->second[it2->second.size()-1] != ']' ) {; 340 error_string = warning + "" - a comma separated list of ints"";; 341 error_string += "" enclosed in square brackets expected"";; 342 error_string += "" as a value of checksum parameter"";; 343 return false;; 344 }; 345 ; 346 TSchemaRuleProcessor::SplitList( it2->second.substr( 1, it2->second.size()-2 ),; 347 lst );; 348 if( lst.empty() ) {; 349 error_string += warning + "" - the list of checksums is empty\n"";; 350 }; 351 ; 352 for( const auto& chk : lst ) {; 353 if( !TSchemaRuleProcessor::IsANumber(chk, true) ) {; 354 error_string = warning + "" - "" + chk + "" is not a valid value"";; 355 error_string += "" of checksum parameter - an integer (decimal/hex) expected"";; 356 return fa",MatchSource.WIKI,doc/master/RConversionRuleParser_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html
https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html:12382,Security,checksum,checksum,12382," it1->second );; 308 std::string warning = ""IO rule for class "" + className;; 309 ; 310 //-----------------------------------------------------------------------; 311 // Check if we have the source tag; 312 //////////////////////////////////////////////////////////////////////////; 313 ; 314 it1 = rule.find( ""sourceClass"" );; 315 if( it1 == rule.end()); 316 {; 317 error_string = warning + "" - sourceClass parameter is missing"";; 318 return false;; 319 }; 320 ; 321 //-----------------------------------------------------------------------; 322 // Check if we have either version or checksum specified; 323 //////////////////////////////////////////////////////////////////////////; 324 ; 325 it1 = rule.find( ""version"" );; 326 it2 = rule.find( ""checksum"" );; 327 if( it1 == rule.end() && it2 == rule.end() ) {; 328 error_string = warning + "" - you need to specify either version or "";; 329 error_string += ""checksum"";; 330 return false;; 331 }; 332 ; 333 //-----------------------------------------------------------------------; 334 // Check if the checksum has been set to right value; 335 //////////////////////////////////////////////////////////////////////////; 336 ; 337 if( it2 != rule.end() ) {; 338 if( it2->second.size() < 2 || it2->second[0] != '[' ||; 339 it2->second[it2->second.size()-1] != ']' ) {; 340 error_string = warning + "" - a comma separated list of ints"";; 341 error_string += "" enclosed in square brackets expected"";; 342 error_string += "" as a value of checksum parameter"";; 343 return false;; 344 }; 345 ; 346 TSchemaRuleProcessor::SplitList( it2->second.substr( 1, it2->second.size()-2 ),; 347 lst );; 348 if( lst.empty() ) {; 349 error_string += warning + "" - the list of checksums is empty\n"";; 350 }; 351 ; 352 for( const auto& chk : lst ) {; 353 if( !TSchemaRuleProcessor::IsANumber(chk, true) ) {; 354 error_string = warning + "" - "" + chk + "" is not a valid value"";; 355 error_string += "" of checksum parameter - an integer (decimal/hex) expected"";; 356 return fa",MatchSource.WIKI,doc/master/RConversionRuleParser_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html
https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html:12812,Security,checksum,checksum,12812,"n false;; 319 }; 320 ; 321 //-----------------------------------------------------------------------; 322 // Check if we have either version or checksum specified; 323 //////////////////////////////////////////////////////////////////////////; 324 ; 325 it1 = rule.find( ""version"" );; 326 it2 = rule.find( ""checksum"" );; 327 if( it1 == rule.end() && it2 == rule.end() ) {; 328 error_string = warning + "" - you need to specify either version or "";; 329 error_string += ""checksum"";; 330 return false;; 331 }; 332 ; 333 //-----------------------------------------------------------------------; 334 // Check if the checksum has been set to right value; 335 //////////////////////////////////////////////////////////////////////////; 336 ; 337 if( it2 != rule.end() ) {; 338 if( it2->second.size() < 2 || it2->second[0] != '[' ||; 339 it2->second[it2->second.size()-1] != ']' ) {; 340 error_string = warning + "" - a comma separated list of ints"";; 341 error_string += "" enclosed in square brackets expected"";; 342 error_string += "" as a value of checksum parameter"";; 343 return false;; 344 }; 345 ; 346 TSchemaRuleProcessor::SplitList( it2->second.substr( 1, it2->second.size()-2 ),; 347 lst );; 348 if( lst.empty() ) {; 349 error_string += warning + "" - the list of checksums is empty\n"";; 350 }; 351 ; 352 for( const auto& chk : lst ) {; 353 if( !TSchemaRuleProcessor::IsANumber(chk, true) ) {; 354 error_string = warning + "" - "" + chk + "" is not a valid value"";; 355 error_string += "" of checksum parameter - an integer (decimal/hex) expected"";; 356 return false;; 357 }; 358 }; 359 }; 360 ; 361 //-----------------------------------------------------------------------; 362 // Check if the version is correct; 363 //////////////////////////////////////////////////////////////////////////; 364 ; 365 std::pair<Int_t, Int_t> ver;; 366 if( it1 != rule.end() ) {; 367 if( it1->second.size() < 2 || it1->second[0] != '[' ||; 368 it1->second[it1->second.size()-1] != ']' ) {; 369 error_string = warning +",MatchSource.WIKI,doc/master/RConversionRuleParser_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html
https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html:13034,Security,checksum,checksums,13034,"--------------------------------------------------------------; 334 // Check if the checksum has been set to right value; 335 //////////////////////////////////////////////////////////////////////////; 336 ; 337 if( it2 != rule.end() ) {; 338 if( it2->second.size() < 2 || it2->second[0] != '[' ||; 339 it2->second[it2->second.size()-1] != ']' ) {; 340 error_string = warning + "" - a comma separated list of ints"";; 341 error_string += "" enclosed in square brackets expected"";; 342 error_string += "" as a value of checksum parameter"";; 343 return false;; 344 }; 345 ; 346 TSchemaRuleProcessor::SplitList( it2->second.substr( 1, it2->second.size()-2 ),; 347 lst );; 348 if( lst.empty() ) {; 349 error_string += warning + "" - the list of checksums is empty\n"";; 350 }; 351 ; 352 for( const auto& chk : lst ) {; 353 if( !TSchemaRuleProcessor::IsANumber(chk, true) ) {; 354 error_string = warning + "" - "" + chk + "" is not a valid value"";; 355 error_string += "" of checksum parameter - an integer (decimal/hex) expected"";; 356 return false;; 357 }; 358 }; 359 }; 360 ; 361 //-----------------------------------------------------------------------; 362 // Check if the version is correct; 363 //////////////////////////////////////////////////////////////////////////; 364 ; 365 std::pair<Int_t, Int_t> ver;; 366 if( it1 != rule.end() ) {; 367 if( it1->second.size() < 2 || it1->second[0] != '[' ||; 368 it1->second[it1->second.size()-1] != ']' ) {; 369 error_string = warning + "" - a comma separated list of version specifiers "";; 370 error_string += ""enclosed in square brackets expected"";; 371 error_string += ""as a value of version parameter"";; 372 return false;; 373 }; 374 ; 375 TSchemaRuleProcessor::SplitList( it1->second.substr( 1, it1->second.size()-2 ),; 376 lst );; 377 if( lst.empty() ) {; 378 error_string = warning + "" - the list of versions is empty"";; 379 }; 380 ; 381 for( const auto& version : lst ); 382 if( !TSchemaRuleProcessor::ProcessVersion( version, ver ) ) {; 383 error_string = ",MatchSource.WIKI,doc/master/RConversionRuleParser_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html
https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html:13258,Security,checksum,checksum,13258,"--------------------------------------------------------------; 334 // Check if the checksum has been set to right value; 335 //////////////////////////////////////////////////////////////////////////; 336 ; 337 if( it2 != rule.end() ) {; 338 if( it2->second.size() < 2 || it2->second[0] != '[' ||; 339 it2->second[it2->second.size()-1] != ']' ) {; 340 error_string = warning + "" - a comma separated list of ints"";; 341 error_string += "" enclosed in square brackets expected"";; 342 error_string += "" as a value of checksum parameter"";; 343 return false;; 344 }; 345 ; 346 TSchemaRuleProcessor::SplitList( it2->second.substr( 1, it2->second.size()-2 ),; 347 lst );; 348 if( lst.empty() ) {; 349 error_string += warning + "" - the list of checksums is empty\n"";; 350 }; 351 ; 352 for( const auto& chk : lst ) {; 353 if( !TSchemaRuleProcessor::IsANumber(chk, true) ) {; 354 error_string = warning + "" - "" + chk + "" is not a valid value"";; 355 error_string += "" of checksum parameter - an integer (decimal/hex) expected"";; 356 return false;; 357 }; 358 }; 359 }; 360 ; 361 //-----------------------------------------------------------------------; 362 // Check if the version is correct; 363 //////////////////////////////////////////////////////////////////////////; 364 ; 365 std::pair<Int_t, Int_t> ver;; 366 if( it1 != rule.end() ) {; 367 if( it1->second.size() < 2 || it1->second[0] != '[' ||; 368 it1->second[it1->second.size()-1] != ']' ) {; 369 error_string = warning + "" - a comma separated list of version specifiers "";; 370 error_string += ""enclosed in square brackets expected"";; 371 error_string += ""as a value of version parameter"";; 372 return false;; 373 }; 374 ; 375 TSchemaRuleProcessor::SplitList( it1->second.substr( 1, it1->second.size()-2 ),; 376 lst );; 377 if( lst.empty() ) {; 378 error_string = warning + "" - the list of versions is empty"";; 379 }; 380 ; 381 for( const auto& version : lst ); 382 if( !TSchemaRuleProcessor::ProcessVersion( version, ver ) ) {; 383 error_string = ",MatchSource.WIKI,doc/master/RConversionRuleParser_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html
https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html:14630,Security,checksum,checksum,14630,"------------------------; 362 // Check if the version is correct; 363 //////////////////////////////////////////////////////////////////////////; 364 ; 365 std::pair<Int_t, Int_t> ver;; 366 if( it1 != rule.end() ) {; 367 if( it1->second.size() < 2 || it1->second[0] != '[' ||; 368 it1->second[it1->second.size()-1] != ']' ) {; 369 error_string = warning + "" - a comma separated list of version specifiers "";; 370 error_string += ""enclosed in square brackets expected"";; 371 error_string += ""as a value of version parameter"";; 372 return false;; 373 }; 374 ; 375 TSchemaRuleProcessor::SplitList( it1->second.substr( 1, it1->second.size()-2 ),; 376 lst );; 377 if( lst.empty() ) {; 378 error_string = warning + "" - the list of versions is empty"";; 379 }; 380 ; 381 for( const auto& version : lst ); 382 if( !TSchemaRuleProcessor::ProcessVersion( version, ver ) ) {; 383 error_string = warning + "" - "" + version + "" is not a valid value"";; 384 error_string += "" of version parameter"";; 385 return false;; 386 }; 387 }; 388 ; 389 //-----------------------------------------------------------------------; 390 // Check if we're dealing with renameing declaration - sourceClass,; 391 // targetClass and either version or checksum required; 392 //////////////////////////////////////////////////////////////////////////; 393 ; 394 if( rule.size() == 3 || (rule.size() == 4 && it1 != rule.end() && it2 != rule.end()) ); 395 return true;; 396 ; 397 //-----------------------------------------------------------------------; 398 // Check if we have all the keys we need; 399 //-----------------------------------------------------------------------; 400 std::string keys[] = {""target"", ""source""};; 401 for( int i = 0; i < 2; ++i ) {; 402 it1 = rule.find( keys[i] );; 403 if( it1 == rule.end() ) {; 404 error_string = warning + "" - required parameter is missing: "";; 405 error_string += keys[i];; 406 return false;; 407 }; 408 }; 409 ; 410 //---------------------------------------------------------------------",MatchSource.WIKI,doc/master/RConversionRuleParser_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html
https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html:31262,Security,checksum,checksum,31262,"t << "" rule->fTarget = \"""" << (*it)[""target""];; 802 output << ""\"";"" << std::endl;; 803 }; 804 ; 805 if( it->find( ""source"" ) != it->end() ) {; 806 output << "" rule->fSource = \"""" << (*it)[""source""];; 807 output << ""\"";"" << std::endl;; 808 }; 809 ; 810 //--------------------------------------------------------------------; 811 // Deal with non mandatory keys; 812 ///////////////////////////////////////////////////////////////////////; 813 ; 814 if( it->find( ""funcname"" ) != it->end() ) {; 815 std::string code = (*it)[""code""];; 816 StrReplace( code, ""\n"", ""\\n"" );; 817 StrReplace( code, ""\"""", ""\\\"""");; 818 ; 819 output << "" rule->fFunctionPtr = (void *)TFunc2void( "";; 820 output << (*it)[""funcname""] << "");"" << std::endl;; 821 output << "" rule->fCode = \"""" << code;; 822 output << ""\"";"" << std::endl;; 823 }; 824 ; 825 if( it->find( ""version"" ) != it->end() ) {; 826 output << "" rule->fVersion = \"""" << (*it)[""version""];; 827 output << ""\"";"" << std::endl;; 828 }; 829 ; 830 if( it->find( ""checksum"" ) != it->end() ) {; 831 output << "" rule->fChecksum = \"""" << (*it)[""checksum""];; 832 output << ""\"";"" << std::endl;; 833 }; 834 ; 835 if( it->find( ""embed"" ) != it->end() ) {; 836 output << "" rule->fEmbed = "" << (*it)[""embed""];; 837 output << "";"" << std::endl;; 838 }; 839 ; 840 if( it->find( ""include"" ) != it->end() ) {; 841 output << "" rule->fInclude = \"""" << (*it)[""include""];; 842 output << ""\"";"" << std::endl;; 843 }; 844 ; 845 if( it->find( ""attributes"" ) != it->end() ) {; 846 output << "" rule->fAttributes = \"""" << (*it)[""attributes""];; 847 output << ""\"";"" << std::endl;; 848 }; 849 }; 850 }; 851 ; 852 /////////////////////////////////////////////////////////////////////////////; 853 /// Get the list of includes specified in the shema rules; 854 ; 855 void GetRuleIncludes( std::list<std::string> &result ); 856 {; 857 std::list<std::string> tmp;; 858 std::list<SchemaRuleMap_t>::iterator rule;; 859 SchemaRuleMap_t::iterator attr;; 860 SchemaRuleClassMap_t::iterator it;; 861 ; 862 /",MatchSource.WIKI,doc/master/RConversionRuleParser_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html
https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html:31340,Security,checksum,checksum,31340,"dl;; 803 }; 804 ; 805 if( it->find( ""source"" ) != it->end() ) {; 806 output << "" rule->fSource = \"""" << (*it)[""source""];; 807 output << ""\"";"" << std::endl;; 808 }; 809 ; 810 //--------------------------------------------------------------------; 811 // Deal with non mandatory keys; 812 ///////////////////////////////////////////////////////////////////////; 813 ; 814 if( it->find( ""funcname"" ) != it->end() ) {; 815 std::string code = (*it)[""code""];; 816 StrReplace( code, ""\n"", ""\\n"" );; 817 StrReplace( code, ""\"""", ""\\\"""");; 818 ; 819 output << "" rule->fFunctionPtr = (void *)TFunc2void( "";; 820 output << (*it)[""funcname""] << "");"" << std::endl;; 821 output << "" rule->fCode = \"""" << code;; 822 output << ""\"";"" << std::endl;; 823 }; 824 ; 825 if( it->find( ""version"" ) != it->end() ) {; 826 output << "" rule->fVersion = \"""" << (*it)[""version""];; 827 output << ""\"";"" << std::endl;; 828 }; 829 ; 830 if( it->find( ""checksum"" ) != it->end() ) {; 831 output << "" rule->fChecksum = \"""" << (*it)[""checksum""];; 832 output << ""\"";"" << std::endl;; 833 }; 834 ; 835 if( it->find( ""embed"" ) != it->end() ) {; 836 output << "" rule->fEmbed = "" << (*it)[""embed""];; 837 output << "";"" << std::endl;; 838 }; 839 ; 840 if( it->find( ""include"" ) != it->end() ) {; 841 output << "" rule->fInclude = \"""" << (*it)[""include""];; 842 output << ""\"";"" << std::endl;; 843 }; 844 ; 845 if( it->find( ""attributes"" ) != it->end() ) {; 846 output << "" rule->fAttributes = \"""" << (*it)[""attributes""];; 847 output << ""\"";"" << std::endl;; 848 }; 849 }; 850 }; 851 ; 852 /////////////////////////////////////////////////////////////////////////////; 853 /// Get the list of includes specified in the shema rules; 854 ; 855 void GetRuleIncludes( std::list<std::string> &result ); 856 {; 857 std::list<std::string> tmp;; 858 std::list<SchemaRuleMap_t>::iterator rule;; 859 SchemaRuleMap_t::iterator attr;; 860 SchemaRuleClassMap_t::iterator it;; 861 ; 862 //-----------------------------------------------------------------------; 863 ",MatchSource.WIKI,doc/master/RConversionRuleParser_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html
https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html:4597,Usability,clear,clear,4597,"-------------------------------------------; 118 // If the first symbol does not end is not followed by equal then it; 119 // defaults to being the sourceClass.; 120 //////////////////////////////////////////////////////////////////////////; 121 ; 122 {; 123 std::string::size_type endsymbol = FindEndSymbol( command );; 124 if ( endsymbol == command.length() || command[endsymbol] == ' ' || command[endsymbol] == '\t' ) {; 125 ; 126// std::string::size_type space_pos = command.find( ' ' );; 127// std::string::size_type equal_pos = command.find( '=' );; 128// if ( space_pos < equal_pos) {; 129 std::string value = TSchemaRuleProcessor::Trim( command.substr( 0, endsymbol ) );; 130 result[""sourceClass""] = value;; 131 result[""targetClass""] = value;; 132 if (endsymbol < command.length()) {; 133 command = TSchemaRuleProcessor::Trim( command.substr( endsymbol+1 ) );; 134 } else {; 135 command.clear();; 136 }; 137 ; 138 //-----------------------------------------------------------------------; 139 // If the first symbol is the targetClass then the 2nd symbol can be; 140 // the source data member name.; 141 //-----------------------------------------------------------------------; 142// space_pos = command.find( ' ' );; 143// equal_pos = command.find( '=' );; 144// if ( space_pos < equal_pos ) {; 145 endsymbol = FindEndSymbol( command );; 146 if ( endsymbol == command.length() || command[endsymbol] == ' ' || command[endsymbol] == '\t' ) {; 147 std::string membervalue = TSchemaRuleProcessor::Trim( command.substr( 0, endsymbol ) );; 148 result[""source""] = membervalue;; 149 result[""target""] = membervalue;; 150 command = TSchemaRuleProcessor::Trim( command.substr( endsymbol+1 ) );; 151 }; 152 }; 153 }; 154 ; 155 //-----------------------------------------------------------------------; 156 // Process the input until there are no characters left; 157 //////////////////////////////////////////////////////////////////////////; 158 ; 159 while( !command.empty() ) {; 160 //---------------",MatchSource.WIKI,doc/master/RConversionRuleParser_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RConversionRuleParser_8cxx_source.html
https://root.cern/doc/master/RConversionRuleParser_8h_source.html:653,Modifiability,variab,variables,653,"h""; 16 ; 17namespace ROOT; 18{; 19 //---------------------------------------------------------------------------; 20 // Global variables; 21 //---------------------------------------------------------------------------; 22 typedef std::map<std::string, std::string> SchemaRuleMap_t;; 23 typedef std::map<std::string, std::list<SchemaRuleMap_t> > SchemaRuleClassMap_t;; 24 R__EXTERN SchemaRuleClassMap_t gReadRules;; 25 R__EXTERN SchemaRuleClassMap_t gReadRawRules;; 26 ; 27 typedef std::map<std::string, ROOT::Internal::TSchemaType> MembersTypeMap_t;; 28 ; 29 //---------------------------------------------------------------------------; 30 // Create the data member name-type map; 31 //---------------------------------------------------------------------------; 32 // void CreateNameTypeMap( const clang::CXXRecordDecl &cl, MembersTypeMap_t& members );; 33 ; 34 //---------------------------------------------------------------------------; 35 // Check if given rule contains references to valid data members; 36 //---------------------------------------------------------------------------; 37 bool HasValidDataMembers( SchemaRuleMap_t& rule, MembersTypeMap_t& members,; 38 std::string& error_string);; 39 ; 40 //---------------------------------------------------------------------------; 41 // Write the conversion function for Read rule; 42 //---------------------------------------------------------------------------; 43 void WriteReadRuleFunc( SchemaRuleMap_t& rule",MatchSource.WIKI,doc/master/RConversionRuleParser_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RConversionRuleParser_8h_source.html
https://root.cern/doc/master/RCsvDS_8cxx_source.html:3273,Availability,avail,available,3273," comma) must be quoted.; 43~~~; 44 1997,Ford,E350,""Super, luxurious truck""; 45~~~; 46- Fields with double-quote characters must be quoted, and each of the embedded; 47double-quote characters must be represented by a pair of double-quote characters.; 48~~~; 49 1997,Ford,E350,""Super, """"luxurious"""" truck""; 50~~~; 51- Fields with embedded line breaks are not supported, even when quoted.; 52~~~; 53 1997,Ford,E350,""Go get one now; 54 they are going fast""; 55~~~; 56- Spaces are considered part of a field and are not ignored.; 57~~~; 58 1997, Ford , E350; 59 not same as; 60 1997,Ford,E350; 61 but same as; 62 1997, ""Ford"" , E350; 63~~~; 64- If a header row is provided, it must contain column names for each of the fields.; 65~~~; 66 Year,Make,Model; 67 1997,Ford,E350; 68 2000,Mercury,Cougar; 69~~~; 70 ; 71The current implementation of RCsvDS reads the entire CSV file content into memory before; 72RDataFrame starts processing it. Therefore, before creating a CSV RDataFrame, it is; 73important to check both how much memory is available and the size of the CSV file.; 74 ; 75RCsvDS can handle empty cells and also allows the usage of the special keywords ""NaN"" and ""nan"" to; 76indicate `nan` values. If the column is of type double, these cells are stored internally as `nan`.; 77Empty cells and explicit `nan`-s inside columns of type Long64_t/bool are stored as zeros.; 78*/; 79// clang-format on; 80 ; 81#include <ROOT/TSeq.hxx>; 82#include <ROOT/RCsvDS.hxx>; 83#include <ROOT/RRawFile.hxx>; 84#include <TError.h>; 85 ; 86#include <algorithm>; 87#include <memory>; 88#include <sstream>; 89#include <string>; 90 ; 91namespace ROOT {; 92 ; 93namespace RDF {; 94 ; 95std::string RCsvDS::AsString(); 96{; 97 return ""CSV data source"";; 98}; 99 ; 100// Regular expressions for type inference; 101const TRegexp RCsvDS::fgIntRegex(""^[-+]?[0-9]+$"");; 102const TRegexp RCsvDS::fgDoubleRegex1(""^[-+]?[0-9]+\\.[0-9]*$"");; 103const TRegexp RCsvDS::fgDoubleRegex2(""^[-+]?[0-9]*\\.[0-9]+$"");; 104const TRegexp ",MatchSource.WIKI,doc/master/RCsvDS_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RCsvDS_8cxx_source.html
https://root.cern/doc/master/RCsvDS_8cxx_source.html:19463,Integrability,message,messages,19463,"es.resize(nColumns, std::vector<Long64_t>(fNSlots));; 549 fStringEvtValues.resize(nColumns, std::vector<std::string>(fNSlots));; 550 fBoolEvtValues.resize(nColumns, std::deque<bool>(fNSlots));; 551}; 552 ; 553std::string RCsvDS::GetLabel(); 554{; 555 return ""RCsv"";; 556}; 557 ; 558RDataFrame FromCSV(std::string_view fileName, bool readHeaders, char delimiter, Long64_t linesChunkSize,; 559 std::unordered_map<std::string, char> &&colTypes); 560{; 561 ROOT::RDataFrame rdf(; 562 std::make_unique<RCsvDS>(fileName, readHeaders, delimiter, linesChunkSize, std::move(colTypes)));; 563 return rdf;; 564}; 565 ; 566} // ns RDF; 567 ; 568} // ns ROOT; RCsvDS.hxx; RRawFile.hxx; b#define b(i)Definition RSha256.hxx:100; sizesize_t size(const MatrixT &matrix)retrieve the size of a square matrix; Long64_tlong long Long64_tDefinition RtypesCore.h:69; ULong64_tunsigned long long ULong64_tDefinition RtypesCore.h:70; TError.h; Infovoid Info(const char *location, const char *msgfmt,...)Use this function for informational messages.Definition TError.cxx:218; Warningvoid Warning(const char *location, const char *msgfmt,...)Use this function in warning situations.Definition TError.cxx:229; pwinID h TVirtualViewer3D TVirtualGLPainter pDefinition TGWin32VirtualGLProxy.cxx:51; offsetOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t Float_t Float_t Int_t Int_t UInt_t UInt_t Rectangle_t Int_t Int_t Window_t TString Int_t GCValues_t GetPrimarySelectionOwner GetDisplay GetScreen GetColormap GetNativeEvent const char const char dpyName wid window const char font_name cursor keysym reg const char only_if_exist regb h Point_t winding char text const char depth char const char Int_t count const char ColorStruct_t color const char Pixmap_t Pixmap_t PictureAttributes_t attr const char char ret_data h unsigned char height h offsetDefinition TGWin32Vi",MatchSource.WIKI,doc/master/RCsvDS_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RCsvDS_8cxx_source.html
https://root.cern/doc/master/RCsvDS_8cxx_source.html:25877,Integrability,interface,interface,25877,"ParseColumnsstd::vector< std::string > ParseColumns(const std::string &)Definition RCsvDS.cxx:276; ROOT::RDF::RCsvDS::FillHeadersvoid FillHeaders(const std::string &)Definition RCsvDS.cxx:111; ROOT::RDF::RCsvDS::fCsvFilestd::unique_ptr< ROOT::Internal::RRawFile > fCsvFileDefinition RCsvDS.hxx:48; ROOT::RDF::RCsvDS::fgDoubleRegex1static const TRegexp fgDoubleRegex1Definition RCsvDS.hxx:43; ROOT::RDF::RCsvDS::fStringEvtValuesstd::vector< std::vector< std::string > > fStringEvtValuesDefinition RCsvDS.hxx:61; ROOT::RDF::RCsvDS::fBoolEvtValuesstd::vector< std::deque< bool > > fBoolEvtValuesDefinition RCsvDS.hxx:64; ROOT::RDF::RCsvDS::ColType_tchar ColType_tDefinition RCsvDS.hxx:39; ROOT::RDF::RCsvDS::FreeRecordsvoid FreeRecords()Definition RCsvDS.cxx:377; ROOT::RDF::RCsvDS::fColTypesListstd::list< ColType_t > fColTypesListDefinition RCsvDS.hxx:56; ROOT::RDF::RDataSource::Record_tstd::vector< void * > Record_tDefinition RDataSource.hxx:112; ROOT::RDataFrameROOT's RDataFrame offers a modern, high-level interface for analysis of data stored in TTree ,...Definition RDataFrame.hxx:41; TRegexpRegular expression class.Definition TRegexp.h:31; TRegexp::IndexSsiz_t Index(const TString &str, Ssiz_t *len, Ssiz_t start=0) constFind the first occurrence of the regexp in string and return the position, or -1 if there is no match...Definition TRegexp.cxx:213; bool; lineTLine * lineDefinition entrylistblock_figure1.C:235; ROOT::RDF::FromCSVRDataFrame FromCSV(std::string_view fileName, bool readHeaders=true, char delimiter=',', Long64_t linesChunkSize=-1LL, std::unordered_map< std::string, char > &&colTypes={})Factory method to create a CSV RDataFrame.Definition RCsvDS.cxx:558; ROOTtbb::task_arena is an alias of tbb::interface7::task_arena, which doesn't allow to forward declare tb...Definition EExecutionPolicy.hxx:4; ROOT::TSeqUTSeq< unsigned int > TSeqUDefinition TSeq.hxx:204. treedataframesrcRCsvDS.cxx. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:02 (GVA Time) usin",MatchSource.WIKI,doc/master/RCsvDS_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RCsvDS_8cxx_source.html
https://root.cern/doc/master/RCsvDS_8cxx_source.html:8995,Performance,load,loaded,8995,"ng::npos) {; 215 std::string msg = ""Type alias '"" + std::string(1, col.second) + ""' is not supported.\n"";; 216 msg += ""Supported type aliases are 'O' for boolean, 'D' for double, 'L' for Long64_t, 'T' for std::string."";; 217 throw std::runtime_error(msg);; 218 }; 219 }; 220}; 221 ; 222void RCsvDS::InferColTypes(std::vector<std::string> &columns); 223{; 224 const auto second_line = fCsvFile->GetFilePos();; 225 ; 226 for (auto i = 0u; i < columns.size(); ++i) {; 227 const auto userSpecifiedType = fColTypes.find(fHeaders[i]);; 228 if (userSpecifiedType != fColTypes.end()) {; 229 fColTypesList.push_back(userSpecifiedType->second);; 230 continue;; 231 }; 232 ; 233 // read <=10 extra lines until a non-empty cell on this column is found, so that type is determined; 234 for (auto extraRowsRead = 0u; extraRowsRead < 10u && columns[i] == ""nan""; ++extraRowsRead) {; 235 std::string line;; 236 if (!fCsvFile->Readln(line)); 237 break; // EOF; 238 const auto temp_columns = ParseColumns(line);; 239 if (temp_columns[i] != ""nan""); 240 columns[i] = temp_columns[i]; // will break the loop in the next iteration; 241 }; 242 // reset the reading from the second line, because the first line is already loaded in `columns`; 243 fCsvFile->Seek(second_line);; 244 ; 245 if (columns[i] == ""nan"") {; 246 // could not find a non-empty value, default to double; 247 fColTypes[fHeaders[i]] = 'D';; 248 fColTypesList.push_back('D');; 249 } else {; 250 InferType(columns[i], i);; 251 }; 252 }; 253}; 254 ; 255void RCsvDS::InferType(const std::string &col, unsigned int idxCol); 256{; 257 ColType_t type;; 258 int dummy;; 259 ; 260 if (fgIntRegex.Index(col, &dummy) != -1) {; 261 type = 'L'; // Long64_t; 262 } else if (fgDoubleRegex1.Index(col, &dummy) != -1 || fgDoubleRegex2.Index(col, &dummy) != -1 ||; 263 fgDoubleRegex3.Index(col, &dummy) != -1) {; 264 type = 'D'; // double; 265 } else if (fgTrueRegex.Index(col, &dummy) != -1 || fgFalseRegex.Index(col, &dummy) != -1) {; 266 type = 'O'; // bool; 267 } else {",MatchSource.WIKI,doc/master/RCsvDS_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RCsvDS_8cxx_source.html
https://root.cern/doc/master/RCsvDS_8cxx_source.html:21662,Security,access,access,21662,"tangle_t WindowAttributes_t indexDefinition TGWin32VirtualXProxy.cxx:168; typeOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t Float_t Float_t Int_t Int_t UInt_t UInt_t Rectangle_t Int_t Int_t Window_t TString Int_t GCValues_t GetPrimarySelectionOwner GetDisplay GetScreen GetColormap GetNativeEvent const char const char dpyName wid window const char font_name cursor keysym reg const char only_if_exist regb h Point_t winding char text const char depth char const char Int_t count const char ColorStruct_t color const char Pixmap_t Pixmap_t PictureAttributes_t attr const char char ret_data h unsigned char height h Atom_t Int_t ULong_t ULong_t unsigned char prop_list Atom_t Atom_t Atom_t Time_t typeDefinition TGWin32VirtualXProxy.cxx:249; gDebugInt_t gDebugDefinition TROOT.cxx:597; TSeq.hxx; ROOT::Internal::RRawFileThe RRawFile provides read-only access to local and remote files.Definition RRawFile.hxx:43; ROOT::RDF::RCsvDS::GetTypeNamestd::string GetTypeName(std::string_view colName) const finalType of a column as a string, e.g.Definition RCsvDS.cxx:495; ROOT::RDF::RCsvDS::FillRecordvoid FillRecord(const std::string &, Record_t &)Definition RCsvDS.cxx:120; ROOT::RDF::RCsvDS::GetTypeColType_t GetType(std::string_view colName) constDefinition RCsvDS.cxx:484; ROOT::RDF::RCsvDS::fDoubleEvtValuesstd::vector< std::vector< double > > fDoubleEvtValuesDefinition RCsvDS.hxx:59; ROOT::RDF::RCsvDS::InferTypevoid InferType(const std::string &, unsigned int)Definition RCsvDS.cxx:255; ROOT::RDF::RCsvDS::fDataPosstd::uint64_t fDataPosDefinition RCsvDS.hxx:45; ROOT::RDF::RCsvDS::fgColTypeMapstatic const std::unordered_map< ColType_t, std::string > fgColTypeMapDefinition RCsvDS.hxx:40; ROOT::RDF::RCsvDS::ParseValuesize_t ParseValue(const std::string &, std::vector< std::string > &, size_t)Definition RCsvDS.cxx:287; ROOT::RDF::RCsv",MatchSource.WIKI,doc/master/RCsvDS_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RCsvDS_8cxx_source.html
https://root.cern/doc/master/RCsvDS_8cxx_source.html:17998,Testability,assert,assert,17998,"d::runtime_error(msg);; 490 }; 491 ; 492 return fColTypes.at(colName.data());; 493}; 494 ; 495std::string RCsvDS::GetTypeName(std::string_view colName) const; 496{; 497 return fgColTypeMap.at(GetType(colName));; 498}; 499 ; 500bool RCsvDS::HasColumn(std::string_view colName) const; 501{; 502 return fHeaders.end() != std::find(fHeaders.begin(), fHeaders.end(), colName);; 503}; 504 ; 505bool RCsvDS::SetEntry(unsigned int slot, ULong64_t entry); 506{; 507 // Here we need to normalise the entry to the number of lines we already processed.; 508 const auto offset = (fEntryRangesRequested - 1) * fLinesChunkSize;; 509 const auto recordPos = entry - offset;; 510 int colIndex = 0;; 511 for (auto &colType : fColTypesList) {; 512 auto dataPtr = fRecords[recordPos][colIndex];; 513 switch (colType) {; 514 case 'D': {; 515 fDoubleEvtValues[colIndex][slot] = *static_cast<double *>(dataPtr);; 516 break;; 517 }; 518 case 'L': {; 519 fLong64EvtValues[colIndex][slot] = *static_cast<Long64_t *>(dataPtr);; 520 break;; 521 }; 522 case 'O': {; 523 fBoolEvtValues[colIndex][slot] = *static_cast<bool *>(dataPtr);; 524 break;; 525 }; 526 case 'T': {; 527 fStringEvtValues[colIndex][slot] = *static_cast<std::string *>(dataPtr);; 528 break;; 529 }; 530 }; 531 colIndex++;; 532 }; 533 return true;; 534}; 535 ; 536void RCsvDS::SetNSlots(unsigned int nSlots); 537{; 538 assert(0U == fNSlots && ""Setting the number of slots even if the number of slots is different from zero."");; 539 ; 540 fNSlots = nSlots;; 541 ; 542 const auto nColumns = fHeaders.size();; 543 // Initialize the entire set of addresses; 544 fColAddresses.resize(nColumns, std::vector<void *>(fNSlots, nullptr));; 545 ; 546 // Initialize the per event data holders; 547 fDoubleEvtValues.resize(nColumns, std::vector<double>(fNSlots));; 548 fLong64EvtValues.resize(nColumns, std::vector<Long64_t>(fNSlots));; 549 fStringEvtValues.resize(nColumns, std::vector<std::string>(fNSlots));; 550 fBoolEvtValues.resize(nColumns, std::deque<bool>(fNSlots));;",MatchSource.WIKI,doc/master/RCsvDS_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RCsvDS_8cxx_source.html
https://root.cern/doc/master/RCsvDS_8cxx_source.html:13952,Usability,clear,clear,13952,"e user is trying to set types only of existing columns; 363 ValidateColTypes(columns);; 364 ; 365 // Infer types of columns with first record; 366 InferColTypes(columns);; 367 ; 368 // rewind; 369 fCsvFile->Seek(fDataPos);; 370 } else {; 371 std::string msg = ""Could not infer column types of CSV file "";; 372 msg += fileName;; 373 throw std::runtime_error(msg);; 374 }; 375}; 376 ; 377void RCsvDS::FreeRecords(); 378{; 379 for (auto &record : fRecords) {; 380 for (size_t i = 0; i < record.size(); ++i) {; 381 void *p = record[i];; 382 const auto colType = fColTypes[fHeaders[i]];; 383 switch (colType) {; 384 case 'D': {; 385 delete static_cast<double *>(p);; 386 break;; 387 }; 388 case 'L': {; 389 delete static_cast<Long64_t *>(p);; 390 break;; 391 }; 392 case 'O': {; 393 delete static_cast<bool *>(p);; 394 break;; 395 }; 396 case 'T': {; 397 delete static_cast<std::string *>(p);; 398 break;; 399 }; 400 }; 401 }; 402 }; 403 fRecords.clear();; 404}; 405 ; 406////////////////////////////////////////////////////////////////////////; 407/// Destructor.; 408RCsvDS::~RCsvDS(); 409{; 410 FreeRecords();; 411}; 412 ; 413void RCsvDS::Finalize(); 414{; 415 fCsvFile->Seek(fDataPos);; 416 fProcessedLines = 0ULL;; 417 fEntryRangesRequested = 0ULL;; 418 FreeRecords();; 419}; 420 ; 421const std::vector<std::string> &RCsvDS::GetColumnNames() const; 422{; 423 return fHeaders;; 424}; 425 ; 426std::vector<std::pair<ULong64_t, ULong64_t>> RCsvDS::GetEntryRanges(); 427{; 428 // Read records and store them in memory; 429 auto linesToRead = fLinesChunkSize;; 430 FreeRecords();; 431 ; 432 std::string line;; 433 while ((-1LL == fLinesChunkSize || 0 != linesToRead) && fCsvFile->Readln(line)) {; 434 if (line.empty()) continue; // skip empty lines; 435 fRecords.emplace_back();; 436 FillRecord(line, fRecords.back());; 437 --linesToRead;; 438 }; 439 ; 440 if (!fColContainingEmpty.empty()) {; 441 std::string msg = """";; 442 for (const auto &col : fColContainingEmpty) {; 443 const auto colT = GetTypeName(",MatchSource.WIKI,doc/master/RCsvDS_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RCsvDS_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:1650,Availability,avail,available,1650,"10 ; 11#include ""ROOT/InternalTreeUtils.hxx""; 12#include ""ROOT/RDataFrame.hxx""; 13#include ""ROOT/RDataSource.hxx""; 14#include ""ROOT/RDF/RDatasetSpec.hxx""; 15#include ""ROOT/RDF/RInterface.hxx""; 16#include ""ROOT/RDF/RLoopManager.hxx""; 17#include ""ROOT/RDF/Utils.hxx""; 18#include <string_view>; 19#include ""TChain.h""; 20#include ""TDirectory.h""; 21#include ""RtypesCore.h"" // for ULong64_t; 22#include ""TTree.h""; 23 ; 24#include <fstream> // std::ifstream; 25#include <nlohmann/json.hpp> // nlohmann::json::parse; 26#include <memory> // for make_shared, allocator, shared_ptr; 27#include <ostream> // ostringstream; 28#include <stdexcept>; 29#include <string>; 30#include <vector>; 31 ; 32// clang-format off; 33/**; 34* \class ROOT::RDataFrame; 35* \ingroup dataframe; 36* \brief ROOT's RDataFrame offers a modern, high-level interface for analysis of data stored in TTree , CSV and other data formats, in C++ or Python.; 37 ; 38In addition, multi-threading and other low-level optimisations allow users to exploit all the resources available; 39on their machines completely transparently.<br>; 40Skip to the [class reference](#reference) or keep reading for the user guide.; 41 ; 42In a nutshell:; 43~~~{.cpp}; 44ROOT::EnableImplicitMT(); // Tell ROOT you want to go parallel; 45ROOT::RDataFrame d(""myTree"", ""file_*.root""); // Interface to TTree and TChain; 46auto myHisto = d.Histo1D(""Branch_A""); // This books the (lazy) filling of a histogram; 47myHisto->Draw(); // Event loop is run here, upon first access to a result; 48~~~; 49 ; 50Calculations are expressed in terms of a type-safe *functional chain of actions and transformations*, RDataFrame takes; 51care of their execution. The implementation automatically puts in place several low level optimisations such as; 52multi-thread parallelization and caching.; 53 ; 54\htmlonly; 55<a href=""https://doi.org/10.5281/zenodo.260230""><img src=""https://zenodo.org/badge/DOI/10.5281/zenodo.260230.svg""; 56alt=""DOI""></a>; 57\endhtmlonly; 58 ; 59## For the",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:6278,Availability,avail,available,6278,"ine a new column that is updated when the input sample changes, e.g. when switching tree being processed in a chain. |; 104| DefineSlot() | Same as Define(), but the user-defined function must take an extra `unsigned int slot` as its first parameter. `slot` will take a different value, `0` to `nThreads - 1`, for each thread of execution. This is meant as a helper in writing thread-safe Define() transformation when using RDataFrame after ROOT::EnableImplicitMT(). DefineSlot() works just as well with single-thread execution: in that case `slot` will always be `0`. |; 105| DefineSlotEntry() | Same as DefineSlot(), but the entry number is passed in addition to the slot number. This is meant as a helper in case the expression depends on the entry number. For details about entry numbers in multi-threaded runs, see [here](\ref helper-cols). |; 106| Filter() | Filter rows based on user-defined conditions. |; 107| FilterAvailable() | Specialized Filter. If the value of the input column is available, keep the entry, otherwise discard it. |; 108| FilterMissing() | Specialized Filter. If the value of the input column is missing, keep the entry, otherwise discard it. |; 109| Range() | Filter rows based on entry number (single-thread only). |; 110| Redefine() | Overwrite the value and/or type of an existing column. See Define() for more information. |; 111| RedefineSlot() | Overwrite the value and/or type of an existing column. See DefineSlot() for more information. |; 112| RedefineSlotEntry() | Overwrite the value and/or type of an existing column. See DefineSlotEntry() for more information. |; 113| Vary() | Register systematic variations for an existing column. Varied results are then extracted via VariationsFor(). |; 114 ; 115 ; 116### Actions; 117Actions aggregate data into a result. Each one is described in more detail in the reference guide.; 118 ; 119In the following, whenever we say an action ""returns"" something, we always mean it returns a smart pointer to it. Actions onl",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:12267,Availability,avail,available,12267,"ad of execution. This is meant as a helper in writing thread-safe Foreach() actions when using RDataFrame after ROOT::EnableImplicitMT(). ForeachSlot() works just as well with single-thread execution: in that case `slot` will always be `0`. |; 152| Snapshot() | Write the processed dataset to disk, in a new TTree and TFile. Custom columns can be saved as well, filtered entries are not saved. Users can specify which columns to save (default is all). Snapshot, by default, overwrites the output file if it already exists. Snapshot() can be made *lazy* setting the appropriate flag in the snapshot options.|; 153 ; 154 ; 155### Queries; 156 ; 157These operations do not modify the dataframe or book computations but simply return information on the RDataFrame object.; 158 ; 159| **Operation** | **Description** |; 160|---------------------|-----------------|; 161| Describe() | Get useful information describing the dataframe, e.g. columns and their types. |; 162| GetColumnNames() | Get the names of all the available columns of the dataset. |; 163| GetColumnType() | Return the type of a given column as a string. |; 164| GetColumnTypeNamesList() | Return the list of type names of columns in the dataset. |; 165| GetDefinedColumnNames() | Get the names of all the defined columns. |; 166| GetFilterNames() | Return the names of all filters in the computation graph. |; 167| GetNRuns() | Return the number of event loops run by this RDataFrame instance so far. |; 168| GetNSlots() | Return the number of processing slots that RDataFrame will use during the event loop (i.e. the concurrency level). |; 169| SaveGraph() | Store the computation graph of an RDataFrame in [DOT format (graphviz)](https://en.wikipedia.org/wiki/DOT_(graph_description_language)) for easy inspection. See the [relevant section](\ref representgraph) for details. |; 170 ; 171\anchor introduction; 172## Introduction; 173Users define their analysis as a sequence of operations to be performed on the dataframe object; the f",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:25677,Availability,avail,available,25677,"t be; 406valid C++ and it is just-in-time compiled. The process has a small runtime overhead and like with filters it is currently the only possible approach when using PyROOT.; 407 ; 408Previously, when showing the different ways an RDataFrame can be created, we showed a constructor that takes a; 409number of entries as a parameter. In the following example we show how to combine such an ""empty"" RDataFrame with Define(); 410transformations to create a dataset on the fly. We then save the generated data on disk using the Snapshot() action.; 411~~~{.cpp}; 412RDataFrame d(100); // an RDF that will generate 100 entries (currently empty); 413int x = -1;; 414auto d_with_columns = d.Define(""x"", [&x] { return ++x; }); 415 .Define(""xx"", [&x] { return x*x; });; 416d_with_columns.Snapshot(""myNewTree"", ""newfile.root"");; 417~~~; 418This example is slightly more advanced than what we have seen so far. First, it makes use of lambda captures (a; 419simple way to make external variables available inside the body of C++ lambdas) to act on the same variable `x` from; 420both Define() transformations. Second, we have *stored* the transformed dataframe in a variable. This is always; 421possible, since at each point of the transformation chain users can store the status of the dataframe for further use (more; 422on this [below](#callgraphs)).; 423 ; 424You can read more about defining new columns [here](#custom-columns).; 425 ; 426\image html RDF_Graph.png ""A graph composed of two branches, one starting with a filter and one with a define. The end point of a branch is always an action.""; 427 ; 428 ; 429### Running on a range of entries; 430It is sometimes necessary to limit the processing of the dataset to a range of entries. For this reason, the RDataFrame; 431offers the concept of ranges as a node of the RDataFrame chain of transformations; this means that filters, columns and; 432actions can be concatenated to and intermixed with Range()s. If a range is specified after a filter, the ",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:27308,Availability,avail,available,27308,"# Running on a range of entries; 430It is sometimes necessary to limit the processing of the dataset to a range of entries. For this reason, the RDataFrame; 431offers the concept of ranges as a node of the RDataFrame chain of transformations; this means that filters, columns and; 432actions can be concatenated to and intermixed with Range()s. If a range is specified after a filter, the range will act; 433exclusively on the entries passing the filter -- it will not even count the other entries! The same goes for a Range(); 434hanging from another Range(). Here are some commented examples:; 435~~~{.cpp}; 436RDataFrame d(""myTree"", ""file.root"");; 437// Here we store a dataframe that loops over only the first 30 entries in a variable; 438auto d30 = d.Range(30);; 439// This is how you pick all entries from 15 onwards; 440auto d15on = d.Range(15, 0);; 441// We can specify a stride too, in this case we pick an event every 3; 442auto d15each3 = d.Range(0, 15, 3);; 443~~~; 444Note that ranges are not available when multi-threading is enabled. More information on ranges is available; 445[here](#ranges).; 446 ; 447### Executing multiple actions in the same event loop; 448As a final example let us apply two different cuts on branch ""MET"" and fill two different histograms with the ""pt_v"" of; 449the filtered events.; 450By now, you should be able to easily understand what is happening:; 451~~~{.cpp}; 452RDataFrame d(""treeName"", ""file.root"");; 453auto h1 = d.Filter(""MET > 10"").Histo1D(""pt_v"");; 454auto h2 = d.Histo1D(""pt_v"");; 455h1->Draw(); // event loop is run once here; 456h2->Draw(""SAME""); // no need to run the event loop again; 457~~~; 458RDataFrame executes all above actions by **running the event-loop only once**. The trick is that actions are not; 459executed at the moment they are called, but they are **lazy**, i.e. delayed until the moment one of their results is; 460accessed through the smart pointer. At that time, the event loop is triggered and *all* results are produc",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:27381,Availability,avail,available,27381,"cessing of the dataset to a range of entries. For this reason, the RDataFrame; 431offers the concept of ranges as a node of the RDataFrame chain of transformations; this means that filters, columns and; 432actions can be concatenated to and intermixed with Range()s. If a range is specified after a filter, the range will act; 433exclusively on the entries passing the filter -- it will not even count the other entries! The same goes for a Range(); 434hanging from another Range(). Here are some commented examples:; 435~~~{.cpp}; 436RDataFrame d(""myTree"", ""file.root"");; 437// Here we store a dataframe that loops over only the first 30 entries in a variable; 438auto d30 = d.Range(30);; 439// This is how you pick all entries from 15 onwards; 440auto d15on = d.Range(15, 0);; 441// We can specify a stride too, in this case we pick an event every 3; 442auto d15each3 = d.Range(0, 15, 3);; 443~~~; 444Note that ranges are not available when multi-threading is enabled. More information on ranges is available; 445[here](#ranges).; 446 ; 447### Executing multiple actions in the same event loop; 448As a final example let us apply two different cuts on branch ""MET"" and fill two different histograms with the ""pt_v"" of; 449the filtered events.; 450By now, you should be able to easily understand what is happening:; 451~~~{.cpp}; 452RDataFrame d(""treeName"", ""file.root"");; 453auto h1 = d.Filter(""MET > 10"").Histo1D(""pt_v"");; 454auto h2 = d.Histo1D(""pt_v"");; 455h1->Draw(); // event loop is run once here; 456h2->Draw(""SAME""); // no need to run the event loop again; 457~~~; 458RDataFrame executes all above actions by **running the event-loop only once**. The trick is that actions are not; 459executed at the moment they are called, but they are **lazy**, i.e. delayed until the moment one of their results is; 460accessed through the smart pointer. At that time, the event loop is triggered and *all* results are produced; 461simultaneously.; 462 ; 463### Properly exploiting RDataFrame laziness; 4",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:34028,Availability,avail,available,34028," can be passed to the Filter() method to create a **named filter**. Named filters; 555work as usual, but also keep track of how many entries they accept and reject.; 556 ; 557Statistics are retrieved through a call to the Report() method:; 558 ; 559- when Report() is called on the main RDataFrame object, it returns a ROOT::RDF::RResultPtr<RCutFlowReport> relative to all; 560named filters declared up to that point; 561- when called on a specific node (e.g. the result of a Define() or Filter()), it returns a ROOT::RDF::RResultPtr<RCutFlowReport>; 562relative all named filters in the section of the chain between the main RDataFrame and that node (included).; 563 ; 564Stats are stored in the same order as named filters have been added to the graph, and *refer to the latest event-loop*; 565that has been run using the relevant RDataFrame.; 566 ; 567\anchor ranges; 568### Ranges; 569When RDataFrame is not being used in a multi-thread environment (i.e. no call to EnableImplicitMT() was made),; 570Range() transformations are available. These act very much like filters but instead of basing their decision on; 571a filter expression, they rely on `begin`,`end` and `stride` parameters.; 572 ; 573- `begin`: initial entry number considered for this range.; 574- `end`: final entry number (excluded) considered for this range. 0 means that the range goes until the end of the dataset.; 575- `stride`: process one entry of the [begin, end) range every `stride` entries. Must be strictly greater than 0.; 576 ; 577The actual number of entries processed downstream of a Range() node will be `(end - begin)/stride` (or less if less; 578entries than that are available).; 579 ; 580Note that ranges act ""locally"", not based on the global entry count: `Range(10,50)` means ""skip the first 10 entries; 581*that reach this node*, let the next 40 entries pass, then stop processing"". If a range node hangs from a filter node,; 582and the range has a `begin` parameter of 10, that means the range will skip",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:34552,Availability,down,downstream,34552,"section of the chain between the main RDataFrame and that node (included).; 563 ; 564Stats are stored in the same order as named filters have been added to the graph, and *refer to the latest event-loop*; 565that has been run using the relevant RDataFrame.; 566 ; 567\anchor ranges; 568### Ranges; 569When RDataFrame is not being used in a multi-thread environment (i.e. no call to EnableImplicitMT() was made),; 570Range() transformations are available. These act very much like filters but instead of basing their decision on; 571a filter expression, they rely on `begin`,`end` and `stride` parameters.; 572 ; 573- `begin`: initial entry number considered for this range.; 574- `end`: final entry number (excluded) considered for this range. 0 means that the range goes until the end of the dataset.; 575- `stride`: process one entry of the [begin, end) range every `stride` entries. Must be strictly greater than 0.; 576 ; 577The actual number of entries processed downstream of a Range() node will be `(end - begin)/stride` (or less if less; 578entries than that are available).; 579 ; 580Note that ranges act ""locally"", not based on the global entry count: `Range(10,50)` means ""skip the first 10 entries; 581*that reach this node*, let the next 40 entries pass, then stop processing"". If a range node hangs from a filter node,; 582and the range has a `begin` parameter of 10, that means the range will skip the first 10 entries *that pass the; 583preceding filter*.; 584 ; 585Ranges allow ""early quitting"": if all branches of execution of a functional graph reached their `end` value of; 586processed entries, the event-loop is immediately interrupted. This is useful for debugging and quick data explorations.; 587 ; 588\anchor custom-columns; 589### Custom columns; 590Custom columns are created by invoking `Define(name, f, columnList)`. As usual, `f` can be any callable object; 591(function, lambda expression, functor class...); it takes the values of the columns listed in `columnList` (",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:34655,Availability,avail,available,34655,"section of the chain between the main RDataFrame and that node (included).; 563 ; 564Stats are stored in the same order as named filters have been added to the graph, and *refer to the latest event-loop*; 565that has been run using the relevant RDataFrame.; 566 ; 567\anchor ranges; 568### Ranges; 569When RDataFrame is not being used in a multi-thread environment (i.e. no call to EnableImplicitMT() was made),; 570Range() transformations are available. These act very much like filters but instead of basing their decision on; 571a filter expression, they rely on `begin`,`end` and `stride` parameters.; 572 ; 573- `begin`: initial entry number considered for this range.; 574- `end`: final entry number (excluded) considered for this range. 0 means that the range goes until the end of the dataset.; 575- `stride`: process one entry of the [begin, end) range every `stride` entries. Must be strictly greater than 0.; 576 ; 577The actual number of entries processed downstream of a Range() node will be `(end - begin)/stride` (or less if less; 578entries than that are available).; 579 ; 580Note that ranges act ""locally"", not based on the global entry count: `Range(10,50)` means ""skip the first 10 entries; 581*that reach this node*, let the next 40 entries pass, then stop processing"". If a range node hangs from a filter node,; 582and the range has a `begin` parameter of 10, that means the range will skip the first 10 entries *that pass the; 583preceding filter*.; 584 ; 585Ranges allow ""early quitting"": if all branches of execution of a functional graph reached their `end` value of; 586processed entries, the event-loop is immediately interrupted. This is useful for debugging and quick data explorations.; 587 ; 588\anchor custom-columns; 589### Custom columns; 590Custom columns are created by invoking `Define(name, f, columnList)`. As usual, `f` can be any callable object; 591(function, lambda expression, functor class...); it takes the values of the columns listed in `columnList` (",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:41073,Availability,avail,available,41073,"o switch `ROOT.RDataFrame` with; 681the backend-specific `RDataFrame` of your choice, for example:; 682 ; 683~~~{.py}; 684import ROOT; 685 ; 686# Point RDataFrame calls to the Spark specific RDataFrame; 687RDataFrame = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame; 688 ; 689# It still accepts the same constructor arguments as traditional RDataFrame; 690df = RDataFrame(""mytree"", ""myfile.root""); 691 ; 692# Continue the application with the traditional RDataFrame API; 693sum = df.Filter(""x > 10"").Sum(""y""); 694h = df.Histo1D((""name"", ""title"", 10, 0, 10), ""x""); 695 ; 696print(sum.GetValue()); 697h.Draw(); 698~~~; 699 ; 700The main goal of this package is to support running any RDataFrame application distributedly. Nonetheless, not all; 701parts of the RDataFrame API currently work with this package. The subset that is currently available is:; 702- AsNumpy; 703- Count; 704- Define; 705- DefinePerSample; 706- Filter; 707- Graph; 708- Histo[1,2,3]D; 709- HistoND; 710- Max; 711- Mean; 712- Min; 713- Profile[1,2,3]D; 714- Redefine; 715- Snapshot; 716- Stats; 717- StdDev; 718- Sum; 719- Systematic variations: Vary and [VariationsFor](\ref ROOT::RDF::Experimental::VariationsFor).; 720- Parallel submission of distributed graphs: [RunGraphs](\ref ROOT::RDF::RunGraphs).; 721- Information about the dataframe: GetColumnNames.; 722 ; 723with support for more operations coming in the future. Data sources other than TTree and TChain (e.g. CSV, RNTuple) are; 724currently not supported.; 725 ; 726\note The distributed RDataFrame module requires at least Python version 3.8.; 727 ; 728### Connecting to a Spark cluster; 729 ; 730In order to distribute the RDataFrame workload, you can connect to a Spark cluster you have access to through the; 731official [Spark API](https://spark.apache.org/docs/latest/rdd-programming-guide.html#initializing-spark), then hook the; 732connection instance to the distributed `RDataFrame` object like so:; 733 ; 734~~~{.py}; 735import pyspark; 736import ROOT;",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:44372,Availability,avail,available,44372,".dask.org/en/stable/)):; 758 ; 759~~~{.py}; 760import ROOT; 761from dask.distributed import Client; 762 ; 763# Point RDataFrame calls to the Dask specific RDataFrame; 764RDataFrame = ROOT.RDF.Experimental.Distributed.Dask.RDataFrame; 765 ; 766# In a Python script the Dask client needs to be initalized in a context; 767# Jupyter notebooks / Python session don't need this; 768if __name__ == ""__main__"":; 769 # With an already setup cluster that exposes a Dask scheduler endpoint; 770 client = Client(""dask_scheduler.domain.com:8786""); 771 ; 772 # The Dask RDataFrame constructor accepts the Dask Client object as an optional argument; 773 df = RDataFrame(""mytree"",""myfile.root"", daskclient=client); 774 # Proceed as usual; 775 df.Define(""x"",""someoperation"").Histo1D((""name"", ""title"", 10, 0, 10), ""x""); 776~~~; 777 ; 778If an instance of [distributed.Client](http://distributed.dask.org/en/stable/api.html#distributed.Client) is not; 779provided to the RDataFrame object, it will be created for you and it will run the computations in the local machine; 780using all cores available.; 781 ; 782### Choosing the number of distributed tasks; 783 ; 784A distributed RDataFrame has internal logic to define in how many chunks the input dataset will be split before sending; 785tasks to the distributed backend. Each task reads and processes one of said chunks. The logic is backend-dependent, but; 786generically tries to infer how many cores are available in the cluster through the connection object. The number of; 787tasks will be equal to the inferred number of cores. There are cases where the connection object of the chosen backend; 788doesn't have information about the actual resources of the cluster. An example of this is when using Dask to connect to; 789a batch system. The client object created at the beginning of the application does not automatically know how many cores; 790will be available during distributed execution, since the jobs are submitted to the batch system after the creat",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:44742,Availability,avail,available,44742,"setup cluster that exposes a Dask scheduler endpoint; 770 client = Client(""dask_scheduler.domain.com:8786""); 771 ; 772 # The Dask RDataFrame constructor accepts the Dask Client object as an optional argument; 773 df = RDataFrame(""mytree"",""myfile.root"", daskclient=client); 774 # Proceed as usual; 775 df.Define(""x"",""someoperation"").Histo1D((""name"", ""title"", 10, 0, 10), ""x""); 776~~~; 777 ; 778If an instance of [distributed.Client](http://distributed.dask.org/en/stable/api.html#distributed.Client) is not; 779provided to the RDataFrame object, it will be created for you and it will run the computations in the local machine; 780using all cores available.; 781 ; 782### Choosing the number of distributed tasks; 783 ; 784A distributed RDataFrame has internal logic to define in how many chunks the input dataset will be split before sending; 785tasks to the distributed backend. Each task reads and processes one of said chunks. The logic is backend-dependent, but; 786generically tries to infer how many cores are available in the cluster through the connection object. The number of; 787tasks will be equal to the inferred number of cores. There are cases where the connection object of the chosen backend; 788doesn't have information about the actual resources of the cluster. An example of this is when using Dask to connect to; 789a batch system. The client object created at the beginning of the application does not automatically know how many cores; 790will be available during distributed execution, since the jobs are submitted to the batch system after the creation of; 791the connection. In such cases, the logic is to default to process the whole dataset in 2 tasks.; 792 ; 793The number of tasks submitted for distributed execution can be also set programmatically, by providing the optional; 794keyword argument `npartitions` when creating the RDataFrame object. This parameter is accepted irrespectively of the; 795backend used:; 796 ; 797~~~{.py}; 798import ROOT; 799 ; 800# Define ",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:45196,Availability,avail,available,45196,"ml#distributed.Client) is not; 779provided to the RDataFrame object, it will be created for you and it will run the computations in the local machine; 780using all cores available.; 781 ; 782### Choosing the number of distributed tasks; 783 ; 784A distributed RDataFrame has internal logic to define in how many chunks the input dataset will be split before sending; 785tasks to the distributed backend. Each task reads and processes one of said chunks. The logic is backend-dependent, but; 786generically tries to infer how many cores are available in the cluster through the connection object. The number of; 787tasks will be equal to the inferred number of cores. There are cases where the connection object of the chosen backend; 788doesn't have information about the actual resources of the cluster. An example of this is when using Dask to connect to; 789a batch system. The client object created at the beginning of the application does not automatically know how many cores; 790will be available during distributed execution, since the jobs are submitted to the batch system after the creation of; 791the connection. In such cases, the logic is to default to process the whole dataset in 2 tasks.; 792 ; 793The number of tasks submitted for distributed execution can be also set programmatically, by providing the optional; 794keyword argument `npartitions` when creating the RDataFrame object. This parameter is accepted irrespectively of the; 795backend used:; 796 ; 797~~~{.py}; 798import ROOT; 799 ; 800# Define correct imports and access the distributed RDataFrame appropriate for the; 801# backend used in the analysis; 802RDataFrame = ROOT.RDF.Experimental.Distributed.[BACKEND].RDataFrame; 803 ; 804if __name__ == ""__main__"":; 805 # The `npartitions` optional argument tells the RDataFrame how many tasks are desired; 806 df = RDataFrame(""mytree"",""myfile.root"", npartitions=NPARTITIONS); 807 # Proceed as usual; 808 df.Define(""x"",""someoperation"").Histo1D((""name"", ""title"", 10, 0, 10),",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:49208,Availability,error,errors,49208,"supports this feature and graphs belonging to different backends can be still triggered with; 849a single call to RunGraphs (e.g. it is possible to send a Spark job and a Dask job at the same time).; 850 ; 851### Histogram models in distributed mode; 852 ; 853When calling a Histo*D operation in distributed mode, remember to pass to the function the model of the histogram to be; 854computed, e.g. the axis range and the number of bins:; 855 ; 856~~~{.py}; 857import ROOT; 858RDataFrame = ROOT.RDF.Experimental.Distributed.[BACKEND].RDataFrame; 859 ; 860if __name__ == ""__main__"":; 861 df = RDataFrame(""mytree"",""myfile.root"").Define(""x"",""someoperation""); 862 # The model can be passed either as a tuple with the arguments in the correct order; 863 df.Histo1D((""name"", ""title"", 10, 0, 10), ""x""); 864 # Or by creating the specific struct; 865 model = ROOT.RDF.TH1DModel(""name"", ""title"", 10, 0, 10); 866 df.Histo1D(model, ""x""); 867~~~; 868 ; 869Without this, two partial histograms resulting from two distributed tasks would have incompatible binning, thus leading; 870to errors when merging them. Failing to pass a histogram model will raise an error on the client side, before starting; 871the distributed execution.; 872 ; 873### Live visualization in distributed mode with dask; 874 ; 875The live visualization feature allows real-time data representation of plots generated during the execution ; 876of a distributed RDataFrame application. ; 877It enables visualizing intermediate results as they are computed across multiple nodes of a Dask cluster; 878by creating a canvas and continuously updating it as partial results become available. ; 879 ; 880The LiveVisualize() function can be imported from the Python package **ROOT.RDF.Experimental.Distributed**:; 881 ; 882~~~{.py}; 883import ROOT; 884 ; 885LiveVisualize = ROOT.RDF.Experimental.Distributed.LiveVisualize; 886~~~; 887 ; 888The function takes drawable objects (e.g. histograms) and optional callback functions as argument, it accepts",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:49282,Availability,error,error,49282,"Spark job and a Dask job at the same time).; 850 ; 851### Histogram models in distributed mode; 852 ; 853When calling a Histo*D operation in distributed mode, remember to pass to the function the model of the histogram to be; 854computed, e.g. the axis range and the number of bins:; 855 ; 856~~~{.py}; 857import ROOT; 858RDataFrame = ROOT.RDF.Experimental.Distributed.[BACKEND].RDataFrame; 859 ; 860if __name__ == ""__main__"":; 861 df = RDataFrame(""mytree"",""myfile.root"").Define(""x"",""someoperation""); 862 # The model can be passed either as a tuple with the arguments in the correct order; 863 df.Histo1D((""name"", ""title"", 10, 0, 10), ""x""); 864 # Or by creating the specific struct; 865 model = ROOT.RDF.TH1DModel(""name"", ""title"", 10, 0, 10); 866 df.Histo1D(model, ""x""); 867~~~; 868 ; 869Without this, two partial histograms resulting from two distributed tasks would have incompatible binning, thus leading; 870to errors when merging them. Failing to pass a histogram model will raise an error on the client side, before starting; 871the distributed execution.; 872 ; 873### Live visualization in distributed mode with dask; 874 ; 875The live visualization feature allows real-time data representation of plots generated during the execution ; 876of a distributed RDataFrame application. ; 877It enables visualizing intermediate results as they are computed across multiple nodes of a Dask cluster; 878by creating a canvas and continuously updating it as partial results become available. ; 879 ; 880The LiveVisualize() function can be imported from the Python package **ROOT.RDF.Experimental.Distributed**:; 881 ; 882~~~{.py}; 883import ROOT; 884 ; 885LiveVisualize = ROOT.RDF.Experimental.Distributed.LiveVisualize; 886~~~; 887 ; 888The function takes drawable objects (e.g. histograms) and optional callback functions as argument, it accepts 4 different input formats:; 889 ; 890- Passing a list or tuple of drawables: ; 891You can pass a list or tuple containing the plots you want to visualize. ",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:49772,Availability,avail,available,49772,"e; 859 ; 860if __name__ == ""__main__"":; 861 df = RDataFrame(""mytree"",""myfile.root"").Define(""x"",""someoperation""); 862 # The model can be passed either as a tuple with the arguments in the correct order; 863 df.Histo1D((""name"", ""title"", 10, 0, 10), ""x""); 864 # Or by creating the specific struct; 865 model = ROOT.RDF.TH1DModel(""name"", ""title"", 10, 0, 10); 866 df.Histo1D(model, ""x""); 867~~~; 868 ; 869Without this, two partial histograms resulting from two distributed tasks would have incompatible binning, thus leading; 870to errors when merging them. Failing to pass a histogram model will raise an error on the client side, before starting; 871the distributed execution.; 872 ; 873### Live visualization in distributed mode with dask; 874 ; 875The live visualization feature allows real-time data representation of plots generated during the execution ; 876of a distributed RDataFrame application. ; 877It enables visualizing intermediate results as they are computed across multiple nodes of a Dask cluster; 878by creating a canvas and continuously updating it as partial results become available. ; 879 ; 880The LiveVisualize() function can be imported from the Python package **ROOT.RDF.Experimental.Distributed**:; 881 ; 882~~~{.py}; 883import ROOT; 884 ; 885LiveVisualize = ROOT.RDF.Experimental.Distributed.LiveVisualize; 886~~~; 887 ; 888The function takes drawable objects (e.g. histograms) and optional callback functions as argument, it accepts 4 different input formats:; 889 ; 890- Passing a list or tuple of drawables: ; 891You can pass a list or tuple containing the plots you want to visualize. For example:; 892 ; 893~~~{.py}; 894LiveVisualize([h_gaus, h_exp, h_random]); 895~~~; 896 ; 897- Passing a list or tuple of drawables with a global callback function: ; 898You can also include a global callback function that will be applied to all plots. For example:; 899 ; 900~~~{.py}; 901def set_fill_color(hist):; 902 hist.SetFillColor(ROOT.kBlue); 903 ; 904LiveVisualize([h_gaus, h_e",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:61003,Availability,down,down,61003,"ax to define systematic variations.; 1036This is done in two steps: a) register variations for one or more existing columns using Vary() and b) extract variations; 1037of normal RDataFrame results using \ref ROOT::RDF::Experimental::VariationsFor ""VariationsFor()"". In between these steps, no other change; 1038to the analysis code is required: the presence of systematic variations for certain columns is automatically propagated; 1039through filters, defines and actions, and RDataFrame will take these dependencies into account when producing varied; 1040results. \ref ROOT::RDF::Experimental::VariationsFor ""VariationsFor()"" is included in header `ROOT/RDFHelpers.hxx`. The compiled C++ programs must include this header; 1041explicitly, this is not required for ROOT macros. ; 1042 ; 1043An example usage of Vary() and \ref ROOT::RDF::Experimental::VariationsFor ""VariationsFor()"" in C++:; 1044 ; 1045~~~{.cpp}; 1046auto nominal_hx =; 1047 df.Vary(""pt"", ""ROOT::RVecD{pt*0.9f, pt*1.1f}"", {""down"", ""up""}); 1048 .Filter(""pt > pt_cut""); 1049 .Define(""x"", someFunc, {""pt""}); 1050 .Histo1D<float>(""x"");; 1051 ; 1052// request the generation of varied results from the nominal_hx; 1053ROOT::RDF::Experimental::RResultMap<TH1D> hx = ROOT::RDF::Experimental::VariationsFor(nominal_hx);; 1054 ; 1055// the event loop runs here, upon first access to any of the results or varied results:; 1056hx[""nominal""].Draw(); // same effect as nominal_hx->Draw(); 1057hx[""pt:down""].Draw(""SAME"");; 1058hx[""pt:up""].Draw(""SAME"");; 1059~~~; 1060 ; 1061A list of variation ""tags"" is passed as the last argument to Vary(). The tags give names to the varied values that are returned; 1062as elements of an RVec of the appropriate C++ type. The number of variation tags must correspond to the number of elements of; 1063this RVec (2 in the example above: the first element will correspond to the tag ""down"", the second; 1064to the tag ""up""). The _full_ variation name will be composed of the varied column name and the variati",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:61467,Availability,down,down,61467,"039through filters, defines and actions, and RDataFrame will take these dependencies into account when producing varied; 1040results. \ref ROOT::RDF::Experimental::VariationsFor ""VariationsFor()"" is included in header `ROOT/RDFHelpers.hxx`. The compiled C++ programs must include this header; 1041explicitly, this is not required for ROOT macros. ; 1042 ; 1043An example usage of Vary() and \ref ROOT::RDF::Experimental::VariationsFor ""VariationsFor()"" in C++:; 1044 ; 1045~~~{.cpp}; 1046auto nominal_hx =; 1047 df.Vary(""pt"", ""ROOT::RVecD{pt*0.9f, pt*1.1f}"", {""down"", ""up""}); 1048 .Filter(""pt > pt_cut""); 1049 .Define(""x"", someFunc, {""pt""}); 1050 .Histo1D<float>(""x"");; 1051 ; 1052// request the generation of varied results from the nominal_hx; 1053ROOT::RDF::Experimental::RResultMap<TH1D> hx = ROOT::RDF::Experimental::VariationsFor(nominal_hx);; 1054 ; 1055// the event loop runs here, upon first access to any of the results or varied results:; 1056hx[""nominal""].Draw(); // same effect as nominal_hx->Draw(); 1057hx[""pt:down""].Draw(""SAME"");; 1058hx[""pt:up""].Draw(""SAME"");; 1059~~~; 1060 ; 1061A list of variation ""tags"" is passed as the last argument to Vary(). The tags give names to the varied values that are returned; 1062as elements of an RVec of the appropriate C++ type. The number of variation tags must correspond to the number of elements of; 1063this RVec (2 in the example above: the first element will correspond to the tag ""down"", the second; 1064to the tag ""up""). The _full_ variation name will be composed of the varied column name and the variation tags (e.g.; 1065""pt:down"", ""pt:up"" in this example). Python usage looks similar.; 1066 ; 1067Note how we use the ""pt"" column as usual in the Filter() and Define() calls and we simply use ""x"" as the value to fill; 1068the resulting histogram. To produce the varied results, RDataFrame will automatically execute the Filter and Define; 1069calls for each variation and fill the histogram with values and cuts that depend on the var",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:61885,Availability,down,down,61885,"ry() and \ref ROOT::RDF::Experimental::VariationsFor ""VariationsFor()"" in C++:; 1044 ; 1045~~~{.cpp}; 1046auto nominal_hx =; 1047 df.Vary(""pt"", ""ROOT::RVecD{pt*0.9f, pt*1.1f}"", {""down"", ""up""}); 1048 .Filter(""pt > pt_cut""); 1049 .Define(""x"", someFunc, {""pt""}); 1050 .Histo1D<float>(""x"");; 1051 ; 1052// request the generation of varied results from the nominal_hx; 1053ROOT::RDF::Experimental::RResultMap<TH1D> hx = ROOT::RDF::Experimental::VariationsFor(nominal_hx);; 1054 ; 1055// the event loop runs here, upon first access to any of the results or varied results:; 1056hx[""nominal""].Draw(); // same effect as nominal_hx->Draw(); 1057hx[""pt:down""].Draw(""SAME"");; 1058hx[""pt:up""].Draw(""SAME"");; 1059~~~; 1060 ; 1061A list of variation ""tags"" is passed as the last argument to Vary(). The tags give names to the varied values that are returned; 1062as elements of an RVec of the appropriate C++ type. The number of variation tags must correspond to the number of elements of; 1063this RVec (2 in the example above: the first element will correspond to the tag ""down"", the second; 1064to the tag ""up""). The _full_ variation name will be composed of the varied column name and the variation tags (e.g.; 1065""pt:down"", ""pt:up"" in this example). Python usage looks similar.; 1066 ; 1067Note how we use the ""pt"" column as usual in the Filter() and Define() calls and we simply use ""x"" as the value to fill; 1068the resulting histogram. To produce the varied results, RDataFrame will automatically execute the Filter and Define; 1069calls for each variation and fill the histogram with values and cuts that depend on the variation.; 1070 ; 1071There is no limitation to the complexity of a Vary() expression. Just like for the Define() and Filter() calls, users are; 1072not limited to string expressions but they can also pass any valid C++ callable, including lambda functions and; 1073complex functors. The callable can be applied to zero or more existing columns and it will always receive their; 1074_n",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:62033,Availability,down,down,62033,"); 1049 .Define(""x"", someFunc, {""pt""}); 1050 .Histo1D<float>(""x"");; 1051 ; 1052// request the generation of varied results from the nominal_hx; 1053ROOT::RDF::Experimental::RResultMap<TH1D> hx = ROOT::RDF::Experimental::VariationsFor(nominal_hx);; 1054 ; 1055// the event loop runs here, upon first access to any of the results or varied results:; 1056hx[""nominal""].Draw(); // same effect as nominal_hx->Draw(); 1057hx[""pt:down""].Draw(""SAME"");; 1058hx[""pt:up""].Draw(""SAME"");; 1059~~~; 1060 ; 1061A list of variation ""tags"" is passed as the last argument to Vary(). The tags give names to the varied values that are returned; 1062as elements of an RVec of the appropriate C++ type. The number of variation tags must correspond to the number of elements of; 1063this RVec (2 in the example above: the first element will correspond to the tag ""down"", the second; 1064to the tag ""up""). The _full_ variation name will be composed of the varied column name and the variation tags (e.g.; 1065""pt:down"", ""pt:up"" in this example). Python usage looks similar.; 1066 ; 1067Note how we use the ""pt"" column as usual in the Filter() and Define() calls and we simply use ""x"" as the value to fill; 1068the resulting histogram. To produce the varied results, RDataFrame will automatically execute the Filter and Define; 1069calls for each variation and fill the histogram with values and cuts that depend on the variation.; 1070 ; 1071There is no limitation to the complexity of a Vary() expression. Just like for the Define() and Filter() calls, users are; 1072not limited to string expressions but they can also pass any valid C++ callable, including lambda functions and; 1073complex functors. The callable can be applied to zero or more existing columns and it will always receive their; 1074_nominal_ value in input.; 1075 ; 1076#### Varying multiple columns in lockstep; 1077 ; 1078In the following Python snippet we use the Vary() signature that allows varying multiple columns simultaneously or; 1079""in locks",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:63184,Availability,down,down,63184,"o produce the varied results, RDataFrame will automatically execute the Filter and Define; 1069calls for each variation and fill the histogram with values and cuts that depend on the variation.; 1070 ; 1071There is no limitation to the complexity of a Vary() expression. Just like for the Define() and Filter() calls, users are; 1072not limited to string expressions but they can also pass any valid C++ callable, including lambda functions and; 1073complex functors. The callable can be applied to zero or more existing columns and it will always receive their; 1074_nominal_ value in input.; 1075 ; 1076#### Varying multiple columns in lockstep; 1077 ; 1078In the following Python snippet we use the Vary() signature that allows varying multiple columns simultaneously or; 1079""in lockstep"":; 1080 ; 1081~~~{.python}; 1082df.Vary([""pt"", ""eta""],; 1083 ""RVec<RVecF>{{pt*0.9, pt*1.1}, {eta*0.9, eta*1.1}}"",; 1084 variationTags=[""down"", ""up""],; 1085 variationName=""ptAndEta""); 1086~~~; 1087 ; 1088The expression returns an RVec of two RVecs: each inner vector contains the varied values for one column. The; 1089inner vectors follow the same ordering as the column names that are passed as the first argument. Besides the variation tags, in; 1090this case we also have to explicitly pass the variation name (here: ""ptAndEta"") as the default column name does not exist.; 1091 ; 1092The above call will produce variations ""ptAndEta:down"" and ""ptAndEta:up"".; 1093 ; 1094#### Combining multiple variations; 1095 ; 1096Even if a result depends on multiple variations, only one variation is applied at a time, i.e. there will be no result produced; 1097by applying multiple systematic variations at the same time.; 1098For example, in the following example snippet, the RResultMap instance `all_h` will contain keys ""nominal"", ""pt:down"",; 1099""pt:up"", ""eta:0"", ""eta:1"", but no ""pt:up&&eta:0"" or similar:; 1100 ; 1101~~~{.cpp}; 1102auto df = _df.Vary(""pt"",; 1103 ""ROOT::RVecD{pt*0.9, pt*1.1}"",; 1104 {""down"", ",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:63684,Availability,down,down,63684,"ble, including lambda functions and; 1073complex functors. The callable can be applied to zero or more existing columns and it will always receive their; 1074_nominal_ value in input.; 1075 ; 1076#### Varying multiple columns in lockstep; 1077 ; 1078In the following Python snippet we use the Vary() signature that allows varying multiple columns simultaneously or; 1079""in lockstep"":; 1080 ; 1081~~~{.python}; 1082df.Vary([""pt"", ""eta""],; 1083 ""RVec<RVecF>{{pt*0.9, pt*1.1}, {eta*0.9, eta*1.1}}"",; 1084 variationTags=[""down"", ""up""],; 1085 variationName=""ptAndEta""); 1086~~~; 1087 ; 1088The expression returns an RVec of two RVecs: each inner vector contains the varied values for one column. The; 1089inner vectors follow the same ordering as the column names that are passed as the first argument. Besides the variation tags, in; 1090this case we also have to explicitly pass the variation name (here: ""ptAndEta"") as the default column name does not exist.; 1091 ; 1092The above call will produce variations ""ptAndEta:down"" and ""ptAndEta:up"".; 1093 ; 1094#### Combining multiple variations; 1095 ; 1096Even if a result depends on multiple variations, only one variation is applied at a time, i.e. there will be no result produced; 1097by applying multiple systematic variations at the same time.; 1098For example, in the following example snippet, the RResultMap instance `all_h` will contain keys ""nominal"", ""pt:down"",; 1099""pt:up"", ""eta:0"", ""eta:1"", but no ""pt:up&&eta:0"" or similar:; 1100 ; 1101~~~{.cpp}; 1102auto df = _df.Vary(""pt"",; 1103 ""ROOT::RVecD{pt*0.9, pt*1.1}"",; 1104 {""down"", ""up""}); 1105 .Vary(""eta"",; 1106 [](float eta) { return RVecF{eta*0.9f, eta*1.1f}; },; 1107 {""eta""},; 1108 2);; 1109 ; 1110auto nom_h = df.Histo2D(histoModel, ""pt"", ""eta"");; 1111auto all_hs = VariationsFor(nom_h);; 1112all_hs.GetKeys(); // returns {""nominal"", ""pt:down"", ""pt:up"", ""eta:0"", ""eta:1""}; 1113~~~; 1114 ; 1115Note how we passed the integer `2` instead of a list of variation tags to the second Vary()",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:64079,Availability,down,down,64079,"{.python}; 1082df.Vary([""pt"", ""eta""],; 1083 ""RVec<RVecF>{{pt*0.9, pt*1.1}, {eta*0.9, eta*1.1}}"",; 1084 variationTags=[""down"", ""up""],; 1085 variationName=""ptAndEta""); 1086~~~; 1087 ; 1088The expression returns an RVec of two RVecs: each inner vector contains the varied values for one column. The; 1089inner vectors follow the same ordering as the column names that are passed as the first argument. Besides the variation tags, in; 1090this case we also have to explicitly pass the variation name (here: ""ptAndEta"") as the default column name does not exist.; 1091 ; 1092The above call will produce variations ""ptAndEta:down"" and ""ptAndEta:up"".; 1093 ; 1094#### Combining multiple variations; 1095 ; 1096Even if a result depends on multiple variations, only one variation is applied at a time, i.e. there will be no result produced; 1097by applying multiple systematic variations at the same time.; 1098For example, in the following example snippet, the RResultMap instance `all_h` will contain keys ""nominal"", ""pt:down"",; 1099""pt:up"", ""eta:0"", ""eta:1"", but no ""pt:up&&eta:0"" or similar:; 1100 ; 1101~~~{.cpp}; 1102auto df = _df.Vary(""pt"",; 1103 ""ROOT::RVecD{pt*0.9, pt*1.1}"",; 1104 {""down"", ""up""}); 1105 .Vary(""eta"",; 1106 [](float eta) { return RVecF{eta*0.9f, eta*1.1f}; },; 1107 {""eta""},; 1108 2);; 1109 ; 1110auto nom_h = df.Histo2D(histoModel, ""pt"", ""eta"");; 1111auto all_hs = VariationsFor(nom_h);; 1112all_hs.GetKeys(); // returns {""nominal"", ""pt:down"", ""pt:up"", ""eta:0"", ""eta:1""}; 1113~~~; 1114 ; 1115Note how we passed the integer `2` instead of a list of variation tags to the second Vary() invocation: this is a; 1116shorthand that automatically generates tags 0 to N-1 (in this case 0 and 1).; 1117 ; 1118\note Currently, VariationsFor() and RResultMap are in the `ROOT::RDF::Experimental` namespace, to indicate that these; 1119 interfaces might still evolve and improve based on user feedback. We expect that some aspects of the related; 1120 programming model will be streamlined in fu",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:64249,Availability,down,down,64249,"e expression returns an RVec of two RVecs: each inner vector contains the varied values for one column. The; 1089inner vectors follow the same ordering as the column names that are passed as the first argument. Besides the variation tags, in; 1090this case we also have to explicitly pass the variation name (here: ""ptAndEta"") as the default column name does not exist.; 1091 ; 1092The above call will produce variations ""ptAndEta:down"" and ""ptAndEta:up"".; 1093 ; 1094#### Combining multiple variations; 1095 ; 1096Even if a result depends on multiple variations, only one variation is applied at a time, i.e. there will be no result produced; 1097by applying multiple systematic variations at the same time.; 1098For example, in the following example snippet, the RResultMap instance `all_h` will contain keys ""nominal"", ""pt:down"",; 1099""pt:up"", ""eta:0"", ""eta:1"", but no ""pt:up&&eta:0"" or similar:; 1100 ; 1101~~~{.cpp}; 1102auto df = _df.Vary(""pt"",; 1103 ""ROOT::RVecD{pt*0.9, pt*1.1}"",; 1104 {""down"", ""up""}); 1105 .Vary(""eta"",; 1106 [](float eta) { return RVecF{eta*0.9f, eta*1.1f}; },; 1107 {""eta""},; 1108 2);; 1109 ; 1110auto nom_h = df.Histo2D(histoModel, ""pt"", ""eta"");; 1111auto all_hs = VariationsFor(nom_h);; 1112all_hs.GetKeys(); // returns {""nominal"", ""pt:down"", ""pt:up"", ""eta:0"", ""eta:1""}; 1113~~~; 1114 ; 1115Note how we passed the integer `2` instead of a list of variation tags to the second Vary() invocation: this is a; 1116shorthand that automatically generates tags 0 to N-1 (in this case 0 and 1).; 1117 ; 1118\note Currently, VariationsFor() and RResultMap are in the `ROOT::RDF::Experimental` namespace, to indicate that these; 1119 interfaces might still evolve and improve based on user feedback. We expect that some aspects of the related; 1120 programming model will be streamlined in future versions.; 1121 ; 1122\note Currently, the results of a Snapshot(), Report() or Display() call cannot be varied (i.e. it is not possible to; 1123 call \ref ROOT::RDF::Experimental::Va",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:64519,Availability,down,down,64519,"091 ; 1092The above call will produce variations ""ptAndEta:down"" and ""ptAndEta:up"".; 1093 ; 1094#### Combining multiple variations; 1095 ; 1096Even if a result depends on multiple variations, only one variation is applied at a time, i.e. there will be no result produced; 1097by applying multiple systematic variations at the same time.; 1098For example, in the following example snippet, the RResultMap instance `all_h` will contain keys ""nominal"", ""pt:down"",; 1099""pt:up"", ""eta:0"", ""eta:1"", but no ""pt:up&&eta:0"" or similar:; 1100 ; 1101~~~{.cpp}; 1102auto df = _df.Vary(""pt"",; 1103 ""ROOT::RVecD{pt*0.9, pt*1.1}"",; 1104 {""down"", ""up""}); 1105 .Vary(""eta"",; 1106 [](float eta) { return RVecF{eta*0.9f, eta*1.1f}; },; 1107 {""eta""},; 1108 2);; 1109 ; 1110auto nom_h = df.Histo2D(histoModel, ""pt"", ""eta"");; 1111auto all_hs = VariationsFor(nom_h);; 1112all_hs.GetKeys(); // returns {""nominal"", ""pt:down"", ""pt:up"", ""eta:0"", ""eta:1""}; 1113~~~; 1114 ; 1115Note how we passed the integer `2` instead of a list of variation tags to the second Vary() invocation: this is a; 1116shorthand that automatically generates tags 0 to N-1 (in this case 0 and 1).; 1117 ; 1118\note Currently, VariationsFor() and RResultMap are in the `ROOT::RDF::Experimental` namespace, to indicate that these; 1119 interfaces might still evolve and improve based on user feedback. We expect that some aspects of the related; 1120 programming model will be streamlined in future versions.; 1121 ; 1122\note Currently, the results of a Snapshot(), Report() or Display() call cannot be varied (i.e. it is not possible to; 1123 call \ref ROOT::RDF::Experimental::VariationsFor ""VariationsFor()"" on them. These limitations will be lifted in future releases.; 1124 ; 1125See the Vary() method for more information and [this tutorial](https://root.cern/doc/master/df106__HiggsToFourLeptons_8C.html) ; 1126for an example usage of Vary and \ref ROOT::RDF::Experimental::VariationsFor ""VariationsFor()"" in the analysis.; 1127 ; 1128\anchor rno",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:65962,Availability,avail,available,65962,"rove based on user feedback. We expect that some aspects of the related; 1120 programming model will be streamlined in future versions.; 1121 ; 1122\note Currently, the results of a Snapshot(), Report() or Display() call cannot be varied (i.e. it is not possible to; 1123 call \ref ROOT::RDF::Experimental::VariationsFor ""VariationsFor()"" on them. These limitations will be lifted in future releases.; 1124 ; 1125See the Vary() method for more information and [this tutorial](https://root.cern/doc/master/df106__HiggsToFourLeptons_8C.html) ; 1126for an example usage of Vary and \ref ROOT::RDF::Experimental::VariationsFor ""VariationsFor()"" in the analysis.; 1127 ; 1128\anchor rnode; 1129### RDataFrame objects as function arguments and return values; 1130RDataFrame variables/nodes are relatively cheap to copy and it's possible to both pass them to (or move them into); 1131functions and to return them from functions. However, in general each dataframe node will have a different C++ type,; 1132which includes all available compile-time information about what that node does. One way to cope with this complication; 1133is to use template functions and/or C++14 auto return types:; 1134~~~{.cpp}; 1135template <typename RDF>; 1136auto ApplySomeFilters(RDF df); 1137{; 1138 return df.Filter(""x > 0"").Filter([](int y) { return y < 0; }, {""y""});; 1139}; 1140~~~; 1141 ; 1142A possibly simpler, C++11-compatible alternative is to take advantage of the fact that any dataframe node can be; 1143converted (implicitly or via an explicit cast) to the common type ROOT::RDF::RNode:; 1144~~~{.cpp}; 1145// a function that conditionally adds a Range to an RDataFrame node.; 1146RNode MaybeAddRange(RNode df, bool mustAddRange); 1147{; 1148 return mustAddRange ? df.Range(1) : df;; 1149}; 1150// use as :; 1151ROOT::RDataFrame df(10);; 1152auto maybeRangedDF = MaybeAddRange(df, true);; 1153~~~; 1154 ; 1155The conversion to ROOT::RDF::RNode is cheap, but it will introduce an extra virtual call during the R",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:73007,Availability,error,error,73007,"f. This; 1236is why we never needed to specify the column types for all actions in the above snippets.; 1237 ; 1238When the column type is not a common one such as `int`, `double`, `char` or `float` it is nonetheless good practice to; 1239specify it as a template parameter to the action itself, like this:; 1240~~~{.cpp}; 1241df.Histo1D(""b1""); // OK, the type of ""b1"" is deduced at runtime; 1242df.Min<MyNumber_t>(""myObject""); // OK, ""myObject"" is deduced to be of type `MyNumber_t`; 1243~~~; 1244 ; 1245Deducing types at runtime requires the just-in-time compilation of the relevant actions, which has a small runtime; 1246overhead, so specifying the type of the columns as template parameters to the action is good practice when performance is a goal.; 1247 ; 1248When strings are passed as expressions to Filter() or Define(), fundamental types are passed as constants. This avoids certaincommon mistakes such as typing `x = 0` rather than `x == 0`:; 1249 ; 1250~~~{.cpp}; 1251// this throws an error (note the typo); 1252df.Define(""x"", ""0"").Filter(""x = 0"");; 1253~~~; 1254 ; 1255\anchor generic-actions; 1256### User-defined custom actions; 1257RDataFrame strives to offer a comprehensive set of standard actions that can be performed on each event. At the same; 1258time, it allows users to inject their own action code to perform arbitrarily complex data reductions.; 1259 ; 1260#### Implementing custom actions with Book(); 1261 ; 1262Through the Book() method, users can implement a custom action and have access to the same features; 1263that built-in RDataFrame actions have, e.g. hooks to events related to the start, end and execution of the; 1264event loop, or the possibility to return a lazy RResultPtr to an arbitrary type of result:; 1265 ; 1266~~~{.cpp}; 1267#include <ROOT/RDataFrame.hxx>; 1268#include <memory>; 1269 ; 1270class MyCounter : public ROOT::Detail::RDF::RActionImpl<MyCounter> {; 1271 std::shared_ptr<int> fFinalResult = std::make_shared<int>(0);; 1272 std::vector<i",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:75919,Availability,avail,available,75919,"adResults.end(), 0);; 1299 }; 1300 ; 1301 // Called by RDataFrame to retrieve the name of this action.; 1302 std::string GetActionName() const { return ""MyCounter""; }; 1303};; 1304 ; 1305int main() {; 1306 ROOT::RDataFrame df(10);; 1307 ROOT::RDF::RResultPtr<int> resultPtr = df.Book<>(MyCounter{df.GetNSlots()}, {});; 1308 // The GetValue call triggers the event loop; 1309 std::cout << ""Number of processed entries: "" << resultPtr.GetValue() << std::endl;; 1310}; 1311~~~; 1312 ; 1313See the Book() method for more information and [this tutorial](https://root.cern/doc/master/df018__customActions_8C.html); 1314for a more complete example.; 1315 ; 1316#### Injecting arbitrary code in the event loop with Foreach() and ForeachSlot(); 1317 ; 1318Foreach() takes a callable (lambda expression, free function, functor...) and a list of columns and; 1319executes the callable on the values of those columns for each event that passes all upstream selections.; 1320It can be used to perform actions that are not already available in the interface. For example, the following snippet; 1321evaluates the root mean square of column ""x"":; 1322~~~{.cpp}; 1323// Single-thread evaluation of RMS of column ""x"" using Foreach; 1324double sumSq = 0.;; 1325unsigned int n = 0;; 1326df.Foreach([&sumSq, &n](double x) { ++n; sumSq += x*x; }, {""x""});; 1327std::cout << ""rms of x: "" << std::sqrt(sumSq / n) << std::endl;; 1328~~~; 1329In multi-thread runs, users are responsible for the thread-safety of the expression passed to Foreach():; 1330thread will execute the expression concurrently.; 1331The code above would need to employ some resource protection mechanism to ensure non-concurrent writing of `rms`; but; 1332this is probably too much head-scratch for such a simple operation.; 1333 ; 1334ForeachSlot() can help in this situation. It is an alternative version of Foreach() for which the function takes an; 1335additional ""processing slot"" parameter besides the columns it should be applied to. RDataFrame;",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:82320,Availability,down,down,82320,":RCsvDS which allows to read comma separated files:; 1413~~~{.cpp}; 1414auto tdf = ROOT::RDF::FromCSV(""MuRun2010B.csv"");; 1415auto filteredEvents =; 1416 tdf.Filter(""Q1 * Q2 == -1""); 1417 .Define(""m"", ""sqrt(pow(E1 + E2, 2) - (pow(px1 + px2, 2) + pow(py1 + py2, 2) + pow(pz1 + pz2, 2)))"");; 1418auto h = filteredEvents.Histo1D(""m"");; 1419h->Draw();; 1420~~~; 1421 ; 1422See also FromNumpy (Python-only), FromRNTuple(), FromArrow(), FromSqlite().; 1423 ; 1424\anchor callgraphs; 1425### Computation graphs (storing and reusing sets of transformations); 1426 ; 1427As we saw, transformed dataframes can be stored as variables and reused multiple times to create modified versions of the dataset. This implicitly defines a **computation graph** in which; 1428several paths of filtering/creation of columns are executed simultaneously, and finally aggregated results are produced.; 1429 ; 1430RDataFrame detects when several actions use the same filter or the same defined column, and **only evaluates each; 1431filter or defined column once per event**, regardless of how many times that result is used down the computation graph.; 1432Objects read from each column are **built once and never copied**, for maximum efficiency.; 1433When ""upstream"" filters are not passed, subsequent filters, temporary column expressions and actions are not evaluated,; 1434so it might be advisable to put the strictest filters first in the graph.; 1435 ; 1436\anchor representgraph; 1437### Visualizing the computation graph; 1438It is possible to print the computation graph from any node to obtain a [DOT (graphviz)](https://en.wikipedia.org/wiki/DOT_(graph_description_language)) representation either on the standard output; 1439or in a file.; 1440 ; 1441Invoking the function ROOT::RDF::SaveGraph() on any node that is not the head node, the computation graph of the branch; 1442the node belongs to is printed. By using the head node, the entire computation graph is printed.; 1443 ; 1444Following there is an exampl",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:87038,Availability,avail,available,87038,"adata"": {; 1515 ""lumi"": 10000.0, ; 1516 ""xsec"": 1.0,; 1517 ""sample_category"" = ""data""; 1518 }; 1519 },; 1520 ""sampleB"": {; 1521 ""trees"": [""tree3"", ""tree4""],; 1522 ""files"": [""file3.root"", ""file4.root""],; 1523 ""metadata"": {; 1524 ""lumi"": 0.5, ; 1525 ""xsec"": 1.5,; 1526 ""sample_category"" = ""MC_background""; 1527 }; 1528 }; 1529 }; 1530}; 1531~~~; 1532 ; 1533The metadata information from the specification file can be then accessed using the DefinePerSample function.; 1534For example, to access luminosity information (stored as a double):; 1535 ; 1536~~~{.python}; 1537df.DefinePerSample(""lumi"", 'rdfsampleinfo_.GetD(""lumi"")'); 1538~~~; 1539 ; 1540or sample_category information (stored as a string):; 1541 ; 1542~~~{.python}; 1543df.DefinePerSample(""sample_category"", 'rdfsampleinfo_.GetS(""sample_category"")'); 1544~~~; 1545 ; 1546or directly the filename:; 1547 ; 1548~~~{.python}; 1549df.DefinePerSample(""name"", ""rdfsampleinfo_.GetSampleName()""); 1550~~~; 1551 ; 1552An example implementation of the ""FromSpec"" method is available in tutorial: df106_HiggstoFourLeptons.py, which also; 1553provides a corresponding exemplary JSON file for the dataset specification.; 1554 ; 1555\anchor progressbar; 1556### Adding a progress bar ; 1557 ; 1558A progress bar showing the processed event statistics can be added to any RDataFrame program.; 1559The event statistics include elapsed time, currently processed file, currently processed events, the rate of event processing ; 1560and an estimated remaining time (per file being processed). It is recorded and printed in the terminal every m events and every ; 1561n seconds (by default m = 1000 and n = 1). The ProgressBar can be also added when the multithread (MT) mode is enabled. ; 1562 ; 1563ProgressBar is added after creating the dataframe object (df):; 1564~~~{.cpp}; 1565ROOT::RDataFrame df(""tree"", ""file.root"");; 1566ROOT::RDF::Experimental::AddProgressBar(df);; 1567~~~; 1568 ; 1569Alternatively, RDataFrame can be cast to an RNode first, giving ",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:92200,Availability,down,downstream,92200,"the same branch of the computation graph clearly; 1634# cannot access that same column, since there would be no value to read; 1635df_missingcol = df_missingcol.Define(""observable"", ""othercolumn * 2""); 1636\endcode; 1637 ; 1638\code{.cpp}; 1639ROOT::RDataFrame df{dataset};; 1640 ; 1641// Anytime an entry from ""col"" is missing, the entire entry will be filtered out; 1642auto df_available = df.FilterAvailable(""col"");; 1643auto df_twicecol = df_available.Define(""twice"", ""col * 2"");; 1644 ; 1645// Conversely, if we want to select the entries for which the column has missing; 1646// values, we do the following; 1647auto df_missingcol = df.FilterMissing(""col"");; 1648// Following operations in the same branch of the computation graph clearly; 1649// cannot access that same column, since there would be no value to read; 1650auto df_observable = df_missingcol.Define(""observable"", ""othercolumn * 2"");; 1651\endcode; 1652 ; 1653#### DefaultValueFor; 1654 ; 1655DefaultValueFor creates a node of the computation graph which just forwards the; 1656values of the columns necessary for other downstream nodes, when they are; 1657available. In case a value of the input column passed to this function is not; 1658available, the node will provide the default value passed to this function call; 1659instead. Example:; 1660 ; 1661\code{.py}; 1662df = ROOT.RDataFrame(dataset); 1663# Anytime an entry from ""col"" is missing, the value will be the default one; 1664default_value = ... # Some sensible default value here; 1665df = df.DefaultValueFor(""col"", default_value) ; 1666df = df.Define(""twice"", ""col * 2""); 1667\endcode; 1668 ; 1669\code{.cpp}; 1670ROOT::RDataFrame df{dataset};; 1671// Anytime an entry from ""col"" is missing, the value will be the default one; 1672constexpr auto default_value = ... // Some sensible default value here; 1673auto df_default = df.DefaultValueFor(""col"", default_value);; 1674auto df_col = df_default.Define(""twice"", ""col * 2"");; 1675\endcode; 1676 ; 1677#### Mixing diff",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:95645,Availability,avail,available,95645,"alues; 1708df_filtered.Display({""twice""})->Print();; 1709\endcode; 1710 ; 1711#### Further considerations; 1712 ; 1713Note that working with missing values is currently supported with a TTree-based; 1714data source. Support of this functionality for other data sources may come in; 1715the future.; 1716 ; 1717*/; 1718// clang-format on; 1719 ; 1720namespace ROOT {; 1721 ; 1722using ROOT::RDF::ColumnNames_t;; 1723using ColumnNamesPtr_t = std::shared_ptr<const ColumnNames_t>;; 1724 ; 1725////////////////////////////////////////////////////////////////////////////; 1726/// \brief Build the dataframe.; 1727/// \param[in] treeName Name of the tree contained in the directory; 1728/// \param[in] dirPtr TDirectory where the tree is stored, e.g. a TFile.; 1729/// \param[in] defaultColumns Collection of default columns.; 1730///; 1731/// The default columns are looked at in case no column is specified in the; 1732/// booking of actions or transformations.; 1733/// \see ROOT::RDF::RInterface for the documentation of the methods available.; 1734RDataFrame::RDataFrame(std::string_view treeName, TDirectory *dirPtr, const ColumnNames_t &defaultColumns); 1735 : RInterface(std::make_shared<RDFDetail::RLoopManager>(nullptr, defaultColumns)); 1736{; 1737 if (!dirPtr) {; 1738 auto msg = ""Invalid TDirectory!"";; 1739 throw std::runtime_error(msg);; 1740 }; 1741 const std::string treeNameInt(treeName);; 1742 auto tree = static_cast<TTree *>(dirPtr->Get(treeNameInt.c_str()));; 1743 if (!tree) {; 1744 auto msg = ""Tree \"""" + treeNameInt + ""\"" cannot be found!"";; 1745 throw std::runtime_error(msg);; 1746 }; 1747 GetProxiedPtr()->SetTree(std::shared_ptr<TTree>(tree, [](TTree *) {}));; 1748}; 1749 ; 1750////////////////////////////////////////////////////////////////////////////; 1751/// \brief Build the dataframe.; 1752/// \param[in] treeName Name of the tree contained in the directory; 1753/// \param[in] filenameglob TDirectory where the tree is stored, e.g. a TFile.; 1754/// \param[in] defaul",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:97013,Availability,avail,available,97013,"td::string treeNameInt(treeName);; 1742 auto tree = static_cast<TTree *>(dirPtr->Get(treeNameInt.c_str()));; 1743 if (!tree) {; 1744 auto msg = ""Tree \"""" + treeNameInt + ""\"" cannot be found!"";; 1745 throw std::runtime_error(msg);; 1746 }; 1747 GetProxiedPtr()->SetTree(std::shared_ptr<TTree>(tree, [](TTree *) {}));; 1748}; 1749 ; 1750////////////////////////////////////////////////////////////////////////////; 1751/// \brief Build the dataframe.; 1752/// \param[in] treeName Name of the tree contained in the directory; 1753/// \param[in] filenameglob TDirectory where the tree is stored, e.g. a TFile.; 1754/// \param[in] defaultColumns Collection of default columns.; 1755///; 1756/// The filename glob supports the same type of expressions as TChain::Add(), and it is passed as-is to TChain's; 1757/// constructor.; 1758///; 1759/// The default columns are looked at in case no column is specified in the; 1760/// booking of actions or transformations.; 1761/// \see ROOT::RDF::RInterface for the documentation of the methods available.; 1762#ifdef R__HAS_ROOT7; 1763RDataFrame::RDataFrame(std::string_view treeName, std::string_view fileNameGlob, const ColumnNames_t &defaultColumns); 1764 : RInterface(ROOT::Detail::RDF::CreateLMFromFile(treeName, fileNameGlob, defaultColumns)); 1765{; 1766}; 1767#else; 1768RDataFrame::RDataFrame(std::string_view treeName, std::string_view fileNameGlob, const ColumnNames_t &defaultColumns); 1769 : RInterface(ROOT::Detail::RDF::CreateLMFromTTree(treeName, fileNameGlob, defaultColumns)); 1770{; 1771}; 1772#endif; 1773 ; 1774////////////////////////////////////////////////////////////////////////////; 1775/// \brief Build the dataframe.; 1776/// \param[in] treeName Name of the tree contained in the directory; 1777/// \param[in] fileglobs Collection of file names of filename globs; 1778/// \param[in] defaultColumns Collection of default columns.; 1779///; 1780/// The filename globs support the same type of expressions as TChain::Add(), and each glo",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:98235,Availability,avail,available,98235,"::RDF::CreateLMFromFile(treeName, fileNameGlob, defaultColumns)); 1765{; 1766}; 1767#else; 1768RDataFrame::RDataFrame(std::string_view treeName, std::string_view fileNameGlob, const ColumnNames_t &defaultColumns); 1769 : RInterface(ROOT::Detail::RDF::CreateLMFromTTree(treeName, fileNameGlob, defaultColumns)); 1770{; 1771}; 1772#endif; 1773 ; 1774////////////////////////////////////////////////////////////////////////////; 1775/// \brief Build the dataframe.; 1776/// \param[in] treeName Name of the tree contained in the directory; 1777/// \param[in] fileglobs Collection of file names of filename globs; 1778/// \param[in] defaultColumns Collection of default columns.; 1779///; 1780/// The filename globs support the same type of expressions as TChain::Add(), and each glob is passed as-is; 1781/// to TChain's constructor.; 1782///; 1783/// The default columns are looked at in case no column is specified in the booking of actions or transformations.; 1784/// \see ROOT::RDF::RInterface for the documentation of the methods available.; 1785#ifdef R__HAS_ROOT7; 1786RDataFrame::RDataFrame(std::string_view datasetName, const std::vector<std::string> &fileNameGlobs,; 1787 const ColumnNames_t &defaultColumns); 1788 : RInterface(ROOT::Detail::RDF::CreateLMFromFile(datasetName, fileNameGlobs, defaultColumns)); 1789{; 1790}; 1791#else; 1792RDataFrame::RDataFrame(std::string_view datasetName, const std::vector<std::string> &fileNameGlobs,; 1793 const ColumnNames_t &defaultColumns); 1794 : RInterface(ROOT::Detail::RDF::CreateLMFromTTree(datasetName, fileNameGlobs, defaultColumns)); 1795{; 1796}; 1797#endif; 1798 ; 1799////////////////////////////////////////////////////////////////////////////; 1800/// \brief Build the dataframe.; 1801/// \param[in] tree The tree or chain to be studied.; 1802/// \param[in] defaultColumns Collection of default column names to fall back to when none is specified.; 1803///; 1804/// The default columns are looked at in case no column is specified in the;",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:99324,Availability,avail,available,99324,"aFrame(std::string_view datasetName, const std::vector<std::string> &fileNameGlobs,; 1787 const ColumnNames_t &defaultColumns); 1788 : RInterface(ROOT::Detail::RDF::CreateLMFromFile(datasetName, fileNameGlobs, defaultColumns)); 1789{; 1790}; 1791#else; 1792RDataFrame::RDataFrame(std::string_view datasetName, const std::vector<std::string> &fileNameGlobs,; 1793 const ColumnNames_t &defaultColumns); 1794 : RInterface(ROOT::Detail::RDF::CreateLMFromTTree(datasetName, fileNameGlobs, defaultColumns)); 1795{; 1796}; 1797#endif; 1798 ; 1799////////////////////////////////////////////////////////////////////////////; 1800/// \brief Build the dataframe.; 1801/// \param[in] tree The tree or chain to be studied.; 1802/// \param[in] defaultColumns Collection of default column names to fall back to when none is specified.; 1803///; 1804/// The default columns are looked at in case no column is specified in the; 1805/// booking of actions or transformations.; 1806/// \see ROOT::RDF::RInterface for the documentation of the methods available.; 1807RDataFrame::RDataFrame(TTree &tree, const ColumnNames_t &defaultColumns); 1808 : RInterface(std::make_shared<RDFDetail::RLoopManager>(&tree, defaultColumns)); 1809{; 1810}; 1811 ; 1812//////////////////////////////////////////////////////////////////////////; 1813/// \brief Build a dataframe that generates numEntries entries.; 1814/// \param[in] numEntries The number of entries to generate.; 1815///; 1816/// An empty-source dataframe constructed with a number of entries will; 1817/// generate those entries on the fly when some action is triggered,; 1818/// and it will do so for all the previously-defined columns.; 1819/// \see ROOT::RDF::RInterface for the documentation of the methods available.; 1820RDataFrame::RDataFrame(ULong64_t numEntries); 1821 : RInterface(std::make_shared<RDFDetail::RLoopManager>(numEntries)); 1822 ; 1823{; 1824}; 1825 ; 1826//////////////////////////////////////////////////////////////////////////; 1827/// \brief",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:100034,Availability,avail,available,100034,"; 1802/// \param[in] defaultColumns Collection of default column names to fall back to when none is specified.; 1803///; 1804/// The default columns are looked at in case no column is specified in the; 1805/// booking of actions or transformations.; 1806/// \see ROOT::RDF::RInterface for the documentation of the methods available.; 1807RDataFrame::RDataFrame(TTree &tree, const ColumnNames_t &defaultColumns); 1808 : RInterface(std::make_shared<RDFDetail::RLoopManager>(&tree, defaultColumns)); 1809{; 1810}; 1811 ; 1812//////////////////////////////////////////////////////////////////////////; 1813/// \brief Build a dataframe that generates numEntries entries.; 1814/// \param[in] numEntries The number of entries to generate.; 1815///; 1816/// An empty-source dataframe constructed with a number of entries will; 1817/// generate those entries on the fly when some action is triggered,; 1818/// and it will do so for all the previously-defined columns.; 1819/// \see ROOT::RDF::RInterface for the documentation of the methods available.; 1820RDataFrame::RDataFrame(ULong64_t numEntries); 1821 : RInterface(std::make_shared<RDFDetail::RLoopManager>(numEntries)); 1822 ; 1823{; 1824}; 1825 ; 1826//////////////////////////////////////////////////////////////////////////; 1827/// \brief Build dataframe associated to data source.; 1828/// \param[in] ds The data source object.; 1829/// \param[in] defaultColumns Collection of default column names to fall back to when none is specified.; 1830///; 1831/// A dataframe associated to a data source will query it to access column values.; 1832/// \see ROOT::RDF::RInterface for the documentation of the methods available.; 1833RDataFrame::RDataFrame(std::unique_ptr<ROOT::RDF::RDataSource> ds, const ColumnNames_t &defaultColumns); 1834 : RInterface(std::make_shared<RDFDetail::RLoopManager>(std::move(ds), defaultColumns)); 1835{; 1836}; 1837 ; 1838//////////////////////////////////////////////////////////////////////////; 1839/// \brief Build dat",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:100663,Availability,avail,available,100663,"e that generates numEntries entries.; 1814/// \param[in] numEntries The number of entries to generate.; 1815///; 1816/// An empty-source dataframe constructed with a number of entries will; 1817/// generate those entries on the fly when some action is triggered,; 1818/// and it will do so for all the previously-defined columns.; 1819/// \see ROOT::RDF::RInterface for the documentation of the methods available.; 1820RDataFrame::RDataFrame(ULong64_t numEntries); 1821 : RInterface(std::make_shared<RDFDetail::RLoopManager>(numEntries)); 1822 ; 1823{; 1824}; 1825 ; 1826//////////////////////////////////////////////////////////////////////////; 1827/// \brief Build dataframe associated to data source.; 1828/// \param[in] ds The data source object.; 1829/// \param[in] defaultColumns Collection of default column names to fall back to when none is specified.; 1830///; 1831/// A dataframe associated to a data source will query it to access column values.; 1832/// \see ROOT::RDF::RInterface for the documentation of the methods available.; 1833RDataFrame::RDataFrame(std::unique_ptr<ROOT::RDF::RDataSource> ds, const ColumnNames_t &defaultColumns); 1834 : RInterface(std::make_shared<RDFDetail::RLoopManager>(std::move(ds), defaultColumns)); 1835{; 1836}; 1837 ; 1838//////////////////////////////////////////////////////////////////////////; 1839/// \brief Build dataframe from an RDatasetSpec object.; 1840/// \param[in] spec The dataset specification object.; 1841///; 1842/// A dataset specification includes trees and file names,; 1843/// as well as an optional friend list and/or entry range.; 1844///; 1845/// ### Example usage from Python:; 1846/// ~~~{.py}; 1847/// spec = (; 1848/// ROOT.RDF.Experimental.RDatasetSpec(); 1849/// .AddSample((""data"", ""tree"", ""file.root"")); 1850/// .WithGlobalFriends(""friendTree"", ""friend.root"", ""alias""); 1851/// .WithGlobalRange((100, 200)); 1852/// ); 1853/// df = ROOT.RDataFrame(spec); 1854/// ~~~; 1855///; 1856/// See also ROOT::RDataFrame::FromSp",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:4492,Deployability,toggle,toggleInherit,4492,"ecial helper columns: `rdfentry_` and `rdfslot_`](\ref helper-cols); 78 - [Just-in-time compilation: column type inference and explicit declaration of column types](\ref jitting); 79 - [User-defined custom actions](\ref generic-actions); 80 - [Dataset joins with friend trees](\ref friends); 81 - [Reading data formats other than ROOT trees](\ref other-file-formats); 82 - [Computation graphs (storing and reusing sets of transformations)](\ref callgraphs); 83 - [Visualizing the computation graph](\ref representgraph); 84 - [Activating RDataFrame execution logs](\ref rdf-logging); 85 - [Creating an RDataFrame from a dataset specification file](\ref rdf-from-spec); 86 - [Adding a progress bar](\ref progressbar); 87 - [Working with missing values in the dataset](\ref missing-values); 88- [Efficient analysis in Python](\ref python); 89- <a class=""el"" href=""classROOT_1_1RDataFrame.html#reference"" onclick=""javascript:toggleInherit('pub_methods_classROOT_1_1RDF_1_1RInterface')"">Class reference</a>; 90 ; 91\anchor cheatsheet; 92## Cheat sheet; 93These are the operations which can be performed with RDataFrame.; 94 ; 95### Transformations; 96Transformations are a way to manipulate the data.; 97 ; 98| **Transformation** | **Description** |; 99|------------------|--------------------|; 100| Alias() | Introduce an alias for a particular column name. |; 101| DefaultValueFor() | If the value of the input column is missing, provide a default value instead. |; 102| Define() | Create a new column in the dataset. Example usages include adding a column that contains the invariant mass of a particle, or a selection of elements of an array (e.g. only the `pt`s of ""good"" muons). |; 103| DefinePerSample() | Define a new column that is updated when the input sample changes, e.g. when switching tree being processed in a chain. |; 104| DefineSlot() | Same as Define(), but the user-defined function must take an extra `unsigned int slot` as its first parameter. `slot` will take a different value, `",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:5308,Deployability,update,updated,5308," with missing values in the dataset](\ref missing-values); 88- [Efficient analysis in Python](\ref python); 89- <a class=""el"" href=""classROOT_1_1RDataFrame.html#reference"" onclick=""javascript:toggleInherit('pub_methods_classROOT_1_1RDF_1_1RInterface')"">Class reference</a>; 90 ; 91\anchor cheatsheet; 92## Cheat sheet; 93These are the operations which can be performed with RDataFrame.; 94 ; 95### Transformations; 96Transformations are a way to manipulate the data.; 97 ; 98| **Transformation** | **Description** |; 99|------------------|--------------------|; 100| Alias() | Introduce an alias for a particular column name. |; 101| DefaultValueFor() | If the value of the input column is missing, provide a default value instead. |; 102| Define() | Create a new column in the dataset. Example usages include adding a column that contains the invariant mass of a particle, or a selection of elements of an array (e.g. only the `pt`s of ""good"" muons). |; 103| DefinePerSample() | Define a new column that is updated when the input sample changes, e.g. when switching tree being processed in a chain. |; 104| DefineSlot() | Same as Define(), but the user-defined function must take an extra `unsigned int slot` as its first parameter. `slot` will take a different value, `0` to `nThreads - 1`, for each thread of execution. This is meant as a helper in writing thread-safe Define() transformation when using RDataFrame after ROOT::EnableImplicitMT(). DefineSlot() works just as well with single-thread execution: in that case `slot` will always be `0`. |; 105| DefineSlotEntry() | Same as DefineSlot(), but the entry number is passed in addition to the slot number. This is meant as a helper in case the expression depends on the entry number. For details about entry numbers in multi-threaded runs, see [here](\ref helper-cols). |; 106| Filter() | Filter rows based on user-defined conditions. |; 107| FilterAvailable() | Specialized Filter. If the value of the input column is available, keep the en",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:42290,Deployability,configurat,configuration,42290,"ne; 715- Snapshot; 716- Stats; 717- StdDev; 718- Sum; 719- Systematic variations: Vary and [VariationsFor](\ref ROOT::RDF::Experimental::VariationsFor).; 720- Parallel submission of distributed graphs: [RunGraphs](\ref ROOT::RDF::RunGraphs).; 721- Information about the dataframe: GetColumnNames.; 722 ; 723with support for more operations coming in the future. Data sources other than TTree and TChain (e.g. CSV, RNTuple) are; 724currently not supported.; 725 ; 726\note The distributed RDataFrame module requires at least Python version 3.8.; 727 ; 728### Connecting to a Spark cluster; 729 ; 730In order to distribute the RDataFrame workload, you can connect to a Spark cluster you have access to through the; 731official [Spark API](https://spark.apache.org/docs/latest/rdd-programming-guide.html#initializing-spark), then hook the; 732connection instance to the distributed `RDataFrame` object like so:; 733 ; 734~~~{.py}; 735import pyspark; 736import ROOT; 737 ; 738# Create a SparkContext object with the right configuration for your Spark cluster; 739conf = SparkConf().setAppName(appName).setMaster(master); 740sc = SparkContext(conf=conf); 741 ; 742# Point RDataFrame calls to the Spark specific RDataFrame; 743RDataFrame = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame; 744 ; 745# The Spark RDataFrame constructor accepts an optional ""sparkcontext"" parameter; 746# and it will distribute the application to the connected cluster; 747df = RDataFrame(""mytree"", ""myfile.root"", sparkcontext = sc); 748~~~; 749 ; 750If an instance of [SparkContext](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.SparkContext.html); 751is not provided, the default behaviour is to create one in the background for you.; 752 ; 753### Connecting to a Dask cluster; 754 ; 755Similarly, you can connect to a Dask cluster by creating your own connection object which internally operates with one; 756of the cluster schedulers supported by Dask (more information in the; 757[Dask distribute",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:49721,Deployability,continuous,continuously,49721,"e; 859 ; 860if __name__ == ""__main__"":; 861 df = RDataFrame(""mytree"",""myfile.root"").Define(""x"",""someoperation""); 862 # The model can be passed either as a tuple with the arguments in the correct order; 863 df.Histo1D((""name"", ""title"", 10, 0, 10), ""x""); 864 # Or by creating the specific struct; 865 model = ROOT.RDF.TH1DModel(""name"", ""title"", 10, 0, 10); 866 df.Histo1D(model, ""x""); 867~~~; 868 ; 869Without this, two partial histograms resulting from two distributed tasks would have incompatible binning, thus leading; 870to errors when merging them. Failing to pass a histogram model will raise an error on the client side, before starting; 871the distributed execution.; 872 ; 873### Live visualization in distributed mode with dask; 874 ; 875The live visualization feature allows real-time data representation of plots generated during the execution ; 876of a distributed RDataFrame application. ; 877It enables visualizing intermediate results as they are computed across multiple nodes of a Dask cluster; 878by creating a canvas and continuously updating it as partial results become available. ; 879 ; 880The LiveVisualize() function can be imported from the Python package **ROOT.RDF.Experimental.Distributed**:; 881 ; 882~~~{.py}; 883import ROOT; 884 ; 885LiveVisualize = ROOT.RDF.Experimental.Distributed.LiveVisualize; 886~~~; 887 ; 888The function takes drawable objects (e.g. histograms) and optional callback functions as argument, it accepts 4 different input formats:; 889 ; 890- Passing a list or tuple of drawables: ; 891You can pass a list or tuple containing the plots you want to visualize. For example:; 892 ; 893~~~{.py}; 894LiveVisualize([h_gaus, h_exp, h_random]); 895~~~; 896 ; 897- Passing a list or tuple of drawables with a global callback function: ; 898You can also include a global callback function that will be applied to all plots. For example:; 899 ; 900~~~{.py}; 901def set_fill_color(hist):; 902 hist.SetFillColor(ROOT.kBlue); 903 ; 904LiveVisualize([h_gaus, h_e",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:58641,Deployability,release,released,58641,"depend on the size of the dataset) as part of the event loop runtime (which scales with the size of the dataset). RDataFrame has an experimental logging feature that simplifies measuring the time spent in just-in-time compilation and in the event loop (as well as providing some more interesting information). See [Activating RDataFrame execution logs](\ref rdf-logging).; 1006 ; 1007### Memory usage; 1008 ; 1009There are two reasons why RDataFrame may consume more memory than expected. Firstly, each result is duplicated for each worker thread, which e.g. in case of many (possibly multi-dimensional) histograms with fine binning can result in visible memory consumption during the event loop. The thread-local copies of the results are destroyed when the final result is produced. Reducing the number of threads or using coarser binning will reduce the memory usage.; 1010 ; 1011Secondly, just-in-time compilation of string expressions or non-templated actions (see the previous paragraph) causes Cling, ROOT's C++ interpreter, to allocate some memory for the generated code that is only released at the end of the application. This commonly results in memory usage creep in long-running applications that create many RDataFrames one after the other. Possible mitigations include creating and running each RDataFrame event loop in a sub-process, or booking all operations for all different RDataFrame computation graphs before the first event loop is triggered, so that the interpreter is invoked only once for all computation graphs:; 1012 ; 1013~~~{.cpp}; 1014// assuming df1 and df2 are separate computation graphs, do:; 1015auto h1 = df1.Histo1D(""x"");; 1016auto h2 = df2.Histo1D(""y"");; 1017h1->Draw(); // we just-in-time compile everything needed by df1 and df2 here; 1018h2->Draw(""SAME"");; 1019 ; 1020// do not:; 1021auto h1 = df1.Histo1D(""x"");; 1022h1->Draw(); // we just-in-time compile here; 1023auto h2 = df2.Histo1D(""y"");; 1024h2->Draw(""SAME""); // we just-in-time compile again here, as ",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:65335,Deployability,release,releases,65335,"eta*0.9f, eta*1.1f}; },; 1107 {""eta""},; 1108 2);; 1109 ; 1110auto nom_h = df.Histo2D(histoModel, ""pt"", ""eta"");; 1111auto all_hs = VariationsFor(nom_h);; 1112all_hs.GetKeys(); // returns {""nominal"", ""pt:down"", ""pt:up"", ""eta:0"", ""eta:1""}; 1113~~~; 1114 ; 1115Note how we passed the integer `2` instead of a list of variation tags to the second Vary() invocation: this is a; 1116shorthand that automatically generates tags 0 to N-1 (in this case 0 and 1).; 1117 ; 1118\note Currently, VariationsFor() and RResultMap are in the `ROOT::RDF::Experimental` namespace, to indicate that these; 1119 interfaces might still evolve and improve based on user feedback. We expect that some aspects of the related; 1120 programming model will be streamlined in future versions.; 1121 ; 1122\note Currently, the results of a Snapshot(), Report() or Display() call cannot be varied (i.e. it is not possible to; 1123 call \ref ROOT::RDF::Experimental::VariationsFor ""VariationsFor()"" on them. These limitations will be lifted in future releases.; 1124 ; 1125See the Vary() method for more information and [this tutorial](https://root.cern/doc/master/df106__HiggsToFourLeptons_8C.html) ; 1126for an example usage of Vary and \ref ROOT::RDF::Experimental::VariationsFor ""VariationsFor()"" in the analysis.; 1127 ; 1128\anchor rnode; 1129### RDataFrame objects as function arguments and return values; 1130RDataFrame variables/nodes are relatively cheap to copy and it's possible to both pass them to (or move them into); 1131functions and to return them from functions. However, in general each dataframe node will have a different C++ type,; 1132which includes all available compile-time information about what that node does. One way to cope with this complication; 1133is to use template functions and/or C++14 auto return types:; 1134~~~{.cpp}; 1135template <typename RDF>; 1136auto ApplySomeFilters(RDF df); 1137{; 1138 return df.Filter(""x > 0"").Filter([](int y) { return y < 0; }, {""y""});; 1139}; 1140~~~; 1141 ; 114",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:35990,Energy Efficiency,efficient,efficient,35990,"first 10 entries *that pass the; 583preceding filter*.; 584 ; 585Ranges allow ""early quitting"": if all branches of execution of a functional graph reached their `end` value of; 586processed entries, the event-loop is immediately interrupted. This is useful for debugging and quick data explorations.; 587 ; 588\anchor custom-columns; 589### Custom columns; 590Custom columns are created by invoking `Define(name, f, columnList)`. As usual, `f` can be any callable object; 591(function, lambda expression, functor class...); it takes the values of the columns listed in `columnList` (a list of; 592strings) as parameters, in the same order as they are listed in `columnList`. `f` must return the value that will be; 593assigned to the temporary column.; 594 ; 595A new variable is created called `name`, accessible as if it was contained in the dataset from subsequent; 596transformations/actions.; 597 ; 598Use cases include:; 599- caching the results of complex calculations for easy and efficient multiple access; 600- extraction of quantities of interest from complex objects; 601- branch aliasing, i.e. changing the name of a branch; 602 ; 603An exception is thrown if the `name` of the new column/branch is already in use for another branch in the TTree.; 604 ; 605It is also possible to specify the quantity to be stored in the new temporary column as a C++ expression with the method; 606`Define(name, expression)`. For example this invocation; 607 ; 608~~~{.cpp}; 609df.Define(""pt"", ""sqrt(px*px + py*py)"");; 610~~~; 611 ; 612will create a new column called ""pt"" the value of which is calculated starting from the columns px and py. The system; 613builds a just-in-time compiled function starting from the expression after having deduced the list of necessary branches; 614from the names of the variables specified by the user.; 615 ; 616#### Custom columns as function of slot and entry number; 617 ; 618It is possible to create custom columns also as a function of the processing slot and en",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:43199,Energy Efficiency,schedul,schedulers,43199,"DataFrame` object like so:; 733 ; 734~~~{.py}; 735import pyspark; 736import ROOT; 737 ; 738# Create a SparkContext object with the right configuration for your Spark cluster; 739conf = SparkConf().setAppName(appName).setMaster(master); 740sc = SparkContext(conf=conf); 741 ; 742# Point RDataFrame calls to the Spark specific RDataFrame; 743RDataFrame = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame; 744 ; 745# The Spark RDataFrame constructor accepts an optional ""sparkcontext"" parameter; 746# and it will distribute the application to the connected cluster; 747df = RDataFrame(""mytree"", ""myfile.root"", sparkcontext = sc); 748~~~; 749 ; 750If an instance of [SparkContext](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.SparkContext.html); 751is not provided, the default behaviour is to create one in the background for you.; 752 ; 753### Connecting to a Dask cluster; 754 ; 755Similarly, you can connect to a Dask cluster by creating your own connection object which internally operates with one; 756of the cluster schedulers supported by Dask (more information in the; 757[Dask distributed docs](http://distributed.dask.org/en/stable/)):; 758 ; 759~~~{.py}; 760import ROOT; 761from dask.distributed import Client; 762 ; 763# Point RDataFrame calls to the Dask specific RDataFrame; 764RDataFrame = ROOT.RDF.Experimental.Distributed.Dask.RDataFrame; 765 ; 766# In a Python script the Dask client needs to be initalized in a context; 767# Jupyter notebooks / Python session don't need this; 768if __name__ == ""__main__"":; 769 # With an already setup cluster that exposes a Dask scheduler endpoint; 770 client = Client(""dask_scheduler.domain.com:8786""); 771 ; 772 # The Dask RDataFrame constructor accepts the Dask Client object as an optional argument; 773 df = RDataFrame(""mytree"",""myfile.root"", daskclient=client); 774 # Proceed as usual; 775 df.Define(""x"",""someoperation"").Histo1D((""name"", ""title"", 10, 0, 10), ""x""); 776~~~; 777 ; 778If an instance of [distributed.Clie",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:43760,Energy Efficiency,schedul,scheduler,43760,"tribute the application to the connected cluster; 747df = RDataFrame(""mytree"", ""myfile.root"", sparkcontext = sc); 748~~~; 749 ; 750If an instance of [SparkContext](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.SparkContext.html); 751is not provided, the default behaviour is to create one in the background for you.; 752 ; 753### Connecting to a Dask cluster; 754 ; 755Similarly, you can connect to a Dask cluster by creating your own connection object which internally operates with one; 756of the cluster schedulers supported by Dask (more information in the; 757[Dask distributed docs](http://distributed.dask.org/en/stable/)):; 758 ; 759~~~{.py}; 760import ROOT; 761from dask.distributed import Client; 762 ; 763# Point RDataFrame calls to the Dask specific RDataFrame; 764RDataFrame = ROOT.RDF.Experimental.Distributed.Dask.RDataFrame; 765 ; 766# In a Python script the Dask client needs to be initalized in a context; 767# Jupyter notebooks / Python session don't need this; 768if __name__ == ""__main__"":; 769 # With an already setup cluster that exposes a Dask scheduler endpoint; 770 client = Client(""dask_scheduler.domain.com:8786""); 771 ; 772 # The Dask RDataFrame constructor accepts the Dask Client object as an optional argument; 773 df = RDataFrame(""mytree"",""myfile.root"", daskclient=client); 774 # Proceed as usual; 775 df.Define(""x"",""someoperation"").Histo1D((""name"", ""title"", 10, 0, 10), ""x""); 776~~~; 777 ; 778If an instance of [distributed.Client](http://distributed.dask.org/en/stable/api.html#distributed.Client) is not; 779provided to the RDataFrame object, it will be created for you and it will run the computations in the local machine; 780using all cores available.; 781 ; 782### Choosing the number of distributed tasks; 783 ; 784A distributed RDataFrame has internal logic to define in how many chunks the input dataset will be split before sending; 785tasks to the distributed backend. Each task reads and processes one of said chunks. The logic is ",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:53034,Energy Efficiency,allocate,allocated,53034,"vantage of a pool of worker threads. **Each worker thread processes a distinct; 939subset of entries**, and their partial results are merged before returning the final values to the user.; 940There are no guarantees on the order in which threads will process the batches of entries.; 941In particular, note that this means that, for multi-thread event loops, there is no; 942guarantee on the order in which Snapshot() will _write_ entries: they could be scrambled with respect to the input dataset. The values of the special `rdfentry_` column will also not correspond to the entry numbers in the input dataset (e.g. TChain) in multi-thread runs.; 943 ; 944\warning By default, RDataFrame will use as many threads as the hardware supports, using up **all** the resources on; 945a machine. This might be undesirable on shared computing resources such as a batch cluster. Therefore, when running on shared computing resources, use; 946~~~{.cpp}; 947ROOT::EnableImplicitMT(i); 948~~~; 949replacing `i` with the number of CPUs/slots that were allocated for this job.; 950 ; 951### Thread-safety of user-defined expressions; 952RDataFrame operations such as Histo1D() or Snapshot() are guaranteed to work correctly in multi-thread event loops.; 953User-defined expressions, such as strings or lambdas passed to Filter(), Define(), Foreach(), Reduce() or Aggregate(); 954will have to be thread-safe, i.e. it should be possible to call them concurrently from different threads.; 955 ; 956Note that simple Filter() and Define() transformations will inherently satisfy this requirement: Filter() / Define(); 957expressions will often be *pure* in the functional programming sense (no side-effects, no dependency on external state),; 958which eliminates all risks of race conditions.; 959 ; 960In order to facilitate writing of thread-safe operations, some RDataFrame features such as Foreach(), Define() or \link ROOT::RDF::RResultPtr::OnPartialResult OnPartialResult()\endlink; 961offer thread-aware counterp",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:57122,Energy Efficiency,reduce,reduce,57122,"performance out of RDataFrame, make sure to avoid just-in-time compiled versions of transformations and actions if at all possible.; 995For instance, `Filter(""x > 0"")` requires just-in-time compilation of the corresponding C++ logic, while the equivalent `Filter([](float x) { return x > 0.; }, {""x""})` does not.; 996Similarly, `Histo1D(""x"")` requires just-in-time compilation after the type of `x` is retrieved from the dataset, while `Histo1D<float>(""x"")` does not; the latter spelling; 997should be preferred for performance-critical applications.; 998 ; 999Python applications cannot easily specify template parameters or pass C++ callables to RDataFrame.; 1000See [Efficient analysis in Python](#python) for possible ways to speed up hot paths in this case.; 1001 ; 1002Just-in-time compilation happens once, right before starting an event loop. To reduce the runtime cost of this step, make sure to book all operations *for all RDataFrame computation graphs*; 1003before the first event loop is triggered: just-in-time compilation will happen once for all code required to be generated up to that point, also across different computation graphs.; 1004 ; 1005Also make sure not to count the just-in-time compilation time (which happens once before the event loop and does not depend on the size of the dataset) as part of the event loop runtime (which scales with the size of the dataset). RDataFrame has an experimental logging feature that simplifies measuring the time spent in just-in-time compilation and in the event loop (as well as providing some more interesting information). See [Activating RDataFrame execution logs](\ref rdf-logging).; 1006 ; 1007### Memory usage; 1008 ; 1009There are two reasons why RDataFrame may consume more memory than expected. Firstly, each result is duplicated for each worker thread, which e.g. in case of many (possibly multi-dimensional) histograms with fine binning can result in visible memory consumption during the event loop. The thread-local copies",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:58211,Energy Efficiency,consumption,consumption,58211,"k all operations *for all RDataFrame computation graphs*; 1003before the first event loop is triggered: just-in-time compilation will happen once for all code required to be generated up to that point, also across different computation graphs.; 1004 ; 1005Also make sure not to count the just-in-time compilation time (which happens once before the event loop and does not depend on the size of the dataset) as part of the event loop runtime (which scales with the size of the dataset). RDataFrame has an experimental logging feature that simplifies measuring the time spent in just-in-time compilation and in the event loop (as well as providing some more interesting information). See [Activating RDataFrame execution logs](\ref rdf-logging).; 1006 ; 1007### Memory usage; 1008 ; 1009There are two reasons why RDataFrame may consume more memory than expected. Firstly, each result is duplicated for each worker thread, which e.g. in case of many (possibly multi-dimensional) histograms with fine binning can result in visible memory consumption during the event loop. The thread-local copies of the results are destroyed when the final result is produced. Reducing the number of threads or using coarser binning will reduce the memory usage.; 1010 ; 1011Secondly, just-in-time compilation of string expressions or non-templated actions (see the previous paragraph) causes Cling, ROOT's C++ interpreter, to allocate some memory for the generated code that is only released at the end of the application. This commonly results in memory usage creep in long-running applications that create many RDataFrames one after the other. Possible mitigations include creating and running each RDataFrame event loop in a sub-process, or booking all operations for all different RDataFrame computation graphs before the first event loop is triggered, so that the interpreter is invoked only once for all computation graphs:; 1012 ; 1013~~~{.cpp}; 1014// assuming df1 and df2 are separate computation graphs, do:;",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:58395,Energy Efficiency,reduce,reduce,58395,", also across different computation graphs.; 1004 ; 1005Also make sure not to count the just-in-time compilation time (which happens once before the event loop and does not depend on the size of the dataset) as part of the event loop runtime (which scales with the size of the dataset). RDataFrame has an experimental logging feature that simplifies measuring the time spent in just-in-time compilation and in the event loop (as well as providing some more interesting information). See [Activating RDataFrame execution logs](\ref rdf-logging).; 1006 ; 1007### Memory usage; 1008 ; 1009There are two reasons why RDataFrame may consume more memory than expected. Firstly, each result is duplicated for each worker thread, which e.g. in case of many (possibly multi-dimensional) histograms with fine binning can result in visible memory consumption during the event loop. The thread-local copies of the results are destroyed when the final result is produced. Reducing the number of threads or using coarser binning will reduce the memory usage.; 1010 ; 1011Secondly, just-in-time compilation of string expressions or non-templated actions (see the previous paragraph) causes Cling, ROOT's C++ interpreter, to allocate some memory for the generated code that is only released at the end of the application. This commonly results in memory usage creep in long-running applications that create many RDataFrames one after the other. Possible mitigations include creating and running each RDataFrame event loop in a sub-process, or booking all operations for all different RDataFrame computation graphs before the first event loop is triggered, so that the interpreter is invoked only once for all computation graphs:; 1012 ; 1013~~~{.cpp}; 1014// assuming df1 and df2 are separate computation graphs, do:; 1015auto h1 = df1.Histo1D(""x"");; 1016auto h2 = df2.Histo1D(""y"");; 1017h1->Draw(); // we just-in-time compile everything needed by df1 and df2 here; 1018h2->Draw(""SAME"");; 1019 ; 1020// do not:; 1021a",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:58584,Energy Efficiency,allocate,allocate,58584,"depend on the size of the dataset) as part of the event loop runtime (which scales with the size of the dataset). RDataFrame has an experimental logging feature that simplifies measuring the time spent in just-in-time compilation and in the event loop (as well as providing some more interesting information). See [Activating RDataFrame execution logs](\ref rdf-logging).; 1006 ; 1007### Memory usage; 1008 ; 1009There are two reasons why RDataFrame may consume more memory than expected. Firstly, each result is duplicated for each worker thread, which e.g. in case of many (possibly multi-dimensional) histograms with fine binning can result in visible memory consumption during the event loop. The thread-local copies of the results are destroyed when the final result is produced. Reducing the number of threads or using coarser binning will reduce the memory usage.; 1010 ; 1011Secondly, just-in-time compilation of string expressions or non-templated actions (see the previous paragraph) causes Cling, ROOT's C++ interpreter, to allocate some memory for the generated code that is only released at the end of the application. This commonly results in memory usage creep in long-running applications that create many RDataFrames one after the other. Possible mitigations include creating and running each RDataFrame event loop in a sub-process, or booking all operations for all different RDataFrame computation graphs before the first event loop is triggered, so that the interpreter is invoked only once for all computation graphs:; 1012 ; 1013~~~{.cpp}; 1014// assuming df1 and df2 are separate computation graphs, do:; 1015auto h1 = df1.Histo1D(""x"");; 1016auto h2 = df2.Histo1D(""y"");; 1017h1->Draw(); // we just-in-time compile everything needed by df1 and df2 here; 1018h2->Draw(""SAME"");; 1019 ; 1020// do not:; 1021auto h1 = df1.Histo1D(""x"");; 1022h1->Draw(); // we just-in-time compile here; 1023auto h2 = df2.Histo1D(""y"");; 1024h2->Draw(""SAME""); // we just-in-time compile again here, as ",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:67633,Energy Efficiency,schedul,schedule,67633,"RNode MaybeAddRange(RNode df, bool mustAddRange); 1147{; 1148 return mustAddRange ? df.Range(1) : df;; 1149}; 1150// use as :; 1151ROOT::RDataFrame df(10);; 1152auto maybeRangedDF = MaybeAddRange(df, true);; 1153~~~; 1154 ; 1155The conversion to ROOT::RDF::RNode is cheap, but it will introduce an extra virtual call during the RDataFrame event; 1156loop (in most cases, the resulting performance impact should be negligible). Python users can perform the conversion with the helper function `ROOT.RDF.AsRNode`.; 1157 ; 1158\anchor RDFCollections; 1159### Storing RDataFrame objects in collections; 1160 ; 1161ROOT::RDF::RNode also makes it simple to store RDataFrame nodes in collections, e.g. a `std::vector<RNode>` or a `std::map<std::string, RNode>`:; 1162 ; 1163~~~{.cpp}; 1164std::vector<ROOT::RDF::RNode> dfs;; 1165dfs.emplace_back(ROOT::RDataFrame(10));; 1166dfs.emplace_back(dfs[0].Define(""x"", ""42.f""));; 1167~~~; 1168 ; 1169\anchor callbacks; 1170### Executing callbacks every N events; 1171It's possible to schedule execution of arbitrary functions (callbacks) during the event loop.; 1172Callbacks can be used e.g. to inspect partial results of the analysis while the event loop is running,; 1173drawing a partially-filled histogram every time a certain number of new entries is processed, or; 1174displaying a progress bar while the event loop runs.; 1175 ; 1176For example one can draw an up-to-date version of a result histogram every 100 entries like this:; 1177~~~{.cpp}; 1178auto h = df.Histo1D(""x"");; 1179TCanvas c(""c"",""x hist"");; 1180h.OnPartialResult(100, [&c](TH1D &h_) { c.cd(); h_.Draw(); c.Update(); });; 1181// event loop runs here, this final `Draw` is executed after the event loop is finished; 1182h->Draw();; 1183~~~; 1184 ; 1185Callbacks are registered to a ROOT::RDF::RResultPtr and must be callables that takes a reference to the result type as argument; 1186and return nothing. RDataFrame will invoke registered callbacks passing partial action results as arguments t",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:1443,Integrability,interface,interface,1443,"*******; 4 * Copyright (C) 1995-2018, Rene Brun and Fons Rademakers. *; 5 * All rights reserved. *; 6 * *; 7 * For the licensing terms see $ROOTSYS/LICENSE. *; 8 * For the list of contributors see $ROOTSYS/README/CREDITS. *; 9 *************************************************************************/; 10 ; 11#include ""ROOT/InternalTreeUtils.hxx""; 12#include ""ROOT/RDataFrame.hxx""; 13#include ""ROOT/RDataSource.hxx""; 14#include ""ROOT/RDF/RDatasetSpec.hxx""; 15#include ""ROOT/RDF/RInterface.hxx""; 16#include ""ROOT/RDF/RLoopManager.hxx""; 17#include ""ROOT/RDF/Utils.hxx""; 18#include <string_view>; 19#include ""TChain.h""; 20#include ""TDirectory.h""; 21#include ""RtypesCore.h"" // for ULong64_t; 22#include ""TTree.h""; 23 ; 24#include <fstream> // std::ifstream; 25#include <nlohmann/json.hpp> // nlohmann::json::parse; 26#include <memory> // for make_shared, allocator, shared_ptr; 27#include <ostream> // ostringstream; 28#include <stdexcept>; 29#include <string>; 30#include <vector>; 31 ; 32// clang-format off; 33/**; 34* \class ROOT::RDataFrame; 35* \ingroup dataframe; 36* \brief ROOT's RDataFrame offers a modern, high-level interface for analysis of data stored in TTree , CSV and other data formats, in C++ or Python.; 37 ; 38In addition, multi-threading and other low-level optimisations allow users to exploit all the resources available; 39on their machines completely transparently.<br>; 40Skip to the [class reference](#reference) or keep reading for the user guide.; 41 ; 42In a nutshell:; 43~~~{.cpp}; 44ROOT::EnableImplicitMT(); // Tell ROOT you want to go parallel; 45ROOT::RDataFrame d(""myTree"", ""file_*.root""); // Interface to TTree and TChain; 46auto myHisto = d.Histo1D(""Branch_A""); // This books the (lazy) filling of a histogram; 47myHisto->Draw(); // Event loop is run here, upon first access to a result; 48~~~; 49 ; 50Calculations are expressed in terms of a type-safe *functional chain of actions and transformations*, RDataFrame takes; 51care of their execution. The implementat",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:6014,Integrability,depend,depends,6014,"ide a default value instead. |; 102| Define() | Create a new column in the dataset. Example usages include adding a column that contains the invariant mass of a particle, or a selection of elements of an array (e.g. only the `pt`s of ""good"" muons). |; 103| DefinePerSample() | Define a new column that is updated when the input sample changes, e.g. when switching tree being processed in a chain. |; 104| DefineSlot() | Same as Define(), but the user-defined function must take an extra `unsigned int slot` as its first parameter. `slot` will take a different value, `0` to `nThreads - 1`, for each thread of execution. This is meant as a helper in writing thread-safe Define() transformation when using RDataFrame after ROOT::EnableImplicitMT(). DefineSlot() works just as well with single-thread execution: in that case `slot` will always be `0`. |; 105| DefineSlotEntry() | Same as DefineSlot(), but the entry number is passed in addition to the slot number. This is meant as a helper in case the expression depends on the entry number. For details about entry numbers in multi-threaded runs, see [here](\ref helper-cols). |; 106| Filter() | Filter rows based on user-defined conditions. |; 107| FilterAvailable() | Specialized Filter. If the value of the input column is available, keep the entry, otherwise discard it. |; 108| FilterMissing() | Specialized Filter. If the value of the input column is missing, keep the entry, otherwise discard it. |; 109| Range() | Filter rows based on entry number (single-thread only). |; 110| Redefine() | Overwrite the value and/or type of an existing column. See Define() for more information. |; 111| RedefineSlot() | Overwrite the value and/or type of an existing column. See DefineSlot() for more information. |; 112| RedefineSlotEntry() | Overwrite the value and/or type of an existing column. See DefineSlotEntry() for more information. |; 113| Vary() | Register systematic variations for an existing column. Varied results are then extracted via Vari",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:20290,Integrability,wrap,wrapped,20290,"ctions (see e.g. FromCSV(), FromSqlite(), FromArrow()):; 316 ; 317~~~{.cpp}; 318auto df = ROOT::RDF::FromCSV(""input.csv"");; 319// use df as usual; 320~~~; 321 ; 322### Filling a histogram; 323Let's now tackle a very common task, filling a histogram:; 324~~~{.cpp}; 325// Fill a TH1D with the ""MET"" branch; 326RDataFrame d(""myTree"", ""file.root"");; 327auto h = d.Histo1D(""MET"");; 328h->Draw();; 329~~~; 330The first line creates an RDataFrame associated to the TTree ""myTree"". This tree has a branch named ""MET"".; 331 ; 332Histo1D() is an *action*; it returns a smart pointer (a ROOT::RDF::RResultPtr, to be precise) to a TH1D histogram filled; 333with the `MET` of all events. If the quantity stored in the column is a collection (e.g. a vector or an array), the; 334histogram is filled with all vector elements for each event.; 335 ; 336You can use the objects returned by actions as if they were pointers to the desired results. There are many other; 337possible [actions](\ref cheatsheet), and all their results are wrapped in smart pointers; we'll see why in a minute.; 338 ; 339### Applying a filter; 340Let's say we want to cut over the value of branch ""MET"" and count how many events pass this cut. This is one way to do it:; 341~~~{.cpp}; 342RDataFrame d(""myTree"", ""file.root"");; 343auto c = d.Filter(""MET > 4."").Count(); // computations booked, not run; 344std::cout << *c << std::endl; // computations run here, upon first access to the result; 345~~~; 346The filter string (which must contain a valid C++ expression) is applied to the specified columns for each event;; 347the name and types of the columns are inferred automatically. The string expression is required to return a `bool`; 348which signals whether the event passes the filter (`true`) or not (`false`).; 349 ; 350You can think of your data as ""flowing"" through the chain of calls, being transformed, filtered and finally used to; 351perform actions. Multiple Filter() calls can be chained one after another.; 352 ; 353Using ",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:30695,Integrability,interface,interface,30695,"once and produce all results in one go.; 501 ; 502### Going parallel; 503Let's say we would like to run the previous examples in parallel on several cores, dividing events fairly between cores.; 504The only modification required to the snippets would be the addition of this line *before* constructing the main; 505dataframe object:; 506~~~{.cpp}; 507ROOT::EnableImplicitMT();; 508~~~; 509Simple as that. More details are given [below](#parallel-execution).; 510 ; 511\anchor collections; 512## Working with collections and object selections; 513 ; 514RDataFrame reads collections as the special type [ROOT::RVec](https://root.cern/doc/master/classROOT_1_1VecOps_1_1RVec.html): for example, a column containing an array of floating point numbers can be read as a ROOT::RVecF. C-style arrays (with variable or static size), STL vectors and most other collection types can be read this way.; 515 ; 516RVec is a container similar to std::vector (and can be used just like a std::vector) but it also offers a rich interface to operate on the array elements in a vectorised fashion, similarly to Python's NumPy arrays.; 517 ; 518For example, to fill a histogram with the ""pt"" of selected particles for each event, Define() can be used to create a column that contains the desired array elements as follows:; 519 ; 520~~~{.cpp}; 521// h is filled with all the elements of `good_pts`, for each event; 522auto h = df.Define(""good_pts"", [](const ROOT::RVecF &pt) { return pt[pt > 0]; }); 523 .Histo1D(""good_pts"");; 524~~~; 525 ; 526And in Python:; 527 ; 528~~~{.py}; 529h = df.Define(""good_pts"", ""pt[pt > 0]"").Histo1D(""good_pts""); 530~~~; 531 ; 532Learn more at ROOT::VecOps::RVec.; 533 ; 534\anchor transformations; 535## Transformations: manipulating data; 536\anchor Filters; 537### Filters; 538A filter is created through a call to `Filter(f, columnList)` or `Filter(filterString)`. In the first overload, `f` can; 539be a function, a lambda expression, a functor class, or any other callable object. It mu",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:32715,Integrability,depend,depend,32715,"e`) or not (`false`). It should perform ""read-only"" operations on the; 541columns, and should not have side-effects (e.g. modification of an external or static variable) to ensure correctness; 542when implicit multi-threading is active. The second overload takes a string with a valid C++ expression in which column; 543names are used as variable names (e.g. `Filter(""x[0] + x[1] > 0"")`). This is a convenience feature that comes with a; 544certain runtime overhead: C++ code has to be generated on the fly from this expression before using it in the event; 545loop. See the paragraph about ""Just-in-time compilation"" below for more information.; 546 ; 547RDataFrame only evaluates filters when necessary: if multiple filters are chained one after another, they are executed; 548in order and the first one returning `false` causes the event to be discarded and triggers the processing of the next; 549entry. If multiple actions or transformations depend on the same filter, that filter is not executed multiple times for; 550each entry: after the first access it simply serves a cached result.; 551 ; 552\anchor named-filters-and-cutflow-reports; 553#### Named filters and cutflow reports; 554An optional string parameter `name` can be passed to the Filter() method to create a **named filter**. Named filters; 555work as usual, but also keep track of how many entries they accept and reject.; 556 ; 557Statistics are retrieved through a call to the Report() method:; 558 ; 559- when Report() is called on the main RDataFrame object, it returns a ROOT::RDF::RResultPtr<RCutFlowReport> relative to all; 560named filters declared up to that point; 561- when called on a specific node (e.g. the result of a Define() or Filter()), it returns a ROOT::RDF::RResultPtr<RCutFlowReport>; 562relative all named filters in the section of the chain between the main RDataFrame and that node (included).; 563 ; 564Stats are stored in the same order as named filters have been added to the graph, and *refer to the",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:38426,Integrability,wrap,wrapping,38426,".)`: the first parameter is the slot number while the second one the number of the entry being processed.; 624 ; 625\anchor actions; 626## Actions: getting results; 627### Instant and lazy actions; 628Actions can be **instant** or **lazy**. Instant actions are executed as soon as they are called, while lazy actions are; 629executed whenever the object they return is accessed for the first time. As a rule of thumb, actions with a return value; 630are lazy, the others are instant.; 631 ; 632### Return type of a lazy action; 633 ; 634When a lazy action is called, it returns a \link ROOT::RDF::RResultPtr ROOT::RDF::RResultPtr<T>\endlink, where T is the; 635type of the result of the action. The final result will be stored in the `RResultPtr` and can be retrieved by; 636dereferencing it or via its `GetValue` method.; 637 ; 638### Actions that return collections; 639 ; 640If the type of the return value of an action is a collection, e.g. `std::vector<int>`, you can iterate its elements; 641directly through the wrapping `RResultPtr`:; 642 ; 643~~~{.cpp}; 644ROOT::RDataFrame df{5};; 645auto df1 = df.Define(""x"", []{ return 42; });; 646for (const auto &el: df1.Take<int>(""x"")){; 647 std::cout << ""Element: "" << el << ""\n"";; 648}; 649~~~; 650 ; 651~~~{.py}; 652df = ROOT.RDataFrame(5).Define(""x"", ""42""); 653for el in df.Take[int](""x""):; 654 print(f""Element: {el}""); 655~~~; 656 ; 657### Actions and readers; 658 ; 659An action that needs values for its computations will request it from a reader, e.g. a column created via `Define` or; 660available from the input dataset. The action will request values from each column of the list of input columns (either; 661inferred or specified by the user), in order. For example:; 662 ; 663~~~{.cpp}; 664ROOT::RDataFrame df{1};; 665auto df1 = df.Define(""x"", []{ return 11; });; 666auto df2 = df1.Define(""y"", []{ return 22; });; 667auto graph = df2.Graph<int, int>(""x"",""y"");; 668~~~; 669 ; 670The `Graph` action is going to request first the value from co",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:44677,Integrability,depend,dependent,44677,"setup cluster that exposes a Dask scheduler endpoint; 770 client = Client(""dask_scheduler.domain.com:8786""); 771 ; 772 # The Dask RDataFrame constructor accepts the Dask Client object as an optional argument; 773 df = RDataFrame(""mytree"",""myfile.root"", daskclient=client); 774 # Proceed as usual; 775 df.Define(""x"",""someoperation"").Histo1D((""name"", ""title"", 10, 0, 10), ""x""); 776~~~; 777 ; 778If an instance of [distributed.Client](http://distributed.dask.org/en/stable/api.html#distributed.Client) is not; 779provided to the RDataFrame object, it will be created for you and it will run the computations in the local machine; 780using all cores available.; 781 ; 782### Choosing the number of distributed tasks; 783 ; 784A distributed RDataFrame has internal logic to define in how many chunks the input dataset will be split before sending; 785tasks to the distributed backend. Each task reads and processes one of said chunks. The logic is backend-dependent, but; 786generically tries to infer how many cores are available in the cluster through the connection object. The number of; 787tasks will be equal to the inferred number of cores. There are cases where the connection object of the chosen backend; 788doesn't have information about the actual resources of the cluster. An example of this is when using Dask to connect to; 789a batch system. The client object created at the beginning of the application does not automatically know how many cores; 790will be available during distributed execution, since the jobs are submitted to the batch system after the creation of; 791the connection. In such cases, the logic is to default to process the whole dataset in 2 tasks.; 792 ; 793The number of tasks submitted for distributed execution can be also set programmatically, by providing the optional; 794keyword argument `npartitions` when creating the RDataFrame object. This parameter is accepted irrespectively of the; 795backend used:; 796 ; 797~~~{.py}; 798import ROOT; 799 ; 800# Define ",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:53687,Integrability,depend,dependency,53687,"in) in multi-thread runs.; 943 ; 944\warning By default, RDataFrame will use as many threads as the hardware supports, using up **all** the resources on; 945a machine. This might be undesirable on shared computing resources such as a batch cluster. Therefore, when running on shared computing resources, use; 946~~~{.cpp}; 947ROOT::EnableImplicitMT(i); 948~~~; 949replacing `i` with the number of CPUs/slots that were allocated for this job.; 950 ; 951### Thread-safety of user-defined expressions; 952RDataFrame operations such as Histo1D() or Snapshot() are guaranteed to work correctly in multi-thread event loops.; 953User-defined expressions, such as strings or lambdas passed to Filter(), Define(), Foreach(), Reduce() or Aggregate(); 954will have to be thread-safe, i.e. it should be possible to call them concurrently from different threads.; 955 ; 956Note that simple Filter() and Define() transformations will inherently satisfy this requirement: Filter() / Define(); 957expressions will often be *pure* in the functional programming sense (no side-effects, no dependency on external state),; 958which eliminates all risks of race conditions.; 959 ; 960In order to facilitate writing of thread-safe operations, some RDataFrame features such as Foreach(), Define() or \link ROOT::RDF::RResultPtr::OnPartialResult OnPartialResult()\endlink; 961offer thread-aware counterparts (ForeachSlot(), DefineSlot(), \link ROOT::RDF::RResultPtr::OnPartialResultSlot OnPartialResultSlot()\endlink): their only difference is that they; 962will pass an extra `slot` argument (an unsigned integer) to the user-defined expression. When calling user-defined code; 963concurrently, RDataFrame guarantees that different threads will employ different values of the `slot` parameter,; 964where `slot` will be a number between 0 and `GetNSlots() - 1`.; 965In other words, within a slot, computation runs sequentially and events are processed sequentially.; 966Note that the same slot might be associated to differen",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:57549,Integrability,depend,depend,57549,"x) { return x > 0.; }, {""x""})` does not.; 996Similarly, `Histo1D(""x"")` requires just-in-time compilation after the type of `x` is retrieved from the dataset, while `Histo1D<float>(""x"")` does not; the latter spelling; 997should be preferred for performance-critical applications.; 998 ; 999Python applications cannot easily specify template parameters or pass C++ callables to RDataFrame.; 1000See [Efficient analysis in Python](#python) for possible ways to speed up hot paths in this case.; 1001 ; 1002Just-in-time compilation happens once, right before starting an event loop. To reduce the runtime cost of this step, make sure to book all operations *for all RDataFrame computation graphs*; 1003before the first event loop is triggered: just-in-time compilation will happen once for all code required to be generated up to that point, also across different computation graphs.; 1004 ; 1005Also make sure not to count the just-in-time compilation time (which happens once before the event loop and does not depend on the size of the dataset) as part of the event loop runtime (which scales with the size of the dataset). RDataFrame has an experimental logging feature that simplifies measuring the time spent in just-in-time compilation and in the event loop (as well as providing some more interesting information). See [Activating RDataFrame execution logs](\ref rdf-logging).; 1006 ; 1007### Memory usage; 1008 ; 1009There are two reasons why RDataFrame may consume more memory than expected. Firstly, each result is duplicated for each worker thread, which e.g. in case of many (possibly multi-dimensional) histograms with fine binning can result in visible memory consumption during the event loop. The thread-local copies of the results are destroyed when the final result is produced. Reducing the number of threads or using coarser binning will reduce the memory usage.; 1010 ; 1011Secondly, just-in-time compilation of string expressions or non-templated actions (see the previous paragraph",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:60514,Integrability,depend,dependencies,60514,"e just-in-time compile here; 1023auto h2 = df2.Histo1D(""y"");; 1024h2->Draw(""SAME""); // we just-in-time compile again here, as the second Histo1D call is new; 1025~~~; 1026 ; 1027\anchor more-features; 1028## More features; 1029Here is a list of the most important features that have been omitted in the ""Crash course"" for brevity.; 1030You don't need to read all these to start using RDataFrame, but they are useful to save typing time and runtime.; 1031 ; 1032\anchor systematics; 1033### Systematic variations; 1034 ; 1035Starting from ROOT v6.26, RDataFrame provides a flexible syntax to define systematic variations.; 1036This is done in two steps: a) register variations for one or more existing columns using Vary() and b) extract variations; 1037of normal RDataFrame results using \ref ROOT::RDF::Experimental::VariationsFor ""VariationsFor()"". In between these steps, no other change; 1038to the analysis code is required: the presence of systematic variations for certain columns is automatically propagated; 1039through filters, defines and actions, and RDataFrame will take these dependencies into account when producing varied; 1040results. \ref ROOT::RDF::Experimental::VariationsFor ""VariationsFor()"" is included in header `ROOT/RDFHelpers.hxx`. The compiled C++ programs must include this header; 1041explicitly, this is not required for ROOT macros. ; 1042 ; 1043An example usage of Vary() and \ref ROOT::RDF::Experimental::VariationsFor ""VariationsFor()"" in C++:; 1044 ; 1045~~~{.cpp}; 1046auto nominal_hx =; 1047 df.Vary(""pt"", ""ROOT::RVecD{pt*0.9f, pt*1.1f}"", {""down"", ""up""}); 1048 .Filter(""pt > pt_cut""); 1049 .Define(""x"", someFunc, {""pt""}); 1050 .Histo1D<float>(""x"");; 1051 ; 1052// request the generation of varied results from the nominal_hx; 1053ROOT::RDF::Experimental::RResultMap<TH1D> hx = ROOT::RDF::Experimental::VariationsFor(nominal_hx);; 1054 ; 1055// the event loop runs here, upon first access to any of the results or varied results:; 1056hx[""nominal""].Draw(); // same",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:62425,Integrability,depend,depend,62425,"o any of the results or varied results:; 1056hx[""nominal""].Draw(); // same effect as nominal_hx->Draw(); 1057hx[""pt:down""].Draw(""SAME"");; 1058hx[""pt:up""].Draw(""SAME"");; 1059~~~; 1060 ; 1061A list of variation ""tags"" is passed as the last argument to Vary(). The tags give names to the varied values that are returned; 1062as elements of an RVec of the appropriate C++ type. The number of variation tags must correspond to the number of elements of; 1063this RVec (2 in the example above: the first element will correspond to the tag ""down"", the second; 1064to the tag ""up""). The _full_ variation name will be composed of the varied column name and the variation tags (e.g.; 1065""pt:down"", ""pt:up"" in this example). Python usage looks similar.; 1066 ; 1067Note how we use the ""pt"" column as usual in the Filter() and Define() calls and we simply use ""x"" as the value to fill; 1068the resulting histogram. To produce the varied results, RDataFrame will automatically execute the Filter and Define; 1069calls for each variation and fill the histogram with values and cuts that depend on the variation.; 1070 ; 1071There is no limitation to the complexity of a Vary() expression. Just like for the Define() and Filter() calls, users are; 1072not limited to string expressions but they can also pass any valid C++ callable, including lambda functions and; 1073complex functors. The callable can be applied to zero or more existing columns and it will always receive their; 1074_nominal_ value in input.; 1075 ; 1076#### Varying multiple columns in lockstep; 1077 ; 1078In the following Python snippet we use the Vary() signature that allows varying multiple columns simultaneously or; 1079""in lockstep"":; 1080 ; 1081~~~{.python}; 1082df.Vary([""pt"", ""eta""],; 1083 ""RVec<RVecF>{{pt*0.9, pt*1.1}, {eta*0.9, eta*1.1}}"",; 1084 variationTags=[""down"", ""up""],; 1085 variationName=""ptAndEta""); 1086~~~; 1087 ; 1088The expression returns an RVec of two RVecs: each inner vector contains the varied values for one col",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:63785,Integrability,depend,depends,63785," and it will always receive their; 1074_nominal_ value in input.; 1075 ; 1076#### Varying multiple columns in lockstep; 1077 ; 1078In the following Python snippet we use the Vary() signature that allows varying multiple columns simultaneously or; 1079""in lockstep"":; 1080 ; 1081~~~{.python}; 1082df.Vary([""pt"", ""eta""],; 1083 ""RVec<RVecF>{{pt*0.9, pt*1.1}, {eta*0.9, eta*1.1}}"",; 1084 variationTags=[""down"", ""up""],; 1085 variationName=""ptAndEta""); 1086~~~; 1087 ; 1088The expression returns an RVec of two RVecs: each inner vector contains the varied values for one column. The; 1089inner vectors follow the same ordering as the column names that are passed as the first argument. Besides the variation tags, in; 1090this case we also have to explicitly pass the variation name (here: ""ptAndEta"") as the default column name does not exist.; 1091 ; 1092The above call will produce variations ""ptAndEta:down"" and ""ptAndEta:up"".; 1093 ; 1094#### Combining multiple variations; 1095 ; 1096Even if a result depends on multiple variations, only one variation is applied at a time, i.e. there will be no result produced; 1097by applying multiple systematic variations at the same time.; 1098For example, in the following example snippet, the RResultMap instance `all_h` will contain keys ""nominal"", ""pt:down"",; 1099""pt:up"", ""eta:0"", ""eta:1"", but no ""pt:up&&eta:0"" or similar:; 1100 ; 1101~~~{.cpp}; 1102auto df = _df.Vary(""pt"",; 1103 ""ROOT::RVecD{pt*0.9, pt*1.1}"",; 1104 {""down"", ""up""}); 1105 .Vary(""eta"",; 1106 [](float eta) { return RVecF{eta*0.9f, eta*1.1f}; },; 1107 {""eta""},; 1108 2);; 1109 ; 1110auto nom_h = df.Histo2D(histoModel, ""pt"", ""eta"");; 1111auto all_hs = VariationsFor(nom_h);; 1112all_hs.GetKeys(); // returns {""nominal"", ""pt:down"", ""pt:up"", ""eta:0"", ""eta:1""}; 1113~~~; 1114 ; 1115Note how we passed the integer `2` instead of a list of variation tags to the second Vary() invocation: this is a; 1116shorthand that automatically generates tags 0 to N-1 (in this case 0 and 1).; 1117 ; 1118\n",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:64907,Integrability,interface,interfaces,64907,"ill be no result produced; 1097by applying multiple systematic variations at the same time.; 1098For example, in the following example snippet, the RResultMap instance `all_h` will contain keys ""nominal"", ""pt:down"",; 1099""pt:up"", ""eta:0"", ""eta:1"", but no ""pt:up&&eta:0"" or similar:; 1100 ; 1101~~~{.cpp}; 1102auto df = _df.Vary(""pt"",; 1103 ""ROOT::RVecD{pt*0.9, pt*1.1}"",; 1104 {""down"", ""up""}); 1105 .Vary(""eta"",; 1106 [](float eta) { return RVecF{eta*0.9f, eta*1.1f}; },; 1107 {""eta""},; 1108 2);; 1109 ; 1110auto nom_h = df.Histo2D(histoModel, ""pt"", ""eta"");; 1111auto all_hs = VariationsFor(nom_h);; 1112all_hs.GetKeys(); // returns {""nominal"", ""pt:down"", ""pt:up"", ""eta:0"", ""eta:1""}; 1113~~~; 1114 ; 1115Note how we passed the integer `2` instead of a list of variation tags to the second Vary() invocation: this is a; 1116shorthand that automatically generates tags 0 to N-1 (in this case 0 and 1).; 1117 ; 1118\note Currently, VariationsFor() and RResultMap are in the `ROOT::RDF::Experimental` namespace, to indicate that these; 1119 interfaces might still evolve and improve based on user feedback. We expect that some aspects of the related; 1120 programming model will be streamlined in future versions.; 1121 ; 1122\note Currently, the results of a Snapshot(), Report() or Display() call cannot be varied (i.e. it is not possible to; 1123 call \ref ROOT::RDF::Experimental::VariationsFor ""VariationsFor()"" on them. These limitations will be lifted in future releases.; 1124 ; 1125See the Vary() method for more information and [this tutorial](https://root.cern/doc/master/df106__HiggsToFourLeptons_8C.html) ; 1126for an example usage of Vary and \ref ROOT::RDF::Experimental::VariationsFor ""VariationsFor()"" in the analysis.; 1127 ; 1128\anchor rnode; 1129### RDataFrame objects as function arguments and return values; 1130RDataFrame variables/nodes are relatively cheap to copy and it's possible to both pass them to (or move them into); 1131functions and to return them from functions. Howev",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:71524,Integrability,message,message,71524,"4340705d2c4db7f8).; 1217 ; 1218\warning Note that in multi-thread event loops the values of `rdfentry_` _do not_ correspond to what would be the entry numbers; 1219of a TChain constructed over the same set of ROOT files, as the entries are processed in an unspecified order.; 1220 ; 1221\anchor jitting; 1222### Just-in-time compilation: column type inference and explicit declaration of column types; 1223C++ is a statically typed language: all types must be known at compile-time. This includes the types of the TTree; 1224branches we want to work on. For filters, defined columns and some of the actions, **column types are deduced from the; 1225signature** of the relevant filter function/temporary column expression/action function:; 1226~~~{.cpp}; 1227// here b1 is deduced to be `int` and b2 to be `double`; 1228df.Filter([](int x, double y) { return x > 0 && y < 0.; }, {""b1"", ""b2""});; 1229~~~; 1230If we specify an incorrect type for one of the columns, an exception with an informative message will be thrown at; 1231runtime, when the column value is actually read from the dataset: RDataFrame detects type mismatches. The same would; 1232happen if we swapped the order of ""b1"" and ""b2"" in the column list passed to Filter().; 1233 ; 1234Certain actions, on the other hand, do not take a function as argument (e.g. Histo1D()), so we cannot deduce the type of; 1235the column at compile-time. In this case **RDataFrame infers the type of the column** from the TTree itself. This; 1236is why we never needed to specify the column types for all actions in the above snippets.; 1237 ; 1238When the column type is not a common one such as `int`, `double`, `char` or `float` it is nonetheless good practice to; 1239specify it as a template parameter to the action itself, like this:; 1240~~~{.cpp}; 1241df.Histo1D(""b1""); // OK, the type of ""b1"" is deduced at runtime; 1242df.Min<MyNumber_t>(""myObject""); // OK, ""myObject"" is deduced to be of type `MyNumber_t`; 1243~~~; 1244 ; 1245Deducing types a",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:73305,Integrability,inject,inject,73305,"~~{.cpp}; 1241df.Histo1D(""b1""); // OK, the type of ""b1"" is deduced at runtime; 1242df.Min<MyNumber_t>(""myObject""); // OK, ""myObject"" is deduced to be of type `MyNumber_t`; 1243~~~; 1244 ; 1245Deducing types at runtime requires the just-in-time compilation of the relevant actions, which has a small runtime; 1246overhead, so specifying the type of the columns as template parameters to the action is good practice when performance is a goal.; 1247 ; 1248When strings are passed as expressions to Filter() or Define(), fundamental types are passed as constants. This avoids certaincommon mistakes such as typing `x = 0` rather than `x == 0`:; 1249 ; 1250~~~{.cpp}; 1251// this throws an error (note the typo); 1252df.Define(""x"", ""0"").Filter(""x = 0"");; 1253~~~; 1254 ; 1255\anchor generic-actions; 1256### User-defined custom actions; 1257RDataFrame strives to offer a comprehensive set of standard actions that can be performed on each event. At the same; 1258time, it allows users to inject their own action code to perform arbitrarily complex data reductions.; 1259 ; 1260#### Implementing custom actions with Book(); 1261 ; 1262Through the Book() method, users can implement a custom action and have access to the same features; 1263that built-in RDataFrame actions have, e.g. hooks to events related to the start, end and execution of the; 1264event loop, or the possibility to return a lazy RResultPtr to an arbitrary type of result:; 1265 ; 1266~~~{.cpp}; 1267#include <ROOT/RDataFrame.hxx>; 1268#include <memory>; 1269 ; 1270class MyCounter : public ROOT::Detail::RDF::RActionImpl<MyCounter> {; 1271 std::shared_ptr<int> fFinalResult = std::make_shared<int>(0);; 1272 std::vector<int> fPerThreadResults;; 1273 ; 1274public:; 1275 // We use a public type alias to advertise the type of the result of this action; 1276 using Result_t = int;; 1277 ; 1278 MyCounter(unsigned int nSlots) : fPerThreadResults(nSlots) {}; 1279 ; 1280 // Called before the event loop to retrieve the address of the resul",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:75936,Integrability,interface,interface,75936,"adResults.end(), 0);; 1299 }; 1300 ; 1301 // Called by RDataFrame to retrieve the name of this action.; 1302 std::string GetActionName() const { return ""MyCounter""; }; 1303};; 1304 ; 1305int main() {; 1306 ROOT::RDataFrame df(10);; 1307 ROOT::RDF::RResultPtr<int> resultPtr = df.Book<>(MyCounter{df.GetNSlots()}, {});; 1308 // The GetValue call triggers the event loop; 1309 std::cout << ""Number of processed entries: "" << resultPtr.GetValue() << std::endl;; 1310}; 1311~~~; 1312 ; 1313See the Book() method for more information and [this tutorial](https://root.cern/doc/master/df018__customActions_8C.html); 1314for a more complete example.; 1315 ; 1316#### Injecting arbitrary code in the event loop with Foreach() and ForeachSlot(); 1317 ; 1318Foreach() takes a callable (lambda expression, free function, functor...) and a list of columns and; 1319executes the callable on the values of those columns for each event that passes all upstream selections.; 1320It can be used to perform actions that are not already available in the interface. For example, the following snippet; 1321evaluates the root mean square of column ""x"":; 1322~~~{.cpp}; 1323// Single-thread evaluation of RMS of column ""x"" using Foreach; 1324double sumSq = 0.;; 1325unsigned int n = 0;; 1326df.Foreach([&sumSq, &n](double x) { ++n; sumSq += x*x; }, {""x""});; 1327std::cout << ""rms of x: "" << std::sqrt(sumSq / n) << std::endl;; 1328~~~; 1329In multi-thread runs, users are responsible for the thread-safety of the expression passed to Foreach():; 1330thread will execute the expression concurrently.; 1331The code above would need to employ some resource protection mechanism to ensure non-concurrent writing of `rms`; but; 1332this is probably too much head-scratch for such a simple operation.; 1333 ; 1334ForeachSlot() can help in this situation. It is an alternative version of Foreach() for which the function takes an; 1335additional ""processing slot"" parameter besides the columns it should be applied to. RDataFrame;",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:80752,Integrability,interface,interfaced,80752,"used as friends of the original; 1384 one: rows will be mismatched.; 1385 ; 1386Indexed friend trees provide a way to perform simple joins of multiple trees over a common column.; 1387When a certain entry in the main tree (or chain) is loaded, the friend trees (or chains) will then load an entry where the; 1388""index"" columns have a value identical to the one in the main one. For example, in Python:; 1389 ; 1390~~~{.py}; 1391main_tree = ...; 1392aux_tree = ...; 1393 ; 1394# If a friend tree has an index on `commonColumn`, when the main tree loads; 1395# a given row, it also loads the row of the friend tree that has the same; 1396# value of `commonColumn`; 1397aux_tree.BuildIndex(""commonColumn""); 1398 ; 1399mainTree.AddFriend(aux_tree); 1400 ; 1401df = ROOT.RDataFrame(mainTree); 1402~~~; 1403 ; 1404RDataFrame supports indexed friend TTrees from ROOT v6.24 in single-thread mode and from v6.28/02 in multi-thread mode.; 1405 ; 1406\anchor other-file-formats; 1407### Reading data formats other than ROOT trees; 1408RDataFrame can be interfaced with RDataSources. The ROOT::RDF::RDataSource interface defines an API that RDataFrame can use to read arbitrary columnar data formats.; 1409 ; 1410RDataFrame calls into concrete RDataSource implementations to retrieve information about the data, retrieve (thread-local) readers or ""cursors"" for selected columns; 1411and to advance the readers to the desired data entry.; 1412Some predefined RDataSources are natively provided by ROOT such as the ROOT::RDF::RCsvDS which allows to read comma separated files:; 1413~~~{.cpp}; 1414auto tdf = ROOT::RDF::FromCSV(""MuRun2010B.csv"");; 1415auto filteredEvents =; 1416 tdf.Filter(""Q1 * Q2 == -1""); 1417 .Define(""m"", ""sqrt(pow(E1 + E2, 2) - (pow(px1 + px2, 2) + pow(py1 + py2, 2) + pow(pz1 + pz2, 2)))"");; 1418auto h = filteredEvents.Histo1D(""m"");; 1419h->Draw();; 1420~~~; 1421 ; 1422See also FromNumpy (Python-only), FromRNTuple(), FromArrow(), FromSqlite().; 1423 ; 1424\anchor callgraphs; 1425### Com",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:80809,Integrability,interface,interface,80809,"le joins of multiple trees over a common column.; 1387When a certain entry in the main tree (or chain) is loaded, the friend trees (or chains) will then load an entry where the; 1388""index"" columns have a value identical to the one in the main one. For example, in Python:; 1389 ; 1390~~~{.py}; 1391main_tree = ...; 1392aux_tree = ...; 1393 ; 1394# If a friend tree has an index on `commonColumn`, when the main tree loads; 1395# a given row, it also loads the row of the friend tree that has the same; 1396# value of `commonColumn`; 1397aux_tree.BuildIndex(""commonColumn""); 1398 ; 1399mainTree.AddFriend(aux_tree); 1400 ; 1401df = ROOT.RDataFrame(mainTree); 1402~~~; 1403 ; 1404RDataFrame supports indexed friend TTrees from ROOT v6.24 in single-thread mode and from v6.28/02 in multi-thread mode.; 1405 ; 1406\anchor other-file-formats; 1407### Reading data formats other than ROOT trees; 1408RDataFrame can be interfaced with RDataSources. The ROOT::RDF::RDataSource interface defines an API that RDataFrame can use to read arbitrary columnar data formats.; 1409 ; 1410RDataFrame calls into concrete RDataSource implementations to retrieve information about the data, retrieve (thread-local) readers or ""cursors"" for selected columns; 1411and to advance the readers to the desired data entry.; 1412Some predefined RDataSources are natively provided by ROOT such as the ROOT::RDF::RCsvDS which allows to read comma separated files:; 1413~~~{.cpp}; 1414auto tdf = ROOT::RDF::FromCSV(""MuRun2010B.csv"");; 1415auto filteredEvents =; 1416 tdf.Filter(""Q1 * Q2 == -1""); 1417 .Define(""m"", ""sqrt(pow(E1 + E2, 2) - (pow(px1 + px2, 2) + pow(py1 + py2, 2) + pow(pz1 + pz2, 2)))"");; 1418auto h = filteredEvents.Histo1D(""m"");; 1419h->Draw();; 1420~~~; 1421 ; 1422See also FromNumpy (Python-only), FromRNTuple(), FromArrow(), FromSqlite().; 1423 ; 1424\anchor callgraphs; 1425### Computation graphs (storing and reusing sets of transformations); 1426 ; 1427As we saw, transformed dataframes can be stored as variab",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:110498,Integrability,interface,interface,110498,"DatasetSpec::REntryRange &entryRange={})Create an RDatasetSpec object for a given range of entries.Definition RDatasetSpec.cxx:216; ROOT::RDF::Experimental::RMetaDataClass behaving as a heterogenuous dictionary to store the metadata of a dataset.Definition RMetaData.hxx:50; ROOT::RDF::Experimental::RSampleClass representing a sample which is a grouping of trees and their fileglobs, and,...Definition RSample.hxx:39; ROOT::RDF::RInterfaceBase::fLoopManagerstd::shared_ptr< ROOT::Detail::RDF::RLoopManager > fLoopManager< The RLoopManager at the root of this computation graph. Never null.Definition RInterfaceBase.hxx:55; ROOT::RDF::RInterfaceBase::fDataSourceRDataSource * fDataSourceNon-owning pointer to a data-source object. Null if no data-source. RLoopManager has ownership of the...Definition RInterfaceBase.hxx:57; ROOT::RDF::RInterfaceBase::GetLoopManagerRDFDetail::RLoopManager * GetLoopManager() constDefinition RInterfaceBase.hxx:128; ROOT::RDataFrameROOT's RDataFrame offers a modern, high-level interface for analysis of data stored in TTree ,...Definition RDataFrame.hxx:41; ROOT::RDataFrame::RDataFrameRDataFrame(std::string_view treeName, std::string_view filenameglob, const ColumnNames_t &defaultColumns={})Build the dataframe.Definition RDataFrame.cxx:1768; ROOT::RDataFrame::ColumnNames_tROOT::RDF::ColumnNames_t ColumnNames_tDefinition RDataFrame.hxx:43; ROOT::RDataFrame::~RDataFrame~RDataFrame()Definition RDataFrame.cxx:1862; TDirectoryDescribe directory structure in memory.Definition TDirectory.h:45; TDirectory::Getvirtual TObject * Get(const char *namecycle)Return pointer to object identified by namecycle.Definition TDirectory.cxx:866; TTreeA TTree represents a columnar dataset.Definition TTree.h:79; ROOT::Detail::RDFDefinition RooAbsDataHelper.h:80; ROOT::RDF::Experimental::FromSpecROOT::RDataFrame FromSpec(const std::string &jsonFile)Factory method to create an RDataFrame from a JSON specification file.Definition RDataFrame.cxx:1906; ROOT::RDF::ColumnNames_ts",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:13639,Modifiability,flexible,flexible,13639,") | Return the number of event loops run by this RDataFrame instance so far. |; 168| GetNSlots() | Return the number of processing slots that RDataFrame will use during the event loop (i.e. the concurrency level). |; 169| SaveGraph() | Store the computation graph of an RDataFrame in [DOT format (graphviz)](https://en.wikipedia.org/wiki/DOT_(graph_description_language)) for easy inspection. See the [relevant section](\ref representgraph) for details. |; 170 ; 171\anchor introduction; 172## Introduction; 173Users define their analysis as a sequence of operations to be performed on the dataframe object; the framework; 174takes care of the management of the loop over entries as well as low-level details such as I/O and parallelization.; 175RDataFrame provides methods to perform most common operations required by ROOT analyses;; 176at the same time, users can just as easily specify custom code that will be executed in the event loop.; 177 ; 178RDataFrame is built with a *modular* and *flexible* workflow in mind, summarised as follows:; 179 ; 1801. Construct a dataframe object by specifying a dataset. RDataFrame supports TTree as well as TChain, [CSV files](https://root.cern/doc/master/df014__CSVDataSource_8C.html), [SQLite files](https://root.cern/doc/master/df027__SQliteDependencyOverVersion_8C.html), [RNTuples](https://root.cern/doc/master/structROOT_1_1Experimental_1_1RNTuple.html), and it can be extended to custom data formats. From Python, [NumPy arrays can be imported into RDataFrame](https://root.cern/doc/master/df032__MakeNumpyDataFrame_8py.html) as well.; 181 ; 1822. Transform the dataframe by:; 183 ; 184 - [Applying filters](https://root.cern/doc/master/classROOT_1_1RDataFrame.html#transformations). This selects only specific rows of the dataset.; 185 ; 186 - [Creating custom columns](https://root.cern/doc/master/classROOT_1_1RDataFrame.html#transformations). Custom columns can, for example, contain the results of a computation that must be performed for every ",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:14062,Modifiability,extend,extended,14062,"f representgraph) for details. |; 170 ; 171\anchor introduction; 172## Introduction; 173Users define their analysis as a sequence of operations to be performed on the dataframe object; the framework; 174takes care of the management of the loop over entries as well as low-level details such as I/O and parallelization.; 175RDataFrame provides methods to perform most common operations required by ROOT analyses;; 176at the same time, users can just as easily specify custom code that will be executed in the event loop.; 177 ; 178RDataFrame is built with a *modular* and *flexible* workflow in mind, summarised as follows:; 179 ; 1801. Construct a dataframe object by specifying a dataset. RDataFrame supports TTree as well as TChain, [CSV files](https://root.cern/doc/master/df014__CSVDataSource_8C.html), [SQLite files](https://root.cern/doc/master/df027__SQliteDependencyOverVersion_8C.html), [RNTuples](https://root.cern/doc/master/structROOT_1_1Experimental_1_1RNTuple.html), and it can be extended to custom data formats. From Python, [NumPy arrays can be imported into RDataFrame](https://root.cern/doc/master/df032__MakeNumpyDataFrame_8py.html) as well.; 181 ; 1822. Transform the dataframe by:; 183 ; 184 - [Applying filters](https://root.cern/doc/master/classROOT_1_1RDataFrame.html#transformations). This selects only specific rows of the dataset.; 185 ; 186 - [Creating custom columns](https://root.cern/doc/master/classROOT_1_1RDataFrame.html#transformations). Custom columns can, for example, contain the results of a computation that must be performed for every row of the dataset.; 187 ; 1883. [Produce results](https://root.cern/doc/master/classROOT_1_1RDataFrame.html#actions). *Actions* are used to aggregate data into results. Most actions are *lazy*, i.e. they are not executed on the spot, but registered with RDataFrame and executed only when a result is accessed for the first time.; 189 ; 190Make sure to book all transformations and actions before you access the contents of ",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:15395,Modifiability,flexible,flexible,15395,"s selects only specific rows of the dataset.; 185 ; 186 - [Creating custom columns](https://root.cern/doc/master/classROOT_1_1RDataFrame.html#transformations). Custom columns can, for example, contain the results of a computation that must be performed for every row of the dataset.; 187 ; 1883. [Produce results](https://root.cern/doc/master/classROOT_1_1RDataFrame.html#actions). *Actions* are used to aggregate data into results. Most actions are *lazy*, i.e. they are not executed on the spot, but registered with RDataFrame and executed only when a result is accessed for the first time.; 189 ; 190Make sure to book all transformations and actions before you access the contents of any of the results. This lets RDataFrame accumulate work and then produce all results at the same time, upon first access to any of them.; 191 ; 192The following table shows how analyses based on TTreeReader and TTree::Draw() translate to RDataFrame. Follow the; 193[crash course](#crash-course) to discover more idiomatic and flexible ways to express analyses with RDataFrame.; 194<table>; 195<tr>; 196 <td>; 197 <b>TTreeReader</b>; 198 </td>; 199 <td>; 200 <b>ROOT::RDataFrame</b>; 201 </td>; 202</tr>; 203<tr>; 204 <td>; 205~~~{.cpp}; 206TTreeReader reader(""myTree"", file);; 207TTreeReaderValue<A_t> a(reader, ""A"");; 208TTreeReaderValue<B_t> b(reader, ""B"");; 209TTreeReaderValue<C_t> c(reader, ""C"");; 210while(reader.Next()) {; 211 if(IsGoodEvent(*a, *b, *c)); 212 DoStuff(*a, *b, *c);; 213}; 214~~~; 215 </td>; 216 <td>; 217~~~{.cpp}; 218ROOT::RDataFrame d(""myTree"", file, {""A"", ""B"", ""C""});; 219d.Filter(IsGoodEvent).Foreach(DoStuff);; 220~~~; 221 </td>; 222</tr>; 223<tr>; 224 <td>; 225 <b>TTree::Draw</b>; 226 </td>; 227 <td>; 228 <b>ROOT::RDataFrame</b>; 229 </td>; 230</tr>; 231<tr>; 232 <td>; 233~~~{.cpp}; 234auto *tree = file->Get<TTree>(""myTree"");; 235tree->Draw(""x"", ""y > 2"");; 236~~~; 237 </td>; 238 <td>; 239~~~{.cpp}; 240ROOT::RDataFrame df(""myTree"", file);; 241auto h = df.Filter(""y > 2"").Histo1D(",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:22948,Modifiability,variab,variables,22948,"4.; }; // a C++11 lambda function checking ""x > 4""; 362auto c = d.Filter(metCut, {""MET""}).Count();; 363std::cout << *c << std::endl;; 364~~~; 365 ; 366An example of a more complex filter expressed as a string containing C++ code is shown below; 367 ; 368~~~{.cpp}; 369RDataFrame d(""myTree"", ""file.root"");; 370auto df = d.Define(""p"", ""std::array<double, 4> p{px, py, pz}; return p;""); 371 .Filter(""double p2 = 0.0; for (auto&& x : p) p2 += x*x; return sqrt(p2) < 10.0;"");; 372~~~; 373 ; 374The code snippet above defines a column `p` that is a fixed-size array using the component column names and then; 375filters on its magnitude by looping over its elements. It must be noted that the usage of strings to define columns; 376like the one above is currently the only possibility when using PyROOT. When writing expressions as such, only constants; 377and data coming from other columns in the dataset can be involved in the code passed as a string. Local variables and; 378functions cannot be used, since the interpreter will not know how to find them. When capturing local state is necessary,; 379it must first be declared to the ROOT C++ interpreter.; 380 ; 381More information on filters and how to use them to automatically generate cutflow reports can be found [below](#Filters).; 382 ; 383### Defining custom columns; 384Let's now consider the case in which ""myTree"" contains two quantities ""x"" and ""y"", but our analysis relies on a derived; 385quantity `z = sqrt(x*x + y*y)`. Using the Define() transformation, we can create a new column in the dataset containing; 386the variable ""z"":; 387~~~{.cpp}; 388RDataFrame d(""myTree"", ""file.root"");; 389auto sqrtSum = [](double x, double y) { return sqrt(x*x + y*y); };; 390auto zMean = d.Define(""z"", sqrtSum, {""x"",""y""}).Mean(""z"");; 391std::cout << *zMean << std::endl;; 392~~~; 393Define() creates the variable ""z"" by applying `sqrtSum` to ""x"" and ""y"". Later in the chain of calls we refer to; 394variables created with Define() as if they were actua",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:23572,Modifiability,variab,variable,23572," fixed-size array using the component column names and then; 375filters on its magnitude by looping over its elements. It must be noted that the usage of strings to define columns; 376like the one above is currently the only possibility when using PyROOT. When writing expressions as such, only constants; 377and data coming from other columns in the dataset can be involved in the code passed as a string. Local variables and; 378functions cannot be used, since the interpreter will not know how to find them. When capturing local state is necessary,; 379it must first be declared to the ROOT C++ interpreter.; 380 ; 381More information on filters and how to use them to automatically generate cutflow reports can be found [below](#Filters).; 382 ; 383### Defining custom columns; 384Let's now consider the case in which ""myTree"" contains two quantities ""x"" and ""y"", but our analysis relies on a derived; 385quantity `z = sqrt(x*x + y*y)`. Using the Define() transformation, we can create a new column in the dataset containing; 386the variable ""z"":; 387~~~{.cpp}; 388RDataFrame d(""myTree"", ""file.root"");; 389auto sqrtSum = [](double x, double y) { return sqrt(x*x + y*y); };; 390auto zMean = d.Define(""z"", sqrtSum, {""x"",""y""}).Mean(""z"");; 391std::cout << *zMean << std::endl;; 392~~~; 393Define() creates the variable ""z"" by applying `sqrtSum` to ""x"" and ""y"". Later in the chain of calls we refer to; 394variables created with Define() as if they were actual tree branches/columns, but they are evaluated on demand, at most; 395once per event. As with filters, Define() calls can be chained with other transformations to create multiple custom; 396columns. Define() and Filter() transformations can be concatenated and intermixed at will.; 397 ; 398As with filters, it is possible to specify new columns as string expressions. This snippet is analogous to the one above:; 399~~~{.cpp}; 400RDataFrame d(""myTree"", ""file.root"");; 401auto zMean = d.Define(""z"", ""sqrt(x*x + y*y)"").Mean(""z"");; 402std::cou",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:23845,Modifiability,variab,variable,23845," constants; 377and data coming from other columns in the dataset can be involved in the code passed as a string. Local variables and; 378functions cannot be used, since the interpreter will not know how to find them. When capturing local state is necessary,; 379it must first be declared to the ROOT C++ interpreter.; 380 ; 381More information on filters and how to use them to automatically generate cutflow reports can be found [below](#Filters).; 382 ; 383### Defining custom columns; 384Let's now consider the case in which ""myTree"" contains two quantities ""x"" and ""y"", but our analysis relies on a derived; 385quantity `z = sqrt(x*x + y*y)`. Using the Define() transformation, we can create a new column in the dataset containing; 386the variable ""z"":; 387~~~{.cpp}; 388RDataFrame d(""myTree"", ""file.root"");; 389auto sqrtSum = [](double x, double y) { return sqrt(x*x + y*y); };; 390auto zMean = d.Define(""z"", sqrtSum, {""x"",""y""}).Mean(""z"");; 391std::cout << *zMean << std::endl;; 392~~~; 393Define() creates the variable ""z"" by applying `sqrtSum` to ""x"" and ""y"". Later in the chain of calls we refer to; 394variables created with Define() as if they were actual tree branches/columns, but they are evaluated on demand, at most; 395once per event. As with filters, Define() calls can be chained with other transformations to create multiple custom; 396columns. Define() and Filter() transformations can be concatenated and intermixed at will.; 397 ; 398As with filters, it is possible to specify new columns as string expressions. This snippet is analogous to the one above:; 399~~~{.cpp}; 400RDataFrame d(""myTree"", ""file.root"");; 401auto zMean = d.Define(""z"", ""sqrt(x*x + y*y)"").Mean(""z"");; 402std::cout << *zMean << std::endl;; 403~~~; 404 ; 405Again the names of the columns used in the expression and their types are inferred automatically. The string must be; 406valid C++ and it is just-in-time compiled. The process has a small runtime overhead and like with filters it is currently the onl",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:25667,Modifiability,variab,variables,25667,"t be; 406valid C++ and it is just-in-time compiled. The process has a small runtime overhead and like with filters it is currently the only possible approach when using PyROOT.; 407 ; 408Previously, when showing the different ways an RDataFrame can be created, we showed a constructor that takes a; 409number of entries as a parameter. In the following example we show how to combine such an ""empty"" RDataFrame with Define(); 410transformations to create a dataset on the fly. We then save the generated data on disk using the Snapshot() action.; 411~~~{.cpp}; 412RDataFrame d(100); // an RDF that will generate 100 entries (currently empty); 413int x = -1;; 414auto d_with_columns = d.Define(""x"", [&x] { return ++x; }); 415 .Define(""xx"", [&x] { return x*x; });; 416d_with_columns.Snapshot(""myNewTree"", ""newfile.root"");; 417~~~; 418This example is slightly more advanced than what we have seen so far. First, it makes use of lambda captures (a; 419simple way to make external variables available inside the body of C++ lambdas) to act on the same variable `x` from; 420both Define() transformations. Second, we have *stored* the transformed dataframe in a variable. This is always; 421possible, since at each point of the transformation chain users can store the status of the dataframe for further use (more; 422on this [below](#callgraphs)).; 423 ; 424You can read more about defining new columns [here](#custom-columns).; 425 ; 426\image html RDF_Graph.png ""A graph composed of two branches, one starting with a filter and one with a define. The end point of a branch is always an action.""; 427 ; 428 ; 429### Running on a range of entries; 430It is sometimes necessary to limit the processing of the dataset to a range of entries. For this reason, the RDataFrame; 431offers the concept of ranges as a node of the RDataFrame chain of transformations; this means that filters, columns and; 432actions can be concatenated to and intermixed with Range()s. If a range is specified after a filter, the ",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:25738,Modifiability,variab,variable,25738,"t be; 406valid C++ and it is just-in-time compiled. The process has a small runtime overhead and like with filters it is currently the only possible approach when using PyROOT.; 407 ; 408Previously, when showing the different ways an RDataFrame can be created, we showed a constructor that takes a; 409number of entries as a parameter. In the following example we show how to combine such an ""empty"" RDataFrame with Define(); 410transformations to create a dataset on the fly. We then save the generated data on disk using the Snapshot() action.; 411~~~{.cpp}; 412RDataFrame d(100); // an RDF that will generate 100 entries (currently empty); 413int x = -1;; 414auto d_with_columns = d.Define(""x"", [&x] { return ++x; }); 415 .Define(""xx"", [&x] { return x*x; });; 416d_with_columns.Snapshot(""myNewTree"", ""newfile.root"");; 417~~~; 418This example is slightly more advanced than what we have seen so far. First, it makes use of lambda captures (a; 419simple way to make external variables available inside the body of C++ lambdas) to act on the same variable `x` from; 420both Define() transformations. Second, we have *stored* the transformed dataframe in a variable. This is always; 421possible, since at each point of the transformation chain users can store the status of the dataframe for further use (more; 422on this [below](#callgraphs)).; 423 ; 424You can read more about defining new columns [here](#custom-columns).; 425 ; 426\image html RDF_Graph.png ""A graph composed of two branches, one starting with a filter and one with a define. The end point of a branch is always an action.""; 427 ; 428 ; 429### Running on a range of entries; 430It is sometimes necessary to limit the processing of the dataset to a range of entries. For this reason, the RDataFrame; 431offers the concept of ranges as a node of the RDataFrame chain of transformations; this means that filters, columns and; 432actions can be concatenated to and intermixed with Range()s. If a range is specified after a filter, the ",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:25847,Modifiability,variab,variable,25847,"he only possible approach when using PyROOT.; 407 ; 408Previously, when showing the different ways an RDataFrame can be created, we showed a constructor that takes a; 409number of entries as a parameter. In the following example we show how to combine such an ""empty"" RDataFrame with Define(); 410transformations to create a dataset on the fly. We then save the generated data on disk using the Snapshot() action.; 411~~~{.cpp}; 412RDataFrame d(100); // an RDF that will generate 100 entries (currently empty); 413int x = -1;; 414auto d_with_columns = d.Define(""x"", [&x] { return ++x; }); 415 .Define(""xx"", [&x] { return x*x; });; 416d_with_columns.Snapshot(""myNewTree"", ""newfile.root"");; 417~~~; 418This example is slightly more advanced than what we have seen so far. First, it makes use of lambda captures (a; 419simple way to make external variables available inside the body of C++ lambdas) to act on the same variable `x` from; 420both Define() transformations. Second, we have *stored* the transformed dataframe in a variable. This is always; 421possible, since at each point of the transformation chain users can store the status of the dataframe for further use (more; 422on this [below](#callgraphs)).; 423 ; 424You can read more about defining new columns [here](#custom-columns).; 425 ; 426\image html RDF_Graph.png ""A graph composed of two branches, one starting with a filter and one with a define. The end point of a branch is always an action.""; 427 ; 428 ; 429### Running on a range of entries; 430It is sometimes necessary to limit the processing of the dataset to a range of entries. For this reason, the RDataFrame; 431offers the concept of ranges as a node of the RDataFrame chain of transformations; this means that filters, columns and; 432actions can be concatenated to and intermixed with Range()s. If a range is specified after a filter, the range will act; 433exclusively on the entries passing the filter -- it will not even count the other entries! The same goes for a Ra",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:27032,Modifiability,variab,variable,27032,"422on this [below](#callgraphs)).; 423 ; 424You can read more about defining new columns [here](#custom-columns).; 425 ; 426\image html RDF_Graph.png ""A graph composed of two branches, one starting with a filter and one with a define. The end point of a branch is always an action.""; 427 ; 428 ; 429### Running on a range of entries; 430It is sometimes necessary to limit the processing of the dataset to a range of entries. For this reason, the RDataFrame; 431offers the concept of ranges as a node of the RDataFrame chain of transformations; this means that filters, columns and; 432actions can be concatenated to and intermixed with Range()s. If a range is specified after a filter, the range will act; 433exclusively on the entries passing the filter -- it will not even count the other entries! The same goes for a Range(); 434hanging from another Range(). Here are some commented examples:; 435~~~{.cpp}; 436RDataFrame d(""myTree"", ""file.root"");; 437// Here we store a dataframe that loops over only the first 30 entries in a variable; 438auto d30 = d.Range(30);; 439// This is how you pick all entries from 15 onwards; 440auto d15on = d.Range(15, 0);; 441// We can specify a stride too, in this case we pick an event every 3; 442auto d15each3 = d.Range(0, 15, 3);; 443~~~; 444Note that ranges are not available when multi-threading is enabled. More information on ranges is available; 445[here](#ranges).; 446 ; 447### Executing multiple actions in the same event loop; 448As a final example let us apply two different cuts on branch ""MET"" and fill two different histograms with the ""pt_v"" of; 449the filtered events.; 450By now, you should be able to easily understand what is happening:; 451~~~{.cpp}; 452RDataFrame d(""treeName"", ""file.root"");; 453auto h1 = d.Filter(""MET > 10"").Histo1D(""pt_v"");; 454auto h2 = d.Histo1D(""pt_v"");; 455h1->Draw(); // event loop is run once here; 456h2->Draw(""SAME""); // no need to run the event loop again; 457~~~; 458RDataFrame executes all above actions by **",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:30482,Modifiability,variab,variable,30482,"497~~~; 498 ; 499It is therefore good practice to declare all your transformations and actions *before* accessing their results, allowing; 500RDataFrame to run the loop once and produce all results in one go.; 501 ; 502### Going parallel; 503Let's say we would like to run the previous examples in parallel on several cores, dividing events fairly between cores.; 504The only modification required to the snippets would be the addition of this line *before* constructing the main; 505dataframe object:; 506~~~{.cpp}; 507ROOT::EnableImplicitMT();; 508~~~; 509Simple as that. More details are given [below](#parallel-execution).; 510 ; 511\anchor collections; 512## Working with collections and object selections; 513 ; 514RDataFrame reads collections as the special type [ROOT::RVec](https://root.cern/doc/master/classROOT_1_1VecOps_1_1RVec.html): for example, a column containing an array of floating point numbers can be read as a ROOT::RVecF. C-style arrays (with variable or static size), STL vectors and most other collection types can be read this way.; 515 ; 516RVec is a container similar to std::vector (and can be used just like a std::vector) but it also offers a rich interface to operate on the array elements in a vectorised fashion, similarly to Python's NumPy arrays.; 517 ; 518For example, to fill a histogram with the ""pt"" of selected particles for each event, Define() can be used to create a column that contains the desired array elements as follows:; 519 ; 520~~~{.cpp}; 521// h is filled with all the elements of `good_pts`, for each event; 522auto h = df.Define(""good_pts"", [](const ROOT::RVecF &pt) { return pt[pt > 0]; }); 523 .Histo1D(""good_pts"");; 524~~~; 525 ; 526And in Python:; 527 ; 528~~~{.py}; 529h = df.Define(""good_pts"", ""pt[pt > 0]"").Histo1D(""good_pts""); 530~~~; 531 ; 532Learn more at ROOT::VecOps::RVec.; 533 ; 534\anchor transformations; 535## Transformations: manipulating data; 536\anchor Filters; 537### Filters; 538A filter is created through a call to `Filt",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:31928,Modifiability,variab,variable,31928,"s the desired array elements as follows:; 519 ; 520~~~{.cpp}; 521// h is filled with all the elements of `good_pts`, for each event; 522auto h = df.Define(""good_pts"", [](const ROOT::RVecF &pt) { return pt[pt > 0]; }); 523 .Histo1D(""good_pts"");; 524~~~; 525 ; 526And in Python:; 527 ; 528~~~{.py}; 529h = df.Define(""good_pts"", ""pt[pt > 0]"").Histo1D(""good_pts""); 530~~~; 531 ; 532Learn more at ROOT::VecOps::RVec.; 533 ; 534\anchor transformations; 535## Transformations: manipulating data; 536\anchor Filters; 537### Filters; 538A filter is created through a call to `Filter(f, columnList)` or `Filter(filterString)`. In the first overload, `f` can; 539be a function, a lambda expression, a functor class, or any other callable object. It must return a `bool` signalling; 540whether the event has passed the selection (`true`) or not (`false`). It should perform ""read-only"" operations on the; 541columns, and should not have side-effects (e.g. modification of an external or static variable) to ensure correctness; 542when implicit multi-threading is active. The second overload takes a string with a valid C++ expression in which column; 543names are used as variable names (e.g. `Filter(""x[0] + x[1] > 0"")`). This is a convenience feature that comes with a; 544certain runtime overhead: C++ code has to be generated on the fly from this expression before using it in the event; 545loop. See the paragraph about ""Just-in-time compilation"" below for more information.; 546 ; 547RDataFrame only evaluates filters when necessary: if multiple filters are chained one after another, they are executed; 548in order and the first one returning `false` causes the event to be discarded and triggers the processing of the next; 549entry. If multiple actions or transformations depend on the same filter, that filter is not executed multiple times for; 550each entry: after the first access it simply serves a cached result.; 551 ; 552\anchor named-filters-and-cutflow-reports; 553#### Named filters and cutflo",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:32106,Modifiability,variab,variable,32106,"or each event; 522auto h = df.Define(""good_pts"", [](const ROOT::RVecF &pt) { return pt[pt > 0]; }); 523 .Histo1D(""good_pts"");; 524~~~; 525 ; 526And in Python:; 527 ; 528~~~{.py}; 529h = df.Define(""good_pts"", ""pt[pt > 0]"").Histo1D(""good_pts""); 530~~~; 531 ; 532Learn more at ROOT::VecOps::RVec.; 533 ; 534\anchor transformations; 535## Transformations: manipulating data; 536\anchor Filters; 537### Filters; 538A filter is created through a call to `Filter(f, columnList)` or `Filter(filterString)`. In the first overload, `f` can; 539be a function, a lambda expression, a functor class, or any other callable object. It must return a `bool` signalling; 540whether the event has passed the selection (`true`) or not (`false`). It should perform ""read-only"" operations on the; 541columns, and should not have side-effects (e.g. modification of an external or static variable) to ensure correctness; 542when implicit multi-threading is active. The second overload takes a string with a valid C++ expression in which column; 543names are used as variable names (e.g. `Filter(""x[0] + x[1] > 0"")`). This is a convenience feature that comes with a; 544certain runtime overhead: C++ code has to be generated on the fly from this expression before using it in the event; 545loop. See the paragraph about ""Just-in-time compilation"" below for more information.; 546 ; 547RDataFrame only evaluates filters when necessary: if multiple filters are chained one after another, they are executed; 548in order and the first one returning `false` causes the event to be discarded and triggers the processing of the next; 549entry. If multiple actions or transformations depend on the same filter, that filter is not executed multiple times for; 550each entry: after the first access it simply serves a cached result.; 551 ; 552\anchor named-filters-and-cutflow-reports; 553#### Named filters and cutflow reports; 554An optional string parameter `name` can be passed to the Filter() method to create a **named filter**. ",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:35769,Modifiability,variab,variable,35769,"t the next 40 entries pass, then stop processing"". If a range node hangs from a filter node,; 582and the range has a `begin` parameter of 10, that means the range will skip the first 10 entries *that pass the; 583preceding filter*.; 584 ; 585Ranges allow ""early quitting"": if all branches of execution of a functional graph reached their `end` value of; 586processed entries, the event-loop is immediately interrupted. This is useful for debugging and quick data explorations.; 587 ; 588\anchor custom-columns; 589### Custom columns; 590Custom columns are created by invoking `Define(name, f, columnList)`. As usual, `f` can be any callable object; 591(function, lambda expression, functor class...); it takes the values of the columns listed in `columnList` (a list of; 592strings) as parameters, in the same order as they are listed in `columnList`. `f` must return the value that will be; 593assigned to the temporary column.; 594 ; 595A new variable is created called `name`, accessible as if it was contained in the dataset from subsequent; 596transformations/actions.; 597 ; 598Use cases include:; 599- caching the results of complex calculations for easy and efficient multiple access; 600- extraction of quantities of interest from complex objects; 601- branch aliasing, i.e. changing the name of a branch; 602 ; 603An exception is thrown if the `name` of the new column/branch is already in use for another branch in the TTree.; 604 ; 605It is also possible to specify the quantity to be stored in the new temporary column as a C++ expression with the method; 606`Define(name, expression)`. For example this invocation; 607 ; 608~~~{.cpp}; 609df.Define(""pt"", ""sqrt(px*px + py*py)"");; 610~~~; 611 ; 612will create a new column called ""pt"" the value of which is calculated starting from the columns px and py. The system; 613builds a just-in-time compiled function starting from the expression after having deduced the list of necessary branches; 614from the names of the variables specified by",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:36803,Modifiability,variab,variables,36803,"mporary column.; 594 ; 595A new variable is created called `name`, accessible as if it was contained in the dataset from subsequent; 596transformations/actions.; 597 ; 598Use cases include:; 599- caching the results of complex calculations for easy and efficient multiple access; 600- extraction of quantities of interest from complex objects; 601- branch aliasing, i.e. changing the name of a branch; 602 ; 603An exception is thrown if the `name` of the new column/branch is already in use for another branch in the TTree.; 604 ; 605It is also possible to specify the quantity to be stored in the new temporary column as a C++ expression with the method; 606`Define(name, expression)`. For example this invocation; 607 ; 608~~~{.cpp}; 609df.Define(""pt"", ""sqrt(px*px + py*py)"");; 610~~~; 611 ; 612will create a new column called ""pt"" the value of which is calculated starting from the columns px and py. The system; 613builds a just-in-time compiled function starting from the expression after having deduced the list of necessary branches; 614from the names of the variables specified by the user.; 615 ; 616#### Custom columns as function of slot and entry number; 617 ; 618It is possible to create custom columns also as a function of the processing slot and entry numbers. The methods that can; 619be invoked are:; 620- `DefineSlot(name, f, columnList)`. In this case the callable f has this signature `R(unsigned int, T1, T2, ...)`: the; 621first parameter is the slot number which ranges from 0 to ROOT::GetThreadPoolSize() - 1.; 622- `DefineSlotEntry(name, f, columnList)`. In this case the callable f has this signature `R(unsigned int, ULong64_t,; 623T1, T2, ...)`: the first parameter is the slot number while the second one the number of the entry being processed.; 624 ; 625\anchor actions; 626## Actions: getting results; 627### Instant and lazy actions; 628Actions can be **instant** or **lazy**. Instant actions are executed as soon as they are called, while lazy actions are; 629execut",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:42290,Modifiability,config,configuration,42290,"ne; 715- Snapshot; 716- Stats; 717- StdDev; 718- Sum; 719- Systematic variations: Vary and [VariationsFor](\ref ROOT::RDF::Experimental::VariationsFor).; 720- Parallel submission of distributed graphs: [RunGraphs](\ref ROOT::RDF::RunGraphs).; 721- Information about the dataframe: GetColumnNames.; 722 ; 723with support for more operations coming in the future. Data sources other than TTree and TChain (e.g. CSV, RNTuple) are; 724currently not supported.; 725 ; 726\note The distributed RDataFrame module requires at least Python version 3.8.; 727 ; 728### Connecting to a Spark cluster; 729 ; 730In order to distribute the RDataFrame workload, you can connect to a Spark cluster you have access to through the; 731official [Spark API](https://spark.apache.org/docs/latest/rdd-programming-guide.html#initializing-spark), then hook the; 732connection instance to the distributed `RDataFrame` object like so:; 733 ; 734~~~{.py}; 735import pyspark; 736import ROOT; 737 ; 738# Create a SparkContext object with the right configuration for your Spark cluster; 739conf = SparkConf().setAppName(appName).setMaster(master); 740sc = SparkContext(conf=conf); 741 ; 742# Point RDataFrame calls to the Spark specific RDataFrame; 743RDataFrame = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame; 744 ; 745# The Spark RDataFrame constructor accepts an optional ""sparkcontext"" parameter; 746# and it will distribute the application to the connected cluster; 747df = RDataFrame(""mytree"", ""myfile.root"", sparkcontext = sc); 748~~~; 749 ; 750If an instance of [SparkContext](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.SparkContext.html); 751is not provided, the default behaviour is to create one in the background for you.; 752 ; 753### Connecting to a Dask cluster; 754 ; 755Similarly, you can connect to a Dask cluster by creating your own connection object which internally operates with one; 756of the cluster schedulers supported by Dask (more information in the; 757[Dask distribute",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:59996,Modifiability,flexible,flexible,59996,"ggered, so that the interpreter is invoked only once for all computation graphs:; 1012 ; 1013~~~{.cpp}; 1014// assuming df1 and df2 are separate computation graphs, do:; 1015auto h1 = df1.Histo1D(""x"");; 1016auto h2 = df2.Histo1D(""y"");; 1017h1->Draw(); // we just-in-time compile everything needed by df1 and df2 here; 1018h2->Draw(""SAME"");; 1019 ; 1020// do not:; 1021auto h1 = df1.Histo1D(""x"");; 1022h1->Draw(); // we just-in-time compile here; 1023auto h2 = df2.Histo1D(""y"");; 1024h2->Draw(""SAME""); // we just-in-time compile again here, as the second Histo1D call is new; 1025~~~; 1026 ; 1027\anchor more-features; 1028## More features; 1029Here is a list of the most important features that have been omitted in the ""Crash course"" for brevity.; 1030You don't need to read all these to start using RDataFrame, but they are useful to save typing time and runtime.; 1031 ; 1032\anchor systematics; 1033### Systematic variations; 1034 ; 1035Starting from ROOT v6.26, RDataFrame provides a flexible syntax to define systematic variations.; 1036This is done in two steps: a) register variations for one or more existing columns using Vary() and b) extract variations; 1037of normal RDataFrame results using \ref ROOT::RDF::Experimental::VariationsFor ""VariationsFor()"". In between these steps, no other change; 1038to the analysis code is required: the presence of systematic variations for certain columns is automatically propagated; 1039through filters, defines and actions, and RDataFrame will take these dependencies into account when producing varied; 1040results. \ref ROOT::RDF::Experimental::VariationsFor ""VariationsFor()"" is included in header `ROOT/RDFHelpers.hxx`. The compiled C++ programs must include this header; 1041explicitly, this is not required for ROOT macros. ; 1042 ; 1043An example usage of Vary() and \ref ROOT::RDF::Experimental::VariationsFor ""VariationsFor()"" in C++:; 1044 ; 1045~~~{.cpp}; 1046auto nominal_hx =; 1047 df.Vary(""pt"", ""ROOT::RVecD{pt*0.9f, pt*1.1f}"", {""down",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:64930,Modifiability,evolve,evolve,64930,"ill be no result produced; 1097by applying multiple systematic variations at the same time.; 1098For example, in the following example snippet, the RResultMap instance `all_h` will contain keys ""nominal"", ""pt:down"",; 1099""pt:up"", ""eta:0"", ""eta:1"", but no ""pt:up&&eta:0"" or similar:; 1100 ; 1101~~~{.cpp}; 1102auto df = _df.Vary(""pt"",; 1103 ""ROOT::RVecD{pt*0.9, pt*1.1}"",; 1104 {""down"", ""up""}); 1105 .Vary(""eta"",; 1106 [](float eta) { return RVecF{eta*0.9f, eta*1.1f}; },; 1107 {""eta""},; 1108 2);; 1109 ; 1110auto nom_h = df.Histo2D(histoModel, ""pt"", ""eta"");; 1111auto all_hs = VariationsFor(nom_h);; 1112all_hs.GetKeys(); // returns {""nominal"", ""pt:down"", ""pt:up"", ""eta:0"", ""eta:1""}; 1113~~~; 1114 ; 1115Note how we passed the integer `2` instead of a list of variation tags to the second Vary() invocation: this is a; 1116shorthand that automatically generates tags 0 to N-1 (in this case 0 and 1).; 1117 ; 1118\note Currently, VariationsFor() and RResultMap are in the `ROOT::RDF::Experimental` namespace, to indicate that these; 1119 interfaces might still evolve and improve based on user feedback. We expect that some aspects of the related; 1120 programming model will be streamlined in future versions.; 1121 ; 1122\note Currently, the results of a Snapshot(), Report() or Display() call cannot be varied (i.e. it is not possible to; 1123 call \ref ROOT::RDF::Experimental::VariationsFor ""VariationsFor()"" on them. These limitations will be lifted in future releases.; 1124 ; 1125See the Vary() method for more information and [this tutorial](https://root.cern/doc/master/df106__HiggsToFourLeptons_8C.html) ; 1126for an example usage of Vary and \ref ROOT::RDF::Experimental::VariationsFor ""VariationsFor()"" in the analysis.; 1127 ; 1128\anchor rnode; 1129### RDataFrame objects as function arguments and return values; 1130RDataFrame variables/nodes are relatively cheap to copy and it's possible to both pass them to (or move them into); 1131functions and to return them from functions. Howev",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:65712,Modifiability,variab,variables,65712,"ags 0 to N-1 (in this case 0 and 1).; 1117 ; 1118\note Currently, VariationsFor() and RResultMap are in the `ROOT::RDF::Experimental` namespace, to indicate that these; 1119 interfaces might still evolve and improve based on user feedback. We expect that some aspects of the related; 1120 programming model will be streamlined in future versions.; 1121 ; 1122\note Currently, the results of a Snapshot(), Report() or Display() call cannot be varied (i.e. it is not possible to; 1123 call \ref ROOT::RDF::Experimental::VariationsFor ""VariationsFor()"" on them. These limitations will be lifted in future releases.; 1124 ; 1125See the Vary() method for more information and [this tutorial](https://root.cern/doc/master/df106__HiggsToFourLeptons_8C.html) ; 1126for an example usage of Vary and \ref ROOT::RDF::Experimental::VariationsFor ""VariationsFor()"" in the analysis.; 1127 ; 1128\anchor rnode; 1129### RDataFrame objects as function arguments and return values; 1130RDataFrame variables/nodes are relatively cheap to copy and it's possible to both pass them to (or move them into); 1131functions and to return them from functions. However, in general each dataframe node will have a different C++ type,; 1132which includes all available compile-time information about what that node does. One way to cope with this complication; 1133is to use template functions and/or C++14 auto return types:; 1134~~~{.cpp}; 1135template <typename RDF>; 1136auto ApplySomeFilters(RDF df); 1137{; 1138 return df.Filter(""x > 0"").Filter([](int y) { return y < 0; }, {""y""});; 1139}; 1140~~~; 1141 ; 1142A possibly simpler, C++11-compatible alternative is to take advantage of the fact that any dataframe node can be; 1143converted (implicitly or via an explicit cast) to the common type ROOT::RDF::RNode:; 1144~~~{.cpp}; 1145// a function that conditionally adds a Range to an RDataFrame node.; 1146RNode MaybeAddRange(RNode df, bool mustAddRange); 1147{; 1148 return mustAddRange ? df.Range(1) : df;; 1149}; 1150// u",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:77928,Modifiability,variab,variable,77928,"ame; 1336guarantees that ForeachSlot() will invoke the user expression with different `slot` parameters for different concurrent; 1337executions (see [Special helper columns: rdfentry_ and rdfslot_](\ref helper-cols) for more information on the slot parameter).; 1338We can take advantage of ForeachSlot() to evaluate a thread-safe root mean square of column ""x"":; 1339~~~{.cpp}; 1340// Thread-safe evaluation of RMS of column ""x"" using ForeachSlot; 1341ROOT::EnableImplicitMT();; 1342const unsigned int nSlots = df.GetNSlots();; 1343std::vector<double> sumSqs(nSlots, 0.);; 1344std::vector<unsigned int> ns(nSlots, 0);; 1345 ; 1346df.ForeachSlot([&sumSqs, &ns](unsigned int slot, double x) { sumSqs[slot] += x*x; ns[slot] += 1; }, {""x""});; 1347double sumSq = std::accumulate(sumSqs.begin(), sumSqs.end(), 0.); // sum all squares; 1348unsigned int n = std::accumulate(ns.begin(), ns.end(), 0); // sum all counts; 1349std::cout << ""rms of x: "" << std::sqrt(sumSq / n) << std::endl;; 1350~~~; 1351Notice how we created one `double` variable for each processing slot and later merged their results via `std::accumulate`.; 1352 ; 1353 ; 1354\anchor friends; 1355### Dataset joins with friend trees; 1356 ; 1357Vertically concatenating multiple trees that have the same columns (creating a logical dataset with the same columns and; 1358more rows) is trivial in RDataFrame: just pass the tree name and a list of file names to RDataFrame's constructor, or create a TChain; 1359out of the desired trees and pass that to RDataFrame.; 1360 ; 1361Horizontal concatenations of trees or chains (creating a logical dataset with the same number of rows and the union of the; 1362columns of multiple trees) leverages TTree's ""friend"" mechanism.; 1363 ; 1364Simple joins of trees that do not have the same number of rows are also possible with indexed friend trees (see below).; 1365 ; 1366To use friend trees in RDataFrame, set up trees with the appropriate relationships and then instantiate an RDataFrame; 1367wit",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:81834,Modifiability,variab,variables,81834,"T::RDF::RDataSource interface defines an API that RDataFrame can use to read arbitrary columnar data formats.; 1409 ; 1410RDataFrame calls into concrete RDataSource implementations to retrieve information about the data, retrieve (thread-local) readers or ""cursors"" for selected columns; 1411and to advance the readers to the desired data entry.; 1412Some predefined RDataSources are natively provided by ROOT such as the ROOT::RDF::RCsvDS which allows to read comma separated files:; 1413~~~{.cpp}; 1414auto tdf = ROOT::RDF::FromCSV(""MuRun2010B.csv"");; 1415auto filteredEvents =; 1416 tdf.Filter(""Q1 * Q2 == -1""); 1417 .Define(""m"", ""sqrt(pow(E1 + E2, 2) - (pow(px1 + px2, 2) + pow(py1 + py2, 2) + pow(pz1 + pz2, 2)))"");; 1418auto h = filteredEvents.Histo1D(""m"");; 1419h->Draw();; 1420~~~; 1421 ; 1422See also FromNumpy (Python-only), FromRNTuple(), FromArrow(), FromSqlite().; 1423 ; 1424\anchor callgraphs; 1425### Computation graphs (storing and reusing sets of transformations); 1426 ; 1427As we saw, transformed dataframes can be stored as variables and reused multiple times to create modified versions of the dataset. This implicitly defines a **computation graph** in which; 1428several paths of filtering/creation of columns are executed simultaneously, and finally aggregated results are produced.; 1429 ; 1430RDataFrame detects when several actions use the same filter or the same defined column, and **only evaluates each; 1431filter or defined column once per event**, regardless of how many times that result is used down the computation graph.; 1432Objects read from each column are **built once and never copied**, for maximum efficiency.; 1433When ""upstream"" filters are not passed, subsequent filters, temporary column expressions and actions are not evaluated,; 1434so it might be advisable to put the strictest filters first in the graph.; 1435 ; 1436\anchor representgraph; 1437### Visualizing the computation graph; 1438It is possible to print the computation graph from any nod",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:84443,Modifiability,variab,variable,84443,"ine(""y"", []() { return 1; });; 1453 ; 1454auto count = df2.Count();; 1455 ; 1456// Prints the graph to the rd1.dot file in the current directory; 1457ROOT::RDF::SaveGraph(df, ""./mydot.dot"");; 1458// Prints the graph to standard output; 1459ROOT::RDF::SaveGraph(df);; 1460~~~; 1461 ; 1462The generated graph can be rendered using one of the graphviz filters, e.g. `dot`. For instance, the image below can be generated with the following command:; 1463~~~{.sh}; 1464$ dot -Tpng computation_graph.dot -ocomputation_graph.png; 1465~~~; 1466 ; 1467\image html RDF_Graph2.png; 1468 ; 1469\anchor rdf-logging; 1470### Activating RDataFrame execution logs; 1471 ; 1472RDataFrame has experimental support for verbose logging of the event loop runtimes and other interesting related information. It is activated as follows:; 1473~~~{.cpp}; 1474#include <ROOT/RLogger.hxx>; 1475 ; 1476// this increases RDF's verbosity level as long as the `verbosity` variable is in scope; 1477auto verbosity = ROOT::Experimental::RLogScopedVerbosity(ROOT::Detail::RDF::RDFLogChannel(), ROOT::Experimental::ELogLevel::kInfo);; 1478~~~; 1479 ; 1480or in Python:; 1481~~~{.python}; 1482import ROOT; 1483 ; 1484verbosity = ROOT.Experimental.RLogScopedVerbosity(ROOT.Detail.RDF.RDFLogChannel(), ROOT.Experimental.ELogLevel.kInfo); 1485~~~; 1486 ; 1487More information (e.g. start and end of each multi-thread task) is printed using `ELogLevel.kDebug` and even more; 1488(e.g. a full dump of the generated code that RDataFrame just-in-time-compiles) using `ELogLevel.kDebug+10`.; 1489 ; 1490\anchor rdf-from-spec; 1491### Creating an RDataFrame from a dataset specification file; 1492 ; 1493RDataFrame can be created using a dataset specification JSON file: ; 1494 ; 1495~~~{.python}; 1496import ROOT; 1497 ; 1498df = ROOT.RDF.Experimental.FromSpec(""spec.json""); 1499~~~; 1500 ; 1501The input dataset specification JSON file needs to be provided by the user and it describes all necessary samples and; 1502their associated metadata i",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:107462,Modifiability,variab,variable,107462,"int> range = fullData[""range""];; 1974 ; 1975 if (range.size() == 1); 1976 spec.WithGlobalRange({range[0]});; 1977 else if (range.size() == 2); 1978 spec.WithGlobalRange({range[0], range[1]});; 1979 }; 1980 return ROOT::RDataFrame(spec);; 1981}; 1982 ; 1983} // namespace Experimental; 1984} // namespace RDF; 1985 ; 1986} // namespace ROOT; 1987 ; 1988namespace cling {; 1989//////////////////////////////////////////////////////////////////////////; 1990/// Print an RDataFrame at the prompt; 1991std::string printValue(ROOT::RDataFrame *df); 1992{; 1993 // The loop manager is never null, except when its construction failed.; 1994 // This can happen e.g. if the constructor of RLoopManager that expects; 1995 // a file name is used and that file doesn't exist. This point is usually; 1996 // not even reached in that situation, since the exception thrown by the; 1997 // constructor will also stop execution of the program. But it can still; 1998 // be reached at the prompt, if the user tries to print the RDataFrame; 1999 // variable after an incomplete initialization.; 2000 auto *lm = df->GetLoopManager();; 2001 if (!lm) {; 2002 throw std::runtime_error(""Cannot print information about this RDataFrame, ""; 2003 ""it was not properly created. It must be discarded."");; 2004 }; 2005 auto *tree = lm->GetTree();; 2006 auto defCols = lm->GetDefaultColumnNames();; 2007 ; 2008 std::ostringstream ret;; 2009 if (tree) {; 2010 ret << ""A data frame built on top of the "" << tree->GetName() << "" dataset."";; 2011 if (!defCols.empty()) {; 2012 if (defCols.size() == 1); 2013 ret << ""\nDefault column: "" << defCols[0];; 2014 else {; 2015 ret << ""\nDefault columns:\n"";; 2016 for (auto &&col : defCols) {; 2017 ret << "" - "" << col << ""\n"";; 2018 }; 2019 }; 2020 }; 2021 } else if (auto ds = df->fDataSource) {; 2022 ret << ""A data frame associated to the data source \"""" << cling::printValue(ds) << ""\"""";; 2023 } else {; 2024 ret << ""An empty data frame that will create "" << lm->GetNEmptyEntries() << "" e",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:1559,Performance,multi-thread,multi-threading,1559,"10 ; 11#include ""ROOT/InternalTreeUtils.hxx""; 12#include ""ROOT/RDataFrame.hxx""; 13#include ""ROOT/RDataSource.hxx""; 14#include ""ROOT/RDF/RDatasetSpec.hxx""; 15#include ""ROOT/RDF/RInterface.hxx""; 16#include ""ROOT/RDF/RLoopManager.hxx""; 17#include ""ROOT/RDF/Utils.hxx""; 18#include <string_view>; 19#include ""TChain.h""; 20#include ""TDirectory.h""; 21#include ""RtypesCore.h"" // for ULong64_t; 22#include ""TTree.h""; 23 ; 24#include <fstream> // std::ifstream; 25#include <nlohmann/json.hpp> // nlohmann::json::parse; 26#include <memory> // for make_shared, allocator, shared_ptr; 27#include <ostream> // ostringstream; 28#include <stdexcept>; 29#include <string>; 30#include <vector>; 31 ; 32// clang-format off; 33/**; 34* \class ROOT::RDataFrame; 35* \ingroup dataframe; 36* \brief ROOT's RDataFrame offers a modern, high-level interface for analysis of data stored in TTree , CSV and other data formats, in C++ or Python.; 37 ; 38In addition, multi-threading and other low-level optimisations allow users to exploit all the resources available; 39on their machines completely transparently.<br>; 40Skip to the [class reference](#reference) or keep reading for the user guide.; 41 ; 42In a nutshell:; 43~~~{.cpp}; 44ROOT::EnableImplicitMT(); // Tell ROOT you want to go parallel; 45ROOT::RDataFrame d(""myTree"", ""file_*.root""); // Interface to TTree and TChain; 46auto myHisto = d.Histo1D(""Branch_A""); // This books the (lazy) filling of a histogram; 47myHisto->Draw(); // Event loop is run here, upon first access to a result; 48~~~; 49 ; 50Calculations are expressed in terms of a type-safe *functional chain of actions and transformations*, RDataFrame takes; 51care of their execution. The implementation automatically puts in place several low level optimisations such as; 52multi-thread parallelization and caching.; 53 ; 54\htmlonly; 55<a href=""https://doi.org/10.5281/zenodo.260230""><img src=""https://zenodo.org/badge/DOI/10.5281/zenodo.260230.svg""; 56alt=""DOI""></a>; 57\endhtmlonly; 58 ; 59## For the",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:4659,Performance,perform,performed,4659,"ecial helper columns: `rdfentry_` and `rdfslot_`](\ref helper-cols); 78 - [Just-in-time compilation: column type inference and explicit declaration of column types](\ref jitting); 79 - [User-defined custom actions](\ref generic-actions); 80 - [Dataset joins with friend trees](\ref friends); 81 - [Reading data formats other than ROOT trees](\ref other-file-formats); 82 - [Computation graphs (storing and reusing sets of transformations)](\ref callgraphs); 83 - [Visualizing the computation graph](\ref representgraph); 84 - [Activating RDataFrame execution logs](\ref rdf-logging); 85 - [Creating an RDataFrame from a dataset specification file](\ref rdf-from-spec); 86 - [Adding a progress bar](\ref progressbar); 87 - [Working with missing values in the dataset](\ref missing-values); 88- [Efficient analysis in Python](\ref python); 89- <a class=""el"" href=""classROOT_1_1RDataFrame.html#reference"" onclick=""javascript:toggleInherit('pub_methods_classROOT_1_1RDF_1_1RInterface')"">Class reference</a>; 90 ; 91\anchor cheatsheet; 92## Cheat sheet; 93These are the operations which can be performed with RDataFrame.; 94 ; 95### Transformations; 96Transformations are a way to manipulate the data.; 97 ; 98| **Transformation** | **Description** |; 99|------------------|--------------------|; 100| Alias() | Introduce an alias for a particular column name. |; 101| DefaultValueFor() | If the value of the input column is missing, provide a default value instead. |; 102| Define() | Create a new column in the dataset. Example usages include adding a column that contains the invariant mass of a particle, or a selection of elements of an array (e.g. only the `pt`s of ""good"" muons). |; 103| DefinePerSample() | Define a new column that is updated when the input sample changes, e.g. when switching tree being processed in a chain. |; 104| DefineSlot() | Same as Define(), but the user-defined function must take an extra `unsigned int slot` as its first parameter. `slot` will take a different value, `",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:6078,Performance,multi-thread,multi-threaded,6078,". Example usages include adding a column that contains the invariant mass of a particle, or a selection of elements of an array (e.g. only the `pt`s of ""good"" muons). |; 103| DefinePerSample() | Define a new column that is updated when the input sample changes, e.g. when switching tree being processed in a chain. |; 104| DefineSlot() | Same as Define(), but the user-defined function must take an extra `unsigned int slot` as its first parameter. `slot` will take a different value, `0` to `nThreads - 1`, for each thread of execution. This is meant as a helper in writing thread-safe Define() transformation when using RDataFrame after ROOT::EnableImplicitMT(). DefineSlot() works just as well with single-thread execution: in that case `slot` will always be `0`. |; 105| DefineSlotEntry() | Same as DefineSlot(), but the entry number is passed in addition to the slot number. This is meant as a helper in case the expression depends on the entry number. For details about entry numbers in multi-threaded runs, see [here](\ref helper-cols). |; 106| Filter() | Filter rows based on user-defined conditions. |; 107| FilterAvailable() | Specialized Filter. If the value of the input column is available, keep the entry, otherwise discard it. |; 108| FilterMissing() | Specialized Filter. If the value of the input column is missing, keep the entry, otherwise discard it. |; 109| Range() | Filter rows based on entry number (single-thread only). |; 110| Redefine() | Overwrite the value and/or type of an existing column. See Define() for more information. |; 111| RedefineSlot() | Overwrite the value and/or type of an existing column. See DefineSlot() for more information. |; 112| RedefineSlotEntry() | Overwrite the value and/or type of an existing column. See DefineSlotEntry() for more information. |; 113| Vary() | Register systematic variations for an existing column. Varied results are then extracted via VariationsFor(). |; 114 ; 115 ; 116### Actions; 117Actions aggregate data into a resul",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:7915,Performance,cache,cached,7915,"ariations for an existing column. Varied results are then extracted via VariationsFor(). |; 114 ; 115 ; 116### Actions; 117Actions aggregate data into a result. Each one is described in more detail in the reference guide.; 118 ; 119In the following, whenever we say an action ""returns"" something, we always mean it returns a smart pointer to it. Actions only act on events that pass all preceding filters.; 120 ; 121Lazy actions only trigger the event loop when one of the results is accessed for the first time, making it easy to; 122produce many different results in one event loop. Instant actions trigger the event loop instantly.; 123 ; 124 ; 125| **Lazy action** | **Description** |; 126|------------------|-----------------|; 127| Aggregate() | Execute a user-defined accumulation operation on the processed column values. |; 128| Book() | Book execution of a custom action using a user-defined helper object. |; 129| Cache() | Cache column values in memory. Custom columns can be cached as well, filtered entries are not cached. Users can specify which columns to save (default is all). |; 130| Count() | Return the number of events processed. Useful e.g. to get a quick count of the number of events passing a Filter. |; 131| Display() | Provides a printable representation of the dataset contents. The method returns a ROOT::RDF::RDisplay() instance which can print a tabular representation of the data or return it as a string. |; 132| Fill() | Fill a user-defined object with the values of the specified columns, as if by calling `Obj.Fill(col1, col2, ...)`. |; 133| Graph() | Fills a TGraph with the two columns provided. If multi-threading is enabled, the order of the points may not be the one expected, it is therefore suggested to sort if before drawing. |; 134| GraphAsymmErrors() | Fills a TGraphAsymmErrors. If multi-threading is enabled, the order of the points may not be the one expected, it is therefore suggested to sort if before drawing. |; 135| Histo1D(), Histo2D(), Histo3",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:7956,Performance,cache,cached,7956,"ariations for an existing column. Varied results are then extracted via VariationsFor(). |; 114 ; 115 ; 116### Actions; 117Actions aggregate data into a result. Each one is described in more detail in the reference guide.; 118 ; 119In the following, whenever we say an action ""returns"" something, we always mean it returns a smart pointer to it. Actions only act on events that pass all preceding filters.; 120 ; 121Lazy actions only trigger the event loop when one of the results is accessed for the first time, making it easy to; 122produce many different results in one event loop. Instant actions trigger the event loop instantly.; 123 ; 124 ; 125| **Lazy action** | **Description** |; 126|------------------|-----------------|; 127| Aggregate() | Execute a user-defined accumulation operation on the processed column values. |; 128| Book() | Book execution of a custom action using a user-defined helper object. |; 129| Cache() | Cache column values in memory. Custom columns can be cached as well, filtered entries are not cached. Users can specify which columns to save (default is all). |; 130| Count() | Return the number of events processed. Useful e.g. to get a quick count of the number of events passing a Filter. |; 131| Display() | Provides a printable representation of the dataset contents. The method returns a ROOT::RDF::RDisplay() instance which can print a tabular representation of the data or return it as a string. |; 132| Fill() | Fill a user-defined object with the values of the specified columns, as if by calling `Obj.Fill(col1, col2, ...)`. |; 133| Graph() | Fills a TGraph with the two columns provided. If multi-threading is enabled, the order of the points may not be the one expected, it is therefore suggested to sort if before drawing. |; 134| GraphAsymmErrors() | Fills a TGraphAsymmErrors. If multi-threading is enabled, the order of the points may not be the one expected, it is therefore suggested to sort if before drawing. |; 135| Histo1D(), Histo2D(), Histo3",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:8565,Performance,multi-thread,multi-threading,8565,"----------|-----------------|; 127| Aggregate() | Execute a user-defined accumulation operation on the processed column values. |; 128| Book() | Book execution of a custom action using a user-defined helper object. |; 129| Cache() | Cache column values in memory. Custom columns can be cached as well, filtered entries are not cached. Users can specify which columns to save (default is all). |; 130| Count() | Return the number of events processed. Useful e.g. to get a quick count of the number of events passing a Filter. |; 131| Display() | Provides a printable representation of the dataset contents. The method returns a ROOT::RDF::RDisplay() instance which can print a tabular representation of the data or return it as a string. |; 132| Fill() | Fill a user-defined object with the values of the specified columns, as if by calling `Obj.Fill(col1, col2, ...)`. |; 133| Graph() | Fills a TGraph with the two columns provided. If multi-threading is enabled, the order of the points may not be the one expected, it is therefore suggested to sort if before drawing. |; 134| GraphAsymmErrors() | Fills a TGraphAsymmErrors. If multi-threading is enabled, the order of the points may not be the one expected, it is therefore suggested to sort if before drawing. |; 135| Histo1D(), Histo2D(), Histo3D() | Fill a one-, two-, three-dimensional histogram with the processed column values. |; 136| HistoND() | Fill an N-dimensional histogram with the processed column values. |; 137| Max() | Return the maximum of processed column values. If the type of the column is inferred, the return type is `double`, the type of the column otherwise.|; 138| Mean() | Return the mean of processed column values.|; 139| Min() | Return the minimum of processed column values. If the type of the column is inferred, the return type is `double`, the type of the column otherwise.|; 140| Profile1D(), Profile2D() | Fill a one- or two-dimensional profile with the column values that passed all filters. |; 141| Reduce() | ",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:8758,Performance,multi-thread,multi-threading,8758,"efined helper object. |; 129| Cache() | Cache column values in memory. Custom columns can be cached as well, filtered entries are not cached. Users can specify which columns to save (default is all). |; 130| Count() | Return the number of events processed. Useful e.g. to get a quick count of the number of events passing a Filter. |; 131| Display() | Provides a printable representation of the dataset contents. The method returns a ROOT::RDF::RDisplay() instance which can print a tabular representation of the data or return it as a string. |; 132| Fill() | Fill a user-defined object with the values of the specified columns, as if by calling `Obj.Fill(col1, col2, ...)`. |; 133| Graph() | Fills a TGraph with the two columns provided. If multi-threading is enabled, the order of the points may not be the one expected, it is therefore suggested to sort if before drawing. |; 134| GraphAsymmErrors() | Fills a TGraphAsymmErrors. If multi-threading is enabled, the order of the points may not be the one expected, it is therefore suggested to sort if before drawing. |; 135| Histo1D(), Histo2D(), Histo3D() | Fill a one-, two-, three-dimensional histogram with the processed column values. |; 136| HistoND() | Fill an N-dimensional histogram with the processed column values. |; 137| Max() | Return the maximum of processed column values. If the type of the column is inferred, the return type is `double`, the type of the column otherwise.|; 138| Mean() | Return the mean of processed column values.|; 139| Min() | Return the minimum of processed column values. If the type of the column is inferred, the return type is `double`, the type of the column otherwise.|; 140| Profile1D(), Profile2D() | Fill a one- or two-dimensional profile with the column values that passed all filters. |; 141| Reduce() | Reduce (e.g. sum, merge) entries using the function (lambda, functor...) passed as argument. The function must have signature `T(T,T)` where `T` is the type of the column. Return the final resu",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:11024,Performance,multi-thread,multi-threading,11024," entries have been accepted and rejected by the filters. See the section on [named filters](#named-filters-and-cutflow-reports) for a more detailed explanation. The method returns a ROOT::RDF::RCutFlowReport instance which can be queried programmatically to get information about the effects of the individual cuts. |; 143| Stats() | Return a TStatistic object filled with the input columns. |; 144| StdDev() | Return the unbiased standard deviation of the processed column values. |; 145| Sum() | Return the sum of the values in the column. If the type of the column is inferred, the return type is `double`, the type of the column otherwise. |; 146| Take() | Extract a column from the dataset as a collection of values, e.g. a `std::vector<float>` for a column of type `float`. |; 147 ; 148| **Instant action** | **Description** |; 149|---------------------|-----------------|; 150| Foreach() | Execute a user-defined function on each entry. Users are responsible for the thread-safety of this callable when executing with implicit multi-threading enabled. |; 151| ForeachSlot() | Same as Foreach(), but the user-defined function must take an extra `unsigned int slot` as its first parameter. `slot` will take a different value, `0` to `nThreads - 1`, for each thread of execution. This is meant as a helper in writing thread-safe Foreach() actions when using RDataFrame after ROOT::EnableImplicitMT(). ForeachSlot() works just as well with single-thread execution: in that case `slot` will always be `0`. |; 152| Snapshot() | Write the processed dataset to disk, in a new TTree and TFile. Custom columns can be saved as well, filtered entries are not saved. Users can specify which columns to save (default is all). Snapshot, by default, overwrites the output file if it already exists. Snapshot() can be made *lazy* setting the appropriate flag in the snapshot options.|; 153 ; 154 ; 155### Queries; 156 ; 157These operations do not modify the dataframe or book computations but simply return info",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:12838,Performance,concurren,concurrency,12838," snapshot options.|; 153 ; 154 ; 155### Queries; 156 ; 157These operations do not modify the dataframe or book computations but simply return information on the RDataFrame object.; 158 ; 159| **Operation** | **Description** |; 160|---------------------|-----------------|; 161| Describe() | Get useful information describing the dataframe, e.g. columns and their types. |; 162| GetColumnNames() | Get the names of all the available columns of the dataset. |; 163| GetColumnType() | Return the type of a given column as a string. |; 164| GetColumnTypeNamesList() | Return the list of type names of columns in the dataset. |; 165| GetDefinedColumnNames() | Get the names of all the defined columns. |; 166| GetFilterNames() | Return the names of all filters in the computation graph. |; 167| GetNRuns() | Return the number of event loops run by this RDataFrame instance so far. |; 168| GetNSlots() | Return the number of processing slots that RDataFrame will use during the event loop (i.e. the concurrency level). |; 169| SaveGraph() | Store the computation graph of an RDataFrame in [DOT format (graphviz)](https://en.wikipedia.org/wiki/DOT_(graph_description_language)) for easy inspection. See the [relevant section](\ref representgraph) for details. |; 170 ; 171\anchor introduction; 172## Introduction; 173Users define their analysis as a sequence of operations to be performed on the dataframe object; the framework; 174takes care of the management of the loop over entries as well as low-level details such as I/O and parallelization.; 175RDataFrame provides methods to perform most common operations required by ROOT analyses;; 176at the same time, users can just as easily specify custom code that will be executed in the event loop.; 177 ; 178RDataFrame is built with a *modular* and *flexible* workflow in mind, summarised as follows:; 179 ; 1801. Construct a dataframe object by specifying a dataset. RDataFrame supports TTree as well as TChain, [CSV files](https://root.cern/doc/master/df",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:13217,Performance,perform,performed,13217," Get the names of all the available columns of the dataset. |; 163| GetColumnType() | Return the type of a given column as a string. |; 164| GetColumnTypeNamesList() | Return the list of type names of columns in the dataset. |; 165| GetDefinedColumnNames() | Get the names of all the defined columns. |; 166| GetFilterNames() | Return the names of all filters in the computation graph. |; 167| GetNRuns() | Return the number of event loops run by this RDataFrame instance so far. |; 168| GetNSlots() | Return the number of processing slots that RDataFrame will use during the event loop (i.e. the concurrency level). |; 169| SaveGraph() | Store the computation graph of an RDataFrame in [DOT format (graphviz)](https://en.wikipedia.org/wiki/DOT_(graph_description_language)) for easy inspection. See the [relevant section](\ref representgraph) for details. |; 170 ; 171\anchor introduction; 172## Introduction; 173Users define their analysis as a sequence of operations to be performed on the dataframe object; the framework; 174takes care of the management of the loop over entries as well as low-level details such as I/O and parallelization.; 175RDataFrame provides methods to perform most common operations required by ROOT analyses;; 176at the same time, users can just as easily specify custom code that will be executed in the event loop.; 177 ; 178RDataFrame is built with a *modular* and *flexible* workflow in mind, summarised as follows:; 179 ; 1801. Construct a dataframe object by specifying a dataset. RDataFrame supports TTree as well as TChain, [CSV files](https://root.cern/doc/master/df014__CSVDataSource_8C.html), [SQLite files](https://root.cern/doc/master/df027__SQliteDependencyOverVersion_8C.html), [RNTuples](https://root.cern/doc/master/structROOT_1_1Experimental_1_1RNTuple.html), and it can be extended to custom data formats. From Python, [NumPy arrays can be imported into RDataFrame](https://root.cern/doc/master/df032__MakeNumpyDataFrame_8py.html) as well.; 181 ; 1822.",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:13421,Performance,perform,perform,13421,"olumnNames() | Get the names of all the defined columns. |; 166| GetFilterNames() | Return the names of all filters in the computation graph. |; 167| GetNRuns() | Return the number of event loops run by this RDataFrame instance so far. |; 168| GetNSlots() | Return the number of processing slots that RDataFrame will use during the event loop (i.e. the concurrency level). |; 169| SaveGraph() | Store the computation graph of an RDataFrame in [DOT format (graphviz)](https://en.wikipedia.org/wiki/DOT_(graph_description_language)) for easy inspection. See the [relevant section](\ref representgraph) for details. |; 170 ; 171\anchor introduction; 172## Introduction; 173Users define their analysis as a sequence of operations to be performed on the dataframe object; the framework; 174takes care of the management of the loop over entries as well as low-level details such as I/O and parallelization.; 175RDataFrame provides methods to perform most common operations required by ROOT analyses;; 176at the same time, users can just as easily specify custom code that will be executed in the event loop.; 177 ; 178RDataFrame is built with a *modular* and *flexible* workflow in mind, summarised as follows:; 179 ; 1801. Construct a dataframe object by specifying a dataset. RDataFrame supports TTree as well as TChain, [CSV files](https://root.cern/doc/master/df014__CSVDataSource_8C.html), [SQLite files](https://root.cern/doc/master/df027__SQliteDependencyOverVersion_8C.html), [RNTuples](https://root.cern/doc/master/structROOT_1_1Experimental_1_1RNTuple.html), and it can be extended to custom data formats. From Python, [NumPy arrays can be imported into RDataFrame](https://root.cern/doc/master/df032__MakeNumpyDataFrame_8py.html) as well.; 181 ; 1822. Transform the dataframe by:; 183 ; 184 - [Applying filters](https://root.cern/doc/master/classROOT_1_1RDataFrame.html#transformations). This selects only specific rows of the dataset.; 185 ; 186 - [Creating custom columns](https://root.cern/doc",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:14624,Performance,perform,performed,14624,"aFrame is built with a *modular* and *flexible* workflow in mind, summarised as follows:; 179 ; 1801. Construct a dataframe object by specifying a dataset. RDataFrame supports TTree as well as TChain, [CSV files](https://root.cern/doc/master/df014__CSVDataSource_8C.html), [SQLite files](https://root.cern/doc/master/df027__SQliteDependencyOverVersion_8C.html), [RNTuples](https://root.cern/doc/master/structROOT_1_1Experimental_1_1RNTuple.html), and it can be extended to custom data formats. From Python, [NumPy arrays can be imported into RDataFrame](https://root.cern/doc/master/df032__MakeNumpyDataFrame_8py.html) as well.; 181 ; 1822. Transform the dataframe by:; 183 ; 184 - [Applying filters](https://root.cern/doc/master/classROOT_1_1RDataFrame.html#transformations). This selects only specific rows of the dataset.; 185 ; 186 - [Creating custom columns](https://root.cern/doc/master/classROOT_1_1RDataFrame.html#transformations). Custom columns can, for example, contain the results of a computation that must be performed for every row of the dataset.; 187 ; 1883. [Produce results](https://root.cern/doc/master/classROOT_1_1RDataFrame.html#actions). *Actions* are used to aggregate data into results. Most actions are *lazy*, i.e. they are not executed on the spot, but registered with RDataFrame and executed only when a result is accessed for the first time.; 189 ; 190Make sure to book all transformations and actions before you access the contents of any of the results. This lets RDataFrame accumulate work and then produce all results at the same time, upon first access to any of them.; 191 ; 192The following table shows how analyses based on TTreeReader and TTree::Draw() translate to RDataFrame. Follow the; 193[crash course](#crash-course) to discover more idiomatic and flexible ways to express analyses with RDataFrame.; 194<table>; 195<tr>; 196 <td>; 197 <b>TTreeReader</b>; 198 </td>; 199 <td>; 200 <b>ROOT::RDataFrame</b>; 201 </td>; 202</tr>; 203<tr>; 204 <td>; 205~~~{.cp",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:21636,Performance,perform,performance,21636," result; 345~~~; 346The filter string (which must contain a valid C++ expression) is applied to the specified columns for each event;; 347the name and types of the columns are inferred automatically. The string expression is required to return a `bool`; 348which signals whether the event passes the filter (`true`) or not (`false`).; 349 ; 350You can think of your data as ""flowing"" through the chain of calls, being transformed, filtered and finally used to; 351perform actions. Multiple Filter() calls can be chained one after another.; 352 ; 353Using string filters is nice for simple things, but they are limited to specifying the equivalent of a single return; 354statement or the body of a lambda, so it's cumbersome to use strings with more complex filters. They also add a small; 355runtime overhead, as ROOT needs to just-in-time compile the string into C++ code. When more freedom is required or; 356runtime performance is very important, a C++ callable can be specified instead (a lambda in the following snippet,; 357but it can be any kind of function or even a functor class), together with a list of column names.; 358This snippet is analogous to the one above:; 359~~~{.cpp}; 360RDataFrame d(""myTree"", ""file.root"");; 361auto metCut = [](double x) { return x > 4.; }; // a C++11 lambda function checking ""x > 4""; 362auto c = d.Filter(metCut, {""MET""}).Count();; 363std::cout << *c << std::endl;; 364~~~; 365 ; 366An example of a more complex filter expressed as a string containing C++ code is shown below; 367 ; 368~~~{.cpp}; 369RDataFrame d(""myTree"", ""file.root"");; 370auto df = d.Define(""p"", ""std::array<double, 4> p{px, py, pz}; return p;""); 371 .Filter(""double p2 = 0.0; for (auto&& x : p) p2 += x*x; return sqrt(p2) < 10.0;"");; 372~~~; 373 ; 374The code snippet above defines a column `p` that is a fixed-size array using the component column names and then; 375filters on its magnitude by looping over its elements. It must be noted that the usage of strings to define columns; 37",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:27323,Performance,multi-thread,multi-threading,27323,"# Running on a range of entries; 430It is sometimes necessary to limit the processing of the dataset to a range of entries. For this reason, the RDataFrame; 431offers the concept of ranges as a node of the RDataFrame chain of transformations; this means that filters, columns and; 432actions can be concatenated to and intermixed with Range()s. If a range is specified after a filter, the range will act; 433exclusively on the entries passing the filter -- it will not even count the other entries! The same goes for a Range(); 434hanging from another Range(). Here are some commented examples:; 435~~~{.cpp}; 436RDataFrame d(""myTree"", ""file.root"");; 437// Here we store a dataframe that loops over only the first 30 entries in a variable; 438auto d30 = d.Range(30);; 439// This is how you pick all entries from 15 onwards; 440auto d15on = d.Range(15, 0);; 441// We can specify a stride too, in this case we pick an event every 3; 442auto d15each3 = d.Range(0, 15, 3);; 443~~~; 444Note that ranges are not available when multi-threading is enabled. More information on ranges is available; 445[here](#ranges).; 446 ; 447### Executing multiple actions in the same event loop; 448As a final example let us apply two different cuts on branch ""MET"" and fill two different histograms with the ""pt_v"" of; 449the filtered events.; 450By now, you should be able to easily understand what is happening:; 451~~~{.cpp}; 452RDataFrame d(""treeName"", ""file.root"");; 453auto h1 = d.Filter(""MET > 10"").Histo1D(""pt_v"");; 454auto h2 = d.Histo1D(""pt_v"");; 455h1->Draw(); // event loop is run once here; 456h2->Draw(""SAME""); // no need to run the event loop again; 457~~~; 458RDataFrame executes all above actions by **running the event-loop only once**. The trick is that actions are not; 459executed at the moment they are called, but they are **lazy**, i.e. delayed until the moment one of their results is; 460accessed through the smart pointer. At that time, the event loop is triggered and *all* results are produc",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:31800,Performance,perform,perform,31800,"ram with the ""pt"" of selected particles for each event, Define() can be used to create a column that contains the desired array elements as follows:; 519 ; 520~~~{.cpp}; 521// h is filled with all the elements of `good_pts`, for each event; 522auto h = df.Define(""good_pts"", [](const ROOT::RVecF &pt) { return pt[pt > 0]; }); 523 .Histo1D(""good_pts"");; 524~~~; 525 ; 526And in Python:; 527 ; 528~~~{.py}; 529h = df.Define(""good_pts"", ""pt[pt > 0]"").Histo1D(""good_pts""); 530~~~; 531 ; 532Learn more at ROOT::VecOps::RVec.; 533 ; 534\anchor transformations; 535## Transformations: manipulating data; 536\anchor Filters; 537### Filters; 538A filter is created through a call to `Filter(f, columnList)` or `Filter(filterString)`. In the first overload, `f` can; 539be a function, a lambda expression, a functor class, or any other callable object. It must return a `bool` signalling; 540whether the event has passed the selection (`true`) or not (`false`). It should perform ""read-only"" operations on the; 541columns, and should not have side-effects (e.g. modification of an external or static variable) to ensure correctness; 542when implicit multi-threading is active. The second overload takes a string with a valid C++ expression in which column; 543names are used as variable names (e.g. `Filter(""x[0] + x[1] > 0"")`). This is a convenience feature that comes with a; 544certain runtime overhead: C++ code has to be generated on the fly from this expression before using it in the event; 545loop. See the paragraph about ""Just-in-time compilation"" below for more information.; 546 ; 547RDataFrame only evaluates filters when necessary: if multiple filters are chained one after another, they are executed; 548in order and the first one returning `false` causes the event to be discarded and triggers the processing of the next; 549entry. If multiple actions or transformations depend on the same filter, that filter is not executed multiple times for; 550each entry: after the first access it simply ",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:31978,Performance,multi-thread,multi-threading,31978,"s the desired array elements as follows:; 519 ; 520~~~{.cpp}; 521// h is filled with all the elements of `good_pts`, for each event; 522auto h = df.Define(""good_pts"", [](const ROOT::RVecF &pt) { return pt[pt > 0]; }); 523 .Histo1D(""good_pts"");; 524~~~; 525 ; 526And in Python:; 527 ; 528~~~{.py}; 529h = df.Define(""good_pts"", ""pt[pt > 0]"").Histo1D(""good_pts""); 530~~~; 531 ; 532Learn more at ROOT::VecOps::RVec.; 533 ; 534\anchor transformations; 535## Transformations: manipulating data; 536\anchor Filters; 537### Filters; 538A filter is created through a call to `Filter(f, columnList)` or `Filter(filterString)`. In the first overload, `f` can; 539be a function, a lambda expression, a functor class, or any other callable object. It must return a `bool` signalling; 540whether the event has passed the selection (`true`) or not (`false`). It should perform ""read-only"" operations on the; 541columns, and should not have side-effects (e.g. modification of an external or static variable) to ensure correctness; 542when implicit multi-threading is active. The second overload takes a string with a valid C++ expression in which column; 543names are used as variable names (e.g. `Filter(""x[0] + x[1] > 0"")`). This is a convenience feature that comes with a; 544certain runtime overhead: C++ code has to be generated on the fly from this expression before using it in the event; 545loop. See the paragraph about ""Just-in-time compilation"" below for more information.; 546 ; 547RDataFrame only evaluates filters when necessary: if multiple filters are chained one after another, they are executed; 548in order and the first one returning `false` causes the event to be discarded and triggers the processing of the next; 549entry. If multiple actions or transformations depend on the same filter, that filter is not executed multiple times for; 550each entry: after the first access it simply serves a cached result.; 551 ; 552\anchor named-filters-and-cutflow-reports; 553#### Named filters and cutflo",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:32847,Performance,cache,cached,32847,"e`) or not (`false`). It should perform ""read-only"" operations on the; 541columns, and should not have side-effects (e.g. modification of an external or static variable) to ensure correctness; 542when implicit multi-threading is active. The second overload takes a string with a valid C++ expression in which column; 543names are used as variable names (e.g. `Filter(""x[0] + x[1] > 0"")`). This is a convenience feature that comes with a; 544certain runtime overhead: C++ code has to be generated on the fly from this expression before using it in the event; 545loop. See the paragraph about ""Just-in-time compilation"" below for more information.; 546 ; 547RDataFrame only evaluates filters when necessary: if multiple filters are chained one after another, they are executed; 548in order and the first one returning `false` causes the event to be discarded and triggers the processing of the next; 549entry. If multiple actions or transformations depend on the same filter, that filter is not executed multiple times for; 550each entry: after the first access it simply serves a cached result.; 551 ; 552\anchor named-filters-and-cutflow-reports; 553#### Named filters and cutflow reports; 554An optional string parameter `name` can be passed to the Filter() method to create a **named filter**. Named filters; 555work as usual, but also keep track of how many entries they accept and reject.; 556 ; 557Statistics are retrieved through a call to the Report() method:; 558 ; 559- when Report() is called on the main RDataFrame object, it returns a ROOT::RDF::RResultPtr<RCutFlowReport> relative to all; 560named filters declared up to that point; 561- when called on a specific node (e.g. the result of a Define() or Filter()), it returns a ROOT::RDF::RResultPtr<RCutFlowReport>; 562relative all named filters in the section of the chain between the main RDataFrame and that node (included).; 563 ; 564Stats are stored in the same order as named filters have been added to the graph, and *refer to the",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:33924,Performance,multi-thread,multi-thread,33924,"d-cutflow-reports; 553#### Named filters and cutflow reports; 554An optional string parameter `name` can be passed to the Filter() method to create a **named filter**. Named filters; 555work as usual, but also keep track of how many entries they accept and reject.; 556 ; 557Statistics are retrieved through a call to the Report() method:; 558 ; 559- when Report() is called on the main RDataFrame object, it returns a ROOT::RDF::RResultPtr<RCutFlowReport> relative to all; 560named filters declared up to that point; 561- when called on a specific node (e.g. the result of a Define() or Filter()), it returns a ROOT::RDF::RResultPtr<RCutFlowReport>; 562relative all named filters in the section of the chain between the main RDataFrame and that node (included).; 563 ; 564Stats are stored in the same order as named filters have been added to the graph, and *refer to the latest event-loop*; 565that has been run using the relevant RDataFrame.; 566 ; 567\anchor ranges; 568### Ranges; 569When RDataFrame is not being used in a multi-thread environment (i.e. no call to EnableImplicitMT() was made),; 570Range() transformations are available. These act very much like filters but instead of basing their decision on; 571a filter expression, they rely on `begin`,`end` and `stride` parameters.; 572 ; 573- `begin`: initial entry number considered for this range.; 574- `end`: final entry number (excluded) considered for this range. 0 means that the range goes until the end of the dataset.; 575- `stride`: process one entry of the [begin, end) range every `stride` entries. Must be strictly greater than 0.; 576 ; 577The actual number of entries processed downstream of a Range() node will be `(end - begin)/stride` (or less if less; 578entries than that are available).; 579 ; 580Note that ranges act ""locally"", not based on the global entry count: `Range(10,50)` means ""skip the first 10 entries; 581*that reach this node*, let the next 40 entries pass, then stop processing"". If a range node hangs",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:39919,Performance,perform,performance,39919,"reated via `Define` or; 660available from the input dataset. The action will request values from each column of the list of input columns (either; 661inferred or specified by the user), in order. For example:; 662 ; 663~~~{.cpp}; 664ROOT::RDataFrame df{1};; 665auto df1 = df.Define(""x"", []{ return 11; });; 666auto df2 = df1.Define(""y"", []{ return 22; });; 667auto graph = df2.Graph<int, int>(""x"",""y"");; 668~~~; 669 ; 670The `Graph` action is going to request first the value from column ""x"", then that of column ""y"". Specifically, the order; 671of execution of the operations of nodes in this branch of the computation graph is guaranteed to be top to bottom.; 672 ; 673\anchor distrdf; 674## Distributed execution; 675 ; 676RDataFrame applications can be executed in parallel through distributed computing frameworks on a set of remote machines; 677thanks to the Python package `ROOT.RDF.Experimental.Distributed`. This experimental, **Python-only** package allows to scale the; 678optimized performance RDataFrame can achieve on a single machine to multiple nodes at the same time. It is designed so; 679that different backends can be easily plugged in, currently supporting [Apache Spark](http://spark.apache.org/) and; 680[Dask](https://dask.org/). To make use of distributed RDataFrame, you only need to switch `ROOT.RDataFrame` with; 681the backend-specific `RDataFrame` of your choice, for example:; 682 ; 683~~~{.py}; 684import ROOT; 685 ; 686# Point RDataFrame calls to the Spark specific RDataFrame; 687RDataFrame = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame; 688 ; 689# It still accepts the same constructor arguments as traditional RDataFrame; 690df = RDataFrame(""mytree"", ""myfile.root""); 691 ; 692# Continue the application with the traditional RDataFrame API; 693sum = df.Filter(""x > 10"").Sum(""y""); 694h = df.Histo1D((""name"", ""title"", 10, 0, 10), ""x""); 695 ; 696print(sum.GetValue()); 697h.Draw(); 698~~~; 699 ; 700The main goal of this package is to support running any RDataF",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:47427,Performance,concurren,concurrently,47427,"line.; 813 ; 814### Distributed Snapshot; 815 ; 816The Snapshot operation behaves slightly differently when executed distributedly. First off, it requires the path; 817supplied to the Snapshot call to be accessible from any worker of the cluster and from the client machine (in general; 818it should be provided as an absolute path). Another important difference is that `n` separate files will be produced,; 819where `n` is the number of dataset partitions. As with local RDataFrame, the result of a Snapshot on a distributed; 820RDataFrame is another distributed RDataFrame on which we can define a new computation graph and run more distributed; 821computations.; 822 ; 823### Distributed RunGraphs; 824 ; 825Submitting multiple distributed RDataFrame executions is supported through the RunGraphs function. Similarly to its; 826local counterpart, the function expects an iterable of objects representing an RDataFrame action. Each action will be; 827triggered concurrently to send multiple computation graphs to a distributed cluster at the same time:; 828 ; 829~~~{.py}; 830import ROOT; 831RDataFrame = ROOT.RDF.Experimental.Distributed.Dask.RDataFrame; 832RunGraphs = ROOT.RDF.Experimental.Distributed.RunGraphs; 833 ; 834# Create 3 different dataframes and book an histogram on each one; 835histoproxies = [; 836 RDataFrame(100); 837 .Define(""x"", ""rdfentry_""); 838 .Histo1D((""name"", ""title"", 10, 0, 100), ""x""); 839 for _ in range(4); 840]; 841 ; 842# Execute the 3 computation graphs; 843RunGraphs(histoproxies); 844# Retrieve all the histograms in one go; 845histos = [histoproxy.GetValue() for histoproxy in histoproxies]; 846~~~; 847 ; 848Every distributed backend supports this feature and graphs belonging to different backends can be still triggered with; 849a single call to RunGraphs (e.g. it is possible to send a Spark job and a Dask job at the same time).; 850 ; 851### Histogram models in distributed mode; 852 ; 853When calling a Histo*D operation in distributed mode, remember to",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:51788,Performance,perform,perform,51788,"nary of drawables and callback functions: ; 908For more control, you can create a dictionary where keys are plots and values are corresponding (optional) callback functions. For example:; 909 ; 910~~~{.py}; 911plot_callback_dict = {; 912 graph: set_marker,; 913 h_exp: fit_exp,; 914 tprofile_2d: None; 915}; 916 ; 917LiveVisualize(plot_callback_dict); 918~~~; 919 ; 920- Passing a Dictionary of drawables and callback functions with a global callback function: ; 921You can also combine a dictionary of plots and callbacks with a global callback function:; 922 ; 923~~~{.py}; 924LiveVisualize(plot_callback_dict, write_to_tfile); 925~~~; 926 ; 927\note The allowed operations to pass to LiveVisualize are:; 928 - Histo1D(), Histo2D(), Histo3D(); 929 - Graph(); 930 - Profile1D(), Profile2D(); 931 ; 932\warning The Live Visualization feature is only supported for the Dask backend.; 933 ; 934\anchor parallel-execution; 935## Performance tips and parallel execution; 936As pointed out before in this document, RDataFrame can transparently perform multi-threaded event loops to speed up; 937the execution of its actions. Users have to call ROOT::EnableImplicitMT() *before* constructing the RDataFrame; 938object to indicate that it should take advantage of a pool of worker threads. **Each worker thread processes a distinct; 939subset of entries**, and their partial results are merged before returning the final values to the user.; 940There are no guarantees on the order in which threads will process the batches of entries.; 941In particular, note that this means that, for multi-thread event loops, there is no; 942guarantee on the order in which Snapshot() will _write_ entries: they could be scrambled with respect to the input dataset. The values of the special `rdfentry_` column will also not correspond to the entry numbers in the input dataset (e.g. TChain) in multi-thread runs.; 943 ; 944\warning By default, RDataFrame will use as many threads as the hardware supports, using up **all",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:51796,Performance,multi-thread,multi-threaded,51796,"nary of drawables and callback functions: ; 908For more control, you can create a dictionary where keys are plots and values are corresponding (optional) callback functions. For example:; 909 ; 910~~~{.py}; 911plot_callback_dict = {; 912 graph: set_marker,; 913 h_exp: fit_exp,; 914 tprofile_2d: None; 915}; 916 ; 917LiveVisualize(plot_callback_dict); 918~~~; 919 ; 920- Passing a Dictionary of drawables and callback functions with a global callback function: ; 921You can also combine a dictionary of plots and callbacks with a global callback function:; 922 ; 923~~~{.py}; 924LiveVisualize(plot_callback_dict, write_to_tfile); 925~~~; 926 ; 927\note The allowed operations to pass to LiveVisualize are:; 928 - Histo1D(), Histo2D(), Histo3D(); 929 - Graph(); 930 - Profile1D(), Profile2D(); 931 ; 932\warning The Live Visualization feature is only supported for the Dask backend.; 933 ; 934\anchor parallel-execution; 935## Performance tips and parallel execution; 936As pointed out before in this document, RDataFrame can transparently perform multi-threaded event loops to speed up; 937the execution of its actions. Users have to call ROOT::EnableImplicitMT() *before* constructing the RDataFrame; 938object to indicate that it should take advantage of a pool of worker threads. **Each worker thread processes a distinct; 939subset of entries**, and their partial results are merged before returning the final values to the user.; 940There are no guarantees on the order in which threads will process the batches of entries.; 941In particular, note that this means that, for multi-thread event loops, there is no; 942guarantee on the order in which Snapshot() will _write_ entries: they could be scrambled with respect to the input dataset. The values of the special `rdfentry_` column will also not correspond to the entry numbers in the input dataset (e.g. TChain) in multi-thread runs.; 943 ; 944\warning By default, RDataFrame will use as many threads as the hardware supports, using up **all",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:52328,Performance,multi-thread,multi-thread,52328,"; 926 ; 927\note The allowed operations to pass to LiveVisualize are:; 928 - Histo1D(), Histo2D(), Histo3D(); 929 - Graph(); 930 - Profile1D(), Profile2D(); 931 ; 932\warning The Live Visualization feature is only supported for the Dask backend.; 933 ; 934\anchor parallel-execution; 935## Performance tips and parallel execution; 936As pointed out before in this document, RDataFrame can transparently perform multi-threaded event loops to speed up; 937the execution of its actions. Users have to call ROOT::EnableImplicitMT() *before* constructing the RDataFrame; 938object to indicate that it should take advantage of a pool of worker threads. **Each worker thread processes a distinct; 939subset of entries**, and their partial results are merged before returning the final values to the user.; 940There are no guarantees on the order in which threads will process the batches of entries.; 941In particular, note that this means that, for multi-thread event loops, there is no; 942guarantee on the order in which Snapshot() will _write_ entries: they could be scrambled with respect to the input dataset. The values of the special `rdfentry_` column will also not correspond to the entry numbers in the input dataset (e.g. TChain) in multi-thread runs.; 943 ; 944\warning By default, RDataFrame will use as many threads as the hardware supports, using up **all** the resources on; 945a machine. This might be undesirable on shared computing resources such as a batch cluster. Therefore, when running on shared computing resources, use; 946~~~{.cpp}; 947ROOT::EnableImplicitMT(i); 948~~~; 949replacing `i` with the number of CPUs/slots that were allocated for this job.; 950 ; 951### Thread-safety of user-defined expressions; 952RDataFrame operations such as Histo1D() or Snapshot() are guaranteed to work correctly in multi-thread event loops.; 953User-defined expressions, such as strings or lambdas passed to Filter(), Define(), Foreach(), Reduce() or Aggregate(); 954will have to be thread-sa",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:52623,Performance,multi-thread,multi-thread,52623,"end.; 933 ; 934\anchor parallel-execution; 935## Performance tips and parallel execution; 936As pointed out before in this document, RDataFrame can transparently perform multi-threaded event loops to speed up; 937the execution of its actions. Users have to call ROOT::EnableImplicitMT() *before* constructing the RDataFrame; 938object to indicate that it should take advantage of a pool of worker threads. **Each worker thread processes a distinct; 939subset of entries**, and their partial results are merged before returning the final values to the user.; 940There are no guarantees on the order in which threads will process the batches of entries.; 941In particular, note that this means that, for multi-thread event loops, there is no; 942guarantee on the order in which Snapshot() will _write_ entries: they could be scrambled with respect to the input dataset. The values of the special `rdfentry_` column will also not correspond to the entry numbers in the input dataset (e.g. TChain) in multi-thread runs.; 943 ; 944\warning By default, RDataFrame will use as many threads as the hardware supports, using up **all** the resources on; 945a machine. This might be undesirable on shared computing resources such as a batch cluster. Therefore, when running on shared computing resources, use; 946~~~{.cpp}; 947ROOT::EnableImplicitMT(i); 948~~~; 949replacing `i` with the number of CPUs/slots that were allocated for this job.; 950 ; 951### Thread-safety of user-defined expressions; 952RDataFrame operations such as Histo1D() or Snapshot() are guaranteed to work correctly in multi-thread event loops.; 953User-defined expressions, such as strings or lambdas passed to Filter(), Define(), Foreach(), Reduce() or Aggregate(); 954will have to be thread-safe, i.e. it should be possible to call them concurrently from different threads.; 955 ; 956Note that simple Filter() and Define() transformations will inherently satisfy this requirement: Filter() / Define(); 957expressions will often be *pu",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:53208,Performance,multi-thread,multi-thread,53208,"turning the final values to the user.; 940There are no guarantees on the order in which threads will process the batches of entries.; 941In particular, note that this means that, for multi-thread event loops, there is no; 942guarantee on the order in which Snapshot() will _write_ entries: they could be scrambled with respect to the input dataset. The values of the special `rdfentry_` column will also not correspond to the entry numbers in the input dataset (e.g. TChain) in multi-thread runs.; 943 ; 944\warning By default, RDataFrame will use as many threads as the hardware supports, using up **all** the resources on; 945a machine. This might be undesirable on shared computing resources such as a batch cluster. Therefore, when running on shared computing resources, use; 946~~~{.cpp}; 947ROOT::EnableImplicitMT(i); 948~~~; 949replacing `i` with the number of CPUs/slots that were allocated for this job.; 950 ; 951### Thread-safety of user-defined expressions; 952RDataFrame operations such as Histo1D() or Snapshot() are guaranteed to work correctly in multi-thread event loops.; 953User-defined expressions, such as strings or lambdas passed to Filter(), Define(), Foreach(), Reduce() or Aggregate(); 954will have to be thread-safe, i.e. it should be possible to call them concurrently from different threads.; 955 ; 956Note that simple Filter() and Define() transformations will inherently satisfy this requirement: Filter() / Define(); 957expressions will often be *pure* in the functional programming sense (no side-effects, no dependency on external state),; 958which eliminates all risks of race conditions.; 959 ; 960In order to facilitate writing of thread-safe operations, some RDataFrame features such as Foreach(), Define() or \link ROOT::RDF::RResultPtr::OnPartialResult OnPartialResult()\endlink; 961offer thread-aware counterparts (ForeachSlot(), DefineSlot(), \link ROOT::RDF::RResultPtr::OnPartialResultSlot OnPartialResultSlot()\endlink): their only difference is that they",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:53429,Performance,concurren,concurrently,53429,"ries: they could be scrambled with respect to the input dataset. The values of the special `rdfentry_` column will also not correspond to the entry numbers in the input dataset (e.g. TChain) in multi-thread runs.; 943 ; 944\warning By default, RDataFrame will use as many threads as the hardware supports, using up **all** the resources on; 945a machine. This might be undesirable on shared computing resources such as a batch cluster. Therefore, when running on shared computing resources, use; 946~~~{.cpp}; 947ROOT::EnableImplicitMT(i); 948~~~; 949replacing `i` with the number of CPUs/slots that were allocated for this job.; 950 ; 951### Thread-safety of user-defined expressions; 952RDataFrame operations such as Histo1D() or Snapshot() are guaranteed to work correctly in multi-thread event loops.; 953User-defined expressions, such as strings or lambdas passed to Filter(), Define(), Foreach(), Reduce() or Aggregate(); 954will have to be thread-safe, i.e. it should be possible to call them concurrently from different threads.; 955 ; 956Note that simple Filter() and Define() transformations will inherently satisfy this requirement: Filter() / Define(); 957expressions will often be *pure* in the functional programming sense (no side-effects, no dependency on external state),; 958which eliminates all risks of race conditions.; 959 ; 960In order to facilitate writing of thread-safe operations, some RDataFrame features such as Foreach(), Define() or \link ROOT::RDF::RResultPtr::OnPartialResult OnPartialResult()\endlink; 961offer thread-aware counterparts (ForeachSlot(), DefineSlot(), \link ROOT::RDF::RResultPtr::OnPartialResultSlot OnPartialResultSlot()\endlink): their only difference is that they; 962will pass an extra `slot` argument (an unsigned integer) to the user-defined expression. When calling user-defined code; 963concurrently, RDataFrame guarantees that different threads will employ different values of the `slot` parameter,; 964where `slot` will be a number between ",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:53752,Performance,race condition,race conditions,53752,"in) in multi-thread runs.; 943 ; 944\warning By default, RDataFrame will use as many threads as the hardware supports, using up **all** the resources on; 945a machine. This might be undesirable on shared computing resources such as a batch cluster. Therefore, when running on shared computing resources, use; 946~~~{.cpp}; 947ROOT::EnableImplicitMT(i); 948~~~; 949replacing `i` with the number of CPUs/slots that were allocated for this job.; 950 ; 951### Thread-safety of user-defined expressions; 952RDataFrame operations such as Histo1D() or Snapshot() are guaranteed to work correctly in multi-thread event loops.; 953User-defined expressions, such as strings or lambdas passed to Filter(), Define(), Foreach(), Reduce() or Aggregate(); 954will have to be thread-safe, i.e. it should be possible to call them concurrently from different threads.; 955 ; 956Note that simple Filter() and Define() transformations will inherently satisfy this requirement: Filter() / Define(); 957expressions will often be *pure* in the functional programming sense (no side-effects, no dependency on external state),; 958which eliminates all risks of race conditions.; 959 ; 960In order to facilitate writing of thread-safe operations, some RDataFrame features such as Foreach(), Define() or \link ROOT::RDF::RResultPtr::OnPartialResult OnPartialResult()\endlink; 961offer thread-aware counterparts (ForeachSlot(), DefineSlot(), \link ROOT::RDF::RResultPtr::OnPartialResultSlot OnPartialResultSlot()\endlink): their only difference is that they; 962will pass an extra `slot` argument (an unsigned integer) to the user-defined expression. When calling user-defined code; 963concurrently, RDataFrame guarantees that different threads will employ different values of the `slot` parameter,; 964where `slot` will be a number between 0 and `GetNSlots() - 1`.; 965In other words, within a slot, computation runs sequentially and events are processed sequentially.; 966Note that the same slot might be associated to differen",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:55404,Performance,concurren,concurrently,55404,"ter,; 964where `slot` will be a number between 0 and `GetNSlots() - 1`.; 965In other words, within a slot, computation runs sequentially and events are processed sequentially.; 966Note that the same slot might be associated to different threads over the course of a single event loop, but two threads; 967will never receive the same slot at the same time.; 968This extra parameter might facilitate writing safe parallel code by having each thread write/modify a different; 969processing slot, e.g. a different element of a list. See [here](#generic-actions) for an example usage of ForeachSlot().; 970 ; 971### Parallel execution of multiple RDataFrame event loops; 972A complex analysis may require multiple separate RDataFrame computation graphs to produce all desired results. This poses the challenge that the; 973event loops of each computation graph can be parallelized, but the different loops run sequentially, one after the other.; 974On many-core architectures it might be desirable to run different event loops concurrently to improve resource usage.; 975ROOT::RDF::RunGraphs() allows running multiple RDataFrame event loops concurrently:; 976~~~{.cpp}; 977ROOT::EnableImplicitMT();; 978ROOT::RDataFrame df1(""tree1"", ""f1.root"");; 979ROOT::RDataFrame df2(""tree2"", ""f2.root"");; 980auto histo1 = df1.Histo1D(""x"");; 981auto histo2 = df2.Histo1D(""y"");; 982 ; 983// just accessing result pointers, the event loops of separate RDataFrames run one after the other; 984histo1->Draw(); // runs first multi-thread event loop; 985histo2->Draw(); // runs second multi-thread event loop; 986 ; 987// alternatively, with ROOT::RDF::RunGraphs, event loops for separate computation graphs can run concurrently; 988ROOT::RDF::RunGraphs({histo1, histo2});; 989histo1->Draw(); // results can then be used as usual; 990~~~; 991 ; 992### Performance considerations; 993 ; 994To obtain the maximum performance out of RDataFrame, make sure to avoid just-in-time compiled versions of transformations and actions if",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:55518,Performance,concurren,concurrently,55518,"putation runs sequentially and events are processed sequentially.; 966Note that the same slot might be associated to different threads over the course of a single event loop, but two threads; 967will never receive the same slot at the same time.; 968This extra parameter might facilitate writing safe parallel code by having each thread write/modify a different; 969processing slot, e.g. a different element of a list. See [here](#generic-actions) for an example usage of ForeachSlot().; 970 ; 971### Parallel execution of multiple RDataFrame event loops; 972A complex analysis may require multiple separate RDataFrame computation graphs to produce all desired results. This poses the challenge that the; 973event loops of each computation graph can be parallelized, but the different loops run sequentially, one after the other.; 974On many-core architectures it might be desirable to run different event loops concurrently to improve resource usage.; 975ROOT::RDF::RunGraphs() allows running multiple RDataFrame event loops concurrently:; 976~~~{.cpp}; 977ROOT::EnableImplicitMT();; 978ROOT::RDataFrame df1(""tree1"", ""f1.root"");; 979ROOT::RDataFrame df2(""tree2"", ""f2.root"");; 980auto histo1 = df1.Histo1D(""x"");; 981auto histo2 = df2.Histo1D(""y"");; 982 ; 983// just accessing result pointers, the event loops of separate RDataFrames run one after the other; 984histo1->Draw(); // runs first multi-thread event loop; 985histo2->Draw(); // runs second multi-thread event loop; 986 ; 987// alternatively, with ROOT::RDF::RunGraphs, event loops for separate computation graphs can run concurrently; 988ROOT::RDF::RunGraphs({histo1, histo2});; 989histo1->Draw(); // results can then be used as usual; 990~~~; 991 ; 992### Performance considerations; 993 ; 994To obtain the maximum performance out of RDataFrame, make sure to avoid just-in-time compiled versions of transformations and actions if at all possible.; 995For instance, `Filter(""x > 0"")` requires just-in-time compilation of the corresponding C",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:55883,Performance,multi-thread,multi-thread,55883,"nalysis may require multiple separate RDataFrame computation graphs to produce all desired results. This poses the challenge that the; 973event loops of each computation graph can be parallelized, but the different loops run sequentially, one after the other.; 974On many-core architectures it might be desirable to run different event loops concurrently to improve resource usage.; 975ROOT::RDF::RunGraphs() allows running multiple RDataFrame event loops concurrently:; 976~~~{.cpp}; 977ROOT::EnableImplicitMT();; 978ROOT::RDataFrame df1(""tree1"", ""f1.root"");; 979ROOT::RDataFrame df2(""tree2"", ""f2.root"");; 980auto histo1 = df1.Histo1D(""x"");; 981auto histo2 = df2.Histo1D(""y"");; 982 ; 983// just accessing result pointers, the event loops of separate RDataFrames run one after the other; 984histo1->Draw(); // runs first multi-thread event loop; 985histo2->Draw(); // runs second multi-thread event loop; 986 ; 987// alternatively, with ROOT::RDF::RunGraphs, event loops for separate computation graphs can run concurrently; 988ROOT::RDF::RunGraphs({histo1, histo2});; 989histo1->Draw(); // results can then be used as usual; 990~~~; 991 ; 992### Performance considerations; 993 ; 994To obtain the maximum performance out of RDataFrame, make sure to avoid just-in-time compiled versions of transformations and actions if at all possible.; 995For instance, `Filter(""x > 0"")` requires just-in-time compilation of the corresponding C++ logic, while the equivalent `Filter([](float x) { return x > 0.; }, {""x""})` does not.; 996Similarly, `Histo1D(""x"")` requires just-in-time compilation after the type of `x` is retrieved from the dataset, while `Histo1D<float>(""x"")` does not; the latter spelling; 997should be preferred for performance-critical applications.; 998 ; 999Python applications cannot easily specify template parameters or pass C++ callables to RDataFrame.; 1000See [Efficient analysis in Python](#python) for possible ways to speed up hot paths in this case.; 1001 ; 1002Just-in-time compila",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:55942,Performance,multi-thread,multi-thread,55942,"nalysis may require multiple separate RDataFrame computation graphs to produce all desired results. This poses the challenge that the; 973event loops of each computation graph can be parallelized, but the different loops run sequentially, one after the other.; 974On many-core architectures it might be desirable to run different event loops concurrently to improve resource usage.; 975ROOT::RDF::RunGraphs() allows running multiple RDataFrame event loops concurrently:; 976~~~{.cpp}; 977ROOT::EnableImplicitMT();; 978ROOT::RDataFrame df1(""tree1"", ""f1.root"");; 979ROOT::RDataFrame df2(""tree2"", ""f2.root"");; 980auto histo1 = df1.Histo1D(""x"");; 981auto histo2 = df2.Histo1D(""y"");; 982 ; 983// just accessing result pointers, the event loops of separate RDataFrames run one after the other; 984histo1->Draw(); // runs first multi-thread event loop; 985histo2->Draw(); // runs second multi-thread event loop; 986 ; 987// alternatively, with ROOT::RDF::RunGraphs, event loops for separate computation graphs can run concurrently; 988ROOT::RDF::RunGraphs({histo1, histo2});; 989histo1->Draw(); // results can then be used as usual; 990~~~; 991 ; 992### Performance considerations; 993 ; 994To obtain the maximum performance out of RDataFrame, make sure to avoid just-in-time compiled versions of transformations and actions if at all possible.; 995For instance, `Filter(""x > 0"")` requires just-in-time compilation of the corresponding C++ logic, while the equivalent `Filter([](float x) { return x > 0.; }, {""x""})` does not.; 996Similarly, `Histo1D(""x"")` requires just-in-time compilation after the type of `x` is retrieved from the dataset, while `Histo1D<float>(""x"")` does not; the latter spelling; 997should be preferred for performance-critical applications.; 998 ; 999Python applications cannot easily specify template parameters or pass C++ callables to RDataFrame.; 1000See [Efficient analysis in Python](#python) for possible ways to speed up hot paths in this case.; 1001 ; 1002Just-in-time compila",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:56073,Performance,concurren,concurrently,56073,"nalysis may require multiple separate RDataFrame computation graphs to produce all desired results. This poses the challenge that the; 973event loops of each computation graph can be parallelized, but the different loops run sequentially, one after the other.; 974On many-core architectures it might be desirable to run different event loops concurrently to improve resource usage.; 975ROOT::RDF::RunGraphs() allows running multiple RDataFrame event loops concurrently:; 976~~~{.cpp}; 977ROOT::EnableImplicitMT();; 978ROOT::RDataFrame df1(""tree1"", ""f1.root"");; 979ROOT::RDataFrame df2(""tree2"", ""f2.root"");; 980auto histo1 = df1.Histo1D(""x"");; 981auto histo2 = df2.Histo1D(""y"");; 982 ; 983// just accessing result pointers, the event loops of separate RDataFrames run one after the other; 984histo1->Draw(); // runs first multi-thread event loop; 985histo2->Draw(); // runs second multi-thread event loop; 986 ; 987// alternatively, with ROOT::RDF::RunGraphs, event loops for separate computation graphs can run concurrently; 988ROOT::RDF::RunGraphs({histo1, histo2});; 989histo1->Draw(); // results can then be used as usual; 990~~~; 991 ; 992### Performance considerations; 993 ; 994To obtain the maximum performance out of RDataFrame, make sure to avoid just-in-time compiled versions of transformations and actions if at all possible.; 995For instance, `Filter(""x > 0"")` requires just-in-time compilation of the corresponding C++ logic, while the equivalent `Filter([](float x) { return x > 0.; }, {""x""})` does not.; 996Similarly, `Histo1D(""x"")` requires just-in-time compilation after the type of `x` is retrieved from the dataset, while `Histo1D<float>(""x"")` does not; the latter spelling; 997should be preferred for performance-critical applications.; 998 ; 999Python applications cannot easily specify template parameters or pass C++ callables to RDataFrame.; 1000See [Efficient analysis in Python](#python) for possible ways to speed up hot paths in this case.; 1001 ; 1002Just-in-time compila",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:56268,Performance,perform,performance,56268,"nalysis may require multiple separate RDataFrame computation graphs to produce all desired results. This poses the challenge that the; 973event loops of each computation graph can be parallelized, but the different loops run sequentially, one after the other.; 974On many-core architectures it might be desirable to run different event loops concurrently to improve resource usage.; 975ROOT::RDF::RunGraphs() allows running multiple RDataFrame event loops concurrently:; 976~~~{.cpp}; 977ROOT::EnableImplicitMT();; 978ROOT::RDataFrame df1(""tree1"", ""f1.root"");; 979ROOT::RDataFrame df2(""tree2"", ""f2.root"");; 980auto histo1 = df1.Histo1D(""x"");; 981auto histo2 = df2.Histo1D(""y"");; 982 ; 983// just accessing result pointers, the event loops of separate RDataFrames run one after the other; 984histo1->Draw(); // runs first multi-thread event loop; 985histo2->Draw(); // runs second multi-thread event loop; 986 ; 987// alternatively, with ROOT::RDF::RunGraphs, event loops for separate computation graphs can run concurrently; 988ROOT::RDF::RunGraphs({histo1, histo2});; 989histo1->Draw(); // results can then be used as usual; 990~~~; 991 ; 992### Performance considerations; 993 ; 994To obtain the maximum performance out of RDataFrame, make sure to avoid just-in-time compiled versions of transformations and actions if at all possible.; 995For instance, `Filter(""x > 0"")` requires just-in-time compilation of the corresponding C++ logic, while the equivalent `Filter([](float x) { return x > 0.; }, {""x""})` does not.; 996Similarly, `Histo1D(""x"")` requires just-in-time compilation after the type of `x` is retrieved from the dataset, while `Histo1D<float>(""x"")` does not; the latter spelling; 997should be preferred for performance-critical applications.; 998 ; 999Python applications cannot easily specify template parameters or pass C++ callables to RDataFrame.; 1000See [Efficient analysis in Python](#python) for possible ways to speed up hot paths in this case.; 1001 ; 1002Just-in-time compila",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:56784,Performance,perform,performance-critical,56784,"x"");; 981auto histo2 = df2.Histo1D(""y"");; 982 ; 983// just accessing result pointers, the event loops of separate RDataFrames run one after the other; 984histo1->Draw(); // runs first multi-thread event loop; 985histo2->Draw(); // runs second multi-thread event loop; 986 ; 987// alternatively, with ROOT::RDF::RunGraphs, event loops for separate computation graphs can run concurrently; 988ROOT::RDF::RunGraphs({histo1, histo2});; 989histo1->Draw(); // results can then be used as usual; 990~~~; 991 ; 992### Performance considerations; 993 ; 994To obtain the maximum performance out of RDataFrame, make sure to avoid just-in-time compiled versions of transformations and actions if at all possible.; 995For instance, `Filter(""x > 0"")` requires just-in-time compilation of the corresponding C++ logic, while the equivalent `Filter([](float x) { return x > 0.; }, {""x""})` does not.; 996Similarly, `Histo1D(""x"")` requires just-in-time compilation after the type of `x` is retrieved from the dataset, while `Histo1D<float>(""x"")` does not; the latter spelling; 997should be preferred for performance-critical applications.; 998 ; 999Python applications cannot easily specify template parameters or pass C++ callables to RDataFrame.; 1000See [Efficient analysis in Python](#python) for possible ways to speed up hot paths in this case.; 1001 ; 1002Just-in-time compilation happens once, right before starting an event loop. To reduce the runtime cost of this step, make sure to book all operations *for all RDataFrame computation graphs*; 1003before the first event loop is triggered: just-in-time compilation will happen once for all code required to be generated up to that point, also across different computation graphs.; 1004 ; 1005Also make sure not to count the just-in-time compilation time (which happens once before the event loop and does not depend on the size of the dataset) as part of the event loop runtime (which scales with the size of the dataset). RDataFrame has an experimental loggi",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:67000,Performance,perform,performance,67000,"er, in general each dataframe node will have a different C++ type,; 1132which includes all available compile-time information about what that node does. One way to cope with this complication; 1133is to use template functions and/or C++14 auto return types:; 1134~~~{.cpp}; 1135template <typename RDF>; 1136auto ApplySomeFilters(RDF df); 1137{; 1138 return df.Filter(""x > 0"").Filter([](int y) { return y < 0; }, {""y""});; 1139}; 1140~~~; 1141 ; 1142A possibly simpler, C++11-compatible alternative is to take advantage of the fact that any dataframe node can be; 1143converted (implicitly or via an explicit cast) to the common type ROOT::RDF::RNode:; 1144~~~{.cpp}; 1145// a function that conditionally adds a Range to an RDataFrame node.; 1146RNode MaybeAddRange(RNode df, bool mustAddRange); 1147{; 1148 return mustAddRange ? df.Range(1) : df;; 1149}; 1150// use as :; 1151ROOT::RDataFrame df(10);; 1152auto maybeRangedDF = MaybeAddRange(df, true);; 1153~~~; 1154 ; 1155The conversion to ROOT::RDF::RNode is cheap, but it will introduce an extra virtual call during the RDataFrame event; 1156loop (in most cases, the resulting performance impact should be negligible). Python users can perform the conversion with the helper function `ROOT.RDF.AsRNode`.; 1157 ; 1158\anchor RDFCollections; 1159### Storing RDataFrame objects in collections; 1160 ; 1161ROOT::RDF::RNode also makes it simple to store RDataFrame nodes in collections, e.g. a `std::vector<RNode>` or a `std::map<std::string, RNode>`:; 1162 ; 1163~~~{.cpp}; 1164std::vector<ROOT::RDF::RNode> dfs;; 1165dfs.emplace_back(ROOT::RDataFrame(10));; 1166dfs.emplace_back(dfs[0].Define(""x"", ""42.f""));; 1167~~~; 1168 ; 1169\anchor callbacks; 1170### Executing callbacks every N events; 1171It's possible to schedule execution of arbitrary functions (callbacks) during the event loop.; 1172Callbacks can be used e.g. to inspect partial results of the analysis while the event loop is running,; 1173drawing a partially-filled histogram every time a",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:67059,Performance,perform,perform,67059," template functions and/or C++14 auto return types:; 1134~~~{.cpp}; 1135template <typename RDF>; 1136auto ApplySomeFilters(RDF df); 1137{; 1138 return df.Filter(""x > 0"").Filter([](int y) { return y < 0; }, {""y""});; 1139}; 1140~~~; 1141 ; 1142A possibly simpler, C++11-compatible alternative is to take advantage of the fact that any dataframe node can be; 1143converted (implicitly or via an explicit cast) to the common type ROOT::RDF::RNode:; 1144~~~{.cpp}; 1145// a function that conditionally adds a Range to an RDataFrame node.; 1146RNode MaybeAddRange(RNode df, bool mustAddRange); 1147{; 1148 return mustAddRange ? df.Range(1) : df;; 1149}; 1150// use as :; 1151ROOT::RDataFrame df(10);; 1152auto maybeRangedDF = MaybeAddRange(df, true);; 1153~~~; 1154 ; 1155The conversion to ROOT::RDF::RNode is cheap, but it will introduce an extra virtual call during the RDataFrame event; 1156loop (in most cases, the resulting performance impact should be negligible). Python users can perform the conversion with the helper function `ROOT.RDF.AsRNode`.; 1157 ; 1158\anchor RDFCollections; 1159### Storing RDataFrame objects in collections; 1160 ; 1161ROOT::RDF::RNode also makes it simple to store RDataFrame nodes in collections, e.g. a `std::vector<RNode>` or a `std::map<std::string, RNode>`:; 1162 ; 1163~~~{.cpp}; 1164std::vector<ROOT::RDF::RNode> dfs;; 1165dfs.emplace_back(ROOT::RDataFrame(10));; 1166dfs.emplace_back(dfs[0].Define(""x"", ""42.f""));; 1167~~~; 1168 ; 1169\anchor callbacks; 1170### Executing callbacks every N events; 1171It's possible to schedule execution of arbitrary functions (callbacks) during the event loop.; 1172Callbacks can be used e.g. to inspect partial results of the analysis while the event loop is running,; 1173drawing a partially-filled histogram every time a certain number of new entries is processed, or; 1174displaying a progress bar while the event loop runs.; 1175 ; 1176For example one can draw an up-to-date version of a result histogram every 100 entries ",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:70581,Performance,multi-thread,multi-thread,70581,"ouble b2) { return b2 > 0; }, {""b2""}) // we can still specify non-default column lists; 1206 .Min(); // returns the minimum value of ""b1"" for the filtered entries; 1207~~~; 1208 ; 1209\anchor helper-cols; 1210### Special helper columns: rdfentry_ and rdfslot_; 1211Every instance of RDataFrame is created with two special columns called `rdfentry_` and `rdfslot_`. The `rdfentry_`; 1212column is of type `ULong64_t` and it holds the current entry number while `rdfslot_` is an `unsigned int`; 1213holding the index of the current data processing slot.; 1214For backwards compatibility reasons, the names `tdfentry_` and `tdfslot_` are also accepted.; 1215These columns are ignored by operations such as [Cache](classROOT_1_1RDF_1_1RInterface.html#aaaa0a7bb8eb21315d8daa08c3e25f6c9); 1216or [Snapshot](classROOT_1_1RDF_1_1RInterface.html#a233b7723e498967f4340705d2c4db7f8).; 1217 ; 1218\warning Note that in multi-thread event loops the values of `rdfentry_` _do not_ correspond to what would be the entry numbers; 1219of a TChain constructed over the same set of ROOT files, as the entries are processed in an unspecified order.; 1220 ; 1221\anchor jitting; 1222### Just-in-time compilation: column type inference and explicit declaration of column types; 1223C++ is a statically typed language: all types must be known at compile-time. This includes the types of the TTree; 1224branches we want to work on. For filters, defined columns and some of the actions, **column types are deduced from the; 1225signature** of the relevant filter function/temporary column expression/action function:; 1226~~~{.cpp}; 1227// here b1 is deduced to be `int` and b2 to be `double`; 1228df.Filter([](int x, double y) { return x > 0 && y < 0.; }, {""b1"", ""b2""});; 1229~~~; 1230If we specify an incorrect type for one of the columns, an exception with an informative message will be thrown at; 1231runtime, when the column value is actually read from the dataset: RDataFrame detects type mismatches. The same would; 1",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:72740,Performance,perform,performance,72740,"e is actually read from the dataset: RDataFrame detects type mismatches. The same would; 1232happen if we swapped the order of ""b1"" and ""b2"" in the column list passed to Filter().; 1233 ; 1234Certain actions, on the other hand, do not take a function as argument (e.g. Histo1D()), so we cannot deduce the type of; 1235the column at compile-time. In this case **RDataFrame infers the type of the column** from the TTree itself. This; 1236is why we never needed to specify the column types for all actions in the above snippets.; 1237 ; 1238When the column type is not a common one such as `int`, `double`, `char` or `float` it is nonetheless good practice to; 1239specify it as a template parameter to the action itself, like this:; 1240~~~{.cpp}; 1241df.Histo1D(""b1""); // OK, the type of ""b1"" is deduced at runtime; 1242df.Min<MyNumber_t>(""myObject""); // OK, ""myObject"" is deduced to be of type `MyNumber_t`; 1243~~~; 1244 ; 1245Deducing types at runtime requires the just-in-time compilation of the relevant actions, which has a small runtime; 1246overhead, so specifying the type of the columns as template parameters to the action is good practice when performance is a goal.; 1247 ; 1248When strings are passed as expressions to Filter() or Define(), fundamental types are passed as constants. This avoids certaincommon mistakes such as typing `x = 0` rather than `x == 0`:; 1249 ; 1250~~~{.cpp}; 1251// this throws an error (note the typo); 1252df.Define(""x"", ""0"").Filter(""x = 0"");; 1253~~~; 1254 ; 1255\anchor generic-actions; 1256### User-defined custom actions; 1257RDataFrame strives to offer a comprehensive set of standard actions that can be performed on each event. At the same; 1258time, it allows users to inject their own action code to perform arbitrarily complex data reductions.; 1259 ; 1260#### Implementing custom actions with Book(); 1261 ; 1262Through the Book() method, users can implement a custom action and have access to the same features; 1263that built-in RDataFrame acti",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:73238,Performance,perform,performed,73238,"n one such as `int`, `double`, `char` or `float` it is nonetheless good practice to; 1239specify it as a template parameter to the action itself, like this:; 1240~~~{.cpp}; 1241df.Histo1D(""b1""); // OK, the type of ""b1"" is deduced at runtime; 1242df.Min<MyNumber_t>(""myObject""); // OK, ""myObject"" is deduced to be of type `MyNumber_t`; 1243~~~; 1244 ; 1245Deducing types at runtime requires the just-in-time compilation of the relevant actions, which has a small runtime; 1246overhead, so specifying the type of the columns as template parameters to the action is good practice when performance is a goal.; 1247 ; 1248When strings are passed as expressions to Filter() or Define(), fundamental types are passed as constants. This avoids certaincommon mistakes such as typing `x = 0` rather than `x == 0`:; 1249 ; 1250~~~{.cpp}; 1251// this throws an error (note the typo); 1252df.Define(""x"", ""0"").Filter(""x = 0"");; 1253~~~; 1254 ; 1255\anchor generic-actions; 1256### User-defined custom actions; 1257RDataFrame strives to offer a comprehensive set of standard actions that can be performed on each event. At the same; 1258time, it allows users to inject their own action code to perform arbitrarily complex data reductions.; 1259 ; 1260#### Implementing custom actions with Book(); 1261 ; 1262Through the Book() method, users can implement a custom action and have access to the same features; 1263that built-in RDataFrame actions have, e.g. hooks to events related to the start, end and execution of the; 1264event loop, or the possibility to return a lazy RResultPtr to an arbitrary type of result:; 1265 ; 1266~~~{.cpp}; 1267#include <ROOT/RDataFrame.hxx>; 1268#include <memory>; 1269 ; 1270class MyCounter : public ROOT::Detail::RDF::RActionImpl<MyCounter> {; 1271 std::shared_ptr<int> fFinalResult = std::make_shared<int>(0);; 1272 std::vector<int> fPerThreadResults;; 1273 ; 1274public:; 1275 // We use a public type alias to advertise the type of the result of this action; 1276 using Result_t",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:73337,Performance,perform,perform,73337,"~~{.cpp}; 1241df.Histo1D(""b1""); // OK, the type of ""b1"" is deduced at runtime; 1242df.Min<MyNumber_t>(""myObject""); // OK, ""myObject"" is deduced to be of type `MyNumber_t`; 1243~~~; 1244 ; 1245Deducing types at runtime requires the just-in-time compilation of the relevant actions, which has a small runtime; 1246overhead, so specifying the type of the columns as template parameters to the action is good practice when performance is a goal.; 1247 ; 1248When strings are passed as expressions to Filter() or Define(), fundamental types are passed as constants. This avoids certaincommon mistakes such as typing `x = 0` rather than `x == 0`:; 1249 ; 1250~~~{.cpp}; 1251// this throws an error (note the typo); 1252df.Define(""x"", ""0"").Filter(""x = 0"");; 1253~~~; 1254 ; 1255\anchor generic-actions; 1256### User-defined custom actions; 1257RDataFrame strives to offer a comprehensive set of standard actions that can be performed on each event. At the same; 1258time, it allows users to inject their own action code to perform arbitrarily complex data reductions.; 1259 ; 1260#### Implementing custom actions with Book(); 1261 ; 1262Through the Book() method, users can implement a custom action and have access to the same features; 1263that built-in RDataFrame actions have, e.g. hooks to events related to the start, end and execution of the; 1264event loop, or the possibility to return a lazy RResultPtr to an arbitrary type of result:; 1265 ; 1266~~~{.cpp}; 1267#include <ROOT/RDataFrame.hxx>; 1268#include <memory>; 1269 ; 1270class MyCounter : public ROOT::Detail::RDF::RActionImpl<MyCounter> {; 1271 std::shared_ptr<int> fFinalResult = std::make_shared<int>(0);; 1272 std::vector<int> fPerThreadResults;; 1273 ; 1274public:; 1275 // We use a public type alias to advertise the type of the result of this action; 1276 using Result_t = int;; 1277 ; 1278 MyCounter(unsigned int nSlots) : fPerThreadResults(nSlots) {}; 1279 ; 1280 // Called before the event loop to retrieve the address of the resul",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:75882,Performance,perform,perform,75882,"adResults.end(), 0);; 1299 }; 1300 ; 1301 // Called by RDataFrame to retrieve the name of this action.; 1302 std::string GetActionName() const { return ""MyCounter""; }; 1303};; 1304 ; 1305int main() {; 1306 ROOT::RDataFrame df(10);; 1307 ROOT::RDF::RResultPtr<int> resultPtr = df.Book<>(MyCounter{df.GetNSlots()}, {});; 1308 // The GetValue call triggers the event loop; 1309 std::cout << ""Number of processed entries: "" << resultPtr.GetValue() << std::endl;; 1310}; 1311~~~; 1312 ; 1313See the Book() method for more information and [this tutorial](https://root.cern/doc/master/df018__customActions_8C.html); 1314for a more complete example.; 1315 ; 1316#### Injecting arbitrary code in the event loop with Foreach() and ForeachSlot(); 1317 ; 1318Foreach() takes a callable (lambda expression, free function, functor...) and a list of columns and; 1319executes the callable on the values of those columns for each event that passes all upstream selections.; 1320It can be used to perform actions that are not already available in the interface. For example, the following snippet; 1321evaluates the root mean square of column ""x"":; 1322~~~{.cpp}; 1323// Single-thread evaluation of RMS of column ""x"" using Foreach; 1324double sumSq = 0.;; 1325unsigned int n = 0;; 1326df.Foreach([&sumSq, &n](double x) { ++n; sumSq += x*x; }, {""x""});; 1327std::cout << ""rms of x: "" << std::sqrt(sumSq / n) << std::endl;; 1328~~~; 1329In multi-thread runs, users are responsible for the thread-safety of the expression passed to Foreach():; 1330thread will execute the expression concurrently.; 1331The code above would need to employ some resource protection mechanism to ensure non-concurrent writing of `rms`; but; 1332this is probably too much head-scratch for such a simple operation.; 1333 ; 1334ForeachSlot() can help in this situation. It is an alternative version of Foreach() for which the function takes an; 1335additional ""processing slot"" parameter besides the columns it should be applied to. RDataFrame;",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:76322,Performance,multi-thread,multi-thread,76322,"resultPtr.GetValue() << std::endl;; 1310}; 1311~~~; 1312 ; 1313See the Book() method for more information and [this tutorial](https://root.cern/doc/master/df018__customActions_8C.html); 1314for a more complete example.; 1315 ; 1316#### Injecting arbitrary code in the event loop with Foreach() and ForeachSlot(); 1317 ; 1318Foreach() takes a callable (lambda expression, free function, functor...) and a list of columns and; 1319executes the callable on the values of those columns for each event that passes all upstream selections.; 1320It can be used to perform actions that are not already available in the interface. For example, the following snippet; 1321evaluates the root mean square of column ""x"":; 1322~~~{.cpp}; 1323// Single-thread evaluation of RMS of column ""x"" using Foreach; 1324double sumSq = 0.;; 1325unsigned int n = 0;; 1326df.Foreach([&sumSq, &n](double x) { ++n; sumSq += x*x; }, {""x""});; 1327std::cout << ""rms of x: "" << std::sqrt(sumSq / n) << std::endl;; 1328~~~; 1329In multi-thread runs, users are responsible for the thread-safety of the expression passed to Foreach():; 1330thread will execute the expression concurrently.; 1331The code above would need to employ some resource protection mechanism to ensure non-concurrent writing of `rms`; but; 1332this is probably too much head-scratch for such a simple operation.; 1333 ; 1334ForeachSlot() can help in this situation. It is an alternative version of Foreach() for which the function takes an; 1335additional ""processing slot"" parameter besides the columns it should be applied to. RDataFrame; 1336guarantees that ForeachSlot() will invoke the user expression with different `slot` parameters for different concurrent; 1337executions (see [Special helper columns: rdfentry_ and rdfslot_](\ref helper-cols) for more information on the slot parameter).; 1338We can take advantage of ForeachSlot() to evaluate a thread-safe root mean square of column ""x"":; 1339~~~{.cpp}; 1340// Thread-safe evaluation of RMS of column ",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:76464,Performance,concurren,concurrently,76464,"resultPtr.GetValue() << std::endl;; 1310}; 1311~~~; 1312 ; 1313See the Book() method for more information and [this tutorial](https://root.cern/doc/master/df018__customActions_8C.html); 1314for a more complete example.; 1315 ; 1316#### Injecting arbitrary code in the event loop with Foreach() and ForeachSlot(); 1317 ; 1318Foreach() takes a callable (lambda expression, free function, functor...) and a list of columns and; 1319executes the callable on the values of those columns for each event that passes all upstream selections.; 1320It can be used to perform actions that are not already available in the interface. For example, the following snippet; 1321evaluates the root mean square of column ""x"":; 1322~~~{.cpp}; 1323// Single-thread evaluation of RMS of column ""x"" using Foreach; 1324double sumSq = 0.;; 1325unsigned int n = 0;; 1326df.Foreach([&sumSq, &n](double x) { ++n; sumSq += x*x; }, {""x""});; 1327std::cout << ""rms of x: "" << std::sqrt(sumSq / n) << std::endl;; 1328~~~; 1329In multi-thread runs, users are responsible for the thread-safety of the expression passed to Foreach():; 1330thread will execute the expression concurrently.; 1331The code above would need to employ some resource protection mechanism to ensure non-concurrent writing of `rms`; but; 1332this is probably too much head-scratch for such a simple operation.; 1333 ; 1334ForeachSlot() can help in this situation. It is an alternative version of Foreach() for which the function takes an; 1335additional ""processing slot"" parameter besides the columns it should be applied to. RDataFrame; 1336guarantees that ForeachSlot() will invoke the user expression with different `slot` parameters for different concurrent; 1337executions (see [Special helper columns: rdfentry_ and rdfslot_](\ref helper-cols) for more information on the slot parameter).; 1338We can take advantage of ForeachSlot() to evaluate a thread-safe root mean square of column ""x"":; 1339~~~{.cpp}; 1340// Thread-safe evaluation of RMS of column ",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:76568,Performance,concurren,concurrent,76568,"trary code in the event loop with Foreach() and ForeachSlot(); 1317 ; 1318Foreach() takes a callable (lambda expression, free function, functor...) and a list of columns and; 1319executes the callable on the values of those columns for each event that passes all upstream selections.; 1320It can be used to perform actions that are not already available in the interface. For example, the following snippet; 1321evaluates the root mean square of column ""x"":; 1322~~~{.cpp}; 1323// Single-thread evaluation of RMS of column ""x"" using Foreach; 1324double sumSq = 0.;; 1325unsigned int n = 0;; 1326df.Foreach([&sumSq, &n](double x) { ++n; sumSq += x*x; }, {""x""});; 1327std::cout << ""rms of x: "" << std::sqrt(sumSq / n) << std::endl;; 1328~~~; 1329In multi-thread runs, users are responsible for the thread-safety of the expression passed to Foreach():; 1330thread will execute the expression concurrently.; 1331The code above would need to employ some resource protection mechanism to ensure non-concurrent writing of `rms`; but; 1332this is probably too much head-scratch for such a simple operation.; 1333 ; 1334ForeachSlot() can help in this situation. It is an alternative version of Foreach() for which the function takes an; 1335additional ""processing slot"" parameter besides the columns it should be applied to. RDataFrame; 1336guarantees that ForeachSlot() will invoke the user expression with different `slot` parameters for different concurrent; 1337executions (see [Special helper columns: rdfentry_ and rdfslot_](\ref helper-cols) for more information on the slot parameter).; 1338We can take advantage of ForeachSlot() to evaluate a thread-safe root mean square of column ""x"":; 1339~~~{.cpp}; 1340// Thread-safe evaluation of RMS of column ""x"" using ForeachSlot; 1341ROOT::EnableImplicitMT();; 1342const unsigned int nSlots = df.GetNSlots();; 1343std::vector<double> sumSqs(nSlots, 0.);; 1344std::vector<unsigned int> ns(nSlots, 0);; 1345 ; 1346df.ForeachSlot([&sumSqs, &ns](unsigned int sl",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:77016,Performance,concurren,concurrent,77016,"umn ""x"":; 1322~~~{.cpp}; 1323// Single-thread evaluation of RMS of column ""x"" using Foreach; 1324double sumSq = 0.;; 1325unsigned int n = 0;; 1326df.Foreach([&sumSq, &n](double x) { ++n; sumSq += x*x; }, {""x""});; 1327std::cout << ""rms of x: "" << std::sqrt(sumSq / n) << std::endl;; 1328~~~; 1329In multi-thread runs, users are responsible for the thread-safety of the expression passed to Foreach():; 1330thread will execute the expression concurrently.; 1331The code above would need to employ some resource protection mechanism to ensure non-concurrent writing of `rms`; but; 1332this is probably too much head-scratch for such a simple operation.; 1333 ; 1334ForeachSlot() can help in this situation. It is an alternative version of Foreach() for which the function takes an; 1335additional ""processing slot"" parameter besides the columns it should be applied to. RDataFrame; 1336guarantees that ForeachSlot() will invoke the user expression with different `slot` parameters for different concurrent; 1337executions (see [Special helper columns: rdfentry_ and rdfslot_](\ref helper-cols) for more information on the slot parameter).; 1338We can take advantage of ForeachSlot() to evaluate a thread-safe root mean square of column ""x"":; 1339~~~{.cpp}; 1340// Thread-safe evaluation of RMS of column ""x"" using ForeachSlot; 1341ROOT::EnableImplicitMT();; 1342const unsigned int nSlots = df.GetNSlots();; 1343std::vector<double> sumSqs(nSlots, 0.);; 1344std::vector<unsigned int> ns(nSlots, 0);; 1345 ; 1346df.ForeachSlot([&sumSqs, &ns](unsigned int slot, double x) { sumSqs[slot] += x*x; ns[slot] += 1; }, {""x""});; 1347double sumSq = std::accumulate(sumSqs.begin(), sumSqs.end(), 0.); // sum all squares; 1348unsigned int n = std::accumulate(ns.begin(), ns.end(), 0); // sum all counts; 1349std::cout << ""rms of x: "" << std::sqrt(sumSq / n) << std::endl;; 1350~~~; 1351Notice how we created one `double` variable for each processing slot and later merged their results via `std::accumulate`.; 1352 ; 1",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:79572,Performance,multi-thread,multi-thread,79572,"rees) leverages TTree's ""friend"" mechanism.; 1363 ; 1364Simple joins of trees that do not have the same number of rows are also possible with indexed friend trees (see below).; 1365 ; 1366To use friend trees in RDataFrame, set up trees with the appropriate relationships and then instantiate an RDataFrame; 1367with the main tree:; 1368 ; 1369~~~{.cpp}; 1370TTree main([...]);; 1371TTree friend([...]);; 1372main.AddFriend(&friend, ""myFriend"");; 1373 ; 1374RDataFrame df(main);; 1375auto df2 = df.Filter(""myFriend.MyCol == 42"");; 1376~~~; 1377 ; 1378The same applies for TChains. Columns coming from the friend trees can be referred to by their full name, like in the example above,; 1379or the friend tree name can be omitted in case the column name is not ambiguous (e.g. ""MyCol"" could be used instead of; 1380""myFriend.MyCol"" in the example above if there is no column ""MyCol"" in the main tree).; 1381 ; 1382\note A common source of confusion is that trees that are written out from a multi-thread Snapshot() call will have their; 1383 entries (block-wise) shuffled with respect to the original tree. Such trees cannot be used as friends of the original; 1384 one: rows will be mismatched.; 1385 ; 1386Indexed friend trees provide a way to perform simple joins of multiple trees over a common column.; 1387When a certain entry in the main tree (or chain) is loaded, the friend trees (or chains) will then load an entry where the; 1388""index"" columns have a value identical to the one in the main one. For example, in Python:; 1389 ; 1390~~~{.py}; 1391main_tree = ...; 1392aux_tree = ...; 1393 ; 1394# If a friend tree has an index on `commonColumn`, when the main tree loads; 1395# a given row, it also loads the row of the friend tree that has the same; 1396# value of `commonColumn`; 1397aux_tree.BuildIndex(""commonColumn""); 1398 ; 1399mainTree.AddFriend(aux_tree); 1400 ; 1401df = ROOT.RDataFrame(mainTree); 1402~~~; 1403 ; 1404RDataFrame supports indexed friend TTrees from ROOT v6.24 in single",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:79827,Performance,perform,perform,79827,"propriate relationships and then instantiate an RDataFrame; 1367with the main tree:; 1368 ; 1369~~~{.cpp}; 1370TTree main([...]);; 1371TTree friend([...]);; 1372main.AddFriend(&friend, ""myFriend"");; 1373 ; 1374RDataFrame df(main);; 1375auto df2 = df.Filter(""myFriend.MyCol == 42"");; 1376~~~; 1377 ; 1378The same applies for TChains. Columns coming from the friend trees can be referred to by their full name, like in the example above,; 1379or the friend tree name can be omitted in case the column name is not ambiguous (e.g. ""MyCol"" could be used instead of; 1380""myFriend.MyCol"" in the example above if there is no column ""MyCol"" in the main tree).; 1381 ; 1382\note A common source of confusion is that trees that are written out from a multi-thread Snapshot() call will have their; 1383 entries (block-wise) shuffled with respect to the original tree. Such trees cannot be used as friends of the original; 1384 one: rows will be mismatched.; 1385 ; 1386Indexed friend trees provide a way to perform simple joins of multiple trees over a common column.; 1387When a certain entry in the main tree (or chain) is loaded, the friend trees (or chains) will then load an entry where the; 1388""index"" columns have a value identical to the one in the main one. For example, in Python:; 1389 ; 1390~~~{.py}; 1391main_tree = ...; 1392aux_tree = ...; 1393 ; 1394# If a friend tree has an index on `commonColumn`, when the main tree loads; 1395# a given row, it also loads the row of the friend tree that has the same; 1396# value of `commonColumn`; 1397aux_tree.BuildIndex(""commonColumn""); 1398 ; 1399mainTree.AddFriend(aux_tree); 1400 ; 1401df = ROOT.RDataFrame(mainTree); 1402~~~; 1403 ; 1404RDataFrame supports indexed friend TTrees from ROOT v6.24 in single-thread mode and from v6.28/02 in multi-thread mode.; 1405 ; 1406\anchor other-file-formats; 1407### Reading data formats other than ROOT trees; 1408RDataFrame can be interfaced with RDataSources. The ROOT::RDF::RDataSource interface defines an AP",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:79945,Performance,load,loaded,79945," 1372main.AddFriend(&friend, ""myFriend"");; 1373 ; 1374RDataFrame df(main);; 1375auto df2 = df.Filter(""myFriend.MyCol == 42"");; 1376~~~; 1377 ; 1378The same applies for TChains. Columns coming from the friend trees can be referred to by their full name, like in the example above,; 1379or the friend tree name can be omitted in case the column name is not ambiguous (e.g. ""MyCol"" could be used instead of; 1380""myFriend.MyCol"" in the example above if there is no column ""MyCol"" in the main tree).; 1381 ; 1382\note A common source of confusion is that trees that are written out from a multi-thread Snapshot() call will have their; 1383 entries (block-wise) shuffled with respect to the original tree. Such trees cannot be used as friends of the original; 1384 one: rows will be mismatched.; 1385 ; 1386Indexed friend trees provide a way to perform simple joins of multiple trees over a common column.; 1387When a certain entry in the main tree (or chain) is loaded, the friend trees (or chains) will then load an entry where the; 1388""index"" columns have a value identical to the one in the main one. For example, in Python:; 1389 ; 1390~~~{.py}; 1391main_tree = ...; 1392aux_tree = ...; 1393 ; 1394# If a friend tree has an index on `commonColumn`, when the main tree loads; 1395# a given row, it also loads the row of the friend tree that has the same; 1396# value of `commonColumn`; 1397aux_tree.BuildIndex(""commonColumn""); 1398 ; 1399mainTree.AddFriend(aux_tree); 1400 ; 1401df = ROOT.RDataFrame(mainTree); 1402~~~; 1403 ; 1404RDataFrame supports indexed friend TTrees from ROOT v6.24 in single-thread mode and from v6.28/02 in multi-thread mode.; 1405 ; 1406\anchor other-file-formats; 1407### Reading data formats other than ROOT trees; 1408RDataFrame can be interfaced with RDataSources. The ROOT::RDF::RDataSource interface defines an API that RDataFrame can use to read arbitrary columnar data formats.; 1409 ; 1410RDataFrame calls into concrete RDataSource implementations to retrieve infor",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:79992,Performance,load,load,79992," 1372main.AddFriend(&friend, ""myFriend"");; 1373 ; 1374RDataFrame df(main);; 1375auto df2 = df.Filter(""myFriend.MyCol == 42"");; 1376~~~; 1377 ; 1378The same applies for TChains. Columns coming from the friend trees can be referred to by their full name, like in the example above,; 1379or the friend tree name can be omitted in case the column name is not ambiguous (e.g. ""MyCol"" could be used instead of; 1380""myFriend.MyCol"" in the example above if there is no column ""MyCol"" in the main tree).; 1381 ; 1382\note A common source of confusion is that trees that are written out from a multi-thread Snapshot() call will have their; 1383 entries (block-wise) shuffled with respect to the original tree. Such trees cannot be used as friends of the original; 1384 one: rows will be mismatched.; 1385 ; 1386Indexed friend trees provide a way to perform simple joins of multiple trees over a common column.; 1387When a certain entry in the main tree (or chain) is loaded, the friend trees (or chains) will then load an entry where the; 1388""index"" columns have a value identical to the one in the main one. For example, in Python:; 1389 ; 1390~~~{.py}; 1391main_tree = ...; 1392aux_tree = ...; 1393 ; 1394# If a friend tree has an index on `commonColumn`, when the main tree loads; 1395# a given row, it also loads the row of the friend tree that has the same; 1396# value of `commonColumn`; 1397aux_tree.BuildIndex(""commonColumn""); 1398 ; 1399mainTree.AddFriend(aux_tree); 1400 ; 1401df = ROOT.RDataFrame(mainTree); 1402~~~; 1403 ; 1404RDataFrame supports indexed friend TTrees from ROOT v6.24 in single-thread mode and from v6.28/02 in multi-thread mode.; 1405 ; 1406\anchor other-file-formats; 1407### Reading data formats other than ROOT trees; 1408RDataFrame can be interfaced with RDataSources. The ROOT::RDF::RDataSource interface defines an API that RDataFrame can use to read arbitrary columnar data formats.; 1409 ; 1410RDataFrame calls into concrete RDataSource implementations to retrieve infor",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:80256,Performance,load,loads,80256,"friend tree name can be omitted in case the column name is not ambiguous (e.g. ""MyCol"" could be used instead of; 1380""myFriend.MyCol"" in the example above if there is no column ""MyCol"" in the main tree).; 1381 ; 1382\note A common source of confusion is that trees that are written out from a multi-thread Snapshot() call will have their; 1383 entries (block-wise) shuffled with respect to the original tree. Such trees cannot be used as friends of the original; 1384 one: rows will be mismatched.; 1385 ; 1386Indexed friend trees provide a way to perform simple joins of multiple trees over a common column.; 1387When a certain entry in the main tree (or chain) is loaded, the friend trees (or chains) will then load an entry where the; 1388""index"" columns have a value identical to the one in the main one. For example, in Python:; 1389 ; 1390~~~{.py}; 1391main_tree = ...; 1392aux_tree = ...; 1393 ; 1394# If a friend tree has an index on `commonColumn`, when the main tree loads; 1395# a given row, it also loads the row of the friend tree that has the same; 1396# value of `commonColumn`; 1397aux_tree.BuildIndex(""commonColumn""); 1398 ; 1399mainTree.AddFriend(aux_tree); 1400 ; 1401df = ROOT.RDataFrame(mainTree); 1402~~~; 1403 ; 1404RDataFrame supports indexed friend TTrees from ROOT v6.24 in single-thread mode and from v6.28/02 in multi-thread mode.; 1405 ; 1406\anchor other-file-formats; 1407### Reading data formats other than ROOT trees; 1408RDataFrame can be interfaced with RDataSources. The ROOT::RDF::RDataSource interface defines an API that RDataFrame can use to read arbitrary columnar data formats.; 1409 ; 1410RDataFrame calls into concrete RDataSource implementations to retrieve information about the data, retrieve (thread-local) readers or ""cursors"" for selected columns; 1411and to advance the readers to the desired data entry.; 1412Some predefined RDataSources are natively provided by ROOT such as the ROOT::RDF::RCsvDS which allows to read comma separated files:; 1413~~",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:80290,Performance,load,loads,80290,"friend tree name can be omitted in case the column name is not ambiguous (e.g. ""MyCol"" could be used instead of; 1380""myFriend.MyCol"" in the example above if there is no column ""MyCol"" in the main tree).; 1381 ; 1382\note A common source of confusion is that trees that are written out from a multi-thread Snapshot() call will have their; 1383 entries (block-wise) shuffled with respect to the original tree. Such trees cannot be used as friends of the original; 1384 one: rows will be mismatched.; 1385 ; 1386Indexed friend trees provide a way to perform simple joins of multiple trees over a common column.; 1387When a certain entry in the main tree (or chain) is loaded, the friend trees (or chains) will then load an entry where the; 1388""index"" columns have a value identical to the one in the main one. For example, in Python:; 1389 ; 1390~~~{.py}; 1391main_tree = ...; 1392aux_tree = ...; 1393 ; 1394# If a friend tree has an index on `commonColumn`, when the main tree loads; 1395# a given row, it also loads the row of the friend tree that has the same; 1396# value of `commonColumn`; 1397aux_tree.BuildIndex(""commonColumn""); 1398 ; 1399mainTree.AddFriend(aux_tree); 1400 ; 1401df = ROOT.RDataFrame(mainTree); 1402~~~; 1403 ; 1404RDataFrame supports indexed friend TTrees from ROOT v6.24 in single-thread mode and from v6.28/02 in multi-thread mode.; 1405 ; 1406\anchor other-file-formats; 1407### Reading data formats other than ROOT trees; 1408RDataFrame can be interfaced with RDataSources. The ROOT::RDF::RDataSource interface defines an API that RDataFrame can use to read arbitrary columnar data formats.; 1409 ; 1410RDataFrame calls into concrete RDataSource implementations to retrieve information about the data, retrieve (thread-local) readers or ""cursors"" for selected columns; 1411and to advance the readers to the desired data entry.; 1412Some predefined RDataSources are natively provided by ROOT such as the ROOT::RDF::RCsvDS which allows to read comma separated files:; 1413~~",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:80619,Performance,multi-thread,multi-thread,80619,"entries (block-wise) shuffled with respect to the original tree. Such trees cannot be used as friends of the original; 1384 one: rows will be mismatched.; 1385 ; 1386Indexed friend trees provide a way to perform simple joins of multiple trees over a common column.; 1387When a certain entry in the main tree (or chain) is loaded, the friend trees (or chains) will then load an entry where the; 1388""index"" columns have a value identical to the one in the main one. For example, in Python:; 1389 ; 1390~~~{.py}; 1391main_tree = ...; 1392aux_tree = ...; 1393 ; 1394# If a friend tree has an index on `commonColumn`, when the main tree loads; 1395# a given row, it also loads the row of the friend tree that has the same; 1396# value of `commonColumn`; 1397aux_tree.BuildIndex(""commonColumn""); 1398 ; 1399mainTree.AddFriend(aux_tree); 1400 ; 1401df = ROOT.RDataFrame(mainTree); 1402~~~; 1403 ; 1404RDataFrame supports indexed friend TTrees from ROOT v6.24 in single-thread mode and from v6.28/02 in multi-thread mode.; 1405 ; 1406\anchor other-file-formats; 1407### Reading data formats other than ROOT trees; 1408RDataFrame can be interfaced with RDataSources. The ROOT::RDF::RDataSource interface defines an API that RDataFrame can use to read arbitrary columnar data formats.; 1409 ; 1410RDataFrame calls into concrete RDataSource implementations to retrieve information about the data, retrieve (thread-local) readers or ""cursors"" for selected columns; 1411and to advance the readers to the desired data entry.; 1412Some predefined RDataSources are natively provided by ROOT such as the ROOT::RDF::RCsvDS which allows to read comma separated files:; 1413~~~{.cpp}; 1414auto tdf = ROOT::RDF::FromCSV(""MuRun2010B.csv"");; 1415auto filteredEvents =; 1416 tdf.Filter(""Q1 * Q2 == -1""); 1417 .Define(""m"", ""sqrt(pow(E1 + E2, 2) - (pow(px1 + px2, 2) + pow(py1 + py2, 2) + pow(pz1 + pz2, 2)))"");; 1418auto h = filteredEvents.Histo1D(""m"");; 1419h->Draw();; 1420~~~; 1421 ; 1422See also FromNumpy (Python-only), ",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:84867,Performance,multi-thread,multi-thread,84867,"tance, the image below can be generated with the following command:; 1463~~~{.sh}; 1464$ dot -Tpng computation_graph.dot -ocomputation_graph.png; 1465~~~; 1466 ; 1467\image html RDF_Graph2.png; 1468 ; 1469\anchor rdf-logging; 1470### Activating RDataFrame execution logs; 1471 ; 1472RDataFrame has experimental support for verbose logging of the event loop runtimes and other interesting related information. It is activated as follows:; 1473~~~{.cpp}; 1474#include <ROOT/RLogger.hxx>; 1475 ; 1476// this increases RDF's verbosity level as long as the `verbosity` variable is in scope; 1477auto verbosity = ROOT::Experimental::RLogScopedVerbosity(ROOT::Detail::RDF::RDFLogChannel(), ROOT::Experimental::ELogLevel::kInfo);; 1478~~~; 1479 ; 1480or in Python:; 1481~~~{.python}; 1482import ROOT; 1483 ; 1484verbosity = ROOT.Experimental.RLogScopedVerbosity(ROOT.Detail.RDF.RDFLogChannel(), ROOT.Experimental.ELogLevel.kInfo); 1485~~~; 1486 ; 1487More information (e.g. start and end of each multi-thread task) is printed using `ELogLevel.kDebug` and even more; 1488(e.g. a full dump of the generated code that RDataFrame just-in-time-compiles) using `ELogLevel.kDebug+10`.; 1489 ; 1490\anchor rdf-from-spec; 1491### Creating an RDataFrame from a dataset specification file; 1492 ; 1493RDataFrame can be created using a dataset specification JSON file: ; 1494 ; 1495~~~{.python}; 1496import ROOT; 1497 ; 1498df = ROOT.RDF.Experimental.FromSpec(""spec.json""); 1499~~~; 1500 ; 1501The input dataset specification JSON file needs to be provided by the user and it describes all necessary samples and; 1502their associated metadata information. The main required key is the ""samples"" (at least one sample is needed) and the; 1503required sub-keys for each sample are ""trees"" and ""files"". Additionally, one can specify a metadata dictionary for each; 1504sample in the ""metadata"" key.; 1505 ; 1506A simple example for the formatting of the specification in the JSON file is the following:; 1507 ; 1508~~~{.cpp}",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:2202,Safety,safe,safe,2202,"> // for make_shared, allocator, shared_ptr; 27#include <ostream> // ostringstream; 28#include <stdexcept>; 29#include <string>; 30#include <vector>; 31 ; 32// clang-format off; 33/**; 34* \class ROOT::RDataFrame; 35* \ingroup dataframe; 36* \brief ROOT's RDataFrame offers a modern, high-level interface for analysis of data stored in TTree , CSV and other data formats, in C++ or Python.; 37 ; 38In addition, multi-threading and other low-level optimisations allow users to exploit all the resources available; 39on their machines completely transparently.<br>; 40Skip to the [class reference](#reference) or keep reading for the user guide.; 41 ; 42In a nutshell:; 43~~~{.cpp}; 44ROOT::EnableImplicitMT(); // Tell ROOT you want to go parallel; 45ROOT::RDataFrame d(""myTree"", ""file_*.root""); // Interface to TTree and TChain; 46auto myHisto = d.Histo1D(""Branch_A""); // This books the (lazy) filling of a histogram; 47myHisto->Draw(); // Event loop is run here, upon first access to a result; 48~~~; 49 ; 50Calculations are expressed in terms of a type-safe *functional chain of actions and transformations*, RDataFrame takes; 51care of their execution. The implementation automatically puts in place several low level optimisations such as; 52multi-thread parallelization and caching.; 53 ; 54\htmlonly; 55<a href=""https://doi.org/10.5281/zenodo.260230""><img src=""https://zenodo.org/badge/DOI/10.5281/zenodo.260230.svg""; 56alt=""DOI""></a>; 57\endhtmlonly; 58 ; 59## For the impatient user; 60You can directly see RDataFrame in action in our [tutorials](https://root.cern/doc/master/group__tutorial__dataframe.html), in C++ or Python.; 61 ; 62## Table of Contents; 63- [Cheat sheet](\ref cheatsheet); 64- [Introduction](\ref introduction); 65- [Crash course](\ref crash-course); 66- [Working with collections](\ref collections); 67- [Transformations: manipulating data](\ref transformations); 68- [Actions: getting results](\ref actions); 69- [Distributed execution in Python](\ref distrdf); 70- [Perf",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:5667,Safety,safe,safe,5667,"; 94 ; 95### Transformations; 96Transformations are a way to manipulate the data.; 97 ; 98| **Transformation** | **Description** |; 99|------------------|--------------------|; 100| Alias() | Introduce an alias for a particular column name. |; 101| DefaultValueFor() | If the value of the input column is missing, provide a default value instead. |; 102| Define() | Create a new column in the dataset. Example usages include adding a column that contains the invariant mass of a particle, or a selection of elements of an array (e.g. only the `pt`s of ""good"" muons). |; 103| DefinePerSample() | Define a new column that is updated when the input sample changes, e.g. when switching tree being processed in a chain. |; 104| DefineSlot() | Same as Define(), but the user-defined function must take an extra `unsigned int slot` as its first parameter. `slot` will take a different value, `0` to `nThreads - 1`, for each thread of execution. This is meant as a helper in writing thread-safe Define() transformation when using RDataFrame after ROOT::EnableImplicitMT(). DefineSlot() works just as well with single-thread execution: in that case `slot` will always be `0`. |; 105| DefineSlotEntry() | Same as DefineSlot(), but the entry number is passed in addition to the slot number. This is meant as a helper in case the expression depends on the entry number. For details about entry numbers in multi-threaded runs, see [here](\ref helper-cols). |; 106| Filter() | Filter rows based on user-defined conditions. |; 107| FilterAvailable() | Specialized Filter. If the value of the input column is available, keep the entry, otherwise discard it. |; 108| FilterMissing() | Specialized Filter. If the value of the input column is missing, keep the entry, otherwise discard it. |; 109| Range() | Filter rows based on entry number (single-thread only). |; 110| Redefine() | Overwrite the value and/or type of an existing column. See Define() for more information. |; 111| RedefineSlot() | Overwrite the value ",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:10971,Safety,safe,safety,10971," entries have been accepted and rejected by the filters. See the section on [named filters](#named-filters-and-cutflow-reports) for a more detailed explanation. The method returns a ROOT::RDF::RCutFlowReport instance which can be queried programmatically to get information about the effects of the individual cuts. |; 143| Stats() | Return a TStatistic object filled with the input columns. |; 144| StdDev() | Return the unbiased standard deviation of the processed column values. |; 145| Sum() | Return the sum of the values in the column. If the type of the column is inferred, the return type is `double`, the type of the column otherwise. |; 146| Take() | Extract a column from the dataset as a collection of values, e.g. a `std::vector<float>` for a column of type `float`. |; 147 ; 148| **Instant action** | **Description** |; 149|---------------------|-----------------|; 150| Foreach() | Execute a user-defined function on each entry. Users are responsible for the thread-safety of this callable when executing with implicit multi-threading enabled. |; 151| ForeachSlot() | Same as Foreach(), but the user-defined function must take an extra `unsigned int slot` as its first parameter. `slot` will take a different value, `0` to `nThreads - 1`, for each thread of execution. This is meant as a helper in writing thread-safe Foreach() actions when using RDataFrame after ROOT::EnableImplicitMT(). ForeachSlot() works just as well with single-thread execution: in that case `slot` will always be `0`. |; 152| Snapshot() | Write the processed dataset to disk, in a new TTree and TFile. Custom columns can be saved as well, filtered entries are not saved. Users can specify which columns to save (default is all). Snapshot, by default, overwrites the output file if it already exists. Snapshot() can be made *lazy* setting the appropriate flag in the snapshot options.|; 153 ; 154 ; 155### Queries; 156 ; 157These operations do not modify the dataframe or book computations but simply return info",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:11318,Safety,safe,safe,11318,"TStatistic object filled with the input columns. |; 144| StdDev() | Return the unbiased standard deviation of the processed column values. |; 145| Sum() | Return the sum of the values in the column. If the type of the column is inferred, the return type is `double`, the type of the column otherwise. |; 146| Take() | Extract a column from the dataset as a collection of values, e.g. a `std::vector<float>` for a column of type `float`. |; 147 ; 148| **Instant action** | **Description** |; 149|---------------------|-----------------|; 150| Foreach() | Execute a user-defined function on each entry. Users are responsible for the thread-safety of this callable when executing with implicit multi-threading enabled. |; 151| ForeachSlot() | Same as Foreach(), but the user-defined function must take an extra `unsigned int slot` as its first parameter. `slot` will take a different value, `0` to `nThreads - 1`, for each thread of execution. This is meant as a helper in writing thread-safe Foreach() actions when using RDataFrame after ROOT::EnableImplicitMT(). ForeachSlot() works just as well with single-thread execution: in that case `slot` will always be `0`. |; 152| Snapshot() | Write the processed dataset to disk, in a new TTree and TFile. Custom columns can be saved as well, filtered entries are not saved. Users can specify which columns to save (default is all). Snapshot, by default, overwrites the output file if it already exists. Snapshot() can be made *lazy* setting the appropriate flag in the snapshot options.|; 153 ; 154 ; 155### Queries; 156 ; 157These operations do not modify the dataframe or book computations but simply return information on the RDataFrame object.; 158 ; 159| **Operation** | **Description** |; 160|---------------------|-----------------|; 161| Describe() | Get useful information describing the dataframe, e.g. columns and their types. |; 162| GetColumnNames() | Get the names of all the available columns of the dataset. |; 163| GetColumnType() | Return ",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:53079,Safety,safe,safety,53079,"turning the final values to the user.; 940There are no guarantees on the order in which threads will process the batches of entries.; 941In particular, note that this means that, for multi-thread event loops, there is no; 942guarantee on the order in which Snapshot() will _write_ entries: they could be scrambled with respect to the input dataset. The values of the special `rdfentry_` column will also not correspond to the entry numbers in the input dataset (e.g. TChain) in multi-thread runs.; 943 ; 944\warning By default, RDataFrame will use as many threads as the hardware supports, using up **all** the resources on; 945a machine. This might be undesirable on shared computing resources such as a batch cluster. Therefore, when running on shared computing resources, use; 946~~~{.cpp}; 947ROOT::EnableImplicitMT(i); 948~~~; 949replacing `i` with the number of CPUs/slots that were allocated for this job.; 950 ; 951### Thread-safety of user-defined expressions; 952RDataFrame operations such as Histo1D() or Snapshot() are guaranteed to work correctly in multi-thread event loops.; 953User-defined expressions, such as strings or lambdas passed to Filter(), Define(), Foreach(), Reduce() or Aggregate(); 954will have to be thread-safe, i.e. it should be possible to call them concurrently from different threads.; 955 ; 956Note that simple Filter() and Define() transformations will inherently satisfy this requirement: Filter() / Define(); 957expressions will often be *pure* in the functional programming sense (no side-effects, no dependency on external state),; 958which eliminates all risks of race conditions.; 959 ; 960In order to facilitate writing of thread-safe operations, some RDataFrame features such as Foreach(), Define() or \link ROOT::RDF::RResultPtr::OnPartialResult OnPartialResult()\endlink; 961offer thread-aware counterparts (ForeachSlot(), DefineSlot(), \link ROOT::RDF::RResultPtr::OnPartialResultSlot OnPartialResultSlot()\endlink): their only difference is that they",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:53383,Safety,safe,safe,53383,"means that, for multi-thread event loops, there is no; 942guarantee on the order in which Snapshot() will _write_ entries: they could be scrambled with respect to the input dataset. The values of the special `rdfentry_` column will also not correspond to the entry numbers in the input dataset (e.g. TChain) in multi-thread runs.; 943 ; 944\warning By default, RDataFrame will use as many threads as the hardware supports, using up **all** the resources on; 945a machine. This might be undesirable on shared computing resources such as a batch cluster. Therefore, when running on shared computing resources, use; 946~~~{.cpp}; 947ROOT::EnableImplicitMT(i); 948~~~; 949replacing `i` with the number of CPUs/slots that were allocated for this job.; 950 ; 951### Thread-safety of user-defined expressions; 952RDataFrame operations such as Histo1D() or Snapshot() are guaranteed to work correctly in multi-thread event loops.; 953User-defined expressions, such as strings or lambdas passed to Filter(), Define(), Foreach(), Reduce() or Aggregate(); 954will have to be thread-safe, i.e. it should be possible to call them concurrently from different threads.; 955 ; 956Note that simple Filter() and Define() transformations will inherently satisfy this requirement: Filter() / Define(); 957expressions will often be *pure* in the functional programming sense (no side-effects, no dependency on external state),; 958which eliminates all risks of race conditions.; 959 ; 960In order to facilitate writing of thread-safe operations, some RDataFrame features such as Foreach(), Define() or \link ROOT::RDF::RResultPtr::OnPartialResult OnPartialResult()\endlink; 961offer thread-aware counterparts (ForeachSlot(), DefineSlot(), \link ROOT::RDF::RResultPtr::OnPartialResultSlot OnPartialResultSlot()\endlink): their only difference is that they; 962will pass an extra `slot` argument (an unsigned integer) to the user-defined expression. When calling user-defined code; 963concurrently, RDataFrame guarantees th",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:53743,Safety,risk,risks,53743,"in) in multi-thread runs.; 943 ; 944\warning By default, RDataFrame will use as many threads as the hardware supports, using up **all** the resources on; 945a machine. This might be undesirable on shared computing resources such as a batch cluster. Therefore, when running on shared computing resources, use; 946~~~{.cpp}; 947ROOT::EnableImplicitMT(i); 948~~~; 949replacing `i` with the number of CPUs/slots that were allocated for this job.; 950 ; 951### Thread-safety of user-defined expressions; 952RDataFrame operations such as Histo1D() or Snapshot() are guaranteed to work correctly in multi-thread event loops.; 953User-defined expressions, such as strings or lambdas passed to Filter(), Define(), Foreach(), Reduce() or Aggregate(); 954will have to be thread-safe, i.e. it should be possible to call them concurrently from different threads.; 955 ; 956Note that simple Filter() and Define() transformations will inherently satisfy this requirement: Filter() / Define(); 957expressions will often be *pure* in the functional programming sense (no side-effects, no dependency on external state),; 958which eliminates all risks of race conditions.; 959 ; 960In order to facilitate writing of thread-safe operations, some RDataFrame features such as Foreach(), Define() or \link ROOT::RDF::RResultPtr::OnPartialResult OnPartialResult()\endlink; 961offer thread-aware counterparts (ForeachSlot(), DefineSlot(), \link ROOT::RDF::RResultPtr::OnPartialResultSlot OnPartialResultSlot()\endlink): their only difference is that they; 962will pass an extra `slot` argument (an unsigned integer) to the user-defined expression. When calling user-defined code; 963concurrently, RDataFrame guarantees that different threads will employ different values of the `slot` parameter,; 964where `slot` will be a number between 0 and `GetNSlots() - 1`.; 965In other words, within a slot, computation runs sequentially and events are processed sequentially.; 966Note that the same slot might be associated to differen",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:53820,Safety,safe,safe,53820,"number of CPUs/slots that were allocated for this job.; 950 ; 951### Thread-safety of user-defined expressions; 952RDataFrame operations such as Histo1D() or Snapshot() are guaranteed to work correctly in multi-thread event loops.; 953User-defined expressions, such as strings or lambdas passed to Filter(), Define(), Foreach(), Reduce() or Aggregate(); 954will have to be thread-safe, i.e. it should be possible to call them concurrently from different threads.; 955 ; 956Note that simple Filter() and Define() transformations will inherently satisfy this requirement: Filter() / Define(); 957expressions will often be *pure* in the functional programming sense (no side-effects, no dependency on external state),; 958which eliminates all risks of race conditions.; 959 ; 960In order to facilitate writing of thread-safe operations, some RDataFrame features such as Foreach(), Define() or \link ROOT::RDF::RResultPtr::OnPartialResult OnPartialResult()\endlink; 961offer thread-aware counterparts (ForeachSlot(), DefineSlot(), \link ROOT::RDF::RResultPtr::OnPartialResultSlot OnPartialResultSlot()\endlink): their only difference is that they; 962will pass an extra `slot` argument (an unsigned integer) to the user-defined expression. When calling user-defined code; 963concurrently, RDataFrame guarantees that different threads will employ different values of the `slot` parameter,; 964where `slot` will be a number between 0 and `GetNSlots() - 1`.; 965In other words, within a slot, computation runs sequentially and events are processed sequentially.; 966Note that the same slot might be associated to different threads over the course of a single event loop, but two threads; 967will never receive the same slot at the same time.; 968This extra parameter might facilitate writing safe parallel code by having each thread write/modify a different; 969processing slot, e.g. a different element of a list. See [here](#generic-actions) for an example usage of ForeachSlot().; 970 ; 971### Parallel e",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:54788,Safety,safe,safe,54788,"ng of thread-safe operations, some RDataFrame features such as Foreach(), Define() or \link ROOT::RDF::RResultPtr::OnPartialResult OnPartialResult()\endlink; 961offer thread-aware counterparts (ForeachSlot(), DefineSlot(), \link ROOT::RDF::RResultPtr::OnPartialResultSlot OnPartialResultSlot()\endlink): their only difference is that they; 962will pass an extra `slot` argument (an unsigned integer) to the user-defined expression. When calling user-defined code; 963concurrently, RDataFrame guarantees that different threads will employ different values of the `slot` parameter,; 964where `slot` will be a number between 0 and `GetNSlots() - 1`.; 965In other words, within a slot, computation runs sequentially and events are processed sequentially.; 966Note that the same slot might be associated to different threads over the course of a single event loop, but two threads; 967will never receive the same slot at the same time.; 968This extra parameter might facilitate writing safe parallel code by having each thread write/modify a different; 969processing slot, e.g. a different element of a list. See [here](#generic-actions) for an example usage of ForeachSlot().; 970 ; 971### Parallel execution of multiple RDataFrame event loops; 972A complex analysis may require multiple separate RDataFrame computation graphs to produce all desired results. This poses the challenge that the; 973event loops of each computation graph can be parallelized, but the different loops run sequentially, one after the other.; 974On many-core architectures it might be desirable to run different event loops concurrently to improve resource usage.; 975ROOT::RDF::RunGraphs() allows running multiple RDataFrame event loops concurrently:; 976~~~{.cpp}; 977ROOT::EnableImplicitMT();; 978ROOT::RDataFrame df1(""tree1"", ""f1.root"");; 979ROOT::RDataFrame df2(""tree2"", ""f2.root"");; 980auto histo1 = df1.Histo1D(""x"");; 981auto histo2 = df2.Histo1D(""y"");; 982 ; 983// just accessing result pointers, the event loops of sep",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:56312,Safety,avoid,avoid,56312,"nalysis may require multiple separate RDataFrame computation graphs to produce all desired results. This poses the challenge that the; 973event loops of each computation graph can be parallelized, but the different loops run sequentially, one after the other.; 974On many-core architectures it might be desirable to run different event loops concurrently to improve resource usage.; 975ROOT::RDF::RunGraphs() allows running multiple RDataFrame event loops concurrently:; 976~~~{.cpp}; 977ROOT::EnableImplicitMT();; 978ROOT::RDataFrame df1(""tree1"", ""f1.root"");; 979ROOT::RDataFrame df2(""tree2"", ""f2.root"");; 980auto histo1 = df1.Histo1D(""x"");; 981auto histo2 = df2.Histo1D(""y"");; 982 ; 983// just accessing result pointers, the event loops of separate RDataFrames run one after the other; 984histo1->Draw(); // runs first multi-thread event loop; 985histo2->Draw(); // runs second multi-thread event loop; 986 ; 987// alternatively, with ROOT::RDF::RunGraphs, event loops for separate computation graphs can run concurrently; 988ROOT::RDF::RunGraphs({histo1, histo2});; 989histo1->Draw(); // results can then be used as usual; 990~~~; 991 ; 992### Performance considerations; 993 ; 994To obtain the maximum performance out of RDataFrame, make sure to avoid just-in-time compiled versions of transformations and actions if at all possible.; 995For instance, `Filter(""x > 0"")` requires just-in-time compilation of the corresponding C++ logic, while the equivalent `Filter([](float x) { return x > 0.; }, {""x""})` does not.; 996Similarly, `Histo1D(""x"")` requires just-in-time compilation after the type of `x` is retrieved from the dataset, while `Histo1D<float>(""x"")` does not; the latter spelling; 997should be preferred for performance-critical applications.; 998 ; 999Python applications cannot easily specify template parameters or pass C++ callables to RDataFrame.; 1000See [Efficient analysis in Python](#python) for possible ways to speed up hot paths in this case.; 1001 ; 1002Just-in-time compila",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:71632,Safety,detect,detects,71632,"4340705d2c4db7f8).; 1217 ; 1218\warning Note that in multi-thread event loops the values of `rdfentry_` _do not_ correspond to what would be the entry numbers; 1219of a TChain constructed over the same set of ROOT files, as the entries are processed in an unspecified order.; 1220 ; 1221\anchor jitting; 1222### Just-in-time compilation: column type inference and explicit declaration of column types; 1223C++ is a statically typed language: all types must be known at compile-time. This includes the types of the TTree; 1224branches we want to work on. For filters, defined columns and some of the actions, **column types are deduced from the; 1225signature** of the relevant filter function/temporary column expression/action function:; 1226~~~{.cpp}; 1227// here b1 is deduced to be `int` and b2 to be `double`; 1228df.Filter([](int x, double y) { return x > 0 && y < 0.; }, {""b1"", ""b2""});; 1229~~~; 1230If we specify an incorrect type for one of the columns, an exception with an informative message will be thrown at; 1231runtime, when the column value is actually read from the dataset: RDataFrame detects type mismatches. The same would; 1232happen if we swapped the order of ""b1"" and ""b2"" in the column list passed to Filter().; 1233 ; 1234Certain actions, on the other hand, do not take a function as argument (e.g. Histo1D()), so we cannot deduce the type of; 1235the column at compile-time. In this case **RDataFrame infers the type of the column** from the TTree itself. This; 1236is why we never needed to specify the column types for all actions in the above snippets.; 1237 ; 1238When the column type is not a common one such as `int`, `double`, `char` or `float` it is nonetheless good practice to; 1239specify it as a template parameter to the action itself, like this:; 1240~~~{.cpp}; 1241df.Histo1D(""b1""); // OK, the type of ""b1"" is deduced at runtime; 1242df.Min<MyNumber_t>(""myObject""); // OK, ""myObject"" is deduced to be of type `MyNumber_t`; 1243~~~; 1244 ; 1245Deducing types a",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:72887,Safety,avoid,avoids,72887,"In this case **RDataFrame infers the type of the column** from the TTree itself. This; 1236is why we never needed to specify the column types for all actions in the above snippets.; 1237 ; 1238When the column type is not a common one such as `int`, `double`, `char` or `float` it is nonetheless good practice to; 1239specify it as a template parameter to the action itself, like this:; 1240~~~{.cpp}; 1241df.Histo1D(""b1""); // OK, the type of ""b1"" is deduced at runtime; 1242df.Min<MyNumber_t>(""myObject""); // OK, ""myObject"" is deduced to be of type `MyNumber_t`; 1243~~~; 1244 ; 1245Deducing types at runtime requires the just-in-time compilation of the relevant actions, which has a small runtime; 1246overhead, so specifying the type of the columns as template parameters to the action is good practice when performance is a goal.; 1247 ; 1248When strings are passed as expressions to Filter() or Define(), fundamental types are passed as constants. This avoids certaincommon mistakes such as typing `x = 0` rather than `x == 0`:; 1249 ; 1250~~~{.cpp}; 1251// this throws an error (note the typo); 1252df.Define(""x"", ""0"").Filter(""x = 0"");; 1253~~~; 1254 ; 1255\anchor generic-actions; 1256### User-defined custom actions; 1257RDataFrame strives to offer a comprehensive set of standard actions that can be performed on each event. At the same; 1258time, it allows users to inject their own action code to perform arbitrarily complex data reductions.; 1259 ; 1260#### Implementing custom actions with Book(); 1261 ; 1262Through the Book() method, users can implement a custom action and have access to the same features; 1263that built-in RDataFrame actions have, e.g. hooks to events related to the start, end and execution of the; 1264event loop, or the possibility to return a lazy RResultPtr to an arbitrary type of result:; 1265 ; 1266~~~{.cpp}; 1267#include <ROOT/RDataFrame.hxx>; 1268#include <memory>; 1269 ; 1270class MyCounter : public ROOT::Detail::RDF::RActionImpl<MyCounter> {; 1271 std",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:76378,Safety,safe,safety,76378,"resultPtr.GetValue() << std::endl;; 1310}; 1311~~~; 1312 ; 1313See the Book() method for more information and [this tutorial](https://root.cern/doc/master/df018__customActions_8C.html); 1314for a more complete example.; 1315 ; 1316#### Injecting arbitrary code in the event loop with Foreach() and ForeachSlot(); 1317 ; 1318Foreach() takes a callable (lambda expression, free function, functor...) and a list of columns and; 1319executes the callable on the values of those columns for each event that passes all upstream selections.; 1320It can be used to perform actions that are not already available in the interface. For example, the following snippet; 1321evaluates the root mean square of column ""x"":; 1322~~~{.cpp}; 1323// Single-thread evaluation of RMS of column ""x"" using Foreach; 1324double sumSq = 0.;; 1325unsigned int n = 0;; 1326df.Foreach([&sumSq, &n](double x) { ++n; sumSq += x*x; }, {""x""});; 1327std::cout << ""rms of x: "" << std::sqrt(sumSq / n) << std::endl;; 1328~~~; 1329In multi-thread runs, users are responsible for the thread-safety of the expression passed to Foreach():; 1330thread will execute the expression concurrently.; 1331The code above would need to employ some resource protection mechanism to ensure non-concurrent writing of `rms`; but; 1332this is probably too much head-scratch for such a simple operation.; 1333 ; 1334ForeachSlot() can help in this situation. It is an alternative version of Foreach() for which the function takes an; 1335additional ""processing slot"" parameter besides the columns it should be applied to. RDataFrame; 1336guarantees that ForeachSlot() will invoke the user expression with different `slot` parameters for different concurrent; 1337executions (see [Special helper columns: rdfentry_ and rdfslot_](\ref helper-cols) for more information on the slot parameter).; 1338We can take advantage of ForeachSlot() to evaluate a thread-safe root mean square of column ""x"":; 1339~~~{.cpp}; 1340// Thread-safe evaluation of RMS of column ",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:77225,Safety,safe,safe,77225,"q += x*x; }, {""x""});; 1327std::cout << ""rms of x: "" << std::sqrt(sumSq / n) << std::endl;; 1328~~~; 1329In multi-thread runs, users are responsible for the thread-safety of the expression passed to Foreach():; 1330thread will execute the expression concurrently.; 1331The code above would need to employ some resource protection mechanism to ensure non-concurrent writing of `rms`; but; 1332this is probably too much head-scratch for such a simple operation.; 1333 ; 1334ForeachSlot() can help in this situation. It is an alternative version of Foreach() for which the function takes an; 1335additional ""processing slot"" parameter besides the columns it should be applied to. RDataFrame; 1336guarantees that ForeachSlot() will invoke the user expression with different `slot` parameters for different concurrent; 1337executions (see [Special helper columns: rdfentry_ and rdfslot_](\ref helper-cols) for more information on the slot parameter).; 1338We can take advantage of ForeachSlot() to evaluate a thread-safe root mean square of column ""x"":; 1339~~~{.cpp}; 1340// Thread-safe evaluation of RMS of column ""x"" using ForeachSlot; 1341ROOT::EnableImplicitMT();; 1342const unsigned int nSlots = df.GetNSlots();; 1343std::vector<double> sumSqs(nSlots, 0.);; 1344std::vector<unsigned int> ns(nSlots, 0);; 1345 ; 1346df.ForeachSlot([&sumSqs, &ns](unsigned int slot, double x) { sumSqs[slot] += x*x; ns[slot] += 1; }, {""x""});; 1347double sumSq = std::accumulate(sumSqs.begin(), sumSqs.end(), 0.); // sum all squares; 1348unsigned int n = std::accumulate(ns.begin(), ns.end(), 0); // sum all counts; 1349std::cout << ""rms of x: "" << std::sqrt(sumSq / n) << std::endl;; 1350~~~; 1351Notice how we created one `double` variable for each processing slot and later merged their results via `std::accumulate`.; 1352 ; 1353 ; 1354\anchor friends; 1355### Dataset joins with friend trees; 1356 ; 1357Vertically concatenating multiple trees that have the same columns (creating a logical dataset with the same col",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:77292,Safety,safe,safe,77292,"ers are responsible for the thread-safety of the expression passed to Foreach():; 1330thread will execute the expression concurrently.; 1331The code above would need to employ some resource protection mechanism to ensure non-concurrent writing of `rms`; but; 1332this is probably too much head-scratch for such a simple operation.; 1333 ; 1334ForeachSlot() can help in this situation. It is an alternative version of Foreach() for which the function takes an; 1335additional ""processing slot"" parameter besides the columns it should be applied to. RDataFrame; 1336guarantees that ForeachSlot() will invoke the user expression with different `slot` parameters for different concurrent; 1337executions (see [Special helper columns: rdfentry_ and rdfslot_](\ref helper-cols) for more information on the slot parameter).; 1338We can take advantage of ForeachSlot() to evaluate a thread-safe root mean square of column ""x"":; 1339~~~{.cpp}; 1340// Thread-safe evaluation of RMS of column ""x"" using ForeachSlot; 1341ROOT::EnableImplicitMT();; 1342const unsigned int nSlots = df.GetNSlots();; 1343std::vector<double> sumSqs(nSlots, 0.);; 1344std::vector<unsigned int> ns(nSlots, 0);; 1345 ; 1346df.ForeachSlot([&sumSqs, &ns](unsigned int slot, double x) { sumSqs[slot] += x*x; ns[slot] += 1; }, {""x""});; 1347double sumSq = std::accumulate(sumSqs.begin(), sumSqs.end(), 0.); // sum all squares; 1348unsigned int n = std::accumulate(ns.begin(), ns.end(), 0); // sum all counts; 1349std::cout << ""rms of x: "" << std::sqrt(sumSq / n) << std::endl;; 1350~~~; 1351Notice how we created one `double` variable for each processing slot and later merged their results via `std::accumulate`.; 1352 ; 1353 ; 1354\anchor friends; 1355### Dataset joins with friend trees; 1356 ; 1357Vertically concatenating multiple trees that have the same columns (creating a logical dataset with the same columns and; 1358more rows) is trivial in RDataFrame: just pass the tree name and a list of file names to RDataFrame's constructor",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:82120,Safety,detect,detects,82120,":RCsvDS which allows to read comma separated files:; 1413~~~{.cpp}; 1414auto tdf = ROOT::RDF::FromCSV(""MuRun2010B.csv"");; 1415auto filteredEvents =; 1416 tdf.Filter(""Q1 * Q2 == -1""); 1417 .Define(""m"", ""sqrt(pow(E1 + E2, 2) - (pow(px1 + px2, 2) + pow(py1 + py2, 2) + pow(pz1 + pz2, 2)))"");; 1418auto h = filteredEvents.Histo1D(""m"");; 1419h->Draw();; 1420~~~; 1421 ; 1422See also FromNumpy (Python-only), FromRNTuple(), FromArrow(), FromSqlite().; 1423 ; 1424\anchor callgraphs; 1425### Computation graphs (storing and reusing sets of transformations); 1426 ; 1427As we saw, transformed dataframes can be stored as variables and reused multiple times to create modified versions of the dataset. This implicitly defines a **computation graph** in which; 1428several paths of filtering/creation of columns are executed simultaneously, and finally aggregated results are produced.; 1429 ; 1430RDataFrame detects when several actions use the same filter or the same defined column, and **only evaluates each; 1431filter or defined column once per event**, regardless of how many times that result is used down the computation graph.; 1432Objects read from each column are **built once and never copied**, for maximum efficiency.; 1433When ""upstream"" filters are not passed, subsequent filters, temporary column expressions and actions are not evaluated,; 1434so it might be advisable to put the strictest filters first in the graph.; 1435 ; 1436\anchor representgraph; 1437### Visualizing the computation graph; 1438It is possible to print the computation graph from any node to obtain a [DOT (graphviz)](https://en.wikipedia.org/wiki/DOT_(graph_description_language)) representation either on the standard output; 1439or in a file.; 1440 ; 1441Invoking the function ROOT::RDF::SaveGraph() on any node that is not the head node, the computation graph of the branch; 1442the node belongs to is printed. By using the head node, the entire computation graph is printed.; 1443 ; 1444Following there is an exampl",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:2122,Security,access,access,2122,"> // for make_shared, allocator, shared_ptr; 27#include <ostream> // ostringstream; 28#include <stdexcept>; 29#include <string>; 30#include <vector>; 31 ; 32// clang-format off; 33/**; 34* \class ROOT::RDataFrame; 35* \ingroup dataframe; 36* \brief ROOT's RDataFrame offers a modern, high-level interface for analysis of data stored in TTree , CSV and other data formats, in C++ or Python.; 37 ; 38In addition, multi-threading and other low-level optimisations allow users to exploit all the resources available; 39on their machines completely transparently.<br>; 40Skip to the [class reference](#reference) or keep reading for the user guide.; 41 ; 42In a nutshell:; 43~~~{.cpp}; 44ROOT::EnableImplicitMT(); // Tell ROOT you want to go parallel; 45ROOT::RDataFrame d(""myTree"", ""file_*.root""); // Interface to TTree and TChain; 46auto myHisto = d.Histo1D(""Branch_A""); // This books the (lazy) filling of a histogram; 47myHisto->Draw(); // Event loop is run here, upon first access to a result; 48~~~; 49 ; 50Calculations are expressed in terms of a type-safe *functional chain of actions and transformations*, RDataFrame takes; 51care of their execution. The implementation automatically puts in place several low level optimisations such as; 52multi-thread parallelization and caching.; 53 ; 54\htmlonly; 55<a href=""https://doi.org/10.5281/zenodo.260230""><img src=""https://zenodo.org/badge/DOI/10.5281/zenodo.260230.svg""; 56alt=""DOI""></a>; 57\endhtmlonly; 58 ; 59## For the impatient user; 60You can directly see RDataFrame in action in our [tutorials](https://root.cern/doc/master/group__tutorial__dataframe.html), in C++ or Python.; 61 ; 62## Table of Contents; 63- [Cheat sheet](\ref cheatsheet); 64- [Introduction](\ref introduction); 65- [Crash course](\ref crash-course); 66- [Working with collections](\ref collections); 67- [Transformations: manipulating data](\ref transformations); 68- [Actions: getting results](\ref actions); 69- [Distributed execution in Python](\ref distrdf); 70- [Perf",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:7411,Security,access,accessed,7411,"p the entry, otherwise discard it. |; 109| Range() | Filter rows based on entry number (single-thread only). |; 110| Redefine() | Overwrite the value and/or type of an existing column. See Define() for more information. |; 111| RedefineSlot() | Overwrite the value and/or type of an existing column. See DefineSlot() for more information. |; 112| RedefineSlotEntry() | Overwrite the value and/or type of an existing column. See DefineSlotEntry() for more information. |; 113| Vary() | Register systematic variations for an existing column. Varied results are then extracted via VariationsFor(). |; 114 ; 115 ; 116### Actions; 117Actions aggregate data into a result. Each one is described in more detail in the reference guide.; 118 ; 119In the following, whenever we say an action ""returns"" something, we always mean it returns a smart pointer to it. Actions only act on events that pass all preceding filters.; 120 ; 121Lazy actions only trigger the event loop when one of the results is accessed for the first time, making it easy to; 122produce many different results in one event loop. Instant actions trigger the event loop instantly.; 123 ; 124 ; 125| **Lazy action** | **Description** |; 126|------------------|-----------------|; 127| Aggregate() | Execute a user-defined accumulation operation on the processed column values. |; 128| Book() | Book execution of a custom action using a user-defined helper object. |; 129| Cache() | Cache column values in memory. Custom columns can be cached as well, filtered entries are not cached. Users can specify which columns to save (default is all). |; 130| Count() | Return the number of events processed. Useful e.g. to get a quick count of the number of events passing a Filter. |; 131| Display() | Provides a printable representation of the dataset contents. The method returns a ROOT::RDF::RDisplay() instance which can print a tabular representation of the data or return it as a string. |; 132| Fill() | Fill a user-defined object with the val",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:14945,Security,access,accessed,14945,"oc/master/df027__SQliteDependencyOverVersion_8C.html), [RNTuples](https://root.cern/doc/master/structROOT_1_1Experimental_1_1RNTuple.html), and it can be extended to custom data formats. From Python, [NumPy arrays can be imported into RDataFrame](https://root.cern/doc/master/df032__MakeNumpyDataFrame_8py.html) as well.; 181 ; 1822. Transform the dataframe by:; 183 ; 184 - [Applying filters](https://root.cern/doc/master/classROOT_1_1RDataFrame.html#transformations). This selects only specific rows of the dataset.; 185 ; 186 - [Creating custom columns](https://root.cern/doc/master/classROOT_1_1RDataFrame.html#transformations). Custom columns can, for example, contain the results of a computation that must be performed for every row of the dataset.; 187 ; 1883. [Produce results](https://root.cern/doc/master/classROOT_1_1RDataFrame.html#actions). *Actions* are used to aggregate data into results. Most actions are *lazy*, i.e. they are not executed on the spot, but registered with RDataFrame and executed only when a result is accessed for the first time.; 189 ; 190Make sure to book all transformations and actions before you access the contents of any of the results. This lets RDataFrame accumulate work and then produce all results at the same time, upon first access to any of them.; 191 ; 192The following table shows how analyses based on TTreeReader and TTree::Draw() translate to RDataFrame. Follow the; 193[crash course](#crash-course) to discover more idiomatic and flexible ways to express analyses with RDataFrame.; 194<table>; 195<tr>; 196 <td>; 197 <b>TTreeReader</b>; 198 </td>; 199 <td>; 200 <b>ROOT::RDataFrame</b>; 201 </td>; 202</tr>; 203<tr>; 204 <td>; 205~~~{.cpp}; 206TTreeReader reader(""myTree"", file);; 207TTreeReaderValue<A_t> a(reader, ""A"");; 208TTreeReaderValue<B_t> b(reader, ""B"");; 209TTreeReaderValue<C_t> c(reader, ""C"");; 210while(reader.Next()) {; 211 if(IsGoodEvent(*a, *b, *c)); 212 DoStuff(*a, *b, *c);; 213}; 214~~~; 215 </td>; 216 <td>; 217~~~{.cpp}; 2",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:15045,Security,access,access,15045,"1_1RNTuple.html), and it can be extended to custom data formats. From Python, [NumPy arrays can be imported into RDataFrame](https://root.cern/doc/master/df032__MakeNumpyDataFrame_8py.html) as well.; 181 ; 1822. Transform the dataframe by:; 183 ; 184 - [Applying filters](https://root.cern/doc/master/classROOT_1_1RDataFrame.html#transformations). This selects only specific rows of the dataset.; 185 ; 186 - [Creating custom columns](https://root.cern/doc/master/classROOT_1_1RDataFrame.html#transformations). Custom columns can, for example, contain the results of a computation that must be performed for every row of the dataset.; 187 ; 1883. [Produce results](https://root.cern/doc/master/classROOT_1_1RDataFrame.html#actions). *Actions* are used to aggregate data into results. Most actions are *lazy*, i.e. they are not executed on the spot, but registered with RDataFrame and executed only when a result is accessed for the first time.; 189 ; 190Make sure to book all transformations and actions before you access the contents of any of the results. This lets RDataFrame accumulate work and then produce all results at the same time, upon first access to any of them.; 191 ; 192The following table shows how analyses based on TTreeReader and TTree::Draw() translate to RDataFrame. Follow the; 193[crash course](#crash-course) to discover more idiomatic and flexible ways to express analyses with RDataFrame.; 194<table>; 195<tr>; 196 <td>; 197 <b>TTreeReader</b>; 198 </td>; 199 <td>; 200 <b>ROOT::RDataFrame</b>; 201 </td>; 202</tr>; 203<tr>; 204 <td>; 205~~~{.cpp}; 206TTreeReader reader(""myTree"", file);; 207TTreeReaderValue<A_t> a(reader, ""A"");; 208TTreeReaderValue<B_t> b(reader, ""B"");; 209TTreeReaderValue<C_t> c(reader, ""C"");; 210while(reader.Next()) {; 211 if(IsGoodEvent(*a, *b, *c)); 212 DoStuff(*a, *b, *c);; 213}; 214~~~; 215 </td>; 216 <td>; 217~~~{.cpp}; 218ROOT::RDataFrame d(""myTree"", file, {""A"", ""B"", ""C""});; 219d.Filter(IsGoodEvent).Foreach(DoStuff);; 220~~~; 221 </td>; 222",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:15183,Security,access,access,15183,"taFrame](https://root.cern/doc/master/df032__MakeNumpyDataFrame_8py.html) as well.; 181 ; 1822. Transform the dataframe by:; 183 ; 184 - [Applying filters](https://root.cern/doc/master/classROOT_1_1RDataFrame.html#transformations). This selects only specific rows of the dataset.; 185 ; 186 - [Creating custom columns](https://root.cern/doc/master/classROOT_1_1RDataFrame.html#transformations). Custom columns can, for example, contain the results of a computation that must be performed for every row of the dataset.; 187 ; 1883. [Produce results](https://root.cern/doc/master/classROOT_1_1RDataFrame.html#actions). *Actions* are used to aggregate data into results. Most actions are *lazy*, i.e. they are not executed on the spot, but registered with RDataFrame and executed only when a result is accessed for the first time.; 189 ; 190Make sure to book all transformations and actions before you access the contents of any of the results. This lets RDataFrame accumulate work and then produce all results at the same time, upon first access to any of them.; 191 ; 192The following table shows how analyses based on TTreeReader and TTree::Draw() translate to RDataFrame. Follow the; 193[crash course](#crash-course) to discover more idiomatic and flexible ways to express analyses with RDataFrame.; 194<table>; 195<tr>; 196 <td>; 197 <b>TTreeReader</b>; 198 </td>; 199 <td>; 200 <b>ROOT::RDataFrame</b>; 201 </td>; 202</tr>; 203<tr>; 204 <td>; 205~~~{.cpp}; 206TTreeReader reader(""myTree"", file);; 207TTreeReaderValue<A_t> a(reader, ""A"");; 208TTreeReaderValue<B_t> b(reader, ""B"");; 209TTreeReaderValue<C_t> c(reader, ""C"");; 210while(reader.Next()) {; 211 if(IsGoodEvent(*a, *b, *c)); 212 DoStuff(*a, *b, *c);; 213}; 214~~~; 215 </td>; 216 <td>; 217~~~{.cpp}; 218ROOT::RDataFrame d(""myTree"", file, {""A"", ""B"", ""C""});; 219d.Filter(IsGoodEvent).Foreach(DoStuff);; 220~~~; 221 </td>; 222</tr>; 223<tr>; 224 <td>; 225 <b>TTree::Draw</b>; 226 </td>; 227 <td>; 228 <b>ROOT::RDataFrame</b>; 229 </td>; 230</",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:20704,Security,access,access,20704,"ee has a branch named ""MET"".; 331 ; 332Histo1D() is an *action*; it returns a smart pointer (a ROOT::RDF::RResultPtr, to be precise) to a TH1D histogram filled; 333with the `MET` of all events. If the quantity stored in the column is a collection (e.g. a vector or an array), the; 334histogram is filled with all vector elements for each event.; 335 ; 336You can use the objects returned by actions as if they were pointers to the desired results. There are many other; 337possible [actions](\ref cheatsheet), and all their results are wrapped in smart pointers; we'll see why in a minute.; 338 ; 339### Applying a filter; 340Let's say we want to cut over the value of branch ""MET"" and count how many events pass this cut. This is one way to do it:; 341~~~{.cpp}; 342RDataFrame d(""myTree"", ""file.root"");; 343auto c = d.Filter(""MET > 4."").Count(); // computations booked, not run; 344std::cout << *c << std::endl; // computations run here, upon first access to the result; 345~~~; 346The filter string (which must contain a valid C++ expression) is applied to the specified columns for each event;; 347the name and types of the columns are inferred automatically. The string expression is required to return a `bool`; 348which signals whether the event passes the filter (`true`) or not (`false`).; 349 ; 350You can think of your data as ""flowing"" through the chain of calls, being transformed, filtered and finally used to; 351perform actions. Multiple Filter() calls can be chained one after another.; 352 ; 353Using string filters is nice for simple things, but they are limited to specifying the equivalent of a single return; 354statement or the body of a lambda, so it's cumbersome to use strings with more complex filters. They also add a small; 355runtime overhead, as ROOT needs to just-in-time compile the string into C++ code. When more freedom is required or; 356runtime performance is very important, a C++ callable can be specified instead (a lambda in the following snippet,; 357but it ",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:29620,Security,access,accessing,29620,"set is only processed once.; 469~~~{.py}; 470df_correct = ROOT.RDataFrame(treename, filename);; 471 ; 472h_a = df_correct.Histo1D(""a""); 473h_b = df_correct.Histo1D(""b""); 474h_c = df_correct.Histo1D(""c""); 475 ; 476h_a_val = h_a.GetValue(); 477h_b_val = h_b.GetValue(); 478h_c_val = h_c.GetValue(); 479 ; 480print(f""How many times was the data set processed? {df_wrong.GetNRuns()} time."") # The answer will be 1 time. ; 481~~~; 482 ; 483An incorrect way - the dataset is processed three times.; 484~~~{.py}; 485df_incorrect = ROOT.RDataFrame(treename, filename);; 486 ; 487h_a = df_incorrect.Histo1D(""a""); 488h_a_val = h_a.GetValue(); 489 ; 490h_b = df_incorrect.Histo1D(""b""); 491h_b_val = h_b.GetValue(); 492 ; 493h_c = df_incorrect.Histo1D(""c""); 494h_c_val = h_c.GetValue(); 495 ; 496print(f""How many times was the data set processed? {df_wrong.GetNRuns()} times."") # The answer will be 3 times. ; 497~~~; 498 ; 499It is therefore good practice to declare all your transformations and actions *before* accessing their results, allowing; 500RDataFrame to run the loop once and produce all results in one go.; 501 ; 502### Going parallel; 503Let's say we would like to run the previous examples in parallel on several cores, dividing events fairly between cores.; 504The only modification required to the snippets would be the addition of this line *before* constructing the main; 505dataframe object:; 506~~~{.cpp}; 507ROOT::EnableImplicitMT();; 508~~~; 509Simple as that. More details are given [below](#parallel-execution).; 510 ; 511\anchor collections; 512## Working with collections and object selections; 513 ; 514RDataFrame reads collections as the special type [ROOT::RVec](https://root.cern/doc/master/classROOT_1_1VecOps_1_1RVec.html): for example, a column containing an array of floating point numbers can be read as a ROOT::RVecF. C-style arrays (with variable or static size), STL vectors and most other collection types can be read this way.; 515 ; 516RVec is a container similar to std:",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:32821,Security,access,access,32821,"e`) or not (`false`). It should perform ""read-only"" operations on the; 541columns, and should not have side-effects (e.g. modification of an external or static variable) to ensure correctness; 542when implicit multi-threading is active. The second overload takes a string with a valid C++ expression in which column; 543names are used as variable names (e.g. `Filter(""x[0] + x[1] > 0"")`). This is a convenience feature that comes with a; 544certain runtime overhead: C++ code has to be generated on the fly from this expression before using it in the event; 545loop. See the paragraph about ""Just-in-time compilation"" below for more information.; 546 ; 547RDataFrame only evaluates filters when necessary: if multiple filters are chained one after another, they are executed; 548in order and the first one returning `false` causes the event to be discarded and triggers the processing of the next; 549entry. If multiple actions or transformations depend on the same filter, that filter is not executed multiple times for; 550each entry: after the first access it simply serves a cached result.; 551 ; 552\anchor named-filters-and-cutflow-reports; 553#### Named filters and cutflow reports; 554An optional string parameter `name` can be passed to the Filter() method to create a **named filter**. Named filters; 555work as usual, but also keep track of how many entries they accept and reject.; 556 ; 557Statistics are retrieved through a call to the Report() method:; 558 ; 559- when Report() is called on the main RDataFrame object, it returns a ROOT::RDF::RResultPtr<RCutFlowReport> relative to all; 560named filters declared up to that point; 561- when called on a specific node (e.g. the result of a Define() or Filter()), it returns a ROOT::RDF::RResultPtr<RCutFlowReport>; 562relative all named filters in the section of the chain between the main RDataFrame and that node (included).; 563 ; 564Stats are stored in the same order as named filters have been added to the graph, and *refer to the",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:35804,Security,access,accessible,35804,"t the next 40 entries pass, then stop processing"". If a range node hangs from a filter node,; 582and the range has a `begin` parameter of 10, that means the range will skip the first 10 entries *that pass the; 583preceding filter*.; 584 ; 585Ranges allow ""early quitting"": if all branches of execution of a functional graph reached their `end` value of; 586processed entries, the event-loop is immediately interrupted. This is useful for debugging and quick data explorations.; 587 ; 588\anchor custom-columns; 589### Custom columns; 590Custom columns are created by invoking `Define(name, f, columnList)`. As usual, `f` can be any callable object; 591(function, lambda expression, functor class...); it takes the values of the columns listed in `columnList` (a list of; 592strings) as parameters, in the same order as they are listed in `columnList`. `f` must return the value that will be; 593assigned to the temporary column.; 594 ; 595A new variable is created called `name`, accessible as if it was contained in the dataset from subsequent; 596transformations/actions.; 597 ; 598Use cases include:; 599- caching the results of complex calculations for easy and efficient multiple access; 600- extraction of quantities of interest from complex objects; 601- branch aliasing, i.e. changing the name of a branch; 602 ; 603An exception is thrown if the `name` of the new column/branch is already in use for another branch in the TTree.; 604 ; 605It is also possible to specify the quantity to be stored in the new temporary column as a C++ expression with the method; 606`Define(name, expression)`. For example this invocation; 607 ; 608~~~{.cpp}; 609df.Define(""pt"", ""sqrt(px*px + py*py)"");; 610~~~; 611 ; 612will create a new column called ""pt"" the value of which is calculated starting from the columns px and py. The system; 613builds a just-in-time compiled function starting from the expression after having deduced the list of necessary branches; 614from the names of the variables specified by",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:36009,Security,access,access,36009,"first 10 entries *that pass the; 583preceding filter*.; 584 ; 585Ranges allow ""early quitting"": if all branches of execution of a functional graph reached their `end` value of; 586processed entries, the event-loop is immediately interrupted. This is useful for debugging and quick data explorations.; 587 ; 588\anchor custom-columns; 589### Custom columns; 590Custom columns are created by invoking `Define(name, f, columnList)`. As usual, `f` can be any callable object; 591(function, lambda expression, functor class...); it takes the values of the columns listed in `columnList` (a list of; 592strings) as parameters, in the same order as they are listed in `columnList`. `f` must return the value that will be; 593assigned to the temporary column.; 594 ; 595A new variable is created called `name`, accessible as if it was contained in the dataset from subsequent; 596transformations/actions.; 597 ; 598Use cases include:; 599- caching the results of complex calculations for easy and efficient multiple access; 600- extraction of quantities of interest from complex objects; 601- branch aliasing, i.e. changing the name of a branch; 602 ; 603An exception is thrown if the `name` of the new column/branch is already in use for another branch in the TTree.; 604 ; 605It is also possible to specify the quantity to be stored in the new temporary column as a C++ expression with the method; 606`Define(name, expression)`. For example this invocation; 607 ; 608~~~{.cpp}; 609df.Define(""pt"", ""sqrt(px*px + py*py)"");; 610~~~; 611 ; 612will create a new column called ""pt"" the value of which is calculated starting from the columns px and py. The system; 613builds a just-in-time compiled function starting from the expression after having deduced the list of necessary branches; 614from the names of the variables specified by the user.; 615 ; 616#### Custom columns as function of slot and entry number; 617 ; 618It is possible to create custom columns also as a function of the processing slot and en",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:37776,Security,access,accessed,37776,"after having deduced the list of necessary branches; 614from the names of the variables specified by the user.; 615 ; 616#### Custom columns as function of slot and entry number; 617 ; 618It is possible to create custom columns also as a function of the processing slot and entry numbers. The methods that can; 619be invoked are:; 620- `DefineSlot(name, f, columnList)`. In this case the callable f has this signature `R(unsigned int, T1, T2, ...)`: the; 621first parameter is the slot number which ranges from 0 to ROOT::GetThreadPoolSize() - 1.; 622- `DefineSlotEntry(name, f, columnList)`. In this case the callable f has this signature `R(unsigned int, ULong64_t,; 623T1, T2, ...)`: the first parameter is the slot number while the second one the number of the entry being processed.; 624 ; 625\anchor actions; 626## Actions: getting results; 627### Instant and lazy actions; 628Actions can be **instant** or **lazy**. Instant actions are executed as soon as they are called, while lazy actions are; 629executed whenever the object they return is accessed for the first time. As a rule of thumb, actions with a return value; 630are lazy, the others are instant.; 631 ; 632### Return type of a lazy action; 633 ; 634When a lazy action is called, it returns a \link ROOT::RDF::RResultPtr ROOT::RDF::RResultPtr<T>\endlink, where T is the; 635type of the result of the action. The final result will be stored in the `RResultPtr` and can be retrieved by; 636dereferencing it or via its `GetValue` method.; 637 ; 638### Actions that return collections; 639 ; 640If the type of the return value of an action is a collection, e.g. `std::vector<int>`, you can iterate its elements; 641directly through the wrapping `RResultPtr`:; 642 ; 643~~~{.cpp}; 644ROOT::RDataFrame df{5};; 645auto df1 = df.Define(""x"", []{ return 42; });; 646for (const auto &el: df1.Take<int>(""x"")){; 647 std::cout << ""Element: "" << el << ""\n"";; 648}; 649~~~; 650 ; 651~~~{.py}; 652df = ROOT.RDataFrame(5).Define(""x"", ""42""); 653for el",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:41962,Security,access,access,41962,"RDataFrame application distributedly. Nonetheless, not all; 701parts of the RDataFrame API currently work with this package. The subset that is currently available is:; 702- AsNumpy; 703- Count; 704- Define; 705- DefinePerSample; 706- Filter; 707- Graph; 708- Histo[1,2,3]D; 709- HistoND; 710- Max; 711- Mean; 712- Min; 713- Profile[1,2,3]D; 714- Redefine; 715- Snapshot; 716- Stats; 717- StdDev; 718- Sum; 719- Systematic variations: Vary and [VariationsFor](\ref ROOT::RDF::Experimental::VariationsFor).; 720- Parallel submission of distributed graphs: [RunGraphs](\ref ROOT::RDF::RunGraphs).; 721- Information about the dataframe: GetColumnNames.; 722 ; 723with support for more operations coming in the future. Data sources other than TTree and TChain (e.g. CSV, RNTuple) are; 724currently not supported.; 725 ; 726\note The distributed RDataFrame module requires at least Python version 3.8.; 727 ; 728### Connecting to a Spark cluster; 729 ; 730In order to distribute the RDataFrame workload, you can connect to a Spark cluster you have access to through the; 731official [Spark API](https://spark.apache.org/docs/latest/rdd-programming-guide.html#initializing-spark), then hook the; 732connection instance to the distributed `RDataFrame` object like so:; 733 ; 734~~~{.py}; 735import pyspark; 736import ROOT; 737 ; 738# Create a SparkContext object with the right configuration for your Spark cluster; 739conf = SparkConf().setAppName(appName).setMaster(master); 740sc = SparkContext(conf=conf); 741 ; 742# Point RDataFrame calls to the Spark specific RDataFrame; 743RDataFrame = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame; 744 ; 745# The Spark RDataFrame constructor accepts an optional ""sparkcontext"" parameter; 746# and it will distribute the application to the connected cluster; 747df = RDataFrame(""mytree"", ""myfile.root"", sparkcontext = sc); 748~~~; 749 ; 750If an instance of [SparkContext](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.SparkContext.html",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:43745,Security,expose,exposes,43745,"tribute the application to the connected cluster; 747df = RDataFrame(""mytree"", ""myfile.root"", sparkcontext = sc); 748~~~; 749 ; 750If an instance of [SparkContext](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.SparkContext.html); 751is not provided, the default behaviour is to create one in the background for you.; 752 ; 753### Connecting to a Dask cluster; 754 ; 755Similarly, you can connect to a Dask cluster by creating your own connection object which internally operates with one; 756of the cluster schedulers supported by Dask (more information in the; 757[Dask distributed docs](http://distributed.dask.org/en/stable/)):; 758 ; 759~~~{.py}; 760import ROOT; 761from dask.distributed import Client; 762 ; 763# Point RDataFrame calls to the Dask specific RDataFrame; 764RDataFrame = ROOT.RDF.Experimental.Distributed.Dask.RDataFrame; 765 ; 766# In a Python script the Dask client needs to be initalized in a context; 767# Jupyter notebooks / Python session don't need this; 768if __name__ == ""__main__"":; 769 # With an already setup cluster that exposes a Dask scheduler endpoint; 770 client = Client(""dask_scheduler.domain.com:8786""); 771 ; 772 # The Dask RDataFrame constructor accepts the Dask Client object as an optional argument; 773 df = RDataFrame(""mytree"",""myfile.root"", daskclient=client); 774 # Proceed as usual; 775 df.Define(""x"",""someoperation"").Histo1D((""name"", ""title"", 10, 0, 10), ""x""); 776~~~; 777 ; 778If an instance of [distributed.Client](http://distributed.dask.org/en/stable/api.html#distributed.Client) is not; 779provided to the RDataFrame object, it will be created for you and it will run the computations in the local machine; 780using all cores available.; 781 ; 782### Choosing the number of distributed tasks; 783 ; 784A distributed RDataFrame has internal logic to define in how many chunks the input dataset will be split before sending; 785tasks to the distributed backend. Each task reads and processes one of said chunks. The logic is ",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:45746,Security,access,access,45746,"gh the connection object. The number of; 787tasks will be equal to the inferred number of cores. There are cases where the connection object of the chosen backend; 788doesn't have information about the actual resources of the cluster. An example of this is when using Dask to connect to; 789a batch system. The client object created at the beginning of the application does not automatically know how many cores; 790will be available during distributed execution, since the jobs are submitted to the batch system after the creation of; 791the connection. In such cases, the logic is to default to process the whole dataset in 2 tasks.; 792 ; 793The number of tasks submitted for distributed execution can be also set programmatically, by providing the optional; 794keyword argument `npartitions` when creating the RDataFrame object. This parameter is accepted irrespectively of the; 795backend used:; 796 ; 797~~~{.py}; 798import ROOT; 799 ; 800# Define correct imports and access the distributed RDataFrame appropriate for the; 801# backend used in the analysis; 802RDataFrame = ROOT.RDF.Experimental.Distributed.[BACKEND].RDataFrame; 803 ; 804if __name__ == ""__main__"":; 805 # The `npartitions` optional argument tells the RDataFrame how many tasks are desired; 806 df = RDataFrame(""mytree"",""myfile.root"", npartitions=NPARTITIONS); 807 # Proceed as usual; 808 df.Define(""x"",""someoperation"").Histo1D((""name"", ""title"", 10, 0, 10), ""x""); 809~~~; 810 ; 811Note that when processing a TTree or TChain dataset, the `npartitions` value should not exceed the number of clusters in; 812the dataset. The number of clusters in a TTree can be retrieved by typing `rootls -lt myfile.root` at a command line.; 813 ; 814### Distributed Snapshot; 815 ; 816The Snapshot operation behaves slightly differently when executed distributedly. First off, it requires the path; 817supplied to the Snapshot call to be accessible from any worker of the cluster and from the client machine (in general; 818it should be provid",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:46667,Security,access,accessible,46667,"import ROOT; 799 ; 800# Define correct imports and access the distributed RDataFrame appropriate for the; 801# backend used in the analysis; 802RDataFrame = ROOT.RDF.Experimental.Distributed.[BACKEND].RDataFrame; 803 ; 804if __name__ == ""__main__"":; 805 # The `npartitions` optional argument tells the RDataFrame how many tasks are desired; 806 df = RDataFrame(""mytree"",""myfile.root"", npartitions=NPARTITIONS); 807 # Proceed as usual; 808 df.Define(""x"",""someoperation"").Histo1D((""name"", ""title"", 10, 0, 10), ""x""); 809~~~; 810 ; 811Note that when processing a TTree or TChain dataset, the `npartitions` value should not exceed the number of clusters in; 812the dataset. The number of clusters in a TTree can be retrieved by typing `rootls -lt myfile.root` at a command line.; 813 ; 814### Distributed Snapshot; 815 ; 816The Snapshot operation behaves slightly differently when executed distributedly. First off, it requires the path; 817supplied to the Snapshot call to be accessible from any worker of the cluster and from the client machine (in general; 818it should be provided as an absolute path). Another important difference is that `n` separate files will be produced,; 819where `n` is the number of dataset partitions. As with local RDataFrame, the result of a Snapshot on a distributed; 820RDataFrame is another distributed RDataFrame on which we can define a new computation graph and run more distributed; 821computations.; 822 ; 823### Distributed RunGraphs; 824 ; 825Submitting multiple distributed RDataFrame executions is supported through the RunGraphs function. Similarly to its; 826local counterpart, the function expects an iterable of objects representing an RDataFrame action. Each action will be; 827triggered concurrently to send multiple computation graphs to a distributed cluster at the same time:; 828 ; 829~~~{.py}; 830import ROOT; 831RDataFrame = ROOT.RDF.Experimental.Distributed.Dask.RDataFrame; 832RunGraphs = ROOT.RDF.Experimental.Distributed.RunGraphs; 833 ; 834# Cr",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:55758,Security,access,accessing,55758,"nalysis may require multiple separate RDataFrame computation graphs to produce all desired results. This poses the challenge that the; 973event loops of each computation graph can be parallelized, but the different loops run sequentially, one after the other.; 974On many-core architectures it might be desirable to run different event loops concurrently to improve resource usage.; 975ROOT::RDF::RunGraphs() allows running multiple RDataFrame event loops concurrently:; 976~~~{.cpp}; 977ROOT::EnableImplicitMT();; 978ROOT::RDataFrame df1(""tree1"", ""f1.root"");; 979ROOT::RDataFrame df2(""tree2"", ""f2.root"");; 980auto histo1 = df1.Histo1D(""x"");; 981auto histo2 = df2.Histo1D(""y"");; 982 ; 983// just accessing result pointers, the event loops of separate RDataFrames run one after the other; 984histo1->Draw(); // runs first multi-thread event loop; 985histo2->Draw(); // runs second multi-thread event loop; 986 ; 987// alternatively, with ROOT::RDF::RunGraphs, event loops for separate computation graphs can run concurrently; 988ROOT::RDF::RunGraphs({histo1, histo2});; 989histo1->Draw(); // results can then be used as usual; 990~~~; 991 ; 992### Performance considerations; 993 ; 994To obtain the maximum performance out of RDataFrame, make sure to avoid just-in-time compiled versions of transformations and actions if at all possible.; 995For instance, `Filter(""x > 0"")` requires just-in-time compilation of the corresponding C++ logic, while the equivalent `Filter([](float x) { return x > 0.; }, {""x""})` does not.; 996Similarly, `Histo1D(""x"")` requires just-in-time compilation after the type of `x` is retrieved from the dataset, while `Histo1D<float>(""x"")` does not; the latter spelling; 997should be preferred for performance-critical applications.; 998 ; 999Python applications cannot easily specify template parameters or pass C++ callables to RDataFrame.; 1000See [Efficient analysis in Python](#python) for possible ways to speed up hot paths in this case.; 1001 ; 1002Just-in-time compila",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:61343,Security,access,access,61343,"nsFor ""VariationsFor()"". In between these steps, no other change; 1038to the analysis code is required: the presence of systematic variations for certain columns is automatically propagated; 1039through filters, defines and actions, and RDataFrame will take these dependencies into account when producing varied; 1040results. \ref ROOT::RDF::Experimental::VariationsFor ""VariationsFor()"" is included in header `ROOT/RDFHelpers.hxx`. The compiled C++ programs must include this header; 1041explicitly, this is not required for ROOT macros. ; 1042 ; 1043An example usage of Vary() and \ref ROOT::RDF::Experimental::VariationsFor ""VariationsFor()"" in C++:; 1044 ; 1045~~~{.cpp}; 1046auto nominal_hx =; 1047 df.Vary(""pt"", ""ROOT::RVecD{pt*0.9f, pt*1.1f}"", {""down"", ""up""}); 1048 .Filter(""pt > pt_cut""); 1049 .Define(""x"", someFunc, {""pt""}); 1050 .Histo1D<float>(""x"");; 1051 ; 1052// request the generation of varied results from the nominal_hx; 1053ROOT::RDF::Experimental::RResultMap<TH1D> hx = ROOT::RDF::Experimental::VariationsFor(nominal_hx);; 1054 ; 1055// the event loop runs here, upon first access to any of the results or varied results:; 1056hx[""nominal""].Draw(); // same effect as nominal_hx->Draw(); 1057hx[""pt:down""].Draw(""SAME"");; 1058hx[""pt:up""].Draw(""SAME"");; 1059~~~; 1060 ; 1061A list of variation ""tags"" is passed as the last argument to Vary(). The tags give names to the varied values that are returned; 1062as elements of an RVec of the appropriate C++ type. The number of variation tags must correspond to the number of elements of; 1063this RVec (2 in the example above: the first element will correspond to the tag ""down"", the second; 1064to the tag ""up""). The _full_ variation name will be composed of the varied column name and the variation tags (e.g.; 1065""pt:down"", ""pt:up"" in this example). Python usage looks similar.; 1066 ; 1067Note how we use the ""pt"" column as usual in the Filter() and Define() calls and we simply use ""x"" as the value to fill; 1068the resulting histog",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:73305,Security,inject,inject,73305,"~~{.cpp}; 1241df.Histo1D(""b1""); // OK, the type of ""b1"" is deduced at runtime; 1242df.Min<MyNumber_t>(""myObject""); // OK, ""myObject"" is deduced to be of type `MyNumber_t`; 1243~~~; 1244 ; 1245Deducing types at runtime requires the just-in-time compilation of the relevant actions, which has a small runtime; 1246overhead, so specifying the type of the columns as template parameters to the action is good practice when performance is a goal.; 1247 ; 1248When strings are passed as expressions to Filter() or Define(), fundamental types are passed as constants. This avoids certaincommon mistakes such as typing `x = 0` rather than `x == 0`:; 1249 ; 1250~~~{.cpp}; 1251// this throws an error (note the typo); 1252df.Define(""x"", ""0"").Filter(""x = 0"");; 1253~~~; 1254 ; 1255\anchor generic-actions; 1256### User-defined custom actions; 1257RDataFrame strives to offer a comprehensive set of standard actions that can be performed on each event. At the same; 1258time, it allows users to inject their own action code to perform arbitrarily complex data reductions.; 1259 ; 1260#### Implementing custom actions with Book(); 1261 ; 1262Through the Book() method, users can implement a custom action and have access to the same features; 1263that built-in RDataFrame actions have, e.g. hooks to events related to the start, end and execution of the; 1264event loop, or the possibility to return a lazy RResultPtr to an arbitrary type of result:; 1265 ; 1266~~~{.cpp}; 1267#include <ROOT/RDataFrame.hxx>; 1268#include <memory>; 1269 ; 1270class MyCounter : public ROOT::Detail::RDF::RActionImpl<MyCounter> {; 1271 std::shared_ptr<int> fFinalResult = std::make_shared<int>(0);; 1272 std::vector<int> fPerThreadResults;; 1273 ; 1274public:; 1275 // We use a public type alias to advertise the type of the result of this action; 1276 using Result_t = int;; 1277 ; 1278 MyCounter(unsigned int nSlots) : fPerThreadResults(nSlots) {}; 1279 ; 1280 // Called before the event loop to retrieve the address of the resul",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:73523,Security,access,access,73523,"t`; 1243~~~; 1244 ; 1245Deducing types at runtime requires the just-in-time compilation of the relevant actions, which has a small runtime; 1246overhead, so specifying the type of the columns as template parameters to the action is good practice when performance is a goal.; 1247 ; 1248When strings are passed as expressions to Filter() or Define(), fundamental types are passed as constants. This avoids certaincommon mistakes such as typing `x = 0` rather than `x == 0`:; 1249 ; 1250~~~{.cpp}; 1251// this throws an error (note the typo); 1252df.Define(""x"", ""0"").Filter(""x = 0"");; 1253~~~; 1254 ; 1255\anchor generic-actions; 1256### User-defined custom actions; 1257RDataFrame strives to offer a comprehensive set of standard actions that can be performed on each event. At the same; 1258time, it allows users to inject their own action code to perform arbitrarily complex data reductions.; 1259 ; 1260#### Implementing custom actions with Book(); 1261 ; 1262Through the Book() method, users can implement a custom action and have access to the same features; 1263that built-in RDataFrame actions have, e.g. hooks to events related to the start, end and execution of the; 1264event loop, or the possibility to return a lazy RResultPtr to an arbitrary type of result:; 1265 ; 1266~~~{.cpp}; 1267#include <ROOT/RDataFrame.hxx>; 1268#include <memory>; 1269 ; 1270class MyCounter : public ROOT::Detail::RDF::RActionImpl<MyCounter> {; 1271 std::shared_ptr<int> fFinalResult = std::make_shared<int>(0);; 1272 std::vector<int> fPerThreadResults;; 1273 ; 1274public:; 1275 // We use a public type alias to advertise the type of the result of this action; 1276 using Result_t = int;; 1277 ; 1278 MyCounter(unsigned int nSlots) : fPerThreadResults(nSlots) {}; 1279 ; 1280 // Called before the event loop to retrieve the address of the result that will be filled/generated.; 1281 std::shared_ptr<int> GetResultPtr() const { return fFinalResult; }; 1282 ; 1283 // Called at the beginning of the event loop.; 1",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:86435,Security,access,accessed,86435,"fication JSON file needs to be provided by the user and it describes all necessary samples and; 1502their associated metadata information. The main required key is the ""samples"" (at least one sample is needed) and the; 1503required sub-keys for each sample are ""trees"" and ""files"". Additionally, one can specify a metadata dictionary for each; 1504sample in the ""metadata"" key.; 1505 ; 1506A simple example for the formatting of the specification in the JSON file is the following:; 1507 ; 1508~~~{.cpp}; 1509{; 1510 ""samples"": {; 1511 ""sampleA"": {; 1512 ""trees"": [""tree1"", ""tree2""],; 1513 ""files"": [""file1.root"", ""file2.root""],; 1514 ""metadata"": {; 1515 ""lumi"": 10000.0, ; 1516 ""xsec"": 1.0,; 1517 ""sample_category"" = ""data""; 1518 }; 1519 },; 1520 ""sampleB"": {; 1521 ""trees"": [""tree3"", ""tree4""],; 1522 ""files"": [""file3.root"", ""file4.root""],; 1523 ""metadata"": {; 1524 ""lumi"": 0.5, ; 1525 ""xsec"": 1.5,; 1526 ""sample_category"" = ""MC_background""; 1527 }; 1528 }; 1529 }; 1530}; 1531~~~; 1532 ; 1533The metadata information from the specification file can be then accessed using the DefinePerSample function.; 1534For example, to access luminosity information (stored as a double):; 1535 ; 1536~~~{.python}; 1537df.DefinePerSample(""lumi"", 'rdfsampleinfo_.GetD(""lumi"")'); 1538~~~; 1539 ; 1540or sample_category information (stored as a string):; 1541 ; 1542~~~{.python}; 1543df.DefinePerSample(""sample_category"", 'rdfsampleinfo_.GetS(""sample_category"")'); 1544~~~; 1545 ; 1546or directly the filename:; 1547 ; 1548~~~{.python}; 1549df.DefinePerSample(""name"", ""rdfsampleinfo_.GetSampleName()""); 1550~~~; 1551 ; 1552An example implementation of the ""FromSpec"" method is available in tutorial: df106_HiggstoFourLeptons.py, which also; 1553provides a corresponding exemplary JSON file for the dataset specification.; 1554 ; 1555\anchor progressbar; 1556### Adding a progress bar ; 1557 ; 1558A progress bar showing the processed event statistics can be added to any RDataFrame program.; 1559The event statistic",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:86501,Security,access,access,86501,"required key is the ""samples"" (at least one sample is needed) and the; 1503required sub-keys for each sample are ""trees"" and ""files"". Additionally, one can specify a metadata dictionary for each; 1504sample in the ""metadata"" key.; 1505 ; 1506A simple example for the formatting of the specification in the JSON file is the following:; 1507 ; 1508~~~{.cpp}; 1509{; 1510 ""samples"": {; 1511 ""sampleA"": {; 1512 ""trees"": [""tree1"", ""tree2""],; 1513 ""files"": [""file1.root"", ""file2.root""],; 1514 ""metadata"": {; 1515 ""lumi"": 10000.0, ; 1516 ""xsec"": 1.0,; 1517 ""sample_category"" = ""data""; 1518 }; 1519 },; 1520 ""sampleB"": {; 1521 ""trees"": [""tree3"", ""tree4""],; 1522 ""files"": [""file3.root"", ""file4.root""],; 1523 ""metadata"": {; 1524 ""lumi"": 0.5, ; 1525 ""xsec"": 1.5,; 1526 ""sample_category"" = ""MC_background""; 1527 }; 1528 }; 1529 }; 1530}; 1531~~~; 1532 ; 1533The metadata information from the specification file can be then accessed using the DefinePerSample function.; 1534For example, to access luminosity information (stored as a double):; 1535 ; 1536~~~{.python}; 1537df.DefinePerSample(""lumi"", 'rdfsampleinfo_.GetD(""lumi"")'); 1538~~~; 1539 ; 1540or sample_category information (stored as a string):; 1541 ; 1542~~~{.python}; 1543df.DefinePerSample(""sample_category"", 'rdfsampleinfo_.GetS(""sample_category"")'); 1544~~~; 1545 ; 1546or directly the filename:; 1547 ; 1548~~~{.python}; 1549df.DefinePerSample(""name"", ""rdfsampleinfo_.GetSampleName()""); 1550~~~; 1551 ; 1552An example implementation of the ""FromSpec"" method is available in tutorial: df106_HiggstoFourLeptons.py, which also; 1553provides a corresponding exemplary JSON file for the dataset specification.; 1554 ; 1555\anchor progressbar; 1556### Adding a progress bar ; 1557 ; 1558A progress bar showing the processed event statistics can be added to any RDataFrame program.; 1559The event statistics include elapsed time, currently processed file, currently processed events, the rate of event processing ; 1560and an estimated remaining time (per",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:91173,Security,access,access,91173,"they will either keep or discard an entire entry; 1614based on whether a condition returns true or false. Specifically:; 1615 ; 1616- FilterAvailable: the condition is whether the value of the column is present.; 1617 If so, the entry is kept. Otherwise if the value is missing the entry is; 1618 discarded.; 1619- FilterMissing: the condition is whether the value of the column is missing. If; 1620 so, the entry is kept. Otherwise if the value is present the entry is; 1621 discarded.; 1622 ; 1623\code{.py}; 1624df = ROOT.RDataFrame(dataset); 1625 ; 1626# Anytime an entry from ""col"" is missing, the entire entry will be filtered out; 1627df_available = df.FilterAvailable(""col""); 1628df_available = df_available.Define(""twice"", ""col * 2""); 1629 ; 1630# Conversely, if we want to select the entries for which the column has missing; 1631# values, we do the following; 1632df_missingcol = df.FilterMissing(""col""); 1633# Following operations in the same branch of the computation graph clearly; 1634# cannot access that same column, since there would be no value to read; 1635df_missingcol = df_missingcol.Define(""observable"", ""othercolumn * 2""); 1636\endcode; 1637 ; 1638\code{.cpp}; 1639ROOT::RDataFrame df{dataset};; 1640 ; 1641// Anytime an entry from ""col"" is missing, the entire entry will be filtered out; 1642auto df_available = df.FilterAvailable(""col"");; 1643auto df_twicecol = df_available.Define(""twice"", ""col * 2"");; 1644 ; 1645// Conversely, if we want to select the entries for which the column has missing; 1646// values, we do the following; 1647auto df_missingcol = df.FilterMissing(""col"");; 1648// Following operations in the same branch of the computation graph clearly; 1649// cannot access that same column, since there would be no value to read; 1650auto df_observable = df_missingcol.Define(""observable"", ""othercolumn * 2"");; 1651\endcode; 1652 ; 1653#### DefaultValueFor; 1654 ; 1655DefaultValueFor creates a node of the computation graph which just forwards the; 1656values ",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:91870,Security,access,access,91870,"le = df_available.Define(""twice"", ""col * 2""); 1629 ; 1630# Conversely, if we want to select the entries for which the column has missing; 1631# values, we do the following; 1632df_missingcol = df.FilterMissing(""col""); 1633# Following operations in the same branch of the computation graph clearly; 1634# cannot access that same column, since there would be no value to read; 1635df_missingcol = df_missingcol.Define(""observable"", ""othercolumn * 2""); 1636\endcode; 1637 ; 1638\code{.cpp}; 1639ROOT::RDataFrame df{dataset};; 1640 ; 1641// Anytime an entry from ""col"" is missing, the entire entry will be filtered out; 1642auto df_available = df.FilterAvailable(""col"");; 1643auto df_twicecol = df_available.Define(""twice"", ""col * 2"");; 1644 ; 1645// Conversely, if we want to select the entries for which the column has missing; 1646// values, we do the following; 1647auto df_missingcol = df.FilterMissing(""col"");; 1648// Following operations in the same branch of the computation graph clearly; 1649// cannot access that same column, since there would be no value to read; 1650auto df_observable = df_missingcol.Define(""observable"", ""othercolumn * 2"");; 1651\endcode; 1652 ; 1653#### DefaultValueFor; 1654 ; 1655DefaultValueFor creates a node of the computation graph which just forwards the; 1656values of the columns necessary for other downstream nodes, when they are; 1657available. In case a value of the input column passed to this function is not; 1658available, the node will provide the default value passed to this function call; 1659instead. Example:; 1660 ; 1661\code{.py}; 1662df = ROOT.RDataFrame(dataset); 1663# Anytime an entry from ""col"" is missing, the value will be the default one; 1664default_value = ... # Some sensible default value here; 1665df = df.DefaultValueFor(""col"", default_value) ; 1666df = df.Define(""twice"", ""col * 2""); 1667\endcode; 1668 ; 1669\code{.cpp}; 1670ROOT::RDataFrame df{dataset};; 1671// Anytime an entry from ""col"" is missing, the value will be the defaul",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:100568,Security,access,access,100568,"//////////////////////////////////////////////////////////; 1813/// \brief Build a dataframe that generates numEntries entries.; 1814/// \param[in] numEntries The number of entries to generate.; 1815///; 1816/// An empty-source dataframe constructed with a number of entries will; 1817/// generate those entries on the fly when some action is triggered,; 1818/// and it will do so for all the previously-defined columns.; 1819/// \see ROOT::RDF::RInterface for the documentation of the methods available.; 1820RDataFrame::RDataFrame(ULong64_t numEntries); 1821 : RInterface(std::make_shared<RDFDetail::RLoopManager>(numEntries)); 1822 ; 1823{; 1824}; 1825 ; 1826//////////////////////////////////////////////////////////////////////////; 1827/// \brief Build dataframe associated to data source.; 1828/// \param[in] ds The data source object.; 1829/// \param[in] defaultColumns Collection of default column names to fall back to when none is specified.; 1830///; 1831/// A dataframe associated to a data source will query it to access column values.; 1832/// \see ROOT::RDF::RInterface for the documentation of the methods available.; 1833RDataFrame::RDataFrame(std::unique_ptr<ROOT::RDF::RDataSource> ds, const ColumnNames_t &defaultColumns); 1834 : RInterface(std::make_shared<RDFDetail::RLoopManager>(std::move(ds), defaultColumns)); 1835{; 1836}; 1837 ; 1838//////////////////////////////////////////////////////////////////////////; 1839/// \brief Build dataframe from an RDatasetSpec object.; 1840/// \param[in] spec The dataset specification object.; 1841///; 1842/// A dataset specification includes trees and file names,; 1843/// as well as an optional friend list and/or entry range.; 1844///; 1845/// ### Example usage from Python:; 1846/// ~~~{.py}; 1847/// spec = (; 1848/// ROOT.RDF.Experimental.RDatasetSpec(); 1849/// .AddSample((""data"", ""tree"", ""file.root"")); 1850/// .WithGlobalFriends(""friendTree"", ""friend.root"", ""alias""); 1851/// .WithGlobalRange((100, 200)); 1852/// ); 1853/// d",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:4129,Testability,log,logs,4129,"the impatient user; 60You can directly see RDataFrame in action in our [tutorials](https://root.cern/doc/master/group__tutorial__dataframe.html), in C++ or Python.; 61 ; 62## Table of Contents; 63- [Cheat sheet](\ref cheatsheet); 64- [Introduction](\ref introduction); 65- [Crash course](\ref crash-course); 66- [Working with collections](\ref collections); 67- [Transformations: manipulating data](\ref transformations); 68- [Actions: getting results](\ref actions); 69- [Distributed execution in Python](\ref distrdf); 70- [Performance tips and parallel execution](\ref parallel-execution); 71- [More features](\ref more-features); 72 - [Systematic variations](\ref systematics); 73 - [RDataFrame objects as function arguments and return values](\ref rnode); 74 - [Storing RDataFrame objects in collections](\ref RDFCollections); 75 - [Executing callbacks every N events](\ref callbacks); 76 - [Default column lists](\ref default-branches); 77 - [Special helper columns: `rdfentry_` and `rdfslot_`](\ref helper-cols); 78 - [Just-in-time compilation: column type inference and explicit declaration of column types](\ref jitting); 79 - [User-defined custom actions](\ref generic-actions); 80 - [Dataset joins with friend trees](\ref friends); 81 - [Reading data formats other than ROOT trees](\ref other-file-formats); 82 - [Computation graphs (storing and reusing sets of transformations)](\ref callgraphs); 83 - [Visualizing the computation graph](\ref representgraph); 84 - [Activating RDataFrame execution logs](\ref rdf-logging); 85 - [Creating an RDataFrame from a dataset specification file](\ref rdf-from-spec); 86 - [Adding a progress bar](\ref progressbar); 87 - [Working with missing values in the dataset](\ref missing-values); 88- [Efficient analysis in Python](\ref python); 89- <a class=""el"" href=""classROOT_1_1RDataFrame.html#reference"" onclick=""javascript:toggleInherit('pub_methods_classROOT_1_1RDF_1_1RInterface')"">Class reference</a>; 90 ; 91\anchor cheatsheet; 92## Cheat sheet; ",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:4144,Testability,log,logging,4144,"the impatient user; 60You can directly see RDataFrame in action in our [tutorials](https://root.cern/doc/master/group__tutorial__dataframe.html), in C++ or Python.; 61 ; 62## Table of Contents; 63- [Cheat sheet](\ref cheatsheet); 64- [Introduction](\ref introduction); 65- [Crash course](\ref crash-course); 66- [Working with collections](\ref collections); 67- [Transformations: manipulating data](\ref transformations); 68- [Actions: getting results](\ref actions); 69- [Distributed execution in Python](\ref distrdf); 70- [Performance tips and parallel execution](\ref parallel-execution); 71- [More features](\ref more-features); 72 - [Systematic variations](\ref systematics); 73 - [RDataFrame objects as function arguments and return values](\ref rnode); 74 - [Storing RDataFrame objects in collections](\ref RDFCollections); 75 - [Executing callbacks every N events](\ref callbacks); 76 - [Default column lists](\ref default-branches); 77 - [Special helper columns: `rdfentry_` and `rdfslot_`](\ref helper-cols); 78 - [Just-in-time compilation: column type inference and explicit declaration of column types](\ref jitting); 79 - [User-defined custom actions](\ref generic-actions); 80 - [Dataset joins with friend trees](\ref friends); 81 - [Reading data formats other than ROOT trees](\ref other-file-formats); 82 - [Computation graphs (storing and reusing sets of transformations)](\ref callgraphs); 83 - [Visualizing the computation graph](\ref representgraph); 84 - [Activating RDataFrame execution logs](\ref rdf-logging); 85 - [Creating an RDataFrame from a dataset specification file](\ref rdf-from-spec); 86 - [Adding a progress bar](\ref progressbar); 87 - [Working with missing values in the dataset](\ref missing-values); 88- [Efficient analysis in Python](\ref python); 89- <a class=""el"" href=""classROOT_1_1RDataFrame.html#reference"" onclick=""javascript:toggleInherit('pub_methods_classROOT_1_1RDF_1_1RInterface')"">Class reference</a>; 90 ; 91\anchor cheatsheet; 92## Cheat sheet; ",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:44486,Testability,log,logic,44486,"perimental.Distributed.Dask.RDataFrame; 765 ; 766# In a Python script the Dask client needs to be initalized in a context; 767# Jupyter notebooks / Python session don't need this; 768if __name__ == ""__main__"":; 769 # With an already setup cluster that exposes a Dask scheduler endpoint; 770 client = Client(""dask_scheduler.domain.com:8786""); 771 ; 772 # The Dask RDataFrame constructor accepts the Dask Client object as an optional argument; 773 df = RDataFrame(""mytree"",""myfile.root"", daskclient=client); 774 # Proceed as usual; 775 df.Define(""x"",""someoperation"").Histo1D((""name"", ""title"", 10, 0, 10), ""x""); 776~~~; 777 ; 778If an instance of [distributed.Client](http://distributed.dask.org/en/stable/api.html#distributed.Client) is not; 779provided to the RDataFrame object, it will be created for you and it will run the computations in the local machine; 780using all cores available.; 781 ; 782### Choosing the number of distributed tasks; 783 ; 784A distributed RDataFrame has internal logic to define in how many chunks the input dataset will be split before sending; 785tasks to the distributed backend. Each task reads and processes one of said chunks. The logic is backend-dependent, but; 786generically tries to infer how many cores are available in the cluster through the connection object. The number of; 787tasks will be equal to the inferred number of cores. There are cases where the connection object of the chosen backend; 788doesn't have information about the actual resources of the cluster. An example of this is when using Dask to connect to; 789a batch system. The client object created at the beginning of the application does not automatically know how many cores; 790will be available during distributed execution, since the jobs are submitted to the batch system after the creation of; 791the connection. In such cases, the logic is to default to process the whole dataset in 2 tasks.; 792 ; 793The number of tasks submitted for distributed execution can be also set progr",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:44660,Testability,log,logic,44660,"setup cluster that exposes a Dask scheduler endpoint; 770 client = Client(""dask_scheduler.domain.com:8786""); 771 ; 772 # The Dask RDataFrame constructor accepts the Dask Client object as an optional argument; 773 df = RDataFrame(""mytree"",""myfile.root"", daskclient=client); 774 # Proceed as usual; 775 df.Define(""x"",""someoperation"").Histo1D((""name"", ""title"", 10, 0, 10), ""x""); 776~~~; 777 ; 778If an instance of [distributed.Client](http://distributed.dask.org/en/stable/api.html#distributed.Client) is not; 779provided to the RDataFrame object, it will be created for you and it will run the computations in the local machine; 780using all cores available.; 781 ; 782### Choosing the number of distributed tasks; 783 ; 784A distributed RDataFrame has internal logic to define in how many chunks the input dataset will be split before sending; 785tasks to the distributed backend. Each task reads and processes one of said chunks. The logic is backend-dependent, but; 786generically tries to infer how many cores are available in the cluster through the connection object. The number of; 787tasks will be equal to the inferred number of cores. There are cases where the connection object of the chosen backend; 788doesn't have information about the actual resources of the cluster. An example of this is when using Dask to connect to; 789a batch system. The client object created at the beginning of the application does not automatically know how many cores; 790will be available during distributed execution, since the jobs are submitted to the batch system after the creation of; 791the connection. In such cases, the logic is to default to process the whole dataset in 2 tasks.; 792 ; 793The number of tasks submitted for distributed execution can be also set programmatically, by providing the optional; 794keyword argument `npartitions` when creating the RDataFrame object. This parameter is accepted irrespectively of the; 795backend used:; 796 ; 797~~~{.py}; 798import ROOT; 799 ; 800# Define ",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:45346,Testability,log,logic,45346,"cores available.; 781 ; 782### Choosing the number of distributed tasks; 783 ; 784A distributed RDataFrame has internal logic to define in how many chunks the input dataset will be split before sending; 785tasks to the distributed backend. Each task reads and processes one of said chunks. The logic is backend-dependent, but; 786generically tries to infer how many cores are available in the cluster through the connection object. The number of; 787tasks will be equal to the inferred number of cores. There are cases where the connection object of the chosen backend; 788doesn't have information about the actual resources of the cluster. An example of this is when using Dask to connect to; 789a batch system. The client object created at the beginning of the application does not automatically know how many cores; 790will be available during distributed execution, since the jobs are submitted to the batch system after the creation of; 791the connection. In such cases, the logic is to default to process the whole dataset in 2 tasks.; 792 ; 793The number of tasks submitted for distributed execution can be also set programmatically, by providing the optional; 794keyword argument `npartitions` when creating the RDataFrame object. This parameter is accepted irrespectively of the; 795backend used:; 796 ; 797~~~{.py}; 798import ROOT; 799 ; 800# Define correct imports and access the distributed RDataFrame appropriate for the; 801# backend used in the analysis; 802RDataFrame = ROOT.RDF.Experimental.Distributed.[BACKEND].RDataFrame; 803 ; 804if __name__ == ""__main__"":; 805 # The `npartitions` optional argument tells the RDataFrame how many tasks are desired; 806 df = RDataFrame(""mytree"",""myfile.root"", npartitions=NPARTITIONS); 807 # Proceed as usual; 808 df.Define(""x"",""someoperation"").Histo1D((""name"", ""title"", 10, 0, 10), ""x""); 809~~~; 810 ; 811Note that when processing a TTree or TChain dataset, the `npartitions` value should not exceed the number of clusters in; 812the dataset. Th",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:56495,Testability,log,logic,56495,"running multiple RDataFrame event loops concurrently:; 976~~~{.cpp}; 977ROOT::EnableImplicitMT();; 978ROOT::RDataFrame df1(""tree1"", ""f1.root"");; 979ROOT::RDataFrame df2(""tree2"", ""f2.root"");; 980auto histo1 = df1.Histo1D(""x"");; 981auto histo2 = df2.Histo1D(""y"");; 982 ; 983// just accessing result pointers, the event loops of separate RDataFrames run one after the other; 984histo1->Draw(); // runs first multi-thread event loop; 985histo2->Draw(); // runs second multi-thread event loop; 986 ; 987// alternatively, with ROOT::RDF::RunGraphs, event loops for separate computation graphs can run concurrently; 988ROOT::RDF::RunGraphs({histo1, histo2});; 989histo1->Draw(); // results can then be used as usual; 990~~~; 991 ; 992### Performance considerations; 993 ; 994To obtain the maximum performance out of RDataFrame, make sure to avoid just-in-time compiled versions of transformations and actions if at all possible.; 995For instance, `Filter(""x > 0"")` requires just-in-time compilation of the corresponding C++ logic, while the equivalent `Filter([](float x) { return x > 0.; }, {""x""})` does not.; 996Similarly, `Histo1D(""x"")` requires just-in-time compilation after the type of `x` is retrieved from the dataset, while `Histo1D<float>(""x"")` does not; the latter spelling; 997should be preferred for performance-critical applications.; 998 ; 999Python applications cannot easily specify template parameters or pass C++ callables to RDataFrame.; 1000See [Efficient analysis in Python](#python) for possible ways to speed up hot paths in this case.; 1001 ; 1002Just-in-time compilation happens once, right before starting an event loop. To reduce the runtime cost of this step, make sure to book all operations *for all RDataFrame computation graphs*; 1003before the first event loop is triggered: just-in-time compilation will happen once for all code required to be generated up to that point, also across different computation graphs.; 1004 ; 1005Also make sure not to count the just-in-time co",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:57694,Testability,log,logging,57694,"should be preferred for performance-critical applications.; 998 ; 999Python applications cannot easily specify template parameters or pass C++ callables to RDataFrame.; 1000See [Efficient analysis in Python](#python) for possible ways to speed up hot paths in this case.; 1001 ; 1002Just-in-time compilation happens once, right before starting an event loop. To reduce the runtime cost of this step, make sure to book all operations *for all RDataFrame computation graphs*; 1003before the first event loop is triggered: just-in-time compilation will happen once for all code required to be generated up to that point, also across different computation graphs.; 1004 ; 1005Also make sure not to count the just-in-time compilation time (which happens once before the event loop and does not depend on the size of the dataset) as part of the event loop runtime (which scales with the size of the dataset). RDataFrame has an experimental logging feature that simplifies measuring the time spent in just-in-time compilation and in the event loop (as well as providing some more interesting information). See [Activating RDataFrame execution logs](\ref rdf-logging).; 1006 ; 1007### Memory usage; 1008 ; 1009There are two reasons why RDataFrame may consume more memory than expected. Firstly, each result is duplicated for each worker thread, which e.g. in case of many (possibly multi-dimensional) histograms with fine binning can result in visible memory consumption during the event loop. The thread-local copies of the results are destroyed when the final result is produced. Reducing the number of threads or using coarser binning will reduce the memory usage.; 1010 ; 1011Secondly, just-in-time compilation of string expressions or non-templated actions (see the previous paragraph) causes Cling, ROOT's C++ interpreter, to allocate some memory for the generated code that is only released at the end of the application. This commonly results in memory usage creep in long-running applications that c",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:57896,Testability,log,logs,57896,"s or pass C++ callables to RDataFrame.; 1000See [Efficient analysis in Python](#python) for possible ways to speed up hot paths in this case.; 1001 ; 1002Just-in-time compilation happens once, right before starting an event loop. To reduce the runtime cost of this step, make sure to book all operations *for all RDataFrame computation graphs*; 1003before the first event loop is triggered: just-in-time compilation will happen once for all code required to be generated up to that point, also across different computation graphs.; 1004 ; 1005Also make sure not to count the just-in-time compilation time (which happens once before the event loop and does not depend on the size of the dataset) as part of the event loop runtime (which scales with the size of the dataset). RDataFrame has an experimental logging feature that simplifies measuring the time spent in just-in-time compilation and in the event loop (as well as providing some more interesting information). See [Activating RDataFrame execution logs](\ref rdf-logging).; 1006 ; 1007### Memory usage; 1008 ; 1009There are two reasons why RDataFrame may consume more memory than expected. Firstly, each result is duplicated for each worker thread, which e.g. in case of many (possibly multi-dimensional) histograms with fine binning can result in visible memory consumption during the event loop. The thread-local copies of the results are destroyed when the final result is produced. Reducing the number of threads or using coarser binning will reduce the memory usage.; 1010 ; 1011Secondly, just-in-time compilation of string expressions or non-templated actions (see the previous paragraph) causes Cling, ROOT's C++ interpreter, to allocate some memory for the generated code that is only released at the end of the application. This commonly results in memory usage creep in long-running applications that create many RDataFrames one after the other. Possible mitigations include creating and running each RDataFrame event loop in a sub",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:57911,Testability,log,logging,57911,"s or pass C++ callables to RDataFrame.; 1000See [Efficient analysis in Python](#python) for possible ways to speed up hot paths in this case.; 1001 ; 1002Just-in-time compilation happens once, right before starting an event loop. To reduce the runtime cost of this step, make sure to book all operations *for all RDataFrame computation graphs*; 1003before the first event loop is triggered: just-in-time compilation will happen once for all code required to be generated up to that point, also across different computation graphs.; 1004 ; 1005Also make sure not to count the just-in-time compilation time (which happens once before the event loop and does not depend on the size of the dataset) as part of the event loop runtime (which scales with the size of the dataset). RDataFrame has an experimental logging feature that simplifies measuring the time spent in just-in-time compilation and in the event loop (as well as providing some more interesting information). See [Activating RDataFrame execution logs](\ref rdf-logging).; 1006 ; 1007### Memory usage; 1008 ; 1009There are two reasons why RDataFrame may consume more memory than expected. Firstly, each result is duplicated for each worker thread, which e.g. in case of many (possibly multi-dimensional) histograms with fine binning can result in visible memory consumption during the event loop. The thread-local copies of the results are destroyed when the final result is produced. Reducing the number of threads or using coarser binning will reduce the memory usage.; 1010 ; 1011Secondly, just-in-time compilation of string expressions or non-templated actions (see the previous paragraph) causes Cling, ROOT's C++ interpreter, to allocate some memory for the generated code that is only released at the end of the application. This commonly results in memory usage creep in long-running applications that create many RDataFrames one after the other. Possible mitigations include creating and running each RDataFrame event loop in a sub",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:78183,Testability,log,logical,78183,"thread-safe root mean square of column ""x"":; 1339~~~{.cpp}; 1340// Thread-safe evaluation of RMS of column ""x"" using ForeachSlot; 1341ROOT::EnableImplicitMT();; 1342const unsigned int nSlots = df.GetNSlots();; 1343std::vector<double> sumSqs(nSlots, 0.);; 1344std::vector<unsigned int> ns(nSlots, 0);; 1345 ; 1346df.ForeachSlot([&sumSqs, &ns](unsigned int slot, double x) { sumSqs[slot] += x*x; ns[slot] += 1; }, {""x""});; 1347double sumSq = std::accumulate(sumSqs.begin(), sumSqs.end(), 0.); // sum all squares; 1348unsigned int n = std::accumulate(ns.begin(), ns.end(), 0); // sum all counts; 1349std::cout << ""rms of x: "" << std::sqrt(sumSq / n) << std::endl;; 1350~~~; 1351Notice how we created one `double` variable for each processing slot and later merged their results via `std::accumulate`.; 1352 ; 1353 ; 1354\anchor friends; 1355### Dataset joins with friend trees; 1356 ; 1357Vertically concatenating multiple trees that have the same columns (creating a logical dataset with the same columns and; 1358more rows) is trivial in RDataFrame: just pass the tree name and a list of file names to RDataFrame's constructor, or create a TChain; 1359out of the desired trees and pass that to RDataFrame.; 1360 ; 1361Horizontal concatenations of trees or chains (creating a logical dataset with the same number of rows and the union of the; 1362columns of multiple trees) leverages TTree's ""friend"" mechanism.; 1363 ; 1364Simple joins of trees that do not have the same number of rows are also possible with indexed friend trees (see below).; 1365 ; 1366To use friend trees in RDataFrame, set up trees with the appropriate relationships and then instantiate an RDataFrame; 1367with the main tree:; 1368 ; 1369~~~{.cpp}; 1370TTree main([...]);; 1371TTree friend([...]);; 1372main.AddFriend(&friend, ""myFriend"");; 1373 ; 1374RDataFrame df(main);; 1375auto df2 = df.Filter(""myFriend.MyCol == 42"");; 1376~~~; 1377 ; 1378The same applies for TChains. Columns coming from the friend trees can be referred to",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:78492,Testability,log,logical,78492,"; 1346df.ForeachSlot([&sumSqs, &ns](unsigned int slot, double x) { sumSqs[slot] += x*x; ns[slot] += 1; }, {""x""});; 1347double sumSq = std::accumulate(sumSqs.begin(), sumSqs.end(), 0.); // sum all squares; 1348unsigned int n = std::accumulate(ns.begin(), ns.end(), 0); // sum all counts; 1349std::cout << ""rms of x: "" << std::sqrt(sumSq / n) << std::endl;; 1350~~~; 1351Notice how we created one `double` variable for each processing slot and later merged their results via `std::accumulate`.; 1352 ; 1353 ; 1354\anchor friends; 1355### Dataset joins with friend trees; 1356 ; 1357Vertically concatenating multiple trees that have the same columns (creating a logical dataset with the same columns and; 1358more rows) is trivial in RDataFrame: just pass the tree name and a list of file names to RDataFrame's constructor, or create a TChain; 1359out of the desired trees and pass that to RDataFrame.; 1360 ; 1361Horizontal concatenations of trees or chains (creating a logical dataset with the same number of rows and the union of the; 1362columns of multiple trees) leverages TTree's ""friend"" mechanism.; 1363 ; 1364Simple joins of trees that do not have the same number of rows are also possible with indexed friend trees (see below).; 1365 ; 1366To use friend trees in RDataFrame, set up trees with the appropriate relationships and then instantiate an RDataFrame; 1367with the main tree:; 1368 ; 1369~~~{.cpp}; 1370TTree main([...]);; 1371TTree friend([...]);; 1372main.AddFriend(&friend, ""myFriend"");; 1373 ; 1374RDataFrame df(main);; 1375auto df2 = df.Filter(""myFriend.MyCol == 42"");; 1376~~~; 1377 ; 1378The same applies for TChains. Columns coming from the friend trees can be referred to by their full name, like in the example above,; 1379or the friend tree name can be omitted in case the column name is not ambiguous (e.g. ""MyCol"" could be used instead of; 1380""myFriend.MyCol"" in the example above if there is no column ""MyCol"" in the main tree).; 1381 ; 1382\note A common source of confu",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:84096,Testability,log,logging,84096,"ted.; 1443 ; 1444Following there is an example of usage:; 1445~~~{.cpp}; 1446// First, a sample computational graph is built; 1447ROOT::RDataFrame df(""tree"", ""f.root"");; 1448 ; 1449auto df2 = df.Define(""x"", []() { return 1; }); 1450 .Filter(""col0 % 1 == col0""); 1451 .Filter([](int b1) { return b1 <2; }, {""cut1""}); 1452 .Define(""y"", []() { return 1; });; 1453 ; 1454auto count = df2.Count();; 1455 ; 1456// Prints the graph to the rd1.dot file in the current directory; 1457ROOT::RDF::SaveGraph(df, ""./mydot.dot"");; 1458// Prints the graph to standard output; 1459ROOT::RDF::SaveGraph(df);; 1460~~~; 1461 ; 1462The generated graph can be rendered using one of the graphviz filters, e.g. `dot`. For instance, the image below can be generated with the following command:; 1463~~~{.sh}; 1464$ dot -Tpng computation_graph.dot -ocomputation_graph.png; 1465~~~; 1466 ; 1467\image html RDF_Graph2.png; 1468 ; 1469\anchor rdf-logging; 1470### Activating RDataFrame execution logs; 1471 ; 1472RDataFrame has experimental support for verbose logging of the event loop runtimes and other interesting related information. It is activated as follows:; 1473~~~{.cpp}; 1474#include <ROOT/RLogger.hxx>; 1475 ; 1476// this increases RDF's verbosity level as long as the `verbosity` variable is in scope; 1477auto verbosity = ROOT::Experimental::RLogScopedVerbosity(ROOT::Detail::RDF::RDFLogChannel(), ROOT::Experimental::ELogLevel::kInfo);; 1478~~~; 1479 ; 1480or in Python:; 1481~~~{.python}; 1482import ROOT; 1483 ; 1484verbosity = ROOT.Experimental.RLogScopedVerbosity(ROOT.Detail.RDF.RDFLogChannel(), ROOT.Experimental.ELogLevel.kInfo); 1485~~~; 1486 ; 1487More information (e.g. start and end of each multi-thread task) is printed using `ELogLevel.kDebug` and even more; 1488(e.g. a full dump of the generated code that RDataFrame just-in-time-compiles) using `ELogLevel.kDebug+10`.; 1489 ; 1490\anchor rdf-from-spec; 1491### Creating an RDataFrame from a dataset specification file; 1492 ; 1493RDataFrame can be",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:84145,Testability,log,logs,84145,"ted.; 1443 ; 1444Following there is an example of usage:; 1445~~~{.cpp}; 1446// First, a sample computational graph is built; 1447ROOT::RDataFrame df(""tree"", ""f.root"");; 1448 ; 1449auto df2 = df.Define(""x"", []() { return 1; }); 1450 .Filter(""col0 % 1 == col0""); 1451 .Filter([](int b1) { return b1 <2; }, {""cut1""}); 1452 .Define(""y"", []() { return 1; });; 1453 ; 1454auto count = df2.Count();; 1455 ; 1456// Prints the graph to the rd1.dot file in the current directory; 1457ROOT::RDF::SaveGraph(df, ""./mydot.dot"");; 1458// Prints the graph to standard output; 1459ROOT::RDF::SaveGraph(df);; 1460~~~; 1461 ; 1462The generated graph can be rendered using one of the graphviz filters, e.g. `dot`. For instance, the image below can be generated with the following command:; 1463~~~{.sh}; 1464$ dot -Tpng computation_graph.dot -ocomputation_graph.png; 1465~~~; 1466 ; 1467\image html RDF_Graph2.png; 1468 ; 1469\anchor rdf-logging; 1470### Activating RDataFrame execution logs; 1471 ; 1472RDataFrame has experimental support for verbose logging of the event loop runtimes and other interesting related information. It is activated as follows:; 1473~~~{.cpp}; 1474#include <ROOT/RLogger.hxx>; 1475 ; 1476// this increases RDF's verbosity level as long as the `verbosity` variable is in scope; 1477auto verbosity = ROOT::Experimental::RLogScopedVerbosity(ROOT::Detail::RDF::RDFLogChannel(), ROOT::Experimental::ELogLevel::kInfo);; 1478~~~; 1479 ; 1480or in Python:; 1481~~~{.python}; 1482import ROOT; 1483 ; 1484verbosity = ROOT.Experimental.RLogScopedVerbosity(ROOT.Detail.RDF.RDFLogChannel(), ROOT.Experimental.ELogLevel.kInfo); 1485~~~; 1486 ; 1487More information (e.g. start and end of each multi-thread task) is printed using `ELogLevel.kDebug` and even more; 1488(e.g. a full dump of the generated code that RDataFrame just-in-time-compiles) using `ELogLevel.kDebug+10`.; 1489 ; 1490\anchor rdf-from-spec; 1491### Creating an RDataFrame from a dataset specification file; 1492 ; 1493RDataFrame can be",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:84210,Testability,log,logging,84210,"ted.; 1443 ; 1444Following there is an example of usage:; 1445~~~{.cpp}; 1446// First, a sample computational graph is built; 1447ROOT::RDataFrame df(""tree"", ""f.root"");; 1448 ; 1449auto df2 = df.Define(""x"", []() { return 1; }); 1450 .Filter(""col0 % 1 == col0""); 1451 .Filter([](int b1) { return b1 <2; }, {""cut1""}); 1452 .Define(""y"", []() { return 1; });; 1453 ; 1454auto count = df2.Count();; 1455 ; 1456// Prints the graph to the rd1.dot file in the current directory; 1457ROOT::RDF::SaveGraph(df, ""./mydot.dot"");; 1458// Prints the graph to standard output; 1459ROOT::RDF::SaveGraph(df);; 1460~~~; 1461 ; 1462The generated graph can be rendered using one of the graphviz filters, e.g. `dot`. For instance, the image below can be generated with the following command:; 1463~~~{.sh}; 1464$ dot -Tpng computation_graph.dot -ocomputation_graph.png; 1465~~~; 1466 ; 1467\image html RDF_Graph2.png; 1468 ; 1469\anchor rdf-logging; 1470### Activating RDataFrame execution logs; 1471 ; 1472RDataFrame has experimental support for verbose logging of the event loop runtimes and other interesting related information. It is activated as follows:; 1473~~~{.cpp}; 1474#include <ROOT/RLogger.hxx>; 1475 ; 1476// this increases RDF's verbosity level as long as the `verbosity` variable is in scope; 1477auto verbosity = ROOT::Experimental::RLogScopedVerbosity(ROOT::Detail::RDF::RDFLogChannel(), ROOT::Experimental::ELogLevel::kInfo);; 1478~~~; 1479 ; 1480or in Python:; 1481~~~{.python}; 1482import ROOT; 1483 ; 1484verbosity = ROOT.Experimental.RLogScopedVerbosity(ROOT.Detail.RDF.RDFLogChannel(), ROOT.Experimental.ELogLevel.kInfo); 1485~~~; 1486 ; 1487More information (e.g. start and end of each multi-thread task) is printed using `ELogLevel.kDebug` and even more; 1488(e.g. a full dump of the generated code that RDataFrame just-in-time-compiles) using `ELogLevel.kDebug+10`.; 1489 ; 1490\anchor rdf-from-spec; 1491### Creating an RDataFrame from a dataset specification file; 1492 ; 1493RDataFrame can be",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:1785,Usability,guid,guide,1785,"ROOT/RDF/RDatasetSpec.hxx""; 15#include ""ROOT/RDF/RInterface.hxx""; 16#include ""ROOT/RDF/RLoopManager.hxx""; 17#include ""ROOT/RDF/Utils.hxx""; 18#include <string_view>; 19#include ""TChain.h""; 20#include ""TDirectory.h""; 21#include ""RtypesCore.h"" // for ULong64_t; 22#include ""TTree.h""; 23 ; 24#include <fstream> // std::ifstream; 25#include <nlohmann/json.hpp> // nlohmann::json::parse; 26#include <memory> // for make_shared, allocator, shared_ptr; 27#include <ostream> // ostringstream; 28#include <stdexcept>; 29#include <string>; 30#include <vector>; 31 ; 32// clang-format off; 33/**; 34* \class ROOT::RDataFrame; 35* \ingroup dataframe; 36* \brief ROOT's RDataFrame offers a modern, high-level interface for analysis of data stored in TTree , CSV and other data formats, in C++ or Python.; 37 ; 38In addition, multi-threading and other low-level optimisations allow users to exploit all the resources available; 39on their machines completely transparently.<br>; 40Skip to the [class reference](#reference) or keep reading for the user guide.; 41 ; 42In a nutshell:; 43~~~{.cpp}; 44ROOT::EnableImplicitMT(); // Tell ROOT you want to go parallel; 45ROOT::RDataFrame d(""myTree"", ""file_*.root""); // Interface to TTree and TChain; 46auto myHisto = d.Histo1D(""Branch_A""); // This books the (lazy) filling of a histogram; 47myHisto->Draw(); // Event loop is run here, upon first access to a result; 48~~~; 49 ; 50Calculations are expressed in terms of a type-safe *functional chain of actions and transformations*, RDataFrame takes; 51care of their execution. The implementation automatically puts in place several low level optimisations such as; 52multi-thread parallelization and caching.; 53 ; 54\htmlonly; 55<a href=""https://doi.org/10.5281/zenodo.260230""><img src=""https://zenodo.org/badge/DOI/10.5281/zenodo.260230.svg""; 56alt=""DOI""></a>; 57\endhtmlonly; 58 ; 59## For the impatient user; 60You can directly see RDataFrame in action in our [tutorials](https://root.cern/doc/master/group__tutorial__d",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:4254,Usability,progress bar,progress bar,4254,"the impatient user; 60You can directly see RDataFrame in action in our [tutorials](https://root.cern/doc/master/group__tutorial__dataframe.html), in C++ or Python.; 61 ; 62## Table of Contents; 63- [Cheat sheet](\ref cheatsheet); 64- [Introduction](\ref introduction); 65- [Crash course](\ref crash-course); 66- [Working with collections](\ref collections); 67- [Transformations: manipulating data](\ref transformations); 68- [Actions: getting results](\ref actions); 69- [Distributed execution in Python](\ref distrdf); 70- [Performance tips and parallel execution](\ref parallel-execution); 71- [More features](\ref more-features); 72 - [Systematic variations](\ref systematics); 73 - [RDataFrame objects as function arguments and return values](\ref rnode); 74 - [Storing RDataFrame objects in collections](\ref RDFCollections); 75 - [Executing callbacks every N events](\ref callbacks); 76 - [Default column lists](\ref default-branches); 77 - [Special helper columns: `rdfentry_` and `rdfslot_`](\ref helper-cols); 78 - [Just-in-time compilation: column type inference and explicit declaration of column types](\ref jitting); 79 - [User-defined custom actions](\ref generic-actions); 80 - [Dataset joins with friend trees](\ref friends); 81 - [Reading data formats other than ROOT trees](\ref other-file-formats); 82 - [Computation graphs (storing and reusing sets of transformations)](\ref callgraphs); 83 - [Visualizing the computation graph](\ref representgraph); 84 - [Activating RDataFrame execution logs](\ref rdf-logging); 85 - [Creating an RDataFrame from a dataset specification file](\ref rdf-from-spec); 86 - [Adding a progress bar](\ref progressbar); 87 - [Working with missing values in the dataset](\ref missing-values); 88- [Efficient analysis in Python](\ref python); 89- <a class=""el"" href=""classROOT_1_1RDataFrame.html#reference"" onclick=""javascript:toggleInherit('pub_methods_classROOT_1_1RDF_1_1RInterface')"">Class reference</a>; 90 ; 91\anchor cheatsheet; 92## Cheat sheet; ",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:7142,Usability,guid,guide,7142,"lper-cols). |; 106| Filter() | Filter rows based on user-defined conditions. |; 107| FilterAvailable() | Specialized Filter. If the value of the input column is available, keep the entry, otherwise discard it. |; 108| FilterMissing() | Specialized Filter. If the value of the input column is missing, keep the entry, otherwise discard it. |; 109| Range() | Filter rows based on entry number (single-thread only). |; 110| Redefine() | Overwrite the value and/or type of an existing column. See Define() for more information. |; 111| RedefineSlot() | Overwrite the value and/or type of an existing column. See DefineSlot() for more information. |; 112| RedefineSlotEntry() | Overwrite the value and/or type of an existing column. See DefineSlotEntry() for more information. |; 113| Vary() | Register systematic variations for an existing column. Varied results are then extracted via VariationsFor(). |; 114 ; 115 ; 116### Actions; 117Actions aggregate data into a result. Each one is described in more detail in the reference guide.; 118 ; 119In the following, whenever we say an action ""returns"" something, we always mean it returns a smart pointer to it. Actions only act on events that pass all preceding filters.; 120 ; 121Lazy actions only trigger the event loop when one of the results is accessed for the first time, making it easy to; 122produce many different results in one event loop. Instant actions trigger the event loop instantly.; 123 ; 124 ; 125| **Lazy action** | **Description** |; 126|------------------|-----------------|; 127| Aggregate() | Execute a user-defined accumulation operation on the processed column values. |; 128| Book() | Book execution of a custom action using a user-defined helper object. |; 129| Cache() | Cache column values in memory. Custom columns can be cached as well, filtered entries are not cached. Users can specify which columns to save (default is all). |; 130| Count() | Return the number of events processed. Useful e.g. to get a quick count of the",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:11973,Usability,simpl,simply,11973," responsible for the thread-safety of this callable when executing with implicit multi-threading enabled. |; 151| ForeachSlot() | Same as Foreach(), but the user-defined function must take an extra `unsigned int slot` as its first parameter. `slot` will take a different value, `0` to `nThreads - 1`, for each thread of execution. This is meant as a helper in writing thread-safe Foreach() actions when using RDataFrame after ROOT::EnableImplicitMT(). ForeachSlot() works just as well with single-thread execution: in that case `slot` will always be `0`. |; 152| Snapshot() | Write the processed dataset to disk, in a new TTree and TFile. Custom columns can be saved as well, filtered entries are not saved. Users can specify which columns to save (default is all). Snapshot, by default, overwrites the output file if it already exists. Snapshot() can be made *lazy* setting the appropriate flag in the snapshot options.|; 153 ; 154 ; 155### Queries; 156 ; 157These operations do not modify the dataframe or book computations but simply return information on the RDataFrame object.; 158 ; 159| **Operation** | **Description** |; 160|---------------------|-----------------|; 161| Describe() | Get useful information describing the dataframe, e.g. columns and their types. |; 162| GetColumnNames() | Get the names of all the available columns of the dataset. |; 163| GetColumnType() | Return the type of a given column as a string. |; 164| GetColumnTypeNamesList() | Return the list of type names of columns in the dataset. |; 165| GetDefinedColumnNames() | Get the names of all the defined columns. |; 166| GetFilterNames() | Return the names of all filters in the computation graph. |; 167| GetNRuns() | Return the number of event loops run by this RDataFrame instance so far. |; 168| GetNSlots() | Return the number of processing slots that RDataFrame will use during the event loop (i.e. the concurrency level). |; 169| SaveGraph() | Store the computation graph of an RDataFrame in [DOT format (gra",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:18900,Usability,simpl,simple,18900,"et<TTree>(""treeName"");; 291 ; 292RDataFrame d1(""treeName"", ""file.root"");; 293RDataFrame d2(""treeName"", f); // same as TTreeReader; 294RDataFrame d3(*t);; 295 ; 296// multiple files -- all constructors are equivalent; 297TChain chain(""myTree"");; 298chain.Add(""file1.root"");; 299chain.Add(""file2.root"");; 300 ; 301RDataFrame d4(""myTree"", {""file1.root"", ""file2.root""});; 302std::vector<std::string> files = {""file1.root"", ""file2.root""};; 303RDataFrame d5(""myTree"", files);; 304RDataFrame d6(""myTree"", ""file*.root""); // the glob is passed as-is to TChain's constructor; 305RDataFrame d7(chain);; 306~~~; 307Additionally, users can construct an RDataFrame with no data source by passing an integer number. This is the number of rows that; 308will be generated by this RDataFrame.; 309~~~{.cpp}; 310RDataFrame d(10); // a RDF with 10 entries (and no columns/branches, for now); 311d.Foreach([] { static int i = 0; std::cout << i++ << std::endl; }); // silly example usage: count to ten; 312~~~; 313This is useful to generate simple datasets on the fly: the contents of each event can be specified with Define() (explained below). For example, we have used this method to generate [Pythia](https://pythia.org/) events and write them to disk in parallel (with the Snapshot action).; 314 ; 315For data sources other than TTrees and TChains, RDataFrame objects are constructed using ad-hoc factory functions (see e.g. FromCSV(), FromSqlite(), FromArrow()):; 316 ; 317~~~{.cpp}; 318auto df = ROOT::RDF::FromCSV(""input.csv"");; 319// use df as usual; 320~~~; 321 ; 322### Filling a histogram; 323Let's now tackle a very common task, filling a histogram:; 324~~~{.cpp}; 325// Fill a TH1D with the ""MET"" branch; 326RDataFrame d(""myTree"", ""file.root"");; 327auto h = d.Histo1D(""MET"");; 328h->Draw();; 329~~~; 330The first line creates an RDataFrame associated to the TTree ""myTree"". This tree has a branch named ""MET"".; 331 ; 332Histo1D() is an *action*; it returns a smart pointer (a ROOT::RDF::RResultPtr, to be pre",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:21299,Usability,simpl,simple,21299," filter; 340Let's say we want to cut over the value of branch ""MET"" and count how many events pass this cut. This is one way to do it:; 341~~~{.cpp}; 342RDataFrame d(""myTree"", ""file.root"");; 343auto c = d.Filter(""MET > 4."").Count(); // computations booked, not run; 344std::cout << *c << std::endl; // computations run here, upon first access to the result; 345~~~; 346The filter string (which must contain a valid C++ expression) is applied to the specified columns for each event;; 347the name and types of the columns are inferred automatically. The string expression is required to return a `bool`; 348which signals whether the event passes the filter (`true`) or not (`false`).; 349 ; 350You can think of your data as ""flowing"" through the chain of calls, being transformed, filtered and finally used to; 351perform actions. Multiple Filter() calls can be chained one after another.; 352 ; 353Using string filters is nice for simple things, but they are limited to specifying the equivalent of a single return; 354statement or the body of a lambda, so it's cumbersome to use strings with more complex filters. They also add a small; 355runtime overhead, as ROOT needs to just-in-time compile the string into C++ code. When more freedom is required or; 356runtime performance is very important, a C++ callable can be specified instead (a lambda in the following snippet,; 357but it can be any kind of function or even a functor class), together with a list of column names.; 358This snippet is analogous to the one above:; 359~~~{.cpp}; 360RDataFrame d(""myTree"", ""file.root"");; 361auto metCut = [](double x) { return x > 4.; }; // a C++11 lambda function checking ""x > 4""; 362auto c = d.Filter(metCut, {""MET""}).Count();; 363std::cout << *c << std::endl;; 364~~~; 365 ; 366An example of a more complex filter expressed as a string containing C++ code is shown below; 367 ; 368~~~{.cpp}; 369RDataFrame d(""myTree"", ""file.root"");; 370auto df = d.Define(""p"", ""std::array<double, 4> p{px, py, pz}; retur",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:32831,Usability,simpl,simply,32831,"e`) or not (`false`). It should perform ""read-only"" operations on the; 541columns, and should not have side-effects (e.g. modification of an external or static variable) to ensure correctness; 542when implicit multi-threading is active. The second overload takes a string with a valid C++ expression in which column; 543names are used as variable names (e.g. `Filter(""x[0] + x[1] > 0"")`). This is a convenience feature that comes with a; 544certain runtime overhead: C++ code has to be generated on the fly from this expression before using it in the event; 545loop. See the paragraph about ""Just-in-time compilation"" below for more information.; 546 ; 547RDataFrame only evaluates filters when necessary: if multiple filters are chained one after another, they are executed; 548in order and the first one returning `false` causes the event to be discarded and triggers the processing of the next; 549entry. If multiple actions or transformations depend on the same filter, that filter is not executed multiple times for; 550each entry: after the first access it simply serves a cached result.; 551 ; 552\anchor named-filters-and-cutflow-reports; 553#### Named filters and cutflow reports; 554An optional string parameter `name` can be passed to the Filter() method to create a **named filter**. Named filters; 555work as usual, but also keep track of how many entries they accept and reject.; 556 ; 557Statistics are retrieved through a call to the Report() method:; 558 ; 559- when Report() is called on the main RDataFrame object, it returns a ROOT::RDF::RResultPtr<RCutFlowReport> relative to all; 560named filters declared up to that point; 561- when called on a specific node (e.g. the result of a Define() or Filter()), it returns a ROOT::RDF::RResultPtr<RCutFlowReport>; 562relative all named filters in the section of the chain between the main RDataFrame and that node (included).; 563 ; 564Stats are stored in the same order as named filters have been added to the graph, and *refer to the",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:42062,Usability,guid,guide,42062,"ubset that is currently available is:; 702- AsNumpy; 703- Count; 704- Define; 705- DefinePerSample; 706- Filter; 707- Graph; 708- Histo[1,2,3]D; 709- HistoND; 710- Max; 711- Mean; 712- Min; 713- Profile[1,2,3]D; 714- Redefine; 715- Snapshot; 716- Stats; 717- StdDev; 718- Sum; 719- Systematic variations: Vary and [VariationsFor](\ref ROOT::RDF::Experimental::VariationsFor).; 720- Parallel submission of distributed graphs: [RunGraphs](\ref ROOT::RDF::RunGraphs).; 721- Information about the dataframe: GetColumnNames.; 722 ; 723with support for more operations coming in the future. Data sources other than TTree and TChain (e.g. CSV, RNTuple) are; 724currently not supported.; 725 ; 726\note The distributed RDataFrame module requires at least Python version 3.8.; 727 ; 728### Connecting to a Spark cluster; 729 ; 730In order to distribute the RDataFrame workload, you can connect to a Spark cluster you have access to through the; 731official [Spark API](https://spark.apache.org/docs/latest/rdd-programming-guide.html#initializing-spark), then hook the; 732connection instance to the distributed `RDataFrame` object like so:; 733 ; 734~~~{.py}; 735import pyspark; 736import ROOT; 737 ; 738# Create a SparkContext object with the right configuration for your Spark cluster; 739conf = SparkConf().setAppName(appName).setMaster(master); 740sc = SparkContext(conf=conf); 741 ; 742# Point RDataFrame calls to the Spark specific RDataFrame; 743RDataFrame = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame; 744 ; 745# The Spark RDataFrame constructor accepts an optional ""sparkcontext"" parameter; 746# and it will distribute the application to the connected cluster; 747df = RDataFrame(""mytree"", ""myfile.root"", sparkcontext = sc); 748~~~; 749 ; 750If an instance of [SparkContext](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.SparkContext.html); 751is not provided, the default behaviour is to create one in the background for you.; 752 ; 753### Connecting to a Dask cluste",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:53486,Usability,simpl,simple,53486,"in) in multi-thread runs.; 943 ; 944\warning By default, RDataFrame will use as many threads as the hardware supports, using up **all** the resources on; 945a machine. This might be undesirable on shared computing resources such as a batch cluster. Therefore, when running on shared computing resources, use; 946~~~{.cpp}; 947ROOT::EnableImplicitMT(i); 948~~~; 949replacing `i` with the number of CPUs/slots that were allocated for this job.; 950 ; 951### Thread-safety of user-defined expressions; 952RDataFrame operations such as Histo1D() or Snapshot() are guaranteed to work correctly in multi-thread event loops.; 953User-defined expressions, such as strings or lambdas passed to Filter(), Define(), Foreach(), Reduce() or Aggregate(); 954will have to be thread-safe, i.e. it should be possible to call them concurrently from different threads.; 955 ; 956Note that simple Filter() and Define() transformations will inherently satisfy this requirement: Filter() / Define(); 957expressions will often be *pure* in the functional programming sense (no side-effects, no dependency on external state),; 958which eliminates all risks of race conditions.; 959 ; 960In order to facilitate writing of thread-safe operations, some RDataFrame features such as Foreach(), Define() or \link ROOT::RDF::RResultPtr::OnPartialResult OnPartialResult()\endlink; 961offer thread-aware counterparts (ForeachSlot(), DefineSlot(), \link ROOT::RDF::RResultPtr::OnPartialResultSlot OnPartialResultSlot()\endlink): their only difference is that they; 962will pass an extra `slot` argument (an unsigned integer) to the user-defined expression. When calling user-defined code; 963concurrently, RDataFrame guarantees that different threads will employ different values of the `slot` parameter,; 964where `slot` will be a number between 0 and `GetNSlots() - 1`.; 965In other words, within a slot, computation runs sequentially and events are processed sequentially.; 966Note that the same slot might be associated to differen",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:57715,Usability,simpl,simplifies,57715,"should be preferred for performance-critical applications.; 998 ; 999Python applications cannot easily specify template parameters or pass C++ callables to RDataFrame.; 1000See [Efficient analysis in Python](#python) for possible ways to speed up hot paths in this case.; 1001 ; 1002Just-in-time compilation happens once, right before starting an event loop. To reduce the runtime cost of this step, make sure to book all operations *for all RDataFrame computation graphs*; 1003before the first event loop is triggered: just-in-time compilation will happen once for all code required to be generated up to that point, also across different computation graphs.; 1004 ; 1005Also make sure not to count the just-in-time compilation time (which happens once before the event loop and does not depend on the size of the dataset) as part of the event loop runtime (which scales with the size of the dataset). RDataFrame has an experimental logging feature that simplifies measuring the time spent in just-in-time compilation and in the event loop (as well as providing some more interesting information). See [Activating RDataFrame execution logs](\ref rdf-logging).; 1006 ; 1007### Memory usage; 1008 ; 1009There are two reasons why RDataFrame may consume more memory than expected. Firstly, each result is duplicated for each worker thread, which e.g. in case of many (possibly multi-dimensional) histograms with fine binning can result in visible memory consumption during the event loop. The thread-local copies of the results are destroyed when the final result is produced. Reducing the number of threads or using coarser binning will reduce the memory usage.; 1010 ; 1011Secondly, just-in-time compilation of string expressions or non-templated actions (see the previous paragraph) causes Cling, ROOT's C++ interpreter, to allocate some memory for the generated code that is only released at the end of the application. This commonly results in memory usage creep in long-running applications that c",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:62189,Usability,simpl,simply,62189,"he nominal_hx; 1053ROOT::RDF::Experimental::RResultMap<TH1D> hx = ROOT::RDF::Experimental::VariationsFor(nominal_hx);; 1054 ; 1055// the event loop runs here, upon first access to any of the results or varied results:; 1056hx[""nominal""].Draw(); // same effect as nominal_hx->Draw(); 1057hx[""pt:down""].Draw(""SAME"");; 1058hx[""pt:up""].Draw(""SAME"");; 1059~~~; 1060 ; 1061A list of variation ""tags"" is passed as the last argument to Vary(). The tags give names to the varied values that are returned; 1062as elements of an RVec of the appropriate C++ type. The number of variation tags must correspond to the number of elements of; 1063this RVec (2 in the example above: the first element will correspond to the tag ""down"", the second; 1064to the tag ""up""). The _full_ variation name will be composed of the varied column name and the variation tags (e.g.; 1065""pt:down"", ""pt:up"" in this example). Python usage looks similar.; 1066 ; 1067Note how we use the ""pt"" column as usual in the Filter() and Define() calls and we simply use ""x"" as the value to fill; 1068the resulting histogram. To produce the varied results, RDataFrame will automatically execute the Filter and Define; 1069calls for each variation and fill the histogram with values and cuts that depend on the variation.; 1070 ; 1071There is no limitation to the complexity of a Vary() expression. Just like for the Define() and Filter() calls, users are; 1072not limited to string expressions but they can also pass any valid C++ callable, including lambda functions and; 1073complex functors. The callable can be applied to zero or more existing columns and it will always receive their; 1074_nominal_ value in input.; 1075 ; 1076#### Varying multiple columns in lockstep; 1077 ; 1078In the following Python snippet we use the Vary() signature that allows varying multiple columns simultaneously or; 1079""in lockstep"":; 1080 ; 1081~~~{.python}; 1082df.Vary([""pt"", ""eta""],; 1083 ""RVec<RVecF>{{pt*0.9, pt*1.1}, {eta*0.9, eta*1.1}}"",; 1084 variat",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:64963,Usability,feedback,feedback,64963,"ill be no result produced; 1097by applying multiple systematic variations at the same time.; 1098For example, in the following example snippet, the RResultMap instance `all_h` will contain keys ""nominal"", ""pt:down"",; 1099""pt:up"", ""eta:0"", ""eta:1"", but no ""pt:up&&eta:0"" or similar:; 1100 ; 1101~~~{.cpp}; 1102auto df = _df.Vary(""pt"",; 1103 ""ROOT::RVecD{pt*0.9, pt*1.1}"",; 1104 {""down"", ""up""}); 1105 .Vary(""eta"",; 1106 [](float eta) { return RVecF{eta*0.9f, eta*1.1f}; },; 1107 {""eta""},; 1108 2);; 1109 ; 1110auto nom_h = df.Histo2D(histoModel, ""pt"", ""eta"");; 1111auto all_hs = VariationsFor(nom_h);; 1112all_hs.GetKeys(); // returns {""nominal"", ""pt:down"", ""pt:up"", ""eta:0"", ""eta:1""}; 1113~~~; 1114 ; 1115Note how we passed the integer `2` instead of a list of variation tags to the second Vary() invocation: this is a; 1116shorthand that automatically generates tags 0 to N-1 (in this case 0 and 1).; 1117 ; 1118\note Currently, VariationsFor() and RResultMap are in the `ROOT::RDF::Experimental` namespace, to indicate that these; 1119 interfaces might still evolve and improve based on user feedback. We expect that some aspects of the related; 1120 programming model will be streamlined in future versions.; 1121 ; 1122\note Currently, the results of a Snapshot(), Report() or Display() call cannot be varied (i.e. it is not possible to; 1123 call \ref ROOT::RDF::Experimental::VariationsFor ""VariationsFor()"" on them. These limitations will be lifted in future releases.; 1124 ; 1125See the Vary() method for more information and [this tutorial](https://root.cern/doc/master/df106__HiggsToFourLeptons_8C.html) ; 1126for an example usage of Vary and \ref ROOT::RDF::Experimental::VariationsFor ""VariationsFor()"" in the analysis.; 1127 ; 1128\anchor rnode; 1129### RDataFrame objects as function arguments and return values; 1130RDataFrame variables/nodes are relatively cheap to copy and it's possible to both pass them to (or move them into); 1131functions and to return them from functions. Howev",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:66330,Usability,simpl,simpler,66330,"nformation and [this tutorial](https://root.cern/doc/master/df106__HiggsToFourLeptons_8C.html) ; 1126for an example usage of Vary and \ref ROOT::RDF::Experimental::VariationsFor ""VariationsFor()"" in the analysis.; 1127 ; 1128\anchor rnode; 1129### RDataFrame objects as function arguments and return values; 1130RDataFrame variables/nodes are relatively cheap to copy and it's possible to both pass them to (or move them into); 1131functions and to return them from functions. However, in general each dataframe node will have a different C++ type,; 1132which includes all available compile-time information about what that node does. One way to cope with this complication; 1133is to use template functions and/or C++14 auto return types:; 1134~~~{.cpp}; 1135template <typename RDF>; 1136auto ApplySomeFilters(RDF df); 1137{; 1138 return df.Filter(""x > 0"").Filter([](int y) { return y < 0; }, {""y""});; 1139}; 1140~~~; 1141 ; 1142A possibly simpler, C++11-compatible alternative is to take advantage of the fact that any dataframe node can be; 1143converted (implicitly or via an explicit cast) to the common type ROOT::RDF::RNode:; 1144~~~{.cpp}; 1145// a function that conditionally adds a Range to an RDataFrame node.; 1146RNode MaybeAddRange(RNode df, bool mustAddRange); 1147{; 1148 return mustAddRange ? df.Range(1) : df;; 1149}; 1150// use as :; 1151ROOT::RDataFrame df(10);; 1152auto maybeRangedDF = MaybeAddRange(df, true);; 1153~~~; 1154 ; 1155The conversion to ROOT::RDF::RNode is cheap, but it will introduce an extra virtual call during the RDataFrame event; 1156loop (in most cases, the resulting performance impact should be negligible). Python users can perform the conversion with the helper function `ROOT.RDF.AsRNode`.; 1157 ; 1158\anchor RDFCollections; 1159### Storing RDataFrame objects in collections; 1160 ; 1161ROOT::RDF::RNode also makes it simple to store RDataFrame nodes in collections, e.g. a `std::vector<RNode>` or a `std::map<std::string, RNode>`:; 1162 ; 1163~~~{.cp",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:67256,Usability,simpl,simple,67256,"1138 return df.Filter(""x > 0"").Filter([](int y) { return y < 0; }, {""y""});; 1139}; 1140~~~; 1141 ; 1142A possibly simpler, C++11-compatible alternative is to take advantage of the fact that any dataframe node can be; 1143converted (implicitly or via an explicit cast) to the common type ROOT::RDF::RNode:; 1144~~~{.cpp}; 1145// a function that conditionally adds a Range to an RDataFrame node.; 1146RNode MaybeAddRange(RNode df, bool mustAddRange); 1147{; 1148 return mustAddRange ? df.Range(1) : df;; 1149}; 1150// use as :; 1151ROOT::RDataFrame df(10);; 1152auto maybeRangedDF = MaybeAddRange(df, true);; 1153~~~; 1154 ; 1155The conversion to ROOT::RDF::RNode is cheap, but it will introduce an extra virtual call during the RDataFrame event; 1156loop (in most cases, the resulting performance impact should be negligible). Python users can perform the conversion with the helper function `ROOT.RDF.AsRNode`.; 1157 ; 1158\anchor RDFCollections; 1159### Storing RDataFrame objects in collections; 1160 ; 1161ROOT::RDF::RNode also makes it simple to store RDataFrame nodes in collections, e.g. a `std::vector<RNode>` or a `std::map<std::string, RNode>`:; 1162 ; 1163~~~{.cpp}; 1164std::vector<ROOT::RDF::RNode> dfs;; 1165dfs.emplace_back(ROOT::RDataFrame(10));; 1166dfs.emplace_back(dfs[0].Define(""x"", ""42.f""));; 1167~~~; 1168 ; 1169\anchor callbacks; 1170### Executing callbacks every N events; 1171It's possible to schedule execution of arbitrary functions (callbacks) during the event loop.; 1172Callbacks can be used e.g. to inspect partial results of the analysis while the event loop is running,; 1173drawing a partially-filled histogram every time a certain number of new entries is processed, or; 1174displaying a progress bar while the event loop runs.; 1175 ; 1176For example one can draw an up-to-date version of a result histogram every 100 entries like this:; 1177~~~{.cpp}; 1178auto h = df.Histo1D(""x"");; 1179TCanvas c(""c"",""x hist"");; 1180h.OnPartialResult(100, [&c](TH1D &h_) { c.cd(); ",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:67938,Usability,progress bar,progress bar,67938,"o ROOT::RDF::RNode is cheap, but it will introduce an extra virtual call during the RDataFrame event; 1156loop (in most cases, the resulting performance impact should be negligible). Python users can perform the conversion with the helper function `ROOT.RDF.AsRNode`.; 1157 ; 1158\anchor RDFCollections; 1159### Storing RDataFrame objects in collections; 1160 ; 1161ROOT::RDF::RNode also makes it simple to store RDataFrame nodes in collections, e.g. a `std::vector<RNode>` or a `std::map<std::string, RNode>`:; 1162 ; 1163~~~{.cpp}; 1164std::vector<ROOT::RDF::RNode> dfs;; 1165dfs.emplace_back(ROOT::RDataFrame(10));; 1166dfs.emplace_back(dfs[0].Define(""x"", ""42.f""));; 1167~~~; 1168 ; 1169\anchor callbacks; 1170### Executing callbacks every N events; 1171It's possible to schedule execution of arbitrary functions (callbacks) during the event loop.; 1172Callbacks can be used e.g. to inspect partial results of the analysis while the event loop is running,; 1173drawing a partially-filled histogram every time a certain number of new entries is processed, or; 1174displaying a progress bar while the event loop runs.; 1175 ; 1176For example one can draw an up-to-date version of a result histogram every 100 entries like this:; 1177~~~{.cpp}; 1178auto h = df.Histo1D(""x"");; 1179TCanvas c(""c"",""x hist"");; 1180h.OnPartialResult(100, [&c](TH1D &h_) { c.cd(); h_.Draw(); c.Update(); });; 1181// event loop runs here, this final `Draw` is executed after the event loop is finished; 1182h->Draw();; 1183~~~; 1184 ; 1185Callbacks are registered to a ROOT::RDF::RResultPtr and must be callables that takes a reference to the result type as argument; 1186and return nothing. RDataFrame will invoke registered callbacks passing partial action results as arguments to them; 1187(e.g. a histogram filled with a part of the selected events).; 1188 ; 1189Read more on ROOT::RDF::RResultPtr::OnPartialResult() and ROOT::RDF::RResultPtr::OnPartialResultSlot().; 1190 ; 1191\anchor default-branches; 1192### Default",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:76656,Usability,simpl,simple,76656,"trary code in the event loop with Foreach() and ForeachSlot(); 1317 ; 1318Foreach() takes a callable (lambda expression, free function, functor...) and a list of columns and; 1319executes the callable on the values of those columns for each event that passes all upstream selections.; 1320It can be used to perform actions that are not already available in the interface. For example, the following snippet; 1321evaluates the root mean square of column ""x"":; 1322~~~{.cpp}; 1323// Single-thread evaluation of RMS of column ""x"" using Foreach; 1324double sumSq = 0.;; 1325unsigned int n = 0;; 1326df.Foreach([&sumSq, &n](double x) { ++n; sumSq += x*x; }, {""x""});; 1327std::cout << ""rms of x: "" << std::sqrt(sumSq / n) << std::endl;; 1328~~~; 1329In multi-thread runs, users are responsible for the thread-safety of the expression passed to Foreach():; 1330thread will execute the expression concurrently.; 1331The code above would need to employ some resource protection mechanism to ensure non-concurrent writing of `rms`; but; 1332this is probably too much head-scratch for such a simple operation.; 1333 ; 1334ForeachSlot() can help in this situation. It is an alternative version of Foreach() for which the function takes an; 1335additional ""processing slot"" parameter besides the columns it should be applied to. RDataFrame; 1336guarantees that ForeachSlot() will invoke the user expression with different `slot` parameters for different concurrent; 1337executions (see [Special helper columns: rdfentry_ and rdfslot_](\ref helper-cols) for more information on the slot parameter).; 1338We can take advantage of ForeachSlot() to evaluate a thread-safe root mean square of column ""x"":; 1339~~~{.cpp}; 1340// Thread-safe evaluation of RMS of column ""x"" using ForeachSlot; 1341ROOT::EnableImplicitMT();; 1342const unsigned int nSlots = df.GetNSlots();; 1343std::vector<double> sumSqs(nSlots, 0.);; 1344std::vector<unsigned int> ns(nSlots, 0);; 1345 ; 1346df.ForeachSlot([&sumSqs, &ns](unsigned int sl",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:79835,Usability,simpl,simple,79835,"propriate relationships and then instantiate an RDataFrame; 1367with the main tree:; 1368 ; 1369~~~{.cpp}; 1370TTree main([...]);; 1371TTree friend([...]);; 1372main.AddFriend(&friend, ""myFriend"");; 1373 ; 1374RDataFrame df(main);; 1375auto df2 = df.Filter(""myFriend.MyCol == 42"");; 1376~~~; 1377 ; 1378The same applies for TChains. Columns coming from the friend trees can be referred to by their full name, like in the example above,; 1379or the friend tree name can be omitted in case the column name is not ambiguous (e.g. ""MyCol"" could be used instead of; 1380""myFriend.MyCol"" in the example above if there is no column ""MyCol"" in the main tree).; 1381 ; 1382\note A common source of confusion is that trees that are written out from a multi-thread Snapshot() call will have their; 1383 entries (block-wise) shuffled with respect to the original tree. Such trees cannot be used as friends of the original; 1384 one: rows will be mismatched.; 1385 ; 1386Indexed friend trees provide a way to perform simple joins of multiple trees over a common column.; 1387When a certain entry in the main tree (or chain) is loaded, the friend trees (or chains) will then load an entry where the; 1388""index"" columns have a value identical to the one in the main one. For example, in Python:; 1389 ; 1390~~~{.py}; 1391main_tree = ...; 1392aux_tree = ...; 1393 ; 1394# If a friend tree has an index on `commonColumn`, when the main tree loads; 1395# a given row, it also loads the row of the friend tree that has the same; 1396# value of `commonColumn`; 1397aux_tree.BuildIndex(""commonColumn""); 1398 ; 1399mainTree.AddFriend(aux_tree); 1400 ; 1401df = ROOT.RDataFrame(mainTree); 1402~~~; 1403 ; 1404RDataFrame supports indexed friend TTrees from ROOT v6.24 in single-thread mode and from v6.28/02 in multi-thread mode.; 1405 ; 1406\anchor other-file-formats; 1407### Reading data formats other than ROOT trees; 1408RDataFrame can be interfaced with RDataSources. The ROOT::RDF::RDataSource interface defines an AP",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:85768,Usability,simpl,simple,85768,"6 ; 1487More information (e.g. start and end of each multi-thread task) is printed using `ELogLevel.kDebug` and even more; 1488(e.g. a full dump of the generated code that RDataFrame just-in-time-compiles) using `ELogLevel.kDebug+10`.; 1489 ; 1490\anchor rdf-from-spec; 1491### Creating an RDataFrame from a dataset specification file; 1492 ; 1493RDataFrame can be created using a dataset specification JSON file: ; 1494 ; 1495~~~{.python}; 1496import ROOT; 1497 ; 1498df = ROOT.RDF.Experimental.FromSpec(""spec.json""); 1499~~~; 1500 ; 1501The input dataset specification JSON file needs to be provided by the user and it describes all necessary samples and; 1502their associated metadata information. The main required key is the ""samples"" (at least one sample is needed) and the; 1503required sub-keys for each sample are ""trees"" and ""files"". Additionally, one can specify a metadata dictionary for each; 1504sample in the ""metadata"" key.; 1505 ; 1506A simple example for the formatting of the specification in the JSON file is the following:; 1507 ; 1508~~~{.cpp}; 1509{; 1510 ""samples"": {; 1511 ""sampleA"": {; 1512 ""trees"": [""tree1"", ""tree2""],; 1513 ""files"": [""file1.root"", ""file2.root""],; 1514 ""metadata"": {; 1515 ""lumi"": 10000.0, ; 1516 ""xsec"": 1.0,; 1517 ""sample_category"" = ""data""; 1518 }; 1519 },; 1520 ""sampleB"": {; 1521 ""trees"": [""tree3"", ""tree4""],; 1522 ""files"": [""file3.root"", ""file4.root""],; 1523 ""metadata"": {; 1524 ""lumi"": 0.5, ; 1525 ""xsec"": 1.5,; 1526 ""sample_category"" = ""MC_background""; 1527 }; 1528 }; 1529 }; 1530}; 1531~~~; 1532 ; 1533The metadata information from the specification file can be then accessed using the DefinePerSample function.; 1534For example, to access luminosity information (stored as a double):; 1535 ; 1536~~~{.python}; 1537df.DefinePerSample(""lumi"", 'rdfsampleinfo_.GetD(""lumi"")'); 1538~~~; 1539 ; 1540or sample_category information (stored as a string):; 1541 ; 1542~~~{.python}; 1543df.DefinePerSample(""sample_category"", 'rdfsampleinfo_.GetS(""sample_ca",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:87232,Usability,progress bar,progress bar,87232,"ec"": 1.5,; 1526 ""sample_category"" = ""MC_background""; 1527 }; 1528 }; 1529 }; 1530}; 1531~~~; 1532 ; 1533The metadata information from the specification file can be then accessed using the DefinePerSample function.; 1534For example, to access luminosity information (stored as a double):; 1535 ; 1536~~~{.python}; 1537df.DefinePerSample(""lumi"", 'rdfsampleinfo_.GetD(""lumi"")'); 1538~~~; 1539 ; 1540or sample_category information (stored as a string):; 1541 ; 1542~~~{.python}; 1543df.DefinePerSample(""sample_category"", 'rdfsampleinfo_.GetS(""sample_category"")'); 1544~~~; 1545 ; 1546or directly the filename:; 1547 ; 1548~~~{.python}; 1549df.DefinePerSample(""name"", ""rdfsampleinfo_.GetSampleName()""); 1550~~~; 1551 ; 1552An example implementation of the ""FromSpec"" method is available in tutorial: df106_HiggstoFourLeptons.py, which also; 1553provides a corresponding exemplary JSON file for the dataset specification.; 1554 ; 1555\anchor progressbar; 1556### Adding a progress bar ; 1557 ; 1558A progress bar showing the processed event statistics can be added to any RDataFrame program.; 1559The event statistics include elapsed time, currently processed file, currently processed events, the rate of event processing ; 1560and an estimated remaining time (per file being processed). It is recorded and printed in the terminal every m events and every ; 1561n seconds (by default m = 1000 and n = 1). The ProgressBar can be also added when the multithread (MT) mode is enabled. ; 1562 ; 1563ProgressBar is added after creating the dataframe object (df):; 1564~~~{.cpp}; 1565ROOT::RDataFrame df(""tree"", ""file.root"");; 1566ROOT::RDF::Experimental::AddProgressBar(df);; 1567~~~; 1568 ; 1569Alternatively, RDataFrame can be cast to an RNode first, giving the user more flexibility ; 1570For example, it can be called at any computational node, such as Filter or Define, not only the head node,; 1571with no change to the ProgressBar function itself (please see the [Efficient analysis in Python](#python) ",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:87260,Usability,progress bar,progress bar,87260,"ec"": 1.5,; 1526 ""sample_category"" = ""MC_background""; 1527 }; 1528 }; 1529 }; 1530}; 1531~~~; 1532 ; 1533The metadata information from the specification file can be then accessed using the DefinePerSample function.; 1534For example, to access luminosity information (stored as a double):; 1535 ; 1536~~~{.python}; 1537df.DefinePerSample(""lumi"", 'rdfsampleinfo_.GetD(""lumi"")'); 1538~~~; 1539 ; 1540or sample_category information (stored as a string):; 1541 ; 1542~~~{.python}; 1543df.DefinePerSample(""sample_category"", 'rdfsampleinfo_.GetS(""sample_category"")'); 1544~~~; 1545 ; 1546or directly the filename:; 1547 ; 1548~~~{.python}; 1549df.DefinePerSample(""name"", ""rdfsampleinfo_.GetSampleName()""); 1550~~~; 1551 ; 1552An example implementation of the ""FromSpec"" method is available in tutorial: df106_HiggstoFourLeptons.py, which also; 1553provides a corresponding exemplary JSON file for the dataset specification.; 1554 ; 1555\anchor progressbar; 1556### Adding a progress bar ; 1557 ; 1558A progress bar showing the processed event statistics can be added to any RDataFrame program.; 1559The event statistics include elapsed time, currently processed file, currently processed events, the rate of event processing ; 1560and an estimated remaining time (per file being processed). It is recorded and printed in the terminal every m events and every ; 1561n seconds (by default m = 1000 and n = 1). The ProgressBar can be also added when the multithread (MT) mode is enabled. ; 1562 ; 1563ProgressBar is added after creating the dataframe object (df):; 1564~~~{.cpp}; 1565ROOT::RDataFrame df(""tree"", ""file.root"");; 1566ROOT::RDF::Experimental::AddProgressBar(df);; 1567~~~; 1568 ; 1569Alternatively, RDataFrame can be cast to an RNode first, giving the user more flexibility ; 1570For example, it can be called at any computational node, such as Filter or Define, not only the head node,; 1571with no change to the ProgressBar function itself (please see the [Efficient analysis in Python](#python) ",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:88520,Usability,progress bar,progress bars,88520,"maining time (per file being processed). It is recorded and printed in the terminal every m events and every ; 1561n seconds (by default m = 1000 and n = 1). The ProgressBar can be also added when the multithread (MT) mode is enabled. ; 1562 ; 1563ProgressBar is added after creating the dataframe object (df):; 1564~~~{.cpp}; 1565ROOT::RDataFrame df(""tree"", ""file.root"");; 1566ROOT::RDF::Experimental::AddProgressBar(df);; 1567~~~; 1568 ; 1569Alternatively, RDataFrame can be cast to an RNode first, giving the user more flexibility ; 1570For example, it can be called at any computational node, such as Filter or Define, not only the head node,; 1571with no change to the ProgressBar function itself (please see the [Efficient analysis in Python](#python) ; 1572section for appropriate usage in Python): ; 1573~~~{.cpp}; 1574ROOT::RDataFrame df(""tree"", ""file.root"");; 1575auto df_1 = ROOT::RDF::RNode(df.Filter(""x>1""));; 1576ROOT::RDF::Experimental::AddProgressBar(df_1);; 1577~~~; 1578Examples of implemented progress bars can be seen by running [Higgs to Four Lepton tutorial](https://root.cern/doc/master/df106__HiggsToFourLeptons_8py_source.html) and [Dimuon tutorial](https://root.cern/doc/master/df102__NanoAODDimuonAnalysis_8C.html). ; 1579 ; 1580\anchor missing-values; 1581### Working with missing values in the dataset; 1582 ; 1583In certain situations a dataset might be missing one or more values at one or; 1584more of its entries. For example:; 1585 ; 1586- If the dataset is composed of multiple files and one or more files is; 1587 missing one or more columns required by the analysis.; 1588- When joining different datasets horizontally according to some index value; 1589 (e.g. the event number), if the index does not find a match in one or more; 1590 other datasets for a certain entry.; 1591 ; 1592For example, suppose that column ""y"" does not have a value for entry 42:; 1593 ; 1594\code{.unparsed}; 1595+-------+---+---+; 1596| Entry | x | y |; 1597+-------+---+---+; 1598| 4",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:91151,Usability,clear,clearly,91151,"they will either keep or discard an entire entry; 1614based on whether a condition returns true or false. Specifically:; 1615 ; 1616- FilterAvailable: the condition is whether the value of the column is present.; 1617 If so, the entry is kept. Otherwise if the value is missing the entry is; 1618 discarded.; 1619- FilterMissing: the condition is whether the value of the column is missing. If; 1620 so, the entry is kept. Otherwise if the value is present the entry is; 1621 discarded.; 1622 ; 1623\code{.py}; 1624df = ROOT.RDataFrame(dataset); 1625 ; 1626# Anytime an entry from ""col"" is missing, the entire entry will be filtered out; 1627df_available = df.FilterAvailable(""col""); 1628df_available = df_available.Define(""twice"", ""col * 2""); 1629 ; 1630# Conversely, if we want to select the entries for which the column has missing; 1631# values, we do the following; 1632df_missingcol = df.FilterMissing(""col""); 1633# Following operations in the same branch of the computation graph clearly; 1634# cannot access that same column, since there would be no value to read; 1635df_missingcol = df_missingcol.Define(""observable"", ""othercolumn * 2""); 1636\endcode; 1637 ; 1638\code{.cpp}; 1639ROOT::RDataFrame df{dataset};; 1640 ; 1641// Anytime an entry from ""col"" is missing, the entire entry will be filtered out; 1642auto df_available = df.FilterAvailable(""col"");; 1643auto df_twicecol = df_available.Define(""twice"", ""col * 2"");; 1644 ; 1645// Conversely, if we want to select the entries for which the column has missing; 1646// values, we do the following; 1647auto df_missingcol = df.FilterMissing(""col"");; 1648// Following operations in the same branch of the computation graph clearly; 1649// cannot access that same column, since there would be no value to read; 1650auto df_observable = df_missingcol.Define(""observable"", ""othercolumn * 2"");; 1651\endcode; 1652 ; 1653#### DefaultValueFor; 1654 ; 1655DefaultValueFor creates a node of the computation graph which just forwards the; 1656values ",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8cxx_source.html:91847,Usability,clear,clearly,91847,"le = df_available.Define(""twice"", ""col * 2""); 1629 ; 1630# Conversely, if we want to select the entries for which the column has missing; 1631# values, we do the following; 1632df_missingcol = df.FilterMissing(""col""); 1633# Following operations in the same branch of the computation graph clearly; 1634# cannot access that same column, since there would be no value to read; 1635df_missingcol = df_missingcol.Define(""observable"", ""othercolumn * 2""); 1636\endcode; 1637 ; 1638\code{.cpp}; 1639ROOT::RDataFrame df{dataset};; 1640 ; 1641// Anytime an entry from ""col"" is missing, the entire entry will be filtered out; 1642auto df_available = df.FilterAvailable(""col"");; 1643auto df_twicecol = df_available.Define(""twice"", ""col * 2"");; 1644 ; 1645// Conversely, if we want to select the entries for which the column has missing; 1646// values, we do the following; 1647auto df_missingcol = df.FilterMissing(""col"");; 1648// Following operations in the same branch of the computation graph clearly; 1649// cannot access that same column, since there would be no value to read; 1650auto df_observable = df_missingcol.Define(""observable"", ""othercolumn * 2"");; 1651\endcode; 1652 ; 1653#### DefaultValueFor; 1654 ; 1655DefaultValueFor creates a node of the computation graph which just forwards the; 1656values of the columns necessary for other downstream nodes, when they are; 1657available. In case a value of the input column passed to this function is not; 1658available, the node will provide the default value passed to this function call; 1659instead. Example:; 1660 ; 1661\code{.py}; 1662df = ROOT.RDataFrame(dataset); 1663# Anytime an entry from ""col"" is missing, the value will be the default one; 1664default_value = ... # Some sensible default value here; 1665df = df.DefaultValueFor(""col"", default_value) ; 1666df = df.Define(""twice"", ""col * 2""); 1667\endcode; 1668 ; 1669\code{.cpp}; 1670ROOT::RDataFrame df{dataset};; 1671// Anytime an entry from ""col"" is missing, the value will be the defaul",MatchSource.WIKI,doc/master/RDataFrame_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8cxx_source.html
https://root.cern/doc/master/RDataFrame_8hxx.html:480,Integrability,depend,dependency,480,". ROOT: tree/dataframe/inc/ROOT/RDataFrame.hxx File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. Classes |; Namespaces |; Functions ; RDataFrame.hxx File Reference. #include ""TROOT.h""; #include ""ROOT/RDF/RDatasetSpec.hxx""; #include ""ROOT/RDF/RInterface.hxx""; #include ""ROOT/RDF/Utils.hxx""; #include <string_view>; #include ""RtypesCore.h""; #include <initializer_list>; #include <memory>; #include <string>; #include <vector>. Include dependency graph for RDataFrame.hxx:. This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead. This graph shows which files directly or indirectly include this file:. This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead. Classes; class ROOT::RDataFrame; ROOT's RDataFrame offers a modern, high-level interface for analysis of data stored in TTree , CSV and other data formats, in C++ or Python. More...; . Namespaces; namespace ROOT; tbb::task_arena is an alias of tbb::interface7::task_arena, which doesn't allow to forward declare tbb::task_arena without forward declaring tbb::interface7 ; ; namespace ROOT::RDF; ; namespace ROOT::RDF::Experimental; . Functions; ROOT::RDataFrameROOT::RDF::Experimental::FromSpec (const std::string &jsonFile); Factory method to create an RDataFrame from a JSON specification file. ; . treedataframeincROOTRDataFrame.hxx. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:26 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/RDataFrame_8hxx.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8hxx.html
https://root.cern/doc/master/RDataFrame_8hxx.html:841,Integrability,interface,interface,841,". ROOT: tree/dataframe/inc/ROOT/RDataFrame.hxx File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. Classes |; Namespaces |; Functions ; RDataFrame.hxx File Reference. #include ""TROOT.h""; #include ""ROOT/RDF/RDatasetSpec.hxx""; #include ""ROOT/RDF/RInterface.hxx""; #include ""ROOT/RDF/Utils.hxx""; #include <string_view>; #include ""RtypesCore.h""; #include <initializer_list>; #include <memory>; #include <string>; #include <vector>. Include dependency graph for RDataFrame.hxx:. This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead. This graph shows which files directly or indirectly include this file:. This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead. Classes; class ROOT::RDataFrame; ROOT's RDataFrame offers a modern, high-level interface for analysis of data stored in TTree , CSV and other data formats, in C++ or Python. More...; . Namespaces; namespace ROOT; tbb::task_arena is an alias of tbb::interface7::task_arena, which doesn't allow to forward declare tbb::task_arena without forward declaring tbb::interface7 ; ; namespace ROOT::RDF; ; namespace ROOT::RDF::Experimental; . Functions; ROOT::RDataFrameROOT::RDF::Experimental::FromSpec (const std::string &jsonFile); Factory method to create an RDataFrame from a JSON specification file. ; . treedataframeincROOTRDataFrame.hxx. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:26 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/RDataFrame_8hxx.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8hxx.html
https://root.cern/doc/master/RDataFrame_8hxx_source.html:750,Integrability,interface,interface,750,". ROOT: tree/dataframe/inc/ROOT/RDataFrame.hxx Source File. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. RDataFrame.hxx. Go to the documentation of this file. 1// Author: Enrico Guiraud, Danilo Piparo CERN 12/2016; 2 ; 3/*************************************************************************; 4 * Copyright (C) 1995-2018, Rene Brun and Fons Rademakers. *; 5 * All rights reserved. *; 6 * *; 7 * For the licensing terms see $ROOTSYS/LICENSE. *; 8 * For the list of contributors see $ROOTSYS/README/CREDITS. *; 9 *************************************************************************/; 10 ; 11/**; 12 \defgroup dataframe Dataframe; 13ROOT's RDataFrame allows to analyse data stored in TTrees with a high level interface.; 14*/; 15 ; 16#ifndef ROOT_RDATAFRAME; 17#define ROOT_RDATAFRAME; 18 ; 19#include ""TROOT.h"" // To allow ROOT::EnableImplicitMT without including ROOT.h; 20#include ""ROOT/RDF/RDatasetSpec.hxx""; 21#include ""ROOT/RDF/RInterface.hxx""; 22#include ""ROOT/RDF/Utils.hxx""; 23#include <string_view>; 24#include ""RtypesCore.h""; 25 ; 26#include <initializer_list>; 27#include <memory>; 28#include <string>; 29#include <vector>; 30 ; 31class TDirectory;; 32class TTree;; 33 ; 34namespace ROOT {; 35namespace RDF {; 36class RDataSource;; 37}; 38 ; 39namespace RDFDetail = ROOT::Detail::RDF;; 40 ; 41class RDataFrame : public ROOT::RDF::RInterface<RDFDetail::RLoopManager> {; 42public:; 43 using ColumnNames_t = ROOT::RDF::ColumnNames_t;; 44 RDataFrame(std::string_view treeName, std::string_view filenameglob, const ColumnNames_t &defaultColumns = {});; 45 RDataFrame(std::string_view treename, const std::vector<std::string> &filenames,; 46 const ColumnNames_t &defaultColumns = {});; 47 RDataFrame(std::string_view treename, std::initializer_list<std::string> filenames,; 48 const ColumnNames_t &defaultColumns = {}):; 49 RDataFrame(treename, std::vector<std::string>(filenames), defaultColumns) {}; 50 RDataFrame(std::string_view treeName, ::TDirector",MatchSource.WIKI,doc/master/RDataFrame_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8hxx_source.html
https://root.cern/doc/master/RDataFrame_8hxx_source.html:3548,Integrability,interface,interface,3548,"~RDataFrame();; 63};; 64 ; 65namespace RDF {; 66namespace Experimental {; 67 ; 68////////////////////////////////////////////////////////////////////////////////////////////////; 69/// \brief Factory method to create an RDataFrame from a JSON specification file.; 70/// \param[in] jsonFile Path of the JSON file, which should follow the format described in; 71/// https://github.com/root-project/root/issues/11624; 72ROOT::RDataFrame FromSpec(const std::string &jsonFile);; 73 ; 74} // namespace Experimental; 75} // namespace RDF; 76 ; 77} // ns ROOT; 78 ; 79/// Print a RDataFrame at the prompt; 80namespace cling {; 81std::string printValue(ROOT::RDataFrame *tdf);; 82} // ns cling; 83 ; 84#endif // ROOT_RDATAFRAME; RDatasetSpec.hxx; RInterface.hxx; RtypesCore.h; ULong64_tunsigned long long ULong64_tDefinition RtypesCore.h:70; TROOT.h; Utils.hxx; ROOT::RDF::Experimental::RDatasetSpecThe dataset specification for RDataFrame.Definition RDatasetSpec.hxx:47; ROOT::RDF::RInterfaceThe public interface to the RDataFrame federation of classes.Definition RInterface.hxx:113; ROOT::RDataFrameROOT's RDataFrame offers a modern, high-level interface for analysis of data stored in TTree ,...Definition RDataFrame.hxx:41; ROOT::RDataFrame::RDataFrameRDataFrame(std::string_view treename, std::initializer_list< std::string > filenames, const ColumnNames_t &defaultColumns={})Definition RDataFrame.hxx:47; ROOT::RDataFrame::RDataFrameRDataFrame(std::string_view treeName, ::TDirectory *dirPtr, const ColumnNames_t &defaultColumns={}); ROOT::RDataFrame::RDataFrameRDataFrame(std::string_view treeName, std::string_view filenameglob, const ColumnNames_t &defaultColumns={})Build the dataframe.Definition RDataFrame.cxx:1768; ROOT::RDataFrame::ColumnNames_tROOT::RDF::ColumnNames_t ColumnNames_tDefinition RDataFrame.hxx:43; ROOT::RDataFrame::~RDataFrame~RDataFrame()Definition RDataFrame.cxx:1862; ROOT::RDataFrame::RDataFrameRDataFrame(RDataFrame &&)=default; ROOT::RDataFrame::RDataFrameRDataFrame(const ",MatchSource.WIKI,doc/master/RDataFrame_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8hxx_source.html
https://root.cern/doc/master/RDataFrame_8hxx_source.html:3691,Integrability,interface,interface,3691,"//////////////////////////////////////////////////; 69/// \brief Factory method to create an RDataFrame from a JSON specification file.; 70/// \param[in] jsonFile Path of the JSON file, which should follow the format described in; 71/// https://github.com/root-project/root/issues/11624; 72ROOT::RDataFrame FromSpec(const std::string &jsonFile);; 73 ; 74} // namespace Experimental; 75} // namespace RDF; 76 ; 77} // ns ROOT; 78 ; 79/// Print a RDataFrame at the prompt; 80namespace cling {; 81std::string printValue(ROOT::RDataFrame *tdf);; 82} // ns cling; 83 ; 84#endif // ROOT_RDATAFRAME; RDatasetSpec.hxx; RInterface.hxx; RtypesCore.h; ULong64_tunsigned long long ULong64_tDefinition RtypesCore.h:70; TROOT.h; Utils.hxx; ROOT::RDF::Experimental::RDatasetSpecThe dataset specification for RDataFrame.Definition RDatasetSpec.hxx:47; ROOT::RDF::RInterfaceThe public interface to the RDataFrame federation of classes.Definition RInterface.hxx:113; ROOT::RDataFrameROOT's RDataFrame offers a modern, high-level interface for analysis of data stored in TTree ,...Definition RDataFrame.hxx:41; ROOT::RDataFrame::RDataFrameRDataFrame(std::string_view treename, std::initializer_list< std::string > filenames, const ColumnNames_t &defaultColumns={})Definition RDataFrame.hxx:47; ROOT::RDataFrame::RDataFrameRDataFrame(std::string_view treeName, ::TDirectory *dirPtr, const ColumnNames_t &defaultColumns={}); ROOT::RDataFrame::RDataFrameRDataFrame(std::string_view treeName, std::string_view filenameglob, const ColumnNames_t &defaultColumns={})Build the dataframe.Definition RDataFrame.cxx:1768; ROOT::RDataFrame::ColumnNames_tROOT::RDF::ColumnNames_t ColumnNames_tDefinition RDataFrame.hxx:43; ROOT::RDataFrame::~RDataFrame~RDataFrame()Definition RDataFrame.cxx:1862; ROOT::RDataFrame::RDataFrameRDataFrame(RDataFrame &&)=default; ROOT::RDataFrame::RDataFrameRDataFrame(const RDataFrame &)=default; ROOT::RDataFrame::operator=RDataFrame & operator=(const RDataFrame &)=default; ROOT::RDataFrame::operato",MatchSource.WIKI,doc/master/RDataFrame_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDataFrame_8hxx_source.html
https://root.cern/doc/master/RDatasetSpec_8hxx_source.html:1620,Availability,avail,available,1620,"9 *************************************************************************/; 10 ; 11#ifndef ROOT_RDF_RDATASETSPEC; 12#define ROOT_RDF_RDATASETSPEC; 13 ; 14#include <limits>; 15#include <string>; 16#include <utility> // std::pair; 17#include <vector>; 18 ; 19#include <ROOT/RDF/RSample.hxx>; 20#include <ROOT/RFriendInfo.hxx>; 21#include <RtypesCore.h> // Long64_t; 22 ; 23namespace ROOT {; 24namespace Detail {; 25namespace RDF {; 26class RLoopManager;; 27}; 28} // namespace Detail; 29namespace RDF {; 30namespace Experimental {; 31 ; 32// clang-format off; 33/**; 34\class ROOT::RDF::Experimental::RDatasetSpec; 35\ingroup dataframe; 36\brief The dataset specification for RDataFrame.; 37 ; 38This class allows users to create the dataset specification for RDataFrame ; 39to which they add samples (using the RSample class object) with tree names and file names, ; 40and, optionally, the metadata information (using the RMetaData class objects). ; 41Adding global friend trees and/or setting the range of events to be processed; 42are also available.; 43 ; 44Note, there exists yet another method to build RDataFrame from the dataset information using the JSON file format: \ref FromSpec(const std::string &jsonFile) ""FromSpec()"". ; 45*/; 46 ; 47class RDatasetSpec {; 48 // clang-format on ; 49 friend class ::ROOT::Detail::RDF::RLoopManager; // for MoveOutSamples; 50 ; 51public:; 52 struct REntryRange {; 53 Long64_t fBegin{0};; 54 Long64_t fEnd{std::numeric_limits<Long64_t>::max()};; 55 REntryRange();; 56 REntryRange(Long64_t endEntry);; 57 REntryRange(Long64_t startEntry, Long64_t endEntry);; 58 };; 59 ; 60private:; 61 std::vector<RSample> fSamples; ///< List of samples; 62 ROOT::TreeUtils::RFriendInfo fFriendInfo; ///< List of friends; 63 REntryRange fEntryRange; ///< Start (inclusive) and end (exclusive) entry for the dataset processing; 64 ; 65 std::vector<RSample> MoveOutSamples();; 66 ; 67public:; 68 RDatasetSpec() = default;; 69 ; 70 const std::vector<std::string> GetSampleName",MatchSource.WIKI,doc/master/RDatasetSpec_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDatasetSpec_8hxx_source.html
https://root.cern/doc/master/RDFHelpers_8cxx_source.html:22092,Availability,robust,robust,22092,"ROOT::TThreadExecutorThis class provides a simple interface to execute the same task multiple times in parallel threads,...Definition TThreadExecutor.hxx:41; ROOT::TThreadExecutor::Foreachvoid Foreach(F func, unsigned nTimes, unsigned nChunks=0)Execute a function without arguments several times in parallel, dividing the execution in nChunks.Definition TThreadExecutor.hxx:146; TStopwatchStopwatch class.Definition TStopwatch.h:28; TStopwatch::RealTimeDouble_t RealTime()Stop the stopwatch (if it is running) and return the realtime (in seconds) passed between the start a...Definition TStopwatch.cxx:110; TStopwatch::Startvoid Start(Bool_t reset=kTRUE)Start the stopwatch.Definition TStopwatch.cxx:58; TStopwatch::CpuTimeDouble_t CpuTime()Stop the stopwatch (if it is running) and return the cputime (in seconds) passed between the start an...Definition TStopwatch.cxx:125; TStopwatch::Stopvoid Stop()Stop the stopwatch.Definition TStopwatch.cxx:77; TTreeReaderA simple, robust and fast interface to read values from ROOT columnar datasets such as TTree,...Definition TTreeReader.h:46; double; int; ROOT::Detail::RDF::RDFLogChannelROOT::Experimental::RLogChannel & RDFLogChannel()Definition RDFUtils.cxx:37; ROOT::Experimental::Internal::GetChannelOrManagerRLogChannel & GetChannelOrManager()Definition RLogger.hxx:302; ROOT::Experimental::ELogLevel::kDebug@ kDebugDebug information; only useful for developers; can have added verbosity up to 255-kDebug.; ROOT::Experimental::ELogLevel::kError@ kErrorAn error.; ROOT::RDF::Experimental::VariationsForRResultMap< T > VariationsFor(RResultPtr< T > resPtr)Produce all required systematic variations for the given result.Definition RDFHelpers.hxx:219; ROOT::RDF::Experimental::AddProgressBarvoid AddProgressBar(ROOT::RDF::RNode df)Add ProgressBar to a ROOT::RDF::RNode.Definition RDFHelpers.cxx:373; ROOT::RDF::RunGraphsunsigned int RunGraphs(std::vector< RResultHandle > handles)Trigger the event loop of multiple RDataFrames concurrently.Definition RD",MatchSource.WIKI,doc/master/RDFHelpers_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8cxx_source.html
https://root.cern/doc/master/RDFHelpers_8cxx_source.html:22625,Availability,error,error,22625,"pwatch (if it is running) and return the realtime (in seconds) passed between the start a...Definition TStopwatch.cxx:110; TStopwatch::Startvoid Start(Bool_t reset=kTRUE)Start the stopwatch.Definition TStopwatch.cxx:58; TStopwatch::CpuTimeDouble_t CpuTime()Stop the stopwatch (if it is running) and return the cputime (in seconds) passed between the start an...Definition TStopwatch.cxx:125; TStopwatch::Stopvoid Stop()Stop the stopwatch.Definition TStopwatch.cxx:77; TTreeReaderA simple, robust and fast interface to read values from ROOT columnar datasets such as TTree,...Definition TTreeReader.h:46; double; int; ROOT::Detail::RDF::RDFLogChannelROOT::Experimental::RLogChannel & RDFLogChannel()Definition RDFUtils.cxx:37; ROOT::Experimental::Internal::GetChannelOrManagerRLogChannel & GetChannelOrManager()Definition RLogger.hxx:302; ROOT::Experimental::ELogLevel::kDebug@ kDebugDebug information; only useful for developers; can have added verbosity up to 255-kDebug.; ROOT::Experimental::ELogLevel::kError@ kErrorAn error.; ROOT::RDF::Experimental::VariationsForRResultMap< T > VariationsFor(RResultPtr< T > resPtr)Produce all required systematic variations for the given result.Definition RDFHelpers.hxx:219; ROOT::RDF::Experimental::AddProgressBarvoid AddProgressBar(ROOT::RDF::RNode df)Add ProgressBar to a ROOT::RDF::RNode.Definition RDFHelpers.cxx:373; ROOT::RDF::RunGraphsunsigned int RunGraphs(std::vector< RResultHandle > handles)Trigger the event loop of multiple RDataFrames concurrently.Definition RDFHelpers.cxx:66; ROOT::RDF::SampleCallback_tstd::function< void(unsigned int, const ROOT::RDF::RSampleInfo &)> SampleCallback_tThe type of a data-block callback, registered with an RDataFrame computation graph via e....Definition RSampleInfo.hxx:134; ROOT::RDF::AsRNodeRNode AsRNode(NodeType node)Cast a RDataFrame node to the common type ROOT::RDF::RNode.Definition RDFHelpers.hxx:158; ROOTtbb::task_arena is an alias of tbb::interface7::task_arena, which doesn't allow to forward d",MatchSource.WIKI,doc/master/RDFHelpers_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8cxx_source.html
https://root.cern/doc/master/RDFHelpers_8cxx_source.html:20295,Integrability,interface,interface,20295,"lpers.cxx:145; ROOT::RDF::Experimental::ProgressHelper::fLastPrintTimestd::chrono::time_point< std::chrono::system_clock > fLastPrintTimeDefinition RDFHelpers.hxx:330; ROOT::RDF::Experimental::ProgressHelper::fBeginTimestd::chrono::time_point< std::chrono::system_clock > fBeginTimeDefinition RDFHelpers.hxx:329; ROOT::RDF::Experimental::ProgressHelper::PrintStatsFinalvoid PrintStatsFinal(std::ostream &stream, std::chrono::seconds totalElapsedSeconds) constDefinition RDFHelpers.cxx:273; ROOT::RDF::Experimental::ProgressHelper::fBarWidthunsigned int fBarWidthDefinition RDFHelpers.hxx:343; ROOT::RDF::Experimental::ProgressHelper::fEventsPerSecondStatisticsIndexstd::size_t fEventsPerSecondStatisticsIndexDefinition RDFHelpers.hxx:341; ROOT::RDF::Experimental::ProgressHelper::ComputeNEventsSoFarstd::size_t ComputeNEventsSoFar() constDefinition RDFHelpers.hxx:435; ROOT::RDF::RInterfaceBase::GetNFilesunsigned int GetNFiles()Definition RInterfaceBase.cxx:27; ROOT::RDF::RInterfaceThe public interface to the RDataFrame federation of classes.Definition RInterface.hxx:113; ROOT::RDF::RInterface::BookRResultPtr< typename std::decay_t< Helper >::Result_t > Book(Helper &&helper, const ColumnNames_t &columns={})Book execution of a custom action using a user-defined helper object.Definition RInterface.hxx:2984; ROOT::RDF::RResultHandleA type-erased version of RResultPtr and RResultMap.Definition RResultHandle.hxx:33; ROOT::RDF::RResultPtrSmart pointer for the return type of actions.Definition RResultPtr.hxx:119; ROOT::RDF::RSampleInfoThis type represents a sample identifier, to be used in conjunction with RDataFrame features such as ...Definition RSampleInfo.hxx:35; ROOT::RDataFrameROOT's RDataFrame offers a modern, high-level interface for analysis of data stored in TTree ,...Definition RDataFrame.hxx:41; ROOT::TThreadExecutorThis class provides a simple interface to execute the same task multiple times in parallel threads,...Definition TThreadExecutor.hxx:41; ROOT::TThreadExecutor::",MatchSource.WIKI,doc/master/RDFHelpers_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8cxx_source.html
https://root.cern/doc/master/RDFHelpers_8cxx_source.html:21038,Integrability,interface,interface,21038,"rs.hxx:341; ROOT::RDF::Experimental::ProgressHelper::ComputeNEventsSoFarstd::size_t ComputeNEventsSoFar() constDefinition RDFHelpers.hxx:435; ROOT::RDF::RInterfaceBase::GetNFilesunsigned int GetNFiles()Definition RInterfaceBase.cxx:27; ROOT::RDF::RInterfaceThe public interface to the RDataFrame federation of classes.Definition RInterface.hxx:113; ROOT::RDF::RInterface::BookRResultPtr< typename std::decay_t< Helper >::Result_t > Book(Helper &&helper, const ColumnNames_t &columns={})Book execution of a custom action using a user-defined helper object.Definition RInterface.hxx:2984; ROOT::RDF::RResultHandleA type-erased version of RResultPtr and RResultMap.Definition RResultHandle.hxx:33; ROOT::RDF::RResultPtrSmart pointer for the return type of actions.Definition RResultPtr.hxx:119; ROOT::RDF::RSampleInfoThis type represents a sample identifier, to be used in conjunction with RDataFrame features such as ...Definition RSampleInfo.hxx:35; ROOT::RDataFrameROOT's RDataFrame offers a modern, high-level interface for analysis of data stored in TTree ,...Definition RDataFrame.hxx:41; ROOT::TThreadExecutorThis class provides a simple interface to execute the same task multiple times in parallel threads,...Definition TThreadExecutor.hxx:41; ROOT::TThreadExecutor::Foreachvoid Foreach(F func, unsigned nTimes, unsigned nChunks=0)Execute a function without arguments several times in parallel, dividing the execution in nChunks.Definition TThreadExecutor.hxx:146; TStopwatchStopwatch class.Definition TStopwatch.h:28; TStopwatch::RealTimeDouble_t RealTime()Stop the stopwatch (if it is running) and return the realtime (in seconds) passed between the start a...Definition TStopwatch.cxx:110; TStopwatch::Startvoid Start(Bool_t reset=kTRUE)Start the stopwatch.Definition TStopwatch.cxx:58; TStopwatch::CpuTimeDouble_t CpuTime()Stop the stopwatch (if it is running) and return the cputime (in seconds) passed between the start an...Definition TStopwatch.cxx:125; TStopwatch::Stopvoid Stop()Stop t",MatchSource.WIKI,doc/master/RDFHelpers_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8cxx_source.html
https://root.cern/doc/master/RDFHelpers_8cxx_source.html:21169,Integrability,interface,interface,21169,"RDF::RInterfaceBase::GetNFilesunsigned int GetNFiles()Definition RInterfaceBase.cxx:27; ROOT::RDF::RInterfaceThe public interface to the RDataFrame federation of classes.Definition RInterface.hxx:113; ROOT::RDF::RInterface::BookRResultPtr< typename std::decay_t< Helper >::Result_t > Book(Helper &&helper, const ColumnNames_t &columns={})Book execution of a custom action using a user-defined helper object.Definition RInterface.hxx:2984; ROOT::RDF::RResultHandleA type-erased version of RResultPtr and RResultMap.Definition RResultHandle.hxx:33; ROOT::RDF::RResultPtrSmart pointer for the return type of actions.Definition RResultPtr.hxx:119; ROOT::RDF::RSampleInfoThis type represents a sample identifier, to be used in conjunction with RDataFrame features such as ...Definition RSampleInfo.hxx:35; ROOT::RDataFrameROOT's RDataFrame offers a modern, high-level interface for analysis of data stored in TTree ,...Definition RDataFrame.hxx:41; ROOT::TThreadExecutorThis class provides a simple interface to execute the same task multiple times in parallel threads,...Definition TThreadExecutor.hxx:41; ROOT::TThreadExecutor::Foreachvoid Foreach(F func, unsigned nTimes, unsigned nChunks=0)Execute a function without arguments several times in parallel, dividing the execution in nChunks.Definition TThreadExecutor.hxx:146; TStopwatchStopwatch class.Definition TStopwatch.h:28; TStopwatch::RealTimeDouble_t RealTime()Stop the stopwatch (if it is running) and return the realtime (in seconds) passed between the start a...Definition TStopwatch.cxx:110; TStopwatch::Startvoid Start(Bool_t reset=kTRUE)Start the stopwatch.Definition TStopwatch.cxx:58; TStopwatch::CpuTimeDouble_t CpuTime()Stop the stopwatch (if it is running) and return the cputime (in seconds) passed between the start an...Definition TStopwatch.cxx:125; TStopwatch::Stopvoid Stop()Stop the stopwatch.Definition TStopwatch.cxx:77; TTreeReaderA simple, robust and fast interface to read values from ROOT columnar datasets such as TTree,.",MatchSource.WIKI,doc/master/RDFHelpers_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8cxx_source.html
https://root.cern/doc/master/RDFHelpers_8cxx_source.html:22108,Integrability,interface,interface,22108,"ROOT::TThreadExecutorThis class provides a simple interface to execute the same task multiple times in parallel threads,...Definition TThreadExecutor.hxx:41; ROOT::TThreadExecutor::Foreachvoid Foreach(F func, unsigned nTimes, unsigned nChunks=0)Execute a function without arguments several times in parallel, dividing the execution in nChunks.Definition TThreadExecutor.hxx:146; TStopwatchStopwatch class.Definition TStopwatch.h:28; TStopwatch::RealTimeDouble_t RealTime()Stop the stopwatch (if it is running) and return the realtime (in seconds) passed between the start a...Definition TStopwatch.cxx:110; TStopwatch::Startvoid Start(Bool_t reset=kTRUE)Start the stopwatch.Definition TStopwatch.cxx:58; TStopwatch::CpuTimeDouble_t CpuTime()Stop the stopwatch (if it is running) and return the cputime (in seconds) passed between the start an...Definition TStopwatch.cxx:125; TStopwatch::Stopvoid Stop()Stop the stopwatch.Definition TStopwatch.cxx:77; TTreeReaderA simple, robust and fast interface to read values from ROOT columnar datasets such as TTree,...Definition TTreeReader.h:46; double; int; ROOT::Detail::RDF::RDFLogChannelROOT::Experimental::RLogChannel & RDFLogChannel()Definition RDFUtils.cxx:37; ROOT::Experimental::Internal::GetChannelOrManagerRLogChannel & GetChannelOrManager()Definition RLogger.hxx:302; ROOT::Experimental::ELogLevel::kDebug@ kDebugDebug information; only useful for developers; can have added verbosity up to 255-kDebug.; ROOT::Experimental::ELogLevel::kError@ kErrorAn error.; ROOT::RDF::Experimental::VariationsForRResultMap< T > VariationsFor(RResultPtr< T > resPtr)Produce all required systematic variations for the given result.Definition RDFHelpers.hxx:219; ROOT::RDF::Experimental::AddProgressBarvoid AddProgressBar(ROOT::RDF::RNode df)Add ProgressBar to a ROOT::RDF::RNode.Definition RDFHelpers.cxx:373; ROOT::RDF::RunGraphsunsigned int RunGraphs(std::vector< RResultHandle > handles)Trigger the event loop of multiple RDataFrames concurrently.Definition RD",MatchSource.WIKI,doc/master/RDFHelpers_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8cxx_source.html
https://root.cern/doc/master/RDFHelpers_8cxx_source.html:6581,Performance,load,load,6581,"Compute a running mean of events/s.; 162double ProgressHelper::EvtPerSec() const; 163{; 164 if (fEventsPerSecondStatisticsIndex < fEventsPerSecondStatistics.size()); 165 return std::accumulate(fEventsPerSecondStatistics.begin(),; 166 fEventsPerSecondStatistics.begin() + fEventsPerSecondStatisticsIndex, 0.) /; 167 fEventsPerSecondStatisticsIndex;; 168 else; 169 return std::accumulate(fEventsPerSecondStatistics.begin(), fEventsPerSecondStatistics.end(), 0.) /; 170 fEventsPerSecondStatistics.size();; 171}; 172 ; 173/// Record current event counts and time stamp, populate evts/s statistics array.; 174std::pair<std::size_t, std::chrono::seconds> ProgressHelper::RecordEvtCountAndTime(); 175{; 176 using namespace std::chrono;; 177 ; 178 auto currentEventCount = fProcessedEvents.load();; 179 auto eventsPerTimeInterval = currentEventCount - fLastProcessedEvents;; 180 fLastProcessedEvents = currentEventCount;; 181 ; 182 auto oldPrintTime = fLastPrintTime;; 183 auto newPrintTime = system_clock::now();; 184 fLastPrintTime = newPrintTime;; 185 ; 186 duration<double> secondsCurrentInterval = newPrintTime - oldPrintTime;; 187 fEventsPerSecondStatistics[fEventsPerSecondStatisticsIndex++ % fEventsPerSecondStatistics.size()] =; 188 eventsPerTimeInterval / secondsCurrentInterval.count();; 189 ; 190 return {currentEventCount, duration_cast<seconds>(newPrintTime - fBeginTime)};; 191}; 192 ; 193namespace {; 194 ; 195struct RestoreStreamState {; 196 RestoreStreamState(std::ostream &stream) : fStream(stream), fFlags(stream.flags()), fFillChar(stream.fill()) {}; 197 ~RestoreStreamState(); 198 {; 199 fStream.flags(fFlags);; 200 fStream.fill(fFillChar);; 201 }; 202 ; 203 std::ostream &fStream;; 204 std::ios_base::fmtflags fFlags;; 205 std::ostream::char_type fFillChar;; 206};; 207 ; 208/// Format std::chrono::seconds as `1:30m`.; 209std::ostream &operator<<(std::ostream &stream, std::chrono::seconds elapsedSeconds); 210{; 211 RestoreStreamState restore(stream);; 212 auto h = std::chrono::durat",MatchSource.WIKI,doc/master/RDFHelpers_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8cxx_source.html
https://root.cern/doc/master/RDFHelpers_8cxx_source.html:23094,Performance,concurren,concurrently,23094,"efinition TStopwatch.cxx:125; TStopwatch::Stopvoid Stop()Stop the stopwatch.Definition TStopwatch.cxx:77; TTreeReaderA simple, robust and fast interface to read values from ROOT columnar datasets such as TTree,...Definition TTreeReader.h:46; double; int; ROOT::Detail::RDF::RDFLogChannelROOT::Experimental::RLogChannel & RDFLogChannel()Definition RDFUtils.cxx:37; ROOT::Experimental::Internal::GetChannelOrManagerRLogChannel & GetChannelOrManager()Definition RLogger.hxx:302; ROOT::Experimental::ELogLevel::kDebug@ kDebugDebug information; only useful for developers; can have added verbosity up to 255-kDebug.; ROOT::Experimental::ELogLevel::kError@ kErrorAn error.; ROOT::RDF::Experimental::VariationsForRResultMap< T > VariationsFor(RResultPtr< T > resPtr)Produce all required systematic variations for the given result.Definition RDFHelpers.hxx:219; ROOT::RDF::Experimental::AddProgressBarvoid AddProgressBar(ROOT::RDF::RNode df)Add ProgressBar to a ROOT::RDF::RNode.Definition RDFHelpers.cxx:373; ROOT::RDF::RunGraphsunsigned int RunGraphs(std::vector< RResultHandle > handles)Trigger the event loop of multiple RDataFrames concurrently.Definition RDFHelpers.cxx:66; ROOT::RDF::SampleCallback_tstd::function< void(unsigned int, const ROOT::RDF::RSampleInfo &)> SampleCallback_tThe type of a data-block callback, registered with an RDataFrame computation graph via e....Definition RSampleInfo.hxx:134; ROOT::RDF::AsRNodeRNode AsRNode(NodeType node)Cast a RDataFrame node to the common type ROOT::RDF::RNode.Definition RDFHelpers.hxx:158; ROOTtbb::task_arena is an alias of tbb::interface7::task_arena, which doesn't allow to forward declare tb...Definition EExecutionPolicy.hxx:4; ROOT::IsImplicitMTEnabledBool_t IsImplicitMTEnabled()Returns true if the implicit multi-threading in ROOT is enabled.Definition TROOT.cxx:570; mTMarker mDefinition textangle.C:8. treedataframesrcRDFHelpers.cxx. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:02 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/RDFHelpers_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8cxx_source.html
https://root.cern/doc/master/RDFHelpers_8cxx_source.html:23732,Performance,multi-thread,multi-threading,23732,"efinition TStopwatch.cxx:125; TStopwatch::Stopvoid Stop()Stop the stopwatch.Definition TStopwatch.cxx:77; TTreeReaderA simple, robust and fast interface to read values from ROOT columnar datasets such as TTree,...Definition TTreeReader.h:46; double; int; ROOT::Detail::RDF::RDFLogChannelROOT::Experimental::RLogChannel & RDFLogChannel()Definition RDFUtils.cxx:37; ROOT::Experimental::Internal::GetChannelOrManagerRLogChannel & GetChannelOrManager()Definition RLogger.hxx:302; ROOT::Experimental::ELogLevel::kDebug@ kDebugDebug information; only useful for developers; can have added verbosity up to 255-kDebug.; ROOT::Experimental::ELogLevel::kError@ kErrorAn error.; ROOT::RDF::Experimental::VariationsForRResultMap< T > VariationsFor(RResultPtr< T > resPtr)Produce all required systematic variations for the given result.Definition RDFHelpers.hxx:219; ROOT::RDF::Experimental::AddProgressBarvoid AddProgressBar(ROOT::RDF::RNode df)Add ProgressBar to a ROOT::RDF::RNode.Definition RDFHelpers.cxx:373; ROOT::RDF::RunGraphsunsigned int RunGraphs(std::vector< RResultHandle > handles)Trigger the event loop of multiple RDataFrames concurrently.Definition RDFHelpers.cxx:66; ROOT::RDF::SampleCallback_tstd::function< void(unsigned int, const ROOT::RDF::RSampleInfo &)> SampleCallback_tThe type of a data-block callback, registered with an RDataFrame computation graph via e....Definition RSampleInfo.hxx:134; ROOT::RDF::AsRNodeRNode AsRNode(NodeType node)Cast a RDataFrame node to the common type ROOT::RDF::RNode.Definition RDFHelpers.hxx:158; ROOTtbb::task_arena is an alias of tbb::interface7::task_arena, which doesn't allow to forward declare tb...Definition EExecutionPolicy.hxx:4; ROOT::IsImplicitMTEnabledBool_t IsImplicitMTEnabled()Returns true if the implicit multi-threading in ROOT is enabled.Definition TROOT.cxx:570; mTMarker mDefinition textangle.C:8. treedataframesrcRDFHelpers.cxx. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:02 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/RDFHelpers_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8cxx_source.html
https://root.cern/doc/master/RDFHelpers_8cxx_source.html:3595,Testability,log,logs,3595,";; 79 }; 80 if (nToRun == 0u); 81 return 0u;; 82 ; 83 // Find the unique event loops; 84 auto sameGraph = [](const RResultHandle &a, const RResultHandle &b) { return a.fLoopManager < b.fLoopManager; };; 85 std::set<RResultHandle, decltype(sameGraph)> s(handles.begin(), handles.end(), sameGraph);; 86 std::vector<RResultHandle> uniqueLoops(s.begin(), s.end());; 87 ; 88 // Trigger jitting. One call is enough to jit the code required by all computation graphs.; 89 TStopwatch sw;; 90 sw.Start();; 91 {; 92 const auto effectiveVerbosity =; 93 ROOT::Experimental::Internal::GetChannelOrManager(ROOT::Detail::RDF::RDFLogChannel()); 94 .GetEffectiveVerbosity(ROOT::Experimental::RLogManager::Get());; 95 if (effectiveVerbosity >= ROOT::Experimental::ELogLevel::kDebug + 10) {; 96 // a very high verbosity was requested, let's not silence anything; 97 uniqueLoops[0].fLoopManager->Jit();; 98 } else {; 99 // silence logs from RLoopManager::Jit: RunGraphs does its own logging; 100 auto silenceRDFLogs = ROOT::Experimental::RLogScopedVerbosity(ROOT::Detail::RDF::RDFLogChannel(),; 101 ROOT::Experimental::ELogLevel::kError);; 102 uniqueLoops[0].fLoopManager->Jit();; 103 }; 104 }; 105 sw.Stop();; 106 R__LOG_INFO(ROOT::Detail::RDF::RDFLogChannel()); 107 << ""Just-in-time compilation phase for RunGraphs ("" << uniqueLoops.size(); 108 << "" unique computation graphs) completed""; 109 << (sw.RealTime() > 1e-3 ? "" in "" + std::to_string(sw.RealTime()) + "" seconds."" : "" in less than 1ms."");; 110 ; 111 // Trigger the unique event loops; 112 auto run = [](RResultHandle &h) {; 113 if (h.fLoopManager); 114 h.fLoopManager->Run(/*jit=*/false);; 115 };; 116 ; 117 sw.Start();; 118#ifdef R__USE_IMT; 119 if (ROOT::IsImplicitMTEnabled()) {; 120 ROOT::TThreadExecutor{}.Foreach(run, uniqueLoops);; 121 } else {; 122#endif; 123 std::for_each(uniqueLoops.begin(), uniqueLoops.end(), run);; 124#ifdef R__USE_IMT; 125 }; 126#endif; 127 sw.Stop();; 128 R__LOG_INFO(ROOT::Detail::RDF::RDFLogChannel()); 129 << ""Finished RunGr",MatchSource.WIKI,doc/master/RDFHelpers_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8cxx_source.html
https://root.cern/doc/master/RDFHelpers_8cxx_source.html:3647,Testability,log,logging,3647,";; 79 }; 80 if (nToRun == 0u); 81 return 0u;; 82 ; 83 // Find the unique event loops; 84 auto sameGraph = [](const RResultHandle &a, const RResultHandle &b) { return a.fLoopManager < b.fLoopManager; };; 85 std::set<RResultHandle, decltype(sameGraph)> s(handles.begin(), handles.end(), sameGraph);; 86 std::vector<RResultHandle> uniqueLoops(s.begin(), s.end());; 87 ; 88 // Trigger jitting. One call is enough to jit the code required by all computation graphs.; 89 TStopwatch sw;; 90 sw.Start();; 91 {; 92 const auto effectiveVerbosity =; 93 ROOT::Experimental::Internal::GetChannelOrManager(ROOT::Detail::RDF::RDFLogChannel()); 94 .GetEffectiveVerbosity(ROOT::Experimental::RLogManager::Get());; 95 if (effectiveVerbosity >= ROOT::Experimental::ELogLevel::kDebug + 10) {; 96 // a very high verbosity was requested, let's not silence anything; 97 uniqueLoops[0].fLoopManager->Jit();; 98 } else {; 99 // silence logs from RLoopManager::Jit: RunGraphs does its own logging; 100 auto silenceRDFLogs = ROOT::Experimental::RLogScopedVerbosity(ROOT::Detail::RDF::RDFLogChannel(),; 101 ROOT::Experimental::ELogLevel::kError);; 102 uniqueLoops[0].fLoopManager->Jit();; 103 }; 104 }; 105 sw.Stop();; 106 R__LOG_INFO(ROOT::Detail::RDF::RDFLogChannel()); 107 << ""Just-in-time compilation phase for RunGraphs ("" << uniqueLoops.size(); 108 << "" unique computation graphs) completed""; 109 << (sw.RealTime() > 1e-3 ? "" in "" + std::to_string(sw.RealTime()) + "" seconds."" : "" in less than 1ms."");; 110 ; 111 // Trigger the unique event loops; 112 auto run = [](RResultHandle &h) {; 113 if (h.fLoopManager); 114 h.fLoopManager->Run(/*jit=*/false);; 115 };; 116 ; 117 sw.Start();; 118#ifdef R__USE_IMT; 119 if (ROOT::IsImplicitMTEnabled()) {; 120 ROOT::TThreadExecutor{}.Foreach(run, uniqueLoops);; 121 } else {; 122#endif; 123 std::for_each(uniqueLoops.begin(), uniqueLoops.end(), run);; 124#ifdef R__USE_IMT; 125 }; 126#endif; 127 sw.Stop();; 128 R__LOG_INFO(ROOT::Detail::RDF::RDFLogChannel()); 129 << ""Finished RunGr",MatchSource.WIKI,doc/master/RDFHelpers_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8cxx_source.html
https://root.cern/doc/master/RDFHelpers_8cxx_source.html:1564,Usability,progress bar,progress bar,1564,"IsImplicitMTEnabled; 13#include ""TError.h"" // Warning; 14#include ""TStopwatch.h""; 15#include ""RConfigure.h"" // R__USE_IMT; 16#include ""ROOT/RLogger.hxx""; 17#include ""ROOT/RDF/RLoopManager.hxx"" // for RLoopManager; 18#include ""ROOT/RDF/Utils.hxx""; 19#include ""ROOT/RResultHandle.hxx"" // for RResultHandle, RunGraphs; 20#ifdef R__USE_IMT; 21#include ""ROOT/TThreadExecutor.hxx""; 22#endif // R__USE_IMT; 23 ; 24#include <algorithm>; 25#include <iostream>; 26#include <set>; 27#include <cstdio>; 28 ; 29// TODO, this function should be part of core libraries; 30#include <numeric>; 31#if (!defined(_WIN32)) && (!defined(_WIN64)); 32#include <unistd.h>; 33#endif; 34 ; 35#if defined(_WIN32) || defined(_WIN64); 36#define WIN32_LEAN_AND_MEAN; 37#define VC_EXTRALEAN; 38#include <io.h>; 39#include <Windows.h>; 40#else; 41#include <sys/ioctl.h>; 42#endif; 43 ; 44// Get terminal size for progress bar; 45int get_tty_size(); 46{; 47#if defined(_WIN32) || defined(_WIN64); 48 if (!_isatty(_fileno(stdout))); 49 return 0;; 50 int width = 0;; 51 CONSOLE_SCREEN_BUFFER_INFO csbi;; 52 if (GetConsoleScreenBufferInfo(GetStdHandle(STD_OUTPUT_HANDLE), &csbi)); 53 width = (int)(csbi.srWindow.Right - csbi.srWindow.Left + 1);; 54 return width;; 55#else; 56 int width = 0;; 57 struct winsize w;; 58 ioctl(fileno(stdout), TIOCGWINSZ, &w);; 59 width = (int)(w.ws_col);; 60 return width;; 61#endif; 62}; 63 ; 64using ROOT::RDF::RResultHandle;; 65 ; 66unsigned int ROOT::RDF::RunGraphs(std::vector<RResultHandle> handles); 67{; 68 if (handles.empty()) {; 69 Warning(""RunGraphs"", ""Got an empty list of handles, now quitting."");; 70 return 0u;; 71 }; 72 ; 73 // Check that there are results which have not yet been run; 74 const unsigned int nToRun =; 75 std::count_if(handles.begin(), handles.end(), [](const auto &h) { return !h.IsReady(); });; 76 if (nToRun < handles.size()) {; 77 Warning(""RunGraphs"", ""Got %zu handles from which %zu link to results which are already ready."", handles.size(),; 78 handles.size() - nToRun)",MatchSource.WIKI,doc/master/RDFHelpers_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8cxx_source.html
https://root.cern/doc/master/RDFHelpers_8cxx_source.html:10739,Usability,progress bar,progress bar,10739,"ours); 239 stream << ""\033[0m"";; 240 stream << ""processing file: "" << currentFileIdx << "" / "" << totalFiles << "" "";; 241 ; 242 // Event counts:; 243 if (fUseShellColours); 244 stream << ""\033[32m"";; 245 ; 246 stream << ""processed evts: "" << currentEventCount;; 247 if (GetNEventsOfCurrentFile != 0) {; 248 stream << "" / "" << std::scientific << std::setprecision(2) << GetNEventsOfCurrentFile;; 249 }; 250 stream << "" "";; 251 ; 252 if (fUseShellColours); 253 stream << ""\033[0m"";; 254 ; 255 // events/s; 256 stream << std::scientific << std::setprecision(2) << evtpersec << "" evt/s"";; 257 ; 258 // Time statistics:; 259 if (GetNEventsOfCurrentFile != 0) {; 260 if (fUseShellColours); 261 stream << ""\033[35m"";; 262 std::chrono::seconds remainingSeconds(; 263 static_cast<long long>((ComputeNEventsSoFar() - currentEventCount) / evtpersec));; 264 stream << "" "" << remainingSeconds << "" ""; 265 << "" remaining time (per file being processed)"";; 266 if (fUseShellColours); 267 stream << ""\033[0m"";; 268 }; 269 ; 270 stream << ""] "";; 271}; 272 ; 273void ProgressHelper::PrintStatsFinal(std::ostream &stream, std::chrono::seconds elapsedSeconds) const; 274{; 275 RestoreStreamState restore(stream);; 276 auto totalEvents = ComputeNEventsSoFar();; 277 auto totalFiles = fTotalFiles;; 278 ; 279 if (fUseShellColours); 280 stream << ""\033[35m"";; 281 stream << ""[""; 282 << ""Total elapsed time: "" << elapsedSeconds << "" "";; 283 if (fUseShellColours); 284 stream << ""\033[0m"";; 285 stream << ""processed files: "" << totalFiles << "" / "" << totalFiles << "" "";; 286 ; 287 // Event counts:; 288 if (fUseShellColours); 289 stream << ""\033[32m"";; 290 ; 291 stream << ""processed evts: "" << totalEvents;; 292 if (totalEvents != 0) {; 293 stream << "" / "" << std::scientific << std::setprecision(2) << totalEvents;; 294 }; 295 ; 296 if (fUseShellColours); 297 stream << ""\033[0m"";; 298 ; 299 stream << ""] "";; 300}; 301 ; 302/// Print a progress bar of width `ProgressHelper::fBarWidth` if `fGetNEventsOfCurrentFile` is known.",MatchSource.WIKI,doc/master/RDFHelpers_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8cxx_source.html
https://root.cern/doc/master/RDFHelpers_8cxx_source.html:18030,Usability,progress bar,progress bar,18030,"sk(TTreeReader *, unsigned int)Definition RDFHelpers.cxx:339; ROOT::RDF::Experimental::ProgressBarAction::fDummyResultstd::shared_ptr< int > fDummyResultDefinition RDFHelpers.cxx:331; ROOT::RDF::Experimental::ProgressBarAction::GetResultPtrstd::shared_ptr< Result_t > GetResultPtr() constDefinition RDFHelpers.cxx:336; ROOT::RDF::Experimental::ProgressBarAction::GetActionNamestd::string GetActionName()Definition RDFHelpers.cxx:360; ROOT::RDF::Experimental::ProgressHelper::fTotalFilesunsigned int fTotalFilesDefinition RDFHelpers.hxx:344; ROOT::RDF::Experimental::ProgressHelper::RecordEvtCountAndTimestd::pair< std::size_t, std::chrono::seconds > RecordEvtCountAndTime()Record current event counts and time stamp, populate evts/s statistics array.Definition RDFHelpers.cxx:174; ROOT::RDF::Experimental::ProgressHelper::fUseShellColoursbool fUseShellColoursDefinition RDFHelpers.hxx:348; ROOT::RDF::Experimental::ProgressHelper::PrintProgressBarvoid PrintProgressBar(std::ostream &stream, std::size_t currentEventCount) constPrint a progress bar of width ProgressHelper::fBarWidth if fGetNEventsOfCurrentFile is known.Definition RDFHelpers.cxx:303; ROOT::RDF::Experimental::ProgressHelper::PrintStatsvoid PrintStats(std::ostream &stream, std::size_t currentEventCount, std::chrono::seconds totalElapsedSeconds) constPrint event and time statistics.Definition RDFHelpers.cxx:225; ROOT::RDF::Experimental::ProgressHelper::fLastProcessedEventsstd::size_t fLastProcessedEventsDefinition RDFHelpers.hxx:334; ROOT::RDF::Experimental::ProgressHelper::fEventsPerSecondStatisticsstd::array< double, 20 > fEventsPerSecondStatisticsDefinition RDFHelpers.hxx:340; ROOT::RDF::Experimental::ProgressHelper::EvtPerSecdouble EvtPerSec() constCompute a running mean of events/s.Definition RDFHelpers.cxx:162; ROOT::RDF::Experimental::ProgressHelper::fProcessedEventsstd::atomic< std::size_t > fProcessedEventsDefinition RDFHelpers.hxx:333; ROOT::RDF::Experimental::ProgressHelper::ComputeCurrentFileIdxunsigned int C",MatchSource.WIKI,doc/master/RDFHelpers_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8cxx_source.html
https://root.cern/doc/master/RDFHelpers_8cxx_source.html:21162,Usability,simpl,simple,21162,"RDF::RInterfaceBase::GetNFilesunsigned int GetNFiles()Definition RInterfaceBase.cxx:27; ROOT::RDF::RInterfaceThe public interface to the RDataFrame federation of classes.Definition RInterface.hxx:113; ROOT::RDF::RInterface::BookRResultPtr< typename std::decay_t< Helper >::Result_t > Book(Helper &&helper, const ColumnNames_t &columns={})Book execution of a custom action using a user-defined helper object.Definition RInterface.hxx:2984; ROOT::RDF::RResultHandleA type-erased version of RResultPtr and RResultMap.Definition RResultHandle.hxx:33; ROOT::RDF::RResultPtrSmart pointer for the return type of actions.Definition RResultPtr.hxx:119; ROOT::RDF::RSampleInfoThis type represents a sample identifier, to be used in conjunction with RDataFrame features such as ...Definition RSampleInfo.hxx:35; ROOT::RDataFrameROOT's RDataFrame offers a modern, high-level interface for analysis of data stored in TTree ,...Definition RDataFrame.hxx:41; ROOT::TThreadExecutorThis class provides a simple interface to execute the same task multiple times in parallel threads,...Definition TThreadExecutor.hxx:41; ROOT::TThreadExecutor::Foreachvoid Foreach(F func, unsigned nTimes, unsigned nChunks=0)Execute a function without arguments several times in parallel, dividing the execution in nChunks.Definition TThreadExecutor.hxx:146; TStopwatchStopwatch class.Definition TStopwatch.h:28; TStopwatch::RealTimeDouble_t RealTime()Stop the stopwatch (if it is running) and return the realtime (in seconds) passed between the start a...Definition TStopwatch.cxx:110; TStopwatch::Startvoid Start(Bool_t reset=kTRUE)Start the stopwatch.Definition TStopwatch.cxx:58; TStopwatch::CpuTimeDouble_t CpuTime()Stop the stopwatch (if it is running) and return the cputime (in seconds) passed between the start an...Definition TStopwatch.cxx:125; TStopwatch::Stopvoid Stop()Stop the stopwatch.Definition TStopwatch.cxx:77; TTreeReaderA simple, robust and fast interface to read values from ROOT columnar datasets such as TTree,.",MatchSource.WIKI,doc/master/RDFHelpers_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8cxx_source.html
https://root.cern/doc/master/RDFHelpers_8cxx_source.html:22084,Usability,simpl,simple,22084,"ROOT::TThreadExecutorThis class provides a simple interface to execute the same task multiple times in parallel threads,...Definition TThreadExecutor.hxx:41; ROOT::TThreadExecutor::Foreachvoid Foreach(F func, unsigned nTimes, unsigned nChunks=0)Execute a function without arguments several times in parallel, dividing the execution in nChunks.Definition TThreadExecutor.hxx:146; TStopwatchStopwatch class.Definition TStopwatch.h:28; TStopwatch::RealTimeDouble_t RealTime()Stop the stopwatch (if it is running) and return the realtime (in seconds) passed between the start a...Definition TStopwatch.cxx:110; TStopwatch::Startvoid Start(Bool_t reset=kTRUE)Start the stopwatch.Definition TStopwatch.cxx:58; TStopwatch::CpuTimeDouble_t CpuTime()Stop the stopwatch (if it is running) and return the cputime (in seconds) passed between the start an...Definition TStopwatch.cxx:125; TStopwatch::Stopvoid Stop()Stop the stopwatch.Definition TStopwatch.cxx:77; TTreeReaderA simple, robust and fast interface to read values from ROOT columnar datasets such as TTree,...Definition TTreeReader.h:46; double; int; ROOT::Detail::RDF::RDFLogChannelROOT::Experimental::RLogChannel & RDFLogChannel()Definition RDFUtils.cxx:37; ROOT::Experimental::Internal::GetChannelOrManagerRLogChannel & GetChannelOrManager()Definition RLogger.hxx:302; ROOT::Experimental::ELogLevel::kDebug@ kDebugDebug information; only useful for developers; can have added verbosity up to 255-kDebug.; ROOT::Experimental::ELogLevel::kError@ kErrorAn error.; ROOT::RDF::Experimental::VariationsForRResultMap< T > VariationsFor(RResultPtr< T > resPtr)Produce all required systematic variations for the given result.Definition RDFHelpers.hxx:219; ROOT::RDF::Experimental::AddProgressBarvoid AddProgressBar(ROOT::RDF::RNode df)Add ProgressBar to a ROOT::RDF::RNode.Definition RDFHelpers.cxx:373; ROOT::RDF::RunGraphsunsigned int RunGraphs(std::vector< RResultHandle > handles)Trigger the event loop of multiple RDataFrames concurrently.Definition RD",MatchSource.WIKI,doc/master/RDFHelpers_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8cxx_source.html
https://root.cern/doc/master/RDFHelpers_8hxx.html:604,Integrability,depend,dependency,604,". ROOT: tree/dataframe/inc/ROOT/RDFHelpers.hxx File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. Classes |; Namespaces |; Typedefs |; Functions ; RDFHelpers.hxx File Reference. #include <ROOT/RDF/GraphUtils.hxx>; #include <ROOT/RDF/RActionBase.hxx>; #include <ROOT/RDF/RResultMap.hxx>; #include <ROOT/RResultHandle.hxx>; #include <ROOT/TypeTraits.hxx>; #include <array>; #include <chrono>; #include <fstream>; #include <functional>; #include <map>; #include <memory>; #include <mutex>; #include <type_traits>; #include <utility>; #include <vector>. Include dependency graph for RDFHelpers.hxx:. This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead. This graph shows which files directly or indirectly include this file:. This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead. Classes; class ROOT::RDF::Experimental::ProgressHelper; RDF progress helper. More...; . Namespaces; namespace ROOT; tbb::task_arena is an alias of tbb::interface7::task_arena, which doesn't allow to forward declare tbb::task_arena without forward declaring tbb::interface7 ; ; namespace ROOT::Internal; ; namespace ROOT::Internal::RDF; ; namespace ROOT::RDF; ; namespace ROOT::RDF::Experimental; . Typedefs; usingROOT::RDF::Experimental::SnapshotPtr_t = ROOT::RDF::RResultPtr< ROOT::RDF::RInterface< ROOT::Detail::RDF::RLoopManager, void > >; . Functions; voidROOT::RDF::Experimental::AddProgressBar (ROOT::RDataFrame df); Add ProgressBar to an RDataFrame. ; ; voidROOT::RDF::Experimental::AddProgressBar (ROOT::RDF::RNode df); Add ProgressBar to a ROOT::RDF::RNode. ; ; template<typename NodeType > ; RNodeROOT::RDF::AsRNode (NodeType node); Cast a RDataFrame node to the common type ROOT::RDF::RNode. ; ; template<typename F , typename Args = typename ROOT::TypeTraits::CallableTraits<std::decay_t<F>>::arg_types_nodecay, typename Ret = typename ROOT::TypeTraits::CallableTraits<std::decay_",MatchSource.WIKI,doc/master/RDFHelpers_8hxx.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx.html
https://root.cern/doc/master/RDFHelpers_8hxx.html:2978,Modifiability,variab,variables,2978,"template<typename F , typename Args = typename ROOT::TypeTraits::CallableTraits<std::decay_t<F>>::arg_types_nodecay, typename Ret = typename ROOT::TypeTraits::CallableTraits<std::decay_t<F>>::ret_type> ; autoROOT::RDF::Not (F &&f) -> decltype(RDFInternal::NotHelper(Args(), std::forward< F >(f))); Given a callable with signature bool(T1, T2, ...) return a callable with same signature that returns the negated result. ; ; template<typename... ArgTypes, typename F > ; std::function< bool(ArgTypes...)>ROOT::Internal::RDF::NotHelper (ROOT::TypeTraits::TypeList< ArgTypes... >, F &&f); ; template<typename... ArgTypes, typename Ret , typename... Args> ; std::function< bool(ArgTypes...)>ROOT::Internal::RDF::NotHelper (ROOT::TypeTraits::TypeList< ArgTypes... >, Ret(*f)(Args...)); ; template<std::size_t N, typename T , typename F > ; autoROOT::Internal::RDF::PassAsVec (F &&f) -> PassAsVecHelper< std::make_index_sequence< N >, T, F >; ; template<std::size_t N, typename T , typename F > ; autoROOT::RDF::PassAsVec (F &&f) -> RDFInternal::PassAsVecHelper< std::make_index_sequence< N >, T, F >; PassAsVec is a callable generator that allows passing N variables of type T to a function as a single collection. ; ; unsigned intROOT::RDF::RunGraphs (std::vector< RResultHandle > handles); Trigger the event loop of multiple RDataFrames concurrently. ; ; template<typename NodeType > ; std::stringROOT::RDF::SaveGraph (NodeType node); Create a graphviz representation of the dataframe computation graph, return it as a string. ; ; template<typename NodeType > ; voidROOT::RDF::SaveGraph (NodeType node, const std::string &outputFile); Create a graphviz representation of the dataframe computation graph, write it to the specified file. ; ; template<typename T > ; RResultMap< T >ROOT::RDF::Experimental::VariationsFor (RResultPtr< T > resPtr); Produce all required systematic variations for the given result. ; ; SnapshotPtr_tROOT::RDF::Experimental::VariationsFor (SnapshotPtr_t ",MatchSource.WIKI,doc/master/RDFHelpers_8hxx.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx.html
https://root.cern/doc/master/RDFHelpers_8hxx.html:3163,Performance,concurren,concurrently,3163,"aits::CallableTraits<std::decay_t<F>>::ret_type> ; autoROOT::RDF::Not (F &&f) -> decltype(RDFInternal::NotHelper(Args(), std::forward< F >(f))); Given a callable with signature bool(T1, T2, ...) return a callable with same signature that returns the negated result. ; ; template<typename... ArgTypes, typename F > ; std::function< bool(ArgTypes...)>ROOT::Internal::RDF::NotHelper (ROOT::TypeTraits::TypeList< ArgTypes... >, F &&f); ; template<typename... ArgTypes, typename Ret , typename... Args> ; std::function< bool(ArgTypes...)>ROOT::Internal::RDF::NotHelper (ROOT::TypeTraits::TypeList< ArgTypes... >, Ret(*f)(Args...)); ; template<std::size_t N, typename T , typename F > ; autoROOT::Internal::RDF::PassAsVec (F &&f) -> PassAsVecHelper< std::make_index_sequence< N >, T, F >; ; template<std::size_t N, typename T , typename F > ; autoROOT::RDF::PassAsVec (F &&f) -> RDFInternal::PassAsVecHelper< std::make_index_sequence< N >, T, F >; PassAsVec is a callable generator that allows passing N variables of type T to a function as a single collection. ; ; unsigned intROOT::RDF::RunGraphs (std::vector< RResultHandle > handles); Trigger the event loop of multiple RDataFrames concurrently. ; ; template<typename NodeType > ; std::stringROOT::RDF::SaveGraph (NodeType node); Create a graphviz representation of the dataframe computation graph, return it as a string. ; ; template<typename NodeType > ; voidROOT::RDF::SaveGraph (NodeType node, const std::string &outputFile); Create a graphviz representation of the dataframe computation graph, write it to the specified file. ; ; template<typename T > ; RResultMap< T >ROOT::RDF::Experimental::VariationsFor (RResultPtr< T > resPtr); Produce all required systematic variations for the given result. ; ; SnapshotPtr_tROOT::RDF::Experimental::VariationsFor (SnapshotPtr_t resPtr); . treedataframeincROOTRDFHelpers.hxx. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:26 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/RDFHelpers_8hxx.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx.html
https://root.cern/doc/master/RDFHelpers_8hxx_source.html:689,Availability,down,down,689,". ROOT: tree/dataframe/inc/ROOT/RDFHelpers.hxx Source File. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. RDFHelpers.hxx. Go to the documentation of this file. 1// Author: Enrico Guiraud, Danilo Piparo CERN 02/2018; 2 ; 3/*************************************************************************; 4 * Copyright (C) 1995-2018, Rene Brun and Fons Rademakers. *; 5 * All rights reserved. *; 6 * *; 7 * For the licensing terms see $ROOTSYS/LICENSE. *; 8 * For the list of contributors see $ROOTSYS/README/CREDITS. *; 9 *************************************************************************/; 10 ; 11// This header contains helper free functions that slim down RDataFrame's programming model; 12 ; 13#ifndef ROOT_RDF_HELPERS; 14#define ROOT_RDF_HELPERS; 15 ; 16#include <ROOT/RDF/GraphUtils.hxx>; 17#include <ROOT/RDF/RActionBase.hxx>; 18#include <ROOT/RDF/RResultMap.hxx>; 19#include <ROOT/RResultHandle.hxx> // users of RunGraphs might rely on this transitive include; 20#include <ROOT/TypeTraits.hxx>; 21 ; 22#include <array>; 23#include <chrono>; 24#include <fstream>; 25#include <functional>; 26#include <map>; 27#include <memory>; 28#include <mutex>; 29#include <type_traits>; 30#include <utility> // std::index_sequence; 31#include <vector>; 32 ; 33namespace ROOT {; 34namespace Internal {; 35namespace RDF {; 36template <typename... ArgTypes, typename F>; 37std::function<bool(ArgTypes...)> NotHelper(ROOT::TypeTraits::TypeList<ArgTypes...>, F &&f); 38{; 39 return std::function<bool(ArgTypes...)>([=](ArgTypes... args) mutable { return !f(args...); });; 40}; 41 ; 42template <typename... ArgTypes, typename Ret, typename... Args>; 43std::function<bool(ArgTypes...)> NotHelper(ROOT::TypeTraits::TypeList<ArgTypes...>, Ret (*f)(Args...)); 44{; 45 return std::function<bool(ArgTypes...)>([=](ArgTypes... args) mutable { return !f(args...); });; 46}; 47 ; 48template <typename I, typename T, typename F>; 49class PassAsVecHelper;; 50 ; 51template <std::size_t... ",MatchSource.WIKI,doc/master/RDFHelpers_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx_source.html
https://root.cern/doc/master/RDFHelpers_8hxx_source.html:3794,Availability,down,down,3794,", T2, ...) return a callable with same signature that returns the negated result; 76///; 77/// The callable must have one single non-template definition of operator(). This is a limitation with respect to; 78/// std::not_fn, required for interoperability with RDataFrame.; 79// clang-format on; 80template <typename F,; 81 typename Args = typename ROOT::TypeTraits::CallableTraits<std::decay_t<F>>::arg_types_nodecay,; 82 typename Ret = typename ROOT::TypeTraits::CallableTraits<std::decay_t<F>>::ret_type>; 83auto Not(F &&f) -> decltype(RDFInternal::NotHelper(Args(), std::forward<F>(f))); 84{; 85 static_assert(std::is_same<Ret, bool>::value, ""RDF::Not requires a callable that returns a bool."");; 86 return RDFInternal::NotHelper(Args(), std::forward<F>(f));; 87}; 88 ; 89// clang-format off; 90/// PassAsVec is a callable generator that allows passing N variables of type T to a function as a single collection.; 91///; 92/// PassAsVec<N, T>(func) returns a callable that takes N arguments of type T, passes them down to function `func` as; 93/// an initializer list `{t1, t2, t3,..., tN}` and returns whatever f({t1, t2, t3, ..., tN}) returns.; 94///; 95/// Note that for this to work with RDataFrame the type of all columns that the callable is applied to must be exactly T.; 96/// Example usage together with RDataFrame (""varX"" columns must all be `float` variables):; 97/// \code; 98/// bool myVecFunc(std::vector<float> args);; 99/// df.Filter(PassAsVec<3, float>(myVecFunc), {""var1"", ""var2"", ""var3""});; 100/// \endcode; 101// clang-format on; 102template <std::size_t N, typename T, typename F>; 103auto PassAsVec(F &&f) -> RDFInternal::PassAsVecHelper<std::make_index_sequence<N>, T, F>; 104{; 105 return RDFInternal::PassAsVecHelper<std::make_index_sequence<N>, T, F>(std::forward<F>(f));; 106}; 107 ; 108// clang-format off; 109/// Create a graphviz representation of the dataframe computation graph, return it as a string.; 110/// \param[in] node any node of the graph. Called on the he",MatchSource.WIKI,doc/master/RDFHelpers_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx_source.html
https://root.cern/doc/master/RDFHelpers_8hxx_source.html:5059,Availability,down,downstream,5059,"lumns must all be `float` variables):; 97/// \code; 98/// bool myVecFunc(std::vector<float> args);; 99/// df.Filter(PassAsVec<3, float>(myVecFunc), {""var1"", ""var2"", ""var3""});; 100/// \endcode; 101// clang-format on; 102template <std::size_t N, typename T, typename F>; 103auto PassAsVec(F &&f) -> RDFInternal::PassAsVecHelper<std::make_index_sequence<N>, T, F>; 104{; 105 return RDFInternal::PassAsVecHelper<std::make_index_sequence<N>, T, F>(std::forward<F>(f));; 106}; 107 ; 108// clang-format off; 109/// Create a graphviz representation of the dataframe computation graph, return it as a string.; 110/// \param[in] node any node of the graph. Called on the head (first) node, it prints the entire graph. Otherwise, only the branch the node belongs to.; 111///; 112/// The output can be displayed with a command akin to `dot -Tpng output.dot > output.png && open output.png`.; 113///; 114/// Note that ""hanging"" Defines, i.e. Defines without downstream nodes, will not be displayed by SaveGraph as they are; 115/// effectively optimized away from the computation graph.; 116///; 117/// Note that SaveGraph is not thread-safe and must not be called concurrently from different threads.; 118// clang-format on; 119template <typename NodeType>; 120std::string SaveGraph(NodeType node); 121{; 122 ROOT::Internal::RDF::GraphDrawing::GraphCreatorHelper helper;; 123 return helper.RepresentGraph(node);; 124}; 125 ; 126// clang-format off; 127/// Create a graphviz representation of the dataframe computation graph, write it to the specified file.; 128/// \param[in] node any node of the graph. Called on the head (first) node, it prints the entire graph. Otherwise, only the branch the node belongs to.; 129/// \param[in] outputFile file where to save the representation.; 130///; 131/// The output can be displayed with a command akin to `dot -Tpng output.dot > output.png && open output.png`.; 132///; 133/// Note that ""hanging"" Defines, i.e. Defines without downstream nodes, will not be displayed by",MatchSource.WIKI,doc/master/RDFHelpers_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx_source.html
https://root.cern/doc/master/RDFHelpers_8hxx_source.html:6072,Availability,down,downstream,6072,"5/// effectively optimized away from the computation graph.; 116///; 117/// Note that SaveGraph is not thread-safe and must not be called concurrently from different threads.; 118// clang-format on; 119template <typename NodeType>; 120std::string SaveGraph(NodeType node); 121{; 122 ROOT::Internal::RDF::GraphDrawing::GraphCreatorHelper helper;; 123 return helper.RepresentGraph(node);; 124}; 125 ; 126// clang-format off; 127/// Create a graphviz representation of the dataframe computation graph, write it to the specified file.; 128/// \param[in] node any node of the graph. Called on the head (first) node, it prints the entire graph. Otherwise, only the branch the node belongs to.; 129/// \param[in] outputFile file where to save the representation.; 130///; 131/// The output can be displayed with a command akin to `dot -Tpng output.dot > output.png && open output.png`.; 132///; 133/// Note that ""hanging"" Defines, i.e. Defines without downstream nodes, will not be displayed by SaveGraph as they are; 134/// effectively optimized away from the computation graph.; 135///; 136/// Note that SaveGraph is not thread-safe and must not be called concurrently from different threads.; 137// clang-format on; 138template <typename NodeType>; 139void SaveGraph(NodeType node, const std::string &outputFile); 140{; 141 ROOT::Internal::RDF::GraphDrawing::GraphCreatorHelper helper;; 142 std::string dotGraph = helper.RepresentGraph(node);; 143 ; 144 std::ofstream out(outputFile);; 145 if (!out.is_open()) {; 146 throw std::runtime_error(""Could not open output file \"""" + outputFile + ""\""for reading"");; 147 }; 148 ; 149 out << dotGraph;; 150 out.close();; 151}; 152 ; 153// clang-format off; 154/// Cast a RDataFrame node to the common type ROOT::RDF::RNode; 155/// \param[in] node Any node of a RDataFrame graph; 156// clang-format on; 157template <typename NodeType>; 158RNode AsRNode(NodeType node); 159{; 160 return node;; 161}; 162 ; 163// clang-format off; 164/// Trigger the event loop of mul",MatchSource.WIKI,doc/master/RDFHelpers_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx_source.html
https://root.cern/doc/master/RDFHelpers_8hxx_source.html:8576,Availability,down,down,8576,"omputation of all results is generally more efficient.; 172/// It should be noted that user-defined operations (e.g., Filters and Defines) of the different RDataFrame graphs are assumed to be safe to call concurrently.; 173///; 174/// ~~~{.cpp}; 175/// ROOT::RDataFrame df1(""tree1"", ""file1.root"");; 176/// auto r1 = df1.Histo1D(""var1"");; 177///; 178/// ROOT::RDataFrame df2(""tree2"", ""file2.root"");; 179/// auto r2 = df2.Sum(""var2"");; 180///; 181/// // RResultPtr -> RResultHandle conversion is automatic; 182/// ROOT::RDF::RunGraphs({r1, r2});; 183/// ~~~; 184// clang-format on; 185unsigned int RunGraphs(std::vector<RResultHandle> handles);; 186 ; 187namespace Experimental {; 188 ; 189/// \brief Produce all required systematic variations for the given result.; 190/// \param[in] resPtr The result for which variations should be produced.; 191/// \return A \ref ROOT::RDF::Experimental::RResultMap ""RResultMap"" object with full variation names as strings; 192/// (e.g. ""pt:down"") and the corresponding varied results as values.; 193///; 194/// A given input RResultPtr<T> produces a corresponding RResultMap<T> with a ""nominal""; 195/// key that will return a value identical to the one contained in the original RResultPtr.; 196/// Other keys correspond to the varied values of this result, one for each variation; 197/// that the result depends on.; 198/// VariationsFor does not trigger the event loop. The event loop is only triggered; 199/// upon first access to a valid key, similarly to what happens with RResultPtr.; 200///; 201/// If the result does not depend, directly or indirectly, from any registered systematic variation, the; 202/// returned RResultMap will contain only the ""nominal"" key.; 203///; 204/// See RDataFrame's \ref ROOT::RDF::RInterface::Vary() ""Vary"" method for more information and example usages.; 205///; 206/// \note Currently, producing variations for the results of \ref ROOT::RDF::RInterface::Display() ""Display"",; 207/// \ref ROOT::RDF::RInterface::Report() ""Re",MatchSource.WIKI,doc/master/RDFHelpers_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx_source.html
https://root.cern/doc/master/RDFHelpers_8hxx_source.html:20827,Availability,error,error,20827," elapsedSeconds) = RecordEvtCountAndTime();; 422 ; 423 if (fIsTTY); 424 std::cout << ""\r"";; 425 ; 426 PrintProgressBar(std::cout, eventCount);; 427 PrintStats(std::cout, eventCount, elapsedSeconds);; 428 ; 429 if (fIsTTY); 430 std::cout << std::flush;; 431 else; 432 std::cout << std::endl;; 433 }; 434 ; 435 std::size_t ComputeNEventsSoFar() const; 436 {; 437 std::unique_lock<std::mutex> lock(fSampleNameToEventEntriesMutex);; 438 std::size_t result = 0;; 439 for (const auto &item : fSampleNameToEventEntries); 440 result += item.second;; 441 return result;; 442 }; 443 ; 444 unsigned int ComputeCurrentFileIdx() const; 445 {; 446 std::unique_lock<std::mutex> lock(fSampleNameToEventEntriesMutex);; 447 return fSampleNameToEventEntries.size();; 448 }; 449};; 450} // namespace Experimental; 451} // namespace RDF; 452} // namespace ROOT; 453#endif; GraphUtils.hxx; RActionBase.hxx; RResultHandle.hxx; RResultMap.hxx; f#define f(i)Definition RSha256.hxx:104; R__ASSERT#define R__ASSERT(e)Checks condition e and reports a fatal error if it's false.Definition TError.h:125; N#define N; resultOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t Float_t Float_t Int_t Int_t UInt_t UInt_t Rectangle_t resultDefinition TGWin32VirtualXProxy.cxx:174; valueOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void valueDefinition TGWin32VirtualXProxy.cxx:142; operator()TRObject operator()(const T1 &t1) constDefinition TRFunctionImport__oprtr.h:14; TypeTraits.hxx; ROOT::Detail::RDF::RLoopManager::Jitvoid Jit()Add RDF nodes that require just-in-time compilation to the computation graph.Definition RLoopManager.cxx:848; ROOT::Internal::RDF::GraphDrawing::GraphCreatorHelperDefinition GraphUtils.hxx:57; ROOT::Internal::RDF::GraphDrawing::GraphCreato",MatchSource.WIKI,doc/master/RDFHelpers_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx_source.html
https://root.cern/doc/master/RDFHelpers_8hxx_source.html:7644,Energy Efficiency,efficient,efficient,7644,"45 if (!out.is_open()) {; 146 throw std::runtime_error(""Could not open output file \"""" + outputFile + ""\""for reading"");; 147 }; 148 ; 149 out << dotGraph;; 150 out.close();; 151}; 152 ; 153// clang-format off; 154/// Cast a RDataFrame node to the common type ROOT::RDF::RNode; 155/// \param[in] node Any node of a RDataFrame graph; 156// clang-format on; 157template <typename NodeType>; 158RNode AsRNode(NodeType node); 159{; 160 return node;; 161}; 162 ; 163// clang-format off; 164/// Trigger the event loop of multiple RDataFrames concurrently; 165/// \param[in] handles A vector of RResultHandles; 166/// \return The number of distinct computation graphs that have been processed; 167///; 168/// This function triggers the event loop of all computation graphs which relate to the; 169/// given RResultHandles. The advantage compared to running the event loop implicitly by accessing the; 170/// RResultPtr is that the event loops will run concurrently. Therefore, the overall; 171/// computation of all results is generally more efficient.; 172/// It should be noted that user-defined operations (e.g., Filters and Defines) of the different RDataFrame graphs are assumed to be safe to call concurrently.; 173///; 174/// ~~~{.cpp}; 175/// ROOT::RDataFrame df1(""tree1"", ""file1.root"");; 176/// auto r1 = df1.Histo1D(""var1"");; 177///; 178/// ROOT::RDataFrame df2(""tree2"", ""file2.root"");; 179/// auto r2 = df2.Sum(""var2"");; 180///; 181/// // RResultPtr -> RResultHandle conversion is automatic; 182/// ROOT::RDF::RunGraphs({r1, r2});; 183/// ~~~; 184// clang-format on; 185unsigned int RunGraphs(std::vector<RResultHandle> handles);; 186 ; 187namespace Experimental {; 188 ; 189/// \brief Produce all required systematic variations for the given result.; 190/// \param[in] resPtr The result for which variations should be produced.; 191/// \return A \ref ROOT::RDF::Experimental::RResultMap ""RResultMap"" object with full variation names as strings; 192/// (e.g. ""pt:down"") and the corresponding varied",MatchSource.WIKI,doc/master/RDFHelpers_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx_source.html
https://root.cern/doc/master/RDFHelpers_8hxx_source.html:3015,Integrability,interoperab,interoperability,3015,"t... N, typename T, typename F>; 52class PassAsVecHelper<std::index_sequence<N...>, T, F> {; 53 template <std::size_t Idx>; 54 using AlwaysT = T;; 55 std::decay_t<F> fFunc;; 56 ; 57public:; 58 PassAsVecHelper(F &&f) : fFunc(std::forward<F>(f)) {}; 59 auto operator()(AlwaysT<N>... args) -> decltype(fFunc({args...})) { return fFunc({args...}); }; 60};; 61 ; 62template <std::size_t N, typename T, typename F>; 63auto PassAsVec(F &&f) -> PassAsVecHelper<std::make_index_sequence<N>, T, F>; 64{; 65 return PassAsVecHelper<std::make_index_sequence<N>, T, F>(std::forward<F>(f));; 66}; 67 ; 68} // namespace RDF; 69} // namespace Internal; 70 ; 71namespace RDF {; 72namespace RDFInternal = ROOT::Internal::RDF;; 73 ; 74// clang-format off; 75/// Given a callable with signature bool(T1, T2, ...) return a callable with same signature that returns the negated result; 76///; 77/// The callable must have one single non-template definition of operator(). This is a limitation with respect to; 78/// std::not_fn, required for interoperability with RDataFrame.; 79// clang-format on; 80template <typename F,; 81 typename Args = typename ROOT::TypeTraits::CallableTraits<std::decay_t<F>>::arg_types_nodecay,; 82 typename Ret = typename ROOT::TypeTraits::CallableTraits<std::decay_t<F>>::ret_type>; 83auto Not(F &&f) -> decltype(RDFInternal::NotHelper(Args(), std::forward<F>(f))); 84{; 85 static_assert(std::is_same<Ret, bool>::value, ""RDF::Not requires a callable that returns a bool."");; 86 return RDFInternal::NotHelper(Args(), std::forward<F>(f));; 87}; 88 ; 89// clang-format off; 90/// PassAsVec is a callable generator that allows passing N variables of type T to a function as a single collection.; 91///; 92/// PassAsVec<N, T>(func) returns a callable that takes N arguments of type T, passes them down to function `func` as; 93/// an initializer list `{t1, t2, t3,..., tN}` and returns whatever f({t1, t2, t3, ..., tN}) returns.; 94///; 95/// Note that for this to work with RDataFrame the type of a",MatchSource.WIKI,doc/master/RDFHelpers_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx_source.html
https://root.cern/doc/master/RDFHelpers_8hxx_source.html:8941,Integrability,depend,depends,8941,".root"");; 176/// auto r1 = df1.Histo1D(""var1"");; 177///; 178/// ROOT::RDataFrame df2(""tree2"", ""file2.root"");; 179/// auto r2 = df2.Sum(""var2"");; 180///; 181/// // RResultPtr -> RResultHandle conversion is automatic; 182/// ROOT::RDF::RunGraphs({r1, r2});; 183/// ~~~; 184// clang-format on; 185unsigned int RunGraphs(std::vector<RResultHandle> handles);; 186 ; 187namespace Experimental {; 188 ; 189/// \brief Produce all required systematic variations for the given result.; 190/// \param[in] resPtr The result for which variations should be produced.; 191/// \return A \ref ROOT::RDF::Experimental::RResultMap ""RResultMap"" object with full variation names as strings; 192/// (e.g. ""pt:down"") and the corresponding varied results as values.; 193///; 194/// A given input RResultPtr<T> produces a corresponding RResultMap<T> with a ""nominal""; 195/// key that will return a value identical to the one contained in the original RResultPtr.; 196/// Other keys correspond to the varied values of this result, one for each variation; 197/// that the result depends on.; 198/// VariationsFor does not trigger the event loop. The event loop is only triggered; 199/// upon first access to a valid key, similarly to what happens with RResultPtr.; 200///; 201/// If the result does not depend, directly or indirectly, from any registered systematic variation, the; 202/// returned RResultMap will contain only the ""nominal"" key.; 203///; 204/// See RDataFrame's \ref ROOT::RDF::RInterface::Vary() ""Vary"" method for more information and example usages.; 205///; 206/// \note Currently, producing variations for the results of \ref ROOT::RDF::RInterface::Display() ""Display"",; 207/// \ref ROOT::RDF::RInterface::Report() ""Report"" and \ref ROOT::RDF::RInterface::Snapshot() ""Snapshot""; 208/// actions is not supported.; 209//; 210// An overview of how systematic variations work internally. Given N variations (including the nominal):; 211//; 212// RResultMap owns RVariedAction; 213// N results N action helpers;",MatchSource.WIKI,doc/master/RDFHelpers_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx_source.html
https://root.cern/doc/master/RDFHelpers_8hxx_source.html:9165,Integrability,depend,depend,9165,"r<RResultHandle> handles);; 186 ; 187namespace Experimental {; 188 ; 189/// \brief Produce all required systematic variations for the given result.; 190/// \param[in] resPtr The result for which variations should be produced.; 191/// \return A \ref ROOT::RDF::Experimental::RResultMap ""RResultMap"" object with full variation names as strings; 192/// (e.g. ""pt:down"") and the corresponding varied results as values.; 193///; 194/// A given input RResultPtr<T> produces a corresponding RResultMap<T> with a ""nominal""; 195/// key that will return a value identical to the one contained in the original RResultPtr.; 196/// Other keys correspond to the varied values of this result, one for each variation; 197/// that the result depends on.; 198/// VariationsFor does not trigger the event loop. The event loop is only triggered; 199/// upon first access to a valid key, similarly to what happens with RResultPtr.; 200///; 201/// If the result does not depend, directly or indirectly, from any registered systematic variation, the; 202/// returned RResultMap will contain only the ""nominal"" key.; 203///; 204/// See RDataFrame's \ref ROOT::RDF::RInterface::Vary() ""Vary"" method for more information and example usages.; 205///; 206/// \note Currently, producing variations for the results of \ref ROOT::RDF::RInterface::Display() ""Display"",; 207/// \ref ROOT::RDF::RInterface::Report() ""Report"" and \ref ROOT::RDF::RInterface::Snapshot() ""Snapshot""; 208/// actions is not supported.; 209//; 210// An overview of how systematic variations work internally. Given N variations (including the nominal):; 211//; 212// RResultMap owns RVariedAction; 213// N results N action helpers; 214// N previous filters; 215// N*#input_cols column readers; 216//; 217// ...and each RFilter and RDefine knows for what universe it needs to construct column readers (""nominal"" by default).; 218template <typename T>; 219RResultMap<T> VariationsFor(RResultPtr<T> resPtr); 220{; 221 R__ASSERT(resPtr != nullptr && ""Calling Var",MatchSource.WIKI,doc/master/RDFHelpers_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx_source.html
https://root.cern/doc/master/RDFHelpers_8hxx_source.html:11961,Integrability,inject,inject,11961,"ssuming that T is copiable: this should be the case; 239 // for all result types in use, as they are copied for each slot; 240 variedResults.emplace_back(new T{*resPtr.fObjPtr});; 241 ; 242 // Check if the result's type T inherits from TNamed; 243 if constexpr (std::is_base_of<TNamed, T>::value) {; 244 // Get the current variation name; 245 std::string variationName = variations[i];; 246 // Replace the colon with an underscore; 247 std::replace(variationName.begin(), variationName.end(), ':', '_'); ; 248 // Get a pointer to the corresponding varied result; 249 auto &variedResult = variedResults.back();; 250 // Set the varied result's name to NOMINALNAME_VARIATIONAME; 251 variedResult->SetName((std::string(variedResult->GetName()) + ""_"" + variationName).c_str());; 252 }; 253 }; 254 ; 255 std::vector<void *> typeErasedResults;; 256 typeErasedResults.reserve(variedResults.size());; 257 for (auto &res : variedResults); 258 typeErasedResults.emplace_back(&res);; 259 ; 260 // Create the RVariedAction and inject it in the computation graph.; 261 // This recursively creates all the required varied column readers and upstream nodes of the computation graph.; 262 variedAction = nominalAction->MakeVariedAction(std::move(typeErasedResults));; 263 }; 264 ; 265 return RDFInternal::MakeResultMap<T>(resPtr.fObjPtr, std::move(variedResults), std::move(variations),; 266 *resPtr.fLoopManager, std::move(nominalAction), std::move(variedAction));; 267}; 268 ; 269using SnapshotPtr_t = ROOT::RDF::RResultPtr<ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager, void>>;; 270SnapshotPtr_t VariationsFor(SnapshotPtr_t resPtr);; 271 ; 272/// \brief Add ProgressBar to a ROOT::RDF::RNode; 273/// \param[in] df RDataFrame node at which ProgressBar is called.; 274///; 275/// The ProgressBar can be added not only at the RDataFrame head node, but also at any any computational node,; 276/// such as Filter or Define.; 277/// ###Example usage:; 278/// ~~~{.cpp}; 279/// ROOT::RDataFrame df(""tree"", ""file.r",MatchSource.WIKI,doc/master/RDFHelpers_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx_source.html
https://root.cern/doc/master/RDFHelpers_8hxx_source.html:26182,Integrability,interface,interface,26182,"::time_point< std::chrono::system_clock > fBeginTimeDefinition RDFHelpers.hxx:329; ROOT::RDF::Experimental::ProgressHelper::PrintStatsFinalvoid PrintStatsFinal(std::ostream &stream, std::chrono::seconds totalElapsedSeconds) constDefinition RDFHelpers.cxx:273; ROOT::RDF::Experimental::ProgressHelper::fPrintIntervalstd::chrono::seconds fPrintIntervalDefinition RDFHelpers.hxx:331; ROOT::RDF::Experimental::ProgressHelper::operator()void operator()(T &)Thread-safe callback for RDataFrame.Definition RDFHelpers.hxx:399; ROOT::RDF::Experimental::ProgressHelper::fBarWidthunsigned int fBarWidthDefinition RDFHelpers.hxx:343; ROOT::RDF::Experimental::ProgressHelper::fEventsPerSecondStatisticsIndexstd::size_t fEventsPerSecondStatisticsIndexDefinition RDFHelpers.hxx:341; ROOT::RDF::Experimental::ProgressHelper::ComputeNEventsSoFarstd::size_t ComputeNEventsSoFar() constDefinition RDFHelpers.hxx:435; ROOT::RDF::Experimental::RResultMapDefinition RResultMap.hxx:98; ROOT::RDF::RInterfaceThe public interface to the RDataFrame federation of classes.Definition RInterface.hxx:113; ROOT::RDF::RResultPtrSmart pointer for the return type of actions.Definition RResultPtr.hxx:119; ROOT::RDF::RResultPtr::fLoopManagerRDFDetail::RLoopManager * fLoopManagerNon-owning pointer to the RLoopManager at the root of this computation graph.Definition RResultPtr.hxx:174; ROOT::RDF::RResultPtr::fActionPtrstd::shared_ptr< RDFInternal::RActionBase > fActionPtrOwning pointer to the action that will produce this result.Definition RResultPtr.hxx:178; ROOT::RDF::RResultPtr::fObjPtrSPT_t fObjPtrShared pointer encapsulating the wrapped result.Definition RResultPtr.hxx:175; ROOT::RDF::RSampleInfoThis type represents a sample identifier, to be used in conjunction with RDataFrame features such as ...Definition RSampleInfo.hxx:35; ROOT::RDataFrameROOT's RDataFrame offers a modern, high-level interface for analysis of data stored in TTree ,...Definition RDataFrame.hxx:41; bool; F#define F(x, y, z); ROOT::Internal::RDFD",MatchSource.WIKI,doc/master/RDFHelpers_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx_source.html
https://root.cern/doc/master/RDFHelpers_8hxx_source.html:26794,Integrability,wrap,wrapped,26794,"igned int fBarWidthDefinition RDFHelpers.hxx:343; ROOT::RDF::Experimental::ProgressHelper::fEventsPerSecondStatisticsIndexstd::size_t fEventsPerSecondStatisticsIndexDefinition RDFHelpers.hxx:341; ROOT::RDF::Experimental::ProgressHelper::ComputeNEventsSoFarstd::size_t ComputeNEventsSoFar() constDefinition RDFHelpers.hxx:435; ROOT::RDF::Experimental::RResultMapDefinition RResultMap.hxx:98; ROOT::RDF::RInterfaceThe public interface to the RDataFrame federation of classes.Definition RInterface.hxx:113; ROOT::RDF::RResultPtrSmart pointer for the return type of actions.Definition RResultPtr.hxx:119; ROOT::RDF::RResultPtr::fLoopManagerRDFDetail::RLoopManager * fLoopManagerNon-owning pointer to the RLoopManager at the root of this computation graph.Definition RResultPtr.hxx:174; ROOT::RDF::RResultPtr::fActionPtrstd::shared_ptr< RDFInternal::RActionBase > fActionPtrOwning pointer to the action that will produce this result.Definition RResultPtr.hxx:178; ROOT::RDF::RResultPtr::fObjPtrSPT_t fObjPtrShared pointer encapsulating the wrapped result.Definition RResultPtr.hxx:175; ROOT::RDF::RSampleInfoThis type represents a sample identifier, to be used in conjunction with RDataFrame features such as ...Definition RSampleInfo.hxx:35; ROOT::RDataFrameROOT's RDataFrame offers a modern, high-level interface for analysis of data stored in TTree ,...Definition RDataFrame.hxx:41; bool; F#define F(x, y, z); ROOT::Internal::RDFDefinition RArrowDS.hxx:23; ROOT::Internal::RDF::NotHelperstd::function< bool(ArgTypes...)> NotHelper(ROOT::TypeTraits::TypeList< ArgTypes... >, F &&f)Definition RDFHelpers.hxx:37; ROOT::Internal::RDF::PassAsVecauto PassAsVec(F &&f) -> PassAsVecHelper< std::make_index_sequence< N >, T, F >Definition RDFHelpers.hxx:63; ROOT::Minuit2::GradientParameterSpace::Internal@ Internal; ROOT::RDF::Experimental::VariationsForRResultMap< T > VariationsFor(RResultPtr< T > resPtr)Produce all required systematic variations for the given result.Definition RDFHelpers.hxx:219; ROOT::RD",MatchSource.WIKI,doc/master/RDFHelpers_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx_source.html
https://root.cern/doc/master/RDFHelpers_8hxx_source.html:27059,Integrability,interface,interface,27059," constDefinition RDFHelpers.hxx:435; ROOT::RDF::Experimental::RResultMapDefinition RResultMap.hxx:98; ROOT::RDF::RInterfaceThe public interface to the RDataFrame federation of classes.Definition RInterface.hxx:113; ROOT::RDF::RResultPtrSmart pointer for the return type of actions.Definition RResultPtr.hxx:119; ROOT::RDF::RResultPtr::fLoopManagerRDFDetail::RLoopManager * fLoopManagerNon-owning pointer to the RLoopManager at the root of this computation graph.Definition RResultPtr.hxx:174; ROOT::RDF::RResultPtr::fActionPtrstd::shared_ptr< RDFInternal::RActionBase > fActionPtrOwning pointer to the action that will produce this result.Definition RResultPtr.hxx:178; ROOT::RDF::RResultPtr::fObjPtrSPT_t fObjPtrShared pointer encapsulating the wrapped result.Definition RResultPtr.hxx:175; ROOT::RDF::RSampleInfoThis type represents a sample identifier, to be used in conjunction with RDataFrame features such as ...Definition RSampleInfo.hxx:35; ROOT::RDataFrameROOT's RDataFrame offers a modern, high-level interface for analysis of data stored in TTree ,...Definition RDataFrame.hxx:41; bool; F#define F(x, y, z); ROOT::Internal::RDFDefinition RArrowDS.hxx:23; ROOT::Internal::RDF::NotHelperstd::function< bool(ArgTypes...)> NotHelper(ROOT::TypeTraits::TypeList< ArgTypes... >, F &&f)Definition RDFHelpers.hxx:37; ROOT::Internal::RDF::PassAsVecauto PassAsVec(F &&f) -> PassAsVecHelper< std::make_index_sequence< N >, T, F >Definition RDFHelpers.hxx:63; ROOT::Minuit2::GradientParameterSpace::Internal@ Internal; ROOT::RDF::Experimental::VariationsForRResultMap< T > VariationsFor(RResultPtr< T > resPtr)Produce all required systematic variations for the given result.Definition RDFHelpers.hxx:219; ROOT::RDF::Experimental::AddProgressBarvoid AddProgressBar(ROOT::RDF::RNode df)Add ProgressBar to a ROOT::RDF::RNode.Definition RDFHelpers.cxx:373; ROOT::RDF::Notauto Not(F &&f) -> decltype(RDFInternal::NotHelper(Args(), std::forward< F >(f)))Given a callable with signature bool(T1, T2, ...) retur",MatchSource.WIKI,doc/master/RDFHelpers_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx_source.html
https://root.cern/doc/master/RDFHelpers_8hxx_source.html:3635,Modifiability,variab,variables,3635," 68} // namespace RDF; 69} // namespace Internal; 70 ; 71namespace RDF {; 72namespace RDFInternal = ROOT::Internal::RDF;; 73 ; 74// clang-format off; 75/// Given a callable with signature bool(T1, T2, ...) return a callable with same signature that returns the negated result; 76///; 77/// The callable must have one single non-template definition of operator(). This is a limitation with respect to; 78/// std::not_fn, required for interoperability with RDataFrame.; 79// clang-format on; 80template <typename F,; 81 typename Args = typename ROOT::TypeTraits::CallableTraits<std::decay_t<F>>::arg_types_nodecay,; 82 typename Ret = typename ROOT::TypeTraits::CallableTraits<std::decay_t<F>>::ret_type>; 83auto Not(F &&f) -> decltype(RDFInternal::NotHelper(Args(), std::forward<F>(f))); 84{; 85 static_assert(std::is_same<Ret, bool>::value, ""RDF::Not requires a callable that returns a bool."");; 86 return RDFInternal::NotHelper(Args(), std::forward<F>(f));; 87}; 88 ; 89// clang-format off; 90/// PassAsVec is a callable generator that allows passing N variables of type T to a function as a single collection.; 91///; 92/// PassAsVec<N, T>(func) returns a callable that takes N arguments of type T, passes them down to function `func` as; 93/// an initializer list `{t1, t2, t3,..., tN}` and returns whatever f({t1, t2, t3, ..., tN}) returns.; 94///; 95/// Note that for this to work with RDataFrame the type of all columns that the callable is applied to must be exactly T.; 96/// Example usage together with RDataFrame (""varX"" columns must all be `float` variables):; 97/// \code; 98/// bool myVecFunc(std::vector<float> args);; 99/// df.Filter(PassAsVec<3, float>(myVecFunc), {""var1"", ""var2"", ""var3""});; 100/// \endcode; 101// clang-format on; 102template <std::size_t N, typename T, typename F>; 103auto PassAsVec(F &&f) -> RDFInternal::PassAsVecHelper<std::make_index_sequence<N>, T, F>; 104{; 105 return RDFInternal::PassAsVecHelper<std::make_index_sequence<N>, T, F>(std::forward<F>(f));; 106",MatchSource.WIKI,doc/master/RDFHelpers_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx_source.html
https://root.cern/doc/master/RDFHelpers_8hxx_source.html:4140,Modifiability,variab,variables,4140,"s::CallableTraits<std::decay_t<F>>::arg_types_nodecay,; 82 typename Ret = typename ROOT::TypeTraits::CallableTraits<std::decay_t<F>>::ret_type>; 83auto Not(F &&f) -> decltype(RDFInternal::NotHelper(Args(), std::forward<F>(f))); 84{; 85 static_assert(std::is_same<Ret, bool>::value, ""RDF::Not requires a callable that returns a bool."");; 86 return RDFInternal::NotHelper(Args(), std::forward<F>(f));; 87}; 88 ; 89// clang-format off; 90/// PassAsVec is a callable generator that allows passing N variables of type T to a function as a single collection.; 91///; 92/// PassAsVec<N, T>(func) returns a callable that takes N arguments of type T, passes them down to function `func` as; 93/// an initializer list `{t1, t2, t3,..., tN}` and returns whatever f({t1, t2, t3, ..., tN}) returns.; 94///; 95/// Note that for this to work with RDataFrame the type of all columns that the callable is applied to must be exactly T.; 96/// Example usage together with RDataFrame (""varX"" columns must all be `float` variables):; 97/// \code; 98/// bool myVecFunc(std::vector<float> args);; 99/// df.Filter(PassAsVec<3, float>(myVecFunc), {""var1"", ""var2"", ""var3""});; 100/// \endcode; 101// clang-format on; 102template <std::size_t N, typename T, typename F>; 103auto PassAsVec(F &&f) -> RDFInternal::PassAsVecHelper<std::make_index_sequence<N>, T, F>; 104{; 105 return RDFInternal::PassAsVecHelper<std::make_index_sequence<N>, T, F>(std::forward<F>(f));; 106}; 107 ; 108// clang-format off; 109/// Create a graphviz representation of the dataframe computation graph, return it as a string.; 110/// \param[in] node any node of the graph. Called on the head (first) node, it prints the entire graph. Otherwise, only the branch the node belongs to.; 111///; 112/// The output can be displayed with a command akin to `dot -Tpng output.dot > output.png && open output.png`.; 113///; 114/// Note that ""hanging"" Defines, i.e. Defines without downstream nodes, will not be displayed by SaveGraph as they are; 115/// effectiv",MatchSource.WIKI,doc/master/RDFHelpers_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx_source.html
https://root.cern/doc/master/RDFHelpers_8hxx_source.html:11169,Modifiability,inherit,inherits,11169,"3 // populate parts of the computation graph for which we only have ""empty shells"", e.g. RJittedActions and; 224 // RJittedFilters; 225 resPtr.fLoopManager->Jit();; 226 ; 227 std::unique_ptr<RDFInternal::RActionBase> variedAction;; 228 std::vector<std::shared_ptr<T>> variedResults;; 229 ; 230 std::shared_ptr<RDFInternal::RActionBase> nominalAction = resPtr.fActionPtr;; 231 std::vector<std::string> variations = nominalAction->GetVariations();; 232 const auto nVariations = variations.size();; 233 ; 234 if (nVariations > 0) {; 235 // clone the result once for each variation; 236 variedResults.reserve(nVariations);; 237 for (auto i = 0u; i < nVariations; ++i){; 238 // implicitly assuming that T is copiable: this should be the case; 239 // for all result types in use, as they are copied for each slot; 240 variedResults.emplace_back(new T{*resPtr.fObjPtr});; 241 ; 242 // Check if the result's type T inherits from TNamed; 243 if constexpr (std::is_base_of<TNamed, T>::value) {; 244 // Get the current variation name; 245 std::string variationName = variations[i];; 246 // Replace the colon with an underscore; 247 std::replace(variationName.begin(), variationName.end(), ':', '_'); ; 248 // Get a pointer to the corresponding varied result; 249 auto &variedResult = variedResults.back();; 250 // Set the varied result's name to NOMINALNAME_VARIATIONAME; 251 variedResult->SetName((std::string(variedResult->GetName()) + ""_"" + variationName).c_str());; 252 }; 253 }; 254 ; 255 std::vector<void *> typeErasedResults;; 256 typeErasedResults.reserve(variedResults.size());; 257 for (auto &res : variedResults); 258 typeErasedResults.emplace_back(&res);; 259 ; 260 // Create the RVariedAction and inject it in the computation graph.; 261 // This recursively creates all the required varied column readers and upstream nodes of the computation graph.; 262 variedAction = nominalAction->MakeVariedAction(std::move(typeErasedResults));; 263 }; 264 ; 265 return RDFInternal::MakeResultMap<T>(resPtr.fObj",MatchSource.WIKI,doc/master/RDFHelpers_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx_source.html
https://root.cern/doc/master/RDFHelpers_8hxx_source.html:5144,Performance,optimiz,optimized,5144,"lumns must all be `float` variables):; 97/// \code; 98/// bool myVecFunc(std::vector<float> args);; 99/// df.Filter(PassAsVec<3, float>(myVecFunc), {""var1"", ""var2"", ""var3""});; 100/// \endcode; 101// clang-format on; 102template <std::size_t N, typename T, typename F>; 103auto PassAsVec(F &&f) -> RDFInternal::PassAsVecHelper<std::make_index_sequence<N>, T, F>; 104{; 105 return RDFInternal::PassAsVecHelper<std::make_index_sequence<N>, T, F>(std::forward<F>(f));; 106}; 107 ; 108// clang-format off; 109/// Create a graphviz representation of the dataframe computation graph, return it as a string.; 110/// \param[in] node any node of the graph. Called on the head (first) node, it prints the entire graph. Otherwise, only the branch the node belongs to.; 111///; 112/// The output can be displayed with a command akin to `dot -Tpng output.dot > output.png && open output.png`.; 113///; 114/// Note that ""hanging"" Defines, i.e. Defines without downstream nodes, will not be displayed by SaveGraph as they are; 115/// effectively optimized away from the computation graph.; 116///; 117/// Note that SaveGraph is not thread-safe and must not be called concurrently from different threads.; 118// clang-format on; 119template <typename NodeType>; 120std::string SaveGraph(NodeType node); 121{; 122 ROOT::Internal::RDF::GraphDrawing::GraphCreatorHelper helper;; 123 return helper.RepresentGraph(node);; 124}; 125 ; 126// clang-format off; 127/// Create a graphviz representation of the dataframe computation graph, write it to the specified file.; 128/// \param[in] node any node of the graph. Called on the head (first) node, it prints the entire graph. Otherwise, only the branch the node belongs to.; 129/// \param[in] outputFile file where to save the representation.; 130///; 131/// The output can be displayed with a command akin to `dot -Tpng output.dot > output.png && open output.png`.; 132///; 133/// Note that ""hanging"" Defines, i.e. Defines without downstream nodes, will not be displayed by",MatchSource.WIKI,doc/master/RDFHelpers_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx_source.html
https://root.cern/doc/master/RDFHelpers_8hxx_source.html:5265,Performance,concurren,concurrently,5265,"float>(myVecFunc), {""var1"", ""var2"", ""var3""});; 100/// \endcode; 101// clang-format on; 102template <std::size_t N, typename T, typename F>; 103auto PassAsVec(F &&f) -> RDFInternal::PassAsVecHelper<std::make_index_sequence<N>, T, F>; 104{; 105 return RDFInternal::PassAsVecHelper<std::make_index_sequence<N>, T, F>(std::forward<F>(f));; 106}; 107 ; 108// clang-format off; 109/// Create a graphviz representation of the dataframe computation graph, return it as a string.; 110/// \param[in] node any node of the graph. Called on the head (first) node, it prints the entire graph. Otherwise, only the branch the node belongs to.; 111///; 112/// The output can be displayed with a command akin to `dot -Tpng output.dot > output.png && open output.png`.; 113///; 114/// Note that ""hanging"" Defines, i.e. Defines without downstream nodes, will not be displayed by SaveGraph as they are; 115/// effectively optimized away from the computation graph.; 116///; 117/// Note that SaveGraph is not thread-safe and must not be called concurrently from different threads.; 118// clang-format on; 119template <typename NodeType>; 120std::string SaveGraph(NodeType node); 121{; 122 ROOT::Internal::RDF::GraphDrawing::GraphCreatorHelper helper;; 123 return helper.RepresentGraph(node);; 124}; 125 ; 126// clang-format off; 127/// Create a graphviz representation of the dataframe computation graph, write it to the specified file.; 128/// \param[in] node any node of the graph. Called on the head (first) node, it prints the entire graph. Otherwise, only the branch the node belongs to.; 129/// \param[in] outputFile file where to save the representation.; 130///; 131/// The output can be displayed with a command akin to `dot -Tpng output.dot > output.png && open output.png`.; 132///; 133/// Note that ""hanging"" Defines, i.e. Defines without downstream nodes, will not be displayed by SaveGraph as they are; 134/// effectively optimized away from the computation graph.; 135///; 136/// Note that SaveGraph is not t",MatchSource.WIKI,doc/master/RDFHelpers_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx_source.html
https://root.cern/doc/master/RDFHelpers_8hxx_source.html:6157,Performance,optimiz,optimized,6157,"5/// effectively optimized away from the computation graph.; 116///; 117/// Note that SaveGraph is not thread-safe and must not be called concurrently from different threads.; 118// clang-format on; 119template <typename NodeType>; 120std::string SaveGraph(NodeType node); 121{; 122 ROOT::Internal::RDF::GraphDrawing::GraphCreatorHelper helper;; 123 return helper.RepresentGraph(node);; 124}; 125 ; 126// clang-format off; 127/// Create a graphviz representation of the dataframe computation graph, write it to the specified file.; 128/// \param[in] node any node of the graph. Called on the head (first) node, it prints the entire graph. Otherwise, only the branch the node belongs to.; 129/// \param[in] outputFile file where to save the representation.; 130///; 131/// The output can be displayed with a command akin to `dot -Tpng output.dot > output.png && open output.png`.; 132///; 133/// Note that ""hanging"" Defines, i.e. Defines without downstream nodes, will not be displayed by SaveGraph as they are; 134/// effectively optimized away from the computation graph.; 135///; 136/// Note that SaveGraph is not thread-safe and must not be called concurrently from different threads.; 137// clang-format on; 138template <typename NodeType>; 139void SaveGraph(NodeType node, const std::string &outputFile); 140{; 141 ROOT::Internal::RDF::GraphDrawing::GraphCreatorHelper helper;; 142 std::string dotGraph = helper.RepresentGraph(node);; 143 ; 144 std::ofstream out(outputFile);; 145 if (!out.is_open()) {; 146 throw std::runtime_error(""Could not open output file \"""" + outputFile + ""\""for reading"");; 147 }; 148 ; 149 out << dotGraph;; 150 out.close();; 151}; 152 ; 153// clang-format off; 154/// Cast a RDataFrame node to the common type ROOT::RDF::RNode; 155/// \param[in] node Any node of a RDataFrame graph; 156// clang-format on; 157template <typename NodeType>; 158RNode AsRNode(NodeType node); 159{; 160 return node;; 161}; 162 ; 163// clang-format off; 164/// Trigger the event loop of mul",MatchSource.WIKI,doc/master/RDFHelpers_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx_source.html
https://root.cern/doc/master/RDFHelpers_8hxx_source.html:6278,Performance,concurren,concurrently,6278,"e called concurrently from different threads.; 118// clang-format on; 119template <typename NodeType>; 120std::string SaveGraph(NodeType node); 121{; 122 ROOT::Internal::RDF::GraphDrawing::GraphCreatorHelper helper;; 123 return helper.RepresentGraph(node);; 124}; 125 ; 126// clang-format off; 127/// Create a graphviz representation of the dataframe computation graph, write it to the specified file.; 128/// \param[in] node any node of the graph. Called on the head (first) node, it prints the entire graph. Otherwise, only the branch the node belongs to.; 129/// \param[in] outputFile file where to save the representation.; 130///; 131/// The output can be displayed with a command akin to `dot -Tpng output.dot > output.png && open output.png`.; 132///; 133/// Note that ""hanging"" Defines, i.e. Defines without downstream nodes, will not be displayed by SaveGraph as they are; 134/// effectively optimized away from the computation graph.; 135///; 136/// Note that SaveGraph is not thread-safe and must not be called concurrently from different threads.; 137// clang-format on; 138template <typename NodeType>; 139void SaveGraph(NodeType node, const std::string &outputFile); 140{; 141 ROOT::Internal::RDF::GraphDrawing::GraphCreatorHelper helper;; 142 std::string dotGraph = helper.RepresentGraph(node);; 143 ; 144 std::ofstream out(outputFile);; 145 if (!out.is_open()) {; 146 throw std::runtime_error(""Could not open output file \"""" + outputFile + ""\""for reading"");; 147 }; 148 ; 149 out << dotGraph;; 150 out.close();; 151}; 152 ; 153// clang-format off; 154/// Cast a RDataFrame node to the common type ROOT::RDF::RNode; 155/// \param[in] node Any node of a RDataFrame graph; 156// clang-format on; 157template <typename NodeType>; 158RNode AsRNode(NodeType node); 159{; 160 return node;; 161}; 162 ; 163// clang-format off; 164/// Trigger the event loop of multiple RDataFrames concurrently; 165/// \param[in] handles A vector of RResultHandles; 166/// \return The number of distinct comput",MatchSource.WIKI,doc/master/RDFHelpers_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx_source.html
https://root.cern/doc/master/RDFHelpers_8hxx_source.html:7145,Performance,concurren,concurrently,7145,"be displayed by SaveGraph as they are; 134/// effectively optimized away from the computation graph.; 135///; 136/// Note that SaveGraph is not thread-safe and must not be called concurrently from different threads.; 137// clang-format on; 138template <typename NodeType>; 139void SaveGraph(NodeType node, const std::string &outputFile); 140{; 141 ROOT::Internal::RDF::GraphDrawing::GraphCreatorHelper helper;; 142 std::string dotGraph = helper.RepresentGraph(node);; 143 ; 144 std::ofstream out(outputFile);; 145 if (!out.is_open()) {; 146 throw std::runtime_error(""Could not open output file \"""" + outputFile + ""\""for reading"");; 147 }; 148 ; 149 out << dotGraph;; 150 out.close();; 151}; 152 ; 153// clang-format off; 154/// Cast a RDataFrame node to the common type ROOT::RDF::RNode; 155/// \param[in] node Any node of a RDataFrame graph; 156// clang-format on; 157template <typename NodeType>; 158RNode AsRNode(NodeType node); 159{; 160 return node;; 161}; 162 ; 163// clang-format off; 164/// Trigger the event loop of multiple RDataFrames concurrently; 165/// \param[in] handles A vector of RResultHandles; 166/// \return The number of distinct computation graphs that have been processed; 167///; 168/// This function triggers the event loop of all computation graphs which relate to the; 169/// given RResultHandles. The advantage compared to running the event loop implicitly by accessing the; 170/// RResultPtr is that the event loops will run concurrently. Therefore, the overall; 171/// computation of all results is generally more efficient.; 172/// It should be noted that user-defined operations (e.g., Filters and Defines) of the different RDataFrame graphs are assumed to be safe to call concurrently.; 173///; 174/// ~~~{.cpp}; 175/// ROOT::RDataFrame df1(""tree1"", ""file1.root"");; 176/// auto r1 = df1.Histo1D(""var1"");; 177///; 178/// ROOT::RDataFrame df2(""tree2"", ""file2.root"");; 179/// auto r2 = df2.Sum(""var2"");; 180///; 181/// // RResultPtr -> RResultHandle conversion is autom",MatchSource.WIKI,doc/master/RDFHelpers_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx_source.html
https://root.cern/doc/master/RDFHelpers_8hxx_source.html:7554,Performance,concurren,concurrently,7554,"elper helper;; 142 std::string dotGraph = helper.RepresentGraph(node);; 143 ; 144 std::ofstream out(outputFile);; 145 if (!out.is_open()) {; 146 throw std::runtime_error(""Could not open output file \"""" + outputFile + ""\""for reading"");; 147 }; 148 ; 149 out << dotGraph;; 150 out.close();; 151}; 152 ; 153// clang-format off; 154/// Cast a RDataFrame node to the common type ROOT::RDF::RNode; 155/// \param[in] node Any node of a RDataFrame graph; 156// clang-format on; 157template <typename NodeType>; 158RNode AsRNode(NodeType node); 159{; 160 return node;; 161}; 162 ; 163// clang-format off; 164/// Trigger the event loop of multiple RDataFrames concurrently; 165/// \param[in] handles A vector of RResultHandles; 166/// \return The number of distinct computation graphs that have been processed; 167///; 168/// This function triggers the event loop of all computation graphs which relate to the; 169/// given RResultHandles. The advantage compared to running the event loop implicitly by accessing the; 170/// RResultPtr is that the event loops will run concurrently. Therefore, the overall; 171/// computation of all results is generally more efficient.; 172/// It should be noted that user-defined operations (e.g., Filters and Defines) of the different RDataFrame graphs are assumed to be safe to call concurrently.; 173///; 174/// ~~~{.cpp}; 175/// ROOT::RDataFrame df1(""tree1"", ""file1.root"");; 176/// auto r1 = df1.Histo1D(""var1"");; 177///; 178/// ROOT::RDataFrame df2(""tree2"", ""file2.root"");; 179/// auto r2 = df2.Sum(""var2"");; 180///; 181/// // RResultPtr -> RResultHandle conversion is automatic; 182/// ROOT::RDF::RunGraphs({r1, r2});; 183/// ~~~; 184// clang-format on; 185unsigned int RunGraphs(std::vector<RResultHandle> handles);; 186 ; 187namespace Experimental {; 188 ; 189/// \brief Produce all required systematic variations for the given result.; 190/// \param[in] resPtr The result for which variations should be produced.; 191/// \return A \ref ROOT::RDF::Experimental::RResul",MatchSource.WIKI,doc/master/RDFHelpers_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx_source.html
https://root.cern/doc/master/RDFHelpers_8hxx_source.html:7805,Performance,concurren,concurrently,7805,"50 out.close();; 151}; 152 ; 153// clang-format off; 154/// Cast a RDataFrame node to the common type ROOT::RDF::RNode; 155/// \param[in] node Any node of a RDataFrame graph; 156// clang-format on; 157template <typename NodeType>; 158RNode AsRNode(NodeType node); 159{; 160 return node;; 161}; 162 ; 163// clang-format off; 164/// Trigger the event loop of multiple RDataFrames concurrently; 165/// \param[in] handles A vector of RResultHandles; 166/// \return The number of distinct computation graphs that have been processed; 167///; 168/// This function triggers the event loop of all computation graphs which relate to the; 169/// given RResultHandles. The advantage compared to running the event loop implicitly by accessing the; 170/// RResultPtr is that the event loops will run concurrently. Therefore, the overall; 171/// computation of all results is generally more efficient.; 172/// It should be noted that user-defined operations (e.g., Filters and Defines) of the different RDataFrame graphs are assumed to be safe to call concurrently.; 173///; 174/// ~~~{.cpp}; 175/// ROOT::RDataFrame df1(""tree1"", ""file1.root"");; 176/// auto r1 = df1.Histo1D(""var1"");; 177///; 178/// ROOT::RDataFrame df2(""tree2"", ""file2.root"");; 179/// auto r2 = df2.Sum(""var2"");; 180///; 181/// // RResultPtr -> RResultHandle conversion is automatic; 182/// ROOT::RDF::RunGraphs({r1, r2});; 183/// ~~~; 184// clang-format on; 185unsigned int RunGraphs(std::vector<RResultHandle> handles);; 186 ; 187namespace Experimental {; 188 ; 189/// \brief Produce all required systematic variations for the given result.; 190/// \param[in] resPtr The result for which variations should be produced.; 191/// \return A \ref ROOT::RDF::Experimental::RResultMap ""RResultMap"" object with full variation names as strings; 192/// (e.g. ""pt:down"") and the corresponding varied results as values.; 193///; 194/// A given input RResultPtr<T> produces a corresponding RResultMap<T> with a ""nominal""; 195/// key that will return a value",MatchSource.WIKI,doc/master/RDFHelpers_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx_source.html
https://root.cern/doc/master/RDFHelpers_8hxx_source.html:5237,Safety,safe,safe,5237,"float>(myVecFunc), {""var1"", ""var2"", ""var3""});; 100/// \endcode; 101// clang-format on; 102template <std::size_t N, typename T, typename F>; 103auto PassAsVec(F &&f) -> RDFInternal::PassAsVecHelper<std::make_index_sequence<N>, T, F>; 104{; 105 return RDFInternal::PassAsVecHelper<std::make_index_sequence<N>, T, F>(std::forward<F>(f));; 106}; 107 ; 108// clang-format off; 109/// Create a graphviz representation of the dataframe computation graph, return it as a string.; 110/// \param[in] node any node of the graph. Called on the head (first) node, it prints the entire graph. Otherwise, only the branch the node belongs to.; 111///; 112/// The output can be displayed with a command akin to `dot -Tpng output.dot > output.png && open output.png`.; 113///; 114/// Note that ""hanging"" Defines, i.e. Defines without downstream nodes, will not be displayed by SaveGraph as they are; 115/// effectively optimized away from the computation graph.; 116///; 117/// Note that SaveGraph is not thread-safe and must not be called concurrently from different threads.; 118// clang-format on; 119template <typename NodeType>; 120std::string SaveGraph(NodeType node); 121{; 122 ROOT::Internal::RDF::GraphDrawing::GraphCreatorHelper helper;; 123 return helper.RepresentGraph(node);; 124}; 125 ; 126// clang-format off; 127/// Create a graphviz representation of the dataframe computation graph, write it to the specified file.; 128/// \param[in] node any node of the graph. Called on the head (first) node, it prints the entire graph. Otherwise, only the branch the node belongs to.; 129/// \param[in] outputFile file where to save the representation.; 130///; 131/// The output can be displayed with a command akin to `dot -Tpng output.dot > output.png && open output.png`.; 132///; 133/// Note that ""hanging"" Defines, i.e. Defines without downstream nodes, will not be displayed by SaveGraph as they are; 134/// effectively optimized away from the computation graph.; 135///; 136/// Note that SaveGraph is not t",MatchSource.WIKI,doc/master/RDFHelpers_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx_source.html
https://root.cern/doc/master/RDFHelpers_8hxx_source.html:6250,Safety,safe,safe,6250,"e called concurrently from different threads.; 118// clang-format on; 119template <typename NodeType>; 120std::string SaveGraph(NodeType node); 121{; 122 ROOT::Internal::RDF::GraphDrawing::GraphCreatorHelper helper;; 123 return helper.RepresentGraph(node);; 124}; 125 ; 126// clang-format off; 127/// Create a graphviz representation of the dataframe computation graph, write it to the specified file.; 128/// \param[in] node any node of the graph. Called on the head (first) node, it prints the entire graph. Otherwise, only the branch the node belongs to.; 129/// \param[in] outputFile file where to save the representation.; 130///; 131/// The output can be displayed with a command akin to `dot -Tpng output.dot > output.png && open output.png`.; 132///; 133/// Note that ""hanging"" Defines, i.e. Defines without downstream nodes, will not be displayed by SaveGraph as they are; 134/// effectively optimized away from the computation graph.; 135///; 136/// Note that SaveGraph is not thread-safe and must not be called concurrently from different threads.; 137// clang-format on; 138template <typename NodeType>; 139void SaveGraph(NodeType node, const std::string &outputFile); 140{; 141 ROOT::Internal::RDF::GraphDrawing::GraphCreatorHelper helper;; 142 std::string dotGraph = helper.RepresentGraph(node);; 143 ; 144 std::ofstream out(outputFile);; 145 if (!out.is_open()) {; 146 throw std::runtime_error(""Could not open output file \"""" + outputFile + ""\""for reading"");; 147 }; 148 ; 149 out << dotGraph;; 150 out.close();; 151}; 152 ; 153// clang-format off; 154/// Cast a RDataFrame node to the common type ROOT::RDF::RNode; 155/// \param[in] node Any node of a RDataFrame graph; 156// clang-format on; 157template <typename NodeType>; 158RNode AsRNode(NodeType node); 159{; 160 return node;; 161}; 162 ; 163// clang-format off; 164/// Trigger the event loop of multiple RDataFrames concurrently; 165/// \param[in] handles A vector of RResultHandles; 166/// \return The number of distinct comput",MatchSource.WIKI,doc/master/RDFHelpers_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx_source.html
https://root.cern/doc/master/RDFHelpers_8hxx_source.html:7792,Safety,safe,safe,7792,"50 out.close();; 151}; 152 ; 153// clang-format off; 154/// Cast a RDataFrame node to the common type ROOT::RDF::RNode; 155/// \param[in] node Any node of a RDataFrame graph; 156// clang-format on; 157template <typename NodeType>; 158RNode AsRNode(NodeType node); 159{; 160 return node;; 161}; 162 ; 163// clang-format off; 164/// Trigger the event loop of multiple RDataFrames concurrently; 165/// \param[in] handles A vector of RResultHandles; 166/// \return The number of distinct computation graphs that have been processed; 167///; 168/// This function triggers the event loop of all computation graphs which relate to the; 169/// given RResultHandles. The advantage compared to running the event loop implicitly by accessing the; 170/// RResultPtr is that the event loops will run concurrently. Therefore, the overall; 171/// computation of all results is generally more efficient.; 172/// It should be noted that user-defined operations (e.g., Filters and Defines) of the different RDataFrame graphs are assumed to be safe to call concurrently.; 173///; 174/// ~~~{.cpp}; 175/// ROOT::RDataFrame df1(""tree1"", ""file1.root"");; 176/// auto r1 = df1.Histo1D(""var1"");; 177///; 178/// ROOT::RDataFrame df2(""tree2"", ""file2.root"");; 179/// auto r2 = df2.Sum(""var2"");; 180///; 181/// // RResultPtr -> RResultHandle conversion is automatic; 182/// ROOT::RDF::RunGraphs({r1, r2});; 183/// ~~~; 184// clang-format on; 185unsigned int RunGraphs(std::vector<RResultHandle> handles);; 186 ; 187namespace Experimental {; 188 ; 189/// \brief Produce all required systematic variations for the given result.; 190/// \param[in] resPtr The result for which variations should be produced.; 191/// \return A \ref ROOT::RDF::Experimental::RResultMap ""RResultMap"" object with full variation names as strings; 192/// (e.g. ""pt:down"") and the corresponding varied results as values.; 193///; 194/// A given input RResultPtr<T> produces a corresponding RResultMap<T> with a ""nominal""; 195/// key that will return a value",MatchSource.WIKI,doc/master/RDFHelpers_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx_source.html
https://root.cern/doc/master/RDFHelpers_8hxx_source.html:14403,Safety,safe,safe,14403,"uding elapsed time, currently processed file,; 290/// currently processed events, the rate of event processing; 291/// and an estimated remaining time (per file being processed).; 292/// ProgressBar should be added after the dataframe object (df) is created first:; 293/// ~~~{.cpp}; 294/// ROOT::RDataFrame df(""tree"", ""file.root"");; 295/// ROOT::RDF::Experimental::AddProgressBar(df);; 296/// ~~~; 297/// For more details see ROOT::RDF::Experimental::ProgressHelper Class.; 298void AddProgressBar(ROOT::RDataFrame df);; 299 ; 300class ProgressBarAction;; 301 ; 302/// RDF progress helper.; 303/// This class provides callback functions to the RDataFrame. The event statistics; 304/// (including elapsed time, currently processed file, currently processed events, the rate of event processing; 305/// and an estimated remaining time (per file being processed)); 306/// are recorded and printed in the terminal every m events and every n seconds.; 307/// ProgressHelper::operator()(unsigned int, T&) is thread safe, and can be used as a callback in MT mode.; 308/// ProgressBar should be added after creating the dataframe object (df):; 309/// ~~~{.cpp}; 310/// ROOT::RDataFrame df(""tree"", ""file.root"");; 311/// ROOT::RDF::Experimental::AddProgressBar(df);; 312/// ~~~; 313/// alternatively RDataFrame can be cast to an RNode first giving it more flexibility.; 314/// For example, it can be called at any computational node, such as Filter or Define, not only the head node,; 315/// with no change to the ProgressBar function itself:; 316/// ~~~{.cpp}; 317/// ROOT::RDataFrame df(""tree"", ""file.root"");; 318/// auto df_1 = ROOT::RDF::RNode(df.Filter(""x>1""));; 319/// ROOT::RDF::Experimental::AddProgressBar(df_1);; 320/// ~~~; 321class ProgressHelper {; 322private:; 323 double EvtPerSec() const;; 324 std::pair<std::size_t, std::chrono::seconds> RecordEvtCountAndTime();; 325 void PrintStats(std::ostream &stream, std::size_t currentEventCount, std::chrono::seconds totalElapsedSeconds) const;; 326 voi",MatchSource.WIKI,doc/master/RDFHelpers_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx_source.html
https://root.cern/doc/master/RDFHelpers_8hxx_source.html:18363,Safety,safe,safe,18363,"e.; 370 /// The idea is to populate the event entries in the *fSampleNameToEventEntries* map; 371 /// by selecting the greater of the two values:; 372 /// *id.EntryRange().second* which is the upper event entry range of the processed sample; 373 /// and the current value of the event entries in the *fSampleNameToEventEntries* map.; 374 /// In the single threaded case, the two numbers are the same as the entry range corresponds; 375 /// to the number of events in an individual file (each sample is simply a single file).; 376 /// In the multithreaded case, the idea is to accumulate the higher event entry value until; 377 /// the total number of events in a given file is reached.; 378 void registerNewSample(unsigned int /*slot*/, const ROOT::RDF::RSampleInfo &id); 379 {; 380 std::lock_guard<std::mutex> lock(fSampleNameToEventEntriesMutex);; 381 fSampleNameToEventEntries[id.AsString()] =; 382 std::max(id.EntryRange().second, fSampleNameToEventEntries[id.AsString()]);; 383 }; 384 ; 385 /// Thread-safe callback for RDataFrame.; 386 /// It will record elapsed times and event statistics, and print a progress bar every n seconds (set by the; 387 /// fPrintInterval). \param slot Ignored. \param value Ignored.; 388 template <typename T>; 389 void operator()(unsigned int /*slot*/, T &value); 390 {; 391 operator()(value);; 392 }; 393 // clang-format off; 394 /// Thread-safe callback for RDataFrame.; 395 /// It will record elapsed times and event statistics, and print a progress bar every n seconds (set by the fPrintInterval).; 396 /// \param value Ignored.; 397 // clang-format on; 398 template <typename T>; 399 void operator()(T & /*value*/); 400 {; 401 using namespace std::chrono;; 402 // ***************************************************; 403 // Warning: Here, everything needs to be thread safe:; 404 // ***************************************************; 405 fProcessedEvents += fIncrement;; 406 ; 407 // We only print every n seconds.; 408 if (duration_cast<seconds>(system_cl",MatchSource.WIKI,doc/master/RDFHelpers_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx_source.html
https://root.cern/doc/master/RDFHelpers_8hxx_source.html:18735,Safety,safe,safe,18735,"oEventEntries* map.; 374 /// In the single threaded case, the two numbers are the same as the entry range corresponds; 375 /// to the number of events in an individual file (each sample is simply a single file).; 376 /// In the multithreaded case, the idea is to accumulate the higher event entry value until; 377 /// the total number of events in a given file is reached.; 378 void registerNewSample(unsigned int /*slot*/, const ROOT::RDF::RSampleInfo &id); 379 {; 380 std::lock_guard<std::mutex> lock(fSampleNameToEventEntriesMutex);; 381 fSampleNameToEventEntries[id.AsString()] =; 382 std::max(id.EntryRange().second, fSampleNameToEventEntries[id.AsString()]);; 383 }; 384 ; 385 /// Thread-safe callback for RDataFrame.; 386 /// It will record elapsed times and event statistics, and print a progress bar every n seconds (set by the; 387 /// fPrintInterval). \param slot Ignored. \param value Ignored.; 388 template <typename T>; 389 void operator()(unsigned int /*slot*/, T &value); 390 {; 391 operator()(value);; 392 }; 393 // clang-format off; 394 /// Thread-safe callback for RDataFrame.; 395 /// It will record elapsed times and event statistics, and print a progress bar every n seconds (set by the fPrintInterval).; 396 /// \param value Ignored.; 397 // clang-format on; 398 template <typename T>; 399 void operator()(T & /*value*/); 400 {; 401 using namespace std::chrono;; 402 // ***************************************************; 403 // Warning: Here, everything needs to be thread safe:; 404 // ***************************************************; 405 fProcessedEvents += fIncrement;; 406 ; 407 // We only print every n seconds.; 408 if (duration_cast<seconds>(system_clock::now() - fLastPrintTime) < fPrintInterval) {; 409 return;; 410 }; 411 ; 412 // ***************************************************; 413 // Protected by lock from here:; 414 // ***************************************************; 415 if (!fPrintMutex.try_lock()); 416 return;; 417 std::lock_guard<std::mutex> l",MatchSource.WIKI,doc/master/RDFHelpers_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx_source.html
https://root.cern/doc/master/RDFHelpers_8hxx_source.html:19167,Safety,safe,safe,19167,"fo &id); 379 {; 380 std::lock_guard<std::mutex> lock(fSampleNameToEventEntriesMutex);; 381 fSampleNameToEventEntries[id.AsString()] =; 382 std::max(id.EntryRange().second, fSampleNameToEventEntries[id.AsString()]);; 383 }; 384 ; 385 /// Thread-safe callback for RDataFrame.; 386 /// It will record elapsed times and event statistics, and print a progress bar every n seconds (set by the; 387 /// fPrintInterval). \param slot Ignored. \param value Ignored.; 388 template <typename T>; 389 void operator()(unsigned int /*slot*/, T &value); 390 {; 391 operator()(value);; 392 }; 393 // clang-format off; 394 /// Thread-safe callback for RDataFrame.; 395 /// It will record elapsed times and event statistics, and print a progress bar every n seconds (set by the fPrintInterval).; 396 /// \param value Ignored.; 397 // clang-format on; 398 template <typename T>; 399 void operator()(T & /*value*/); 400 {; 401 using namespace std::chrono;; 402 // ***************************************************; 403 // Warning: Here, everything needs to be thread safe:; 404 // ***************************************************; 405 fProcessedEvents += fIncrement;; 406 ; 407 // We only print every n seconds.; 408 if (duration_cast<seconds>(system_clock::now() - fLastPrintTime) < fPrintInterval) {; 409 return;; 410 }; 411 ; 412 // ***************************************************; 413 // Protected by lock from here:; 414 // ***************************************************; 415 if (!fPrintMutex.try_lock()); 416 return;; 417 std::lock_guard<std::mutex> lockGuard(fPrintMutex, std::adopt_lock);; 418 ; 419 std::size_t eventCount;; 420 seconds elapsedSeconds;; 421 std::tie(eventCount, elapsedSeconds) = RecordEvtCountAndTime();; 422 ; 423 if (fIsTTY); 424 std::cout << ""\r"";; 425 ; 426 PrintProgressBar(std::cout, eventCount);; 427 PrintStats(std::cout, eventCount, elapsedSeconds);; 428 ; 429 if (fIsTTY); 430 std::cout << std::flush;; 431 else; 432 std::cout << std::endl;; 433 }; 434 ; 435 std::size_t C",MatchSource.WIKI,doc/master/RDFHelpers_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx_source.html
https://root.cern/doc/master/RDFHelpers_8hxx_source.html:23492,Safety,safe,safe,23492,"FHelpers.hxx:346; ROOT::RDF::Experimental::ProgressHelper::fTotalFilesunsigned int fTotalFilesDefinition RDFHelpers.hxx:344; ROOT::RDF::Experimental::ProgressHelper::RecordEvtCountAndTimestd::pair< std::size_t, std::chrono::seconds > RecordEvtCountAndTime()Record current event counts and time stamp, populate evts/s statistics array.Definition RDFHelpers.cxx:174; ROOT::RDF::Experimental::ProgressHelper::registerNewSamplevoid registerNewSample(unsigned int, const ROOT::RDF::RSampleInfo &id)Register a new sample for completion statistics.Definition RDFHelpers.hxx:378; ROOT::RDF::Experimental::ProgressHelper::fUseShellColoursbool fUseShellColoursDefinition RDFHelpers.hxx:348; ROOT::RDF::Experimental::ProgressHelper::PrintProgressBarvoid PrintProgressBar(std::ostream &stream, std::size_t currentEventCount) constPrint a progress bar of width ProgressHelper::fBarWidth if fGetNEventsOfCurrentFile is known.Definition RDFHelpers.cxx:303; ROOT::RDF::Experimental::ProgressHelper::operator()void operator()(unsigned int, T &value)Thread-safe callback for RDataFrame.Definition RDFHelpers.hxx:389; ROOT::RDF::Experimental::ProgressHelper::PrintStatsvoid PrintStats(std::ostream &stream, std::size_t currentEventCount, std::chrono::seconds totalElapsedSeconds) constPrint event and time statistics.Definition RDFHelpers.cxx:225; ROOT::RDF::Experimental::ProgressHelper::fSampleNameToEventEntriesstd::map< std::string, ULong64_t > fSampleNameToEventEntriesDefinition RDFHelpers.hxx:338; ROOT::RDF::Experimental::ProgressHelper::fTreestd::shared_ptr< TTree > fTreeDefinition RDFHelpers.hxx:350; ROOT::RDF::Experimental::ProgressHelper::fIncrementstd::size_t fIncrementDefinition RDFHelpers.hxx:335; ROOT::RDF::Experimental::ProgressHelper::fLastProcessedEventsstd::size_t fLastProcessedEventsDefinition RDFHelpers.hxx:334; ROOT::RDF::Experimental::ProgressHelper::fSampleNameToEventEntriesMutexstd::mutex fSampleNameToEventEntriesMutexDefinition RDFHelpers.hxx:337; ROOT::RDF::Experimental::ProgressHelp",MatchSource.WIKI,doc/master/RDFHelpers_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx_source.html
https://root.cern/doc/master/RDFHelpers_8hxx_source.html:25646,Safety,safe,safe,25646,"ouble EvtPerSec() constCompute a running mean of events/s.Definition RDFHelpers.cxx:162; ROOT::RDF::Experimental::ProgressHelper::fProcessedEventsstd::atomic< std::size_t > fProcessedEventsDefinition RDFHelpers.hxx:333; ROOT::RDF::Experimental::ProgressHelper::ComputeCurrentFileIdxunsigned int ComputeCurrentFileIdx() constDefinition RDFHelpers.hxx:444; ROOT::RDF::Experimental::ProgressHelper::fLastPrintTimestd::chrono::time_point< std::chrono::system_clock > fLastPrintTimeDefinition RDFHelpers.hxx:330; ROOT::RDF::Experimental::ProgressHelper::fBeginTimestd::chrono::time_point< std::chrono::system_clock > fBeginTimeDefinition RDFHelpers.hxx:329; ROOT::RDF::Experimental::ProgressHelper::PrintStatsFinalvoid PrintStatsFinal(std::ostream &stream, std::chrono::seconds totalElapsedSeconds) constDefinition RDFHelpers.cxx:273; ROOT::RDF::Experimental::ProgressHelper::fPrintIntervalstd::chrono::seconds fPrintIntervalDefinition RDFHelpers.hxx:331; ROOT::RDF::Experimental::ProgressHelper::operator()void operator()(T &)Thread-safe callback for RDataFrame.Definition RDFHelpers.hxx:399; ROOT::RDF::Experimental::ProgressHelper::fBarWidthunsigned int fBarWidthDefinition RDFHelpers.hxx:343; ROOT::RDF::Experimental::ProgressHelper::fEventsPerSecondStatisticsIndexstd::size_t fEventsPerSecondStatisticsIndexDefinition RDFHelpers.hxx:341; ROOT::RDF::Experimental::ProgressHelper::ComputeNEventsSoFarstd::size_t ComputeNEventsSoFar() constDefinition RDFHelpers.hxx:435; ROOT::RDF::Experimental::RResultMapDefinition RResultMap.hxx:98; ROOT::RDF::RInterfaceThe public interface to the RDataFrame federation of classes.Definition RInterface.hxx:113; ROOT::RDF::RResultPtrSmart pointer for the return type of actions.Definition RResultPtr.hxx:119; ROOT::RDF::RResultPtr::fLoopManagerRDFDetail::RLoopManager * fLoopManagerNon-owning pointer to the RLoopManager at the root of this computation graph.Definition RResultPtr.hxx:174; ROOT::RDF::RResultPtr::fActionPtrstd::shared_ptr< RDFInternal::RActionBase >",MatchSource.WIKI,doc/master/RDFHelpers_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx_source.html
https://root.cern/doc/master/RDFHelpers_8hxx_source.html:7488,Security,access,accessing,7488,"elper helper;; 142 std::string dotGraph = helper.RepresentGraph(node);; 143 ; 144 std::ofstream out(outputFile);; 145 if (!out.is_open()) {; 146 throw std::runtime_error(""Could not open output file \"""" + outputFile + ""\""for reading"");; 147 }; 148 ; 149 out << dotGraph;; 150 out.close();; 151}; 152 ; 153// clang-format off; 154/// Cast a RDataFrame node to the common type ROOT::RDF::RNode; 155/// \param[in] node Any node of a RDataFrame graph; 156// clang-format on; 157template <typename NodeType>; 158RNode AsRNode(NodeType node); 159{; 160 return node;; 161}; 162 ; 163// clang-format off; 164/// Trigger the event loop of multiple RDataFrames concurrently; 165/// \param[in] handles A vector of RResultHandles; 166/// \return The number of distinct computation graphs that have been processed; 167///; 168/// This function triggers the event loop of all computation graphs which relate to the; 169/// given RResultHandles. The advantage compared to running the event loop implicitly by accessing the; 170/// RResultPtr is that the event loops will run concurrently. Therefore, the overall; 171/// computation of all results is generally more efficient.; 172/// It should be noted that user-defined operations (e.g., Filters and Defines) of the different RDataFrame graphs are assumed to be safe to call concurrently.; 173///; 174/// ~~~{.cpp}; 175/// ROOT::RDataFrame df1(""tree1"", ""file1.root"");; 176/// auto r1 = df1.Histo1D(""var1"");; 177///; 178/// ROOT::RDataFrame df2(""tree2"", ""file2.root"");; 179/// auto r2 = df2.Sum(""var2"");; 180///; 181/// // RResultPtr -> RResultHandle conversion is automatic; 182/// ROOT::RDF::RunGraphs({r1, r2});; 183/// ~~~; 184// clang-format on; 185unsigned int RunGraphs(std::vector<RResultHandle> handles);; 186 ; 187namespace Experimental {; 188 ; 189/// \brief Produce all required systematic variations for the given result.; 190/// \param[in] resPtr The result for which variations should be produced.; 191/// \return A \ref ROOT::RDF::Experimental::RResul",MatchSource.WIKI,doc/master/RDFHelpers_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx_source.html
https://root.cern/doc/master/RDFHelpers_8hxx_source.html:9060,Security,access,access,9060,"RResultHandle conversion is automatic; 182/// ROOT::RDF::RunGraphs({r1, r2});; 183/// ~~~; 184// clang-format on; 185unsigned int RunGraphs(std::vector<RResultHandle> handles);; 186 ; 187namespace Experimental {; 188 ; 189/// \brief Produce all required systematic variations for the given result.; 190/// \param[in] resPtr The result for which variations should be produced.; 191/// \return A \ref ROOT::RDF::Experimental::RResultMap ""RResultMap"" object with full variation names as strings; 192/// (e.g. ""pt:down"") and the corresponding varied results as values.; 193///; 194/// A given input RResultPtr<T> produces a corresponding RResultMap<T> with a ""nominal""; 195/// key that will return a value identical to the one contained in the original RResultPtr.; 196/// Other keys correspond to the varied values of this result, one for each variation; 197/// that the result depends on.; 198/// VariationsFor does not trigger the event loop. The event loop is only triggered; 199/// upon first access to a valid key, similarly to what happens with RResultPtr.; 200///; 201/// If the result does not depend, directly or indirectly, from any registered systematic variation, the; 202/// returned RResultMap will contain only the ""nominal"" key.; 203///; 204/// See RDataFrame's \ref ROOT::RDF::RInterface::Vary() ""Vary"" method for more information and example usages.; 205///; 206/// \note Currently, producing variations for the results of \ref ROOT::RDF::RInterface::Display() ""Display"",; 207/// \ref ROOT::RDF::RInterface::Report() ""Report"" and \ref ROOT::RDF::RInterface::Snapshot() ""Snapshot""; 208/// actions is not supported.; 209//; 210// An overview of how systematic variations work internally. Given N variations (including the nominal):; 211//; 212// RResultMap owns RVariedAction; 213// N results N action helpers; 214// N previous filters; 215// N*#input_cols column readers; 216//; 217// ...and each RFilter and RDefine knows for what universe it needs to construct column readers (""nomina",MatchSource.WIKI,doc/master/RDFHelpers_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx_source.html
https://root.cern/doc/master/RDFHelpers_8hxx_source.html:11961,Security,inject,inject,11961,"ssuming that T is copiable: this should be the case; 239 // for all result types in use, as they are copied for each slot; 240 variedResults.emplace_back(new T{*resPtr.fObjPtr});; 241 ; 242 // Check if the result's type T inherits from TNamed; 243 if constexpr (std::is_base_of<TNamed, T>::value) {; 244 // Get the current variation name; 245 std::string variationName = variations[i];; 246 // Replace the colon with an underscore; 247 std::replace(variationName.begin(), variationName.end(), ':', '_'); ; 248 // Get a pointer to the corresponding varied result; 249 auto &variedResult = variedResults.back();; 250 // Set the varied result's name to NOMINALNAME_VARIATIONAME; 251 variedResult->SetName((std::string(variedResult->GetName()) + ""_"" + variationName).c_str());; 252 }; 253 }; 254 ; 255 std::vector<void *> typeErasedResults;; 256 typeErasedResults.reserve(variedResults.size());; 257 for (auto &res : variedResults); 258 typeErasedResults.emplace_back(&res);; 259 ; 260 // Create the RVariedAction and inject it in the computation graph.; 261 // This recursively creates all the required varied column readers and upstream nodes of the computation graph.; 262 variedAction = nominalAction->MakeVariedAction(std::move(typeErasedResults));; 263 }; 264 ; 265 return RDFInternal::MakeResultMap<T>(resPtr.fObjPtr, std::move(variedResults), std::move(variations),; 266 *resPtr.fLoopManager, std::move(nominalAction), std::move(variedAction));; 267}; 268 ; 269using SnapshotPtr_t = ROOT::RDF::RResultPtr<ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager, void>>;; 270SnapshotPtr_t VariationsFor(SnapshotPtr_t resPtr);; 271 ; 272/// \brief Add ProgressBar to a ROOT::RDF::RNode; 273/// \param[in] df RDataFrame node at which ProgressBar is called.; 274///; 275/// The ProgressBar can be added not only at the RDataFrame head node, but also at any any computational node,; 276/// such as Filter or Define.; 277/// ###Example usage:; 278/// ~~~{.cpp}; 279/// ROOT::RDataFrame df(""tree"", ""file.r",MatchSource.WIKI,doc/master/RDFHelpers_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx_source.html
https://root.cern/doc/master/RDFHelpers_8hxx_source.html:16675,Usability,progress bar,progress bar,16675,":system_clock::now();; 330 std::chrono::time_point<std::chrono::system_clock> fLastPrintTime = fBeginTime;; 331 std::chrono::seconds fPrintInterval{1};; 332 ; 333 std::atomic<std::size_t> fProcessedEvents{0};; 334 std::size_t fLastProcessedEvents{0};; 335 std::size_t fIncrement;; 336 ; 337 mutable std::mutex fSampleNameToEventEntriesMutex;; 338 std::map<std::string, ULong64_t> fSampleNameToEventEntries; // Filename, events in the file; 339 ; 340 std::array<double, 20> fEventsPerSecondStatistics;; 341 std::size_t fEventsPerSecondStatisticsIndex{0};; 342 ; 343 unsigned int fBarWidth;; 344 unsigned int fTotalFiles;; 345 ; 346 std::mutex fPrintMutex;; 347 bool fIsTTY;; 348 bool fUseShellColours;; 349 ; 350 std::shared_ptr<TTree> fTree{nullptr};; 351 ; 352public:; 353 /// Create a progress helper.; 354 /// \param increment RDF callbacks are called every `n` events. Pass this `n` here.; 355 /// \param totalFiles read total number of files in the RDF.; 356 /// \param progressBarWidth Number of characters the progress bar will occupy.; 357 /// \param printInterval Update every stats every `n` seconds.; 358 /// \param useColors Use shell colour codes to colour the output. Automatically disabled when; 359 /// we are not writing to a tty.; 360 ProgressHelper(std::size_t increment, unsigned int totalFiles = 1, unsigned int progressBarWidth = 40,; 361 unsigned int printInterval = 1, bool useColors = true);; 362 ; 363 ~ProgressHelper() = default;; 364 ; 365 friend class ProgressBarAction;; 366 ; 367 /// Register a new sample for completion statistics.; 368 /// \see ROOT::RDF::RInterface::DefinePerSample().; 369 /// The *id.AsString()* refers to the name of the currently processed file.; 370 /// The idea is to populate the event entries in the *fSampleNameToEventEntries* map; 371 /// by selecting the greater of the two values:; 372 /// *id.EntryRange().second* which is the upper event entry range of the processed sample; 373 /// and the current value of the event entries in the *f",MatchSource.WIKI,doc/master/RDFHelpers_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx_source.html
https://root.cern/doc/master/RDFHelpers_8hxx_source.html:17858,Usability,simpl,simply,17858," useColors Use shell colour codes to colour the output. Automatically disabled when; 359 /// we are not writing to a tty.; 360 ProgressHelper(std::size_t increment, unsigned int totalFiles = 1, unsigned int progressBarWidth = 40,; 361 unsigned int printInterval = 1, bool useColors = true);; 362 ; 363 ~ProgressHelper() = default;; 364 ; 365 friend class ProgressBarAction;; 366 ; 367 /// Register a new sample for completion statistics.; 368 /// \see ROOT::RDF::RInterface::DefinePerSample().; 369 /// The *id.AsString()* refers to the name of the currently processed file.; 370 /// The idea is to populate the event entries in the *fSampleNameToEventEntries* map; 371 /// by selecting the greater of the two values:; 372 /// *id.EntryRange().second* which is the upper event entry range of the processed sample; 373 /// and the current value of the event entries in the *fSampleNameToEventEntries* map.; 374 /// In the single threaded case, the two numbers are the same as the entry range corresponds; 375 /// to the number of events in an individual file (each sample is simply a single file).; 376 /// In the multithreaded case, the idea is to accumulate the higher event entry value until; 377 /// the total number of events in a given file is reached.; 378 void registerNewSample(unsigned int /*slot*/, const ROOT::RDF::RSampleInfo &id); 379 {; 380 std::lock_guard<std::mutex> lock(fSampleNameToEventEntriesMutex);; 381 fSampleNameToEventEntries[id.AsString()] =; 382 std::max(id.EntryRange().second, fSampleNameToEventEntries[id.AsString()]);; 383 }; 384 ; 385 /// Thread-safe callback for RDataFrame.; 386 /// It will record elapsed times and event statistics, and print a progress bar every n seconds (set by the; 387 /// fPrintInterval). \param slot Ignored. \param value Ignored.; 388 template <typename T>; 389 void operator()(unsigned int /*slot*/, T &value); 390 {; 391 operator()(value);; 392 }; 393 // clang-format off; 394 /// Thread-safe callback for RDataFrame.; 395 /// It will re",MatchSource.WIKI,doc/master/RDFHelpers_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx_source.html
https://root.cern/doc/master/RDFHelpers_8hxx_source.html:18465,Usability,progress bar,progress bar,18465,"selecting the greater of the two values:; 372 /// *id.EntryRange().second* which is the upper event entry range of the processed sample; 373 /// and the current value of the event entries in the *fSampleNameToEventEntries* map.; 374 /// In the single threaded case, the two numbers are the same as the entry range corresponds; 375 /// to the number of events in an individual file (each sample is simply a single file).; 376 /// In the multithreaded case, the idea is to accumulate the higher event entry value until; 377 /// the total number of events in a given file is reached.; 378 void registerNewSample(unsigned int /*slot*/, const ROOT::RDF::RSampleInfo &id); 379 {; 380 std::lock_guard<std::mutex> lock(fSampleNameToEventEntriesMutex);; 381 fSampleNameToEventEntries[id.AsString()] =; 382 std::max(id.EntryRange().second, fSampleNameToEventEntries[id.AsString()]);; 383 }; 384 ; 385 /// Thread-safe callback for RDataFrame.; 386 /// It will record elapsed times and event statistics, and print a progress bar every n seconds (set by the; 387 /// fPrintInterval). \param slot Ignored. \param value Ignored.; 388 template <typename T>; 389 void operator()(unsigned int /*slot*/, T &value); 390 {; 391 operator()(value);; 392 }; 393 // clang-format off; 394 /// Thread-safe callback for RDataFrame.; 395 /// It will record elapsed times and event statistics, and print a progress bar every n seconds (set by the fPrintInterval).; 396 /// \param value Ignored.; 397 // clang-format on; 398 template <typename T>; 399 void operator()(T & /*value*/); 400 {; 401 using namespace std::chrono;; 402 // ***************************************************; 403 // Warning: Here, everything needs to be thread safe:; 404 // ***************************************************; 405 fProcessedEvents += fIncrement;; 406 ; 407 // We only print every n seconds.; 408 if (duration_cast<seconds>(system_clock::now() - fLastPrintTime) < fPrintInterval) {; 409 return;; 410 }; 411 ; 412 // ***********************",MatchSource.WIKI,doc/master/RDFHelpers_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx_source.html
https://root.cern/doc/master/RDFHelpers_8hxx_source.html:18837,Usability,progress bar,progress bar,18837,"ividual file (each sample is simply a single file).; 376 /// In the multithreaded case, the idea is to accumulate the higher event entry value until; 377 /// the total number of events in a given file is reached.; 378 void registerNewSample(unsigned int /*slot*/, const ROOT::RDF::RSampleInfo &id); 379 {; 380 std::lock_guard<std::mutex> lock(fSampleNameToEventEntriesMutex);; 381 fSampleNameToEventEntries[id.AsString()] =; 382 std::max(id.EntryRange().second, fSampleNameToEventEntries[id.AsString()]);; 383 }; 384 ; 385 /// Thread-safe callback for RDataFrame.; 386 /// It will record elapsed times and event statistics, and print a progress bar every n seconds (set by the; 387 /// fPrintInterval). \param slot Ignored. \param value Ignored.; 388 template <typename T>; 389 void operator()(unsigned int /*slot*/, T &value); 390 {; 391 operator()(value);; 392 }; 393 // clang-format off; 394 /// Thread-safe callback for RDataFrame.; 395 /// It will record elapsed times and event statistics, and print a progress bar every n seconds (set by the fPrintInterval).; 396 /// \param value Ignored.; 397 // clang-format on; 398 template <typename T>; 399 void operator()(T & /*value*/); 400 {; 401 using namespace std::chrono;; 402 // ***************************************************; 403 // Warning: Here, everything needs to be thread safe:; 404 // ***************************************************; 405 fProcessedEvents += fIncrement;; 406 ; 407 // We only print every n seconds.; 408 if (duration_cast<seconds>(system_clock::now() - fLastPrintTime) < fPrintInterval) {; 409 return;; 410 }; 411 ; 412 // ***************************************************; 413 // Protected by lock from here:; 414 // ***************************************************; 415 if (!fPrintMutex.try_lock()); 416 return;; 417 std::lock_guard<std::mutex> lockGuard(fPrintMutex, std::adopt_lock);; 418 ; 419 std::size_t eventCount;; 420 seconds elapsedSeconds;; 421 std::tie(eventCount, elapsedSeconds) = RecordEvtCou",MatchSource.WIKI,doc/master/RDFHelpers_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx_source.html
https://root.cern/doc/master/RDFHelpers_8hxx_source.html:23279,Usability,progress bar,progress bar,23279,"Helper~ProgressHelper()=default; ROOT::RDF::Experimental::ProgressHelper::fIsTTYbool fIsTTYDefinition RDFHelpers.hxx:347; ROOT::RDF::Experimental::ProgressHelper::fPrintMutexstd::mutex fPrintMutexDefinition RDFHelpers.hxx:346; ROOT::RDF::Experimental::ProgressHelper::fTotalFilesunsigned int fTotalFilesDefinition RDFHelpers.hxx:344; ROOT::RDF::Experimental::ProgressHelper::RecordEvtCountAndTimestd::pair< std::size_t, std::chrono::seconds > RecordEvtCountAndTime()Record current event counts and time stamp, populate evts/s statistics array.Definition RDFHelpers.cxx:174; ROOT::RDF::Experimental::ProgressHelper::registerNewSamplevoid registerNewSample(unsigned int, const ROOT::RDF::RSampleInfo &id)Register a new sample for completion statistics.Definition RDFHelpers.hxx:378; ROOT::RDF::Experimental::ProgressHelper::fUseShellColoursbool fUseShellColoursDefinition RDFHelpers.hxx:348; ROOT::RDF::Experimental::ProgressHelper::PrintProgressBarvoid PrintProgressBar(std::ostream &stream, std::size_t currentEventCount) constPrint a progress bar of width ProgressHelper::fBarWidth if fGetNEventsOfCurrentFile is known.Definition RDFHelpers.cxx:303; ROOT::RDF::Experimental::ProgressHelper::operator()void operator()(unsigned int, T &value)Thread-safe callback for RDataFrame.Definition RDFHelpers.hxx:389; ROOT::RDF::Experimental::ProgressHelper::PrintStatsvoid PrintStats(std::ostream &stream, std::size_t currentEventCount, std::chrono::seconds totalElapsedSeconds) constPrint event and time statistics.Definition RDFHelpers.cxx:225; ROOT::RDF::Experimental::ProgressHelper::fSampleNameToEventEntriesstd::map< std::string, ULong64_t > fSampleNameToEventEntriesDefinition RDFHelpers.hxx:338; ROOT::RDF::Experimental::ProgressHelper::fTreestd::shared_ptr< TTree > fTreeDefinition RDFHelpers.hxx:350; ROOT::RDF::Experimental::ProgressHelper::fIncrementstd::size_t fIncrementDefinition RDFHelpers.hxx:335; ROOT::RDF::Experimental::ProgressHelper::fLastProcessedEventsstd::size_t fLastProcessedEventsDe",MatchSource.WIKI,doc/master/RDFHelpers_8hxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFHelpers_8hxx_source.html
https://root.cern/doc/master/RDFUtils_8cxx_source.html:4086,Availability,failure,failure,4086,"},; 87 {""double"", typeid(double)},; 88 {""Double_t"", typeid(double)},; 89 {""float"", typeid(float)},; 90 {""Float_t"", typeid(float)},; 91 {""long long"", typeid(long long)},; 92 {""long long int"", typeid(long long)},; 93 {""Long64_t"", typeid(long long)},; 94 {""unsigned long long"", typeid(unsigned long long)},; 95 {""unsigned long long int"", typeid(unsigned long long)},; 96 {""ULong64_t"", typeid(unsigned long long)},; 97 {""bool"", typeid(bool)},; 98 {""Bool_t"", typeid(bool)}};; 99 ; 100 if (auto it = typeName2TypeIDMap.find(name); it != typeName2TypeIDMap.end()); 101 return it->second.get();; 102 ; 103 if (auto c = TClass::GetClass(name.c_str())) {; 104 if (!c->GetTypeInfo()) {; 105 throw std::runtime_error(""Cannot extract type_info of type "" + name + ""."");; 106 }; 107 return *c->GetTypeInfo();; 108 }; 109 ; 110 throw std::runtime_error(""Cannot extract type_info of type "" + name + ""."");; 111}; 112 ; 113/// Returns the name of a type starting from its type_info; 114/// An empty string is returned in case of failure; 115/// References and pointers are not supported since those cannot be stored in; 116/// columns.; 117/// Note that this function will take a lock and may be a potential source of; 118/// contention in multithreaded execution.; 119std::string TypeID2TypeName(const std::type_info &id); 120{; 121 const static std::unordered_map<TypeInfoRef, std::string, TypeInfoRefHash, TypeInfoRefEqualComp> typeID2TypeNameMap{; 122 {typeid(char), ""char""}, {typeid(unsigned char), ""unsigned char""},; 123 {typeid(int), ""int""}, {typeid(unsigned int), ""unsigned int""},; 124 {typeid(short), ""short""}, {typeid(unsigned short), ""unsigned short""},; 125 {typeid(long), ""long""}, {typeid(unsigned long), ""unsigned long""},; 126 {typeid(double), ""double""}, {typeid(float), ""float""},; 127 {typeid(Long64_t), ""Long64_t""}, {typeid(ULong64_t), ""ULong64_t""},; 128 {typeid(bool), ""bool""}};; 129 ; 130 if (auto it = typeID2TypeNameMap.find(id); it != typeID2TypeNameMap.end()); 131 return it->second;; 132 ; 133 if ",MatchSource.WIKI,doc/master/RDFUtils_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFUtils_8cxx_source.html
https://root.cern/doc/master/RDFUtils_8cxx_source.html:13365,Availability,error,error,13365,"e(const std::vector<std::string> &columnNames); 315{; 316 auto newColNames = columnNames;; 317 for (auto &col : newColNames) {; 318 const auto dotPos = col.find('.');; 319 if (dotPos != std::string::npos && dotPos != col.size() - 1 && dotPos != 0u) {; 320 auto oldName = col;; 321 std::replace(col.begin(), col.end(), '.', '_');; 322 if (std::find(columnNames.begin(), columnNames.end(), col) != columnNames.end()); 323 throw std::runtime_error(""Column "" + oldName + "" would be written as "" + col +; 324 "" but this column already exists. Please use Alias to select a new name for "" +; 325 oldName);; 326 Info(""Snapshot"", ""Column %s will be saved as %s"", oldName.c_str(), col.c_str());; 327 }; 328 }; 329 ; 330 return newColNames;; 331}; 332 ; 333void InterpreterDeclare(const std::string &code); 334{; 335 R__LOG_DEBUG(10, RDFLogChannel()) << ""Declaring the following code to cling:\n\n"" << code << '\n';; 336 ; 337 if (!gInterpreter->Declare(code.c_str())) {; 338 const auto msg =; 339 ""\nRDataFrame: An error occurred during just-in-time compilation. The lines above might indicate the cause of ""; 340 ""the crash\n All RDF objects that have not run an event loop yet should be considered in an invalid state.\n"";; 341 throw std::runtime_error(msg);; 342 }; 343}; 344 ; 345Long64_t InterpreterCalc(const std::string &code, const std::string &context); 346{; 347 R__LOG_DEBUG(10, RDFLogChannel()) << ""Jitting and executing the following code:\n\n"" << code << '\n';; 348 ; 349 TInterpreter::EErrorCode errorCode(TInterpreter::kNoError); // storage for cling errors; 350 ; 351 auto callCalc = [&errorCode, &context](const std::string &codeSlice) {; 352 gInterpreter->Calc(codeSlice.c_str(), &errorCode);; 353 if (errorCode != TInterpreter::EErrorCode::kNoError) {; 354 std::string msg = ""\nAn error occurred during just-in-time compilation"";; 355 if (!context.empty()); 356 msg += "" in "" + context;; 357 msg +=; 358 "". The lines above might indicate the cause of the crash\nAll RDF objects that have no",MatchSource.WIKI,doc/master/RDFUtils_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFUtils_8cxx_source.html
https://root.cern/doc/master/RDFUtils_8cxx_source.html:13861,Availability,error,errorCode,13861,"""Column "" + oldName + "" would be written as "" + col +; 324 "" but this column already exists. Please use Alias to select a new name for "" +; 325 oldName);; 326 Info(""Snapshot"", ""Column %s will be saved as %s"", oldName.c_str(), col.c_str());; 327 }; 328 }; 329 ; 330 return newColNames;; 331}; 332 ; 333void InterpreterDeclare(const std::string &code); 334{; 335 R__LOG_DEBUG(10, RDFLogChannel()) << ""Declaring the following code to cling:\n\n"" << code << '\n';; 336 ; 337 if (!gInterpreter->Declare(code.c_str())) {; 338 const auto msg =; 339 ""\nRDataFrame: An error occurred during just-in-time compilation. The lines above might indicate the cause of ""; 340 ""the crash\n All RDF objects that have not run an event loop yet should be considered in an invalid state.\n"";; 341 throw std::runtime_error(msg);; 342 }; 343}; 344 ; 345Long64_t InterpreterCalc(const std::string &code, const std::string &context); 346{; 347 R__LOG_DEBUG(10, RDFLogChannel()) << ""Jitting and executing the following code:\n\n"" << code << '\n';; 348 ; 349 TInterpreter::EErrorCode errorCode(TInterpreter::kNoError); // storage for cling errors; 350 ; 351 auto callCalc = [&errorCode, &context](const std::string &codeSlice) {; 352 gInterpreter->Calc(codeSlice.c_str(), &errorCode);; 353 if (errorCode != TInterpreter::EErrorCode::kNoError) {; 354 std::string msg = ""\nAn error occurred during just-in-time compilation"";; 355 if (!context.empty()); 356 msg += "" in "" + context;; 357 msg +=; 358 "". The lines above might indicate the cause of the crash\nAll RDF objects that have not run their event ""; 359 ""loop yet should be considered in an invalid state.\n"";; 360 throw std::runtime_error(msg);; 361 }; 362 };; 363 ; 364 // Call Calc every 1000 newlines in order to avoid jitting a very large function body, which is slow:; 365 // see https://github.com/root-project/root/issues/9312 and https://github.com/root-project/root/issues/7604; 366 std::size_t substr_start = 0;; 367 std::size_t substr_end = 0;; 368 while (substr",MatchSource.WIKI,doc/master/RDFUtils_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFUtils_8cxx_source.html
https://root.cern/doc/master/RDFUtils_8cxx_source.html:13917,Availability,error,errors,13917,"""Column "" + oldName + "" would be written as "" + col +; 324 "" but this column already exists. Please use Alias to select a new name for "" +; 325 oldName);; 326 Info(""Snapshot"", ""Column %s will be saved as %s"", oldName.c_str(), col.c_str());; 327 }; 328 }; 329 ; 330 return newColNames;; 331}; 332 ; 333void InterpreterDeclare(const std::string &code); 334{; 335 R__LOG_DEBUG(10, RDFLogChannel()) << ""Declaring the following code to cling:\n\n"" << code << '\n';; 336 ; 337 if (!gInterpreter->Declare(code.c_str())) {; 338 const auto msg =; 339 ""\nRDataFrame: An error occurred during just-in-time compilation. The lines above might indicate the cause of ""; 340 ""the crash\n All RDF objects that have not run an event loop yet should be considered in an invalid state.\n"";; 341 throw std::runtime_error(msg);; 342 }; 343}; 344 ; 345Long64_t InterpreterCalc(const std::string &code, const std::string &context); 346{; 347 R__LOG_DEBUG(10, RDFLogChannel()) << ""Jitting and executing the following code:\n\n"" << code << '\n';; 348 ; 349 TInterpreter::EErrorCode errorCode(TInterpreter::kNoError); // storage for cling errors; 350 ; 351 auto callCalc = [&errorCode, &context](const std::string &codeSlice) {; 352 gInterpreter->Calc(codeSlice.c_str(), &errorCode);; 353 if (errorCode != TInterpreter::EErrorCode::kNoError) {; 354 std::string msg = ""\nAn error occurred during just-in-time compilation"";; 355 if (!context.empty()); 356 msg += "" in "" + context;; 357 msg +=; 358 "". The lines above might indicate the cause of the crash\nAll RDF objects that have not run their event ""; 359 ""loop yet should be considered in an invalid state.\n"";; 360 throw std::runtime_error(msg);; 361 }; 362 };; 363 ; 364 // Call Calc every 1000 newlines in order to avoid jitting a very large function body, which is slow:; 365 // see https://github.com/root-project/root/issues/9312 and https://github.com/root-project/root/issues/7604; 366 std::size_t substr_start = 0;; 367 std::size_t substr_end = 0;; 368 while (substr",MatchSource.WIKI,doc/master/RDFUtils_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFUtils_8cxx_source.html
https://root.cern/doc/master/RDFUtils_8cxx_source.html:13953,Availability,error,errorCode,13953,"""Column "" + oldName + "" would be written as "" + col +; 324 "" but this column already exists. Please use Alias to select a new name for "" +; 325 oldName);; 326 Info(""Snapshot"", ""Column %s will be saved as %s"", oldName.c_str(), col.c_str());; 327 }; 328 }; 329 ; 330 return newColNames;; 331}; 332 ; 333void InterpreterDeclare(const std::string &code); 334{; 335 R__LOG_DEBUG(10, RDFLogChannel()) << ""Declaring the following code to cling:\n\n"" << code << '\n';; 336 ; 337 if (!gInterpreter->Declare(code.c_str())) {; 338 const auto msg =; 339 ""\nRDataFrame: An error occurred during just-in-time compilation. The lines above might indicate the cause of ""; 340 ""the crash\n All RDF objects that have not run an event loop yet should be considered in an invalid state.\n"";; 341 throw std::runtime_error(msg);; 342 }; 343}; 344 ; 345Long64_t InterpreterCalc(const std::string &code, const std::string &context); 346{; 347 R__LOG_DEBUG(10, RDFLogChannel()) << ""Jitting and executing the following code:\n\n"" << code << '\n';; 348 ; 349 TInterpreter::EErrorCode errorCode(TInterpreter::kNoError); // storage for cling errors; 350 ; 351 auto callCalc = [&errorCode, &context](const std::string &codeSlice) {; 352 gInterpreter->Calc(codeSlice.c_str(), &errorCode);; 353 if (errorCode != TInterpreter::EErrorCode::kNoError) {; 354 std::string msg = ""\nAn error occurred during just-in-time compilation"";; 355 if (!context.empty()); 356 msg += "" in "" + context;; 357 msg +=; 358 "". The lines above might indicate the cause of the crash\nAll RDF objects that have not run their event ""; 359 ""loop yet should be considered in an invalid state.\n"";; 360 throw std::runtime_error(msg);; 361 }; 362 };; 363 ; 364 // Call Calc every 1000 newlines in order to avoid jitting a very large function body, which is slow:; 365 // see https://github.com/root-project/root/issues/9312 and https://github.com/root-project/root/issues/7604; 366 std::size_t substr_start = 0;; 367 std::size_t substr_end = 0;; 368 while (substr",MatchSource.WIKI,doc/master/RDFUtils_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFUtils_8cxx_source.html
https://root.cern/doc/master/RDFUtils_8cxx_source.html:14050,Availability,error,errorCode,14050,"(const std::string &code); 334{; 335 R__LOG_DEBUG(10, RDFLogChannel()) << ""Declaring the following code to cling:\n\n"" << code << '\n';; 336 ; 337 if (!gInterpreter->Declare(code.c_str())) {; 338 const auto msg =; 339 ""\nRDataFrame: An error occurred during just-in-time compilation. The lines above might indicate the cause of ""; 340 ""the crash\n All RDF objects that have not run an event loop yet should be considered in an invalid state.\n"";; 341 throw std::runtime_error(msg);; 342 }; 343}; 344 ; 345Long64_t InterpreterCalc(const std::string &code, const std::string &context); 346{; 347 R__LOG_DEBUG(10, RDFLogChannel()) << ""Jitting and executing the following code:\n\n"" << code << '\n';; 348 ; 349 TInterpreter::EErrorCode errorCode(TInterpreter::kNoError); // storage for cling errors; 350 ; 351 auto callCalc = [&errorCode, &context](const std::string &codeSlice) {; 352 gInterpreter->Calc(codeSlice.c_str(), &errorCode);; 353 if (errorCode != TInterpreter::EErrorCode::kNoError) {; 354 std::string msg = ""\nAn error occurred during just-in-time compilation"";; 355 if (!context.empty()); 356 msg += "" in "" + context;; 357 msg +=; 358 "". The lines above might indicate the cause of the crash\nAll RDF objects that have not run their event ""; 359 ""loop yet should be considered in an invalid state.\n"";; 360 throw std::runtime_error(msg);; 361 }; 362 };; 363 ; 364 // Call Calc every 1000 newlines in order to avoid jitting a very large function body, which is slow:; 365 // see https://github.com/root-project/root/issues/9312 and https://github.com/root-project/root/issues/7604; 366 std::size_t substr_start = 0;; 367 std::size_t substr_end = 0;; 368 while (substr_end != std::string::npos && substr_start != code.size() - 1) {; 369 for (std::size_t i = 0u; i < 1000u && substr_end != std::string::npos; ++i) {; 370 substr_end = code.find('\n', substr_end + 1);; 371 }; 372 const std::string subs = code.substr(substr_start, substr_end - substr_start);; 373 substr_start = substr_end;; 37",MatchSource.WIKI,doc/master/RDFUtils_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFUtils_8cxx_source.html
https://root.cern/doc/master/RDFUtils_8cxx_source.html:14071,Availability,error,errorCode,14071,"(const std::string &code); 334{; 335 R__LOG_DEBUG(10, RDFLogChannel()) << ""Declaring the following code to cling:\n\n"" << code << '\n';; 336 ; 337 if (!gInterpreter->Declare(code.c_str())) {; 338 const auto msg =; 339 ""\nRDataFrame: An error occurred during just-in-time compilation. The lines above might indicate the cause of ""; 340 ""the crash\n All RDF objects that have not run an event loop yet should be considered in an invalid state.\n"";; 341 throw std::runtime_error(msg);; 342 }; 343}; 344 ; 345Long64_t InterpreterCalc(const std::string &code, const std::string &context); 346{; 347 R__LOG_DEBUG(10, RDFLogChannel()) << ""Jitting and executing the following code:\n\n"" << code << '\n';; 348 ; 349 TInterpreter::EErrorCode errorCode(TInterpreter::kNoError); // storage for cling errors; 350 ; 351 auto callCalc = [&errorCode, &context](const std::string &codeSlice) {; 352 gInterpreter->Calc(codeSlice.c_str(), &errorCode);; 353 if (errorCode != TInterpreter::EErrorCode::kNoError) {; 354 std::string msg = ""\nAn error occurred during just-in-time compilation"";; 355 if (!context.empty()); 356 msg += "" in "" + context;; 357 msg +=; 358 "". The lines above might indicate the cause of the crash\nAll RDF objects that have not run their event ""; 359 ""loop yet should be considered in an invalid state.\n"";; 360 throw std::runtime_error(msg);; 361 }; 362 };; 363 ; 364 // Call Calc every 1000 newlines in order to avoid jitting a very large function body, which is slow:; 365 // see https://github.com/root-project/root/issues/9312 and https://github.com/root-project/root/issues/7604; 366 std::size_t substr_start = 0;; 367 std::size_t substr_end = 0;; 368 while (substr_end != std::string::npos && substr_start != code.size() - 1) {; 369 for (std::size_t i = 0u; i < 1000u && substr_end != std::string::npos; ++i) {; 370 substr_end = code.find('\n', substr_end + 1);; 371 }; 372 const std::string subs = code.substr(substr_start, substr_end - substr_start);; 373 substr_start = substr_end;; 37",MatchSource.WIKI,doc/master/RDFUtils_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFUtils_8cxx_source.html
https://root.cern/doc/master/RDFUtils_8cxx_source.html:14151,Availability,error,error,14151,"(const std::string &code); 334{; 335 R__LOG_DEBUG(10, RDFLogChannel()) << ""Declaring the following code to cling:\n\n"" << code << '\n';; 336 ; 337 if (!gInterpreter->Declare(code.c_str())) {; 338 const auto msg =; 339 ""\nRDataFrame: An error occurred during just-in-time compilation. The lines above might indicate the cause of ""; 340 ""the crash\n All RDF objects that have not run an event loop yet should be considered in an invalid state.\n"";; 341 throw std::runtime_error(msg);; 342 }; 343}; 344 ; 345Long64_t InterpreterCalc(const std::string &code, const std::string &context); 346{; 347 R__LOG_DEBUG(10, RDFLogChannel()) << ""Jitting and executing the following code:\n\n"" << code << '\n';; 348 ; 349 TInterpreter::EErrorCode errorCode(TInterpreter::kNoError); // storage for cling errors; 350 ; 351 auto callCalc = [&errorCode, &context](const std::string &codeSlice) {; 352 gInterpreter->Calc(codeSlice.c_str(), &errorCode);; 353 if (errorCode != TInterpreter::EErrorCode::kNoError) {; 354 std::string msg = ""\nAn error occurred during just-in-time compilation"";; 355 if (!context.empty()); 356 msg += "" in "" + context;; 357 msg +=; 358 "". The lines above might indicate the cause of the crash\nAll RDF objects that have not run their event ""; 359 ""loop yet should be considered in an invalid state.\n"";; 360 throw std::runtime_error(msg);; 361 }; 362 };; 363 ; 364 // Call Calc every 1000 newlines in order to avoid jitting a very large function body, which is slow:; 365 // see https://github.com/root-project/root/issues/9312 and https://github.com/root-project/root/issues/7604; 366 std::size_t substr_start = 0;; 367 std::size_t substr_end = 0;; 368 while (substr_end != std::string::npos && substr_start != code.size() - 1) {; 369 for (std::size_t i = 0u; i < 1000u && substr_end != std::string::npos; ++i) {; 370 substr_end = code.find('\n', substr_end + 1);; 371 }; 372 const std::string subs = code.substr(substr_start, substr_end - substr_start);; 373 substr_start = substr_end;; 37",MatchSource.WIKI,doc/master/RDFUtils_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFUtils_8cxx_source.html
https://root.cern/doc/master/RDFUtils_8cxx_source.html:18178,Availability,avail,available,18178,": column \"""" + colName + ""\"" is being used as "";; 421 if (tName.empty()) {; 422 errMsg += requestedType.name();; 423 errMsg += "" (extracted from type info)"";; 424 } else {; 425 errMsg += tName;; 426 }; 427 errMsg += "" but the Define or Vary node advertises it as "";; 428 if (colTypeName.empty()) {; 429 auto &id = colType;; 430 errMsg += id.name();; 431 errMsg += "" (extracted from type info)"";; 432 } else {; 433 errMsg += colTypeName;; 434 }; 435 throw std::runtime_error(errMsg);; 436 }; 437}; 438 ; 439bool IsStrInVec(const std::string &str, const std::vector<std::string> &vec); 440{; 441 return std::find(vec.cbegin(), vec.cend(), str) != vec.cend();; 442}; 443 ; 444auto RStringCache::Insert(const std::string &string) -> decltype(fStrings)::const_iterator; 445{; 446 {; 447 std::shared_lock l{fMutex};; 448 if (auto it = fStrings.find(string); it != fStrings.end()); 449 return it;; 450 }; 451 ; 452 // TODO: Would be nicer to use a lock upgrade strategy a-la TVirtualRWMutex; 453 // but that is unfortunately not usable outside the already available ROOT mutexes; 454 std::unique_lock l{fMutex};; 455 if (auto it = fStrings.find(string); it != fStrings.end()); 456 return it;; 457 ; 458 return fStrings.insert(string).first;; 459}; 460} // end NS RDF; 461} // end NS Internal; 462} // end NS ROOT; RDataSource.hxx; RDefineBase.hxx; RLogger.hxx; R__LOG_DEBUG#define R__LOG_DEBUG(DEBUGLEVEL,...)Definition RLogger.hxx:365; RLoopManager.hxx; b#define b(i)Definition RSha256.hxx:100; c#define c(i)Definition RSha256.hxx:101; RtypesCore.h; Long64_tlong long Long64_tDefinition RtypesCore.h:69; ULong64_tunsigned long long ULong64_tDefinition RtypesCore.h:70; TBranchElement.h; TBranch.h; TClassEdit.h; TClassRef.h; TClass.h; TError.h; Infovoid Info(const char *location, const char *msgfmt,...)Use this function for informational messages.Definition TError.cxx:218; lengthOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAli",MatchSource.WIKI,doc/master/RDFUtils_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFUtils_8cxx_source.html
https://root.cern/doc/master/RDFUtils_8cxx_source.html:24082,Availability,failure,failure,24082,"ogChannel & RDFLogChannel()Definition RDFUtils.cxx:37; ROOT::Internal::RDF::ReplaceDotWithUnderscorestd::vector< std::string > ReplaceDotWithUnderscore(const std::vector< std::string > &columnNames)Replace occurrences of '.Definition RDFUtils.cxx:314; ROOT::Internal::RDF::TypeName2TypeIDconst std::type_info & TypeName2TypeID(const std::string &name)Return the type_info associated to a name.Definition RDFUtils.cxx:62; ROOT::Internal::RDF::GetNSlotsunsigned int GetNSlots()Definition RDFUtils.cxx:301; ROOT::Internal::RDF::ComposeRVecTypeNamestd::string ComposeRVecTypeName(const std::string &valueType)Definition RDFUtils.cxx:140; ROOT::Internal::RDF::GetLeafTypeNamestd::string GetLeafTypeName(TLeaf *leaf, const std::string &colName)Definition RDFUtils.cxx:145; ROOT::Internal::RDF::TypeName2ROOTTypeNamechar TypeName2ROOTTypeName(const std::string &b)Convert type name (e.g.Definition RDFUtils.cxx:259; ROOT::Internal::RDF::TypeID2TypeNamestd::string TypeID2TypeName(const std::type_info &id)Returns the name of a type starting from its type_info An empty string is returned in case of failure...Definition RDFUtils.cxx:119; ROOT::Internal::RDF::IsStrInVecbool IsStrInVec(const std::string &str, const std::vector< std::string > &vec)Definition RDFUtils.cxx:439; ROOT::Internal::RDF::GetColumnWidthunsigned int GetColumnWidth(const std::vector< std::string > &names, const unsigned int minColumnSpace=8u)Get optimal column width for printing a table given the names and the desired minimal space between c...Definition RDFUtils.cxx:390; ROOT::Internal::RDF::GetBranchOrLeafTypeNamestd::string GetBranchOrLeafTypeName(TTree &t, const std::string &colName)Return the typename of object colName stored in t, if any.Definition RDFUtils.cxx:172; ROOT::Internal::RDF::InterpreterCalcLong64_t InterpreterCalc(const std::string &code, const std::string &context="""")Jit code in the interpreter with TInterpreter::Calc, throw in case of errors.Definition RDFUtils.cxx:345; ROOT::Internal::RDF::ColumnName",MatchSource.WIKI,doc/master/RDFUtils_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFUtils_8cxx_source.html
https://root.cern/doc/master/RDFUtils_8cxx_source.html:24923,Availability,error,errors,24923,"st std::string &b)Convert type name (e.g.Definition RDFUtils.cxx:259; ROOT::Internal::RDF::TypeID2TypeNamestd::string TypeID2TypeName(const std::type_info &id)Returns the name of a type starting from its type_info An empty string is returned in case of failure...Definition RDFUtils.cxx:119; ROOT::Internal::RDF::IsStrInVecbool IsStrInVec(const std::string &str, const std::vector< std::string > &vec)Definition RDFUtils.cxx:439; ROOT::Internal::RDF::GetColumnWidthunsigned int GetColumnWidth(const std::vector< std::string > &names, const unsigned int minColumnSpace=8u)Get optimal column width for printing a table given the names and the desired minimal space between c...Definition RDFUtils.cxx:390; ROOT::Internal::RDF::GetBranchOrLeafTypeNamestd::string GetBranchOrLeafTypeName(TTree &t, const std::string &colName)Return the typename of object colName stored in t, if any.Definition RDFUtils.cxx:172; ROOT::Internal::RDF::InterpreterCalcLong64_t InterpreterCalc(const std::string &code, const std::string &context="""")Jit code in the interpreter with TInterpreter::Calc, throw in case of errors.Definition RDFUtils.cxx:345; ROOT::Internal::RDF::ColumnName2ColumnTypeNamestd::string ColumnName2ColumnTypeName(const std::string &colName, TTree *, RDataSource *, RDefineBase *, bool vector2RVec=true)Return a string containing the type of the given branch.Definition RDFUtils.cxx:229; ROOT::Internal::RDF::CheckReaderTypeMatchesvoid CheckReaderTypeMatches(const std::type_info &colType, const std::type_info &requestedType, const std::string &colName)Definition RDFUtils.cxx:402; ROOT::Internal::RDF::IsInternalColumnbool IsInternalColumn(std::string_view colName)Whether custom column with name colName is an ""internal"" column such as rdfentry_ or rdfslot_.Definition RDFUtils.cxx:381; ROOT::Internal::RDF::InterpreterDeclarevoid InterpreterDeclare(const std::string &code)Declare code in the interpreter via the TInterpreter::Declare method, throw in case of errors.Definition RDFUtils.cxx:333; ",MatchSource.WIKI,doc/master/RDFUtils_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFUtils_8cxx_source.html
https://root.cern/doc/master/RDFUtils_8cxx_source.html:25793,Availability,error,errors,25793,"ny.Definition RDFUtils.cxx:172; ROOT::Internal::RDF::InterpreterCalcLong64_t InterpreterCalc(const std::string &code, const std::string &context="""")Jit code in the interpreter with TInterpreter::Calc, throw in case of errors.Definition RDFUtils.cxx:345; ROOT::Internal::RDF::ColumnName2ColumnTypeNamestd::string ColumnName2ColumnTypeName(const std::string &colName, TTree *, RDataSource *, RDefineBase *, bool vector2RVec=true)Return a string containing the type of the given branch.Definition RDFUtils.cxx:229; ROOT::Internal::RDF::CheckReaderTypeMatchesvoid CheckReaderTypeMatches(const std::type_info &colType, const std::type_info &requestedType, const std::string &colName)Definition RDFUtils.cxx:402; ROOT::Internal::RDF::IsInternalColumnbool IsInternalColumn(std::string_view colName)Whether custom column with name colName is an ""internal"" column such as rdfentry_ or rdfslot_.Definition RDFUtils.cxx:381; ROOT::Internal::RDF::InterpreterDeclarevoid InterpreterDeclare(const std::string &code)Declare code in the interpreter via the TInterpreter::Declare method, throw in case of errors.Definition RDFUtils.cxx:333; ROOT::Minuit2::GradientParameterSpace::Internal@ Internal; ROOT::RDFDefinition RArrowDS.hxx:28; ROOTtbb::task_arena is an alias of tbb::interface7::task_arena, which doesn't allow to forward declare tb...Definition EExecutionPolicy.hxx:4; ROOT::IsImplicitMTEnabledBool_t IsImplicitMTEnabled()Returns true if the implicit multi-threading in ROOT is enabled.Definition TROOT.cxx:570; ROOT::GetThreadPoolSizeUInt_t GetThreadPoolSize()Returns the size of ROOT's thread pool.Definition TROOT.cxx:577; ROOT::kSTLvector@ kSTLvectorDefinition ESTLType.h:30; TClassEdit::IsSTLContROOT::ESTLType IsSTLCont(std::string_view type)type : type name: vector<list<classA,allocator>,allocator> result: 0 : not stl container code of cont...Definition TClassEdit.cxx:1378; TClassEdit::GetSplitint GetSplit(const char *type, std::vector< std::string > &output, int &nestedLoc, EModType mode=TClas",MatchSource.WIKI,doc/master/RDFUtils_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFUtils_8cxx_source.html
https://root.cern/doc/master/RDFUtils_8cxx_source.html:18075,Deployability,upgrade,upgrade,18075,": column \"""" + colName + ""\"" is being used as "";; 421 if (tName.empty()) {; 422 errMsg += requestedType.name();; 423 errMsg += "" (extracted from type info)"";; 424 } else {; 425 errMsg += tName;; 426 }; 427 errMsg += "" but the Define or Vary node advertises it as "";; 428 if (colTypeName.empty()) {; 429 auto &id = colType;; 430 errMsg += id.name();; 431 errMsg += "" (extracted from type info)"";; 432 } else {; 433 errMsg += colTypeName;; 434 }; 435 throw std::runtime_error(errMsg);; 436 }; 437}; 438 ; 439bool IsStrInVec(const std::string &str, const std::vector<std::string> &vec); 440{; 441 return std::find(vec.cbegin(), vec.cend(), str) != vec.cend();; 442}; 443 ; 444auto RStringCache::Insert(const std::string &string) -> decltype(fStrings)::const_iterator; 445{; 446 {; 447 std::shared_lock l{fMutex};; 448 if (auto it = fStrings.find(string); it != fStrings.end()); 449 return it;; 450 }; 451 ; 452 // TODO: Would be nicer to use a lock upgrade strategy a-la TVirtualRWMutex; 453 // but that is unfortunately not usable outside the already available ROOT mutexes; 454 std::unique_lock l{fMutex};; 455 if (auto it = fStrings.find(string); it != fStrings.end()); 456 return it;; 457 ; 458 return fStrings.insert(string).first;; 459}; 460} // end NS RDF; 461} // end NS Internal; 462} // end NS ROOT; RDataSource.hxx; RDefineBase.hxx; RLogger.hxx; R__LOG_DEBUG#define R__LOG_DEBUG(DEBUGLEVEL,...)Definition RLogger.hxx:365; RLoopManager.hxx; b#define b(i)Definition RSha256.hxx:100; c#define c(i)Definition RSha256.hxx:101; RtypesCore.h; Long64_tlong long Long64_tDefinition RtypesCore.h:69; ULong64_tunsigned long long ULong64_tDefinition RtypesCore.h:70; TBranchElement.h; TBranch.h; TClassEdit.h; TClassRef.h; TClass.h; TError.h; Infovoid Info(const char *location, const char *msgfmt,...)Use this function for informational messages.Definition TError.cxx:218; lengthOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAli",MatchSource.WIKI,doc/master/RDFUtils_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFUtils_8cxx_source.html
https://root.cern/doc/master/RDFUtils_8cxx_source.html:20205,Deployability,configurat,configuration,20205,"butes_t Float_t Float_t Float_t Int_t Int_t UInt_t UInt_t Rectangle_t Int_t Int_t Window_t TString Int_t GCValues_t GetPrimarySelectionOwner GetDisplay GetScreen GetColormap GetNativeEvent const char const char dpyName wid window const char font_name cursor keysym reg const char only_if_exist regb h Point_t winding char text const char depth char const char Int_t count const char ColorStruct_t color const char Pixmap_t Pixmap_t PictureAttributes_t attr const char char ret_data h unsigned char height h lengthDefinition TGWin32VirtualXProxy.cxx:245; namechar name[80]Definition TGX11.cxx:110; TInterpreter.h; gInterpreter#define gInterpreterDefinition TInterpreter.h:573; TLeaf.h; operator()TRObject operator()(const T1 &t1) constDefinition TRFunctionImport__oprtr.h:14; TROOT.h; TTree.h; Utils.hxx; ROOT::Detail::RDF::RDefineBaseDefinition RDefineBase.hxx:39; ROOT::Detail::RDF::RDefineBase::GetTypeNamestd::string GetTypeName() constDefinition RDefineBase.cxx:47; ROOT::Experimental::RLogChannelA log configuration for a channel, e.g.Definition RLogger.hxx:101; ROOT::Internal::RDF::RStringCache::Insertauto Insert(const std::string &string) -> decltype(fStrings)::const_iteratorInserts the input string in the cache and returns an iterator to the cached string.Definition RDFUtils.cxx:444; ROOT::RDF::RDataSourceRDataSource defines an API that RDataFrame can use to read arbitrary data formats.Definition RDataSource.hxx:109; ROOT::RDF::RDataSource::HasColumnvirtual bool HasColumn(std::string_view colName) const =0Checks if the dataset has a certain column.; ROOT::RDF::RDataSource::GetTypeNamevirtual std::string GetTypeName(std::string_view colName) const =0Type of a column as a string, e.g.; TBranchElementA Branch for the case of an object.Definition TBranchElement.h:39; TBranchElement::GetClassvirtual TClass * GetClass() constDefinition TBranchElement.h:187; TBranch::Classstatic TClass * Class(); TClassRefTClassRef is used to implement a permanent reference to a TClass object.Defi",MatchSource.WIKI,doc/master/RDFUtils_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFUtils_8cxx_source.html
https://root.cern/doc/master/RDFUtils_8cxx_source.html:12128,Integrability,message,message,12128,"274 {""unsigned short int"", 's'},; 275 {""UShort_t"", 's'},; 276 {""long"", 'G'},; 277 {""long int"", 'G'},; 278 {""Long_t"", 'G'},; 279 {""unsigned long"", 'g'},; 280 {""unsigned long int"", 'g'},; 281 {""ULong_t"", 'g'},; 282 {""double"", 'D'},; 283 {""Double_t"", 'D'},; 284 {""float"", 'F'},; 285 {""Float_t"", 'F'},; 286 {""long long"", 'L'},; 287 {""long long int"", 'L'},; 288 {""Long64_t"", 'L'},; 289 {""unsigned long long"", 'l'},; 290 {""unsigned long long int"", 'l'},; 291 {""ULong64_t"", 'l'},; 292 {""bool"", 'O'},; 293 {""Bool_t"", 'O'}};; 294 ; 295 if (auto it = typeName2ROOTTypeNameMap.find(b); it != typeName2ROOTTypeNameMap.end()); 296 return it->second;; 297 ; 298 return ' ';; 299}; 300 ; 301unsigned int GetNSlots(); 302{; 303 unsigned int nSlots = 1;; 304#ifdef R__USE_IMT; 305 if (ROOT::IsImplicitMTEnabled()); 306 nSlots = ROOT::GetThreadPoolSize();; 307#endif // R__USE_IMT; 308 return nSlots;; 309}; 310 ; 311/// Replace occurrences of '.' with '_' in each string passed as argument.; 312/// An Info message is printed when this happens. Dots at the end of the string are not replaced.; 313/// An exception is thrown in case the resulting set of strings would contain duplicates.; 314std::vector<std::string> ReplaceDotWithUnderscore(const std::vector<std::string> &columnNames); 315{; 316 auto newColNames = columnNames;; 317 for (auto &col : newColNames) {; 318 const auto dotPos = col.find('.');; 319 if (dotPos != std::string::npos && dotPos != col.size() - 1 && dotPos != 0u) {; 320 auto oldName = col;; 321 std::replace(col.begin(), col.end(), '.', '_');; 322 if (std::find(columnNames.begin(), columnNames.end(), col) != columnNames.end()); 323 throw std::runtime_error(""Column "" + oldName + "" would be written as "" + col +; 324 "" but this column already exists. Please use Alias to select a new name for "" +; 325 oldName);; 326 Info(""Snapshot"", ""Column %s will be saved as %s"", oldName.c_str(), col.c_str());; 327 }; 328 }; 329 ; 330 return newColNames;; 331}; 332 ; 333void InterpreterDeclare(const st",MatchSource.WIKI,doc/master/RDFUtils_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFUtils_8cxx_source.html
https://root.cern/doc/master/RDFUtils_8cxx_source.html:18963,Integrability,message,messages,18963,"uto it = fStrings.find(string); it != fStrings.end()); 449 return it;; 450 }; 451 ; 452 // TODO: Would be nicer to use a lock upgrade strategy a-la TVirtualRWMutex; 453 // but that is unfortunately not usable outside the already available ROOT mutexes; 454 std::unique_lock l{fMutex};; 455 if (auto it = fStrings.find(string); it != fStrings.end()); 456 return it;; 457 ; 458 return fStrings.insert(string).first;; 459}; 460} // end NS RDF; 461} // end NS Internal; 462} // end NS ROOT; RDataSource.hxx; RDefineBase.hxx; RLogger.hxx; R__LOG_DEBUG#define R__LOG_DEBUG(DEBUGLEVEL,...)Definition RLogger.hxx:365; RLoopManager.hxx; b#define b(i)Definition RSha256.hxx:100; c#define c(i)Definition RSha256.hxx:101; RtypesCore.h; Long64_tlong long Long64_tDefinition RtypesCore.h:69; ULong64_tunsigned long long ULong64_tDefinition RtypesCore.h:70; TBranchElement.h; TBranch.h; TClassEdit.h; TClassRef.h; TClass.h; TError.h; Infovoid Info(const char *location, const char *msgfmt,...)Use this function for informational messages.Definition TError.cxx:218; lengthOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void char Point_t Rectangle_t WindowAttributes_t Float_t Float_t Float_t Int_t Int_t UInt_t UInt_t Rectangle_t Int_t Int_t Window_t TString Int_t GCValues_t GetPrimarySelectionOwner GetDisplay GetScreen GetColormap GetNativeEvent const char const char dpyName wid window const char font_name cursor keysym reg const char only_if_exist regb h Point_t winding char text const char depth char const char Int_t count const char ColorStruct_t color const char Pixmap_t Pixmap_t PictureAttributes_t attr const char char ret_data h unsigned char height h lengthDefinition TGWin32VirtualXProxy.cxx:245; namechar name[80]Definition TGX11.cxx:110; TInterpreter.h; gInterpreter#define gInterpreterDefinition TInterpreter.h:573; TLeaf.h; operator()TRObject operator()(const T1 &t1) constDefinition TRFunc",MatchSource.WIKI,doc/master/RDFUtils_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFUtils_8cxx_source.html
https://root.cern/doc/master/RDFUtils_8cxx_source.html:5707,Modifiability,variab,variable-sized,5707,"""}, {typeid(ULong64_t), ""ULong64_t""},; 128 {typeid(bool), ""bool""}};; 129 ; 130 if (auto it = typeID2TypeNameMap.find(id); it != typeID2TypeNameMap.end()); 131 return it->second;; 132 ; 133 if (auto c = TClass::GetClass(id)) {; 134 return c->GetName();; 135 }; 136 ; 137 return """";; 138}; 139 ; 140std::string ComposeRVecTypeName(const std::string &valueType); 141{; 142 return ""ROOT::VecOps::RVec<"" + valueType + "">"";; 143}; 144 ; 145std::string GetLeafTypeName(TLeaf *leaf, const std::string &colName); 146{; 147 const char *colTypeCStr = leaf->GetTypeName();; 148 std::string colType = colTypeCStr == nullptr ? """" : colTypeCStr;; 149 if (colType.empty()); 150 throw std::runtime_error(""Could not deduce type of leaf "" + colName);; 151 if (leaf->GetLeafCount() != nullptr && leaf->GetLenStatic() == 1) {; 152 // this is a variable-sized array; 153 colType = ComposeRVecTypeName(colType);; 154 } else if (leaf->GetLeafCount() == nullptr && leaf->GetLenStatic() > 1) {; 155 // this is a fixed-sized array (we do not differentiate between variable- and fixed-sized arrays); 156 colType = ComposeRVecTypeName(colType);; 157 } else if (leaf->GetLeafCount() != nullptr && leaf->GetLenStatic() > 1) {; 158 // we do not know how to deal with this branch; 159 throw std::runtime_error(""TTree leaf "" + colName +; 160 "" has both a leaf count and a static length. This is not supported."");; 161 }; 162 ; 163 return colType;; 164}; 165 ; 166/// Return the typename of object colName stored in t, if any. Return an empty string if colName is not in t.; 167/// Supported cases:; 168/// - leaves corresponding to single values, variable- and fixed-length arrays, with following syntax:; 169/// - ""leafname"", as long as TTree::GetLeaf resolves it; 170/// - ""b1.b2...leafname"", as long as TTree::GetLeaf(""b1.b2...."", ""leafname"") resolves it; 171/// - TBranchElements, as long as TTree::GetBranch resolves their names; 172std::string GetBranchOrLeafTypeName(TTree &t, const std::string &colName); 173{; 174 // look for",MatchSource.WIKI,doc/master/RDFUtils_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFUtils_8cxx_source.html
https://root.cern/doc/master/RDFUtils_8cxx_source.html:5921,Modifiability,variab,variable,5921,"""}, {typeid(ULong64_t), ""ULong64_t""},; 128 {typeid(bool), ""bool""}};; 129 ; 130 if (auto it = typeID2TypeNameMap.find(id); it != typeID2TypeNameMap.end()); 131 return it->second;; 132 ; 133 if (auto c = TClass::GetClass(id)) {; 134 return c->GetName();; 135 }; 136 ; 137 return """";; 138}; 139 ; 140std::string ComposeRVecTypeName(const std::string &valueType); 141{; 142 return ""ROOT::VecOps::RVec<"" + valueType + "">"";; 143}; 144 ; 145std::string GetLeafTypeName(TLeaf *leaf, const std::string &colName); 146{; 147 const char *colTypeCStr = leaf->GetTypeName();; 148 std::string colType = colTypeCStr == nullptr ? """" : colTypeCStr;; 149 if (colType.empty()); 150 throw std::runtime_error(""Could not deduce type of leaf "" + colName);; 151 if (leaf->GetLeafCount() != nullptr && leaf->GetLenStatic() == 1) {; 152 // this is a variable-sized array; 153 colType = ComposeRVecTypeName(colType);; 154 } else if (leaf->GetLeafCount() == nullptr && leaf->GetLenStatic() > 1) {; 155 // this is a fixed-sized array (we do not differentiate between variable- and fixed-sized arrays); 156 colType = ComposeRVecTypeName(colType);; 157 } else if (leaf->GetLeafCount() != nullptr && leaf->GetLenStatic() > 1) {; 158 // we do not know how to deal with this branch; 159 throw std::runtime_error(""TTree leaf "" + colName +; 160 "" has both a leaf count and a static length. This is not supported."");; 161 }; 162 ; 163 return colType;; 164}; 165 ; 166/// Return the typename of object colName stored in t, if any. Return an empty string if colName is not in t.; 167/// Supported cases:; 168/// - leaves corresponding to single values, variable- and fixed-length arrays, with following syntax:; 169/// - ""leafname"", as long as TTree::GetLeaf resolves it; 170/// - ""b1.b2...leafname"", as long as TTree::GetLeaf(""b1.b2...."", ""leafname"") resolves it; 171/// - TBranchElements, as long as TTree::GetBranch resolves their names; 172std::string GetBranchOrLeafTypeName(TTree &t, const std::string &colName); 173{; 174 // look for",MatchSource.WIKI,doc/master/RDFUtils_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFUtils_8cxx_source.html
https://root.cern/doc/master/RDFUtils_8cxx_source.html:6497,Modifiability,variab,variable,6497,"olType.empty()); 150 throw std::runtime_error(""Could not deduce type of leaf "" + colName);; 151 if (leaf->GetLeafCount() != nullptr && leaf->GetLenStatic() == 1) {; 152 // this is a variable-sized array; 153 colType = ComposeRVecTypeName(colType);; 154 } else if (leaf->GetLeafCount() == nullptr && leaf->GetLenStatic() > 1) {; 155 // this is a fixed-sized array (we do not differentiate between variable- and fixed-sized arrays); 156 colType = ComposeRVecTypeName(colType);; 157 } else if (leaf->GetLeafCount() != nullptr && leaf->GetLenStatic() > 1) {; 158 // we do not know how to deal with this branch; 159 throw std::runtime_error(""TTree leaf "" + colName +; 160 "" has both a leaf count and a static length. This is not supported."");; 161 }; 162 ; 163 return colType;; 164}; 165 ; 166/// Return the typename of object colName stored in t, if any. Return an empty string if colName is not in t.; 167/// Supported cases:; 168/// - leaves corresponding to single values, variable- and fixed-length arrays, with following syntax:; 169/// - ""leafname"", as long as TTree::GetLeaf resolves it; 170/// - ""b1.b2...leafname"", as long as TTree::GetLeaf(""b1.b2...."", ""leafname"") resolves it; 171/// - TBranchElements, as long as TTree::GetBranch resolves their names; 172std::string GetBranchOrLeafTypeName(TTree &t, const std::string &colName); 173{; 174 // look for TLeaf either with GetLeaf(colName) or with GetLeaf(branchName, leafName) (splitting on last dot); 175 auto *leaf = t.GetLeaf(colName.c_str());; 176 if (!leaf); 177 leaf = t.FindLeaf(colName.c_str()); // try harder; 178 if (!leaf) {; 179 // try splitting branchname and leafname; 180 const auto dotPos = colName.find_last_of('.');; 181 const auto hasDot = dotPos != std::string::npos;; 182 if (hasDot) {; 183 const auto branchName = colName.substr(0, dotPos);; 184 const auto leafName = colName.substr(dotPos + 1);; 185 leaf = t.GetLeaf(branchName.c_str(), leafName.c_str());; 186 }; 187 }; 188 if (leaf); 189 return GetLeafTypeName(leaf, std",MatchSource.WIKI,doc/master/RDFUtils_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFUtils_8cxx_source.html
https://root.cern/doc/master/RDFUtils_8cxx_source.html:9362,Modifiability,variab,variable-sized,9362,"Class = beMom->GetClass();; 208 if (beMomClass && 0 == std::strcmp(""TClonesArray"", beMomClass->GetName())); 209 return be->GetTypeName();; 210 }; 211 return be->GetClassName();; 212 }; 213 } else if (branch->IsA() == TBranch::Class() && branch->GetListOfLeaves()->GetEntriesUnsafe() == 1) {; 214 // normal branch (not a TBranchElement): if it has only one leaf, we pick the type of the leaf:; 215 // RDF and TTreeReader allow referring to branch.leaf as just branch if branch has only one leaf; 216 leaf = static_cast<TLeaf *>(branch->GetListOfLeaves()->UncheckedAt(0));; 217 return GetLeafTypeName(leaf, std::string(leaf->GetFullName()));; 218 }; 219 }; 220 ; 221 // we could not find a branch or a leaf called colName; 222 return std::string();; 223}; 224 ; 225/// Return a string containing the type of the given branch. Works both with real TTree branches and with temporary; 226/// column created by Define. Throws if type name deduction fails.; 227/// Note that for fixed- or variable-sized c-style arrays the returned type name will be RVec<T>.; 228/// vector2RVec specifies whether typename 'std::vector<T>' should be converted to 'RVec<T>' or returned as is; 229std::string ColumnName2ColumnTypeName(const std::string &colName, TTree *tree, RDataSource *ds, RDefineBase *define,; 230 bool vector2RVec); 231{; 232 std::string colType;; 233 ; 234 // must check defines first: we want Redefines to have precedence over everything else; 235 if (define) {; 236 colType = define->GetTypeName();; 237 } else if (ds && ds->HasColumn(colName)) {; 238 colType = ds->GetTypeName(colName);; 239 } else if (tree) {; 240 colType = GetBranchOrLeafTypeName(*tree, colName);; 241 if (vector2RVec && TClassEdit::IsSTLCont(colType) == ROOT::ESTLType::kSTLvector) {; 242 std::vector<std::string> split;; 243 int dummy;; 244 TClassEdit::GetSplit(colType.c_str(), split, dummy);; 245 auto &valueType = split[1];; 246 colType = ComposeRVecTypeName(valueType);; 247 }; 248 }; 249 ; 250 if (colType.empty()); 251 thr",MatchSource.WIKI,doc/master/RDFUtils_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFUtils_8cxx_source.html
https://root.cern/doc/master/RDFUtils_8cxx_source.html:16729,Modifiability,inherit,inheritedType,16729,"th;; 397 }; 398 columnWidth = (columnWidth / minColumnSpace + 1) * minColumnSpace;; 399 return columnWidth;; 400}; 401 ; 402void CheckReaderTypeMatches(const std::type_info &colType, const std::type_info &requestedType,; 403 const std::string &colName); 404{; 405 // We want to explicitly support the reading of bools as unsigned char, as; 406 // this is quite common to circumvent the std::vector<bool> specialization.; 407 const bool explicitlySupported = (colType == typeid(bool) && requestedType == typeid(unsigned char)) ? true : false;; 408 ; 409 // Here we compare names and not typeinfos since they may come from two different contexts: a compiled; 410 // and a jitted one.; 411 const auto diffTypes = (0 != std::strcmp(colType.name(), requestedType.name()));; 412 auto inheritedType = [&]() {; 413 auto colTClass = TClass::GetClass(colType);; 414 return colTClass && colTClass->InheritsFrom(TClass::GetClass(requestedType));; 415 };; 416 ; 417 if (!explicitlySupported && diffTypes && !inheritedType()) {; 418 const auto tName = TypeID2TypeName(requestedType);; 419 const auto colTypeName = TypeID2TypeName(colType);; 420 std::string errMsg = ""RDataFrame: type mismatch: column \"""" + colName + ""\"" is being used as "";; 421 if (tName.empty()) {; 422 errMsg += requestedType.name();; 423 errMsg += "" (extracted from type info)"";; 424 } else {; 425 errMsg += tName;; 426 }; 427 errMsg += "" but the Define or Vary node advertises it as "";; 428 if (colTypeName.empty()) {; 429 auto &id = colType;; 430 errMsg += id.name();; 431 errMsg += "" (extracted from type info)"";; 432 } else {; 433 errMsg += colTypeName;; 434 }; 435 throw std::runtime_error(errMsg);; 436 }; 437}; 438 ; 439bool IsStrInVec(const std::string &str, const std::vector<std::string> &vec); 440{; 441 return std::find(vec.cbegin(), vec.cend(), str) != vec.cend();; 442}; 443 ; 444auto RStringCache::Insert(const std::string &string) -> decltype(fStrings)::const_iterator; 445{; 446 {; 447 std::shared_lock l{fMutex};; 448 if (aut",MatchSource.WIKI,doc/master/RDFUtils_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFUtils_8cxx_source.html
https://root.cern/doc/master/RDFUtils_8cxx_source.html:16946,Modifiability,inherit,inheritedType,16946,"th;; 397 }; 398 columnWidth = (columnWidth / minColumnSpace + 1) * minColumnSpace;; 399 return columnWidth;; 400}; 401 ; 402void CheckReaderTypeMatches(const std::type_info &colType, const std::type_info &requestedType,; 403 const std::string &colName); 404{; 405 // We want to explicitly support the reading of bools as unsigned char, as; 406 // this is quite common to circumvent the std::vector<bool> specialization.; 407 const bool explicitlySupported = (colType == typeid(bool) && requestedType == typeid(unsigned char)) ? true : false;; 408 ; 409 // Here we compare names and not typeinfos since they may come from two different contexts: a compiled; 410 // and a jitted one.; 411 const auto diffTypes = (0 != std::strcmp(colType.name(), requestedType.name()));; 412 auto inheritedType = [&]() {; 413 auto colTClass = TClass::GetClass(colType);; 414 return colTClass && colTClass->InheritsFrom(TClass::GetClass(requestedType));; 415 };; 416 ; 417 if (!explicitlySupported && diffTypes && !inheritedType()) {; 418 const auto tName = TypeID2TypeName(requestedType);; 419 const auto colTypeName = TypeID2TypeName(colType);; 420 std::string errMsg = ""RDataFrame: type mismatch: column \"""" + colName + ""\"" is being used as "";; 421 if (tName.empty()) {; 422 errMsg += requestedType.name();; 423 errMsg += "" (extracted from type info)"";; 424 } else {; 425 errMsg += tName;; 426 }; 427 errMsg += "" but the Define or Vary node advertises it as "";; 428 if (colTypeName.empty()) {; 429 auto &id = colType;; 430 errMsg += id.name();; 431 errMsg += "" (extracted from type info)"";; 432 } else {; 433 errMsg += colTypeName;; 434 }; 435 throw std::runtime_error(errMsg);; 436 }; 437}; 438 ; 439bool IsStrInVec(const std::string &str, const std::vector<std::string> &vec); 440{; 441 return std::find(vec.cbegin(), vec.cend(), str) != vec.cend();; 442}; 443 ; 444auto RStringCache::Insert(const std::string &string) -> decltype(fStrings)::const_iterator; 445{; 446 {; 447 std::shared_lock l{fMutex};; 448 if (aut",MatchSource.WIKI,doc/master/RDFUtils_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFUtils_8cxx_source.html
https://root.cern/doc/master/RDFUtils_8cxx_source.html:20205,Modifiability,config,configuration,20205,"butes_t Float_t Float_t Float_t Int_t Int_t UInt_t UInt_t Rectangle_t Int_t Int_t Window_t TString Int_t GCValues_t GetPrimarySelectionOwner GetDisplay GetScreen GetColormap GetNativeEvent const char const char dpyName wid window const char font_name cursor keysym reg const char only_if_exist regb h Point_t winding char text const char depth char const char Int_t count const char ColorStruct_t color const char Pixmap_t Pixmap_t PictureAttributes_t attr const char char ret_data h unsigned char height h lengthDefinition TGWin32VirtualXProxy.cxx:245; namechar name[80]Definition TGX11.cxx:110; TInterpreter.h; gInterpreter#define gInterpreterDefinition TInterpreter.h:573; TLeaf.h; operator()TRObject operator()(const T1 &t1) constDefinition TRFunctionImport__oprtr.h:14; TROOT.h; TTree.h; Utils.hxx; ROOT::Detail::RDF::RDefineBaseDefinition RDefineBase.hxx:39; ROOT::Detail::RDF::RDefineBase::GetTypeNamestd::string GetTypeName() constDefinition RDefineBase.cxx:47; ROOT::Experimental::RLogChannelA log configuration for a channel, e.g.Definition RLogger.hxx:101; ROOT::Internal::RDF::RStringCache::Insertauto Insert(const std::string &string) -> decltype(fStrings)::const_iteratorInserts the input string in the cache and returns an iterator to the cached string.Definition RDFUtils.cxx:444; ROOT::RDF::RDataSourceRDataSource defines an API that RDataFrame can use to read arbitrary data formats.Definition RDataSource.hxx:109; ROOT::RDF::RDataSource::HasColumnvirtual bool HasColumn(std::string_view colName) const =0Checks if the dataset has a certain column.; ROOT::RDF::RDataSource::GetTypeNamevirtual std::string GetTypeName(std::string_view colName) const =0Type of a column as a string, e.g.; TBranchElementA Branch for the case of an object.Definition TBranchElement.h:39; TBranchElement::GetClassvirtual TClass * GetClass() constDefinition TBranchElement.h:187; TBranch::Classstatic TClass * Class(); TClassRefTClassRef is used to implement a permanent reference to a TClass object.Defi",MatchSource.WIKI,doc/master/RDFUtils_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFUtils_8cxx_source.html
https://root.cern/doc/master/RDFUtils_8cxx_source.html:21813,Modifiability,variab,variable-sized,21813,"d::string GetTypeName(std::string_view colName) const =0Type of a column as a string, e.g.; TBranchElementA Branch for the case of an object.Definition TBranchElement.h:39; TBranchElement::GetClassvirtual TClass * GetClass() constDefinition TBranchElement.h:187; TBranch::Classstatic TClass * Class(); TClassRefTClassRef is used to implement a permanent reference to a TClass object.Definition TClassRef.h:28; TClass::GetClassstatic TClass * GetClass(const char *name, Bool_t load=kTRUE, Bool_t silent=kFALSE)Static method returning pointer to TClass of the specified class name.Definition TClass.cxx:3035; TInterpreter::EErrorCodeEErrorCodeDefinition TInterpreter.h:72; TInterpreter::kNoError@ kNoErrorDefinition TInterpreter.h:73; TLeafA TLeaf describes individual elements of a TBranch See TBranch structure in TTree.Definition TLeaf.h:57; TLeaf::GetTypeNamevirtual const char * GetTypeName() constDefinition TLeaf.h:139; TLeaf::GetLeafCountvirtual TLeaf * GetLeafCount() constIf this leaf stores a variable-sized array or a multi-dimensional array whose last dimension has vari...Definition TLeaf.h:121; TLeaf::GetLenStaticvirtual Int_t GetLenStatic() constReturn the fixed length of this leaf.Definition TLeaf.h:132; TNamed::GetNameconst char * GetName() const overrideReturns name of object.Definition TNamed.h:47; TTreeA TTree represents a columnar dataset.Definition TTree.h:79; TTree::FindBranchvirtual TBranch * FindBranch(const char *name)Return the branch that correspond to the path 'branchname', which can include the name of the tree or...Definition TTree.cxx:4841; TTree::GetBranchvirtual TBranch * GetBranch(const char *name)Return pointer to the branch with the given name in this tree or its friends.Definition TTree.cxx:5294; TTree::GetLeafvirtual TLeaf * GetLeaf(const char *branchname, const char *leafname)Return pointer to the 1st Leaf named name in any Branch of this Tree or any branch in the list of fri...Definition TTree.cxx:6195; TTree::FindLeafvirtual TLeaf * FindLeaf(",MatchSource.WIKI,doc/master/RDFUtils_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFUtils_8cxx_source.html
https://root.cern/doc/master/RDFUtils_8cxx_source.html:20415,Performance,cache,cache,20415,"etColormap GetNativeEvent const char const char dpyName wid window const char font_name cursor keysym reg const char only_if_exist regb h Point_t winding char text const char depth char const char Int_t count const char ColorStruct_t color const char Pixmap_t Pixmap_t PictureAttributes_t attr const char char ret_data h unsigned char height h lengthDefinition TGWin32VirtualXProxy.cxx:245; namechar name[80]Definition TGX11.cxx:110; TInterpreter.h; gInterpreter#define gInterpreterDefinition TInterpreter.h:573; TLeaf.h; operator()TRObject operator()(const T1 &t1) constDefinition TRFunctionImport__oprtr.h:14; TROOT.h; TTree.h; Utils.hxx; ROOT::Detail::RDF::RDefineBaseDefinition RDefineBase.hxx:39; ROOT::Detail::RDF::RDefineBase::GetTypeNamestd::string GetTypeName() constDefinition RDefineBase.cxx:47; ROOT::Experimental::RLogChannelA log configuration for a channel, e.g.Definition RLogger.hxx:101; ROOT::Internal::RDF::RStringCache::Insertauto Insert(const std::string &string) -> decltype(fStrings)::const_iteratorInserts the input string in the cache and returns an iterator to the cached string.Definition RDFUtils.cxx:444; ROOT::RDF::RDataSourceRDataSource defines an API that RDataFrame can use to read arbitrary data formats.Definition RDataSource.hxx:109; ROOT::RDF::RDataSource::HasColumnvirtual bool HasColumn(std::string_view colName) const =0Checks if the dataset has a certain column.; ROOT::RDF::RDataSource::GetTypeNamevirtual std::string GetTypeName(std::string_view colName) const =0Type of a column as a string, e.g.; TBranchElementA Branch for the case of an object.Definition TBranchElement.h:39; TBranchElement::GetClassvirtual TClass * GetClass() constDefinition TBranchElement.h:187; TBranch::Classstatic TClass * Class(); TClassRefTClassRef is used to implement a permanent reference to a TClass object.Definition TClassRef.h:28; TClass::GetClassstatic TClass * GetClass(const char *name, Bool_t load=kTRUE, Bool_t silent=kFALSE)Static method returning pointer to TClass ",MatchSource.WIKI,doc/master/RDFUtils_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFUtils_8cxx_source.html
https://root.cern/doc/master/RDFUtils_8cxx_source.html:20452,Performance,cache,cached,20452,"etColormap GetNativeEvent const char const char dpyName wid window const char font_name cursor keysym reg const char only_if_exist regb h Point_t winding char text const char depth char const char Int_t count const char ColorStruct_t color const char Pixmap_t Pixmap_t PictureAttributes_t attr const char char ret_data h unsigned char height h lengthDefinition TGWin32VirtualXProxy.cxx:245; namechar name[80]Definition TGX11.cxx:110; TInterpreter.h; gInterpreter#define gInterpreterDefinition TInterpreter.h:573; TLeaf.h; operator()TRObject operator()(const T1 &t1) constDefinition TRFunctionImport__oprtr.h:14; TROOT.h; TTree.h; Utils.hxx; ROOT::Detail::RDF::RDefineBaseDefinition RDefineBase.hxx:39; ROOT::Detail::RDF::RDefineBase::GetTypeNamestd::string GetTypeName() constDefinition RDefineBase.cxx:47; ROOT::Experimental::RLogChannelA log configuration for a channel, e.g.Definition RLogger.hxx:101; ROOT::Internal::RDF::RStringCache::Insertauto Insert(const std::string &string) -> decltype(fStrings)::const_iteratorInserts the input string in the cache and returns an iterator to the cached string.Definition RDFUtils.cxx:444; ROOT::RDF::RDataSourceRDataSource defines an API that RDataFrame can use to read arbitrary data formats.Definition RDataSource.hxx:109; ROOT::RDF::RDataSource::HasColumnvirtual bool HasColumn(std::string_view colName) const =0Checks if the dataset has a certain column.; ROOT::RDF::RDataSource::GetTypeNamevirtual std::string GetTypeName(std::string_view colName) const =0Type of a column as a string, e.g.; TBranchElementA Branch for the case of an object.Definition TBranchElement.h:39; TBranchElement::GetClassvirtual TClass * GetClass() constDefinition TBranchElement.h:187; TBranch::Classstatic TClass * Class(); TClassRefTClassRef is used to implement a permanent reference to a TClass object.Definition TClassRef.h:28; TClass::GetClassstatic TClass * GetClass(const char *name, Bool_t load=kTRUE, Bool_t silent=kFALSE)Static method returning pointer to TClass ",MatchSource.WIKI,doc/master/RDFUtils_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFUtils_8cxx_source.html
https://root.cern/doc/master/RDFUtils_8cxx_source.html:21287,Performance,load,load,21287,"nsertauto Insert(const std::string &string) -> decltype(fStrings)::const_iteratorInserts the input string in the cache and returns an iterator to the cached string.Definition RDFUtils.cxx:444; ROOT::RDF::RDataSourceRDataSource defines an API that RDataFrame can use to read arbitrary data formats.Definition RDataSource.hxx:109; ROOT::RDF::RDataSource::HasColumnvirtual bool HasColumn(std::string_view colName) const =0Checks if the dataset has a certain column.; ROOT::RDF::RDataSource::GetTypeNamevirtual std::string GetTypeName(std::string_view colName) const =0Type of a column as a string, e.g.; TBranchElementA Branch for the case of an object.Definition TBranchElement.h:39; TBranchElement::GetClassvirtual TClass * GetClass() constDefinition TBranchElement.h:187; TBranch::Classstatic TClass * Class(); TClassRefTClassRef is used to implement a permanent reference to a TClass object.Definition TClassRef.h:28; TClass::GetClassstatic TClass * GetClass(const char *name, Bool_t load=kTRUE, Bool_t silent=kFALSE)Static method returning pointer to TClass of the specified class name.Definition TClass.cxx:3035; TInterpreter::EErrorCodeEErrorCodeDefinition TInterpreter.h:72; TInterpreter::kNoError@ kNoErrorDefinition TInterpreter.h:73; TLeafA TLeaf describes individual elements of a TBranch See TBranch structure in TTree.Definition TLeaf.h:57; TLeaf::GetTypeNamevirtual const char * GetTypeName() constDefinition TLeaf.h:139; TLeaf::GetLeafCountvirtual TLeaf * GetLeafCount() constIf this leaf stores a variable-sized array or a multi-dimensional array whose last dimension has vari...Definition TLeaf.h:121; TLeaf::GetLenStaticvirtual Int_t GetLenStatic() constReturn the fixed length of this leaf.Definition TLeaf.h:132; TNamed::GetNameconst char * GetName() const overrideReturns name of object.Definition TNamed.h:47; TTreeA TTree represents a columnar dataset.Definition TTree.h:79; TTree::FindBranchvirtual TBranch * FindBranch(const char *name)Return the branch that correspond to the p",MatchSource.WIKI,doc/master/RDFUtils_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFUtils_8cxx_source.html
https://root.cern/doc/master/RDFUtils_8cxx_source.html:26150,Performance,multi-thread,multi-threading,26150,"Namestd::string ColumnName2ColumnTypeName(const std::string &colName, TTree *, RDataSource *, RDefineBase *, bool vector2RVec=true)Return a string containing the type of the given branch.Definition RDFUtils.cxx:229; ROOT::Internal::RDF::CheckReaderTypeMatchesvoid CheckReaderTypeMatches(const std::type_info &colType, const std::type_info &requestedType, const std::string &colName)Definition RDFUtils.cxx:402; ROOT::Internal::RDF::IsInternalColumnbool IsInternalColumn(std::string_view colName)Whether custom column with name colName is an ""internal"" column such as rdfentry_ or rdfslot_.Definition RDFUtils.cxx:381; ROOT::Internal::RDF::InterpreterDeclarevoid InterpreterDeclare(const std::string &code)Declare code in the interpreter via the TInterpreter::Declare method, throw in case of errors.Definition RDFUtils.cxx:333; ROOT::Minuit2::GradientParameterSpace::Internal@ Internal; ROOT::RDFDefinition RArrowDS.hxx:28; ROOTtbb::task_arena is an alias of tbb::interface7::task_arena, which doesn't allow to forward declare tb...Definition EExecutionPolicy.hxx:4; ROOT::IsImplicitMTEnabledBool_t IsImplicitMTEnabled()Returns true if the implicit multi-threading in ROOT is enabled.Definition TROOT.cxx:570; ROOT::GetThreadPoolSizeUInt_t GetThreadPoolSize()Returns the size of ROOT's thread pool.Definition TROOT.cxx:577; ROOT::kSTLvector@ kSTLvectorDefinition ESTLType.h:30; TClassEdit::IsSTLContROOT::ESTLType IsSTLCont(std::string_view type)type : type name: vector<list<classA,allocator>,allocator> result: 0 : not stl container code of cont...Definition TClassEdit.cxx:1378; TClassEdit::GetSplitint GetSplit(const char *type, std::vector< std::string > &output, int &nestedLoc, EModType mode=TClassEdit::kNone)Stores in output (after emptying it) the split type.Definition TClassEdit.cxx:1029; vecDefinition civetweb.c:1855; lTLine lDefinition textangle.C:4. treedataframesrcRDFUtils.cxx. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:02 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/RDFUtils_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFUtils_8cxx_source.html
https://root.cern/doc/master/RDFUtils_8cxx_source.html:14548,Safety,avoid,avoid,14548,"d be considered in an invalid state.\n"";; 341 throw std::runtime_error(msg);; 342 }; 343}; 344 ; 345Long64_t InterpreterCalc(const std::string &code, const std::string &context); 346{; 347 R__LOG_DEBUG(10, RDFLogChannel()) << ""Jitting and executing the following code:\n\n"" << code << '\n';; 348 ; 349 TInterpreter::EErrorCode errorCode(TInterpreter::kNoError); // storage for cling errors; 350 ; 351 auto callCalc = [&errorCode, &context](const std::string &codeSlice) {; 352 gInterpreter->Calc(codeSlice.c_str(), &errorCode);; 353 if (errorCode != TInterpreter::EErrorCode::kNoError) {; 354 std::string msg = ""\nAn error occurred during just-in-time compilation"";; 355 if (!context.empty()); 356 msg += "" in "" + context;; 357 msg +=; 358 "". The lines above might indicate the cause of the crash\nAll RDF objects that have not run their event ""; 359 ""loop yet should be considered in an invalid state.\n"";; 360 throw std::runtime_error(msg);; 361 }; 362 };; 363 ; 364 // Call Calc every 1000 newlines in order to avoid jitting a very large function body, which is slow:; 365 // see https://github.com/root-project/root/issues/9312 and https://github.com/root-project/root/issues/7604; 366 std::size_t substr_start = 0;; 367 std::size_t substr_end = 0;; 368 while (substr_end != std::string::npos && substr_start != code.size() - 1) {; 369 for (std::size_t i = 0u; i < 1000u && substr_end != std::string::npos; ++i) {; 370 substr_end = code.find('\n', substr_end + 1);; 371 }; 372 const std::string subs = code.substr(substr_start, substr_end - substr_start);; 373 substr_start = substr_end;; 374 ; 375 callCalc(subs);; 376 }; 377 ; 378 return 0; // we used to forward the return value of Calc, but that's not possible anymore.; 379}; 380 ; 381bool IsInternalColumn(std::string_view colName); 382{; 383 const auto str = colName.data();; 384 const auto goodPrefix = colName.size() > 3 && // has at least more characters than {r,t}df; 385 ('r' == str[0] || 't' == str[0]) && // starts with r or t; 386 ",MatchSource.WIKI,doc/master/RDFUtils_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFUtils_8cxx_source.html
https://root.cern/doc/master/RDFUtils_8cxx_source.html:20201,Testability,log,log,20201,"butes_t Float_t Float_t Float_t Int_t Int_t UInt_t UInt_t Rectangle_t Int_t Int_t Window_t TString Int_t GCValues_t GetPrimarySelectionOwner GetDisplay GetScreen GetColormap GetNativeEvent const char const char dpyName wid window const char font_name cursor keysym reg const char only_if_exist regb h Point_t winding char text const char depth char const char Int_t count const char ColorStruct_t color const char Pixmap_t Pixmap_t PictureAttributes_t attr const char char ret_data h unsigned char height h lengthDefinition TGWin32VirtualXProxy.cxx:245; namechar name[80]Definition TGX11.cxx:110; TInterpreter.h; gInterpreter#define gInterpreterDefinition TInterpreter.h:573; TLeaf.h; operator()TRObject operator()(const T1 &t1) constDefinition TRFunctionImport__oprtr.h:14; TROOT.h; TTree.h; Utils.hxx; ROOT::Detail::RDF::RDefineBaseDefinition RDefineBase.hxx:39; ROOT::Detail::RDF::RDefineBase::GetTypeNamestd::string GetTypeName() constDefinition RDefineBase.cxx:47; ROOT::Experimental::RLogChannelA log configuration for a channel, e.g.Definition RLogger.hxx:101; ROOT::Internal::RDF::RStringCache::Insertauto Insert(const std::string &string) -> decltype(fStrings)::const_iteratorInserts the input string in the cache and returns an iterator to the cached string.Definition RDFUtils.cxx:444; ROOT::RDF::RDataSourceRDataSource defines an API that RDataFrame can use to read arbitrary data formats.Definition RDataSource.hxx:109; ROOT::RDF::RDataSource::HasColumnvirtual bool HasColumn(std::string_view colName) const =0Checks if the dataset has a certain column.; ROOT::RDF::RDataSource::GetTypeNamevirtual std::string GetTypeName(std::string_view colName) const =0Type of a column as a string, e.g.; TBranchElementA Branch for the case of an object.Definition TBranchElement.h:39; TBranchElement::GetClassvirtual TClass * GetClass() constDefinition TBranchElement.h:187; TBranch::Classstatic TClass * Class(); TClassRefTClassRef is used to implement a permanent reference to a TClass object.Defi",MatchSource.WIKI,doc/master/RDFUtils_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFUtils_8cxx_source.html
https://root.cern/doc/master/RDFUtils_8cxx_source.html:18151,Usability,usab,usable,18151,": column \"""" + colName + ""\"" is being used as "";; 421 if (tName.empty()) {; 422 errMsg += requestedType.name();; 423 errMsg += "" (extracted from type info)"";; 424 } else {; 425 errMsg += tName;; 426 }; 427 errMsg += "" but the Define or Vary node advertises it as "";; 428 if (colTypeName.empty()) {; 429 auto &id = colType;; 430 errMsg += id.name();; 431 errMsg += "" (extracted from type info)"";; 432 } else {; 433 errMsg += colTypeName;; 434 }; 435 throw std::runtime_error(errMsg);; 436 }; 437}; 438 ; 439bool IsStrInVec(const std::string &str, const std::vector<std::string> &vec); 440{; 441 return std::find(vec.cbegin(), vec.cend(), str) != vec.cend();; 442}; 443 ; 444auto RStringCache::Insert(const std::string &string) -> decltype(fStrings)::const_iterator; 445{; 446 {; 447 std::shared_lock l{fMutex};; 448 if (auto it = fStrings.find(string); it != fStrings.end()); 449 return it;; 450 }; 451 ; 452 // TODO: Would be nicer to use a lock upgrade strategy a-la TVirtualRWMutex; 453 // but that is unfortunately not usable outside the already available ROOT mutexes; 454 std::unique_lock l{fMutex};; 455 if (auto it = fStrings.find(string); it != fStrings.end()); 456 return it;; 457 ; 458 return fStrings.insert(string).first;; 459}; 460} // end NS RDF; 461} // end NS Internal; 462} // end NS ROOT; RDataSource.hxx; RDefineBase.hxx; RLogger.hxx; R__LOG_DEBUG#define R__LOG_DEBUG(DEBUGLEVEL,...)Definition RLogger.hxx:365; RLoopManager.hxx; b#define b(i)Definition RSha256.hxx:100; c#define c(i)Definition RSha256.hxx:101; RtypesCore.h; Long64_tlong long Long64_tDefinition RtypesCore.h:69; ULong64_tunsigned long long ULong64_tDefinition RtypesCore.h:70; TBranchElement.h; TBranch.h; TClassEdit.h; TClassRef.h; TClass.h; TError.h; Infovoid Info(const char *location, const char *msgfmt,...)Use this function for informational messages.Definition TError.cxx:218; lengthOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAli",MatchSource.WIKI,doc/master/RDFUtils_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RDFUtils_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:9298,Availability,error,errors,9298,"245 fMvaEventErrorUpper( 0 ),; 246 fLogger ( 0 ); 247{; 248 fDataSetManager = new DataSetManager( fDataInputHandler );; 249 fDataSetManager->AddDataSetInfo(fDataSetInfo);; 250 fLogger = new MsgLogger(this);; 251 SetConfigName( GetName() );; 252 DeclareOptions();; 253 ParseOptions();; 254 ; 255 // arguments: names of input variables given in form: ""name1:name2:name3""; 256 // verbose flag; 257 DecodeVarNames(varNames);; 258 Init();; 259}; 260 ; 261////////////////////////////////////////////////////////////////////////////////; 262/// declaration of configuration options; 263 ; 264void TMVA::Reader::DeclareOptions(); 265{; 266 if (gTools().CheckForSilentOption( GetOptions() )) Log().InhibitOutput(); // make sure is silent if wanted to; 267 ; 268 DeclareOptionRef( fVerbose, ""V"", ""Verbose flag"" );; 269 DeclareOptionRef( fColor, ""Color"", ""Color flag (default True)"" );; 270 DeclareOptionRef( fSilent, ""Silent"", ""Boolean silent flag (default False)"" );; 271 DeclareOptionRef( fCalculateError, ""Error"", ""Calculates errors (default False)"" );; 272}; 273 ; 274////////////////////////////////////////////////////////////////////////////////; 275/// destructor; 276 ; 277TMVA::Reader::~Reader( void ); 278{; 279 delete fDataSetManager; // DSMTEST; 280 ; 281 delete fLogger;; 282 ; 283 for (auto it=fMethodMap.begin(); it!=fMethodMap.end(); it++){; 284 MethodBase * kl = dynamic_cast<TMVA::MethodBase*>(it->second);; 285 delete kl;; 286 }; 287}; 288 ; 289////////////////////////////////////////////////////////////////////////////////; 290/// default initialisation (no member variables); 291 ; 292void TMVA::Reader::Init( void ); 293{; 294 if (Verbose()) fLogger->SetMinType( kVERBOSE );; 295 ; 296 gConfig().SetUseColor( fColor );; 297 gConfig().SetSilent ( fSilent );; 298}; 299 ; 300////////////////////////////////////////////////////////////////////////////////; 301/// Add a float variable or expression to the reader; 302 ; 303void TMVA::Reader::AddVariable( const TString& expression, Float",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:12197,Availability,error,error,12197,"////////////////////////////////; 319/// Add a float spectator or expression to the reader; 320 ; 321void TMVA::Reader::AddSpectator( const TString& expression, Float_t* datalink ); 322{; 323 DataInfo().AddSpectator( expression, """", """", 0, 0, 'F', kFALSE ,(void*)datalink );; 324}; 325 ; 326////////////////////////////////////////////////////////////////////////////////; 327/// Add an integer spectator or expression to the reader; 328 ; 329void TMVA::Reader::AddSpectator( const TString& expression, Int_t* datalink ); 330{; 331 DataInfo().AddSpectator(expression, """", """", 0, 0, 'I', kFALSE, (void*)datalink );; 332}; 333 ; 334////////////////////////////////////////////////////////////////////////////////; 335/// read the method type from the file; 336 ; 337TString TMVA::Reader::GetMethodTypeFromFile( const TString& filename ); 338{; 339 std::ifstream fin( filename );; 340 if (!fin.good()) { // file not found --> Error; 341 Log() << kFATAL << ""<BookMVA> fatal error: ""; 342 << ""unable to open input weight file: "" << filename << Endl;; 343 }; 344 ; 345 TString fullMethodName("""");; 346 if (filename.EndsWith("".xml"")) {; 347 fin.close();; 348 void* doc = gTools().xmlengine().ParseFile(filename,gTools().xmlenginebuffersize());// the default buffer size in TXMLEngine::ParseFile is 100k. Starting with ROOT 5.29 one can set the buffer size, see: http://savannah.cern.ch/bugs/?78864. This might be necessary for large XML files; 349 void* rootnode = gTools().xmlengine().DocGetRootElement(doc); // node ""MethodSetup""; 350 gTools().ReadAttr(rootnode, ""Method"", fullMethodName);; 351 gTools().xmlengine().FreeDoc(doc);; 352 }; 353 else {; 354 char buf[512];; 355 fin.getline(buf,512);; 356 while (!TString(buf).BeginsWith(""Method"")) fin.getline(buf,512);; 357 fullMethodName = TString(buf);; 358 fin.close();; 359 }; 360 TString methodType = fullMethodName(0,fullMethodName.Index(""::""));; 361 if (methodType.Contains("" "")) methodType = methodType(methodType.Last(' ')+1,methodType.Length());; 3",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:19619,Availability,avail,available,19619,"ry for the cuts method where it represents the efficiency cutoff; 498 ; 499Double_t TMVA::Reader::EvaluateMVA( const std::vector<Double_t>& inputVec, const TString& methodTag, Double_t aux ); 500{; 501 // performs a copy to float values which are internally used by all methods; 502 if(fTmpEvalVec.size() != inputVec.size()); 503 fTmpEvalVec.resize(inputVec.size());; 504 ; 505 for (UInt_t idx=0; idx!=inputVec.size(); idx++ ); 506 fTmpEvalVec[idx]=inputVec[idx];; 507 ; 508 return EvaluateMVA( fTmpEvalVec, methodTag, aux );; 509}; 510 ; 511////////////////////////////////////////////////////////////////////////////////; 512/// evaluates MVA for given set of input variables; 513 ; 514Double_t TMVA::Reader::EvaluateMVA( const TString& methodTag, Double_t aux ); 515{; 516 IMethod* method = 0;; 517 ; 518 std::map<TString, IMethod*>::iterator it = fMethodMap.find( methodTag );; 519 if (it == fMethodMap.end()) {; 520 Log() << kINFO << ""<EvaluateMVA> unknown classifier in map; ""; 521 << ""you looked for \"""" << methodTag << ""\"" within available methods: "" << Endl;; 522 for (it = fMethodMap.begin(); it!=fMethodMap.end(); ++it) Log() << ""--> "" << it->first << Endl;; 523 Log() << ""Check calling string"" << kFATAL << Endl;; 524 }; 525 ; 526 else method = it->second;; 527 ; 528 MethodBase * kl = dynamic_cast<TMVA::MethodBase*>(method);; 529 ; 530 if(kl==0); 531 Log() << kFATAL << methodTag << "" is not a method"" << Endl;; 532 ; 533 // check for NaN in event data: (note: in the factory, this check was done already at the creation of the datasets, hence; 534 // it is not again checked in each of these subsequent calls..; 535 const Event* ev = kl->GetEvent();; 536 for (UInt_t i=0; i<ev->GetNVariables(); i++){; 537 if (TMath::IsNaN(ev->GetValue(i))) {; 538 Log() << kERROR << i << ""-th variable of the event is NaN --> return MVA value -999, \n that's all I can do, please fix or remove this event."" << Endl;; 539 return -999;; 540 }; 541 }; 542 return this->EvaluateMVA( kl, aux );; 543}; 544 ;",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:21728,Availability,avail,available,21728,"; 547 ; 548Double_t TMVA::Reader::EvaluateMVA( MethodBase* method, Double_t aux ); 549{; 550 // the aux value is only needed for MethodCuts: it sets the; 551 // required signal efficiency; 552 if (method->GetMethodType() == TMVA::Types::kCuts) {; 553 TMVA::MethodCuts* mc = dynamic_cast<TMVA::MethodCuts*>(method);; 554 if(mc); 555 mc->SetTestSignalEfficiency( aux );; 556 }; 557 ; 558 return method->GetMvaValue( (fCalculateError?&fMvaEventError:0),; 559 (fCalculateError?&fMvaEventErrorUpper:0) );; 560}; 561 ; 562////////////////////////////////////////////////////////////////////////////////; 563/// evaluates MVA for given set of input variables; 564 ; 565const std::vector< Float_t >& TMVA::Reader::EvaluateRegression( const TString& methodTag, Double_t aux ); 566{; 567 IMethod* method = 0;; 568 ; 569 std::map<TString, IMethod*>::iterator it = fMethodMap.find( methodTag );; 570 if (it == fMethodMap.end()) {; 571 Log() << kINFO << ""<EvaluateMVA> unknown method in map; ""; 572 << ""you looked for \"""" << methodTag << ""\"" within available methods: "" << Endl;; 573 for (it = fMethodMap.begin(); it!=fMethodMap.end(); ++it) Log() << ""--> "" << it->first << Endl;; 574 Log() << ""Check calling string"" << kFATAL << Endl;; 575 }; 576 else method = it->second;; 577 ; 578 MethodBase * kl = dynamic_cast<TMVA::MethodBase*>(method);; 579 ; 580 if(kl==0); 581 Log() << kFATAL << methodTag << "" is not a method"" << Endl;; 582 // check for NaN in event data: (note: in the factory, this check was done already at the creation of the datasets, hence; 583 // it is not again checked in each of these subsequent calls..; 584 const Event* ev = kl->GetEvent();; 585 for (UInt_t i=0; i<ev->GetNVariables(); i++){; 586 if (TMath::IsNaN(ev->GetValue(i))) {; 587 Log() << kERROR << i << ""-th variable of the event is NaN, \n regression values might evaluate to .. what do I know. \n sorry this warning is all I can do, please fix or remove this event."" << Endl;; 588 }; 589 }; 590 ; 591 return this->EvaluateRegress",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:24598,Availability,avail,available,24598,"9 ; 610 ; 611////////////////////////////////////////////////////////////////////////////////; 612/// evaluates the regression MVA; 613 ; 614Float_t TMVA::Reader::EvaluateRegression( UInt_t tgtNumber, const TString& methodTag, Double_t aux ); 615{; 616 try {; 617 return EvaluateRegression(methodTag, aux).at(tgtNumber);; 618 }; 619 catch (std::out_of_range &) {; 620 Log() << kWARNING << ""Regression could not be evaluated for target-number "" << tgtNumber << Endl;; 621 return 0;; 622 }; 623}; 624 ; 625 ; 626 ; 627////////////////////////////////////////////////////////////////////////////////; 628/// evaluates MVA for given set of input variables; 629 ; 630const std::vector< Float_t >& TMVA::Reader::EvaluateMulticlass( const TString& methodTag, Double_t aux ); 631{; 632 IMethod* method = 0;; 633 ; 634 std::map<TString, IMethod*>::iterator it = fMethodMap.find( methodTag );; 635 if (it == fMethodMap.end()) {; 636 Log() << kINFO << ""<EvaluateMVA> unknown method in map; ""; 637 << ""you looked for \"""" << methodTag << ""\"" within available methods: "" << Endl;; 638 for (it = fMethodMap.begin(); it!=fMethodMap.end(); ++it) Log() << ""--> "" << it->first << Endl;; 639 Log() << ""Check calling string"" << kFATAL << Endl;; 640 }; 641 else method = it->second;; 642 ; 643 MethodBase * kl = dynamic_cast<TMVA::MethodBase*>(method);; 644 ; 645 if(kl==0); 646 Log() << kFATAL << methodTag << "" is not a method"" << Endl;; 647 // check for NaN in event data: (note: in the factory, this check was done already at the creation of the datasets, hence; 648 // it is not again checked in each of these subsequent calls..; 649 ; 650 const Event* ev = kl->GetEvent();; 651 for (UInt_t i=0; i<ev->GetNVariables(); i++){; 652 if (TMath::IsNaN(ev->GetValue(i))) {; 653 Log() << kERROR << i << ""-th variable of the event is NaN, \n regression values might evaluate to .. what do I know. \n sorry this warning is all I can do, please fix or remove this event."" << Endl;; 654 }; 655 }; 656 ; 657 return this->EvaluateM",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:28034,Availability,avail,available,28034,"r::FindMVA( const TString& methodTag ); 696{; 697 std::map<TString, IMethod*>::iterator it = fMethodMap.find( methodTag );; 698 if (it != fMethodMap.end()) return it->second;; 699 Log() << kERROR << ""Method "" << methodTag << "" not found!"" << Endl;; 700 return 0;; 701}; 702 ; 703////////////////////////////////////////////////////////////////////////////////; 704/// evaluates probability of MVA for given set of input variables; 705 ; 706Double_t TMVA::Reader::GetProba( const TString& methodTag, Double_t ap_sig, Double_t mvaVal ); 707{; 708 IMethod* method = 0;; 709 std::map<TString, IMethod*>::iterator it = fMethodMap.find( methodTag );; 710 if (it == fMethodMap.end()) {; 711 for (it = fMethodMap.begin(); it!=fMethodMap.end(); ++it) Log() << ""M"" << it->first << Endl;; 712 Log() << kFATAL << ""<EvaluateMVA> unknown classifier in map: "" << method << ""; ""; 713 << ""you looked for "" << methodTag<< "" while the available methods are : "" << Endl;; 714 }; 715 else method = it->second;; 716 ; 717 MethodBase* kl = dynamic_cast<MethodBase*>(method);; 718 if(kl==0) return -1;; 719 // check for NaN in event data: (note: in the factory, this check was done already at the creation of the datasets, hence; 720 // it is not again checked in each of these subsequent calls..; 721 const Event* ev = kl->GetEvent();; 722 for (UInt_t i=0; i<ev->GetNVariables(); i++){; 723 if (TMath::IsNaN(ev->GetValue(i))) {; 724 Log() << kERROR << i << ""-th variable of the event is NaN --> return MVA value -999, \n that's all I can do, please fix or remove this event."" << Endl;; 725 return -999;; 726 }; 727 }; 728 ; 729 if (mvaVal == -9999999) mvaVal = kl->GetMvaValue();; 730 ; 731 return kl->GetProba( mvaVal, ap_sig );; 732}; 733 ; 734////////////////////////////////////////////////////////////////////////////////; 735/// evaluates the MVA's rarity; 736 ; 737Double_t TMVA::Reader::GetRarity( const TString& methodTag, Double_t mvaVal ); 738{; 739 IMethod* method = 0;; 740 std::map<TString, IMethod*>::iterato",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:29435,Availability,avail,available,29435,"(i))) {; 724 Log() << kERROR << i << ""-th variable of the event is NaN --> return MVA value -999, \n that's all I can do, please fix or remove this event."" << Endl;; 725 return -999;; 726 }; 727 }; 728 ; 729 if (mvaVal == -9999999) mvaVal = kl->GetMvaValue();; 730 ; 731 return kl->GetProba( mvaVal, ap_sig );; 732}; 733 ; 734////////////////////////////////////////////////////////////////////////////////; 735/// evaluates the MVA's rarity; 736 ; 737Double_t TMVA::Reader::GetRarity( const TString& methodTag, Double_t mvaVal ); 738{; 739 IMethod* method = 0;; 740 std::map<TString, IMethod*>::iterator it = fMethodMap.find( methodTag );; 741 if (it == fMethodMap.end()) {; 742 for (it = fMethodMap.begin(); it!=fMethodMap.end(); ++it) Log() << ""M"" << it->first << Endl;; 743 Log() << kFATAL << ""<EvaluateMVA> unknown classifier in map: \"""" << method << ""\""; ""; 744 << ""you looked for \"""" << methodTag<< ""\"" while the available methods are : "" << Endl;; 745 }; 746 else method = it->second;; 747 ; 748 MethodBase* kl = dynamic_cast<MethodBase*>(method);; 749 if(kl==0) return -1;; 750 // check for NaN in event data: (note: in the factory, this check was done already at the creation of the datasets, hence; 751 // it is not again checked in each of these subsequent calls..; 752 const Event* ev = kl->GetEvent();; 753 for (UInt_t i=0; i<ev->GetNVariables(); i++){; 754 if (TMath::IsNaN(ev->GetValue(i))) {; 755 Log() << kERROR << i << ""-th variable of the event is NaN --> return MVA value -999, \n that's all I can do, please fix or remove this event."" << Endl;; 756 return -999;; 757 }; 758 }; 759 ; 760 if (mvaVal == -9999999) mvaVal = kl->GetMvaValue();; 761 ; 762 return kl->GetRarity( mvaVal );; 763}; 764 ; 765// ---------------------------------------------------------------------------------------; 766// ----- methods related to the decoding of the input variable names ---------------------; 767// ---------------------------------------------------------------------------------------",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:408,Deployability,integrat,integrated,408,". ROOT: tmva/tmva/src/Reader.cxx Source File. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. Reader.cxx. Go to the documentation of this file. 1// @(#)root/tmva $Id$; 2// Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Eckhard von Toerne, Jan Therhaag; 3 ; 4/**********************************************************************************; 5 * Project: TMVA - a Root-integrated toolkit for multivariate data analysis *; 6 * Package: TMVA *; 7 * Class : Reader *; 8 * *; 9 * *; 10 * Description: *; 11 * Reader class to be used in the user application to interpret the trained *; 12 * MVAs in an analysis context *; 13 * *; 14 * Authors (alphabetical order): *; 15 * Andreas Hoecker <Andreas.Hocker@cern.ch> - CERN, Switzerland *; 16 * Peter Speckmayer <peter.speckmayer@cern.ch> - CERN, Switzerland *; 17 * Joerg Stelzer <Joerg.Stelzer@cern.ch> - CERN, Switzerland *; 18 * Jan Therhaag <Jan.Therhaag@cern.ch> - U of Bonn, Germany *; 19 * Eckhard v. Toerne <evt@uni-bonn.de> - U of Bonn, Germany *; 20 * Helge Voss <Helge.Voss@cern.ch> - MPI-K Heidelberg, Germany *; 21 * Kai Voss <Kai.Voss@cern.ch> - U. of Victoria, Canada *; 22 * *; 23 * Copyright (c) 2005-2011: *; 24 * CERN, Switzerland *; 25 * U. of Victoria, Canada *; 26 * MPI-K Heidelberg, Germany *; 27 * U. of Bonn, Germany *; 28 * *; 29 * Redistribution and use in source and binary forms, with or without *; 30 * modification, are permitted according to the terms listed in LICENSE *; 31 * (see tmva/doc/LICENSE) *; 32 **********************************************************************************/; 33 ; 34/*! \class TMVA::Reader; 35\ingroup TMVA; 36 ; 37 The Reader class serves to use the MVAs in a specific analysis context.; 38 Within an event loop, a vector is filled that corresponds to the variables; 39 that were used to train the MVA(s) during the training stage. This vector; 40 is transfered to the Reader, who takes care of interpreting the weight; 41 file of the MVA of choice, an",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:8832,Deployability,configurat,configuration,8832,"tr() );; 201 ; 202 Init();; 203}; 204 ; 205////////////////////////////////////////////////////////////////////////////////; 206/// constructor; 207 ; 208TMVA::Reader::Reader( const std::string& varNames, const TString& theOption, Bool_t verbose ); 209 : Configurable( theOption ),; 210 fDataSetManager( NULL ), // DSMTEST; 211 fDataSetInfo(),; 212 fVerbose( verbose ),; 213 fSilent ( kFALSE ),; 214 fColor ( kFALSE ),; 215 fCalculateError(kFALSE),; 216 fMvaEventError( 0 ),; 217 fMvaEventErrorUpper( 0 ),; 218 fLogger ( 0 ); 219{; 220 fDataSetManager = new DataSetManager( fDataInputHandler );; 221 fDataSetManager->AddDataSetInfo(fDataSetInfo);; 222 fLogger = new MsgLogger(this);; 223 SetConfigName( GetName() );; 224 DeclareOptions();; 225 ParseOptions();; 226 ; 227 // arguments: names of input variables given in form: ""name1:name2:name3""; 228 // verbose flag; 229 DecodeVarNames(varNames);; 230 Init();; 231}; 232 ; 233////////////////////////////////////////////////////////////////////////////////; 234/// constructor; 235 ; 236TMVA::Reader::Reader( const TString& varNames, const TString& theOption, Bool_t verbose ); 237 : Configurable( theOption ),; 238 fDataSetManager( NULL ), // DSMTEST; 239 fDataSetInfo(),; 240 fVerbose( verbose ),; 241 fSilent ( kFALSE ),; 242 fColor ( kFALSE ),; 243 fCalculateError(kFALSE),; 244 fMvaEventError( 0 ),; 245 fMvaEventErrorUpper( 0 ),; 246 fLogger ( 0 ); 247{; 248 fDataSetManager = new DataSetManager( fDataInputHandler );; 249 fDataSetManager->AddDataSetInfo(fDataSetInfo);; 250 fLogger = new MsgLogger(this);; 251 SetConfigName( GetName() );; 252 DeclareOptions();; 253 ParseOptions();; 254 ; 255 // arguments: names of input variables given in form: ""name1:name2:name3""; 256 // verbose flag; 257 DecodeVarNames(varNames);; 258 Init();; 259}; 260 ; 261////////////////////////////////////////////////////////////////////////////////; 262/// declaration of configuration options; 263 ; 264void TMVA::Reader::DeclareOptions(); 265{; 266 if (gTools().",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:39937,Deployability,configurat,configuration,39937,"ing GetMethodTypeFromFile(const TString &filename)read the method type from the fileDefinition Reader.cxx:337; TMVA::Reader::fDataSetManagerDataSetManager * fDataSetManagerDefinition Reader.h:128; TMVA::Reader::fDataSetInfoDataSetInfo fDataSetInfoDefinition Reader.h:136; TMVA::Reader::BookMVAIMethod * BookMVA(const TString &methodTag, const TString &weightfile)read method name from weight fileDefinition Reader.cxx:368; TMVA::Reader::ReaderReader(const TString &theOption="""", Bool_t verbose=0)constructorDefinition Reader.cxx:123; TMVA::Reader::EvaluateMulticlassconst std::vector< Float_t > & EvaluateMulticlass(const TString &methodTag, Double_t aux=0)evaluates MVA for given set of input variablesDefinition Reader.cxx:630; TMVA::Reader::fDataInputHandlerDataInputHandler fDataInputHandlerDefinition Reader.h:138; TMVA::Reader::DecodeVarNamesvoid DecodeVarNames(const std::string &varNames)decodes ""name1:name2:..."" formDefinition Reader.cxx:772; TMVA::Reader::DeclareOptionsvoid DeclareOptions()declaration of configuration optionsDefinition Reader.cxx:264; TMVA::Reader::AddSpectatorvoid AddSpectator(const TString &expression, Float_t *)Add a float spectator or expression to the reader.Definition Reader.cxx:321; TMVA::Reader::AddVariablevoid AddVariable(const TString &expression, Float_t *)Add a float variable or expression to the reader.Definition Reader.cxx:303; TMVA::Reader::~Readervirtual ~Reader(void)destructorDefinition Reader.cxx:277; TMVA::Reader::fLoggerMsgLogger * fLogger! message loggerDefinition Reader.h:161; TMVA::Reader::DataInfoconst DataSetInfo & DataInfo() constDefinition Reader.h:117; TMVA::Tools::xmlengineTXMLEngine & xmlengine()Definition Tools.h:262; TMVA::Tools::ReadAttrvoid ReadAttr(void *node, const char *, T &value)read attribute from xmlDefinition Tools.h:329; TMVA::Types::Instancestatic Types & Instance()The single instance of ""Types"" if existing already, or create it (Singleton)Definition Types.cxx:70; TMVA::Types::EMVAEMVADefinition Types.h:76; T",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:41623,Energy Efficiency,allocate,allocated,41623,"Reader.h:161; TMVA::Reader::DataInfoconst DataSetInfo & DataInfo() constDefinition Reader.h:117; TMVA::Tools::xmlengineTXMLEngine & xmlengine()Definition Tools.h:262; TMVA::Tools::ReadAttrvoid ReadAttr(void *node, const char *, T &value)read attribute from xmlDefinition Tools.h:329; TMVA::Types::Instancestatic Types & Instance()The single instance of ""Types"" if existing already, or create it (Singleton)Definition Types.cxx:70; TMVA::Types::EMVAEMVADefinition Types.h:76; TMVA::Types::kCategory@ kCategoryDefinition Types.h:97; TMVA::Types::kCuts@ kCutsDefinition Types.h:78; TStringBasic string class.Definition TString.h:139; TString::LengthSsiz_t Length() constDefinition TString.h:417; TString::ReplaceAllTString & ReplaceAll(const TString &s1, const TString &s2)Definition TString.h:704; TString::LastSsiz_t Last(char c) constFind last occurrence of a character c.Definition TString.cxx:931; TString::ContainsBool_t Contains(const char *pat, ECaseCompare cmp=kExact) constDefinition TString.h:632; TString::IndexSsiz_t Index(const char *pat, Ssiz_t i=0, ECaseCompare cmp=kExact) constDefinition TString.h:651; TXMLEngine::FreeDocvoid FreeDoc(XMLDocPointer_t xmldoc)frees allocated document data and deletes document itselfDefinition TXMLEngine.cxx:1288; TXMLEngine::DocGetRootElementXMLNodePointer_t DocGetRootElement(XMLDocPointer_t xmldoc)returns root node of documentDefinition TXMLEngine.cxx:1339; TXMLEngine::ParseFileXMLDocPointer_t ParseFile(const char *filename, Int_t maxbuf=100000)Parses content of file and tries to produce xml structures.Definition TXMLEngine.cxx:1356; bool; double; int; unsigned int; nconst Int_t nDefinition legend1.C:16; TMVA::gConfigConfig & gConfig(); TMVA::gToolsTools & gTools(); TMVA::EndlMsgLogger & Endl(MsgLogger &ml)Definition MsgLogger.h:148; TMath::IsNaNBool_t IsNaN(Double_t x)Definition TMath.h:892; Config.h; Types.h. tmvatmvasrcReader.cxx. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:01 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:408,Integrability,integrat,integrated,408,". ROOT: tmva/tmva/src/Reader.cxx Source File. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. Reader.cxx. Go to the documentation of this file. 1// @(#)root/tmva $Id$; 2// Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Eckhard von Toerne, Jan Therhaag; 3 ; 4/**********************************************************************************; 5 * Project: TMVA - a Root-integrated toolkit for multivariate data analysis *; 6 * Package: TMVA *; 7 * Class : Reader *; 8 * *; 9 * *; 10 * Description: *; 11 * Reader class to be used in the user application to interpret the trained *; 12 * MVAs in an analysis context *; 13 * *; 14 * Authors (alphabetical order): *; 15 * Andreas Hoecker <Andreas.Hocker@cern.ch> - CERN, Switzerland *; 16 * Peter Speckmayer <peter.speckmayer@cern.ch> - CERN, Switzerland *; 17 * Joerg Stelzer <Joerg.Stelzer@cern.ch> - CERN, Switzerland *; 18 * Jan Therhaag <Jan.Therhaag@cern.ch> - U of Bonn, Germany *; 19 * Eckhard v. Toerne <evt@uni-bonn.de> - U of Bonn, Germany *; 20 * Helge Voss <Helge.Voss@cern.ch> - MPI-K Heidelberg, Germany *; 21 * Kai Voss <Kai.Voss@cern.ch> - U. of Victoria, Canada *; 22 * *; 23 * Copyright (c) 2005-2011: *; 24 * CERN, Switzerland *; 25 * U. of Victoria, Canada *; 26 * MPI-K Heidelberg, Germany *; 27 * U. of Bonn, Germany *; 28 * *; 29 * Redistribution and use in source and binary forms, with or without *; 30 * modification, are permitted according to the terms listed in LICENSE *; 31 * (see tmva/doc/LICENSE) *; 32 **********************************************************************************/; 33 ; 34/*! \class TMVA::Reader; 35\ingroup TMVA; 36 ; 37 The Reader class serves to use the MVAs in a specific analysis context.; 38 Within an event loop, a vector is filled that corresponds to the variables; 39 that were used to train the MVA(s) during the training stage. This vector; 40 is transfered to the Reader, who takes care of interpreting the weight; 41 file of the MVA of choice, an",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:40419,Integrability,message,message,40419,"bose=0)constructorDefinition Reader.cxx:123; TMVA::Reader::EvaluateMulticlassconst std::vector< Float_t > & EvaluateMulticlass(const TString &methodTag, Double_t aux=0)evaluates MVA for given set of input variablesDefinition Reader.cxx:630; TMVA::Reader::fDataInputHandlerDataInputHandler fDataInputHandlerDefinition Reader.h:138; TMVA::Reader::DecodeVarNamesvoid DecodeVarNames(const std::string &varNames)decodes ""name1:name2:..."" formDefinition Reader.cxx:772; TMVA::Reader::DeclareOptionsvoid DeclareOptions()declaration of configuration optionsDefinition Reader.cxx:264; TMVA::Reader::AddSpectatorvoid AddSpectator(const TString &expression, Float_t *)Add a float spectator or expression to the reader.Definition Reader.cxx:321; TMVA::Reader::AddVariablevoid AddVariable(const TString &expression, Float_t *)Add a float variable or expression to the reader.Definition Reader.cxx:303; TMVA::Reader::~Readervirtual ~Reader(void)destructorDefinition Reader.cxx:277; TMVA::Reader::fLoggerMsgLogger * fLogger! message loggerDefinition Reader.h:161; TMVA::Reader::DataInfoconst DataSetInfo & DataInfo() constDefinition Reader.h:117; TMVA::Tools::xmlengineTXMLEngine & xmlengine()Definition Tools.h:262; TMVA::Tools::ReadAttrvoid ReadAttr(void *node, const char *, T &value)read attribute from xmlDefinition Tools.h:329; TMVA::Types::Instancestatic Types & Instance()The single instance of ""Types"" if existing already, or create it (Singleton)Definition Types.cxx:70; TMVA::Types::EMVAEMVADefinition Types.h:76; TMVA::Types::kCategory@ kCategoryDefinition Types.h:97; TMVA::Types::kCuts@ kCutsDefinition Types.h:78; TStringBasic string class.Definition TString.h:139; TString::LengthSsiz_t Length() constDefinition TString.h:417; TString::ReplaceAllTString & ReplaceAll(const TString &s1, const TString &s2)Definition TString.h:704; TString::LastSsiz_t Last(char c) constFind last occurrence of a character c.Definition TString.cxx:931; TString::ContainsBool_t Contains(const char *pat, ECaseCompare cmp",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:1805,Modifiability,variab,variables,1805,"yer@cern.ch> - CERN, Switzerland *; 17 * Joerg Stelzer <Joerg.Stelzer@cern.ch> - CERN, Switzerland *; 18 * Jan Therhaag <Jan.Therhaag@cern.ch> - U of Bonn, Germany *; 19 * Eckhard v. Toerne <evt@uni-bonn.de> - U of Bonn, Germany *; 20 * Helge Voss <Helge.Voss@cern.ch> - MPI-K Heidelberg, Germany *; 21 * Kai Voss <Kai.Voss@cern.ch> - U. of Victoria, Canada *; 22 * *; 23 * Copyright (c) 2005-2011: *; 24 * CERN, Switzerland *; 25 * U. of Victoria, Canada *; 26 * MPI-K Heidelberg, Germany *; 27 * U. of Bonn, Germany *; 28 * *; 29 * Redistribution and use in source and binary forms, with or without *; 30 * modification, are permitted according to the terms listed in LICENSE *; 31 * (see tmva/doc/LICENSE) *; 32 **********************************************************************************/; 33 ; 34/*! \class TMVA::Reader; 35\ingroup TMVA; 36 ; 37 The Reader class serves to use the MVAs in a specific analysis context.; 38 Within an event loop, a vector is filled that corresponds to the variables; 39 that were used to train the MVA(s) during the training stage. This vector; 40 is transfered to the Reader, who takes care of interpreting the weight; 41 file of the MVA of choice, and to return the MVA's output. This is then; 42 used by the user for further analysis.; 43 ; 44 Usage:; 45 ; 46~~~ {.cpp}; 47 // ------ before starting the event loop (eg, in the initialisation step); 48 ; 49 //; 50 // create TMVA::Reader object; 51 //; 52 TMVA::Reader *reader = new TMVA::Reader();; 53 ; 54 // create a set of variables and declare them to the reader; 55 // - the variable names must corresponds in name and type to; 56 // those given in the weight file(s) that you use; 57 Float_t var1, var2, var3, var4;; 58 reader->AddVariable( ""var1"", &var1 );; 59 reader->AddVariable( ""var2"", &var2 );; 60 reader->AddVariable( ""var3"", &var3 );; 61 reader->AddVariable( ""var4"", &var4 );; 62 ; 63 // book the MVA of your choice (prior training of these methods, ie,; 64 // existence of the weight files i",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:2328,Modifiability,variab,variables,2328,"ee tmva/doc/LICENSE) *; 32 **********************************************************************************/; 33 ; 34/*! \class TMVA::Reader; 35\ingroup TMVA; 36 ; 37 The Reader class serves to use the MVAs in a specific analysis context.; 38 Within an event loop, a vector is filled that corresponds to the variables; 39 that were used to train the MVA(s) during the training stage. This vector; 40 is transfered to the Reader, who takes care of interpreting the weight; 41 file of the MVA of choice, and to return the MVA's output. This is then; 42 used by the user for further analysis.; 43 ; 44 Usage:; 45 ; 46~~~ {.cpp}; 47 // ------ before starting the event loop (eg, in the initialisation step); 48 ; 49 //; 50 // create TMVA::Reader object; 51 //; 52 TMVA::Reader *reader = new TMVA::Reader();; 53 ; 54 // create a set of variables and declare them to the reader; 55 // - the variable names must corresponds in name and type to; 56 // those given in the weight file(s) that you use; 57 Float_t var1, var2, var3, var4;; 58 reader->AddVariable( ""var1"", &var1 );; 59 reader->AddVariable( ""var2"", &var2 );; 60 reader->AddVariable( ""var3"", &var3 );; 61 reader->AddVariable( ""var4"", &var4 );; 62 ; 63 // book the MVA of your choice (prior training of these methods, ie,; 64 // existence of the weight files is required); 65 reader->BookMVA( ""Fisher method"", ""weights/Fisher.weights.txt"" );; 66 reader->BookMVA( ""MLP method"", ""weights/MLP.weights.txt"" );; 67 // ... etc; 68 ; 69 // ------- start your event loop; 70 ; 71 for (Long64_t ievt=0; ievt<myTree->GetEntries();ievt++) {; 72 ; 73 // fill vector with values of variables computed from those in the tree; 74 var1 = myvar1;; 75 var2 = myvar2;; 76 var3 = myvar3;; 77 var4 = myvar4;; 78 ; 79 // retrieve the corresponding MVA output; 80 double mvaFi = reader->EvaluateMVA( ""Fisher method"" );; 81 double mvaNN = reader->EvaluateMVA( ""MLP method"" );; 82 ; 83 // do something with these ...., e.g., fill them into your ntuple; 84 ; 85 } // end of ",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:2382,Modifiability,variab,variable,2382,"ee tmva/doc/LICENSE) *; 32 **********************************************************************************/; 33 ; 34/*! \class TMVA::Reader; 35\ingroup TMVA; 36 ; 37 The Reader class serves to use the MVAs in a specific analysis context.; 38 Within an event loop, a vector is filled that corresponds to the variables; 39 that were used to train the MVA(s) during the training stage. This vector; 40 is transfered to the Reader, who takes care of interpreting the weight; 41 file of the MVA of choice, and to return the MVA's output. This is then; 42 used by the user for further analysis.; 43 ; 44 Usage:; 45 ; 46~~~ {.cpp}; 47 // ------ before starting the event loop (eg, in the initialisation step); 48 ; 49 //; 50 // create TMVA::Reader object; 51 //; 52 TMVA::Reader *reader = new TMVA::Reader();; 53 ; 54 // create a set of variables and declare them to the reader; 55 // - the variable names must corresponds in name and type to; 56 // those given in the weight file(s) that you use; 57 Float_t var1, var2, var3, var4;; 58 reader->AddVariable( ""var1"", &var1 );; 59 reader->AddVariable( ""var2"", &var2 );; 60 reader->AddVariable( ""var3"", &var3 );; 61 reader->AddVariable( ""var4"", &var4 );; 62 ; 63 // book the MVA of your choice (prior training of these methods, ie,; 64 // existence of the weight files is required); 65 reader->BookMVA( ""Fisher method"", ""weights/Fisher.weights.txt"" );; 66 reader->BookMVA( ""MLP method"", ""weights/MLP.weights.txt"" );; 67 // ... etc; 68 ; 69 // ------- start your event loop; 70 ; 71 for (Long64_t ievt=0; ievt<myTree->GetEntries();ievt++) {; 72 ; 73 // fill vector with values of variables computed from those in the tree; 74 var1 = myvar1;; 75 var2 = myvar2;; 76 var3 = myvar3;; 77 var4 = myvar4;; 78 ; 79 // retrieve the corresponding MVA output; 80 double mvaFi = reader->EvaluateMVA( ""Fisher method"" );; 81 double mvaNN = reader->EvaluateMVA( ""MLP method"" );; 82 ; 83 // do something with these ...., e.g., fill them into your ntuple; 84 ; 85 } // end of ",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:3117,Modifiability,variab,variables,3117," 48 ; 49 //; 50 // create TMVA::Reader object; 51 //; 52 TMVA::Reader *reader = new TMVA::Reader();; 53 ; 54 // create a set of variables and declare them to the reader; 55 // - the variable names must corresponds in name and type to; 56 // those given in the weight file(s) that you use; 57 Float_t var1, var2, var3, var4;; 58 reader->AddVariable( ""var1"", &var1 );; 59 reader->AddVariable( ""var2"", &var2 );; 60 reader->AddVariable( ""var3"", &var3 );; 61 reader->AddVariable( ""var4"", &var4 );; 62 ; 63 // book the MVA of your choice (prior training of these methods, ie,; 64 // existence of the weight files is required); 65 reader->BookMVA( ""Fisher method"", ""weights/Fisher.weights.txt"" );; 66 reader->BookMVA( ""MLP method"", ""weights/MLP.weights.txt"" );; 67 // ... etc; 68 ; 69 // ------- start your event loop; 70 ; 71 for (Long64_t ievt=0; ievt<myTree->GetEntries();ievt++) {; 72 ; 73 // fill vector with values of variables computed from those in the tree; 74 var1 = myvar1;; 75 var2 = myvar2;; 76 var3 = myvar3;; 77 var4 = myvar4;; 78 ; 79 // retrieve the corresponding MVA output; 80 double mvaFi = reader->EvaluateMVA( ""Fisher method"" );; 81 double mvaNN = reader->EvaluateMVA( ""MLP method"" );; 82 ; 83 // do something with these ...., e.g., fill them into your ntuple; 84 ; 85 } // end of event loop; 86 ; 87 delete reader;; 88~~~; 89*/; 90 ; 91#include ""TMVA/Reader.h""; 92 ; 93#include ""TMVA/Config.h""; 94#include ""TMVA/Configurable.h""; 95#include ""TMVA/ClassifierFactory.h""; 96#include ""TMVA/DataInputHandler.h""; 97#include ""TMVA/DataSetInfo.h""; 98#include ""TMVA/DataSetManager.h""; 99#include ""TMVA/IMethod.h""; 100#include ""TMVA/MethodBase.h""; 101#include ""TMVA/MethodCuts.h""; 102#include ""TMVA/MethodCategory.h""; 103#include ""TMVA/MsgLogger.h""; 104#include ""TMVA/Tools.h""; 105#include ""TMVA/Types.h""; 106 ; 107#include ""TLeaf.h""; 108#include ""TString.h""; 109#include ""TH1D.h""; 110#include ""TVector.h""; 111#include ""TXMLEngine.h""; 112#include ""TMath.h""; 113 ; 114#include <cstdlib>; 115 ; 116",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:5763,Modifiability,variab,variables,5763," 106 ; 107#include ""TLeaf.h""; 108#include ""TString.h""; 109#include ""TH1D.h""; 110#include ""TVector.h""; 111#include ""TXMLEngine.h""; 112#include ""TMath.h""; 113 ; 114#include <cstdlib>; 115 ; 116#include <string>; 117#include <vector>; 118#include <fstream>; 119 ; 120////////////////////////////////////////////////////////////////////////////////; 121/// constructor; 122 ; 123TMVA::Reader::Reader( const TString& theOption, Bool_t verbose ); 124: Configurable( theOption ),; 125 fDataSetManager( NULL ), // DSMTEST; 126 fDataSetInfo(),; 127 fVerbose( verbose ),; 128 fSilent ( kFALSE ),; 129 fColor ( kFALSE ),; 130 fCalculateError(kFALSE),; 131 fMvaEventError( 0 ),; 132 fMvaEventErrorUpper( 0 ),; 133 fLogger ( 0 ); 134{; 135 fDataSetManager = new DataSetManager( fDataInputHandler );; 136 fDataSetManager->AddDataSetInfo(fDataSetInfo);; 137 fLogger = new MsgLogger(this);; 138 SetConfigName( GetName() );; 139 DeclareOptions();; 140 ParseOptions();; 141 ; 142 Init();; 143}; 144 ; 145////////////////////////////////////////////////////////////////////////////////; 146/// constructor; 147 ; 148TMVA::Reader::Reader( std::vector<TString>& inputVars, const TString& theOption, Bool_t verbose ); 149 : Configurable( theOption ),; 150 fDataSetManager( NULL ), // DSMTEST; 151 fDataSetInfo(),; 152 fVerbose( verbose ),; 153 fSilent ( kFALSE ),; 154 fColor ( kFALSE ),; 155 fCalculateError(kFALSE),; 156 fMvaEventError( 0 ),; 157 fMvaEventErrorUpper( 0 ), //zjh; 158 fLogger ( 0 ); 159{; 160 fDataSetManager = new DataSetManager( fDataInputHandler );; 161 fDataSetManager->AddDataSetInfo(fDataSetInfo);; 162 fLogger = new MsgLogger(this);; 163 SetConfigName( GetName() );; 164 DeclareOptions();; 165 ParseOptions();; 166 ; 167 // arguments: names of input variables (vector); 168 // verbose flag; 169 for (std::vector<TString>::iterator ivar = inputVars.begin(); ivar != inputVars.end(); ++ivar); 170 DataInfo().AddVariable( *ivar );; 171 ; 172 Init();; 173}; 174 ; 175//////////////////////////////////",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:6741,Modifiability,variab,variables,6741,"fCalculateError(kFALSE),; 156 fMvaEventError( 0 ),; 157 fMvaEventErrorUpper( 0 ), //zjh; 158 fLogger ( 0 ); 159{; 160 fDataSetManager = new DataSetManager( fDataInputHandler );; 161 fDataSetManager->AddDataSetInfo(fDataSetInfo);; 162 fLogger = new MsgLogger(this);; 163 SetConfigName( GetName() );; 164 DeclareOptions();; 165 ParseOptions();; 166 ; 167 // arguments: names of input variables (vector); 168 // verbose flag; 169 for (std::vector<TString>::iterator ivar = inputVars.begin(); ivar != inputVars.end(); ++ivar); 170 DataInfo().AddVariable( *ivar );; 171 ; 172 Init();; 173}; 174 ; 175////////////////////////////////////////////////////////////////////////////////; 176/// constructor; 177 ; 178TMVA::Reader::Reader( std::vector<std::string>& inputVars, const TString& theOption, Bool_t verbose ); 179 : Configurable( theOption ),; 180 fDataSetManager( NULL ), // DSMTEST; 181 fDataSetInfo(),; 182 fVerbose( verbose ),; 183 fSilent ( kFALSE ),; 184 fColor ( kFALSE ),; 185 fCalculateError(kFALSE),; 186 fMvaEventError( 0 ),; 187 fMvaEventErrorUpper( 0 ),; 188 fLogger ( 0 ); 189{; 190 fDataSetManager = new DataSetManager( fDataInputHandler );; 191 fDataSetManager->AddDataSetInfo(fDataSetInfo);; 192 fLogger = new MsgLogger(this);; 193 SetConfigName( GetName() );; 194 DeclareOptions();; 195 ParseOptions();; 196 ; 197 // arguments: names of input variables (vector); 198 // verbose flag; 199 for (std::vector<std::string>::iterator ivar = inputVars.begin(); ivar != inputVars.end(); ++ivar); 200 DataInfo().AddVariable( ivar->c_str() );; 201 ; 202 Init();; 203}; 204 ; 205////////////////////////////////////////////////////////////////////////////////; 206/// constructor; 207 ; 208TMVA::Reader::Reader( const std::string& varNames, const TString& theOption, Bool_t verbose ); 209 : Configurable( theOption ),; 210 fDataSetManager( NULL ), // DSMTEST; 211 fDataSetInfo(),; 212 fVerbose( verbose ),; 213 fSilent ( kFALSE ),; 214 fColor ( kFALSE ),; 215 fCalculateError(kFALSE),; 216 fMva",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:7723,Modifiability,variab,variables,7723,,MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:8602,Modifiability,variab,variables,8602,"tr() );; 201 ; 202 Init();; 203}; 204 ; 205////////////////////////////////////////////////////////////////////////////////; 206/// constructor; 207 ; 208TMVA::Reader::Reader( const std::string& varNames, const TString& theOption, Bool_t verbose ); 209 : Configurable( theOption ),; 210 fDataSetManager( NULL ), // DSMTEST; 211 fDataSetInfo(),; 212 fVerbose( verbose ),; 213 fSilent ( kFALSE ),; 214 fColor ( kFALSE ),; 215 fCalculateError(kFALSE),; 216 fMvaEventError( 0 ),; 217 fMvaEventErrorUpper( 0 ),; 218 fLogger ( 0 ); 219{; 220 fDataSetManager = new DataSetManager( fDataInputHandler );; 221 fDataSetManager->AddDataSetInfo(fDataSetInfo);; 222 fLogger = new MsgLogger(this);; 223 SetConfigName( GetName() );; 224 DeclareOptions();; 225 ParseOptions();; 226 ; 227 // arguments: names of input variables given in form: ""name1:name2:name3""; 228 // verbose flag; 229 DecodeVarNames(varNames);; 230 Init();; 231}; 232 ; 233////////////////////////////////////////////////////////////////////////////////; 234/// constructor; 235 ; 236TMVA::Reader::Reader( const TString& varNames, const TString& theOption, Bool_t verbose ); 237 : Configurable( theOption ),; 238 fDataSetManager( NULL ), // DSMTEST; 239 fDataSetInfo(),; 240 fVerbose( verbose ),; 241 fSilent ( kFALSE ),; 242 fColor ( kFALSE ),; 243 fCalculateError(kFALSE),; 244 fMvaEventError( 0 ),; 245 fMvaEventErrorUpper( 0 ),; 246 fLogger ( 0 ); 247{; 248 fDataSetManager = new DataSetManager( fDataInputHandler );; 249 fDataSetManager->AddDataSetInfo(fDataSetInfo);; 250 fLogger = new MsgLogger(this);; 251 SetConfigName( GetName() );; 252 DeclareOptions();; 253 ParseOptions();; 254 ; 255 // arguments: names of input variables given in form: ""name1:name2:name3""; 256 // verbose flag; 257 DecodeVarNames(varNames);; 258 Init();; 259}; 260 ; 261////////////////////////////////////////////////////////////////////////////////; 262/// declaration of configuration options; 263 ; 264void TMVA::Reader::DeclareOptions(); 265{; 266 if (gTools().",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:8832,Modifiability,config,configuration,8832,"tr() );; 201 ; 202 Init();; 203}; 204 ; 205////////////////////////////////////////////////////////////////////////////////; 206/// constructor; 207 ; 208TMVA::Reader::Reader( const std::string& varNames, const TString& theOption, Bool_t verbose ); 209 : Configurable( theOption ),; 210 fDataSetManager( NULL ), // DSMTEST; 211 fDataSetInfo(),; 212 fVerbose( verbose ),; 213 fSilent ( kFALSE ),; 214 fColor ( kFALSE ),; 215 fCalculateError(kFALSE),; 216 fMvaEventError( 0 ),; 217 fMvaEventErrorUpper( 0 ),; 218 fLogger ( 0 ); 219{; 220 fDataSetManager = new DataSetManager( fDataInputHandler );; 221 fDataSetManager->AddDataSetInfo(fDataSetInfo);; 222 fLogger = new MsgLogger(this);; 223 SetConfigName( GetName() );; 224 DeclareOptions();; 225 ParseOptions();; 226 ; 227 // arguments: names of input variables given in form: ""name1:name2:name3""; 228 // verbose flag; 229 DecodeVarNames(varNames);; 230 Init();; 231}; 232 ; 233////////////////////////////////////////////////////////////////////////////////; 234/// constructor; 235 ; 236TMVA::Reader::Reader( const TString& varNames, const TString& theOption, Bool_t verbose ); 237 : Configurable( theOption ),; 238 fDataSetManager( NULL ), // DSMTEST; 239 fDataSetInfo(),; 240 fVerbose( verbose ),; 241 fSilent ( kFALSE ),; 242 fColor ( kFALSE ),; 243 fCalculateError(kFALSE),; 244 fMvaEventError( 0 ),; 245 fMvaEventErrorUpper( 0 ),; 246 fLogger ( 0 ); 247{; 248 fDataSetManager = new DataSetManager( fDataInputHandler );; 249 fDataSetManager->AddDataSetInfo(fDataSetInfo);; 250 fLogger = new MsgLogger(this);; 251 SetConfigName( GetName() );; 252 DeclareOptions();; 253 ParseOptions();; 254 ; 255 // arguments: names of input variables given in form: ""name1:name2:name3""; 256 // verbose flag; 257 DecodeVarNames(varNames);; 258 Init();; 259}; 260 ; 261////////////////////////////////////////////////////////////////////////////////; 262/// declaration of configuration options; 263 ; 264void TMVA::Reader::DeclareOptions(); 265{; 266 if (gTools().",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:9857,Modifiability,variab,variables,9857,"///////; 262/// declaration of configuration options; 263 ; 264void TMVA::Reader::DeclareOptions(); 265{; 266 if (gTools().CheckForSilentOption( GetOptions() )) Log().InhibitOutput(); // make sure is silent if wanted to; 267 ; 268 DeclareOptionRef( fVerbose, ""V"", ""Verbose flag"" );; 269 DeclareOptionRef( fColor, ""Color"", ""Color flag (default True)"" );; 270 DeclareOptionRef( fSilent, ""Silent"", ""Boolean silent flag (default False)"" );; 271 DeclareOptionRef( fCalculateError, ""Error"", ""Calculates errors (default False)"" );; 272}; 273 ; 274////////////////////////////////////////////////////////////////////////////////; 275/// destructor; 276 ; 277TMVA::Reader::~Reader( void ); 278{; 279 delete fDataSetManager; // DSMTEST; 280 ; 281 delete fLogger;; 282 ; 283 for (auto it=fMethodMap.begin(); it!=fMethodMap.end(); it++){; 284 MethodBase * kl = dynamic_cast<TMVA::MethodBase*>(it->second);; 285 delete kl;; 286 }; 287}; 288 ; 289////////////////////////////////////////////////////////////////////////////////; 290/// default initialisation (no member variables); 291 ; 292void TMVA::Reader::Init( void ); 293{; 294 if (Verbose()) fLogger->SetMinType( kVERBOSE );; 295 ; 296 gConfig().SetUseColor( fColor );; 297 gConfig().SetSilent ( fSilent );; 298}; 299 ; 300////////////////////////////////////////////////////////////////////////////////; 301/// Add a float variable or expression to the reader; 302 ; 303void TMVA::Reader::AddVariable( const TString& expression, Float_t* datalink ); 304{; 305 DataInfo().AddVariable( expression, """", """", 0, 0, 'F', kFALSE ,(void*)datalink ); // <= should this be F or rather T?; 306}; 307 ; 308////////////////////////////////////////////////////////////////////////////////; 309 ; 310void TMVA::Reader::AddVariable( const TString& expression, Int_t* datalink ); 311{; 312 Log() << kFATAL << ""Reader::AddVariable( const TString& expression, Int_t* datalink ), this function is deprecated, please provide all variables to the reader as floats"" << Endl;; 313 ",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:10168,Modifiability,variab,variable,10168,"Ref( fSilent, ""Silent"", ""Boolean silent flag (default False)"" );; 271 DeclareOptionRef( fCalculateError, ""Error"", ""Calculates errors (default False)"" );; 272}; 273 ; 274////////////////////////////////////////////////////////////////////////////////; 275/// destructor; 276 ; 277TMVA::Reader::~Reader( void ); 278{; 279 delete fDataSetManager; // DSMTEST; 280 ; 281 delete fLogger;; 282 ; 283 for (auto it=fMethodMap.begin(); it!=fMethodMap.end(); it++){; 284 MethodBase * kl = dynamic_cast<TMVA::MethodBase*>(it->second);; 285 delete kl;; 286 }; 287}; 288 ; 289////////////////////////////////////////////////////////////////////////////////; 290/// default initialisation (no member variables); 291 ; 292void TMVA::Reader::Init( void ); 293{; 294 if (Verbose()) fLogger->SetMinType( kVERBOSE );; 295 ; 296 gConfig().SetUseColor( fColor );; 297 gConfig().SetSilent ( fSilent );; 298}; 299 ; 300////////////////////////////////////////////////////////////////////////////////; 301/// Add a float variable or expression to the reader; 302 ; 303void TMVA::Reader::AddVariable( const TString& expression, Float_t* datalink ); 304{; 305 DataInfo().AddVariable( expression, """", """", 0, 0, 'F', kFALSE ,(void*)datalink ); // <= should this be F or rather T?; 306}; 307 ; 308////////////////////////////////////////////////////////////////////////////////; 309 ; 310void TMVA::Reader::AddVariable( const TString& expression, Int_t* datalink ); 311{; 312 Log() << kFATAL << ""Reader::AddVariable( const TString& expression, Int_t* datalink ), this function is deprecated, please provide all variables to the reader as floats"" << Endl;; 313 // Add an integer variable or expression to the reader; 314 Log() << kFATAL << ""Reader::AddVariable( const TString& expression, Int_t* datalink ), this function is deprecated, please provide all variables to the reader as floats"" << Endl;; 315 DataInfo().AddVariable(expression, """", """", 0, 0, 'I', kFALSE, (void*)datalink ); // <= should this be F or rather T?; 316}; 31",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:10753,Modifiability,variab,variables,10753,"second);; 285 delete kl;; 286 }; 287}; 288 ; 289////////////////////////////////////////////////////////////////////////////////; 290/// default initialisation (no member variables); 291 ; 292void TMVA::Reader::Init( void ); 293{; 294 if (Verbose()) fLogger->SetMinType( kVERBOSE );; 295 ; 296 gConfig().SetUseColor( fColor );; 297 gConfig().SetSilent ( fSilent );; 298}; 299 ; 300////////////////////////////////////////////////////////////////////////////////; 301/// Add a float variable or expression to the reader; 302 ; 303void TMVA::Reader::AddVariable( const TString& expression, Float_t* datalink ); 304{; 305 DataInfo().AddVariable( expression, """", """", 0, 0, 'F', kFALSE ,(void*)datalink ); // <= should this be F or rather T?; 306}; 307 ; 308////////////////////////////////////////////////////////////////////////////////; 309 ; 310void TMVA::Reader::AddVariable( const TString& expression, Int_t* datalink ); 311{; 312 Log() << kFATAL << ""Reader::AddVariable( const TString& expression, Int_t* datalink ), this function is deprecated, please provide all variables to the reader as floats"" << Endl;; 313 // Add an integer variable or expression to the reader; 314 Log() << kFATAL << ""Reader::AddVariable( const TString& expression, Int_t* datalink ), this function is deprecated, please provide all variables to the reader as floats"" << Endl;; 315 DataInfo().AddVariable(expression, """", """", 0, 0, 'I', kFALSE, (void*)datalink ); // <= should this be F or rather T?; 316}; 317 ; 318////////////////////////////////////////////////////////////////////////////////; 319/// Add a float spectator or expression to the reader; 320 ; 321void TMVA::Reader::AddSpectator( const TString& expression, Float_t* datalink ); 322{; 323 DataInfo().AddSpectator( expression, """", """", 0, 0, 'F', kFALSE ,(void*)datalink );; 324}; 325 ; 326////////////////////////////////////////////////////////////////////////////////; 327/// Add an integer spectator or expression to the reader; 328 ; 329void TMVA::Reader",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:10820,Modifiability,variab,variable,10820,"second);; 285 delete kl;; 286 }; 287}; 288 ; 289////////////////////////////////////////////////////////////////////////////////; 290/// default initialisation (no member variables); 291 ; 292void TMVA::Reader::Init( void ); 293{; 294 if (Verbose()) fLogger->SetMinType( kVERBOSE );; 295 ; 296 gConfig().SetUseColor( fColor );; 297 gConfig().SetSilent ( fSilent );; 298}; 299 ; 300////////////////////////////////////////////////////////////////////////////////; 301/// Add a float variable or expression to the reader; 302 ; 303void TMVA::Reader::AddVariable( const TString& expression, Float_t* datalink ); 304{; 305 DataInfo().AddVariable( expression, """", """", 0, 0, 'F', kFALSE ,(void*)datalink ); // <= should this be F or rather T?; 306}; 307 ; 308////////////////////////////////////////////////////////////////////////////////; 309 ; 310void TMVA::Reader::AddVariable( const TString& expression, Int_t* datalink ); 311{; 312 Log() << kFATAL << ""Reader::AddVariable( const TString& expression, Int_t* datalink ), this function is deprecated, please provide all variables to the reader as floats"" << Endl;; 313 // Add an integer variable or expression to the reader; 314 Log() << kFATAL << ""Reader::AddVariable( const TString& expression, Int_t* datalink ), this function is deprecated, please provide all variables to the reader as floats"" << Endl;; 315 DataInfo().AddVariable(expression, """", """", 0, 0, 'I', kFALSE, (void*)datalink ); // <= should this be F or rather T?; 316}; 317 ; 318////////////////////////////////////////////////////////////////////////////////; 319/// Add a float spectator or expression to the reader; 320 ; 321void TMVA::Reader::AddSpectator( const TString& expression, Float_t* datalink ); 322{; 323 DataInfo().AddSpectator( expression, """", """", 0, 0, 'F', kFALSE ,(void*)datalink );; 324}; 325 ; 326////////////////////////////////////////////////////////////////////////////////; 327/// Add an integer spectator or expression to the reader; 328 ; 329void TMVA::Reader",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:10997,Modifiability,variab,variables,10997,"second);; 285 delete kl;; 286 }; 287}; 288 ; 289////////////////////////////////////////////////////////////////////////////////; 290/// default initialisation (no member variables); 291 ; 292void TMVA::Reader::Init( void ); 293{; 294 if (Verbose()) fLogger->SetMinType( kVERBOSE );; 295 ; 296 gConfig().SetUseColor( fColor );; 297 gConfig().SetSilent ( fSilent );; 298}; 299 ; 300////////////////////////////////////////////////////////////////////////////////; 301/// Add a float variable or expression to the reader; 302 ; 303void TMVA::Reader::AddVariable( const TString& expression, Float_t* datalink ); 304{; 305 DataInfo().AddVariable( expression, """", """", 0, 0, 'F', kFALSE ,(void*)datalink ); // <= should this be F or rather T?; 306}; 307 ; 308////////////////////////////////////////////////////////////////////////////////; 309 ; 310void TMVA::Reader::AddVariable( const TString& expression, Int_t* datalink ); 311{; 312 Log() << kFATAL << ""Reader::AddVariable( const TString& expression, Int_t* datalink ), this function is deprecated, please provide all variables to the reader as floats"" << Endl;; 313 // Add an integer variable or expression to the reader; 314 Log() << kFATAL << ""Reader::AddVariable( const TString& expression, Int_t* datalink ), this function is deprecated, please provide all variables to the reader as floats"" << Endl;; 315 DataInfo().AddVariable(expression, """", """", 0, 0, 'I', kFALSE, (void*)datalink ); // <= should this be F or rather T?; 316}; 317 ; 318////////////////////////////////////////////////////////////////////////////////; 319/// Add a float spectator or expression to the reader; 320 ; 321void TMVA::Reader::AddSpectator( const TString& expression, Float_t* datalink ); 322{; 323 DataInfo().AddSpectator( expression, """", """", 0, 0, 'F', kFALSE ,(void*)datalink );; 324}; 325 ; 326////////////////////////////////////////////////////////////////////////////////; 327/// Add an integer spectator or expression to the reader; 328 ; 329void TMVA::Reader",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:17883,Modifiability,variab,variable,17883,"e(); 459 << ""\"" of type: \"""" << method->GetMethodTypeName() << ""\"""" << Endl;; 460 ; 461 return method;; 462}; 463 ; 464////////////////////////////////////////////////////////////////////////////////; 465/// Evaluate a std::vector<float> of input data for a given method; 466/// The parameter aux is obligatory for the cuts method where it represents the efficiency cutoff; 467 ; 468Double_t TMVA::Reader::EvaluateMVA( const std::vector<Float_t>& inputVec, const TString& methodTag, Double_t aux ); 469{; 470 // create a temporary event from the vector.; 471 IMethod* imeth = FindMVA( methodTag );; 472 MethodBase* meth = dynamic_cast<TMVA::MethodBase*>(imeth);; 473 if(meth==0) return 0;; 474 ; 475 // Event* tmpEvent=new Event(inputVec, 2); // ToDo resolve magic 2 issue; 476 Event* tmpEvent=new Event(inputVec, DataInfo().GetNVariables()); // is this the solution?; 477 for (UInt_t i=0; i<inputVec.size(); i++){; 478 if (TMath::IsNaN(inputVec[i])) {; 479 Log() << kERROR << i << ""-th variable of the event is NaN --> return MVA value -999, \n that's all I can do, please fix or remove this event."" << Endl;; 480 delete tmpEvent;; 481 return -999;; 482 }; 483 }; 484 ; 485 if (meth->GetMethodType() == TMVA::Types::kCuts) {; 486 TMVA::MethodCuts* mc = dynamic_cast<TMVA::MethodCuts*>(meth);; 487 if(mc); 488 mc->SetTestSignalEfficiency( aux );; 489 }; 490 Double_t val = meth->GetMvaValue( tmpEvent, (fCalculateError?&fMvaEventError:0));; 491 delete tmpEvent;; 492 return val;; 493}; 494 ; 495////////////////////////////////////////////////////////////////////////////////; 496/// Evaluate a std::vector<double> of input data for a given method; 497/// The parameter aux is obligatory for the cuts method where it represents the efficiency cutoff; 498 ; 499Double_t TMVA::Reader::EvaluateMVA( const std::vector<Double_t>& inputVec, const TString& methodTag, Double_t aux ); 500{; 501 // performs a copy to float values which are internally used by all methods; 502 if(fTmpEvalVec.size() != inputVe",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:19249,Modifiability,variab,variables,19249,"SignalEfficiency( aux );; 489 }; 490 Double_t val = meth->GetMvaValue( tmpEvent, (fCalculateError?&fMvaEventError:0));; 491 delete tmpEvent;; 492 return val;; 493}; 494 ; 495////////////////////////////////////////////////////////////////////////////////; 496/// Evaluate a std::vector<double> of input data for a given method; 497/// The parameter aux is obligatory for the cuts method where it represents the efficiency cutoff; 498 ; 499Double_t TMVA::Reader::EvaluateMVA( const std::vector<Double_t>& inputVec, const TString& methodTag, Double_t aux ); 500{; 501 // performs a copy to float values which are internally used by all methods; 502 if(fTmpEvalVec.size() != inputVec.size()); 503 fTmpEvalVec.resize(inputVec.size());; 504 ; 505 for (UInt_t idx=0; idx!=inputVec.size(); idx++ ); 506 fTmpEvalVec[idx]=inputVec[idx];; 507 ; 508 return EvaluateMVA( fTmpEvalVec, methodTag, aux );; 509}; 510 ; 511////////////////////////////////////////////////////////////////////////////////; 512/// evaluates MVA for given set of input variables; 513 ; 514Double_t TMVA::Reader::EvaluateMVA( const TString& methodTag, Double_t aux ); 515{; 516 IMethod* method = 0;; 517 ; 518 std::map<TString, IMethod*>::iterator it = fMethodMap.find( methodTag );; 519 if (it == fMethodMap.end()) {; 520 Log() << kINFO << ""<EvaluateMVA> unknown classifier in map; ""; 521 << ""you looked for \"""" << methodTag << ""\"" within available methods: "" << Endl;; 522 for (it = fMethodMap.begin(); it!=fMethodMap.end(); ++it) Log() << ""--> "" << it->first << Endl;; 523 Log() << ""Check calling string"" << kFATAL << Endl;; 524 }; 525 ; 526 else method = it->second;; 527 ; 528 MethodBase * kl = dynamic_cast<TMVA::MethodBase*>(method);; 529 ; 530 if(kl==0); 531 Log() << kFATAL << methodTag << "" is not a method"" << Endl;; 532 ; 533 // check for NaN in event data: (note: in the factory, this check was done already at the creation of the datasets, hence; 534 // it is not again checked in each of these subsequent calls..; 535 const ",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:20373,Modifiability,variab,variable,20373,"; 515{; 516 IMethod* method = 0;; 517 ; 518 std::map<TString, IMethod*>::iterator it = fMethodMap.find( methodTag );; 519 if (it == fMethodMap.end()) {; 520 Log() << kINFO << ""<EvaluateMVA> unknown classifier in map; ""; 521 << ""you looked for \"""" << methodTag << ""\"" within available methods: "" << Endl;; 522 for (it = fMethodMap.begin(); it!=fMethodMap.end(); ++it) Log() << ""--> "" << it->first << Endl;; 523 Log() << ""Check calling string"" << kFATAL << Endl;; 524 }; 525 ; 526 else method = it->second;; 527 ; 528 MethodBase * kl = dynamic_cast<TMVA::MethodBase*>(method);; 529 ; 530 if(kl==0); 531 Log() << kFATAL << methodTag << "" is not a method"" << Endl;; 532 ; 533 // check for NaN in event data: (note: in the factory, this check was done already at the creation of the datasets, hence; 534 // it is not again checked in each of these subsequent calls..; 535 const Event* ev = kl->GetEvent();; 536 for (UInt_t i=0; i<ev->GetNVariables(); i++){; 537 if (TMath::IsNaN(ev->GetValue(i))) {; 538 Log() << kERROR << i << ""-th variable of the event is NaN --> return MVA value -999, \n that's all I can do, please fix or remove this event."" << Endl;; 539 return -999;; 540 }; 541 }; 542 return this->EvaluateMVA( kl, aux );; 543}; 544 ; 545////////////////////////////////////////////////////////////////////////////////; 546/// evaluates the MVA; 547 ; 548Double_t TMVA::Reader::EvaluateMVA( MethodBase* method, Double_t aux ); 549{; 550 // the aux value is only needed for MethodCuts: it sets the; 551 // required signal efficiency; 552 if (method->GetMethodType() == TMVA::Types::kCuts) {; 553 TMVA::MethodCuts* mc = dynamic_cast<TMVA::MethodCuts*>(method);; 554 if(mc); 555 mc->SetTestSignalEfficiency( aux );; 556 }; 557 ; 558 return method->GetMvaValue( (fCalculateError?&fMvaEventError:0),; 559 (fCalculateError?&fMvaEventErrorUpper:0) );; 560}; 561 ; 562////////////////////////////////////////////////////////////////////////////////; 563/// evaluates MVA for given set of input variables; 5",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:21334,Modifiability,variab,variables,21334,"check for NaN in event data: (note: in the factory, this check was done already at the creation of the datasets, hence; 534 // it is not again checked in each of these subsequent calls..; 535 const Event* ev = kl->GetEvent();; 536 for (UInt_t i=0; i<ev->GetNVariables(); i++){; 537 if (TMath::IsNaN(ev->GetValue(i))) {; 538 Log() << kERROR << i << ""-th variable of the event is NaN --> return MVA value -999, \n that's all I can do, please fix or remove this event."" << Endl;; 539 return -999;; 540 }; 541 }; 542 return this->EvaluateMVA( kl, aux );; 543}; 544 ; 545////////////////////////////////////////////////////////////////////////////////; 546/// evaluates the MVA; 547 ; 548Double_t TMVA::Reader::EvaluateMVA( MethodBase* method, Double_t aux ); 549{; 550 // the aux value is only needed for MethodCuts: it sets the; 551 // required signal efficiency; 552 if (method->GetMethodType() == TMVA::Types::kCuts) {; 553 TMVA::MethodCuts* mc = dynamic_cast<TMVA::MethodCuts*>(method);; 554 if(mc); 555 mc->SetTestSignalEfficiency( aux );; 556 }; 557 ; 558 return method->GetMvaValue( (fCalculateError?&fMvaEventError:0),; 559 (fCalculateError?&fMvaEventErrorUpper:0) );; 560}; 561 ; 562////////////////////////////////////////////////////////////////////////////////; 563/// evaluates MVA for given set of input variables; 564 ; 565const std::vector< Float_t >& TMVA::Reader::EvaluateRegression( const TString& methodTag, Double_t aux ); 566{; 567 IMethod* method = 0;; 568 ; 569 std::map<TString, IMethod*>::iterator it = fMethodMap.find( methodTag );; 570 if (it == fMethodMap.end()) {; 571 Log() << kINFO << ""<EvaluateMVA> unknown method in map; ""; 572 << ""you looked for \"""" << methodTag << ""\"" within available methods: "" << Endl;; 573 for (it = fMethodMap.begin(); it!=fMethodMap.end(); ++it) Log() << ""--> "" << it->first << Endl;; 574 Log() << ""Check calling string"" << kFATAL << Endl;; 575 }; 576 else method = it->second;; 577 ; 578 MethodBase * kl = dynamic_cast<TMVA::MethodBase*>(method)",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:22470,Modifiability,variab,variable,22470,"st TString& methodTag, Double_t aux ); 566{; 567 IMethod* method = 0;; 568 ; 569 std::map<TString, IMethod*>::iterator it = fMethodMap.find( methodTag );; 570 if (it == fMethodMap.end()) {; 571 Log() << kINFO << ""<EvaluateMVA> unknown method in map; ""; 572 << ""you looked for \"""" << methodTag << ""\"" within available methods: "" << Endl;; 573 for (it = fMethodMap.begin(); it!=fMethodMap.end(); ++it) Log() << ""--> "" << it->first << Endl;; 574 Log() << ""Check calling string"" << kFATAL << Endl;; 575 }; 576 else method = it->second;; 577 ; 578 MethodBase * kl = dynamic_cast<TMVA::MethodBase*>(method);; 579 ; 580 if(kl==0); 581 Log() << kFATAL << methodTag << "" is not a method"" << Endl;; 582 // check for NaN in event data: (note: in the factory, this check was done already at the creation of the datasets, hence; 583 // it is not again checked in each of these subsequent calls..; 584 const Event* ev = kl->GetEvent();; 585 for (UInt_t i=0; i<ev->GetNVariables(); i++){; 586 if (TMath::IsNaN(ev->GetValue(i))) {; 587 Log() << kERROR << i << ""-th variable of the event is NaN, \n regression values might evaluate to .. what do I know. \n sorry this warning is all I can do, please fix or remove this event."" << Endl;; 588 }; 589 }; 590 ; 591 return this->EvaluateRegression( kl, aux );; 592}; 593 ; 594////////////////////////////////////////////////////////////////////////////////; 595/// evaluates the regression MVA; 596/// check for NaN in event data: (note: in the factory, this check was done already at the creation of the datasets, hence; 597/// it is not again checked in each of these subsequent calls.; 598 ; 599const std::vector< Float_t >& TMVA::Reader::EvaluateRegression( MethodBase* method, Double_t /*aux*/ ); 600{; 601 const Event* ev = method->GetEvent();; 602 for (UInt_t i=0; i<ev->GetNVariables(); i++){; 603 if (TMath::IsNaN(ev->GetValue(i))) {; 604 Log() << kERROR << i << ""-th variable of the event is NaN, \n regression values might evaluate to .. what do I know. \n sorry",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:23326,Modifiability,variab,variable,23326,"the datasets, hence; 583 // it is not again checked in each of these subsequent calls..; 584 const Event* ev = kl->GetEvent();; 585 for (UInt_t i=0; i<ev->GetNVariables(); i++){; 586 if (TMath::IsNaN(ev->GetValue(i))) {; 587 Log() << kERROR << i << ""-th variable of the event is NaN, \n regression values might evaluate to .. what do I know. \n sorry this warning is all I can do, please fix or remove this event."" << Endl;; 588 }; 589 }; 590 ; 591 return this->EvaluateRegression( kl, aux );; 592}; 593 ; 594////////////////////////////////////////////////////////////////////////////////; 595/// evaluates the regression MVA; 596/// check for NaN in event data: (note: in the factory, this check was done already at the creation of the datasets, hence; 597/// it is not again checked in each of these subsequent calls.; 598 ; 599const std::vector< Float_t >& TMVA::Reader::EvaluateRegression( MethodBase* method, Double_t /*aux*/ ); 600{; 601 const Event* ev = method->GetEvent();; 602 for (UInt_t i=0; i<ev->GetNVariables(); i++){; 603 if (TMath::IsNaN(ev->GetValue(i))) {; 604 Log() << kERROR << i << ""-th variable of the event is NaN, \n regression values might evaluate to .. what do I know. \n sorry this warning is all I can do, please fix or remove this event."" << Endl;; 605 }; 606 }; 607 return method->GetRegressionValues();; 608}; 609 ; 610 ; 611////////////////////////////////////////////////////////////////////////////////; 612/// evaluates the regression MVA; 613 ; 614Float_t TMVA::Reader::EvaluateRegression( UInt_t tgtNumber, const TString& methodTag, Double_t aux ); 615{; 616 try {; 617 return EvaluateRegression(methodTag, aux).at(tgtNumber);; 618 }; 619 catch (std::out_of_range &) {; 620 Log() << kWARNING << ""Regression could not be evaluated for target-number "" << tgtNumber << Endl;; 621 return 0;; 622 }; 623}; 624 ; 625 ; 626 ; 627////////////////////////////////////////////////////////////////////////////////; 628/// evaluates MVA for given set of input variables; 6",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:24204,Modifiability,variab,variables,24204," ); 600{; 601 const Event* ev = method->GetEvent();; 602 for (UInt_t i=0; i<ev->GetNVariables(); i++){; 603 if (TMath::IsNaN(ev->GetValue(i))) {; 604 Log() << kERROR << i << ""-th variable of the event is NaN, \n regression values might evaluate to .. what do I know. \n sorry this warning is all I can do, please fix or remove this event."" << Endl;; 605 }; 606 }; 607 return method->GetRegressionValues();; 608}; 609 ; 610 ; 611////////////////////////////////////////////////////////////////////////////////; 612/// evaluates the regression MVA; 613 ; 614Float_t TMVA::Reader::EvaluateRegression( UInt_t tgtNumber, const TString& methodTag, Double_t aux ); 615{; 616 try {; 617 return EvaluateRegression(methodTag, aux).at(tgtNumber);; 618 }; 619 catch (std::out_of_range &) {; 620 Log() << kWARNING << ""Regression could not be evaluated for target-number "" << tgtNumber << Endl;; 621 return 0;; 622 }; 623}; 624 ; 625 ; 626 ; 627////////////////////////////////////////////////////////////////////////////////; 628/// evaluates MVA for given set of input variables; 629 ; 630const std::vector< Float_t >& TMVA::Reader::EvaluateMulticlass( const TString& methodTag, Double_t aux ); 631{; 632 IMethod* method = 0;; 633 ; 634 std::map<TString, IMethod*>::iterator it = fMethodMap.find( methodTag );; 635 if (it == fMethodMap.end()) {; 636 Log() << kINFO << ""<EvaluateMVA> unknown method in map; ""; 637 << ""you looked for \"""" << methodTag << ""\"" within available methods: "" << Endl;; 638 for (it = fMethodMap.begin(); it!=fMethodMap.end(); ++it) Log() << ""--> "" << it->first << Endl;; 639 Log() << ""Check calling string"" << kFATAL << Endl;; 640 }; 641 else method = it->second;; 642 ; 643 MethodBase * kl = dynamic_cast<TMVA::MethodBase*>(method);; 644 ; 645 if(kl==0); 646 Log() << kFATAL << methodTag << "" is not a method"" << Endl;; 647 // check for NaN in event data: (note: in the factory, this check was done already at the creation of the datasets, hence; 648 // it is not again checked in each o",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:25346,Modifiability,variab,variable,25346,"TString& methodTag, Double_t aux ); 631{; 632 IMethod* method = 0;; 633 ; 634 std::map<TString, IMethod*>::iterator it = fMethodMap.find( methodTag );; 635 if (it == fMethodMap.end()) {; 636 Log() << kINFO << ""<EvaluateMVA> unknown method in map; ""; 637 << ""you looked for \"""" << methodTag << ""\"" within available methods: "" << Endl;; 638 for (it = fMethodMap.begin(); it!=fMethodMap.end(); ++it) Log() << ""--> "" << it->first << Endl;; 639 Log() << ""Check calling string"" << kFATAL << Endl;; 640 }; 641 else method = it->second;; 642 ; 643 MethodBase * kl = dynamic_cast<TMVA::MethodBase*>(method);; 644 ; 645 if(kl==0); 646 Log() << kFATAL << methodTag << "" is not a method"" << Endl;; 647 // check for NaN in event data: (note: in the factory, this check was done already at the creation of the datasets, hence; 648 // it is not again checked in each of these subsequent calls..; 649 ; 650 const Event* ev = kl->GetEvent();; 651 for (UInt_t i=0; i<ev->GetNVariables(); i++){; 652 if (TMath::IsNaN(ev->GetValue(i))) {; 653 Log() << kERROR << i << ""-th variable of the event is NaN, \n regression values might evaluate to .. what do I know. \n sorry this warning is all I can do, please fix or remove this event."" << Endl;; 654 }; 655 }; 656 ; 657 return this->EvaluateMulticlass( kl, aux );; 658}; 659 ; 660////////////////////////////////////////////////////////////////////////////////; 661/// evaluates the multiclass MVA; 662/// check for NaN in event data: (note: in the factory, this check was done already at the creation of the datasets, hence; 663/// it is not again checked in each of these subsequent calls.; 664 ; 665const std::vector< Float_t >& TMVA::Reader::EvaluateMulticlass( MethodBase* method, Double_t /*aux*/ ); 666{; 667 const Event* ev = method->GetEvent();; 668 for (UInt_t i=0; i<ev->GetNVariables(); i++){; 669 if (TMath::IsNaN(ev->GetValue(i))) {; 670 Log() << kERROR << i << ""-th variable of the event is NaN, \n regression values might evaluate to .. what do I know. \n so",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:26202,Modifiability,variab,variable,26202,"tasets, hence; 648 // it is not again checked in each of these subsequent calls..; 649 ; 650 const Event* ev = kl->GetEvent();; 651 for (UInt_t i=0; i<ev->GetNVariables(); i++){; 652 if (TMath::IsNaN(ev->GetValue(i))) {; 653 Log() << kERROR << i << ""-th variable of the event is NaN, \n regression values might evaluate to .. what do I know. \n sorry this warning is all I can do, please fix or remove this event."" << Endl;; 654 }; 655 }; 656 ; 657 return this->EvaluateMulticlass( kl, aux );; 658}; 659 ; 660////////////////////////////////////////////////////////////////////////////////; 661/// evaluates the multiclass MVA; 662/// check for NaN in event data: (note: in the factory, this check was done already at the creation of the datasets, hence; 663/// it is not again checked in each of these subsequent calls.; 664 ; 665const std::vector< Float_t >& TMVA::Reader::EvaluateMulticlass( MethodBase* method, Double_t /*aux*/ ); 666{; 667 const Event* ev = method->GetEvent();; 668 for (UInt_t i=0; i<ev->GetNVariables(); i++){; 669 if (TMath::IsNaN(ev->GetValue(i))) {; 670 Log() << kERROR << i << ""-th variable of the event is NaN, \n regression values might evaluate to .. what do I know. \n sorry this warning is all I can do, please fix or remove this event."" << Endl;; 671 }; 672 }; 673 return method->GetMulticlassValues();; 674}; 675 ; 676 ; 677////////////////////////////////////////////////////////////////////////////////; 678/// evaluates the multiclass MVA; 679 ; 680Float_t TMVA::Reader::EvaluateMulticlass( UInt_t clsNumber, const TString& methodTag, Double_t aux ); 681{; 682 try {; 683 return EvaluateMulticlass(methodTag, aux).at(clsNumber);; 684 }; 685 catch (std::out_of_range &) {; 686 Log() << kWARNING << ""Multiclass could not be evaluated for class-number "" << clsNumber << Endl;; 687 return 0;; 688 }; 689}; 690 ; 691 ; 692////////////////////////////////////////////////////////////////////////////////; 693/// return pointer to method with tag ""methodTag""; 694 ; 695",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:27538,Modifiability,variab,variables,27538,"//////////////////////////; 678/// evaluates the multiclass MVA; 679 ; 680Float_t TMVA::Reader::EvaluateMulticlass( UInt_t clsNumber, const TString& methodTag, Double_t aux ); 681{; 682 try {; 683 return EvaluateMulticlass(methodTag, aux).at(clsNumber);; 684 }; 685 catch (std::out_of_range &) {; 686 Log() << kWARNING << ""Multiclass could not be evaluated for class-number "" << clsNumber << Endl;; 687 return 0;; 688 }; 689}; 690 ; 691 ; 692////////////////////////////////////////////////////////////////////////////////; 693/// return pointer to method with tag ""methodTag""; 694 ; 695TMVA::IMethod* TMVA::Reader::FindMVA( const TString& methodTag ); 696{; 697 std::map<TString, IMethod*>::iterator it = fMethodMap.find( methodTag );; 698 if (it != fMethodMap.end()) return it->second;; 699 Log() << kERROR << ""Method "" << methodTag << "" not found!"" << Endl;; 700 return 0;; 701}; 702 ; 703////////////////////////////////////////////////////////////////////////////////; 704/// evaluates probability of MVA for given set of input variables; 705 ; 706Double_t TMVA::Reader::GetProba( const TString& methodTag, Double_t ap_sig, Double_t mvaVal ); 707{; 708 IMethod* method = 0;; 709 std::map<TString, IMethod*>::iterator it = fMethodMap.find( methodTag );; 710 if (it == fMethodMap.end()) {; 711 for (it = fMethodMap.begin(); it!=fMethodMap.end(); ++it) Log() << ""M"" << it->first << Endl;; 712 Log() << kFATAL << ""<EvaluateMVA> unknown classifier in map: "" << method << ""; ""; 713 << ""you looked for "" << methodTag<< "" while the available methods are : "" << Endl;; 714 }; 715 else method = it->second;; 716 ; 717 MethodBase* kl = dynamic_cast<MethodBase*>(method);; 718 if(kl==0) return -1;; 719 // check for NaN in event data: (note: in the factory, this check was done already at the creation of the datasets, hence; 720 // it is not again checked in each of these subsequent calls..; 721 const Event* ev = kl->GetEvent();; 722 for (UInt_t i=0; i<ev->GetNVariables(); i++){; 723 if (TMath::IsNaN(ev",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:28557,Modifiability,variab,variable,28557,"of input variables; 705 ; 706Double_t TMVA::Reader::GetProba( const TString& methodTag, Double_t ap_sig, Double_t mvaVal ); 707{; 708 IMethod* method = 0;; 709 std::map<TString, IMethod*>::iterator it = fMethodMap.find( methodTag );; 710 if (it == fMethodMap.end()) {; 711 for (it = fMethodMap.begin(); it!=fMethodMap.end(); ++it) Log() << ""M"" << it->first << Endl;; 712 Log() << kFATAL << ""<EvaluateMVA> unknown classifier in map: "" << method << ""; ""; 713 << ""you looked for "" << methodTag<< "" while the available methods are : "" << Endl;; 714 }; 715 else method = it->second;; 716 ; 717 MethodBase* kl = dynamic_cast<MethodBase*>(method);; 718 if(kl==0) return -1;; 719 // check for NaN in event data: (note: in the factory, this check was done already at the creation of the datasets, hence; 720 // it is not again checked in each of these subsequent calls..; 721 const Event* ev = kl->GetEvent();; 722 for (UInt_t i=0; i<ev->GetNVariables(); i++){; 723 if (TMath::IsNaN(ev->GetValue(i))) {; 724 Log() << kERROR << i << ""-th variable of the event is NaN --> return MVA value -999, \n that's all I can do, please fix or remove this event."" << Endl;; 725 return -999;; 726 }; 727 }; 728 ; 729 if (mvaVal == -9999999) mvaVal = kl->GetMvaValue();; 730 ; 731 return kl->GetProba( mvaVal, ap_sig );; 732}; 733 ; 734////////////////////////////////////////////////////////////////////////////////; 735/// evaluates the MVA's rarity; 736 ; 737Double_t TMVA::Reader::GetRarity( const TString& methodTag, Double_t mvaVal ); 738{; 739 IMethod* method = 0;; 740 std::map<TString, IMethod*>::iterator it = fMethodMap.find( methodTag );; 741 if (it == fMethodMap.end()) {; 742 for (it = fMethodMap.begin(); it!=fMethodMap.end(); ++it) Log() << ""M"" << it->first << Endl;; 743 Log() << kFATAL << ""<EvaluateMVA> unknown classifier in map: \"""" << method << ""\""; ""; 744 << ""you looked for \"""" << methodTag<< ""\"" while the available methods are : "" << Endl;; 745 }; 746 else method = it->second;; 747 ; 748 MethodBase*",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:29958,Modifiability,variab,variable,29958,"evaluates the MVA's rarity; 736 ; 737Double_t TMVA::Reader::GetRarity( const TString& methodTag, Double_t mvaVal ); 738{; 739 IMethod* method = 0;; 740 std::map<TString, IMethod*>::iterator it = fMethodMap.find( methodTag );; 741 if (it == fMethodMap.end()) {; 742 for (it = fMethodMap.begin(); it!=fMethodMap.end(); ++it) Log() << ""M"" << it->first << Endl;; 743 Log() << kFATAL << ""<EvaluateMVA> unknown classifier in map: \"""" << method << ""\""; ""; 744 << ""you looked for \"""" << methodTag<< ""\"" while the available methods are : "" << Endl;; 745 }; 746 else method = it->second;; 747 ; 748 MethodBase* kl = dynamic_cast<MethodBase*>(method);; 749 if(kl==0) return -1;; 750 // check for NaN in event data: (note: in the factory, this check was done already at the creation of the datasets, hence; 751 // it is not again checked in each of these subsequent calls..; 752 const Event* ev = kl->GetEvent();; 753 for (UInt_t i=0; i<ev->GetNVariables(); i++){; 754 if (TMath::IsNaN(ev->GetValue(i))) {; 755 Log() << kERROR << i << ""-th variable of the event is NaN --> return MVA value -999, \n that's all I can do, please fix or remove this event."" << Endl;; 756 return -999;; 757 }; 758 }; 759 ; 760 if (mvaVal == -9999999) mvaVal = kl->GetMvaValue();; 761 ; 762 return kl->GetRarity( mvaVal );; 763}; 764 ; 765// ---------------------------------------------------------------------------------------; 766// ----- methods related to the decoding of the input variable names ---------------------; 767// ---------------------------------------------------------------------------------------; 768 ; 769////////////////////////////////////////////////////////////////////////////////; 770/// decodes ""name1:name2:..."" form; 771 ; 772void TMVA::Reader::DecodeVarNames( const std::string& varNames ); 773{; 774 size_t ipos = 0, f = 0;; 775 while (f != varNames.length()) {; 776 f = varNames.find( ':', ipos );; 777 if (f > varNames.length()) f = varNames.length();; 778 std::string subs = varNames.substr( ipos",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:30384,Modifiability,variab,variable,30384," \"""" << method << ""\""; ""; 744 << ""you looked for \"""" << methodTag<< ""\"" while the available methods are : "" << Endl;; 745 }; 746 else method = it->second;; 747 ; 748 MethodBase* kl = dynamic_cast<MethodBase*>(method);; 749 if(kl==0) return -1;; 750 // check for NaN in event data: (note: in the factory, this check was done already at the creation of the datasets, hence; 751 // it is not again checked in each of these subsequent calls..; 752 const Event* ev = kl->GetEvent();; 753 for (UInt_t i=0; i<ev->GetNVariables(); i++){; 754 if (TMath::IsNaN(ev->GetValue(i))) {; 755 Log() << kERROR << i << ""-th variable of the event is NaN --> return MVA value -999, \n that's all I can do, please fix or remove this event."" << Endl;; 756 return -999;; 757 }; 758 }; 759 ; 760 if (mvaVal == -9999999) mvaVal = kl->GetMvaValue();; 761 ; 762 return kl->GetRarity( mvaVal );; 763}; 764 ; 765// ---------------------------------------------------------------------------------------; 766// ----- methods related to the decoding of the input variable names ---------------------; 767// ---------------------------------------------------------------------------------------; 768 ; 769////////////////////////////////////////////////////////////////////////////////; 770/// decodes ""name1:name2:..."" form; 771 ; 772void TMVA::Reader::DecodeVarNames( const std::string& varNames ); 773{; 774 size_t ipos = 0, f = 0;; 775 while (f != varNames.length()) {; 776 f = varNames.find( ':', ipos );; 777 if (f > varNames.length()) f = varNames.length();; 778 std::string subs = varNames.substr( ipos, f-ipos ); ipos = f+1;; 779 DataInfo().AddVariable( subs.c_str() );; 780 }; 781}; 782 ; 783////////////////////////////////////////////////////////////////////////////////; 784/// decodes ""name1:name2:..."" form; 785 ; 786void TMVA::Reader::DecodeVarNames( const TString& varNames ); 787{; 788 TString format;; 789 Int_t n = varNames.Length();; 790 TString format_obj;; 791 ; 792 for (int i=0; i< n+1 ; i++) {; 793 format.A",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:34578,Modifiability,variab,variable,34578," Create(const std::string &name, const TString &job, const TString &title, DataSetInfo &dsi, const TString &option)creates the method if needed based on the method name using the creator function the factory has stor...Definition ClassifierFactory.cxx:89; TMVA::ClassifierFactory::Instancestatic ClassifierFactory & Instance()access to the ClassifierFactory singleton creates the instance if neededDefinition ClassifierFactory.cxx:48; TMVA::Config::SetUseColorvoid SetUseColor(Bool_t uc)Definition Config.h:60; TMVA::Config::SetSilentvoid SetSilent(Bool_t s)Definition Config.h:63; TMVA::ConfigurableDefinition Configurable.h:45; TMVA::Configurable::SetConfigNamevoid SetConfigName(const char *n)Definition Configurable.h:63; TMVA::Configurable::ParseOptionsvirtual void ParseOptions()options parserDefinition Configurable.cxx:124; TMVA::DataSetInfo::AddVariableVariableInfo & AddVariable(const TString &expression, const TString &title="""", const TString &unit="""", Double_t min=0, Double_t max=0, char varType='F', Bool_t normalized=kTRUE, void *external=nullptr)add a variable (can be a complex expression) to the set of variables used in the MV analysisDefinition DataSetInfo.cxx:207; TMVA::DataSetManagerClass that contains all the data information.Definition DataSetManager.h:51; TMVA::DataSetManager::AddDataSetInfoDataSetInfo & AddDataSetInfo(DataSetInfo &dsi)stores a copy of the dataset info objectDefinition DataSetManager.cxx:105; TMVA::EventDefinition Event.h:51; TMVA::Event::GetValueFloat_t GetValue(UInt_t ivar) constreturn value of i'th variableDefinition Event.cxx:236; TMVA::Event::GetNVariablesUInt_t GetNVariables() constaccessor to the number of variablesDefinition Event.cxx:316; TMVA::IMethodInterface for all concrete MVA method implementations.Definition IMethod.h:53; TMVA::MethodBaseVirtual base Class for all MVA method.Definition MethodBase.h:111; TMVA::MethodBase::GetRegressionValuesconst std::vector< Float_t > & GetRegressionValues(const TMVA::Event *const ev)Definitio",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:34631,Modifiability,variab,variables,34631," Create(const std::string &name, const TString &job, const TString &title, DataSetInfo &dsi, const TString &option)creates the method if needed based on the method name using the creator function the factory has stor...Definition ClassifierFactory.cxx:89; TMVA::ClassifierFactory::Instancestatic ClassifierFactory & Instance()access to the ClassifierFactory singleton creates the instance if neededDefinition ClassifierFactory.cxx:48; TMVA::Config::SetUseColorvoid SetUseColor(Bool_t uc)Definition Config.h:60; TMVA::Config::SetSilentvoid SetSilent(Bool_t s)Definition Config.h:63; TMVA::ConfigurableDefinition Configurable.h:45; TMVA::Configurable::SetConfigNamevoid SetConfigName(const char *n)Definition Configurable.h:63; TMVA::Configurable::ParseOptionsvirtual void ParseOptions()options parserDefinition Configurable.cxx:124; TMVA::DataSetInfo::AddVariableVariableInfo & AddVariable(const TString &expression, const TString &title="""", const TString &unit="""", Double_t min=0, Double_t max=0, char varType='F', Bool_t normalized=kTRUE, void *external=nullptr)add a variable (can be a complex expression) to the set of variables used in the MV analysisDefinition DataSetInfo.cxx:207; TMVA::DataSetManagerClass that contains all the data information.Definition DataSetManager.h:51; TMVA::DataSetManager::AddDataSetInfoDataSetInfo & AddDataSetInfo(DataSetInfo &dsi)stores a copy of the dataset info objectDefinition DataSetManager.cxx:105; TMVA::EventDefinition Event.h:51; TMVA::Event::GetValueFloat_t GetValue(UInt_t ivar) constreturn value of i'th variableDefinition Event.cxx:236; TMVA::Event::GetNVariablesUInt_t GetNVariables() constaccessor to the number of variablesDefinition Event.cxx:316; TMVA::IMethodInterface for all concrete MVA method implementations.Definition IMethod.h:53; TMVA::MethodBaseVirtual base Class for all MVA method.Definition MethodBase.h:111; TMVA::MethodBase::GetRegressionValuesconst std::vector< Float_t > & GetRegressionValues(const TMVA::Event *const ev)Definitio",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:35061,Modifiability,variab,variableDefinition,35061,"::SetSilentvoid SetSilent(Bool_t s)Definition Config.h:63; TMVA::ConfigurableDefinition Configurable.h:45; TMVA::Configurable::SetConfigNamevoid SetConfigName(const char *n)Definition Configurable.h:63; TMVA::Configurable::ParseOptionsvirtual void ParseOptions()options parserDefinition Configurable.cxx:124; TMVA::DataSetInfo::AddVariableVariableInfo & AddVariable(const TString &expression, const TString &title="""", const TString &unit="""", Double_t min=0, Double_t max=0, char varType='F', Bool_t normalized=kTRUE, void *external=nullptr)add a variable (can be a complex expression) to the set of variables used in the MV analysisDefinition DataSetInfo.cxx:207; TMVA::DataSetManagerClass that contains all the data information.Definition DataSetManager.h:51; TMVA::DataSetManager::AddDataSetInfoDataSetInfo & AddDataSetInfo(DataSetInfo &dsi)stores a copy of the dataset info objectDefinition DataSetManager.cxx:105; TMVA::EventDefinition Event.h:51; TMVA::Event::GetValueFloat_t GetValue(UInt_t ivar) constreturn value of i'th variableDefinition Event.cxx:236; TMVA::Event::GetNVariablesUInt_t GetNVariables() constaccessor to the number of variablesDefinition Event.cxx:316; TMVA::IMethodInterface for all concrete MVA method implementations.Definition IMethod.h:53; TMVA::MethodBaseVirtual base Class for all MVA method.Definition MethodBase.h:111; TMVA::MethodBase::GetRegressionValuesconst std::vector< Float_t > & GetRegressionValues(const TMVA::Event *const ev)Definition MethodBase.h:214; TMVA::MethodBase::GetMvaValuevirtual Double_t GetMvaValue(Double_t *errLower=nullptr, Double_t *errUpper=nullptr)=0; TMVA::MethodBase::DeclareCompatibilityOptionsvirtual void DeclareCompatibilityOptions()options that are used ONLY for the READER to ensure backward compatibility they are hence without any...Definition MethodBase.cxx:596; TMVA::MethodBase::GetMethodTypeNameTString GetMethodTypeName() constDefinition MethodBase.h:332; TMVA::MethodBase::GetProbavirtual Double_t GetProba(const Event *e",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:35175,Modifiability,variab,variablesDefinition,35175,"::Configurable::SetConfigNamevoid SetConfigName(const char *n)Definition Configurable.h:63; TMVA::Configurable::ParseOptionsvirtual void ParseOptions()options parserDefinition Configurable.cxx:124; TMVA::DataSetInfo::AddVariableVariableInfo & AddVariable(const TString &expression, const TString &title="""", const TString &unit="""", Double_t min=0, Double_t max=0, char varType='F', Bool_t normalized=kTRUE, void *external=nullptr)add a variable (can be a complex expression) to the set of variables used in the MV analysisDefinition DataSetInfo.cxx:207; TMVA::DataSetManagerClass that contains all the data information.Definition DataSetManager.h:51; TMVA::DataSetManager::AddDataSetInfoDataSetInfo & AddDataSetInfo(DataSetInfo &dsi)stores a copy of the dataset info objectDefinition DataSetManager.cxx:105; TMVA::EventDefinition Event.h:51; TMVA::Event::GetValueFloat_t GetValue(UInt_t ivar) constreturn value of i'th variableDefinition Event.cxx:236; TMVA::Event::GetNVariablesUInt_t GetNVariables() constaccessor to the number of variablesDefinition Event.cxx:316; TMVA::IMethodInterface for all concrete MVA method implementations.Definition IMethod.h:53; TMVA::MethodBaseVirtual base Class for all MVA method.Definition MethodBase.h:111; TMVA::MethodBase::GetRegressionValuesconst std::vector< Float_t > & GetRegressionValues(const TMVA::Event *const ev)Definition MethodBase.h:214; TMVA::MethodBase::GetMvaValuevirtual Double_t GetMvaValue(Double_t *errLower=nullptr, Double_t *errUpper=nullptr)=0; TMVA::MethodBase::DeclareCompatibilityOptionsvirtual void DeclareCompatibilityOptions()options that are used ONLY for the READER to ensure backward compatibility they are hence without any...Definition MethodBase.cxx:596; TMVA::MethodBase::GetMethodTypeNameTString GetMethodTypeName() constDefinition MethodBase.h:332; TMVA::MethodBase::GetProbavirtual Double_t GetProba(const Event *ev)Definition MethodBase.cxx:2247; TMVA::MethodBase::GetMulticlassValuesvirtual const std::vector< Float_t > & Ge",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:37904,Modifiability,variab,variablesDefinition,37904,"eftype=Types::kBackground) constcompute rarity:Definition MethodBase.cxx:2285; TMVA::MethodBase::GetMethodTypeTypes::EMVA GetMethodType() constDefinition MethodBase.h:333; TMVA::MethodBase::CheckSetupvirtual void CheckSetup()check may be overridden by derived class (sometimes, eg, fitters are used which can only be implement...Definition MethodBase.cxx:433; TMVA::MethodCategoryClass for categorizing the phase space.Definition MethodCategory.h:58; TMVA::MethodCategory::fDataSetManagerDataSetManager * fDataSetManagerDefinition MethodCategory.h:138; TMVA::MethodCutsMultivariate optimisation of signal efficiency for given background efficiency, applying rectangular ...Definition MethodCuts.h:61; TMVA::MethodCuts::SetTestSignalEfficiencyvoid SetTestSignalEfficiency(Double_t effS)Definition MethodCuts.h:116; TMVA::MsgLoggerostringstream derivative to redirect and format outputDefinition MsgLogger.h:57; TMVA::Reader::EvaluateRegressionconst std::vector< Float_t > & EvaluateRegression(const TString &methodTag, Double_t aux=0)evaluates MVA for given set of input variablesDefinition Reader.cxx:565; TMVA::Reader::GetNamevirtual const char * GetName() constReturns name of object.Definition Reader.h:113; TMVA::Reader::EvaluateMVADouble_t EvaluateMVA(const std::vector< Float_t > &, const TString &methodTag, Double_t aux=0)Evaluate a std::vector<float> of input data for a given method The parameter aux is obligatory for th...Definition Reader.cxx:468; TMVA::Reader::GetRarityDouble_t GetRarity(const TString &methodTag, Double_t mvaVal=-9999999)evaluates the MVA's rarityDefinition Reader.cxx:737; TMVA::Reader::FindMVAIMethod * FindMVA(const TString &methodTag)return pointer to method with tag ""methodTag""Definition Reader.cxx:695; TMVA::Reader::Initvoid Init(void)default initialisation (no member variables)Definition Reader.cxx:292; TMVA::Reader::GetProbaDouble_t GetProba(const TString &methodTag, Double_t ap_sig=0.5, Double_t mvaVal=-9999999)evaluates probability of MVA for given set",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:38644,Modifiability,variab,variables,38644,"efinition MethodCuts.h:116; TMVA::MsgLoggerostringstream derivative to redirect and format outputDefinition MsgLogger.h:57; TMVA::Reader::EvaluateRegressionconst std::vector< Float_t > & EvaluateRegression(const TString &methodTag, Double_t aux=0)evaluates MVA for given set of input variablesDefinition Reader.cxx:565; TMVA::Reader::GetNamevirtual const char * GetName() constReturns name of object.Definition Reader.h:113; TMVA::Reader::EvaluateMVADouble_t EvaluateMVA(const std::vector< Float_t > &, const TString &methodTag, Double_t aux=0)Evaluate a std::vector<float> of input data for a given method The parameter aux is obligatory for th...Definition Reader.cxx:468; TMVA::Reader::GetRarityDouble_t GetRarity(const TString &methodTag, Double_t mvaVal=-9999999)evaluates the MVA's rarityDefinition Reader.cxx:737; TMVA::Reader::FindMVAIMethod * FindMVA(const TString &methodTag)return pointer to method with tag ""methodTag""Definition Reader.cxx:695; TMVA::Reader::Initvoid Init(void)default initialisation (no member variables)Definition Reader.cxx:292; TMVA::Reader::GetProbaDouble_t GetProba(const TString &methodTag, Double_t ap_sig=0.5, Double_t mvaVal=-9999999)evaluates probability of MVA for given set of input variablesDefinition Reader.cxx:706; TMVA::Reader::GetMethodTypeFromFileTString GetMethodTypeFromFile(const TString &filename)read the method type from the fileDefinition Reader.cxx:337; TMVA::Reader::fDataSetManagerDataSetManager * fDataSetManagerDefinition Reader.h:128; TMVA::Reader::fDataSetInfoDataSetInfo fDataSetInfoDefinition Reader.h:136; TMVA::Reader::BookMVAIMethod * BookMVA(const TString &methodTag, const TString &weightfile)read method name from weight fileDefinition Reader.cxx:368; TMVA::Reader::ReaderReader(const TString &theOption="""", Bool_t verbose=0)constructorDefinition Reader.cxx:123; TMVA::Reader::EvaluateMulticlassconst std::vector< Float_t > & EvaluateMulticlass(const TString &methodTag, Double_t aux=0)evaluates MVA for given set of input variab",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:38845,Modifiability,variab,variablesDefinition,38845,"ression(const TString &methodTag, Double_t aux=0)evaluates MVA for given set of input variablesDefinition Reader.cxx:565; TMVA::Reader::GetNamevirtual const char * GetName() constReturns name of object.Definition Reader.h:113; TMVA::Reader::EvaluateMVADouble_t EvaluateMVA(const std::vector< Float_t > &, const TString &methodTag, Double_t aux=0)Evaluate a std::vector<float> of input data for a given method The parameter aux is obligatory for th...Definition Reader.cxx:468; TMVA::Reader::GetRarityDouble_t GetRarity(const TString &methodTag, Double_t mvaVal=-9999999)evaluates the MVA's rarityDefinition Reader.cxx:737; TMVA::Reader::FindMVAIMethod * FindMVA(const TString &methodTag)return pointer to method with tag ""methodTag""Definition Reader.cxx:695; TMVA::Reader::Initvoid Init(void)default initialisation (no member variables)Definition Reader.cxx:292; TMVA::Reader::GetProbaDouble_t GetProba(const TString &methodTag, Double_t ap_sig=0.5, Double_t mvaVal=-9999999)evaluates probability of MVA for given set of input variablesDefinition Reader.cxx:706; TMVA::Reader::GetMethodTypeFromFileTString GetMethodTypeFromFile(const TString &filename)read the method type from the fileDefinition Reader.cxx:337; TMVA::Reader::fDataSetManagerDataSetManager * fDataSetManagerDefinition Reader.h:128; TMVA::Reader::fDataSetInfoDataSetInfo fDataSetInfoDefinition Reader.h:136; TMVA::Reader::BookMVAIMethod * BookMVA(const TString &methodTag, const TString &weightfile)read method name from weight fileDefinition Reader.cxx:368; TMVA::Reader::ReaderReader(const TString &theOption="""", Bool_t verbose=0)constructorDefinition Reader.cxx:123; TMVA::Reader::EvaluateMulticlassconst std::vector< Float_t > & EvaluateMulticlass(const TString &methodTag, Double_t aux=0)evaluates MVA for given set of input variablesDefinition Reader.cxx:630; TMVA::Reader::fDataInputHandlerDataInputHandler fDataInputHandlerDefinition Reader.h:138; TMVA::Reader::DecodeVarNamesvoid DecodeVarNames(const std::string &varNames)dec",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:39614,Modifiability,variab,variablesDefinition,39614,"hodTag""Definition Reader.cxx:695; TMVA::Reader::Initvoid Init(void)default initialisation (no member variables)Definition Reader.cxx:292; TMVA::Reader::GetProbaDouble_t GetProba(const TString &methodTag, Double_t ap_sig=0.5, Double_t mvaVal=-9999999)evaluates probability of MVA for given set of input variablesDefinition Reader.cxx:706; TMVA::Reader::GetMethodTypeFromFileTString GetMethodTypeFromFile(const TString &filename)read the method type from the fileDefinition Reader.cxx:337; TMVA::Reader::fDataSetManagerDataSetManager * fDataSetManagerDefinition Reader.h:128; TMVA::Reader::fDataSetInfoDataSetInfo fDataSetInfoDefinition Reader.h:136; TMVA::Reader::BookMVAIMethod * BookMVA(const TString &methodTag, const TString &weightfile)read method name from weight fileDefinition Reader.cxx:368; TMVA::Reader::ReaderReader(const TString &theOption="""", Bool_t verbose=0)constructorDefinition Reader.cxx:123; TMVA::Reader::EvaluateMulticlassconst std::vector< Float_t > & EvaluateMulticlass(const TString &methodTag, Double_t aux=0)evaluates MVA for given set of input variablesDefinition Reader.cxx:630; TMVA::Reader::fDataInputHandlerDataInputHandler fDataInputHandlerDefinition Reader.h:138; TMVA::Reader::DecodeVarNamesvoid DecodeVarNames(const std::string &varNames)decodes ""name1:name2:..."" formDefinition Reader.cxx:772; TMVA::Reader::DeclareOptionsvoid DeclareOptions()declaration of configuration optionsDefinition Reader.cxx:264; TMVA::Reader::AddSpectatorvoid AddSpectator(const TString &expression, Float_t *)Add a float spectator or expression to the reader.Definition Reader.cxx:321; TMVA::Reader::AddVariablevoid AddVariable(const TString &expression, Float_t *)Add a float variable or expression to the reader.Definition Reader.cxx:303; TMVA::Reader::~Readervirtual ~Reader(void)destructorDefinition Reader.cxx:277; TMVA::Reader::fLoggerMsgLogger * fLogger! message loggerDefinition Reader.h:161; TMVA::Reader::DataInfoconst DataSetInfo & DataInfo() constDefinition Reader.h:117; TM",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:39937,Modifiability,config,configuration,39937,"ing GetMethodTypeFromFile(const TString &filename)read the method type from the fileDefinition Reader.cxx:337; TMVA::Reader::fDataSetManagerDataSetManager * fDataSetManagerDefinition Reader.h:128; TMVA::Reader::fDataSetInfoDataSetInfo fDataSetInfoDefinition Reader.h:136; TMVA::Reader::BookMVAIMethod * BookMVA(const TString &methodTag, const TString &weightfile)read method name from weight fileDefinition Reader.cxx:368; TMVA::Reader::ReaderReader(const TString &theOption="""", Bool_t verbose=0)constructorDefinition Reader.cxx:123; TMVA::Reader::EvaluateMulticlassconst std::vector< Float_t > & EvaluateMulticlass(const TString &methodTag, Double_t aux=0)evaluates MVA for given set of input variablesDefinition Reader.cxx:630; TMVA::Reader::fDataInputHandlerDataInputHandler fDataInputHandlerDefinition Reader.h:138; TMVA::Reader::DecodeVarNamesvoid DecodeVarNames(const std::string &varNames)decodes ""name1:name2:..."" formDefinition Reader.cxx:772; TMVA::Reader::DeclareOptionsvoid DeclareOptions()declaration of configuration optionsDefinition Reader.cxx:264; TMVA::Reader::AddSpectatorvoid AddSpectator(const TString &expression, Float_t *)Add a float spectator or expression to the reader.Definition Reader.cxx:321; TMVA::Reader::AddVariablevoid AddVariable(const TString &expression, Float_t *)Add a float variable or expression to the reader.Definition Reader.cxx:303; TMVA::Reader::~Readervirtual ~Reader(void)destructorDefinition Reader.cxx:277; TMVA::Reader::fLoggerMsgLogger * fLogger! message loggerDefinition Reader.h:161; TMVA::Reader::DataInfoconst DataSetInfo & DataInfo() constDefinition Reader.h:117; TMVA::Tools::xmlengineTXMLEngine & xmlengine()Definition Tools.h:262; TMVA::Tools::ReadAttrvoid ReadAttr(void *node, const char *, T &value)read attribute from xmlDefinition Tools.h:329; TMVA::Types::Instancestatic Types & Instance()The single instance of ""Types"" if existing already, or create it (Singleton)Definition Types.cxx:70; TMVA::Types::EMVAEMVADefinition Types.h:76; T",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:40234,Modifiability,variab,variable,40234,"er::BookMVAIMethod * BookMVA(const TString &methodTag, const TString &weightfile)read method name from weight fileDefinition Reader.cxx:368; TMVA::Reader::ReaderReader(const TString &theOption="""", Bool_t verbose=0)constructorDefinition Reader.cxx:123; TMVA::Reader::EvaluateMulticlassconst std::vector< Float_t > & EvaluateMulticlass(const TString &methodTag, Double_t aux=0)evaluates MVA for given set of input variablesDefinition Reader.cxx:630; TMVA::Reader::fDataInputHandlerDataInputHandler fDataInputHandlerDefinition Reader.h:138; TMVA::Reader::DecodeVarNamesvoid DecodeVarNames(const std::string &varNames)decodes ""name1:name2:..."" formDefinition Reader.cxx:772; TMVA::Reader::DeclareOptionsvoid DeclareOptions()declaration of configuration optionsDefinition Reader.cxx:264; TMVA::Reader::AddSpectatorvoid AddSpectator(const TString &expression, Float_t *)Add a float spectator or expression to the reader.Definition Reader.cxx:321; TMVA::Reader::AddVariablevoid AddVariable(const TString &expression, Float_t *)Add a float variable or expression to the reader.Definition Reader.cxx:303; TMVA::Reader::~Readervirtual ~Reader(void)destructorDefinition Reader.cxx:277; TMVA::Reader::fLoggerMsgLogger * fLogger! message loggerDefinition Reader.h:161; TMVA::Reader::DataInfoconst DataSetInfo & DataInfo() constDefinition Reader.h:117; TMVA::Tools::xmlengineTXMLEngine & xmlengine()Definition Tools.h:262; TMVA::Tools::ReadAttrvoid ReadAttr(void *node, const char *, T &value)read attribute from xmlDefinition Tools.h:329; TMVA::Types::Instancestatic Types & Instance()The single instance of ""Types"" if existing already, or create it (Singleton)Definition Types.cxx:70; TMVA::Types::EMVAEMVADefinition Types.h:76; TMVA::Types::kCategory@ kCategoryDefinition Types.h:97; TMVA::Types::kCuts@ kCutsDefinition Types.h:78; TStringBasic string class.Definition TString.h:139; TString::LengthSsiz_t Length() constDefinition TString.h:417; TString::ReplaceAllTString & ReplaceAll(const TString &s1, const T",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:18786,Performance,perform,performs,18786," the vector.; 471 IMethod* imeth = FindMVA( methodTag );; 472 MethodBase* meth = dynamic_cast<TMVA::MethodBase*>(imeth);; 473 if(meth==0) return 0;; 474 ; 475 // Event* tmpEvent=new Event(inputVec, 2); // ToDo resolve magic 2 issue; 476 Event* tmpEvent=new Event(inputVec, DataInfo().GetNVariables()); // is this the solution?; 477 for (UInt_t i=0; i<inputVec.size(); i++){; 478 if (TMath::IsNaN(inputVec[i])) {; 479 Log() << kERROR << i << ""-th variable of the event is NaN --> return MVA value -999, \n that's all I can do, please fix or remove this event."" << Endl;; 480 delete tmpEvent;; 481 return -999;; 482 }; 483 }; 484 ; 485 if (meth->GetMethodType() == TMVA::Types::kCuts) {; 486 TMVA::MethodCuts* mc = dynamic_cast<TMVA::MethodCuts*>(meth);; 487 if(mc); 488 mc->SetTestSignalEfficiency( aux );; 489 }; 490 Double_t val = meth->GetMvaValue( tmpEvent, (fCalculateError?&fMvaEventError:0));; 491 delete tmpEvent;; 492 return val;; 493}; 494 ; 495////////////////////////////////////////////////////////////////////////////////; 496/// Evaluate a std::vector<double> of input data for a given method; 497/// The parameter aux is obligatory for the cuts method where it represents the efficiency cutoff; 498 ; 499Double_t TMVA::Reader::EvaluateMVA( const std::vector<Double_t>& inputVec, const TString& methodTag, Double_t aux ); 500{; 501 // performs a copy to float values which are internally used by all methods; 502 if(fTmpEvalVec.size() != inputVec.size()); 503 fTmpEvalVec.resize(inputVec.size());; 504 ; 505 for (UInt_t idx=0; idx!=inputVec.size(); idx++ ); 506 fTmpEvalVec[idx]=inputVec[idx];; 507 ; 508 return EvaluateMVA( fTmpEvalVec, methodTag, aux );; 509}; 510 ; 511////////////////////////////////////////////////////////////////////////////////; 512/// evaluates MVA for given set of input variables; 513 ; 514Double_t TMVA::Reader::EvaluateMVA( const TString& methodTag, Double_t aux ); 515{; 516 IMethod* method = 0;; 517 ; 518 std::map<TString, IMethod*>::iterator it = fMeth",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:33835,Security,access,access,33835,"indow_t TString Int_t GCValues_t GetPrimarySelectionOwner GetDisplay GetScreen GetColormap GetNativeEvent const char const char dpyName wid window const char font_name cursor keysym reg const char only_if_exist regb h Point_t winding char text const char depth char const char Int_t count const char ColorStruct_t color const char Pixmap_t Pixmap_t PictureAttributes_t attr const char char ret_data h unsigned char height h Atom_t Int_t ULong_t ULong_t unsigned char prop_list Atom_t Atom_t Atom_t Time_t formatDefinition TGWin32VirtualXProxy.cxx:249; TH1D.h; TLeaf.h; TMath.h; TString.h; TVector.h; TXMLEngine.h; Tools.h; TMVA::ClassifierFactory::CreateIMethod * Create(const std::string &name, const TString &job, const TString &title, DataSetInfo &dsi, const TString &option)creates the method if needed based on the method name using the creator function the factory has stor...Definition ClassifierFactory.cxx:89; TMVA::ClassifierFactory::Instancestatic ClassifierFactory & Instance()access to the ClassifierFactory singleton creates the instance if neededDefinition ClassifierFactory.cxx:48; TMVA::Config::SetUseColorvoid SetUseColor(Bool_t uc)Definition Config.h:60; TMVA::Config::SetSilentvoid SetSilent(Bool_t s)Definition Config.h:63; TMVA::ConfigurableDefinition Configurable.h:45; TMVA::Configurable::SetConfigNamevoid SetConfigName(const char *n)Definition Configurable.h:63; TMVA::Configurable::ParseOptionsvirtual void ParseOptions()options parserDefinition Configurable.cxx:124; TMVA::DataSetInfo::AddVariableVariableInfo & AddVariable(const TString &expression, const TString &title="""", const TString &unit="""", Double_t min=0, Double_t max=0, char varType='F', Bool_t normalized=kTRUE, void *external=nullptr)add a variable (can be a complex expression) to the set of variables used in the MV analysisDefinition DataSetInfo.cxx:207; TMVA::DataSetManagerClass that contains all the data information.Definition DataSetManager.h:51; TMVA::DataSetManager::AddDataSetInfoDataSetInfo & AddD",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:13504,Testability,assert,assert,13504,"void* doc = gTools().xmlengine().ParseFile(filename,gTools().xmlenginebuffersize());// the default buffer size in TXMLEngine::ParseFile is 100k. Starting with ROOT 5.29 one can set the buffer size, see: http://savannah.cern.ch/bugs/?78864. This might be necessary for large XML files; 349 void* rootnode = gTools().xmlengine().DocGetRootElement(doc); // node ""MethodSetup""; 350 gTools().ReadAttr(rootnode, ""Method"", fullMethodName);; 351 gTools().xmlengine().FreeDoc(doc);; 352 }; 353 else {; 354 char buf[512];; 355 fin.getline(buf,512);; 356 while (!TString(buf).BeginsWith(""Method"")) fin.getline(buf,512);; 357 fullMethodName = TString(buf);; 358 fin.close();; 359 }; 360 TString methodType = fullMethodName(0,fullMethodName.Index(""::""));; 361 if (methodType.Contains("" "")) methodType = methodType(methodType.Last(' ')+1,methodType.Length());; 362 return methodType;; 363}; 364 ; 365////////////////////////////////////////////////////////////////////////////////; 366/// read method name from weight file; 367 ; 368TMVA::IMethod* TMVA::Reader::BookMVA( const TString& methodTag, const TString& weightfile ); 369{; 370 // assert non-existence; 371 if (fMethodMap.find( methodTag ) != fMethodMap.end()); 372 Log() << kFATAL << ""<BookMVA> method tag \"""" << methodTag << ""\"" already exists!"" << Endl;; 373 ; 374 TString methodType(GetMethodTypeFromFile(weightfile));; 375 ; 376 Log() << kINFO << ""Booking \"""" << methodTag << ""\"" of type \"""" << methodType << ""\"" from "" << weightfile << ""."" << Endl;; 377 ; 378 MethodBase* method = dynamic_cast<MethodBase*>(this->BookMVA( Types::Instance().GetMethodType(methodType),; 379 weightfile ) );; 380 if( method && method->GetMethodType() == Types::kCategory ){; 381 MethodCategory *methCat = (dynamic_cast<MethodCategory*>(method));; 382 if( !methCat ); 383 Log() << kFATAL << ""Method with type kCategory cannot be casted to MethodCategory. /Reader"" << Endl;; 384 methCat->fDataSetManager = fDataSetManager;; 385 }; 386 ; 387 return fMethodMap[methodTag] = m",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8cxx_source.html:40427,Testability,log,loggerDefinition,40427,"bose=0)constructorDefinition Reader.cxx:123; TMVA::Reader::EvaluateMulticlassconst std::vector< Float_t > & EvaluateMulticlass(const TString &methodTag, Double_t aux=0)evaluates MVA for given set of input variablesDefinition Reader.cxx:630; TMVA::Reader::fDataInputHandlerDataInputHandler fDataInputHandlerDefinition Reader.h:138; TMVA::Reader::DecodeVarNamesvoid DecodeVarNames(const std::string &varNames)decodes ""name1:name2:..."" formDefinition Reader.cxx:772; TMVA::Reader::DeclareOptionsvoid DeclareOptions()declaration of configuration optionsDefinition Reader.cxx:264; TMVA::Reader::AddSpectatorvoid AddSpectator(const TString &expression, Float_t *)Add a float spectator or expression to the reader.Definition Reader.cxx:321; TMVA::Reader::AddVariablevoid AddVariable(const TString &expression, Float_t *)Add a float variable or expression to the reader.Definition Reader.cxx:303; TMVA::Reader::~Readervirtual ~Reader(void)destructorDefinition Reader.cxx:277; TMVA::Reader::fLoggerMsgLogger * fLogger! message loggerDefinition Reader.h:161; TMVA::Reader::DataInfoconst DataSetInfo & DataInfo() constDefinition Reader.h:117; TMVA::Tools::xmlengineTXMLEngine & xmlengine()Definition Tools.h:262; TMVA::Tools::ReadAttrvoid ReadAttr(void *node, const char *, T &value)read attribute from xmlDefinition Tools.h:329; TMVA::Types::Instancestatic Types & Instance()The single instance of ""Types"" if existing already, or create it (Singleton)Definition Types.cxx:70; TMVA::Types::EMVAEMVADefinition Types.h:76; TMVA::Types::kCategory@ kCategoryDefinition Types.h:97; TMVA::Types::kCuts@ kCutsDefinition Types.h:78; TStringBasic string class.Definition TString.h:139; TString::LengthSsiz_t Length() constDefinition TString.h:417; TString::ReplaceAllTString & ReplaceAll(const TString &s1, const TString &s2)Definition TString.h:704; TString::LastSsiz_t Last(char c) constFind last occurrence of a character c.Definition TString.cxx:931; TString::ContainsBool_t Contains(const char *pat, ECaseCompare cmp",MatchSource.WIKI,doc/master/Reader_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8cxx_source.html
https://root.cern/doc/master/Reader_8h.html:424,Integrability,depend,dependency,424,". ROOT: tmva/tmva/inc/TMVA/Reader.h File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. Classes |; Namespaces ; Reader.h File Reference. #include ""TMVA/Configurable.h""; #include ""TMVA/Types.h""; #include ""TMVA/DataSetInfo.h""; #include ""TMVA/DataInputHandler.h""; #include ""TMVA/DataSetManager.h""; #include <vector>; #include <map>; #include <stdexcept>; #include <string>. Include dependency graph for Reader.h:. This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead. This graph shows which files directly or indirectly include this file:. This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead. Classes; class TMVA::Reader; The Reader class serves to use the MVAs in a specific analysis context. More...; . Namespaces; namespace TMVA; create variable transformations ; . tmvatmvaincTMVAReader.h. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:25 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/Reader_8h.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8h.html
https://root.cern/doc/master/Reader_8h.html:850,Modifiability,variab,variable,850,". ROOT: tmva/tmva/inc/TMVA/Reader.h File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. Classes |; Namespaces ; Reader.h File Reference. #include ""TMVA/Configurable.h""; #include ""TMVA/Types.h""; #include ""TMVA/DataSetInfo.h""; #include ""TMVA/DataInputHandler.h""; #include ""TMVA/DataSetManager.h""; #include <vector>; #include <map>; #include <stdexcept>; #include <string>. Include dependency graph for Reader.h:. This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead. This graph shows which files directly or indirectly include this file:. This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead. Classes; class TMVA::Reader; The Reader class serves to use the MVAs in a specific analysis context. More...; . Namespaces; namespace TMVA; create variable transformations ; . tmvatmvaincTMVAReader.h. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:25 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/Reader_8h.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8h.html
https://root.cern/doc/master/Reader_8h_source.html:3741,Availability,error,error,3741,"able {; 65 ; 66 public:; 67 ; 68 // without prior specification of variables; 69 Reader( const TString& theOption="""", Bool_t verbose = 0 );; 70 ; 71 // STL types; 72 Reader( std::vector<std::string>& varNames, const TString& theOption = """", Bool_t verbose = 0 );; 73 Reader( const std::string& varNames, const TString& theOption, Bool_t verbose = 0 ); // format: ""var1:var2:...""; 74 ; 75 // Root types; 76 Reader( std::vector<TString>& varNames, const TString& theOption = """", Bool_t verbose = 0 );; 77 Reader( const TString& varNames, const TString& theOption, Bool_t verbose = 0 ); // format: ""var1:var2:...""; 78 ; 79 virtual ~Reader( void );; 80 ; 81 // book MVA method via weight file; 82 IMethod* BookMVA( const TString& methodTag, const TString& weightfile );; 83 IMethod* BookMVA( TMVA::Types::EMVA methodType, const char* xmlstr );; 84 IMethod* FindMVA( const TString& methodTag );; 85 ; 86 // returns the MVA response for given event; 87 Double_t EvaluateMVA( const std::vector<Float_t> &, const TString& methodTag, Double_t aux = 0 );; 88 Double_t EvaluateMVA( const std::vector<Double_t>&, const TString& methodTag, Double_t aux = 0 );; 89 Double_t EvaluateMVA( MethodBase* method, Double_t aux = 0 );; 90 Double_t EvaluateMVA( const TString& methodTag, Double_t aux = 0 );; 91 ; 92 // returns error on MVA response for given event; 93 // NOTE: must be called AFTER ""EvaluateMVA(...)"" call !; 94 Double_t GetMVAError() const { return fMvaEventError; }; 95 Double_t GetMVAErrorLower() const { return fMvaEventError; }; 96 Double_t GetMVAErrorUpper() const { return fMvaEventErrorUpper; }; 97 ; 98 // regression response; 99 const std::vector< Float_t >& EvaluateRegression( const TString& methodTag, Double_t aux = 0 );; 100 const std::vector< Float_t >& EvaluateRegression( MethodBase* method, Double_t aux = 0 );; 101 Float_t EvaluateRegression( UInt_t tgtNumber, const TString& methodTag, Double_t aux = 0 );; 102 ; 103 // multiclass response; 104 const std::vector< Float_t >& EvaluateM",MatchSource.WIKI,doc/master/Reader_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8h_source.html
https://root.cern/doc/master/Reader_8h_source.html:6337,Availability,error,error,6337,"Double_t mvaVal=-9999999 );; 111 ; 112 // accessors; 113 virtual const char* GetName() const { return ""Reader""; }; 114 Bool_t Verbose( void ) const { return fVerbose; }; 115 void SetVerbose( Bool_t v ) { fVerbose = v; }; 116 ; 117 const DataSetInfo& DataInfo() const { return fDataSetInfo; }; 118 DataSetInfo& DataInfo() { return fDataSetInfo; }; 119 ; 120 void AddVariable( const TString& expression, Float_t* );; 121 void AddVariable( const TString& expression, Int_t* );; 122 ; 123 void AddSpectator( const TString& expression, Float_t* );; 124 void AddSpectator( const TString& expression, Int_t* );; 125 ; 126 private:; 127 ; 128 DataSetManager* fDataSetManager; // DSMTEST; 129 ; 130 ; 131 TString GetMethodTypeFromFile( const TString& filename );; 132 ; 133 // this booking method is internal; 134 IMethod* BookMVA( Types::EMVA method, const TString& weightfile );; 135 ; 136 DataSetInfo fDataSetInfo; // the data set; 137 ; 138 DataInputHandler fDataInputHandler;; 139 ; 140 // Init Reader class; 141 void Init( void );; 142 ; 143 // Decode Constructor string (or TString) and fill variable name std::vector; 144 void DecodeVarNames( const std::string& varNames );; 145 void DecodeVarNames( const TString& varNames );; 146 ; 147 void DeclareOptions();; 148 ; 149 Bool_t fVerbose; ///< verbosity; 150 Bool_t fSilent; ///< silent mode; 151 Bool_t fColor; ///< color mode; 152 Bool_t fCalculateError; ///< error calculation mode; 153 ; 154 Double_t fMvaEventError; ///< per-event error returned by MVA; 155 Double_t fMvaEventErrorUpper; ///< per-event error returned by MVA; 156 ; 157 std::map<TString, IMethod*> fMethodMap; ///< map of methods; 158 ; 159 std::vector<Float_t> fTmpEvalVec; ///< temporary evaluation vector (if user input is v<double>); 160 ; 161 mutable MsgLogger* fLogger; ///<! message logger; 162 MsgLogger& Log() const { return *fLogger; }; 163 ; 164 ClassDef(Reader,0); // Interpret the trained MVAs in an analysis context; 165 };; 166 ; 167}; 168 ; 169#endif; Configurable.",MatchSource.WIKI,doc/master/Reader_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8h_source.html
https://root.cern/doc/master/Reader_8h_source.html:6411,Availability,error,error,6411,"Double_t mvaVal=-9999999 );; 111 ; 112 // accessors; 113 virtual const char* GetName() const { return ""Reader""; }; 114 Bool_t Verbose( void ) const { return fVerbose; }; 115 void SetVerbose( Bool_t v ) { fVerbose = v; }; 116 ; 117 const DataSetInfo& DataInfo() const { return fDataSetInfo; }; 118 DataSetInfo& DataInfo() { return fDataSetInfo; }; 119 ; 120 void AddVariable( const TString& expression, Float_t* );; 121 void AddVariable( const TString& expression, Int_t* );; 122 ; 123 void AddSpectator( const TString& expression, Float_t* );; 124 void AddSpectator( const TString& expression, Int_t* );; 125 ; 126 private:; 127 ; 128 DataSetManager* fDataSetManager; // DSMTEST; 129 ; 130 ; 131 TString GetMethodTypeFromFile( const TString& filename );; 132 ; 133 // this booking method is internal; 134 IMethod* BookMVA( Types::EMVA method, const TString& weightfile );; 135 ; 136 DataSetInfo fDataSetInfo; // the data set; 137 ; 138 DataInputHandler fDataInputHandler;; 139 ; 140 // Init Reader class; 141 void Init( void );; 142 ; 143 // Decode Constructor string (or TString) and fill variable name std::vector; 144 void DecodeVarNames( const std::string& varNames );; 145 void DecodeVarNames( const TString& varNames );; 146 ; 147 void DeclareOptions();; 148 ; 149 Bool_t fVerbose; ///< verbosity; 150 Bool_t fSilent; ///< silent mode; 151 Bool_t fColor; ///< color mode; 152 Bool_t fCalculateError; ///< error calculation mode; 153 ; 154 Double_t fMvaEventError; ///< per-event error returned by MVA; 155 Double_t fMvaEventErrorUpper; ///< per-event error returned by MVA; 156 ; 157 std::map<TString, IMethod*> fMethodMap; ///< map of methods; 158 ; 159 std::vector<Float_t> fTmpEvalVec; ///< temporary evaluation vector (if user input is v<double>); 160 ; 161 mutable MsgLogger* fLogger; ///<! message logger; 162 MsgLogger& Log() const { return *fLogger; }; 163 ; 164 ClassDef(Reader,0); // Interpret the trained MVAs in an analysis context; 165 };; 166 ; 167}; 168 ; 169#endif; Configurable.",MatchSource.WIKI,doc/master/Reader_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8h_source.html
https://root.cern/doc/master/Reader_8h_source.html:6483,Availability,error,error,6483,"Double_t mvaVal=-9999999 );; 111 ; 112 // accessors; 113 virtual const char* GetName() const { return ""Reader""; }; 114 Bool_t Verbose( void ) const { return fVerbose; }; 115 void SetVerbose( Bool_t v ) { fVerbose = v; }; 116 ; 117 const DataSetInfo& DataInfo() const { return fDataSetInfo; }; 118 DataSetInfo& DataInfo() { return fDataSetInfo; }; 119 ; 120 void AddVariable( const TString& expression, Float_t* );; 121 void AddVariable( const TString& expression, Int_t* );; 122 ; 123 void AddSpectator( const TString& expression, Float_t* );; 124 void AddSpectator( const TString& expression, Int_t* );; 125 ; 126 private:; 127 ; 128 DataSetManager* fDataSetManager; // DSMTEST; 129 ; 130 ; 131 TString GetMethodTypeFromFile( const TString& filename );; 132 ; 133 // this booking method is internal; 134 IMethod* BookMVA( Types::EMVA method, const TString& weightfile );; 135 ; 136 DataSetInfo fDataSetInfo; // the data set; 137 ; 138 DataInputHandler fDataInputHandler;; 139 ; 140 // Init Reader class; 141 void Init( void );; 142 ; 143 // Decode Constructor string (or TString) and fill variable name std::vector; 144 void DecodeVarNames( const std::string& varNames );; 145 void DecodeVarNames( const TString& varNames );; 146 ; 147 void DeclareOptions();; 148 ; 149 Bool_t fVerbose; ///< verbosity; 150 Bool_t fSilent; ///< silent mode; 151 Bool_t fColor; ///< color mode; 152 Bool_t fCalculateError; ///< error calculation mode; 153 ; 154 Double_t fMvaEventError; ///< per-event error returned by MVA; 155 Double_t fMvaEventErrorUpper; ///< per-event error returned by MVA; 156 ; 157 std::map<TString, IMethod*> fMethodMap; ///< map of methods; 158 ; 159 std::vector<Float_t> fTmpEvalVec; ///< temporary evaluation vector (if user input is v<double>); 160 ; 161 mutable MsgLogger* fLogger; ///<! message logger; 162 MsgLogger& Log() const { return *fLogger; }; 163 ; 164 ClassDef(Reader,0); // Interpret the trained MVAs in an analysis context; 165 };; 166 ; 167}; 168 ; 169#endif; Configurable.",MatchSource.WIKI,doc/master/Reader_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8h_source.html
https://root.cern/doc/master/Reader_8h_source.html:9885,Availability,error,error,9885,"r.h:157; TMVA::Reader::GetNamevirtual const char * GetName() constReturns name of object.Definition Reader.h:113; TMVA::Reader::EvaluateMVADouble_t EvaluateMVA(const std::vector< Float_t > &, const TString &methodTag, Double_t aux=0)Evaluate a std::vector<float> of input data for a given method The parameter aux is obligatory for th...Definition Reader.cxx:468; TMVA::Reader::GetRarityDouble_t GetRarity(const TString &methodTag, Double_t mvaVal=-9999999)evaluates the MVA's rarityDefinition Reader.cxx:737; TMVA::Reader::FindMVAIMethod * FindMVA(const TString &methodTag)return pointer to method with tag ""methodTag""Definition Reader.cxx:695; TMVA::Reader::Initvoid Init(void)default initialisation (no member variables)Definition Reader.cxx:292; TMVA::Reader::GetProbaDouble_t GetProba(const TString &methodTag, Double_t ap_sig=0.5, Double_t mvaVal=-9999999)evaluates probability of MVA for given set of input variablesDefinition Reader.cxx:706; TMVA::Reader::fMvaEventErrorUpperDouble_t fMvaEventErrorUpperper-event error returned by MVADefinition Reader.h:155; TMVA::Reader::SetVerbosevoid SetVerbose(Bool_t v)Definition Reader.h:115; TMVA::Reader::GetMethodTypeFromFileTString GetMethodTypeFromFile(const TString &filename)read the method type from the fileDefinition Reader.cxx:337; TMVA::Reader::fDataSetManagerDataSetManager * fDataSetManagerDefinition Reader.h:128; TMVA::Reader::fColorBool_t fColorcolor modeDefinition Reader.h:151; TMVA::Reader::fDataSetInfoDataSetInfo fDataSetInfoDefinition Reader.h:136; TMVA::Reader::fVerboseBool_t fVerboseverbosityDefinition Reader.h:149; TMVA::Reader::fCalculateErrorBool_t fCalculateErrorerror calculation modeDefinition Reader.h:152; TMVA::Reader::VerboseBool_t Verbose(void) constDefinition Reader.h:114; TMVA::Reader::fMvaEventErrorDouble_t fMvaEventErrorper-event error returned by MVADefinition Reader.h:154; TMVA::Reader::fTmpEvalVecstd::vector< Float_t > fTmpEvalVectemporary evaluation vector (if user input is v<double>)Definition Reader.",MatchSource.WIKI,doc/master/Reader_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8h_source.html
https://root.cern/doc/master/Reader_8h_source.html:10686,Availability,error,error,10686,"thodTag, Double_t ap_sig=0.5, Double_t mvaVal=-9999999)evaluates probability of MVA for given set of input variablesDefinition Reader.cxx:706; TMVA::Reader::fMvaEventErrorUpperDouble_t fMvaEventErrorUpperper-event error returned by MVADefinition Reader.h:155; TMVA::Reader::SetVerbosevoid SetVerbose(Bool_t v)Definition Reader.h:115; TMVA::Reader::GetMethodTypeFromFileTString GetMethodTypeFromFile(const TString &filename)read the method type from the fileDefinition Reader.cxx:337; TMVA::Reader::fDataSetManagerDataSetManager * fDataSetManagerDefinition Reader.h:128; TMVA::Reader::fColorBool_t fColorcolor modeDefinition Reader.h:151; TMVA::Reader::fDataSetInfoDataSetInfo fDataSetInfoDefinition Reader.h:136; TMVA::Reader::fVerboseBool_t fVerboseverbosityDefinition Reader.h:149; TMVA::Reader::fCalculateErrorBool_t fCalculateErrorerror calculation modeDefinition Reader.h:152; TMVA::Reader::VerboseBool_t Verbose(void) constDefinition Reader.h:114; TMVA::Reader::fMvaEventErrorDouble_t fMvaEventErrorper-event error returned by MVADefinition Reader.h:154; TMVA::Reader::fTmpEvalVecstd::vector< Float_t > fTmpEvalVectemporary evaluation vector (if user input is v<double>)Definition Reader.h:159; TMVA::Reader::BookMVAIMethod * BookMVA(const TString &methodTag, const TString &weightfile)read method name from weight fileDefinition Reader.cxx:368; TMVA::Reader::EvaluateMulticlassconst std::vector< Float_t > & EvaluateMulticlass(const TString &methodTag, Double_t aux=0)evaluates MVA for given set of input variablesDefinition Reader.cxx:630; TMVA::Reader::GetMVAErrorUpperDouble_t GetMVAErrorUpper() constDefinition Reader.h:96; TMVA::Reader::LogMsgLogger & Log() constDefinition Reader.h:162; TMVA::Reader::GetMVAErrorLowerDouble_t GetMVAErrorLower() constDefinition Reader.h:95; TMVA::Reader::DataInfoDataSetInfo & DataInfo()Definition Reader.h:118; TMVA::Reader::fDataInputHandlerDataInputHandler fDataInputHandlerDefinition Reader.h:138; TMVA::Reader::DecodeVarNamesvoid DecodeVarNames(const",MatchSource.WIKI,doc/master/Reader_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8h_source.html
https://root.cern/doc/master/Reader_8h_source.html:437,Deployability,integrat,integrated,437,". ROOT: tmva/tmva/inc/TMVA/Reader.h Source File. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. Reader.h. Go to the documentation of this file. 1// @(#)root/tmva $Id$; 2// Author: Andreas Hoecker, Peter Speckmayer, Joerg Stelzer, Helge Voss, Kai Voss, Eckhard von Toerne, Jan Therhaag; 3 ; 4/**********************************************************************************; 5 * Project: TMVA - a Root-integrated toolkit for multivariate data analysis *; 6 * Package: TMVA *; 7 * Class : Reader *; 8 * *; 9 * *; 10 * Description: *; 11 * Reader class to be used in the user application to interpret the trained *; 12 * MVAs in an analysis context *; 13 * *; 14 * Authors (alphabetical order): *; 15 * Andreas Hoecker <Andreas.Hocker@cern.ch> - CERN, Switzerland *; 16 * Peter Speckmayer <peter.speckmayer@cern.ch> - CERN, Switzerland *; 17 * Joerg Stelzer <Joerg.Stelzer@cern.ch> - CERN, Switzerland *; 18 * Jan Therhaag <Jan.Therhaag@cern.ch> - U of Bonn, Germany *; 19 * Eckhard v. Toerne <evt@uni-bonn.de> - U of Bonn, Germany *; 20 * Helge Voss <Helge.Voss@cern.ch> - MPI-K Heidelberg, Germany *; 21 * Kai Voss <Kai.Voss@cern.ch> - U. of Victoria, Canada *; 22 * *; 23 * Copyright (c) 2005-2011: *; 24 * CERN, Switzerland *; 25 * U. of Victoria, Canada *; 26 * MPI-K Heidelberg, Germany *; 27 * U. of Bonn, Germany *; 28 * *; 29 * Redistribution and use in source and binary forms, with or without *; 30 * modification, are permitted according to the terms listed in LICENSE *; 31 * (see tmva/doc/LICENSE) *; 32 **********************************************************************************/; 33 ; 34#ifndef ROOT_TMVA_Reader; 35#define ROOT_TMVA_Reader; 36 ; 37//////////////////////////////////////////////////////////////////////////; 38// //; 39// Reader //; 40// //; 41// Reader class to be used in the user application to interpret the //; 42// trained MVAs in an analysis context //; 43// //; 44/////////////////////////////////////////////////////////",MatchSource.WIKI,doc/master/Reader_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8h_source.html
https://root.cern/doc/master/Reader_8h_source.html:11887,Deployability,configurat,configuration,11887," TMVA::Reader::BookMVAIMethod * BookMVA(const TString &methodTag, const TString &weightfile)read method name from weight fileDefinition Reader.cxx:368; TMVA::Reader::EvaluateMulticlassconst std::vector< Float_t > & EvaluateMulticlass(const TString &methodTag, Double_t aux=0)evaluates MVA for given set of input variablesDefinition Reader.cxx:630; TMVA::Reader::GetMVAErrorUpperDouble_t GetMVAErrorUpper() constDefinition Reader.h:96; TMVA::Reader::LogMsgLogger & Log() constDefinition Reader.h:162; TMVA::Reader::GetMVAErrorLowerDouble_t GetMVAErrorLower() constDefinition Reader.h:95; TMVA::Reader::DataInfoDataSetInfo & DataInfo()Definition Reader.h:118; TMVA::Reader::fDataInputHandlerDataInputHandler fDataInputHandlerDefinition Reader.h:138; TMVA::Reader::DecodeVarNamesvoid DecodeVarNames(const std::string &varNames)decodes ""name1:name2:..."" formDefinition Reader.cxx:772; TMVA::Reader::fSilentBool_t fSilentsilent modeDefinition Reader.h:150; TMVA::Reader::DeclareOptionsvoid DeclareOptions()declaration of configuration optionsDefinition Reader.cxx:264; TMVA::Reader::AddSpectatorvoid AddSpectator(const TString &expression, Float_t *)Add a float spectator or expression to the reader.Definition Reader.cxx:321; TMVA::Reader::AddVariablevoid AddVariable(const TString &expression, Float_t *)Add a float variable or expression to the reader.Definition Reader.cxx:303; TMVA::Reader::~Readervirtual ~Reader(void)destructorDefinition Reader.cxx:277; TMVA::Reader::fLoggerMsgLogger * fLogger! message loggerDefinition Reader.h:161; TMVA::Reader::DataInfoconst DataSetInfo & DataInfo() constDefinition Reader.h:117; TMVA::Reader::GetMVAErrorDouble_t GetMVAError() constDefinition Reader.h:94; TMVA::Types::EMVAEMVADefinition Types.h:76; TStringBasic string class.Definition TString.h:139; bool; double; int; TMVAcreate variable transformationsDefinition GeneticMinimizer.h:22; v@ vDefinition rootcling_impl.cxx:3699; Types.h. tmvatmvaincTMVAReader.h. ROOT master - Reference Guide Generated on Tu",MatchSource.WIKI,doc/master/Reader_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8h_source.html
https://root.cern/doc/master/Reader_8h_source.html:437,Integrability,integrat,integrated,437,". ROOT: tmva/tmva/inc/TMVA/Reader.h Source File. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. Reader.h. Go to the documentation of this file. 1// @(#)root/tmva $Id$; 2// Author: Andreas Hoecker, Peter Speckmayer, Joerg Stelzer, Helge Voss, Kai Voss, Eckhard von Toerne, Jan Therhaag; 3 ; 4/**********************************************************************************; 5 * Project: TMVA - a Root-integrated toolkit for multivariate data analysis *; 6 * Package: TMVA *; 7 * Class : Reader *; 8 * *; 9 * *; 10 * Description: *; 11 * Reader class to be used in the user application to interpret the trained *; 12 * MVAs in an analysis context *; 13 * *; 14 * Authors (alphabetical order): *; 15 * Andreas Hoecker <Andreas.Hocker@cern.ch> - CERN, Switzerland *; 16 * Peter Speckmayer <peter.speckmayer@cern.ch> - CERN, Switzerland *; 17 * Joerg Stelzer <Joerg.Stelzer@cern.ch> - CERN, Switzerland *; 18 * Jan Therhaag <Jan.Therhaag@cern.ch> - U of Bonn, Germany *; 19 * Eckhard v. Toerne <evt@uni-bonn.de> - U of Bonn, Germany *; 20 * Helge Voss <Helge.Voss@cern.ch> - MPI-K Heidelberg, Germany *; 21 * Kai Voss <Kai.Voss@cern.ch> - U. of Victoria, Canada *; 22 * *; 23 * Copyright (c) 2005-2011: *; 24 * CERN, Switzerland *; 25 * U. of Victoria, Canada *; 26 * MPI-K Heidelberg, Germany *; 27 * U. of Bonn, Germany *; 28 * *; 29 * Redistribution and use in source and binary forms, with or without *; 30 * modification, are permitted according to the terms listed in LICENSE *; 31 * (see tmva/doc/LICENSE) *; 32 **********************************************************************************/; 33 ; 34#ifndef ROOT_TMVA_Reader; 35#define ROOT_TMVA_Reader; 36 ; 37//////////////////////////////////////////////////////////////////////////; 38// //; 39// Reader //; 40// //; 41// Reader class to be used in the user application to interpret the //; 42// trained MVAs in an analysis context //; 43// //; 44/////////////////////////////////////////////////////////",MatchSource.WIKI,doc/master/Reader_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8h_source.html
https://root.cern/doc/master/Reader_8h_source.html:6728,Integrability,message,message,6728,"Double_t mvaVal=-9999999 );; 111 ; 112 // accessors; 113 virtual const char* GetName() const { return ""Reader""; }; 114 Bool_t Verbose( void ) const { return fVerbose; }; 115 void SetVerbose( Bool_t v ) { fVerbose = v; }; 116 ; 117 const DataSetInfo& DataInfo() const { return fDataSetInfo; }; 118 DataSetInfo& DataInfo() { return fDataSetInfo; }; 119 ; 120 void AddVariable( const TString& expression, Float_t* );; 121 void AddVariable( const TString& expression, Int_t* );; 122 ; 123 void AddSpectator( const TString& expression, Float_t* );; 124 void AddSpectator( const TString& expression, Int_t* );; 125 ; 126 private:; 127 ; 128 DataSetManager* fDataSetManager; // DSMTEST; 129 ; 130 ; 131 TString GetMethodTypeFromFile( const TString& filename );; 132 ; 133 // this booking method is internal; 134 IMethod* BookMVA( Types::EMVA method, const TString& weightfile );; 135 ; 136 DataSetInfo fDataSetInfo; // the data set; 137 ; 138 DataInputHandler fDataInputHandler;; 139 ; 140 // Init Reader class; 141 void Init( void );; 142 ; 143 // Decode Constructor string (or TString) and fill variable name std::vector; 144 void DecodeVarNames( const std::string& varNames );; 145 void DecodeVarNames( const TString& varNames );; 146 ; 147 void DeclareOptions();; 148 ; 149 Bool_t fVerbose; ///< verbosity; 150 Bool_t fSilent; ///< silent mode; 151 Bool_t fColor; ///< color mode; 152 Bool_t fCalculateError; ///< error calculation mode; 153 ; 154 Double_t fMvaEventError; ///< per-event error returned by MVA; 155 Double_t fMvaEventErrorUpper; ///< per-event error returned by MVA; 156 ; 157 std::map<TString, IMethod*> fMethodMap; ///< map of methods; 158 ; 159 std::vector<Float_t> fTmpEvalVec; ///< temporary evaluation vector (if user input is v<double>); 160 ; 161 mutable MsgLogger* fLogger; ///<! message logger; 162 MsgLogger& Log() const { return *fLogger; }; 163 ; 164 ClassDef(Reader,0); // Interpret the trained MVAs in an analysis context; 165 };; 166 ; 167}; 168 ; 169#endif; Configurable.",MatchSource.WIKI,doc/master/Reader_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8h_source.html
https://root.cern/doc/master/Reader_8h_source.html:12369,Integrability,message,message,12369,"odTag, const TString &weightfile)read method name from weight fileDefinition Reader.cxx:368; TMVA::Reader::EvaluateMulticlassconst std::vector< Float_t > & EvaluateMulticlass(const TString &methodTag, Double_t aux=0)evaluates MVA for given set of input variablesDefinition Reader.cxx:630; TMVA::Reader::GetMVAErrorUpperDouble_t GetMVAErrorUpper() constDefinition Reader.h:96; TMVA::Reader::LogMsgLogger & Log() constDefinition Reader.h:162; TMVA::Reader::GetMVAErrorLowerDouble_t GetMVAErrorLower() constDefinition Reader.h:95; TMVA::Reader::DataInfoDataSetInfo & DataInfo()Definition Reader.h:118; TMVA::Reader::fDataInputHandlerDataInputHandler fDataInputHandlerDefinition Reader.h:138; TMVA::Reader::DecodeVarNamesvoid DecodeVarNames(const std::string &varNames)decodes ""name1:name2:..."" formDefinition Reader.cxx:772; TMVA::Reader::fSilentBool_t fSilentsilent modeDefinition Reader.h:150; TMVA::Reader::DeclareOptionsvoid DeclareOptions()declaration of configuration optionsDefinition Reader.cxx:264; TMVA::Reader::AddSpectatorvoid AddSpectator(const TString &expression, Float_t *)Add a float spectator or expression to the reader.Definition Reader.cxx:321; TMVA::Reader::AddVariablevoid AddVariable(const TString &expression, Float_t *)Add a float variable or expression to the reader.Definition Reader.cxx:303; TMVA::Reader::~Readervirtual ~Reader(void)destructorDefinition Reader.cxx:277; TMVA::Reader::fLoggerMsgLogger * fLogger! message loggerDefinition Reader.h:161; TMVA::Reader::DataInfoconst DataSetInfo & DataInfo() constDefinition Reader.h:117; TMVA::Reader::GetMVAErrorDouble_t GetMVAError() constDefinition Reader.h:94; TMVA::Types::EMVAEMVADefinition Types.h:76; TStringBasic string class.Definition TString.h:139; bool; double; int; TMVAcreate variable transformationsDefinition GeneticMinimizer.h:22; v@ vDefinition rootcling_impl.cxx:3699; Types.h. tmvatmvaincTMVAReader.h. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:40:58 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/Reader_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8h_source.html
https://root.cern/doc/master/Reader_8h_source.html:2503,Modifiability,variab,variables,2503,"ed in LICENSE *; 31 * (see tmva/doc/LICENSE) *; 32 **********************************************************************************/; 33 ; 34#ifndef ROOT_TMVA_Reader; 35#define ROOT_TMVA_Reader; 36 ; 37//////////////////////////////////////////////////////////////////////////; 38// //; 39// Reader //; 40// //; 41// Reader class to be used in the user application to interpret the //; 42// trained MVAs in an analysis context //; 43// //; 44//////////////////////////////////////////////////////////////////////////; 45 ; 46#include ""TMVA/Configurable.h""; 47#include ""TMVA/Types.h""; 48#include ""TMVA/DataSetInfo.h""; 49#include ""TMVA/DataInputHandler.h""; 50#include ""TMVA/DataSetManager.h""; 51 ; 52#include <vector>; 53#include <map>; 54#include <stdexcept>; 55#include <string>; 56 ; 57namespace TMVA {; 58 ; 59 class IMethod;; 60 class MethodBase;; 61 class DataSetInfo;; 62 class MethodCuts;; 63 ; 64 class Reader : public Configurable {; 65 ; 66 public:; 67 ; 68 // without prior specification of variables; 69 Reader( const TString& theOption="""", Bool_t verbose = 0 );; 70 ; 71 // STL types; 72 Reader( std::vector<std::string>& varNames, const TString& theOption = """", Bool_t verbose = 0 );; 73 Reader( const std::string& varNames, const TString& theOption, Bool_t verbose = 0 ); // format: ""var1:var2:...""; 74 ; 75 // Root types; 76 Reader( std::vector<TString>& varNames, const TString& theOption = """", Bool_t verbose = 0 );; 77 Reader( const TString& varNames, const TString& theOption, Bool_t verbose = 0 ); // format: ""var1:var2:...""; 78 ; 79 virtual ~Reader( void );; 80 ; 81 // book MVA method via weight file; 82 IMethod* BookMVA( const TString& methodTag, const TString& weightfile );; 83 IMethod* BookMVA( TMVA::Types::EMVA methodType, const char* xmlstr );; 84 IMethod* FindMVA( const TString& methodTag );; 85 ; 86 // returns the MVA response for given event; 87 Double_t EvaluateMVA( const std::vector<Float_t> &, const TString& methodTag, Double_t aux = 0 );; 88 Double_t Evalua",MatchSource.WIKI,doc/master/Reader_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8h_source.html
https://root.cern/doc/master/Reader_8h_source.html:6016,Modifiability,variab,variable,6016,"Double_t mvaVal=-9999999 );; 111 ; 112 // accessors; 113 virtual const char* GetName() const { return ""Reader""; }; 114 Bool_t Verbose( void ) const { return fVerbose; }; 115 void SetVerbose( Bool_t v ) { fVerbose = v; }; 116 ; 117 const DataSetInfo& DataInfo() const { return fDataSetInfo; }; 118 DataSetInfo& DataInfo() { return fDataSetInfo; }; 119 ; 120 void AddVariable( const TString& expression, Float_t* );; 121 void AddVariable( const TString& expression, Int_t* );; 122 ; 123 void AddSpectator( const TString& expression, Float_t* );; 124 void AddSpectator( const TString& expression, Int_t* );; 125 ; 126 private:; 127 ; 128 DataSetManager* fDataSetManager; // DSMTEST; 129 ; 130 ; 131 TString GetMethodTypeFromFile( const TString& filename );; 132 ; 133 // this booking method is internal; 134 IMethod* BookMVA( Types::EMVA method, const TString& weightfile );; 135 ; 136 DataSetInfo fDataSetInfo; // the data set; 137 ; 138 DataInputHandler fDataInputHandler;; 139 ; 140 // Init Reader class; 141 void Init( void );; 142 ; 143 // Decode Constructor string (or TString) and fill variable name std::vector; 144 void DecodeVarNames( const std::string& varNames );; 145 void DecodeVarNames( const TString& varNames );; 146 ; 147 void DeclareOptions();; 148 ; 149 Bool_t fVerbose; ///< verbosity; 150 Bool_t fSilent; ///< silent mode; 151 Bool_t fColor; ///< color mode; 152 Bool_t fCalculateError; ///< error calculation mode; 153 ; 154 Double_t fMvaEventError; ///< per-event error returned by MVA; 155 Double_t fMvaEventErrorUpper; ///< per-event error returned by MVA; 156 ; 157 std::map<TString, IMethod*> fMethodMap; ///< map of methods; 158 ; 159 std::vector<Float_t> fTmpEvalVec; ///< temporary evaluation vector (if user input is v<double>); 160 ; 161 mutable MsgLogger* fLogger; ///<! message logger; 162 MsgLogger& Log() const { return *fLogger; }; 163 ; 164 ClassDef(Reader,0); // Interpret the trained MVAs in an analysis context; 165 };; 166 ; 167}; 168 ; 169#endif; Configurable.",MatchSource.WIKI,doc/master/Reader_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8h_source.html
https://root.cern/doc/master/Reader_8h_source.html:8733,Modifiability,variab,variablesDefinition,8733," const char only_if_exist regb h Point_t winding char text const char depth char const char Int_t count const char ColorStruct_t color const char filenameDefinition TGWin32VirtualXProxy.cxx:232; TMVA::ConfigurableDefinition Configurable.h:45; TMVA::DataInputHandlerClass that contains all the data information.Definition DataInputHandler.h:78; TMVA::DataSetInfoClass that contains all the data information.Definition DataSetInfo.h:62; TMVA::DataSetManagerClass that contains all the data information.Definition DataSetManager.h:51; TMVA::IMethodInterface for all concrete MVA method implementations.Definition IMethod.h:53; TMVA::MethodBaseVirtual base Class for all MVA method.Definition MethodBase.h:111; TMVA::MsgLoggerostringstream derivative to redirect and format outputDefinition MsgLogger.h:57; TMVA::ReaderThe Reader class serves to use the MVAs in a specific analysis context.Definition Reader.h:64; TMVA::Reader::EvaluateRegressionconst std::vector< Float_t > & EvaluateRegression(const TString &methodTag, Double_t aux=0)evaluates MVA for given set of input variablesDefinition Reader.cxx:565; TMVA::Reader::fMethodMapstd::map< TString, IMethod * > fMethodMapmap of methodsDefinition Reader.h:157; TMVA::Reader::GetNamevirtual const char * GetName() constReturns name of object.Definition Reader.h:113; TMVA::Reader::EvaluateMVADouble_t EvaluateMVA(const std::vector< Float_t > &, const TString &methodTag, Double_t aux=0)Evaluate a std::vector<float> of input data for a given method The parameter aux is obligatory for th...Definition Reader.cxx:468; TMVA::Reader::GetRarityDouble_t GetRarity(const TString &methodTag, Double_t mvaVal=-9999999)evaluates the MVA's rarityDefinition Reader.cxx:737; TMVA::Reader::FindMVAIMethod * FindMVA(const TString &methodTag)return pointer to method with tag ""methodTag""Definition Reader.cxx:695; TMVA::Reader::Initvoid Init(void)default initialisation (no member variables)Definition Reader.cxx:292; TMVA::Reader::GetProbaDouble_t GetProba(const TStr",MatchSource.WIKI,doc/master/Reader_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8h_source.html
https://root.cern/doc/master/Reader_8h_source.html:9577,Modifiability,variab,variables,9577,"nition Reader.h:64; TMVA::Reader::EvaluateRegressionconst std::vector< Float_t > & EvaluateRegression(const TString &methodTag, Double_t aux=0)evaluates MVA for given set of input variablesDefinition Reader.cxx:565; TMVA::Reader::fMethodMapstd::map< TString, IMethod * > fMethodMapmap of methodsDefinition Reader.h:157; TMVA::Reader::GetNamevirtual const char * GetName() constReturns name of object.Definition Reader.h:113; TMVA::Reader::EvaluateMVADouble_t EvaluateMVA(const std::vector< Float_t > &, const TString &methodTag, Double_t aux=0)Evaluate a std::vector<float> of input data for a given method The parameter aux is obligatory for th...Definition Reader.cxx:468; TMVA::Reader::GetRarityDouble_t GetRarity(const TString &methodTag, Double_t mvaVal=-9999999)evaluates the MVA's rarityDefinition Reader.cxx:737; TMVA::Reader::FindMVAIMethod * FindMVA(const TString &methodTag)return pointer to method with tag ""methodTag""Definition Reader.cxx:695; TMVA::Reader::Initvoid Init(void)default initialisation (no member variables)Definition Reader.cxx:292; TMVA::Reader::GetProbaDouble_t GetProba(const TString &methodTag, Double_t ap_sig=0.5, Double_t mvaVal=-9999999)evaluates probability of MVA for given set of input variablesDefinition Reader.cxx:706; TMVA::Reader::fMvaEventErrorUpperDouble_t fMvaEventErrorUpperper-event error returned by MVADefinition Reader.h:155; TMVA::Reader::SetVerbosevoid SetVerbose(Bool_t v)Definition Reader.h:115; TMVA::Reader::GetMethodTypeFromFileTString GetMethodTypeFromFile(const TString &filename)read the method type from the fileDefinition Reader.cxx:337; TMVA::Reader::fDataSetManagerDataSetManager * fDataSetManagerDefinition Reader.h:128; TMVA::Reader::fColorBool_t fColorcolor modeDefinition Reader.h:151; TMVA::Reader::fDataSetInfoDataSetInfo fDataSetInfoDefinition Reader.h:136; TMVA::Reader::fVerboseBool_t fVerboseverbosityDefinition Reader.h:149; TMVA::Reader::fCalculateErrorBool_t fCalculateErrorerror calculation modeDefinition Reader.h:152; ",MatchSource.WIKI,doc/master/Reader_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8h_source.html
https://root.cern/doc/master/Reader_8h_source.html:9778,Modifiability,variab,variablesDefinition,9778,"n Reader.cxx:565; TMVA::Reader::fMethodMapstd::map< TString, IMethod * > fMethodMapmap of methodsDefinition Reader.h:157; TMVA::Reader::GetNamevirtual const char * GetName() constReturns name of object.Definition Reader.h:113; TMVA::Reader::EvaluateMVADouble_t EvaluateMVA(const std::vector< Float_t > &, const TString &methodTag, Double_t aux=0)Evaluate a std::vector<float> of input data for a given method The parameter aux is obligatory for th...Definition Reader.cxx:468; TMVA::Reader::GetRarityDouble_t GetRarity(const TString &methodTag, Double_t mvaVal=-9999999)evaluates the MVA's rarityDefinition Reader.cxx:737; TMVA::Reader::FindMVAIMethod * FindMVA(const TString &methodTag)return pointer to method with tag ""methodTag""Definition Reader.cxx:695; TMVA::Reader::Initvoid Init(void)default initialisation (no member variables)Definition Reader.cxx:292; TMVA::Reader::GetProbaDouble_t GetProba(const TString &methodTag, Double_t ap_sig=0.5, Double_t mvaVal=-9999999)evaluates probability of MVA for given set of input variablesDefinition Reader.cxx:706; TMVA::Reader::fMvaEventErrorUpperDouble_t fMvaEventErrorUpperper-event error returned by MVADefinition Reader.h:155; TMVA::Reader::SetVerbosevoid SetVerbose(Bool_t v)Definition Reader.h:115; TMVA::Reader::GetMethodTypeFromFileTString GetMethodTypeFromFile(const TString &filename)read the method type from the fileDefinition Reader.cxx:337; TMVA::Reader::fDataSetManagerDataSetManager * fDataSetManagerDefinition Reader.h:128; TMVA::Reader::fColorBool_t fColorcolor modeDefinition Reader.h:151; TMVA::Reader::fDataSetInfoDataSetInfo fDataSetInfoDefinition Reader.h:136; TMVA::Reader::fVerboseBool_t fVerboseverbosityDefinition Reader.h:149; TMVA::Reader::fCalculateErrorBool_t fCalculateErrorerror calculation modeDefinition Reader.h:152; TMVA::Reader::VerboseBool_t Verbose(void) constDefinition Reader.h:114; TMVA::Reader::fMvaEventErrorDouble_t fMvaEventErrorper-event error returned by MVADefinition Reader.h:154; TMVA::Reader::fTmpEv",MatchSource.WIKI,doc/master/Reader_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8h_source.html
https://root.cern/doc/master/Reader_8h_source.html:11183,Modifiability,variab,variablesDefinition,11183,"pe from the fileDefinition Reader.cxx:337; TMVA::Reader::fDataSetManagerDataSetManager * fDataSetManagerDefinition Reader.h:128; TMVA::Reader::fColorBool_t fColorcolor modeDefinition Reader.h:151; TMVA::Reader::fDataSetInfoDataSetInfo fDataSetInfoDefinition Reader.h:136; TMVA::Reader::fVerboseBool_t fVerboseverbosityDefinition Reader.h:149; TMVA::Reader::fCalculateErrorBool_t fCalculateErrorerror calculation modeDefinition Reader.h:152; TMVA::Reader::VerboseBool_t Verbose(void) constDefinition Reader.h:114; TMVA::Reader::fMvaEventErrorDouble_t fMvaEventErrorper-event error returned by MVADefinition Reader.h:154; TMVA::Reader::fTmpEvalVecstd::vector< Float_t > fTmpEvalVectemporary evaluation vector (if user input is v<double>)Definition Reader.h:159; TMVA::Reader::BookMVAIMethod * BookMVA(const TString &methodTag, const TString &weightfile)read method name from weight fileDefinition Reader.cxx:368; TMVA::Reader::EvaluateMulticlassconst std::vector< Float_t > & EvaluateMulticlass(const TString &methodTag, Double_t aux=0)evaluates MVA for given set of input variablesDefinition Reader.cxx:630; TMVA::Reader::GetMVAErrorUpperDouble_t GetMVAErrorUpper() constDefinition Reader.h:96; TMVA::Reader::LogMsgLogger & Log() constDefinition Reader.h:162; TMVA::Reader::GetMVAErrorLowerDouble_t GetMVAErrorLower() constDefinition Reader.h:95; TMVA::Reader::DataInfoDataSetInfo & DataInfo()Definition Reader.h:118; TMVA::Reader::fDataInputHandlerDataInputHandler fDataInputHandlerDefinition Reader.h:138; TMVA::Reader::DecodeVarNamesvoid DecodeVarNames(const std::string &varNames)decodes ""name1:name2:..."" formDefinition Reader.cxx:772; TMVA::Reader::fSilentBool_t fSilentsilent modeDefinition Reader.h:150; TMVA::Reader::DeclareOptionsvoid DeclareOptions()declaration of configuration optionsDefinition Reader.cxx:264; TMVA::Reader::AddSpectatorvoid AddSpectator(const TString &expression, Float_t *)Add a float spectator or expression to the reader.Definition Reader.cxx:321; TMVA::Reader::AddVa",MatchSource.WIKI,doc/master/Reader_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8h_source.html
https://root.cern/doc/master/Reader_8h_source.html:11887,Modifiability,config,configuration,11887," TMVA::Reader::BookMVAIMethod * BookMVA(const TString &methodTag, const TString &weightfile)read method name from weight fileDefinition Reader.cxx:368; TMVA::Reader::EvaluateMulticlassconst std::vector< Float_t > & EvaluateMulticlass(const TString &methodTag, Double_t aux=0)evaluates MVA for given set of input variablesDefinition Reader.cxx:630; TMVA::Reader::GetMVAErrorUpperDouble_t GetMVAErrorUpper() constDefinition Reader.h:96; TMVA::Reader::LogMsgLogger & Log() constDefinition Reader.h:162; TMVA::Reader::GetMVAErrorLowerDouble_t GetMVAErrorLower() constDefinition Reader.h:95; TMVA::Reader::DataInfoDataSetInfo & DataInfo()Definition Reader.h:118; TMVA::Reader::fDataInputHandlerDataInputHandler fDataInputHandlerDefinition Reader.h:138; TMVA::Reader::DecodeVarNamesvoid DecodeVarNames(const std::string &varNames)decodes ""name1:name2:..."" formDefinition Reader.cxx:772; TMVA::Reader::fSilentBool_t fSilentsilent modeDefinition Reader.h:150; TMVA::Reader::DeclareOptionsvoid DeclareOptions()declaration of configuration optionsDefinition Reader.cxx:264; TMVA::Reader::AddSpectatorvoid AddSpectator(const TString &expression, Float_t *)Add a float spectator or expression to the reader.Definition Reader.cxx:321; TMVA::Reader::AddVariablevoid AddVariable(const TString &expression, Float_t *)Add a float variable or expression to the reader.Definition Reader.cxx:303; TMVA::Reader::~Readervirtual ~Reader(void)destructorDefinition Reader.cxx:277; TMVA::Reader::fLoggerMsgLogger * fLogger! message loggerDefinition Reader.h:161; TMVA::Reader::DataInfoconst DataSetInfo & DataInfo() constDefinition Reader.h:117; TMVA::Reader::GetMVAErrorDouble_t GetMVAError() constDefinition Reader.h:94; TMVA::Types::EMVAEMVADefinition Types.h:76; TStringBasic string class.Definition TString.h:139; bool; double; int; TMVAcreate variable transformationsDefinition GeneticMinimizer.h:22; v@ vDefinition rootcling_impl.cxx:3699; Types.h. tmvatmvaincTMVAReader.h. ROOT master - Reference Guide Generated on Tu",MatchSource.WIKI,doc/master/Reader_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8h_source.html
https://root.cern/doc/master/Reader_8h_source.html:12184,Modifiability,variab,variable,12184,"odTag, const TString &weightfile)read method name from weight fileDefinition Reader.cxx:368; TMVA::Reader::EvaluateMulticlassconst std::vector< Float_t > & EvaluateMulticlass(const TString &methodTag, Double_t aux=0)evaluates MVA for given set of input variablesDefinition Reader.cxx:630; TMVA::Reader::GetMVAErrorUpperDouble_t GetMVAErrorUpper() constDefinition Reader.h:96; TMVA::Reader::LogMsgLogger & Log() constDefinition Reader.h:162; TMVA::Reader::GetMVAErrorLowerDouble_t GetMVAErrorLower() constDefinition Reader.h:95; TMVA::Reader::DataInfoDataSetInfo & DataInfo()Definition Reader.h:118; TMVA::Reader::fDataInputHandlerDataInputHandler fDataInputHandlerDefinition Reader.h:138; TMVA::Reader::DecodeVarNamesvoid DecodeVarNames(const std::string &varNames)decodes ""name1:name2:..."" formDefinition Reader.cxx:772; TMVA::Reader::fSilentBool_t fSilentsilent modeDefinition Reader.h:150; TMVA::Reader::DeclareOptionsvoid DeclareOptions()declaration of configuration optionsDefinition Reader.cxx:264; TMVA::Reader::AddSpectatorvoid AddSpectator(const TString &expression, Float_t *)Add a float spectator or expression to the reader.Definition Reader.cxx:321; TMVA::Reader::AddVariablevoid AddVariable(const TString &expression, Float_t *)Add a float variable or expression to the reader.Definition Reader.cxx:303; TMVA::Reader::~Readervirtual ~Reader(void)destructorDefinition Reader.cxx:277; TMVA::Reader::fLoggerMsgLogger * fLogger! message loggerDefinition Reader.h:161; TMVA::Reader::DataInfoconst DataSetInfo & DataInfo() constDefinition Reader.h:117; TMVA::Reader::GetMVAErrorDouble_t GetMVAError() constDefinition Reader.h:94; TMVA::Types::EMVAEMVADefinition Types.h:76; TStringBasic string class.Definition TString.h:139; bool; double; int; TMVAcreate variable transformationsDefinition GeneticMinimizer.h:22; v@ vDefinition rootcling_impl.cxx:3699; Types.h. tmvatmvaincTMVAReader.h. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:40:58 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/Reader_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8h_source.html
https://root.cern/doc/master/Reader_8h_source.html:12694,Modifiability,variab,variable,12694,"odTag, const TString &weightfile)read method name from weight fileDefinition Reader.cxx:368; TMVA::Reader::EvaluateMulticlassconst std::vector< Float_t > & EvaluateMulticlass(const TString &methodTag, Double_t aux=0)evaluates MVA for given set of input variablesDefinition Reader.cxx:630; TMVA::Reader::GetMVAErrorUpperDouble_t GetMVAErrorUpper() constDefinition Reader.h:96; TMVA::Reader::LogMsgLogger & Log() constDefinition Reader.h:162; TMVA::Reader::GetMVAErrorLowerDouble_t GetMVAErrorLower() constDefinition Reader.h:95; TMVA::Reader::DataInfoDataSetInfo & DataInfo()Definition Reader.h:118; TMVA::Reader::fDataInputHandlerDataInputHandler fDataInputHandlerDefinition Reader.h:138; TMVA::Reader::DecodeVarNamesvoid DecodeVarNames(const std::string &varNames)decodes ""name1:name2:..."" formDefinition Reader.cxx:772; TMVA::Reader::fSilentBool_t fSilentsilent modeDefinition Reader.h:150; TMVA::Reader::DeclareOptionsvoid DeclareOptions()declaration of configuration optionsDefinition Reader.cxx:264; TMVA::Reader::AddSpectatorvoid AddSpectator(const TString &expression, Float_t *)Add a float spectator or expression to the reader.Definition Reader.cxx:321; TMVA::Reader::AddVariablevoid AddVariable(const TString &expression, Float_t *)Add a float variable or expression to the reader.Definition Reader.cxx:303; TMVA::Reader::~Readervirtual ~Reader(void)destructorDefinition Reader.cxx:277; TMVA::Reader::fLoggerMsgLogger * fLogger! message loggerDefinition Reader.h:161; TMVA::Reader::DataInfoconst DataSetInfo & DataInfo() constDefinition Reader.h:117; TMVA::Reader::GetMVAErrorDouble_t GetMVAError() constDefinition Reader.h:94; TMVA::Types::EMVAEMVADefinition Types.h:76; TStringBasic string class.Definition TString.h:139; bool; double; int; TMVAcreate variable transformationsDefinition GeneticMinimizer.h:22; v@ vDefinition rootcling_impl.cxx:3699; Types.h. tmvatmvaincTMVAReader.h. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:40:58 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/Reader_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8h_source.html
https://root.cern/doc/master/Reader_8h_source.html:4722,Security,access,accessors,4722,"/ returns the MVA response for given event; 87 Double_t EvaluateMVA( const std::vector<Float_t> &, const TString& methodTag, Double_t aux = 0 );; 88 Double_t EvaluateMVA( const std::vector<Double_t>&, const TString& methodTag, Double_t aux = 0 );; 89 Double_t EvaluateMVA( MethodBase* method, Double_t aux = 0 );; 90 Double_t EvaluateMVA( const TString& methodTag, Double_t aux = 0 );; 91 ; 92 // returns error on MVA response for given event; 93 // NOTE: must be called AFTER ""EvaluateMVA(...)"" call !; 94 Double_t GetMVAError() const { return fMvaEventError; }; 95 Double_t GetMVAErrorLower() const { return fMvaEventError; }; 96 Double_t GetMVAErrorUpper() const { return fMvaEventErrorUpper; }; 97 ; 98 // regression response; 99 const std::vector< Float_t >& EvaluateRegression( const TString& methodTag, Double_t aux = 0 );; 100 const std::vector< Float_t >& EvaluateRegression( MethodBase* method, Double_t aux = 0 );; 101 Float_t EvaluateRegression( UInt_t tgtNumber, const TString& methodTag, Double_t aux = 0 );; 102 ; 103 // multiclass response; 104 const std::vector< Float_t >& EvaluateMulticlass( const TString& methodTag, Double_t aux = 0 );; 105 const std::vector< Float_t >& EvaluateMulticlass( MethodBase* method, Double_t aux = 0 );; 106 Float_t EvaluateMulticlass( UInt_t clsNumber, const TString& methodTag, Double_t aux = 0 );; 107 ; 108 // probability and rarity accessors (see Users Guide for definition of Rarity); 109 Double_t GetProba ( const TString& methodTag, Double_t ap_sig=0.5, Double_t mvaVal=-9999999 );; 110 Double_t GetRarity( const TString& methodTag, Double_t mvaVal=-9999999 );; 111 ; 112 // accessors; 113 virtual const char* GetName() const { return ""Reader""; }; 114 Bool_t Verbose( void ) const { return fVerbose; }; 115 void SetVerbose( Bool_t v ) { fVerbose = v; }; 116 ; 117 const DataSetInfo& DataInfo() const { return fDataSetInfo; }; 118 DataSetInfo& DataInfo() { return fDataSetInfo; }; 119 ; 120 void AddVariable( const TString& expression, Float_t* ",MatchSource.WIKI,doc/master/Reader_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8h_source.html
https://root.cern/doc/master/Reader_8h_source.html:4968,Security,access,accessors,4968,,MatchSource.WIKI,doc/master/Reader_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8h_source.html
https://root.cern/doc/master/Reader_8h_source.html:6736,Testability,log,logger,6736,"Double_t mvaVal=-9999999 );; 111 ; 112 // accessors; 113 virtual const char* GetName() const { return ""Reader""; }; 114 Bool_t Verbose( void ) const { return fVerbose; }; 115 void SetVerbose( Bool_t v ) { fVerbose = v; }; 116 ; 117 const DataSetInfo& DataInfo() const { return fDataSetInfo; }; 118 DataSetInfo& DataInfo() { return fDataSetInfo; }; 119 ; 120 void AddVariable( const TString& expression, Float_t* );; 121 void AddVariable( const TString& expression, Int_t* );; 122 ; 123 void AddSpectator( const TString& expression, Float_t* );; 124 void AddSpectator( const TString& expression, Int_t* );; 125 ; 126 private:; 127 ; 128 DataSetManager* fDataSetManager; // DSMTEST; 129 ; 130 ; 131 TString GetMethodTypeFromFile( const TString& filename );; 132 ; 133 // this booking method is internal; 134 IMethod* BookMVA( Types::EMVA method, const TString& weightfile );; 135 ; 136 DataSetInfo fDataSetInfo; // the data set; 137 ; 138 DataInputHandler fDataInputHandler;; 139 ; 140 // Init Reader class; 141 void Init( void );; 142 ; 143 // Decode Constructor string (or TString) and fill variable name std::vector; 144 void DecodeVarNames( const std::string& varNames );; 145 void DecodeVarNames( const TString& varNames );; 146 ; 147 void DeclareOptions();; 148 ; 149 Bool_t fVerbose; ///< verbosity; 150 Bool_t fSilent; ///< silent mode; 151 Bool_t fColor; ///< color mode; 152 Bool_t fCalculateError; ///< error calculation mode; 153 ; 154 Double_t fMvaEventError; ///< per-event error returned by MVA; 155 Double_t fMvaEventErrorUpper; ///< per-event error returned by MVA; 156 ; 157 std::map<TString, IMethod*> fMethodMap; ///< map of methods; 158 ; 159 std::vector<Float_t> fTmpEvalVec; ///< temporary evaluation vector (if user input is v<double>); 160 ; 161 mutable MsgLogger* fLogger; ///<! message logger; 162 MsgLogger& Log() const { return *fLogger; }; 163 ; 164 ClassDef(Reader,0); // Interpret the trained MVAs in an analysis context; 165 };; 166 ; 167}; 168 ; 169#endif; Configurable.",MatchSource.WIKI,doc/master/Reader_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8h_source.html
https://root.cern/doc/master/Reader_8h_source.html:12377,Testability,log,loggerDefinition,12377,"odTag, const TString &weightfile)read method name from weight fileDefinition Reader.cxx:368; TMVA::Reader::EvaluateMulticlassconst std::vector< Float_t > & EvaluateMulticlass(const TString &methodTag, Double_t aux=0)evaluates MVA for given set of input variablesDefinition Reader.cxx:630; TMVA::Reader::GetMVAErrorUpperDouble_t GetMVAErrorUpper() constDefinition Reader.h:96; TMVA::Reader::LogMsgLogger & Log() constDefinition Reader.h:162; TMVA::Reader::GetMVAErrorLowerDouble_t GetMVAErrorLower() constDefinition Reader.h:95; TMVA::Reader::DataInfoDataSetInfo & DataInfo()Definition Reader.h:118; TMVA::Reader::fDataInputHandlerDataInputHandler fDataInputHandlerDefinition Reader.h:138; TMVA::Reader::DecodeVarNamesvoid DecodeVarNames(const std::string &varNames)decodes ""name1:name2:..."" formDefinition Reader.cxx:772; TMVA::Reader::fSilentBool_t fSilentsilent modeDefinition Reader.h:150; TMVA::Reader::DeclareOptionsvoid DeclareOptions()declaration of configuration optionsDefinition Reader.cxx:264; TMVA::Reader::AddSpectatorvoid AddSpectator(const TString &expression, Float_t *)Add a float spectator or expression to the reader.Definition Reader.cxx:321; TMVA::Reader::AddVariablevoid AddVariable(const TString &expression, Float_t *)Add a float variable or expression to the reader.Definition Reader.cxx:303; TMVA::Reader::~Readervirtual ~Reader(void)destructorDefinition Reader.cxx:277; TMVA::Reader::fLoggerMsgLogger * fLogger! message loggerDefinition Reader.h:161; TMVA::Reader::DataInfoconst DataSetInfo & DataInfo() constDefinition Reader.h:117; TMVA::Reader::GetMVAErrorDouble_t GetMVAError() constDefinition Reader.h:94; TMVA::Types::EMVAEMVADefinition Types.h:76; TStringBasic string class.Definition TString.h:139; bool; double; int; TMVAcreate variable transformationsDefinition GeneticMinimizer.h:22; v@ vDefinition rootcling_impl.cxx:3699; Types.h. tmvatmvaincTMVAReader.h. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:40:58 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/Reader_8h_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/Reader_8h_source.html
https://root.cern/doc/master/rebin_8C.html:214,Modifiability,variab,variable,214,". ROOT: tutorials/hist/rebin.C File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. rebin.C File ReferenceTutorials  Histograms tutorials. Detailed Description; Rebin a variable bin-width histogram. ; This tutorial illustrates how to:; create a variable bin-width histogram with a binning such that the population per bin is about the same.; rebin a variable bin-width histogram into another one. ; #include ""TH1.h""; #include ""TCanvas.h""; void rebin() {; //create a fix bin histogram; TH1F *h = new TH1F(""h"",""test rebin"",100,-3,3);; Int_t nentries = 1000;; h->FillRandom(""gaus"",nentries);; Double_t xbins[1001];; Int_t k=0;; TAxis *axis = h->GetXaxis();; for (Int_t i=1;i<=100;i++) {; Int_t y = (Int_t)h->GetBinContent(i);; if (y <=0) continue;; Double_t dx = axis->GetBinWidth(i)/y;; Double_t xmin = axis->GetBinLowEdge(i);; for (Int_t j=0;j<y;j++) {; xbins[k] = xmin +j*dx;; k++;; }; }; xbins[k] = axis->GetXmax();; //create a variable bin-width histogram out of fix bin histogram; //new rebinned histogram should have about 10 entries per bin; TH1F *hnew = new TH1F(""hnew"",""rebinned"",k,xbins);; hnew->FillRandom(""gaus"",10*nentries);; ; //rebin hnew keeping only 50% of the bins; Double_t xbins2[501];; Int_t kk=0;; for (Int_t j=0;j<k;j+=2) {; xbins2[kk] = xbins[j];; kk++;; }; xbins2[kk] = xbins[k];; TH1F *hnew2 = (TH1F*)hnew->Rebin(kk,""hnew2"",xbins2);; ; //draw the 3 histograms; TCanvas *c1 = new TCanvas(""c1"",""c1"",800,1000);; c1->Divide(1,3);; c1->cd(1);; h->Draw();; c1->cd(2);; hnew->Draw();; c1->cd(3);; hnew2->Draw();; }; h#define h(i)Definition RSha256.hxx:106; Int_tint Int_tDefinition RtypesCore.h:45; Double_tdouble Double_tDefinition RtypesCore.h:59; TCanvas.h; TH1.h; xminfloat xminDefinition THbookFile.cxx:95; nentriesint nentriesDefinition THbookFile.cxx:91; TAxisClass to manage histogram axis.Definition TAxis.h:31; TAxis::GetXmaxDouble_t GetXmax() constDefinition TAxis.h:140; TAxis::GetBinLowEdgevirtual Double_t GetBinLowEdge(Int_t",MatchSource.WIKI,doc/master/rebin_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rebin_8C.html
https://root.cern/doc/master/rebin_8C.html:290,Modifiability,variab,variable,290,". ROOT: tutorials/hist/rebin.C File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. rebin.C File ReferenceTutorials  Histograms tutorials. Detailed Description; Rebin a variable bin-width histogram. ; This tutorial illustrates how to:; create a variable bin-width histogram with a binning such that the population per bin is about the same.; rebin a variable bin-width histogram into another one. ; #include ""TH1.h""; #include ""TCanvas.h""; void rebin() {; //create a fix bin histogram; TH1F *h = new TH1F(""h"",""test rebin"",100,-3,3);; Int_t nentries = 1000;; h->FillRandom(""gaus"",nentries);; Double_t xbins[1001];; Int_t k=0;; TAxis *axis = h->GetXaxis();; for (Int_t i=1;i<=100;i++) {; Int_t y = (Int_t)h->GetBinContent(i);; if (y <=0) continue;; Double_t dx = axis->GetBinWidth(i)/y;; Double_t xmin = axis->GetBinLowEdge(i);; for (Int_t j=0;j<y;j++) {; xbins[k] = xmin +j*dx;; k++;; }; }; xbins[k] = axis->GetXmax();; //create a variable bin-width histogram out of fix bin histogram; //new rebinned histogram should have about 10 entries per bin; TH1F *hnew = new TH1F(""hnew"",""rebinned"",k,xbins);; hnew->FillRandom(""gaus"",10*nentries);; ; //rebin hnew keeping only 50% of the bins; Double_t xbins2[501];; Int_t kk=0;; for (Int_t j=0;j<k;j+=2) {; xbins2[kk] = xbins[j];; kk++;; }; xbins2[kk] = xbins[k];; TH1F *hnew2 = (TH1F*)hnew->Rebin(kk,""hnew2"",xbins2);; ; //draw the 3 histograms; TCanvas *c1 = new TCanvas(""c1"",""c1"",800,1000);; c1->Divide(1,3);; c1->cd(1);; h->Draw();; c1->cd(2);; hnew->Draw();; c1->cd(3);; hnew2->Draw();; }; h#define h(i)Definition RSha256.hxx:106; Int_tint Int_tDefinition RtypesCore.h:45; Double_tdouble Double_tDefinition RtypesCore.h:59; TCanvas.h; TH1.h; xminfloat xminDefinition THbookFile.cxx:95; nentriesint nentriesDefinition THbookFile.cxx:91; TAxisClass to manage histogram axis.Definition TAxis.h:31; TAxis::GetXmaxDouble_t GetXmax() constDefinition TAxis.h:140; TAxis::GetBinLowEdgevirtual Double_t GetBinLowEdge(Int_t",MatchSource.WIKI,doc/master/rebin_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rebin_8C.html
https://root.cern/doc/master/rebin_8C.html:395,Modifiability,variab,variable,395,". ROOT: tutorials/hist/rebin.C File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. rebin.C File ReferenceTutorials  Histograms tutorials. Detailed Description; Rebin a variable bin-width histogram. ; This tutorial illustrates how to:; create a variable bin-width histogram with a binning such that the population per bin is about the same.; rebin a variable bin-width histogram into another one. ; #include ""TH1.h""; #include ""TCanvas.h""; void rebin() {; //create a fix bin histogram; TH1F *h = new TH1F(""h"",""test rebin"",100,-3,3);; Int_t nentries = 1000;; h->FillRandom(""gaus"",nentries);; Double_t xbins[1001];; Int_t k=0;; TAxis *axis = h->GetXaxis();; for (Int_t i=1;i<=100;i++) {; Int_t y = (Int_t)h->GetBinContent(i);; if (y <=0) continue;; Double_t dx = axis->GetBinWidth(i)/y;; Double_t xmin = axis->GetBinLowEdge(i);; for (Int_t j=0;j<y;j++) {; xbins[k] = xmin +j*dx;; k++;; }; }; xbins[k] = axis->GetXmax();; //create a variable bin-width histogram out of fix bin histogram; //new rebinned histogram should have about 10 entries per bin; TH1F *hnew = new TH1F(""hnew"",""rebinned"",k,xbins);; hnew->FillRandom(""gaus"",10*nentries);; ; //rebin hnew keeping only 50% of the bins; Double_t xbins2[501];; Int_t kk=0;; for (Int_t j=0;j<k;j+=2) {; xbins2[kk] = xbins[j];; kk++;; }; xbins2[kk] = xbins[k];; TH1F *hnew2 = (TH1F*)hnew->Rebin(kk,""hnew2"",xbins2);; ; //draw the 3 histograms; TCanvas *c1 = new TCanvas(""c1"",""c1"",800,1000);; c1->Divide(1,3);; c1->cd(1);; h->Draw();; c1->cd(2);; hnew->Draw();; c1->cd(3);; hnew2->Draw();; }; h#define h(i)Definition RSha256.hxx:106; Int_tint Int_tDefinition RtypesCore.h:45; Double_tdouble Double_tDefinition RtypesCore.h:59; TCanvas.h; TH1.h; xminfloat xminDefinition THbookFile.cxx:95; nentriesint nentriesDefinition THbookFile.cxx:91; TAxisClass to manage histogram axis.Definition TAxis.h:31; TAxis::GetXmaxDouble_t GetXmax() constDefinition TAxis.h:140; TAxis::GetBinLowEdgevirtual Double_t GetBinLowEdge(Int_t",MatchSource.WIKI,doc/master/rebin_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rebin_8C.html
https://root.cern/doc/master/rebin_8C.html:974,Modifiability,variab,variable,974,". ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. rebin.C File ReferenceTutorials  Histograms tutorials. Detailed Description; Rebin a variable bin-width histogram. ; This tutorial illustrates how to:; create a variable bin-width histogram with a binning such that the population per bin is about the same.; rebin a variable bin-width histogram into another one. ; #include ""TH1.h""; #include ""TCanvas.h""; void rebin() {; //create a fix bin histogram; TH1F *h = new TH1F(""h"",""test rebin"",100,-3,3);; Int_t nentries = 1000;; h->FillRandom(""gaus"",nentries);; Double_t xbins[1001];; Int_t k=0;; TAxis *axis = h->GetXaxis();; for (Int_t i=1;i<=100;i++) {; Int_t y = (Int_t)h->GetBinContent(i);; if (y <=0) continue;; Double_t dx = axis->GetBinWidth(i)/y;; Double_t xmin = axis->GetBinLowEdge(i);; for (Int_t j=0;j<y;j++) {; xbins[k] = xmin +j*dx;; k++;; }; }; xbins[k] = axis->GetXmax();; //create a variable bin-width histogram out of fix bin histogram; //new rebinned histogram should have about 10 entries per bin; TH1F *hnew = new TH1F(""hnew"",""rebinned"",k,xbins);; hnew->FillRandom(""gaus"",10*nentries);; ; //rebin hnew keeping only 50% of the bins; Double_t xbins2[501];; Int_t kk=0;; for (Int_t j=0;j<k;j+=2) {; xbins2[kk] = xbins[j];; kk++;; }; xbins2[kk] = xbins[k];; TH1F *hnew2 = (TH1F*)hnew->Rebin(kk,""hnew2"",xbins2);; ; //draw the 3 histograms; TCanvas *c1 = new TCanvas(""c1"",""c1"",800,1000);; c1->Divide(1,3);; c1->cd(1);; h->Draw();; c1->cd(2);; hnew->Draw();; c1->cd(3);; hnew2->Draw();; }; h#define h(i)Definition RSha256.hxx:106; Int_tint Int_tDefinition RtypesCore.h:45; Double_tdouble Double_tDefinition RtypesCore.h:59; TCanvas.h; TH1.h; xminfloat xminDefinition THbookFile.cxx:95; nentriesint nentriesDefinition THbookFile.cxx:91; TAxisClass to manage histogram axis.Definition TAxis.h:31; TAxis::GetXmaxDouble_t GetXmax() constDefinition TAxis.h:140; TAxis::GetBinLowEdgevirtual Double_t GetBinLowEdge(Int_t bin) constReturn low edge of bin.Definition",MatchSource.WIKI,doc/master/rebin_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rebin_8C.html
https://root.cern/doc/master/rebin_8C.html:554,Testability,test,test,554,". ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. rebin.C File ReferenceTutorials  Histograms tutorials. Detailed Description; Rebin a variable bin-width histogram. ; This tutorial illustrates how to:; create a variable bin-width histogram with a binning such that the population per bin is about the same.; rebin a variable bin-width histogram into another one. ; #include ""TH1.h""; #include ""TCanvas.h""; void rebin() {; //create a fix bin histogram; TH1F *h = new TH1F(""h"",""test rebin"",100,-3,3);; Int_t nentries = 1000;; h->FillRandom(""gaus"",nentries);; Double_t xbins[1001];; Int_t k=0;; TAxis *axis = h->GetXaxis();; for (Int_t i=1;i<=100;i++) {; Int_t y = (Int_t)h->GetBinContent(i);; if (y <=0) continue;; Double_t dx = axis->GetBinWidth(i)/y;; Double_t xmin = axis->GetBinLowEdge(i);; for (Int_t j=0;j<y;j++) {; xbins[k] = xmin +j*dx;; k++;; }; }; xbins[k] = axis->GetXmax();; //create a variable bin-width histogram out of fix bin histogram; //new rebinned histogram should have about 10 entries per bin; TH1F *hnew = new TH1F(""hnew"",""rebinned"",k,xbins);; hnew->FillRandom(""gaus"",10*nentries);; ; //rebin hnew keeping only 50% of the bins; Double_t xbins2[501];; Int_t kk=0;; for (Int_t j=0;j<k;j+=2) {; xbins2[kk] = xbins[j];; kk++;; }; xbins2[kk] = xbins[k];; TH1F *hnew2 = (TH1F*)hnew->Rebin(kk,""hnew2"",xbins2);; ; //draw the 3 histograms; TCanvas *c1 = new TCanvas(""c1"",""c1"",800,1000);; c1->Divide(1,3);; c1->cd(1);; h->Draw();; c1->cd(2);; hnew->Draw();; c1->cd(3);; hnew2->Draw();; }; h#define h(i)Definition RSha256.hxx:106; Int_tint Int_tDefinition RtypesCore.h:45; Double_tdouble Double_tDefinition RtypesCore.h:59; TCanvas.h; TH1.h; xminfloat xminDefinition THbookFile.cxx:95; nentriesint nentriesDefinition THbookFile.cxx:91; TAxisClass to manage histogram axis.Definition TAxis.h:31; TAxis::GetXmaxDouble_t GetXmax() constDefinition TAxis.h:140; TAxis::GetBinLowEdgevirtual Double_t GetBinLowEdge(Int_t bin) constReturn low edge of bin.Definition",MatchSource.WIKI,doc/master/rebin_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rebin_8C.html
https://root.cern/doc/master/rebin_8C_source.html:246,Modifiability,variab,variable,246,". ROOT: tutorials/hist/rebin.C Source File. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. rebin.C. Go to the documentation of this file. 1/// \file; 2/// \ingroup tutorial_hist; 3/// \notebook -js; 4/// Rebin a variable bin-width histogram.; 5///; 6/// This tutorial illustrates how to:; 7/// - create a variable bin-width histogram with a binning such; 8/// that the population per bin is about the same.; 9/// - rebin a variable bin-width histogram into another one.; 10///; 11/// \macro_image; 12/// \macro_code; 13///; 14/// \author Rene Brun; 15 ; 16#include ""TH1.h""; 17#include ""TCanvas.h""; 18void rebin() {; 19 //create a fix bin histogram; 20 TH1F *h = new TH1F(""h"",""test rebin"",100,-3,3);; 21 Int_t nentries = 1000;; 22 h->FillRandom(""gaus"",nentries);; 23 Double_t xbins[1001];; 24 Int_t k=0;; 25 TAxis *axis = h->GetXaxis();; 26 for (Int_t i=1;i<=100;i++) {; 27 Int_t y = (Int_t)h->GetBinContent(i);; 28 if (y <=0) continue;; 29 Double_t dx = axis->GetBinWidth(i)/y;; 30 Double_t xmin = axis->GetBinLowEdge(i);; 31 for (Int_t j=0;j<y;j++) {; 32 xbins[k] = xmin +j*dx;; 33 k++;; 34 }; 35 }; 36 xbins[k] = axis->GetXmax();; 37 //create a variable bin-width histogram out of fix bin histogram; 38 //new rebinned histogram should have about 10 entries per bin; 39 TH1F *hnew = new TH1F(""hnew"",""rebinned"",k,xbins);; 40 hnew->FillRandom(""gaus"",10*nentries);; 41 ; 42 //rebin hnew keeping only 50% of the bins; 43 Double_t xbins2[501];; 44 Int_t kk=0;; 45 for (Int_t j=0;j<k;j+=2) {; 46 xbins2[kk] = xbins[j];; 47 kk++;; 48 }; 49 xbins2[kk] = xbins[k];; 50 TH1F *hnew2 = (TH1F*)hnew->Rebin(kk,""hnew2"",xbins2);; 51 ; 52 //draw the 3 histograms; 53 TCanvas *c1 = new TCanvas(""c1"",""c1"",800,1000);; 54 c1->Divide(1,3);; 55 c1->cd(1);; 56 h->Draw();; 57 c1->cd(2);; 58 hnew->Draw();; 59 c1->cd(3);; 60 hnew2->Draw();; 61}; h#define h(i)Definition RSha256.hxx:106; Int_tint Int_tDefinition RtypesCore.h:45; Double_tdouble Double_tDefinition RtypesCore.h:59; TCanvas.h; ",MatchSource.WIKI,doc/master/rebin_8C_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rebin_8C_source.html
https://root.cern/doc/master/rebin_8C_source.html:339,Modifiability,variab,variable,339,". ROOT: tutorials/hist/rebin.C Source File. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. rebin.C. Go to the documentation of this file. 1/// \file; 2/// \ingroup tutorial_hist; 3/// \notebook -js; 4/// Rebin a variable bin-width histogram.; 5///; 6/// This tutorial illustrates how to:; 7/// - create a variable bin-width histogram with a binning such; 8/// that the population per bin is about the same.; 9/// - rebin a variable bin-width histogram into another one.; 10///; 11/// \macro_image; 12/// \macro_code; 13///; 14/// \author Rene Brun; 15 ; 16#include ""TH1.h""; 17#include ""TCanvas.h""; 18void rebin() {; 19 //create a fix bin histogram; 20 TH1F *h = new TH1F(""h"",""test rebin"",100,-3,3);; 21 Int_t nentries = 1000;; 22 h->FillRandom(""gaus"",nentries);; 23 Double_t xbins[1001];; 24 Int_t k=0;; 25 TAxis *axis = h->GetXaxis();; 26 for (Int_t i=1;i<=100;i++) {; 27 Int_t y = (Int_t)h->GetBinContent(i);; 28 if (y <=0) continue;; 29 Double_t dx = axis->GetBinWidth(i)/y;; 30 Double_t xmin = axis->GetBinLowEdge(i);; 31 for (Int_t j=0;j<y;j++) {; 32 xbins[k] = xmin +j*dx;; 33 k++;; 34 }; 35 }; 36 xbins[k] = axis->GetXmax();; 37 //create a variable bin-width histogram out of fix bin histogram; 38 //new rebinned histogram should have about 10 entries per bin; 39 TH1F *hnew = new TH1F(""hnew"",""rebinned"",k,xbins);; 40 hnew->FillRandom(""gaus"",10*nentries);; 41 ; 42 //rebin hnew keeping only 50% of the bins; 43 Double_t xbins2[501];; 44 Int_t kk=0;; 45 for (Int_t j=0;j<k;j+=2) {; 46 xbins2[kk] = xbins[j];; 47 kk++;; 48 }; 49 xbins2[kk] = xbins[k];; 50 TH1F *hnew2 = (TH1F*)hnew->Rebin(kk,""hnew2"",xbins2);; 51 ; 52 //draw the 3 histograms; 53 TCanvas *c1 = new TCanvas(""c1"",""c1"",800,1000);; 54 c1->Divide(1,3);; 55 c1->cd(1);; 56 h->Draw();; 57 c1->cd(2);; 58 hnew->Draw();; 59 c1->cd(3);; 60 hnew2->Draw();; 61}; h#define h(i)Definition RSha256.hxx:106; Int_tint Int_tDefinition RtypesCore.h:45; Double_tdouble Double_tDefinition RtypesCore.h:59; TCanvas.h; ",MatchSource.WIKI,doc/master/rebin_8C_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rebin_8C_source.html
https://root.cern/doc/master/rebin_8C_source.html:457,Modifiability,variab,variable,457,". ROOT: tutorials/hist/rebin.C Source File. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. rebin.C. Go to the documentation of this file. 1/// \file; 2/// \ingroup tutorial_hist; 3/// \notebook -js; 4/// Rebin a variable bin-width histogram.; 5///; 6/// This tutorial illustrates how to:; 7/// - create a variable bin-width histogram with a binning such; 8/// that the population per bin is about the same.; 9/// - rebin a variable bin-width histogram into another one.; 10///; 11/// \macro_image; 12/// \macro_code; 13///; 14/// \author Rene Brun; 15 ; 16#include ""TH1.h""; 17#include ""TCanvas.h""; 18void rebin() {; 19 //create a fix bin histogram; 20 TH1F *h = new TH1F(""h"",""test rebin"",100,-3,3);; 21 Int_t nentries = 1000;; 22 h->FillRandom(""gaus"",nentries);; 23 Double_t xbins[1001];; 24 Int_t k=0;; 25 TAxis *axis = h->GetXaxis();; 26 for (Int_t i=1;i<=100;i++) {; 27 Int_t y = (Int_t)h->GetBinContent(i);; 28 if (y <=0) continue;; 29 Double_t dx = axis->GetBinWidth(i)/y;; 30 Double_t xmin = axis->GetBinLowEdge(i);; 31 for (Int_t j=0;j<y;j++) {; 32 xbins[k] = xmin +j*dx;; 33 k++;; 34 }; 35 }; 36 xbins[k] = axis->GetXmax();; 37 //create a variable bin-width histogram out of fix bin histogram; 38 //new rebinned histogram should have about 10 entries per bin; 39 TH1F *hnew = new TH1F(""hnew"",""rebinned"",k,xbins);; 40 hnew->FillRandom(""gaus"",10*nentries);; 41 ; 42 //rebin hnew keeping only 50% of the bins; 43 Double_t xbins2[501];; 44 Int_t kk=0;; 45 for (Int_t j=0;j<k;j+=2) {; 46 xbins2[kk] = xbins[j];; 47 kk++;; 48 }; 49 xbins2[kk] = xbins[k];; 50 TH1F *hnew2 = (TH1F*)hnew->Rebin(kk,""hnew2"",xbins2);; 51 ; 52 //draw the 3 histograms; 53 TCanvas *c1 = new TCanvas(""c1"",""c1"",800,1000);; 54 c1->Divide(1,3);; 55 c1->cd(1);; 56 h->Draw();; 57 c1->cd(2);; 58 hnew->Draw();; 59 c1->cd(3);; 60 hnew2->Draw();; 61}; h#define h(i)Definition RSha256.hxx:106; Int_tint Int_tDefinition RtypesCore.h:45; Double_tdouble Double_tDefinition RtypesCore.h:59; TCanvas.h; ",MatchSource.WIKI,doc/master/rebin_8C_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rebin_8C_source.html
https://root.cern/doc/master/rebin_8C_source.html:1181,Modifiability,variab,variable,1181,"-width histogram.; 5///; 6/// This tutorial illustrates how to:; 7/// - create a variable bin-width histogram with a binning such; 8/// that the population per bin is about the same.; 9/// - rebin a variable bin-width histogram into another one.; 10///; 11/// \macro_image; 12/// \macro_code; 13///; 14/// \author Rene Brun; 15 ; 16#include ""TH1.h""; 17#include ""TCanvas.h""; 18void rebin() {; 19 //create a fix bin histogram; 20 TH1F *h = new TH1F(""h"",""test rebin"",100,-3,3);; 21 Int_t nentries = 1000;; 22 h->FillRandom(""gaus"",nentries);; 23 Double_t xbins[1001];; 24 Int_t k=0;; 25 TAxis *axis = h->GetXaxis();; 26 for (Int_t i=1;i<=100;i++) {; 27 Int_t y = (Int_t)h->GetBinContent(i);; 28 if (y <=0) continue;; 29 Double_t dx = axis->GetBinWidth(i)/y;; 30 Double_t xmin = axis->GetBinLowEdge(i);; 31 for (Int_t j=0;j<y;j++) {; 32 xbins[k] = xmin +j*dx;; 33 k++;; 34 }; 35 }; 36 xbins[k] = axis->GetXmax();; 37 //create a variable bin-width histogram out of fix bin histogram; 38 //new rebinned histogram should have about 10 entries per bin; 39 TH1F *hnew = new TH1F(""hnew"",""rebinned"",k,xbins);; 40 hnew->FillRandom(""gaus"",10*nentries);; 41 ; 42 //rebin hnew keeping only 50% of the bins; 43 Double_t xbins2[501];; 44 Int_t kk=0;; 45 for (Int_t j=0;j<k;j+=2) {; 46 xbins2[kk] = xbins[j];; 47 kk++;; 48 }; 49 xbins2[kk] = xbins[k];; 50 TH1F *hnew2 = (TH1F*)hnew->Rebin(kk,""hnew2"",xbins2);; 51 ; 52 //draw the 3 histograms; 53 TCanvas *c1 = new TCanvas(""c1"",""c1"",800,1000);; 54 c1->Divide(1,3);; 55 c1->cd(1);; 56 h->Draw();; 57 c1->cd(2);; 58 hnew->Draw();; 59 c1->cd(3);; 60 hnew2->Draw();; 61}; h#define h(i)Definition RSha256.hxx:106; Int_tint Int_tDefinition RtypesCore.h:45; Double_tdouble Double_tDefinition RtypesCore.h:59; TCanvas.h; TH1.h; xminfloat xminDefinition THbookFile.cxx:95; nentriesint nentriesDefinition THbookFile.cxx:91; TAxisClass to manage histogram axis.Definition TAxis.h:31; TAxis::GetXmaxDouble_t GetXmax() constDefinition TAxis.h:140; TAxis::GetBinLowEdgevirtual Double_",MatchSource.WIKI,doc/master/rebin_8C_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rebin_8C_source.html
https://root.cern/doc/master/rebin_8C_source.html:710,Testability,test,test,710,"-width histogram.; 5///; 6/// This tutorial illustrates how to:; 7/// - create a variable bin-width histogram with a binning such; 8/// that the population per bin is about the same.; 9/// - rebin a variable bin-width histogram into another one.; 10///; 11/// \macro_image; 12/// \macro_code; 13///; 14/// \author Rene Brun; 15 ; 16#include ""TH1.h""; 17#include ""TCanvas.h""; 18void rebin() {; 19 //create a fix bin histogram; 20 TH1F *h = new TH1F(""h"",""test rebin"",100,-3,3);; 21 Int_t nentries = 1000;; 22 h->FillRandom(""gaus"",nentries);; 23 Double_t xbins[1001];; 24 Int_t k=0;; 25 TAxis *axis = h->GetXaxis();; 26 for (Int_t i=1;i<=100;i++) {; 27 Int_t y = (Int_t)h->GetBinContent(i);; 28 if (y <=0) continue;; 29 Double_t dx = axis->GetBinWidth(i)/y;; 30 Double_t xmin = axis->GetBinLowEdge(i);; 31 for (Int_t j=0;j<y;j++) {; 32 xbins[k] = xmin +j*dx;; 33 k++;; 34 }; 35 }; 36 xbins[k] = axis->GetXmax();; 37 //create a variable bin-width histogram out of fix bin histogram; 38 //new rebinned histogram should have about 10 entries per bin; 39 TH1F *hnew = new TH1F(""hnew"",""rebinned"",k,xbins);; 40 hnew->FillRandom(""gaus"",10*nentries);; 41 ; 42 //rebin hnew keeping only 50% of the bins; 43 Double_t xbins2[501];; 44 Int_t kk=0;; 45 for (Int_t j=0;j<k;j+=2) {; 46 xbins2[kk] = xbins[j];; 47 kk++;; 48 }; 49 xbins2[kk] = xbins[k];; 50 TH1F *hnew2 = (TH1F*)hnew->Rebin(kk,""hnew2"",xbins2);; 51 ; 52 //draw the 3 histograms; 53 TCanvas *c1 = new TCanvas(""c1"",""c1"",800,1000);; 54 c1->Divide(1,3);; 55 c1->cd(1);; 56 h->Draw();; 57 c1->cd(2);; 58 hnew->Draw();; 59 c1->cd(3);; 60 hnew2->Draw();; 61}; h#define h(i)Definition RSha256.hxx:106; Int_tint Int_tDefinition RtypesCore.h:45; Double_tdouble Double_tDefinition RtypesCore.h:59; TCanvas.h; TH1.h; xminfloat xminDefinition THbookFile.cxx:95; nentriesint nentriesDefinition THbookFile.cxx:91; TAxisClass to manage histogram axis.Definition TAxis.h:31; TAxis::GetXmaxDouble_t GetXmax() constDefinition TAxis.h:140; TAxis::GetBinLowEdgevirtual Double_",MatchSource.WIKI,doc/master/rebin_8C_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rebin_8C_source.html
https://root.cern/doc/master/RElement_8cxx_source.html:9087,Deployability,configurat,configuration,9087,"e::RElement::GetTitlevirtual std::string GetTitle() constTitle of browsable (optional)Definition RElement.hxx:71; ROOT::Browsable::RElement::ComparePathsstatic int ComparePaths(const RElementPath_t &path1, const RElementPath_t &path2)Compare two paths, Returns number of elements matches in both paths.Definition RElement.cxx:145; ROOT::Browsable::RElement::GetPathAsStringstatic std::string GetPathAsString(const RElementPath_t &path)Converts element path back to string.Definition RElement.cxx:160; ROOT::Browsable::RElement::GetSubElementstatic std::shared_ptr< RElement > GetSubElement(std::shared_ptr< RElement > &elem, const RElementPath_t &path)Returns sub element.Definition RElement.cxx:69; ROOT::Browsable::RElement::CreateItemvirtual std::unique_ptr< RItem > CreateItem() constReturns item with element description.Definition RElement.cxx:105; ROOT::Browsable::RElement::ParsePathstatic RElementPath_t ParsePath(const std::string &str)Parse string path to produce RElementPath_t One should avoid to use string pathes as much as possible...Definition RElement.cxx:116; ROOT::Experimental::RLogChannelA log configuration for a channel, e.g.Definition RLogger.hxx:101; TBufferJSON::ConvertToJSONstatic TString ConvertToJSON(const TObject *obj, Int_t compact=0, const char *member_name=nullptr)Converts object, inherited from TObject class, to JSON string Lower digit of compact parameter define...Definition TBufferJSON.cxx:522; TString::Dataconst char * Data() constDefinition TString.h:376; nconst Int_t nDefinition legend1.C:16; ROOT::BrowsableDefinition RAnyObjectHolder.hxx:15; ROOT::Browsable::RElementPath_tstd::vector< std::string > RElementPath_tDefinition RElement.hxx:20; ROOT::BrowsableLogROOT::Experimental::RLogChannel & BrowsableLog()Log channel for Browsable diagnostics.Definition RElement.cxx:20; slashTCanvas * slash()Definition slash.C:1. guibrowsablesrcRElement.cxx. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:40:26 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/RElement_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RElement_8cxx_source.html
https://root.cern/doc/master/RElement_8cxx_source.html:6340,Integrability,depend,depends,6340,"tract index from name; 175/// Index coded by client with `###<indx>$$$` suffix; 176/// Such coding used by browser to identify element by index; 177 ; 178int RElement::ExtractItemIndex(std::string &name); 179{; 180 auto p1 = name.rfind(""###""), p2 = name.rfind(""$$$"");; 181 if ((p1 == std::string::npos) || (p2 == std::string::npos) || (p1 >= p2) || (p2 != name.length()-3)) return -1;; 182 ; 183 int indx = std::stoi(name.substr(p1+3,p2-p1-3));; 184 name.resize(p1);; 185 return indx;; 186}; RElement.hxx; RItem.hxx; RLevelIter.hxx; RLogger.hxx; TBufferJSON.h; namechar name[80]Definition TGX11.cxx:110; ROOT::Browsable::RElement::GetNamevirtual std::string GetName() const =0Name of browsable, must be provided in derived classes.; ROOT::Browsable::RElement::GetContentKindstatic EContentKind GetContentKind(const std::string &kind)Find item with specified name Default implementation, should work for all.Definition RElement.cxx:52; ROOT::Browsable::RElement::GetContentvirtual std::string GetContent(const std::string &=""text"")Returns element content, depends from kind.Definition RElement.cxx:90; ROOT::Browsable::RElement::EContentKindEContentKindDefinition RElement.hxx:37; ROOT::Browsable::RElement::kFileName@ kFileName""filename"" - file name if applicableDefinition RElement.hxx:44; ROOT::Browsable::RElement::kNone@ kNonenot recognizedDefinition RElement.hxx:38; ROOT::Browsable::RElement::kJpeg@ kJpeg""jpg"" or ""jpeg"" - plain jpg binary code, returned inside std::stringDefinition RElement.hxx:42; ROOT::Browsable::RElement::kPng@ kPng""png"" - plain png binary code, returned inside std::stringDefinition RElement.hxx:41; ROOT::Browsable::RElement::kJson@ kJson""json"" representation of object, can be used in code editorDefinition RElement.hxx:43; ROOT::Browsable::RElement::kText@ kText""text"" - plain text for code editorDefinition RElement.hxx:39; ROOT::Browsable::RElement::kImage@ kImage""image64"" - base64 for supported image formats (png/gif/gpeg)Definition RElement.hxx:40; ROOT::Browsa",MatchSource.WIKI,doc/master/RElement_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RElement_8cxx_source.html
https://root.cern/doc/master/RElement_8cxx_source.html:9087,Modifiability,config,configuration,9087,"e::RElement::GetTitlevirtual std::string GetTitle() constTitle of browsable (optional)Definition RElement.hxx:71; ROOT::Browsable::RElement::ComparePathsstatic int ComparePaths(const RElementPath_t &path1, const RElementPath_t &path2)Compare two paths, Returns number of elements matches in both paths.Definition RElement.cxx:145; ROOT::Browsable::RElement::GetPathAsStringstatic std::string GetPathAsString(const RElementPath_t &path)Converts element path back to string.Definition RElement.cxx:160; ROOT::Browsable::RElement::GetSubElementstatic std::shared_ptr< RElement > GetSubElement(std::shared_ptr< RElement > &elem, const RElementPath_t &path)Returns sub element.Definition RElement.cxx:69; ROOT::Browsable::RElement::CreateItemvirtual std::unique_ptr< RItem > CreateItem() constReturns item with element description.Definition RElement.cxx:105; ROOT::Browsable::RElement::ParsePathstatic RElementPath_t ParsePath(const std::string &str)Parse string path to produce RElementPath_t One should avoid to use string pathes as much as possible...Definition RElement.cxx:116; ROOT::Experimental::RLogChannelA log configuration for a channel, e.g.Definition RLogger.hxx:101; TBufferJSON::ConvertToJSONstatic TString ConvertToJSON(const TObject *obj, Int_t compact=0, const char *member_name=nullptr)Converts object, inherited from TObject class, to JSON string Lower digit of compact parameter define...Definition TBufferJSON.cxx:522; TString::Dataconst char * Data() constDefinition TString.h:376; nconst Int_t nDefinition legend1.C:16; ROOT::BrowsableDefinition RAnyObjectHolder.hxx:15; ROOT::Browsable::RElementPath_tstd::vector< std::string > RElementPath_tDefinition RElement.hxx:20; ROOT::BrowsableLogROOT::Experimental::RLogChannel & BrowsableLog()Log channel for Browsable diagnostics.Definition RElement.cxx:20; slashTCanvas * slash()Definition slash.C:1. guibrowsablesrcRElement.cxx. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:40:26 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/RElement_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RElement_8cxx_source.html
https://root.cern/doc/master/RElement_8cxx_source.html:9289,Modifiability,inherit,inherited,9289,"e::RElement::GetTitlevirtual std::string GetTitle() constTitle of browsable (optional)Definition RElement.hxx:71; ROOT::Browsable::RElement::ComparePathsstatic int ComparePaths(const RElementPath_t &path1, const RElementPath_t &path2)Compare two paths, Returns number of elements matches in both paths.Definition RElement.cxx:145; ROOT::Browsable::RElement::GetPathAsStringstatic std::string GetPathAsString(const RElementPath_t &path)Converts element path back to string.Definition RElement.cxx:160; ROOT::Browsable::RElement::GetSubElementstatic std::shared_ptr< RElement > GetSubElement(std::shared_ptr< RElement > &elem, const RElementPath_t &path)Returns sub element.Definition RElement.cxx:69; ROOT::Browsable::RElement::CreateItemvirtual std::unique_ptr< RItem > CreateItem() constReturns item with element description.Definition RElement.cxx:105; ROOT::Browsable::RElement::ParsePathstatic RElementPath_t ParsePath(const std::string &str)Parse string path to produce RElementPath_t One should avoid to use string pathes as much as possible...Definition RElement.cxx:116; ROOT::Experimental::RLogChannelA log configuration for a channel, e.g.Definition RLogger.hxx:101; TBufferJSON::ConvertToJSONstatic TString ConvertToJSON(const TObject *obj, Int_t compact=0, const char *member_name=nullptr)Converts object, inherited from TObject class, to JSON string Lower digit of compact parameter define...Definition TBufferJSON.cxx:522; TString::Dataconst char * Data() constDefinition TString.h:376; nconst Int_t nDefinition legend1.C:16; ROOT::BrowsableDefinition RAnyObjectHolder.hxx:15; ROOT::Browsable::RElementPath_tstd::vector< std::string > RElementPath_tDefinition RElement.hxx:20; ROOT::BrowsableLogROOT::Experimental::RLogChannel & BrowsableLog()Log channel for Browsable diagnostics.Definition RElement.cxx:20; slashTCanvas * slash()Definition slash.C:1. guibrowsablesrcRElement.cxx. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:40:26 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/RElement_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RElement_8cxx_source.html
https://root.cern/doc/master/RElement_8cxx_source.html:3600,Safety,avoid,avoid,3600,"th_t &path); 70{; 71 auto curr = elem;; 72 ; 73 for (auto &itemname : path) {; 74 if (!curr); 75 return nullptr;; 76 ; 77 auto iter = curr->GetChildsIter();; 78 if (!iter || !iter->Find(itemname)); 79 return nullptr;; 80 ; 81 curr = iter->GetElement();; 82 }; 83 ; 84 return curr;; 85}; 86 ; 87/////////////////////////////////////////////////////////////////////; 88/// Returns string content like text file content or json representation; 89 ; 90std::string RElement::GetContent(const std::string &kind); 91{; 92 if (GetContentKind(kind) == kJson) {; 93 auto obj = GetObject();; 94 if (obj); 95 return TBufferJSON::ConvertToJSON(obj->GetObject(), obj->GetClass()).Data();; 96 }; 97 ; 98 return """"s;; 99}; 100 ; 101 ; 102/////////////////////////////////////////////////////////////////////; 103/// Returns item with element description; 104 ; 105std::unique_ptr<RItem> RElement::CreateItem() const; 106{; 107 auto item = std::make_unique<RItem>(GetName());; 108 item->SetTitle(GetTitle());; 109 return item;; 110}; 111 ; 112/////////////////////////////////////////////////////////////////////; 113/// Parse string path to produce RElementPath_t; 114/// One should avoid to use string pathes as much as possible; 115 ; 116RElementPath_t RElement::ParsePath(const std::string &strpath); 117{; 118 RElementPath_t arr;; 119 if (strpath.empty()); 120 return arr;; 121 ; 122 std::string slash = ""/"";; 123 ; 124 std::string::size_type previous = 0;; 125 if (strpath[0] == slash[0]) previous++;; 126 ; 127 auto current = strpath.find(slash, previous);; 128 while (current != std::string::npos) {; 129 if (current > previous); 130 arr.emplace_back(strpath.substr(previous, current - previous));; 131 previous = current + 1;; 132 current = strpath.find(slash, previous);; 133 }; 134 ; 135 if (previous < strpath.length()); 136 arr.emplace_back(strpath.substr(previous));; 137 ; 138 return arr;; 139}; 140 ; 141/////////////////////////////////////////////////////////////////////; 142/// Compare two paths,; ",MatchSource.WIKI,doc/master/RElement_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RElement_8cxx_source.html
https://root.cern/doc/master/RElement_8cxx_source.html:8972,Safety,avoid,avoid,8972,"wser to...Definition RElement.cxx:178; ROOT::Browsable::RElement::GetTitlevirtual std::string GetTitle() constTitle of browsable (optional)Definition RElement.hxx:71; ROOT::Browsable::RElement::ComparePathsstatic int ComparePaths(const RElementPath_t &path1, const RElementPath_t &path2)Compare two paths, Returns number of elements matches in both paths.Definition RElement.cxx:145; ROOT::Browsable::RElement::GetPathAsStringstatic std::string GetPathAsString(const RElementPath_t &path)Converts element path back to string.Definition RElement.cxx:160; ROOT::Browsable::RElement::GetSubElementstatic std::shared_ptr< RElement > GetSubElement(std::shared_ptr< RElement > &elem, const RElementPath_t &path)Returns sub element.Definition RElement.cxx:69; ROOT::Browsable::RElement::CreateItemvirtual std::unique_ptr< RItem > CreateItem() constReturns item with element description.Definition RElement.cxx:105; ROOT::Browsable::RElement::ParsePathstatic RElementPath_t ParsePath(const std::string &str)Parse string path to produce RElementPath_t One should avoid to use string pathes as much as possible...Definition RElement.cxx:116; ROOT::Experimental::RLogChannelA log configuration for a channel, e.g.Definition RLogger.hxx:101; TBufferJSON::ConvertToJSONstatic TString ConvertToJSON(const TObject *obj, Int_t compact=0, const char *member_name=nullptr)Converts object, inherited from TObject class, to JSON string Lower digit of compact parameter define...Definition TBufferJSON.cxx:522; TString::Dataconst char * Data() constDefinition TString.h:376; nconst Int_t nDefinition legend1.C:16; ROOT::BrowsableDefinition RAnyObjectHolder.hxx:15; ROOT::Browsable::RElementPath_tstd::vector< std::string > RElementPath_tDefinition RElement.hxx:20; ROOT::BrowsableLogROOT::Experimental::RLogChannel & BrowsableLog()Log channel for Browsable diagnostics.Definition RElement.cxx:20; slashTCanvas * slash()Definition slash.C:1. guibrowsablesrcRElement.cxx. ROOT master - Reference Guide Generated on Tue Nov ",MatchSource.WIKI,doc/master/RElement_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RElement_8cxx_source.html
https://root.cern/doc/master/RElement_8cxx_source.html:9083,Testability,log,log,9083,"e::RElement::GetTitlevirtual std::string GetTitle() constTitle of browsable (optional)Definition RElement.hxx:71; ROOT::Browsable::RElement::ComparePathsstatic int ComparePaths(const RElementPath_t &path1, const RElementPath_t &path2)Compare two paths, Returns number of elements matches in both paths.Definition RElement.cxx:145; ROOT::Browsable::RElement::GetPathAsStringstatic std::string GetPathAsString(const RElementPath_t &path)Converts element path back to string.Definition RElement.cxx:160; ROOT::Browsable::RElement::GetSubElementstatic std::shared_ptr< RElement > GetSubElement(std::shared_ptr< RElement > &elem, const RElementPath_t &path)Returns sub element.Definition RElement.cxx:69; ROOT::Browsable::RElement::CreateItemvirtual std::unique_ptr< RItem > CreateItem() constReturns item with element description.Definition RElement.cxx:105; ROOT::Browsable::RElement::ParsePathstatic RElementPath_t ParsePath(const std::string &str)Parse string path to produce RElementPath_t One should avoid to use string pathes as much as possible...Definition RElement.cxx:116; ROOT::Experimental::RLogChannelA log configuration for a channel, e.g.Definition RLogger.hxx:101; TBufferJSON::ConvertToJSONstatic TString ConvertToJSON(const TObject *obj, Int_t compact=0, const char *member_name=nullptr)Converts object, inherited from TObject class, to JSON string Lower digit of compact parameter define...Definition TBufferJSON.cxx:522; TString::Dataconst char * Data() constDefinition TString.h:376; nconst Int_t nDefinition legend1.C:16; ROOT::BrowsableDefinition RAnyObjectHolder.hxx:15; ROOT::Browsable::RElementPath_tstd::vector< std::string > RElementPath_tDefinition RElement.hxx:20; ROOT::BrowsableLogROOT::Experimental::RLogChannel & BrowsableLog()Log channel for Browsable diagnostics.Definition RElement.cxx:20; slashTCanvas * slash()Definition slash.C:1. guibrowsablesrcRElement.cxx. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:40:26 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/RElement_8cxx_source.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/RElement_8cxx_source.html
https://root.cern/doc/master/rf101__basics_8C.html:1973,Availability,error,errors,1973,"ma);; ; // Construct plot frame in 'x'; RooPlot *xframe = x.frame(Title(""Gaussian pdf.""));; ; // P l o t m o d e l a n d c h a n g e p a r a m e t e r v a l u e s; // ---------------------------------------------------------------------------; ; // Plot gauss in frame (i.e. in x); gauss.plotOn(xframe);; ; // Change the value of sigma to 3; sigma.setVal(3);; ; // Plot gauss in frame (i.e. in x) and draw frame on canvas; gauss.plotOn(xframe, LineColor(kRed));; ; // G e n e r a t e e v e n t s; // -----------------------------; ; // Generate a dataset of 1000 events in x from gauss; std::unique_ptr<RooDataSet> data{gauss.generate(x, 10000)};; ; // Make a second plot frame in x and draw both the; // data and the pdf in the frame; RooPlot *xframe2 = x.frame(Title(""Gaussian pdf with data""));; data->plotOn(xframe2);; gauss.plotOn(xframe2);; ; // F i t m o d e l t o d a t a; // -----------------------------; ; // Fit pdf to data; gauss.fitTo(*data, PrintLevel(-1));; ; // Print values of mean and sigma (that now reflect fitted values and errors); mean.Print();; sigma.Print();; ; // Draw all frames on a canvas; TCanvas *c = new TCanvas(""rf101_basics"", ""rf101_basics"", 800, 400); c->Divide(2);; c->cd(1);; gPad->SetLeftMargin(0.15);; xframe->GetYaxis()->SetTitleOffset(1.6);; xframe->Draw();; c->cd(2);; gPad->SetLeftMargin(0.15);; xframe2->GetYaxis()->SetTitleOffset(1.6);; xframe2->Draw();; }; c#define c(i)Definition RSha256.hxx:101; RooDataSet.h; RooGaussian.h; RooPlot.h; RooRealVar.h; kRed@ kRedDefinition Rtypes.h:66; TAxis.h; TCanvas.h; dataOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void dataDefinition TGWin32VirtualXProxy.cxx:104; gPad#define gPadDefinition TVirtualPad.h:308; RooGaussianPlain Gaussian p.d.f.Definition RooGaussian.h:24; RooPlotPlot frame and a container for graphics objects within that frame.Definition RooPlot.h:45; RooPlot::framestatic RooPlot * frame(c",MatchSource.WIKI,doc/master/rf101__basics_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf101__basics_8C.html
https://root.cern/doc/master/rf101__basics_8C.html:4178,Availability,error,error,4178,"efinition TVirtualPad.h:308; RooGaussianPlain Gaussian p.d.f.Definition RooGaussian.h:24; RooPlotPlot frame and a container for graphics objects within that frame.Definition RooPlot.h:45; RooPlot::framestatic RooPlot * frame(const RooAbsRealLValue &var, double xmin, double xmax, Int_t nBins)Create a new frame for a given variable in x.Definition RooPlot.cxx:225; RooPlot::GetYaxisTAxis * GetYaxis() constDefinition RooPlot.cxx:1264; RooPlot::Drawvoid Draw(Option_t *options=nullptr) overrideDraw this plot and all of the elements it contains.Definition RooPlot.cxx:637; RooRealVarVariable that can be changed from the outside.Definition RooRealVar.h:37; TAttAxis::SetTitleOffsetvirtual void SetTitleOffset(Float_t offset=1)Set distance between the axis and the axis title.Definition TAttAxis.cxx:298; TCanvasThe Canvas class.Definition TCanvas.h:23; sigmaconst Double_t sigmaDefinition h1analysisProxy.h:11; xDouble_t x[n]Definition legend1.C:17; RooFitThe namespace RooFit contains mostly switches that change the behaviour of functions of PDFs (or othe...Definition JSONIO.h:26; rf101_basicsDefinition rf101_basics.py:1; ; [#1] INFO:Fitting -- RooAbsPdf::fitTo(gauss_over_gauss_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_gauss_over_gauss_Int[x]_gaussData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; RooRealVar::mean = 1.01746 +/- 0.0300144 L(-10 - 10) ; RooRealVar::sigma = 2.9787 +/- 0.0219217 L(0.1 - 10) ; DateJuly 2008 ; AuthorWouter Verkerke ; Definition in file rf101_basics.C. tutorialsroofitrf101_basics.C. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:30 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/rf101__basics_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf101__basics_8C.html
https://root.cern/doc/master/rf101__basics_8C.html:581,Modifiability,variab,variables,581,". ROOT: tutorials/roofit/rf101_basics.C File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. rf101_basics.C File ReferenceTutorials  RooFit Tutorials. Detailed Description; Basic functionality: fitting, plotting, toy data generation on one-dimensional PDFs. ; pdf = gauss(x,m,s). ; #include ""RooRealVar.h""; #include ""RooDataSet.h""; #include ""RooGaussian.h""; #include ""TCanvas.h""; #include ""RooPlot.h""; #include ""TAxis.h""; using namespace RooFit;; ; void rf101_basics(); {; // S e t u p m o d e l; // ---------------------; ; // Declare variables x,mean,sigma with associated name, title, initial value and allowed range; RooRealVar x(""x"", ""x"", -10, 10);; RooRealVar mean(""mean"", ""mean of gaussian"", 1, -10, 10);; RooRealVar sigma(""sigma"", ""width of gaussian"", 1, 0.1, 10);; ; // Build gaussian pdf in terms of x,mean and sigma; RooGaussian gauss(""gauss"", ""gaussian PDF"", x, mean, sigma);; ; // Construct plot frame in 'x'; RooPlot *xframe = x.frame(Title(""Gaussian pdf.""));; ; // P l o t m o d e l a n d c h a n g e p a r a m e t e r v a l u e s; // ---------------------------------------------------------------------------; ; // Plot gauss in frame (i.e. in x); gauss.plotOn(xframe);; ; // Change the value of sigma to 3; sigma.setVal(3);; ; // Plot gauss in frame (i.e. in x) and draw frame on canvas; gauss.plotOn(xframe, LineColor(kRed));; ; // G e n e r a t e e v e n t s; // -----------------------------; ; // Generate a dataset of 1000 events in x from gauss; std::unique_ptr<RooDataSet> data{gauss.generate(x, 10000)};; ; // Make a second plot frame in x and draw both the; // data and the pdf in the frame; RooPlot *xframe2 = x.frame(Title(""Gaussian pdf with data""));; data->plotOn(xframe2);; gauss.plotOn(xframe2);; ; // F i t m o d e l t o d a t a; // -----------------------------; ; // Fit pdf to data; gauss.fitTo(*data, PrintLevel(-1));; ; // Print values of mean and sigma (that now reflect fitted values and errors); mean.Print();; sigm",MatchSource.WIKI,doc/master/rf101__basics_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf101__basics_8C.html
https://root.cern/doc/master/rf101__basics_8C.html:3026,Modifiability,variab,variable,3026,"values and errors); mean.Print();; sigma.Print();; ; // Draw all frames on a canvas; TCanvas *c = new TCanvas(""rf101_basics"", ""rf101_basics"", 800, 400); c->Divide(2);; c->cd(1);; gPad->SetLeftMargin(0.15);; xframe->GetYaxis()->SetTitleOffset(1.6);; xframe->Draw();; c->cd(2);; gPad->SetLeftMargin(0.15);; xframe2->GetYaxis()->SetTitleOffset(1.6);; xframe2->Draw();; }; c#define c(i)Definition RSha256.hxx:101; RooDataSet.h; RooGaussian.h; RooPlot.h; RooRealVar.h; kRed@ kRedDefinition Rtypes.h:66; TAxis.h; TCanvas.h; dataOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void dataDefinition TGWin32VirtualXProxy.cxx:104; gPad#define gPadDefinition TVirtualPad.h:308; RooGaussianPlain Gaussian p.d.f.Definition RooGaussian.h:24; RooPlotPlot frame and a container for graphics objects within that frame.Definition RooPlot.h:45; RooPlot::framestatic RooPlot * frame(const RooAbsRealLValue &var, double xmin, double xmax, Int_t nBins)Create a new frame for a given variable in x.Definition RooPlot.cxx:225; RooPlot::GetYaxisTAxis * GetYaxis() constDefinition RooPlot.cxx:1264; RooPlot::Drawvoid Draw(Option_t *options=nullptr) overrideDraw this plot and all of the elements it contains.Definition RooPlot.cxx:637; RooRealVarVariable that can be changed from the outside.Definition RooRealVar.h:37; TAttAxis::SetTitleOffsetvirtual void SetTitleOffset(Float_t offset=1)Set distance between the axis and the axis title.Definition TAttAxis.cxx:298; TCanvasThe Canvas class.Definition TCanvas.h:23; sigmaconst Double_t sigmaDefinition h1analysisProxy.h:11; xDouble_t x[n]Definition legend1.C:17; RooFitThe namespace RooFit contains mostly switches that change the behaviour of functions of PDFs (or othe...Definition JSONIO.h:26; rf101_basicsDefinition rf101_basics.py:1; ; [#1] INFO:Fitting -- RooAbsPdf::fitTo(gauss_over_gauss_Int[x]) fixing normalization set for coefficient determination to observables ",MatchSource.WIKI,doc/master/rf101__basics_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf101__basics_8C.html
https://root.cern/doc/master/rf101__basics_8C.html:4272,Performance,optimiz,optimization,4272,"efinition TVirtualPad.h:308; RooGaussianPlain Gaussian p.d.f.Definition RooGaussian.h:24; RooPlotPlot frame and a container for graphics objects within that frame.Definition RooPlot.h:45; RooPlot::framestatic RooPlot * frame(const RooAbsRealLValue &var, double xmin, double xmax, Int_t nBins)Create a new frame for a given variable in x.Definition RooPlot.cxx:225; RooPlot::GetYaxisTAxis * GetYaxis() constDefinition RooPlot.cxx:1264; RooPlot::Drawvoid Draw(Option_t *options=nullptr) overrideDraw this plot and all of the elements it contains.Definition RooPlot.cxx:637; RooRealVarVariable that can be changed from the outside.Definition RooRealVar.h:37; TAttAxis::SetTitleOffsetvirtual void SetTitleOffset(Float_t offset=1)Set distance between the axis and the axis title.Definition TAttAxis.cxx:298; TCanvasThe Canvas class.Definition TCanvas.h:23; sigmaconst Double_t sigmaDefinition h1analysisProxy.h:11; xDouble_t x[n]Definition legend1.C:17; RooFitThe namespace RooFit contains mostly switches that change the behaviour of functions of PDFs (or othe...Definition JSONIO.h:26; rf101_basicsDefinition rf101_basics.py:1; ; [#1] INFO:Fitting -- RooAbsPdf::fitTo(gauss_over_gauss_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_gauss_over_gauss_Int[x]_gaussData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; RooRealVar::mean = 1.01746 +/- 0.0300144 L(-10 - 10) ; RooRealVar::sigma = 2.9787 +/- 0.0219217 L(0.1 - 10) ; DateJuly 2008 ; AuthorWouter Verkerke ; Definition in file rf101_basics.C. tutorialsroofitrf101_basics.C. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:30 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/rf101__basics_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf101__basics_8C.html
https://root.cern/doc/master/rf101__basics_8C.html:4369,Performance,optimiz,optimization,4369,"efinition TVirtualPad.h:308; RooGaussianPlain Gaussian p.d.f.Definition RooGaussian.h:24; RooPlotPlot frame and a container for graphics objects within that frame.Definition RooPlot.h:45; RooPlot::framestatic RooPlot * frame(const RooAbsRealLValue &var, double xmin, double xmax, Int_t nBins)Create a new frame for a given variable in x.Definition RooPlot.cxx:225; RooPlot::GetYaxisTAxis * GetYaxis() constDefinition RooPlot.cxx:1264; RooPlot::Drawvoid Draw(Option_t *options=nullptr) overrideDraw this plot and all of the elements it contains.Definition RooPlot.cxx:637; RooRealVarVariable that can be changed from the outside.Definition RooRealVar.h:37; TAttAxis::SetTitleOffsetvirtual void SetTitleOffset(Float_t offset=1)Set distance between the axis and the axis title.Definition TAttAxis.cxx:298; TCanvasThe Canvas class.Definition TCanvas.h:23; sigmaconst Double_t sigmaDefinition h1analysisProxy.h:11; xDouble_t x[n]Definition legend1.C:17; RooFitThe namespace RooFit contains mostly switches that change the behaviour of functions of PDFs (or othe...Definition JSONIO.h:26; rf101_basicsDefinition rf101_basics.py:1; ; [#1] INFO:Fitting -- RooAbsPdf::fitTo(gauss_over_gauss_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_gauss_over_gauss_Int[x]_gaussData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; RooRealVar::mean = 1.01746 +/- 0.0300144 L(-10 - 10) ; RooRealVar::sigma = 2.9787 +/- 0.0219217 L(0.1 - 10) ; DateJuly 2008 ; AuthorWouter Verkerke ; Definition in file rf101_basics.C. tutorialsroofitrf101_basics.C. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:30 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/rf101__basics_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf101__basics_8C.html
https://root.cern/doc/master/rf101__basics_8py.html:1688,Availability,error,errors,1688,"terms of x,mean and sigma; gauss = ROOT.RooGaussian(""gauss"", ""gaussian PDF"", x, mean, sigma); ; # Construct plot frame in 'x'; xframe = x.frame(Title=""Gaussian pdf"") # RooPlot; ; # Plot model and change parameter values; # ---------------------------------------------------------------------------; # Plot gauss in frame (i.e. in x); gauss.plotOn(xframe); ; # Change the value of sigma to 3; sigma.setVal(3); ; # Plot gauss in frame (i.e. in x) and draw frame on canvas; gauss.plotOn(xframe, LineColor=""r""); ; # Generate events; # -----------------------------; # Generate a dataset of 1000 events in x from gauss; data = gauss.generate({x}, 10000) # ROOT.RooDataSet; ; # Make a second plot frame in x and draw both the; # data and the pdf in the frame; xframe2 = x.frame(Title=""Gaussian pdf with data"") # RooPlot; data.plotOn(xframe2); gauss.plotOn(xframe2); ; # Fit model to data; # -----------------------------; # Fit pdf to data; gauss.fitTo(data, PrintLevel=-1); ; # Print values of mean and sigma (that now reflect fitted values and; # errors); mean.Print(); sigma.Print(); ; # Draw all frames on a canvas; c = ROOT.TCanvas(""rf101_basics"", ""rf101_basics"", 800, 400); c.Divide(2); c.cd(1); ROOT.gPad.SetLeftMargin(0.15); xframe.GetYaxis().SetTitleOffset(1.6); xframe.Draw(); c.cd(2); ROOT.gPad.SetLeftMargin(0.15); xframe2.GetYaxis().SetTitleOffset(1.6); xframe2.Draw(); ; c.SaveAs(""rf101_basics.png""); [#1] INFO:Fitting -- RooAbsPdf::fitTo(gauss_over_gauss_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_gauss_over_gauss_Int[x]_gaussData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; RooRealVar::mean = 1.01746 +/- 0.0300",MatchSource.WIKI,doc/master/rf101__basics_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf101__basics_8py.html
https://root.cern/doc/master/rf101__basics_8py.html:2402,Availability,error,error,2402,"me (i.e. in x); gauss.plotOn(xframe); ; # Change the value of sigma to 3; sigma.setVal(3); ; # Plot gauss in frame (i.e. in x) and draw frame on canvas; gauss.plotOn(xframe, LineColor=""r""); ; # Generate events; # -----------------------------; # Generate a dataset of 1000 events in x from gauss; data = gauss.generate({x}, 10000) # ROOT.RooDataSet; ; # Make a second plot frame in x and draw both the; # data and the pdf in the frame; xframe2 = x.frame(Title=""Gaussian pdf with data"") # RooPlot; data.plotOn(xframe2); gauss.plotOn(xframe2); ; # Fit model to data; # -----------------------------; # Fit pdf to data; gauss.fitTo(data, PrintLevel=-1); ; # Print values of mean and sigma (that now reflect fitted values and; # errors); mean.Print(); sigma.Print(); ; # Draw all frames on a canvas; c = ROOT.TCanvas(""rf101_basics"", ""rf101_basics"", 800, 400); c.Divide(2); c.cd(1); ROOT.gPad.SetLeftMargin(0.15); xframe.GetYaxis().SetTitleOffset(1.6); xframe.Draw(); c.cd(2); ROOT.gPad.SetLeftMargin(0.15); xframe2.GetYaxis().SetTitleOffset(1.6); xframe2.Draw(); ; c.SaveAs(""rf101_basics.png""); [#1] INFO:Fitting -- RooAbsPdf::fitTo(gauss_over_gauss_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_gauss_over_gauss_Int[x]_gaussData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; RooRealVar::mean = 1.01746 +/- 0.0300144 L(-10 - 10) ; RooRealVar::sigma = 2.9787 +/- 0.0219217 L(0.1 - 10) ; DateFebruary 2018 ; AuthorsClemens Lange, Wouter Verkerke (C++ version) ; Definition in file rf101_basics.py. tutorialsroofitrf101_basics.py. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:30 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/rf101__basics_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf101__basics_8py.html
https://root.cern/doc/master/rf101__basics_8py.html:359,Modifiability,variab,variables,359,". ROOT: tutorials/roofit/rf101_basics.py File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. Namespaces ; rf101_basics.py File ReferenceTutorials  RooFit Tutorials. Detailed Description; This tutorial illustrates the basic features of RooFit. . ; import ROOT; ; # Set up model; # ---------------------; # Declare variables x,mean,sigma with associated name, title, initial; # value and allowed range; x = ROOT.RooRealVar(""x"", ""x"", -10, 10); mean = ROOT.RooRealVar(""mean"", ""mean of gaussian"", 1, -10, 10); sigma = ROOT.RooRealVar(""sigma"", ""width of gaussian"", 1, 0.1, 10); ; # Build gaussian pdf in terms of x,mean and sigma; gauss = ROOT.RooGaussian(""gauss"", ""gaussian PDF"", x, mean, sigma); ; # Construct plot frame in 'x'; xframe = x.frame(Title=""Gaussian pdf"") # RooPlot; ; # Plot model and change parameter values; # ---------------------------------------------------------------------------; # Plot gauss in frame (i.e. in x); gauss.plotOn(xframe); ; # Change the value of sigma to 3; sigma.setVal(3); ; # Plot gauss in frame (i.e. in x) and draw frame on canvas; gauss.plotOn(xframe, LineColor=""r""); ; # Generate events; # -----------------------------; # Generate a dataset of 1000 events in x from gauss; data = gauss.generate({x}, 10000) # ROOT.RooDataSet; ; # Make a second plot frame in x and draw both the; # data and the pdf in the frame; xframe2 = x.frame(Title=""Gaussian pdf with data"") # RooPlot; data.plotOn(xframe2); gauss.plotOn(xframe2); ; # Fit model to data; # -----------------------------; # Fit pdf to data; gauss.fitTo(data, PrintLevel=-1); ; # Print values of mean and sigma (that now reflect fitted values and; # errors); mean.Print(); sigma.Print(); ; # Draw all frames on a canvas; c = ROOT.TCanvas(""rf101_basics"", ""rf101_basics"", 800, 400); c.Divide(2); c.cd(1); ROOT.gPad.SetLeftMargin(0.15); xframe.GetYaxis().SetTitleOffset(1.6); xframe.Draw(); c.cd(2); ROOT.gPad.SetLeftMargin(0.15); xframe2.GetYaxis().SetTitleOffset(1",MatchSource.WIKI,doc/master/rf101__basics_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf101__basics_8py.html
https://root.cern/doc/master/rf101__basics_8py.html:2496,Performance,optimiz,optimization,2496,"me (i.e. in x); gauss.plotOn(xframe); ; # Change the value of sigma to 3; sigma.setVal(3); ; # Plot gauss in frame (i.e. in x) and draw frame on canvas; gauss.plotOn(xframe, LineColor=""r""); ; # Generate events; # -----------------------------; # Generate a dataset of 1000 events in x from gauss; data = gauss.generate({x}, 10000) # ROOT.RooDataSet; ; # Make a second plot frame in x and draw both the; # data and the pdf in the frame; xframe2 = x.frame(Title=""Gaussian pdf with data"") # RooPlot; data.plotOn(xframe2); gauss.plotOn(xframe2); ; # Fit model to data; # -----------------------------; # Fit pdf to data; gauss.fitTo(data, PrintLevel=-1); ; # Print values of mean and sigma (that now reflect fitted values and; # errors); mean.Print(); sigma.Print(); ; # Draw all frames on a canvas; c = ROOT.TCanvas(""rf101_basics"", ""rf101_basics"", 800, 400); c.Divide(2); c.cd(1); ROOT.gPad.SetLeftMargin(0.15); xframe.GetYaxis().SetTitleOffset(1.6); xframe.Draw(); c.cd(2); ROOT.gPad.SetLeftMargin(0.15); xframe2.GetYaxis().SetTitleOffset(1.6); xframe2.Draw(); ; c.SaveAs(""rf101_basics.png""); [#1] INFO:Fitting -- RooAbsPdf::fitTo(gauss_over_gauss_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_gauss_over_gauss_Int[x]_gaussData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; RooRealVar::mean = 1.01746 +/- 0.0300144 L(-10 - 10) ; RooRealVar::sigma = 2.9787 +/- 0.0219217 L(0.1 - 10) ; DateFebruary 2018 ; AuthorsClemens Lange, Wouter Verkerke (C++ version) ; Definition in file rf101_basics.py. tutorialsroofitrf101_basics.py. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:30 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/rf101__basics_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf101__basics_8py.html
https://root.cern/doc/master/rf101__basics_8py.html:2593,Performance,optimiz,optimization,2593,"me (i.e. in x); gauss.plotOn(xframe); ; # Change the value of sigma to 3; sigma.setVal(3); ; # Plot gauss in frame (i.e. in x) and draw frame on canvas; gauss.plotOn(xframe, LineColor=""r""); ; # Generate events; # -----------------------------; # Generate a dataset of 1000 events in x from gauss; data = gauss.generate({x}, 10000) # ROOT.RooDataSet; ; # Make a second plot frame in x and draw both the; # data and the pdf in the frame; xframe2 = x.frame(Title=""Gaussian pdf with data"") # RooPlot; data.plotOn(xframe2); gauss.plotOn(xframe2); ; # Fit model to data; # -----------------------------; # Fit pdf to data; gauss.fitTo(data, PrintLevel=-1); ; # Print values of mean and sigma (that now reflect fitted values and; # errors); mean.Print(); sigma.Print(); ; # Draw all frames on a canvas; c = ROOT.TCanvas(""rf101_basics"", ""rf101_basics"", 800, 400); c.Divide(2); c.cd(1); ROOT.gPad.SetLeftMargin(0.15); xframe.GetYaxis().SetTitleOffset(1.6); xframe.Draw(); c.cd(2); ROOT.gPad.SetLeftMargin(0.15); xframe2.GetYaxis().SetTitleOffset(1.6); xframe2.Draw(); ; c.SaveAs(""rf101_basics.png""); [#1] INFO:Fitting -- RooAbsPdf::fitTo(gauss_over_gauss_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_gauss_over_gauss_Int[x]_gaussData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; RooRealVar::mean = 1.01746 +/- 0.0300144 L(-10 - 10) ; RooRealVar::sigma = 2.9787 +/- 0.0219217 L(0.1 - 10) ; DateFebruary 2018 ; AuthorsClemens Lange, Wouter Verkerke (C++ version) ; Definition in file rf101_basics.py. tutorialsroofitrf101_basics.py. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:30 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/rf101__basics_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf101__basics_8py.html
https://root.cern/doc/master/rf102__dataimport_8C.html:1307,Availability,error,error,1307,". ROOT: tutorials/roofit/rf102_dataimport.C File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. rf102_dataimport.C File ReferenceTutorials  RooFit Tutorials. Detailed Description; Basic functionality: importing data from ROOT TTrees and THx histograms. . ; #include ""RooRealVar.h""; #include ""RooDataSet.h""; #include ""RooDataHist.h""; #include ""RooGaussian.h""; #include ""TCanvas.h""; #include ""RooPlot.h""; #include ""TTree.h""; #include ""TH1D.h""; #include ""TRandom.h""; using namespace RooFit;; ; TH1 *makeTH1();; TTree *makeTTree();; ; void rf102_dataimport(); {; // ---------------------------------------------------; // I m p o r t i n g R O O T h i s t o g r a m s; // ===================================================; ; // I m p o r t T H 1 i n t o a R o o D a t a H i s t; // ---------------------------------------------------------; ; // Create a ROOT TH1 histogram; TH1 *hh = makeTH1();; ; // Declare observable x; RooRealVar x(""x"", ""x"", -10, 10);; ; // Create a binned dataset that imports contents of TH1 and associates its contents to observable 'x'; RooDataHist dh(""dh"", ""dh"", x, Import(*hh));; ; // P l o t a n d f i t a R o o D a t a H i s t; // ---------------------------------------------------; ; // Make plot of binned dataset showing Poisson error bars (RooFit default); RooPlot *frame = x.frame(Title(""Imported TH1 with Poisson error bars""));; dh.plotOn(frame);; ; // Fit a Gaussian pdf to the data; RooRealVar mean(""mean"", ""mean"", 0, -10, 10);; RooRealVar sigma(""sigma"", ""sigma"", 3, 0.1, 10);; RooGaussian gauss(""gauss"", ""gauss"", x, mean, sigma);; gauss.fitTo(dh, PrintLevel(-1));; gauss.plotOn(frame);; ; // P l o t a n d f i t a R o o D a t a H i s t w i t h i n t e r n a l e r r o r s; // ---------------------------------------------------------------------------------------------; ; // If histogram has custom error (i.e. its contents is does not originate from a Poisson process; // but e.g. is a sum of weighted events) you c",MatchSource.WIKI,doc/master/rf102__dataimport_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8C.html
https://root.cern/doc/master/rf102__dataimport_8C.html:1394,Availability,error,error,1394,"ude ""RooGaussian.h""; #include ""TCanvas.h""; #include ""RooPlot.h""; #include ""TTree.h""; #include ""TH1D.h""; #include ""TRandom.h""; using namespace RooFit;; ; TH1 *makeTH1();; TTree *makeTTree();; ; void rf102_dataimport(); {; // ---------------------------------------------------; // I m p o r t i n g R O O T h i s t o g r a m s; // ===================================================; ; // I m p o r t T H 1 i n t o a R o o D a t a H i s t; // ---------------------------------------------------------; ; // Create a ROOT TH1 histogram; TH1 *hh = makeTH1();; ; // Declare observable x; RooRealVar x(""x"", ""x"", -10, 10);; ; // Create a binned dataset that imports contents of TH1 and associates its contents to observable 'x'; RooDataHist dh(""dh"", ""dh"", x, Import(*hh));; ; // P l o t a n d f i t a R o o D a t a H i s t; // ---------------------------------------------------; ; // Make plot of binned dataset showing Poisson error bars (RooFit default); RooPlot *frame = x.frame(Title(""Imported TH1 with Poisson error bars""));; dh.plotOn(frame);; ; // Fit a Gaussian pdf to the data; RooRealVar mean(""mean"", ""mean"", 0, -10, 10);; RooRealVar sigma(""sigma"", ""sigma"", 3, 0.1, 10);; RooGaussian gauss(""gauss"", ""gauss"", x, mean, sigma);; gauss.fitTo(dh, PrintLevel(-1));; gauss.plotOn(frame);; ; // P l o t a n d f i t a R o o D a t a H i s t w i t h i n t e r n a l e r r o r s; // ---------------------------------------------------------------------------------------------; ; // If histogram has custom error (i.e. its contents is does not originate from a Poisson process; // but e.g. is a sum of weighted events) you can data with symmetric 'sum-of-weights' error instead; // (same error bars as shown by ROOT); RooPlot *frame2 = x.frame(Title(""Imported TH1 with internal errors""));; dh.plotOn(frame2, DataError(RooAbsData::SumW2));; gauss.plotOn(frame2);; ; // Please note that error bars shown (Poisson or SumW2) are for visualization only, the are NOT used; // in a maximum likelihood fit; //; // A",MatchSource.WIKI,doc/master/rf102__dataimport_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8C.html
https://root.cern/doc/master/rf102__dataimport_8C.html:1884,Availability,error,error,1884,"m p o r t T H 1 i n t o a R o o D a t a H i s t; // ---------------------------------------------------------; ; // Create a ROOT TH1 histogram; TH1 *hh = makeTH1();; ; // Declare observable x; RooRealVar x(""x"", ""x"", -10, 10);; ; // Create a binned dataset that imports contents of TH1 and associates its contents to observable 'x'; RooDataHist dh(""dh"", ""dh"", x, Import(*hh));; ; // P l o t a n d f i t a R o o D a t a H i s t; // ---------------------------------------------------; ; // Make plot of binned dataset showing Poisson error bars (RooFit default); RooPlot *frame = x.frame(Title(""Imported TH1 with Poisson error bars""));; dh.plotOn(frame);; ; // Fit a Gaussian pdf to the data; RooRealVar mean(""mean"", ""mean"", 0, -10, 10);; RooRealVar sigma(""sigma"", ""sigma"", 3, 0.1, 10);; RooGaussian gauss(""gauss"", ""gauss"", x, mean, sigma);; gauss.fitTo(dh, PrintLevel(-1));; gauss.plotOn(frame);; ; // P l o t a n d f i t a R o o D a t a H i s t w i t h i n t e r n a l e r r o r s; // ---------------------------------------------------------------------------------------------; ; // If histogram has custom error (i.e. its contents is does not originate from a Poisson process; // but e.g. is a sum of weighted events) you can data with symmetric 'sum-of-weights' error instead; // (same error bars as shown by ROOT); RooPlot *frame2 = x.frame(Title(""Imported TH1 with internal errors""));; dh.plotOn(frame2, DataError(RooAbsData::SumW2));; gauss.plotOn(frame2);; ; // Please note that error bars shown (Poisson or SumW2) are for visualization only, the are NOT used; // in a maximum likelihood fit; //; // A (binned) ML fit will ALWAYS assume the Poisson error interpretation of data (the mathematical definition; // of likelihood does not take any external definition of errors). Data with non-unit weights can only be correctly; // fitted with a chi^2 fit (see rf602_chi2fit.C); ; // -----------------------------------------; // I m p o r t i n g R O O T T T r e e s; // =======================",MatchSource.WIKI,doc/master/rf102__dataimport_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8C.html
https://root.cern/doc/master/rf102__dataimport_8C.html:2041,Availability,error,error,2041,"rts contents of TH1 and associates its contents to observable 'x'; RooDataHist dh(""dh"", ""dh"", x, Import(*hh));; ; // P l o t a n d f i t a R o o D a t a H i s t; // ---------------------------------------------------; ; // Make plot of binned dataset showing Poisson error bars (RooFit default); RooPlot *frame = x.frame(Title(""Imported TH1 with Poisson error bars""));; dh.plotOn(frame);; ; // Fit a Gaussian pdf to the data; RooRealVar mean(""mean"", ""mean"", 0, -10, 10);; RooRealVar sigma(""sigma"", ""sigma"", 3, 0.1, 10);; RooGaussian gauss(""gauss"", ""gauss"", x, mean, sigma);; gauss.fitTo(dh, PrintLevel(-1));; gauss.plotOn(frame);; ; // P l o t a n d f i t a R o o D a t a H i s t w i t h i n t e r n a l e r r o r s; // ---------------------------------------------------------------------------------------------; ; // If histogram has custom error (i.e. its contents is does not originate from a Poisson process; // but e.g. is a sum of weighted events) you can data with symmetric 'sum-of-weights' error instead; // (same error bars as shown by ROOT); RooPlot *frame2 = x.frame(Title(""Imported TH1 with internal errors""));; dh.plotOn(frame2, DataError(RooAbsData::SumW2));; gauss.plotOn(frame2);; ; // Please note that error bars shown (Poisson or SumW2) are for visualization only, the are NOT used; // in a maximum likelihood fit; //; // A (binned) ML fit will ALWAYS assume the Poisson error interpretation of data (the mathematical definition; // of likelihood does not take any external definition of errors). Data with non-unit weights can only be correctly; // fitted with a chi^2 fit (see rf602_chi2fit.C); ; // -----------------------------------------; // I m p o r t i n g R O O T T T r e e s; // =========================================; ; // I m p o r t T T r e e i n t o a R o o D a t a S e t; // -----------------------------------------------------------; ; TTree *tree = makeTTree();; ; // Define 2nd observable y; RooRealVar y(""y"", ""y"", -10, 10);; ; // Construct unbinned dataset",MatchSource.WIKI,doc/master/rf102__dataimport_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8C.html
https://root.cern/doc/master/rf102__dataimport_8C.html:2065,Availability,error,error,2065,"rts contents of TH1 and associates its contents to observable 'x'; RooDataHist dh(""dh"", ""dh"", x, Import(*hh));; ; // P l o t a n d f i t a R o o D a t a H i s t; // ---------------------------------------------------; ; // Make plot of binned dataset showing Poisson error bars (RooFit default); RooPlot *frame = x.frame(Title(""Imported TH1 with Poisson error bars""));; dh.plotOn(frame);; ; // Fit a Gaussian pdf to the data; RooRealVar mean(""mean"", ""mean"", 0, -10, 10);; RooRealVar sigma(""sigma"", ""sigma"", 3, 0.1, 10);; RooGaussian gauss(""gauss"", ""gauss"", x, mean, sigma);; gauss.fitTo(dh, PrintLevel(-1));; gauss.plotOn(frame);; ; // P l o t a n d f i t a R o o D a t a H i s t w i t h i n t e r n a l e r r o r s; // ---------------------------------------------------------------------------------------------; ; // If histogram has custom error (i.e. its contents is does not originate from a Poisson process; // but e.g. is a sum of weighted events) you can data with symmetric 'sum-of-weights' error instead; // (same error bars as shown by ROOT); RooPlot *frame2 = x.frame(Title(""Imported TH1 with internal errors""));; dh.plotOn(frame2, DataError(RooAbsData::SumW2));; gauss.plotOn(frame2);; ; // Please note that error bars shown (Poisson or SumW2) are for visualization only, the are NOT used; // in a maximum likelihood fit; //; // A (binned) ML fit will ALWAYS assume the Poisson error interpretation of data (the mathematical definition; // of likelihood does not take any external definition of errors). Data with non-unit weights can only be correctly; // fitted with a chi^2 fit (see rf602_chi2fit.C); ; // -----------------------------------------; // I m p o r t i n g R O O T T T r e e s; // =========================================; ; // I m p o r t T T r e e i n t o a R o o D a t a S e t; // -----------------------------------------------------------; ; TTree *tree = makeTTree();; ; // Define 2nd observable y; RooRealVar y(""y"", ""y"", -10, 10);; ; // Construct unbinned dataset",MatchSource.WIKI,doc/master/rf102__dataimport_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8C.html
https://root.cern/doc/master/rf102__dataimport_8C.html:2155,Availability,error,errors,2155,"t(*hh));; ; // P l o t a n d f i t a R o o D a t a H i s t; // ---------------------------------------------------; ; // Make plot of binned dataset showing Poisson error bars (RooFit default); RooPlot *frame = x.frame(Title(""Imported TH1 with Poisson error bars""));; dh.plotOn(frame);; ; // Fit a Gaussian pdf to the data; RooRealVar mean(""mean"", ""mean"", 0, -10, 10);; RooRealVar sigma(""sigma"", ""sigma"", 3, 0.1, 10);; RooGaussian gauss(""gauss"", ""gauss"", x, mean, sigma);; gauss.fitTo(dh, PrintLevel(-1));; gauss.plotOn(frame);; ; // P l o t a n d f i t a R o o D a t a H i s t w i t h i n t e r n a l e r r o r s; // ---------------------------------------------------------------------------------------------; ; // If histogram has custom error (i.e. its contents is does not originate from a Poisson process; // but e.g. is a sum of weighted events) you can data with symmetric 'sum-of-weights' error instead; // (same error bars as shown by ROOT); RooPlot *frame2 = x.frame(Title(""Imported TH1 with internal errors""));; dh.plotOn(frame2, DataError(RooAbsData::SumW2));; gauss.plotOn(frame2);; ; // Please note that error bars shown (Poisson or SumW2) are for visualization only, the are NOT used; // in a maximum likelihood fit; //; // A (binned) ML fit will ALWAYS assume the Poisson error interpretation of data (the mathematical definition; // of likelihood does not take any external definition of errors). Data with non-unit weights can only be correctly; // fitted with a chi^2 fit (see rf602_chi2fit.C); ; // -----------------------------------------; // I m p o r t i n g R O O T T T r e e s; // =========================================; ; // I m p o r t T T r e e i n t o a R o o D a t a S e t; // -----------------------------------------------------------; ; TTree *tree = makeTTree();; ; // Define 2nd observable y; RooRealVar y(""y"", ""y"", -10, 10);; ; // Construct unbinned dataset importing tree branches x and y matching between branches and RooRealVars; // is done by name of the ",MatchSource.WIKI,doc/master/rf102__dataimport_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8C.html
https://root.cern/doc/master/rf102__dataimport_8C.html:2262,Availability,error,error,2262,"son error bars""));; dh.plotOn(frame);; ; // Fit a Gaussian pdf to the data; RooRealVar mean(""mean"", ""mean"", 0, -10, 10);; RooRealVar sigma(""sigma"", ""sigma"", 3, 0.1, 10);; RooGaussian gauss(""gauss"", ""gauss"", x, mean, sigma);; gauss.fitTo(dh, PrintLevel(-1));; gauss.plotOn(frame);; ; // P l o t a n d f i t a R o o D a t a H i s t w i t h i n t e r n a l e r r o r s; // ---------------------------------------------------------------------------------------------; ; // If histogram has custom error (i.e. its contents is does not originate from a Poisson process; // but e.g. is a sum of weighted events) you can data with symmetric 'sum-of-weights' error instead; // (same error bars as shown by ROOT); RooPlot *frame2 = x.frame(Title(""Imported TH1 with internal errors""));; dh.plotOn(frame2, DataError(RooAbsData::SumW2));; gauss.plotOn(frame2);; ; // Please note that error bars shown (Poisson or SumW2) are for visualization only, the are NOT used; // in a maximum likelihood fit; //; // A (binned) ML fit will ALWAYS assume the Poisson error interpretation of data (the mathematical definition; // of likelihood does not take any external definition of errors). Data with non-unit weights can only be correctly; // fitted with a chi^2 fit (see rf602_chi2fit.C); ; // -----------------------------------------; // I m p o r t i n g R O O T T T r e e s; // =========================================; ; // I m p o r t T T r e e i n t o a R o o D a t a S e t; // -----------------------------------------------------------; ; TTree *tree = makeTTree();; ; // Define 2nd observable y; RooRealVar y(""y"", ""y"", -10, 10);; ; // Construct unbinned dataset importing tree branches x and y matching between branches and RooRealVars; // is done by name of the branch/RRV; //; // Note that ONLY entries for which x,y have values within their allowed ranges as defined in; // RooRealVar x and y are imported. Since the y values in the import tree are in the range [-15,15]; // and RRV y defines a range [-10,1",MatchSource.WIKI,doc/master/rf102__dataimport_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8C.html
https://root.cern/doc/master/rf102__dataimport_8C.html:2432,Availability,error,error,2432,"son error bars""));; dh.plotOn(frame);; ; // Fit a Gaussian pdf to the data; RooRealVar mean(""mean"", ""mean"", 0, -10, 10);; RooRealVar sigma(""sigma"", ""sigma"", 3, 0.1, 10);; RooGaussian gauss(""gauss"", ""gauss"", x, mean, sigma);; gauss.fitTo(dh, PrintLevel(-1));; gauss.plotOn(frame);; ; // P l o t a n d f i t a R o o D a t a H i s t w i t h i n t e r n a l e r r o r s; // ---------------------------------------------------------------------------------------------; ; // If histogram has custom error (i.e. its contents is does not originate from a Poisson process; // but e.g. is a sum of weighted events) you can data with symmetric 'sum-of-weights' error instead; // (same error bars as shown by ROOT); RooPlot *frame2 = x.frame(Title(""Imported TH1 with internal errors""));; dh.plotOn(frame2, DataError(RooAbsData::SumW2));; gauss.plotOn(frame2);; ; // Please note that error bars shown (Poisson or SumW2) are for visualization only, the are NOT used; // in a maximum likelihood fit; //; // A (binned) ML fit will ALWAYS assume the Poisson error interpretation of data (the mathematical definition; // of likelihood does not take any external definition of errors). Data with non-unit weights can only be correctly; // fitted with a chi^2 fit (see rf602_chi2fit.C); ; // -----------------------------------------; // I m p o r t i n g R O O T T T r e e s; // =========================================; ; // I m p o r t T T r e e i n t o a R o o D a t a S e t; // -----------------------------------------------------------; ; TTree *tree = makeTTree();; ; // Define 2nd observable y; RooRealVar y(""y"", ""y"", -10, 10);; ; // Construct unbinned dataset importing tree branches x and y matching between branches and RooRealVars; // is done by name of the branch/RRV; //; // Note that ONLY entries for which x,y have values within their allowed ranges as defined in; // RooRealVar x and y are imported. Since the y values in the import tree are in the range [-15,15]; // and RRV y defines a range [-10,1",MatchSource.WIKI,doc/master/rf102__dataimport_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8C.html
https://root.cern/doc/master/rf102__dataimport_8C.html:2549,Availability,error,errors,2549,"son error bars""));; dh.plotOn(frame);; ; // Fit a Gaussian pdf to the data; RooRealVar mean(""mean"", ""mean"", 0, -10, 10);; RooRealVar sigma(""sigma"", ""sigma"", 3, 0.1, 10);; RooGaussian gauss(""gauss"", ""gauss"", x, mean, sigma);; gauss.fitTo(dh, PrintLevel(-1));; gauss.plotOn(frame);; ; // P l o t a n d f i t a R o o D a t a H i s t w i t h i n t e r n a l e r r o r s; // ---------------------------------------------------------------------------------------------; ; // If histogram has custom error (i.e. its contents is does not originate from a Poisson process; // but e.g. is a sum of weighted events) you can data with symmetric 'sum-of-weights' error instead; // (same error bars as shown by ROOT); RooPlot *frame2 = x.frame(Title(""Imported TH1 with internal errors""));; dh.plotOn(frame2, DataError(RooAbsData::SumW2));; gauss.plotOn(frame2);; ; // Please note that error bars shown (Poisson or SumW2) are for visualization only, the are NOT used; // in a maximum likelihood fit; //; // A (binned) ML fit will ALWAYS assume the Poisson error interpretation of data (the mathematical definition; // of likelihood does not take any external definition of errors). Data with non-unit weights can only be correctly; // fitted with a chi^2 fit (see rf602_chi2fit.C); ; // -----------------------------------------; // I m p o r t i n g R O O T T T r e e s; // =========================================; ; // I m p o r t T T r e e i n t o a R o o D a t a S e t; // -----------------------------------------------------------; ; TTree *tree = makeTTree();; ; // Define 2nd observable y; RooRealVar y(""y"", ""y"", -10, 10);; ; // Construct unbinned dataset importing tree branches x and y matching between branches and RooRealVars; // is done by name of the branch/RRV; //; // Note that ONLY entries for which x,y have values within their allowed ranges as defined in; // RooRealVar x and y are imported. Since the y values in the import tree are in the range [-15,15]; // and RRV y defines a range [-10,1",MatchSource.WIKI,doc/master/rf102__dataimport_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8C.html
https://root.cern/doc/master/rf102__dataimport_8C.html:10533,Availability,error,error,10533,"Distribution with the given mean and sigm...Definition TRandom.cxx:275; TRandom::Uniformvirtual Double_t Uniform(Double_t x1=1)Returns a uniform deviate on the interval (0, x1).Definition TRandom.cxx:682; TTreeA TTree represents a columnar dataset.Definition TTree.h:79; double; sigmaconst Double_t sigmaDefinition h1analysisProxy.h:11; yDouble_t y[n]Definition legend1.C:17; xDouble_t x[n]Definition legend1.C:17; RooFitThe namespace RooFit contains mostly switches that change the behaviour of functions of PDFs (or othe...Definition JSONIO.h:26; TMVA_SOFIE_GNN_Parser.treetreeDefinition TMVA_SOFIE_GNN_Parser.py:169; rf102_dataimportDefinition rf102_dataimport.py:1; ; [#1] INFO:Fitting -- RooAbsPdf::fitTo(gauss_over_gauss_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_gauss_over_gauss_Int[x]_dh) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #0 because y cannot accommodate the value 14.424; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #3 because y cannot accommodate the value -12.0022; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #5 because y cannot accommodate the value 13.8261; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #6 because y cannot accommodate the value -14.9925; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping ...; [#0] WARNING:DataHandling -- RooTreeDataStore::loadValues(ds) Ignored 36 out-of-range events; ; -----------------------; Reading data from ASCII; [#1] INFO:DataHandling -- RooDataSet::read: reading file rf102_",MatchSource.WIKI,doc/master/rf102__dataimport_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8C.html
https://root.cern/doc/master/rf102__dataimport_8C.html:4275,Integrability,message,message,4275,"mported. Since the y values in the import tree are in the range [-15,15]; // and RRV y defines a range [-10,10] this means that the RooDataSet below will have less entries than the TTree; // 'tree'; ; RooDataSet ds(""ds"", ""ds"", RooArgSet(x, y), Import(*tree));; ; // U s e a s c i i i m p o r t / e x p o r t f o r d a t a s e t s; // ------------------------------------------------------------------------------------; {; // Write data to output stream; std::ofstream outstream(""rf102_testData.txt"");; // Optionally, adjust the stream here (e.g. std::setprecision); ds.write(outstream);; outstream.close();; }; ; // Read data from input stream. The variables of the dataset need to be supplied; // to the RooDataSet::read() function.; std::cout << ""\n-----------------------\nReading data from ASCII\n"";; RooDataSet *dataReadBack =; RooDataSet::read(""rf102_testData.txt"",; RooArgList(x, y), // variables to be read. If the file has more fields, these are ignored.; ""D""); // Prints if a RooFit message stream listens for debug messages. Use Q for quiet.; ; dataReadBack->Print(""V"");; ; std::cout << ""\nOriginal data, line 20:\n"";; ds.get(20)->Print(""V"");; ; std::cout << ""\nRead-back data, line 20:\n"";; dataReadBack->get(20)->Print(""V"");; ; // P l o t d a t a s e t s w i t h m u l t i p l e b i n n i n g c h o i c e s; // ------------------------------------------------------------------------------------; ; // Print number of events in dataset; ds.Print();; ; // Print unbinned dataset with default frame binning (100 bins); RooPlot *frame3 = y.frame(Title(""Unbinned data shown in default frame binning""));; ds.plotOn(frame3);; ; // Print unbinned dataset with custom binning choice (20 bins); RooPlot *frame4 = y.frame(Title(""Unbinned data shown with custom binning""));; ds.plotOn(frame4, Binning(20));; ; RooPlot *frame5 = y.frame(Title(""Unbinned data read back from ASCII file""));; ds.plotOn(frame5, Binning(20));; dataReadBack->plotOn(frame5, Binning(20), MarkerColor(kRed), MarkerStyle(5))",MatchSource.WIKI,doc/master/rf102__dataimport_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8C.html
https://root.cern/doc/master/rf102__dataimport_8C.html:4308,Integrability,message,messages,4308,"mported. Since the y values in the import tree are in the range [-15,15]; // and RRV y defines a range [-10,10] this means that the RooDataSet below will have less entries than the TTree; // 'tree'; ; RooDataSet ds(""ds"", ""ds"", RooArgSet(x, y), Import(*tree));; ; // U s e a s c i i i m p o r t / e x p o r t f o r d a t a s e t s; // ------------------------------------------------------------------------------------; {; // Write data to output stream; std::ofstream outstream(""rf102_testData.txt"");; // Optionally, adjust the stream here (e.g. std::setprecision); ds.write(outstream);; outstream.close();; }; ; // Read data from input stream. The variables of the dataset need to be supplied; // to the RooDataSet::read() function.; std::cout << ""\n-----------------------\nReading data from ASCII\n"";; RooDataSet *dataReadBack =; RooDataSet::read(""rf102_testData.txt"",; RooArgList(x, y), // variables to be read. If the file has more fields, these are ignored.; ""D""); // Prints if a RooFit message stream listens for debug messages. Use Q for quiet.; ; dataReadBack->Print(""V"");; ; std::cout << ""\nOriginal data, line 20:\n"";; ds.get(20)->Print(""V"");; ; std::cout << ""\nRead-back data, line 20:\n"";; dataReadBack->get(20)->Print(""V"");; ; // P l o t d a t a s e t s w i t h m u l t i p l e b i n n i n g c h o i c e s; // ------------------------------------------------------------------------------------; ; // Print number of events in dataset; ds.Print();; ; // Print unbinned dataset with default frame binning (100 bins); RooPlot *frame3 = y.frame(Title(""Unbinned data shown in default frame binning""));; ds.plotOn(frame3);; ; // Print unbinned dataset with custom binning choice (20 bins); RooPlot *frame4 = y.frame(Title(""Unbinned data shown with custom binning""));; ds.plotOn(frame4, Binning(20));; ; RooPlot *frame5 = y.frame(Title(""Unbinned data read back from ASCII file""));; ds.plotOn(frame5, Binning(20));; dataReadBack->plotOn(frame5, Binning(20), MarkerColor(kRed), MarkerStyle(5))",MatchSource.WIKI,doc/master/rf102__dataimport_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8C.html
https://root.cern/doc/master/rf102__dataimport_8C.html:3931,Modifiability,variab,variables,3931,"le y; RooRealVar y(""y"", ""y"", -10, 10);; ; // Construct unbinned dataset importing tree branches x and y matching between branches and RooRealVars; // is done by name of the branch/RRV; //; // Note that ONLY entries for which x,y have values within their allowed ranges as defined in; // RooRealVar x and y are imported. Since the y values in the import tree are in the range [-15,15]; // and RRV y defines a range [-10,10] this means that the RooDataSet below will have less entries than the TTree; // 'tree'; ; RooDataSet ds(""ds"", ""ds"", RooArgSet(x, y), Import(*tree));; ; // U s e a s c i i i m p o r t / e x p o r t f o r d a t a s e t s; // ------------------------------------------------------------------------------------; {; // Write data to output stream; std::ofstream outstream(""rf102_testData.txt"");; // Optionally, adjust the stream here (e.g. std::setprecision); ds.write(outstream);; outstream.close();; }; ; // Read data from input stream. The variables of the dataset need to be supplied; // to the RooDataSet::read() function.; std::cout << ""\n-----------------------\nReading data from ASCII\n"";; RooDataSet *dataReadBack =; RooDataSet::read(""rf102_testData.txt"",; RooArgList(x, y), // variables to be read. If the file has more fields, these are ignored.; ""D""); // Prints if a RooFit message stream listens for debug messages. Use Q for quiet.; ; dataReadBack->Print(""V"");; ; std::cout << ""\nOriginal data, line 20:\n"";; ds.get(20)->Print(""V"");; ; std::cout << ""\nRead-back data, line 20:\n"";; dataReadBack->get(20)->Print(""V"");; ; // P l o t d a t a s e t s w i t h m u l t i p l e b i n n i n g c h o i c e s; // ------------------------------------------------------------------------------------; ; // Print number of events in dataset; ds.Print();; ; // Print unbinned dataset with default frame binning (100 bins); RooPlot *frame3 = y.frame(Title(""Unbinned data shown in default frame binning""));; ds.plotOn(frame3);; ; // Print unbinned dataset with custom binning choice (",MatchSource.WIKI,doc/master/rf102__dataimport_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8C.html
https://root.cern/doc/master/rf102__dataimport_8C.html:4176,Modifiability,variab,variables,4176,"ONLY entries for which x,y have values within their allowed ranges as defined in; // RooRealVar x and y are imported. Since the y values in the import tree are in the range [-15,15]; // and RRV y defines a range [-10,10] this means that the RooDataSet below will have less entries than the TTree; // 'tree'; ; RooDataSet ds(""ds"", ""ds"", RooArgSet(x, y), Import(*tree));; ; // U s e a s c i i i m p o r t / e x p o r t f o r d a t a s e t s; // ------------------------------------------------------------------------------------; {; // Write data to output stream; std::ofstream outstream(""rf102_testData.txt"");; // Optionally, adjust the stream here (e.g. std::setprecision); ds.write(outstream);; outstream.close();; }; ; // Read data from input stream. The variables of the dataset need to be supplied; // to the RooDataSet::read() function.; std::cout << ""\n-----------------------\nReading data from ASCII\n"";; RooDataSet *dataReadBack =; RooDataSet::read(""rf102_testData.txt"",; RooArgList(x, y), // variables to be read. If the file has more fields, these are ignored.; ""D""); // Prints if a RooFit message stream listens for debug messages. Use Q for quiet.; ; dataReadBack->Print(""V"");; ; std::cout << ""\nOriginal data, line 20:\n"";; ds.get(20)->Print(""V"");; ; std::cout << ""\nRead-back data, line 20:\n"";; dataReadBack->get(20)->Print(""V"");; ; // P l o t d a t a s e t s w i t h m u l t i p l e b i n n i n g c h o i c e s; // ------------------------------------------------------------------------------------; ; // Print number of events in dataset; ds.Print();; ; // Print unbinned dataset with default frame binning (100 bins); RooPlot *frame3 = y.frame(Title(""Unbinned data shown in default frame binning""));; ds.plotOn(frame3);; ; // Print unbinned dataset with custom binning choice (20 bins); RooPlot *frame4 = y.frame(Title(""Unbinned data shown with custom binning""));; ds.plotOn(frame4, Binning(20));; ; RooPlot *frame5 = y.frame(Title(""Unbinned data read back from ASCII file""));; d",MatchSource.WIKI,doc/master/rf102__dataimport_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8C.html
https://root.cern/doc/master/rf102__dataimport_8C.html:8121,Modifiability,variab,variables,8121," const RooCmdArg &arg3={}, const RooCmdArg &arg4={}, const RooCmdArg &arg5={}, const RooCmdArg &arg6={}, const RooCmdArg &arg7={}, const RooCmdArg &arg8={}) constDefinition RooAbsData.cxx:548; RooAbsData::Printvoid Print(Option_t *options=nullptr) const overrideThis method must be overridden when a class wants to print itself.Definition RooAbsData.h:225; RooArgListRooArgList is a container object that can hold multiple RooAbsArg objects.Definition RooArgList.h:22; RooArgSetRooArgSet is a container object that can hold multiple RooAbsArg objects.Definition RooArgSet.h:24; RooDataHistContainer class to hold N-dimensional binned data.Definition RooDataHist.h:40; RooDataSetContainer class to hold unbinned data.Definition RooDataSet.h:33; RooDataSet::getconst RooArgSet * get(Int_t index) const overrideReturn RooArgSet with coordinates of event 'index'.Definition RooDataSet.cxx:835; RooDataSet::readstatic RooDataSet * read(const char *filename, const RooArgList &variables, const char *opts="""", const char *commonPath="""", const char *indexCatName=nullptr)Read data from a text file and create a dataset from it.Definition RooDataSet.cxx:1372; RooGaussianPlain Gaussian p.d.f.Definition RooGaussian.h:24; RooPlotPlot frame and a container for graphics objects within that frame.Definition RooPlot.h:45; RooPlot::framestatic RooPlot * frame(const RooAbsRealLValue &var, double xmin, double xmax, Int_t nBins)Create a new frame for a given variable in x.Definition RooPlot.cxx:225; RooPlot::GetYaxisTAxis * GetYaxis() constDefinition RooPlot.cxx:1264; RooPlot::Drawvoid Draw(Option_t *options=nullptr) overrideDraw this plot and all of the elements it contains.Definition RooPlot.cxx:637; RooRealVarVariable that can be changed from the outside.Definition RooRealVar.h:37; TAttAxis::SetTitleOffsetvirtual void SetTitleOffset(Float_t offset=1)Set distance between the axis and the axis title.Definition TAttAxis.cxx:298; TCanvasThe Canvas class.Definition TCanvas.h:23; TH1D1-D histogram with a d",MatchSource.WIKI,doc/master/rf102__dataimport_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8C.html
https://root.cern/doc/master/rf102__dataimport_8C.html:8595,Modifiability,variab,variable,8595,"a container object that can hold multiple RooAbsArg objects.Definition RooArgList.h:22; RooArgSetRooArgSet is a container object that can hold multiple RooAbsArg objects.Definition RooArgSet.h:24; RooDataHistContainer class to hold N-dimensional binned data.Definition RooDataHist.h:40; RooDataSetContainer class to hold unbinned data.Definition RooDataSet.h:33; RooDataSet::getconst RooArgSet * get(Int_t index) const overrideReturn RooArgSet with coordinates of event 'index'.Definition RooDataSet.cxx:835; RooDataSet::readstatic RooDataSet * read(const char *filename, const RooArgList &variables, const char *opts="""", const char *commonPath="""", const char *indexCatName=nullptr)Read data from a text file and create a dataset from it.Definition RooDataSet.cxx:1372; RooGaussianPlain Gaussian p.d.f.Definition RooGaussian.h:24; RooPlotPlot frame and a container for graphics objects within that frame.Definition RooPlot.h:45; RooPlot::framestatic RooPlot * frame(const RooAbsRealLValue &var, double xmin, double xmax, Int_t nBins)Create a new frame for a given variable in x.Definition RooPlot.cxx:225; RooPlot::GetYaxisTAxis * GetYaxis() constDefinition RooPlot.cxx:1264; RooPlot::Drawvoid Draw(Option_t *options=nullptr) overrideDraw this plot and all of the elements it contains.Definition RooPlot.cxx:637; RooRealVarVariable that can be changed from the outside.Definition RooRealVar.h:37; TAttAxis::SetTitleOffsetvirtual void SetTitleOffset(Float_t offset=1)Set distance between the axis and the axis title.Definition TAttAxis.cxx:298; TCanvasThe Canvas class.Definition TCanvas.h:23; TH1D1-D histogram with a double per channel (see TH1 documentation)Definition TH1.h:670; TH1TH1 is the base class of all histogram classes in ROOT.Definition TH1.h:59; TH1::Fillvirtual Int_t Fill(Double_t x)Increment bin with abscissa X by 1.Definition TH1.cxx:3344; TRandom::Gausvirtual Double_t Gaus(Double_t mean=0, Double_t sigma=1)Samples a random number from the standard Normal (Gaussian) Distribution",MatchSource.WIKI,doc/master/rf102__dataimport_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8C.html
https://root.cern/doc/master/rf102__dataimport_8C.html:10627,Performance,optimiz,optimization,10627,"Distribution with the given mean and sigm...Definition TRandom.cxx:275; TRandom::Uniformvirtual Double_t Uniform(Double_t x1=1)Returns a uniform deviate on the interval (0, x1).Definition TRandom.cxx:682; TTreeA TTree represents a columnar dataset.Definition TTree.h:79; double; sigmaconst Double_t sigmaDefinition h1analysisProxy.h:11; yDouble_t y[n]Definition legend1.C:17; xDouble_t x[n]Definition legend1.C:17; RooFitThe namespace RooFit contains mostly switches that change the behaviour of functions of PDFs (or othe...Definition JSONIO.h:26; TMVA_SOFIE_GNN_Parser.treetreeDefinition TMVA_SOFIE_GNN_Parser.py:169; rf102_dataimportDefinition rf102_dataimport.py:1; ; [#1] INFO:Fitting -- RooAbsPdf::fitTo(gauss_over_gauss_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_gauss_over_gauss_Int[x]_dh) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #0 because y cannot accommodate the value 14.424; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #3 because y cannot accommodate the value -12.0022; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #5 because y cannot accommodate the value 13.8261; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #6 because y cannot accommodate the value -14.9925; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping ...; [#0] WARNING:DataHandling -- RooTreeDataStore::loadValues(ds) Ignored 36 out-of-range events; ; -----------------------; Reading data from ASCII; [#1] INFO:DataHandling -- RooDataSet::read: reading file rf102_",MatchSource.WIKI,doc/master/rf102__dataimport_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8C.html
https://root.cern/doc/master/rf102__dataimport_8C.html:10724,Performance,optimiz,optimization,10724,"Distribution with the given mean and sigm...Definition TRandom.cxx:275; TRandom::Uniformvirtual Double_t Uniform(Double_t x1=1)Returns a uniform deviate on the interval (0, x1).Definition TRandom.cxx:682; TTreeA TTree represents a columnar dataset.Definition TTree.h:79; double; sigmaconst Double_t sigmaDefinition h1analysisProxy.h:11; yDouble_t y[n]Definition legend1.C:17; xDouble_t x[n]Definition legend1.C:17; RooFitThe namespace RooFit contains mostly switches that change the behaviour of functions of PDFs (or othe...Definition JSONIO.h:26; TMVA_SOFIE_GNN_Parser.treetreeDefinition TMVA_SOFIE_GNN_Parser.py:169; rf102_dataimportDefinition rf102_dataimport.py:1; ; [#1] INFO:Fitting -- RooAbsPdf::fitTo(gauss_over_gauss_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_gauss_over_gauss_Int[x]_dh) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #0 because y cannot accommodate the value 14.424; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #3 because y cannot accommodate the value -12.0022; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #5 because y cannot accommodate the value 13.8261; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #6 because y cannot accommodate the value -14.9925; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping ...; [#0] WARNING:DataHandling -- RooTreeDataStore::loadValues(ds) Ignored 36 out-of-range events; ; -----------------------; Reading data from ASCII; [#1] INFO:DataHandling -- RooDataSet::read: reading file rf102_",MatchSource.WIKI,doc/master/rf102__dataimport_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8C.html
https://root.cern/doc/master/rf102__dataimport_8C.html:10782,Performance,load,loadValues,10782,"Distribution with the given mean and sigm...Definition TRandom.cxx:275; TRandom::Uniformvirtual Double_t Uniform(Double_t x1=1)Returns a uniform deviate on the interval (0, x1).Definition TRandom.cxx:682; TTreeA TTree represents a columnar dataset.Definition TTree.h:79; double; sigmaconst Double_t sigmaDefinition h1analysisProxy.h:11; yDouble_t y[n]Definition legend1.C:17; xDouble_t x[n]Definition legend1.C:17; RooFitThe namespace RooFit contains mostly switches that change the behaviour of functions of PDFs (or othe...Definition JSONIO.h:26; TMVA_SOFIE_GNN_Parser.treetreeDefinition TMVA_SOFIE_GNN_Parser.py:169; rf102_dataimportDefinition rf102_dataimport.py:1; ; [#1] INFO:Fitting -- RooAbsPdf::fitTo(gauss_over_gauss_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_gauss_over_gauss_Int[x]_dh) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #0 because y cannot accommodate the value 14.424; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #3 because y cannot accommodate the value -12.0022; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #5 because y cannot accommodate the value 13.8261; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #6 because y cannot accommodate the value -14.9925; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping ...; [#0] WARNING:DataHandling -- RooTreeDataStore::loadValues(ds) Ignored 36 out-of-range events; ; -----------------------; Reading data from ASCII; [#1] INFO:DataHandling -- RooDataSet::read: reading file rf102_",MatchSource.WIKI,doc/master/rf102__dataimport_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8C.html
https://root.cern/doc/master/rf102__dataimport_8C.html:10906,Performance,load,loadValues,10906,"n legend1.C:17; RooFitThe namespace RooFit contains mostly switches that change the behaviour of functions of PDFs (or othe...Definition JSONIO.h:26; TMVA_SOFIE_GNN_Parser.treetreeDefinition TMVA_SOFIE_GNN_Parser.py:169; rf102_dataimportDefinition rf102_dataimport.py:1; ; [#1] INFO:Fitting -- RooAbsPdf::fitTo(gauss_over_gauss_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_gauss_over_gauss_Int[x]_dh) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #0 because y cannot accommodate the value 14.424; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #3 because y cannot accommodate the value -12.0022; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #5 because y cannot accommodate the value 13.8261; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #6 because y cannot accommodate the value -14.9925; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping ...; [#0] WARNING:DataHandling -- RooTreeDataStore::loadValues(ds) Ignored 36 out-of-range events; ; -----------------------; Reading data from ASCII; [#1] INFO:DataHandling -- RooDataSet::read: reading file rf102_testData.txt; [#1] INFO:DataHandling -- RooDataSet::read: read 64 events (ignored 0 out of range events); DataStore dataset (rf102_testData.txt); Contains 64 entries; Observables: ; 1) x = 0.0174204 L(-10 - 10) ""x""; 2) y = 9.46654 L(-10 - 10) ""y""; 3) blindState = Normal(idx = 0); ""Blinding State""; ; Original data, line 20:; 1) RooRealVar:: x = -0.79919; 2) RooRealVar:: y = 0.0106407; ; Read-back ",MatchSource.WIKI,doc/master/rf102__dataimport_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8C.html
https://root.cern/doc/master/rf102__dataimport_8C.html:11032,Performance,load,loadValues,11032,".Definition JSONIO.h:26; TMVA_SOFIE_GNN_Parser.treetreeDefinition TMVA_SOFIE_GNN_Parser.py:169; rf102_dataimportDefinition rf102_dataimport.py:1; ; [#1] INFO:Fitting -- RooAbsPdf::fitTo(gauss_over_gauss_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_gauss_over_gauss_Int[x]_dh) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #0 because y cannot accommodate the value 14.424; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #3 because y cannot accommodate the value -12.0022; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #5 because y cannot accommodate the value 13.8261; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #6 because y cannot accommodate the value -14.9925; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping ...; [#0] WARNING:DataHandling -- RooTreeDataStore::loadValues(ds) Ignored 36 out-of-range events; ; -----------------------; Reading data from ASCII; [#1] INFO:DataHandling -- RooDataSet::read: reading file rf102_testData.txt; [#1] INFO:DataHandling -- RooDataSet::read: read 64 events (ignored 0 out of range events); DataStore dataset (rf102_testData.txt); Contains 64 entries; Observables: ; 1) x = 0.0174204 L(-10 - 10) ""x""; 2) y = 9.46654 L(-10 - 10) ""y""; 3) blindState = Normal(idx = 0); ""Blinding State""; ; Original data, line 20:; 1) RooRealVar:: x = -0.79919; 2) RooRealVar:: y = 0.0106407; ; Read-back data, line 20:; 1) RooRealVar:: x = -0.79919; 2) RooRealVar:: y = 0.0106407; 3) RooCategory:: blindState = Normal(idx = 0); ;",MatchSource.WIKI,doc/master/rf102__dataimport_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8C.html
https://root.cern/doc/master/rf102__dataimport_8C.html:11157,Performance,load,loadValues,11157,"02_dataimport.py:1; ; [#1] INFO:Fitting -- RooAbsPdf::fitTo(gauss_over_gauss_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_gauss_over_gauss_Int[x]_dh) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #0 because y cannot accommodate the value 14.424; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #3 because y cannot accommodate the value -12.0022; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #5 because y cannot accommodate the value 13.8261; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #6 because y cannot accommodate the value -14.9925; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping ...; [#0] WARNING:DataHandling -- RooTreeDataStore::loadValues(ds) Ignored 36 out-of-range events; ; -----------------------; Reading data from ASCII; [#1] INFO:DataHandling -- RooDataSet::read: reading file rf102_testData.txt; [#1] INFO:DataHandling -- RooDataSet::read: read 64 events (ignored 0 out of range events); DataStore dataset (rf102_testData.txt); Contains 64 entries; Observables: ; 1) x = 0.0174204 L(-10 - 10) ""x""; 2) y = 9.46654 L(-10 - 10) ""y""; 3) blindState = Normal(idx = 0); ""Blinding State""; ; Original data, line 20:; 1) RooRealVar:: x = -0.79919; 2) RooRealVar:: y = 0.0106407; ; Read-back data, line 20:; 1) RooRealVar:: x = -0.79919; 2) RooRealVar:: y = 0.0106407; 3) RooCategory:: blindState = Normal(idx = 0); ; RooDataSet::ds[x,y] = 64 entries; DateJuly 2008 ; AuthorWouter Verkerke ; Definition in file rf102_dataimport.C. tutorialsro",MatchSource.WIKI,doc/master/rf102__dataimport_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8C.html
https://root.cern/doc/master/rf102__dataimport_8C.html:11283,Performance,load,loadValues,11283,"ation set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_gauss_over_gauss_Int[x]_dh) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #0 because y cannot accommodate the value 14.424; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #3 because y cannot accommodate the value -12.0022; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #5 because y cannot accommodate the value 13.8261; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #6 because y cannot accommodate the value -14.9925; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping ...; [#0] WARNING:DataHandling -- RooTreeDataStore::loadValues(ds) Ignored 36 out-of-range events; ; -----------------------; Reading data from ASCII; [#1] INFO:DataHandling -- RooDataSet::read: reading file rf102_testData.txt; [#1] INFO:DataHandling -- RooDataSet::read: read 64 events (ignored 0 out of range events); DataStore dataset (rf102_testData.txt); Contains 64 entries; Observables: ; 1) x = 0.0174204 L(-10 - 10) ""x""; 2) y = 9.46654 L(-10 - 10) ""y""; 3) blindState = Normal(idx = 0); ""Blinding State""; ; Original data, line 20:; 1) RooRealVar:: x = -0.79919; 2) RooRealVar:: y = 0.0106407; ; Read-back data, line 20:; 1) RooRealVar:: x = -0.79919; 2) RooRealVar:: y = 0.0106407; 3) RooCategory:: blindState = Normal(idx = 0); ; RooDataSet::ds[x,y] = 64 entries; DateJuly 2008 ; AuthorWouter Verkerke ; Definition in file rf102_dataimport.C. tutorialsroofitrf102_dataimport.C. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:30 (GVA Time)",MatchSource.WIKI,doc/master/rf102__dataimport_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8C.html
https://root.cern/doc/master/rf102__dataimport_8C.html:11359,Performance,load,loadValues,11359,"termination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_gauss_over_gauss_Int[x]_dh) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #0 because y cannot accommodate the value 14.424; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #3 because y cannot accommodate the value -12.0022; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #5 because y cannot accommodate the value 13.8261; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #6 because y cannot accommodate the value -14.9925; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping ...; [#0] WARNING:DataHandling -- RooTreeDataStore::loadValues(ds) Ignored 36 out-of-range events; ; -----------------------; Reading data from ASCII; [#1] INFO:DataHandling -- RooDataSet::read: reading file rf102_testData.txt; [#1] INFO:DataHandling -- RooDataSet::read: read 64 events (ignored 0 out of range events); DataStore dataset (rf102_testData.txt); Contains 64 entries; Observables: ; 1) x = 0.0174204 L(-10 - 10) ""x""; 2) y = 9.46654 L(-10 - 10) ""y""; 3) blindState = Normal(idx = 0); ""Blinding State""; ; Original data, line 20:; 1) RooRealVar:: x = -0.79919; 2) RooRealVar:: y = 0.0106407; ; Read-back data, line 20:; 1) RooRealVar:: x = -0.79919; 2) RooRealVar:: y = 0.0106407; 3) RooCategory:: blindState = Normal(idx = 0); ; RooDataSet::ds[x,y] = 64 entries; DateJuly 2008 ; AuthorWouter Verkerke ; Definition in file rf102_dataimport.C. tutorialsroofitrf102_dataimport.C. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:30 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/rf102__dataimport_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8C.html
https://root.cern/doc/master/rf102__dataimport_8py.html:1562,Availability,error,error,1562,"25, -10, 10); for i in range(100):; hh.Fill(ROOT.gRandom.Gaus(0, 3)); return hh; ; ; def makeTTree():; # Create ROOT ROOT.TTree filled with a Gaussian distribution in x and a; # uniform distribution in y; ; tree = ROOT.TTree(""tree"", ""tree""); px = array(""d"", [0]); py = array(""d"", [0]); tree.Branch(""x"", px, ""x/D""); tree.Branch(""y"", py, ""y/D""); for i in range(100):; px[0] = ROOT.gRandom.Gaus(0, 3); py[0] = ROOT.gRandom.Uniform() * 30 - 15; tree.Fill(); return tree; ; ; ############################; # Importing ROOT histograms; ############################; # Import ROOT TH1 into a RooDataHist; # ---------------------------------------------------------; # Create a ROOT TH1 histogram; hh = makeTH1(); ; # Declare observable x; x = ROOT.RooRealVar(""x"", ""x"", -10, 10); ; # Create a binned dataset that imports contents of ROOT.TH1 and associates; # its contents to observable 'x'; dh = ROOT.RooDataHist(""dh"", ""dh"", [x], Import=hh); ; # Plot and fit a RooDataHist; # ---------------------------------------------------; # Make plot of binned dataset showing Poisson error bars (RooFit default); frame = x.frame(Title=""Imported ROOT.TH1 with Poisson error bars""); dh.plotOn(frame); ; # Fit a Gaussian p.d.f to the data; mean = ROOT.RooRealVar(""mean"", ""mean"", 0, -10, 10); sigma = ROOT.RooRealVar(""sigma"", ""sigma"", 3, 0.1, 10); gauss = ROOT.RooGaussian(""gauss"", ""gauss"", x, mean, sigma); gauss.fitTo(dh, PrintLevel=-1); gauss.plotOn(frame); ; # Plot and fit a RooDataHist with internal errors; # ---------------------------------------------------------------------------------------------; ; # If histogram has custom error (i.e. its contents is does not originate from a Poisson process; # but e.g. is a sum of weighted events) you can data with symmetric 'sum-of-weights' error instead; # (same error bars as shown by ROOT); frame2 = x.frame(Title=""Imported ROOT.TH1 with internal errors""); dh.plotOn(frame2, DataError=""SumW2""); gauss.plotOn(frame2); ; # Please note that error bars shown (Poisson ",MatchSource.WIKI,doc/master/rf102__dataimport_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8py.html
https://root.cern/doc/master/rf102__dataimport_8py.html:1645,Availability,error,error,1645,"distribution in x and a; # uniform distribution in y; ; tree = ROOT.TTree(""tree"", ""tree""); px = array(""d"", [0]); py = array(""d"", [0]); tree.Branch(""x"", px, ""x/D""); tree.Branch(""y"", py, ""y/D""); for i in range(100):; px[0] = ROOT.gRandom.Gaus(0, 3); py[0] = ROOT.gRandom.Uniform() * 30 - 15; tree.Fill(); return tree; ; ; ############################; # Importing ROOT histograms; ############################; # Import ROOT TH1 into a RooDataHist; # ---------------------------------------------------------; # Create a ROOT TH1 histogram; hh = makeTH1(); ; # Declare observable x; x = ROOT.RooRealVar(""x"", ""x"", -10, 10); ; # Create a binned dataset that imports contents of ROOT.TH1 and associates; # its contents to observable 'x'; dh = ROOT.RooDataHist(""dh"", ""dh"", [x], Import=hh); ; # Plot and fit a RooDataHist; # ---------------------------------------------------; # Make plot of binned dataset showing Poisson error bars (RooFit default); frame = x.frame(Title=""Imported ROOT.TH1 with Poisson error bars""); dh.plotOn(frame); ; # Fit a Gaussian p.d.f to the data; mean = ROOT.RooRealVar(""mean"", ""mean"", 0, -10, 10); sigma = ROOT.RooRealVar(""sigma"", ""sigma"", 3, 0.1, 10); gauss = ROOT.RooGaussian(""gauss"", ""gauss"", x, mean, sigma); gauss.fitTo(dh, PrintLevel=-1); gauss.plotOn(frame); ; # Plot and fit a RooDataHist with internal errors; # ---------------------------------------------------------------------------------------------; ; # If histogram has custom error (i.e. its contents is does not originate from a Poisson process; # but e.g. is a sum of weighted events) you can data with symmetric 'sum-of-weights' error instead; # (same error bars as shown by ROOT); frame2 = x.frame(Title=""Imported ROOT.TH1 with internal errors""); dh.plotOn(frame2, DataError=""SumW2""); gauss.plotOn(frame2); ; # Please note that error bars shown (Poisson or SumW2) are for visualization only, the are NOT used; # in a maximum likelihood fit; #; # A (binned) ML fit will ALWAYS assume the Poisson error int",MatchSource.WIKI,doc/master/rf102__dataimport_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8py.html
https://root.cern/doc/master/rf102__dataimport_8py.html:1980,Availability,error,errors,1980,"s; ############################; # Import ROOT TH1 into a RooDataHist; # ---------------------------------------------------------; # Create a ROOT TH1 histogram; hh = makeTH1(); ; # Declare observable x; x = ROOT.RooRealVar(""x"", ""x"", -10, 10); ; # Create a binned dataset that imports contents of ROOT.TH1 and associates; # its contents to observable 'x'; dh = ROOT.RooDataHist(""dh"", ""dh"", [x], Import=hh); ; # Plot and fit a RooDataHist; # ---------------------------------------------------; # Make plot of binned dataset showing Poisson error bars (RooFit default); frame = x.frame(Title=""Imported ROOT.TH1 with Poisson error bars""); dh.plotOn(frame); ; # Fit a Gaussian p.d.f to the data; mean = ROOT.RooRealVar(""mean"", ""mean"", 0, -10, 10); sigma = ROOT.RooRealVar(""sigma"", ""sigma"", 3, 0.1, 10); gauss = ROOT.RooGaussian(""gauss"", ""gauss"", x, mean, sigma); gauss.fitTo(dh, PrintLevel=-1); gauss.plotOn(frame); ; # Plot and fit a RooDataHist with internal errors; # ---------------------------------------------------------------------------------------------; ; # If histogram has custom error (i.e. its contents is does not originate from a Poisson process; # but e.g. is a sum of weighted events) you can data with symmetric 'sum-of-weights' error instead; # (same error bars as shown by ROOT); frame2 = x.frame(Title=""Imported ROOT.TH1 with internal errors""); dh.plotOn(frame2, DataError=""SumW2""); gauss.plotOn(frame2); ; # Please note that error bars shown (Poisson or SumW2) are for visualization only, the are NOT used; # in a maximum likelihood fit; #; # A (binned) ML fit will ALWAYS assume the Poisson error interpretation of data (the mathematical definition; # of likelihood does not take any external definition of errors). Data with non-unit weights can only be correctly; # fitted with a chi^2 fit (see rf602_chi2fit.py); #; # Importing ROOT TTrees; # -----------------------------------------------------------; # Import ROOT TTree into a RooDataSet; ; tree = makeTTree(); ; # Defi",MatchSource.WIKI,doc/master/rf102__dataimport_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8py.html
https://root.cern/doc/master/rf102__dataimport_8py.html:2113,Availability,error,error,2113,"s; ############################; # Import ROOT TH1 into a RooDataHist; # ---------------------------------------------------------; # Create a ROOT TH1 histogram; hh = makeTH1(); ; # Declare observable x; x = ROOT.RooRealVar(""x"", ""x"", -10, 10); ; # Create a binned dataset that imports contents of ROOT.TH1 and associates; # its contents to observable 'x'; dh = ROOT.RooDataHist(""dh"", ""dh"", [x], Import=hh); ; # Plot and fit a RooDataHist; # ---------------------------------------------------; # Make plot of binned dataset showing Poisson error bars (RooFit default); frame = x.frame(Title=""Imported ROOT.TH1 with Poisson error bars""); dh.plotOn(frame); ; # Fit a Gaussian p.d.f to the data; mean = ROOT.RooRealVar(""mean"", ""mean"", 0, -10, 10); sigma = ROOT.RooRealVar(""sigma"", ""sigma"", 3, 0.1, 10); gauss = ROOT.RooGaussian(""gauss"", ""gauss"", x, mean, sigma); gauss.fitTo(dh, PrintLevel=-1); gauss.plotOn(frame); ; # Plot and fit a RooDataHist with internal errors; # ---------------------------------------------------------------------------------------------; ; # If histogram has custom error (i.e. its contents is does not originate from a Poisson process; # but e.g. is a sum of weighted events) you can data with symmetric 'sum-of-weights' error instead; # (same error bars as shown by ROOT); frame2 = x.frame(Title=""Imported ROOT.TH1 with internal errors""); dh.plotOn(frame2, DataError=""SumW2""); gauss.plotOn(frame2); ; # Please note that error bars shown (Poisson or SumW2) are for visualization only, the are NOT used; # in a maximum likelihood fit; #; # A (binned) ML fit will ALWAYS assume the Poisson error interpretation of data (the mathematical definition; # of likelihood does not take any external definition of errors). Data with non-unit weights can only be correctly; # fitted with a chi^2 fit (see rf602_chi2fit.py); #; # Importing ROOT TTrees; # -----------------------------------------------------------; # Import ROOT TTree into a RooDataSet; ; tree = makeTTree(); ; # Defi",MatchSource.WIKI,doc/master/rf102__dataimport_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8py.html
https://root.cern/doc/master/rf102__dataimport_8py.html:2269,Availability,error,error,2269,"); ; # Create a binned dataset that imports contents of ROOT.TH1 and associates; # its contents to observable 'x'; dh = ROOT.RooDataHist(""dh"", ""dh"", [x], Import=hh); ; # Plot and fit a RooDataHist; # ---------------------------------------------------; # Make plot of binned dataset showing Poisson error bars (RooFit default); frame = x.frame(Title=""Imported ROOT.TH1 with Poisson error bars""); dh.plotOn(frame); ; # Fit a Gaussian p.d.f to the data; mean = ROOT.RooRealVar(""mean"", ""mean"", 0, -10, 10); sigma = ROOT.RooRealVar(""sigma"", ""sigma"", 3, 0.1, 10); gauss = ROOT.RooGaussian(""gauss"", ""gauss"", x, mean, sigma); gauss.fitTo(dh, PrintLevel=-1); gauss.plotOn(frame); ; # Plot and fit a RooDataHist with internal errors; # ---------------------------------------------------------------------------------------------; ; # If histogram has custom error (i.e. its contents is does not originate from a Poisson process; # but e.g. is a sum of weighted events) you can data with symmetric 'sum-of-weights' error instead; # (same error bars as shown by ROOT); frame2 = x.frame(Title=""Imported ROOT.TH1 with internal errors""); dh.plotOn(frame2, DataError=""SumW2""); gauss.plotOn(frame2); ; # Please note that error bars shown (Poisson or SumW2) are for visualization only, the are NOT used; # in a maximum likelihood fit; #; # A (binned) ML fit will ALWAYS assume the Poisson error interpretation of data (the mathematical definition; # of likelihood does not take any external definition of errors). Data with non-unit weights can only be correctly; # fitted with a chi^2 fit (see rf602_chi2fit.py); #; # Importing ROOT TTrees; # -----------------------------------------------------------; # Import ROOT TTree into a RooDataSet; ; tree = makeTTree(); ; # Define 2nd observable y; y = ROOT.RooRealVar(""y"", ""y"", -10, 10); ; # Construct unbinned dataset importing tree branches x and y matching between branches and ROOT.RooRealVars; # is done by name of the branch/RRV; #; # Note that ONLY entries for wh",MatchSource.WIKI,doc/master/rf102__dataimport_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8py.html
https://root.cern/doc/master/rf102__dataimport_8py.html:2292,Availability,error,error,2292,"); ; # Create a binned dataset that imports contents of ROOT.TH1 and associates; # its contents to observable 'x'; dh = ROOT.RooDataHist(""dh"", ""dh"", [x], Import=hh); ; # Plot and fit a RooDataHist; # ---------------------------------------------------; # Make plot of binned dataset showing Poisson error bars (RooFit default); frame = x.frame(Title=""Imported ROOT.TH1 with Poisson error bars""); dh.plotOn(frame); ; # Fit a Gaussian p.d.f to the data; mean = ROOT.RooRealVar(""mean"", ""mean"", 0, -10, 10); sigma = ROOT.RooRealVar(""sigma"", ""sigma"", 3, 0.1, 10); gauss = ROOT.RooGaussian(""gauss"", ""gauss"", x, mean, sigma); gauss.fitTo(dh, PrintLevel=-1); gauss.plotOn(frame); ; # Plot and fit a RooDataHist with internal errors; # ---------------------------------------------------------------------------------------------; ; # If histogram has custom error (i.e. its contents is does not originate from a Poisson process; # but e.g. is a sum of weighted events) you can data with symmetric 'sum-of-weights' error instead; # (same error bars as shown by ROOT); frame2 = x.frame(Title=""Imported ROOT.TH1 with internal errors""); dh.plotOn(frame2, DataError=""SumW2""); gauss.plotOn(frame2); ; # Please note that error bars shown (Poisson or SumW2) are for visualization only, the are NOT used; # in a maximum likelihood fit; #; # A (binned) ML fit will ALWAYS assume the Poisson error interpretation of data (the mathematical definition; # of likelihood does not take any external definition of errors). Data with non-unit weights can only be correctly; # fitted with a chi^2 fit (see rf602_chi2fit.py); #; # Importing ROOT TTrees; # -----------------------------------------------------------; # Import ROOT TTree into a RooDataSet; ; tree = makeTTree(); ; # Define 2nd observable y; y = ROOT.RooRealVar(""y"", ""y"", -10, 10); ; # Construct unbinned dataset importing tree branches x and y matching between branches and ROOT.RooRealVars; # is done by name of the branch/RRV; #; # Note that ONLY entries for wh",MatchSource.WIKI,doc/master/rf102__dataimport_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8py.html
https://root.cern/doc/master/rf102__dataimport_8py.html:2378,Availability,error,errors,2378,"'; dh = ROOT.RooDataHist(""dh"", ""dh"", [x], Import=hh); ; # Plot and fit a RooDataHist; # ---------------------------------------------------; # Make plot of binned dataset showing Poisson error bars (RooFit default); frame = x.frame(Title=""Imported ROOT.TH1 with Poisson error bars""); dh.plotOn(frame); ; # Fit a Gaussian p.d.f to the data; mean = ROOT.RooRealVar(""mean"", ""mean"", 0, -10, 10); sigma = ROOT.RooRealVar(""sigma"", ""sigma"", 3, 0.1, 10); gauss = ROOT.RooGaussian(""gauss"", ""gauss"", x, mean, sigma); gauss.fitTo(dh, PrintLevel=-1); gauss.plotOn(frame); ; # Plot and fit a RooDataHist with internal errors; # ---------------------------------------------------------------------------------------------; ; # If histogram has custom error (i.e. its contents is does not originate from a Poisson process; # but e.g. is a sum of weighted events) you can data with symmetric 'sum-of-weights' error instead; # (same error bars as shown by ROOT); frame2 = x.frame(Title=""Imported ROOT.TH1 with internal errors""); dh.plotOn(frame2, DataError=""SumW2""); gauss.plotOn(frame2); ; # Please note that error bars shown (Poisson or SumW2) are for visualization only, the are NOT used; # in a maximum likelihood fit; #; # A (binned) ML fit will ALWAYS assume the Poisson error interpretation of data (the mathematical definition; # of likelihood does not take any external definition of errors). Data with non-unit weights can only be correctly; # fitted with a chi^2 fit (see rf602_chi2fit.py); #; # Importing ROOT TTrees; # -----------------------------------------------------------; # Import ROOT TTree into a RooDataSet; ; tree = makeTTree(); ; # Define 2nd observable y; y = ROOT.RooRealVar(""y"", ""y"", -10, 10); ; # Construct unbinned dataset importing tree branches x and y matching between branches and ROOT.RooRealVars; # is done by name of the branch/RRV; #; # Note that ONLY entries for which x,y have values within their allowed ranges as defined in; # ROOT.RooRealVar x and y are imported. Since the",MatchSource.WIKI,doc/master/rf102__dataimport_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8py.html
https://root.cern/doc/master/rf102__dataimport_8py.html:2469,Availability,error,error,2469," = x.frame(Title=""Imported ROOT.TH1 with Poisson error bars""); dh.plotOn(frame); ; # Fit a Gaussian p.d.f to the data; mean = ROOT.RooRealVar(""mean"", ""mean"", 0, -10, 10); sigma = ROOT.RooRealVar(""sigma"", ""sigma"", 3, 0.1, 10); gauss = ROOT.RooGaussian(""gauss"", ""gauss"", x, mean, sigma); gauss.fitTo(dh, PrintLevel=-1); gauss.plotOn(frame); ; # Plot and fit a RooDataHist with internal errors; # ---------------------------------------------------------------------------------------------; ; # If histogram has custom error (i.e. its contents is does not originate from a Poisson process; # but e.g. is a sum of weighted events) you can data with symmetric 'sum-of-weights' error instead; # (same error bars as shown by ROOT); frame2 = x.frame(Title=""Imported ROOT.TH1 with internal errors""); dh.plotOn(frame2, DataError=""SumW2""); gauss.plotOn(frame2); ; # Please note that error bars shown (Poisson or SumW2) are for visualization only, the are NOT used; # in a maximum likelihood fit; #; # A (binned) ML fit will ALWAYS assume the Poisson error interpretation of data (the mathematical definition; # of likelihood does not take any external definition of errors). Data with non-unit weights can only be correctly; # fitted with a chi^2 fit (see rf602_chi2fit.py); #; # Importing ROOT TTrees; # -----------------------------------------------------------; # Import ROOT TTree into a RooDataSet; ; tree = makeTTree(); ; # Define 2nd observable y; y = ROOT.RooRealVar(""y"", ""y"", -10, 10); ; # Construct unbinned dataset importing tree branches x and y matching between branches and ROOT.RooRealVars; # is done by name of the branch/RRV; #; # Note that ONLY entries for which x,y have values within their allowed ranges as defined in; # ROOT.RooRealVar x and y are imported. Since the y values in the import tree are in the range [-15,15]; # and RRV y defines a range [-10,10] this means that the ROOT.RooDataSet; # below will have less entries than the ROOT.TTree 'tree'; ; ds = ROOT.RooDataSet(""ds"", ""d",MatchSource.WIKI,doc/master/rf102__dataimport_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8py.html
https://root.cern/doc/master/rf102__dataimport_8py.html:2636,Availability,error,error,2636," = x.frame(Title=""Imported ROOT.TH1 with Poisson error bars""); dh.plotOn(frame); ; # Fit a Gaussian p.d.f to the data; mean = ROOT.RooRealVar(""mean"", ""mean"", 0, -10, 10); sigma = ROOT.RooRealVar(""sigma"", ""sigma"", 3, 0.1, 10); gauss = ROOT.RooGaussian(""gauss"", ""gauss"", x, mean, sigma); gauss.fitTo(dh, PrintLevel=-1); gauss.plotOn(frame); ; # Plot and fit a RooDataHist with internal errors; # ---------------------------------------------------------------------------------------------; ; # If histogram has custom error (i.e. its contents is does not originate from a Poisson process; # but e.g. is a sum of weighted events) you can data with symmetric 'sum-of-weights' error instead; # (same error bars as shown by ROOT); frame2 = x.frame(Title=""Imported ROOT.TH1 with internal errors""); dh.plotOn(frame2, DataError=""SumW2""); gauss.plotOn(frame2); ; # Please note that error bars shown (Poisson or SumW2) are for visualization only, the are NOT used; # in a maximum likelihood fit; #; # A (binned) ML fit will ALWAYS assume the Poisson error interpretation of data (the mathematical definition; # of likelihood does not take any external definition of errors). Data with non-unit weights can only be correctly; # fitted with a chi^2 fit (see rf602_chi2fit.py); #; # Importing ROOT TTrees; # -----------------------------------------------------------; # Import ROOT TTree into a RooDataSet; ; tree = makeTTree(); ; # Define 2nd observable y; y = ROOT.RooRealVar(""y"", ""y"", -10, 10); ; # Construct unbinned dataset importing tree branches x and y matching between branches and ROOT.RooRealVars; # is done by name of the branch/RRV; #; # Note that ONLY entries for which x,y have values within their allowed ranges as defined in; # ROOT.RooRealVar x and y are imported. Since the y values in the import tree are in the range [-15,15]; # and RRV y defines a range [-10,10] this means that the ROOT.RooDataSet; # below will have less entries than the ROOT.TTree 'tree'; ; ds = ROOT.RooDataSet(""ds"", ""d",MatchSource.WIKI,doc/master/rf102__dataimport_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8py.html
https://root.cern/doc/master/rf102__dataimport_8py.html:2752,Availability,error,errors,2752," = x.frame(Title=""Imported ROOT.TH1 with Poisson error bars""); dh.plotOn(frame); ; # Fit a Gaussian p.d.f to the data; mean = ROOT.RooRealVar(""mean"", ""mean"", 0, -10, 10); sigma = ROOT.RooRealVar(""sigma"", ""sigma"", 3, 0.1, 10); gauss = ROOT.RooGaussian(""gauss"", ""gauss"", x, mean, sigma); gauss.fitTo(dh, PrintLevel=-1); gauss.plotOn(frame); ; # Plot and fit a RooDataHist with internal errors; # ---------------------------------------------------------------------------------------------; ; # If histogram has custom error (i.e. its contents is does not originate from a Poisson process; # but e.g. is a sum of weighted events) you can data with symmetric 'sum-of-weights' error instead; # (same error bars as shown by ROOT); frame2 = x.frame(Title=""Imported ROOT.TH1 with internal errors""); dh.plotOn(frame2, DataError=""SumW2""); gauss.plotOn(frame2); ; # Please note that error bars shown (Poisson or SumW2) are for visualization only, the are NOT used; # in a maximum likelihood fit; #; # A (binned) ML fit will ALWAYS assume the Poisson error interpretation of data (the mathematical definition; # of likelihood does not take any external definition of errors). Data with non-unit weights can only be correctly; # fitted with a chi^2 fit (see rf602_chi2fit.py); #; # Importing ROOT TTrees; # -----------------------------------------------------------; # Import ROOT TTree into a RooDataSet; ; tree = makeTTree(); ; # Define 2nd observable y; y = ROOT.RooRealVar(""y"", ""y"", -10, 10); ; # Construct unbinned dataset importing tree branches x and y matching between branches and ROOT.RooRealVars; # is done by name of the branch/RRV; #; # Note that ONLY entries for which x,y have values within their allowed ranges as defined in; # ROOT.RooRealVar x and y are imported. Since the y values in the import tree are in the range [-15,15]; # and RRV y defines a range [-10,10] this means that the ROOT.RooDataSet; # below will have less entries than the ROOT.TTree 'tree'; ; ds = ROOT.RooDataSet(""ds"", ""d",MatchSource.WIKI,doc/master/rf102__dataimport_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8py.html
https://root.cern/doc/master/rf102__dataimport_8py.html:6320,Availability,error,error,6320,"TCanvas(""rf102_dataimport"", ""rf102_dataimport"", 800, 800); c.Divide(3, 2); c.cd(1); ROOT.gPad.SetLeftMargin(0.15); frame.GetYaxis().SetTitleOffset(1.4); frame.Draw(); c.cd(2); ROOT.gPad.SetLeftMargin(0.15); frame2.GetYaxis().SetTitleOffset(1.4); frame2.Draw(); c.cd(4); ROOT.gPad.SetLeftMargin(0.15); frame3.GetYaxis().SetTitleOffset(1.4); frame3.Draw(); c.cd(5); ROOT.gPad.SetLeftMargin(0.15); frame4.GetYaxis().SetTitleOffset(1.4); frame4.Draw(); c.cd(6); ROOT.gPad.SetLeftMargin(0.15); frame4.GetYaxis().SetTitleOffset(1.4); frame5.Draw(); ; c.SaveAs(""rf102_dataimport.png""); Printvoid Print(GNN_Data &d, std::string txt="""")Definition TMVA_SOFIE_GNN_Application.C:59; [#1] INFO:Fitting -- RooAbsPdf::fitTo(gauss_over_gauss_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_gauss_over_gauss_Int[x]_dh) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #0 because y cannot accommodate the value 14.424; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #3 because y cannot accommodate the value -12.0022; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #5 because y cannot accommodate the value 13.8261; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #6 because y cannot accommodate the value -14.9925; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping ...; [#0] WARNING:DataHandling -- RooTreeDataStore::loadValues(ds) Ignored 36 out-of-range events; [#1] INFO:DataHandling -- RooDataSet::read: reading file rf102_testData.txt; [#1] INFO:DataHandling -- RooDataSet::r",MatchSource.WIKI,doc/master/rf102__dataimport_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8py.html
https://root.cern/doc/master/rf102__dataimport_8py.html:4361,Integrability,message,message,4361,"ince the y values in the import tree are in the range [-15,15]; # and RRV y defines a range [-10,10] this means that the ROOT.RooDataSet; # below will have less entries than the ROOT.TTree 'tree'; ; ds = ROOT.RooDataSet(""ds"", ""ds"", {x, y}, Import=tree); ; # Use ascii import/export for datasets; # ------------------------------------------------------------------------------------; ; ; def write_dataset(ds, filename):; # Write data to output stream; outstream = ROOT.std.ofstream(filename); # Optionally, adjust the stream here (e.g. std::setprecision); ds.write(outstream); outstream.close(); ; ; write_dataset(ds, ""rf102_testData.txt""); ; # Read data from input stream. The variables of the dataset need to be supplied; # to the RooDataSet::read() function.; print(""\n-----------------------\nReading data from ASCII""); dataReadBack = ROOT.RooDataSet.read(; ""rf102_testData.txt"",; [x, y], # variables to be read. If the file has more fields, these are ignored.; ""D"", # Prints if a RooFit message stream listens for debug messages. Use Q for quiet.; ); ; dataReadBack.Print(""V""); ; print(""\nOriginal data, line 20:""); ds.get(20).Print(""V""); ; print(""\nRead-back data, line 20:""); dataReadBack.get(20).Print(""V""); ; ; # Plot data set with multiple binning choices; # ------------------------------------------------------------------------------------; # Print number of events in dataset; ds.Print(); ; # Print unbinned dataset with default frame binning (100 bins); frame3 = y.frame(Title=""Unbinned data shown in default frame binning""); ds.plotOn(frame3); ; # Print unbinned dataset with custom binning choice (20 bins); frame4 = y.frame(Title=""Unbinned data shown with custom binning""); ds.plotOn(frame4, Binning=20); ; frame5 = y.frame(Title=""Unbinned data read back from ASCII file""); ds.plotOn(frame5, Binning=20); dataReadBack.plotOn(frame5, Binning=20, MarkerColor=""r"", MarkerStyle=5); ; # Draw all frames on a canvas; c = ROOT.TCanvas(""rf102_dataimport"", ""rf102_dataimport"", 800, 800); c",MatchSource.WIKI,doc/master/rf102__dataimport_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8py.html
https://root.cern/doc/master/rf102__dataimport_8py.html:4394,Integrability,message,messages,4394,"ince the y values in the import tree are in the range [-15,15]; # and RRV y defines a range [-10,10] this means that the ROOT.RooDataSet; # below will have less entries than the ROOT.TTree 'tree'; ; ds = ROOT.RooDataSet(""ds"", ""ds"", {x, y}, Import=tree); ; # Use ascii import/export for datasets; # ------------------------------------------------------------------------------------; ; ; def write_dataset(ds, filename):; # Write data to output stream; outstream = ROOT.std.ofstream(filename); # Optionally, adjust the stream here (e.g. std::setprecision); ds.write(outstream); outstream.close(); ; ; write_dataset(ds, ""rf102_testData.txt""); ; # Read data from input stream. The variables of the dataset need to be supplied; # to the RooDataSet::read() function.; print(""\n-----------------------\nReading data from ASCII""); dataReadBack = ROOT.RooDataSet.read(; ""rf102_testData.txt"",; [x, y], # variables to be read. If the file has more fields, these are ignored.; ""D"", # Prints if a RooFit message stream listens for debug messages. Use Q for quiet.; ); ; dataReadBack.Print(""V""); ; print(""\nOriginal data, line 20:""); ds.get(20).Print(""V""); ; print(""\nRead-back data, line 20:""); dataReadBack.get(20).Print(""V""); ; ; # Plot data set with multiple binning choices; # ------------------------------------------------------------------------------------; # Print number of events in dataset; ds.Print(); ; # Print unbinned dataset with default frame binning (100 bins); frame3 = y.frame(Title=""Unbinned data shown in default frame binning""); ds.plotOn(frame3); ; # Print unbinned dataset with custom binning choice (20 bins); frame4 = y.frame(Title=""Unbinned data shown with custom binning""); ds.plotOn(frame4, Binning=20); ; frame5 = y.frame(Title=""Unbinned data read back from ASCII file""); ds.plotOn(frame5, Binning=20); dataReadBack.plotOn(frame5, Binning=20, MarkerColor=""r"", MarkerStyle=5); ; # Draw all frames on a canvas; c = ROOT.TCanvas(""rf102_dataimport"", ""rf102_dataimport"", 800, 800); c",MatchSource.WIKI,doc/master/rf102__dataimport_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8py.html
https://root.cern/doc/master/rf102__dataimport_8py.html:4047,Modifiability,variab,variables,4047,"Construct unbinned dataset importing tree branches x and y matching between branches and ROOT.RooRealVars; # is done by name of the branch/RRV; #; # Note that ONLY entries for which x,y have values within their allowed ranges as defined in; # ROOT.RooRealVar x and y are imported. Since the y values in the import tree are in the range [-15,15]; # and RRV y defines a range [-10,10] this means that the ROOT.RooDataSet; # below will have less entries than the ROOT.TTree 'tree'; ; ds = ROOT.RooDataSet(""ds"", ""ds"", {x, y}, Import=tree); ; # Use ascii import/export for datasets; # ------------------------------------------------------------------------------------; ; ; def write_dataset(ds, filename):; # Write data to output stream; outstream = ROOT.std.ofstream(filename); # Optionally, adjust the stream here (e.g. std::setprecision); ds.write(outstream); outstream.close(); ; ; write_dataset(ds, ""rf102_testData.txt""); ; # Read data from input stream. The variables of the dataset need to be supplied; # to the RooDataSet::read() function.; print(""\n-----------------------\nReading data from ASCII""); dataReadBack = ROOT.RooDataSet.read(; ""rf102_testData.txt"",; [x, y], # variables to be read. If the file has more fields, these are ignored.; ""D"", # Prints if a RooFit message stream listens for debug messages. Use Q for quiet.; ); ; dataReadBack.Print(""V""); ; print(""\nOriginal data, line 20:""); ds.get(20).Print(""V""); ; print(""\nRead-back data, line 20:""); dataReadBack.get(20).Print(""V""); ; ; # Plot data set with multiple binning choices; # ------------------------------------------------------------------------------------; # Print number of events in dataset; ds.Print(); ; # Print unbinned dataset with default frame binning (100 bins); frame3 = y.frame(Title=""Unbinned data shown in default frame binning""); ds.plotOn(frame3); ; # Print unbinned dataset with custom binning choice (20 bins); frame4 = y.frame(Title=""Unbinned data shown with custom binning""); ds.plotOn(frame4, Binnin",MatchSource.WIKI,doc/master/rf102__dataimport_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8py.html
https://root.cern/doc/master/rf102__dataimport_8py.html:4264,Modifiability,variab,variables,4264,"h x,y have values within their allowed ranges as defined in; # ROOT.RooRealVar x and y are imported. Since the y values in the import tree are in the range [-15,15]; # and RRV y defines a range [-10,10] this means that the ROOT.RooDataSet; # below will have less entries than the ROOT.TTree 'tree'; ; ds = ROOT.RooDataSet(""ds"", ""ds"", {x, y}, Import=tree); ; # Use ascii import/export for datasets; # ------------------------------------------------------------------------------------; ; ; def write_dataset(ds, filename):; # Write data to output stream; outstream = ROOT.std.ofstream(filename); # Optionally, adjust the stream here (e.g. std::setprecision); ds.write(outstream); outstream.close(); ; ; write_dataset(ds, ""rf102_testData.txt""); ; # Read data from input stream. The variables of the dataset need to be supplied; # to the RooDataSet::read() function.; print(""\n-----------------------\nReading data from ASCII""); dataReadBack = ROOT.RooDataSet.read(; ""rf102_testData.txt"",; [x, y], # variables to be read. If the file has more fields, these are ignored.; ""D"", # Prints if a RooFit message stream listens for debug messages. Use Q for quiet.; ); ; dataReadBack.Print(""V""); ; print(""\nOriginal data, line 20:""); ds.get(20).Print(""V""); ; print(""\nRead-back data, line 20:""); dataReadBack.get(20).Print(""V""); ; ; # Plot data set with multiple binning choices; # ------------------------------------------------------------------------------------; # Print number of events in dataset; ds.Print(); ; # Print unbinned dataset with default frame binning (100 bins); frame3 = y.frame(Title=""Unbinned data shown in default frame binning""); ds.plotOn(frame3); ; # Print unbinned dataset with custom binning choice (20 bins); frame4 = y.frame(Title=""Unbinned data shown with custom binning""); ds.plotOn(frame4, Binning=20); ; frame5 = y.frame(Title=""Unbinned data read back from ASCII file""); ds.plotOn(frame5, Binning=20); dataReadBack.plotOn(frame5, Binning=20, MarkerColor=""r"", MarkerStyle=5); ",MatchSource.WIKI,doc/master/rf102__dataimport_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8py.html
https://root.cern/doc/master/rf102__dataimport_8py.html:6414,Performance,optimiz,optimization,6414,"TCanvas(""rf102_dataimport"", ""rf102_dataimport"", 800, 800); c.Divide(3, 2); c.cd(1); ROOT.gPad.SetLeftMargin(0.15); frame.GetYaxis().SetTitleOffset(1.4); frame.Draw(); c.cd(2); ROOT.gPad.SetLeftMargin(0.15); frame2.GetYaxis().SetTitleOffset(1.4); frame2.Draw(); c.cd(4); ROOT.gPad.SetLeftMargin(0.15); frame3.GetYaxis().SetTitleOffset(1.4); frame3.Draw(); c.cd(5); ROOT.gPad.SetLeftMargin(0.15); frame4.GetYaxis().SetTitleOffset(1.4); frame4.Draw(); c.cd(6); ROOT.gPad.SetLeftMargin(0.15); frame4.GetYaxis().SetTitleOffset(1.4); frame5.Draw(); ; c.SaveAs(""rf102_dataimport.png""); Printvoid Print(GNN_Data &d, std::string txt="""")Definition TMVA_SOFIE_GNN_Application.C:59; [#1] INFO:Fitting -- RooAbsPdf::fitTo(gauss_over_gauss_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_gauss_over_gauss_Int[x]_dh) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #0 because y cannot accommodate the value 14.424; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #3 because y cannot accommodate the value -12.0022; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #5 because y cannot accommodate the value 13.8261; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #6 because y cannot accommodate the value -14.9925; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping ...; [#0] WARNING:DataHandling -- RooTreeDataStore::loadValues(ds) Ignored 36 out-of-range events; [#1] INFO:DataHandling -- RooDataSet::read: reading file rf102_testData.txt; [#1] INFO:DataHandling -- RooDataSet::r",MatchSource.WIKI,doc/master/rf102__dataimport_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8py.html
https://root.cern/doc/master/rf102__dataimport_8py.html:6511,Performance,optimiz,optimization,6511,"TCanvas(""rf102_dataimport"", ""rf102_dataimport"", 800, 800); c.Divide(3, 2); c.cd(1); ROOT.gPad.SetLeftMargin(0.15); frame.GetYaxis().SetTitleOffset(1.4); frame.Draw(); c.cd(2); ROOT.gPad.SetLeftMargin(0.15); frame2.GetYaxis().SetTitleOffset(1.4); frame2.Draw(); c.cd(4); ROOT.gPad.SetLeftMargin(0.15); frame3.GetYaxis().SetTitleOffset(1.4); frame3.Draw(); c.cd(5); ROOT.gPad.SetLeftMargin(0.15); frame4.GetYaxis().SetTitleOffset(1.4); frame4.Draw(); c.cd(6); ROOT.gPad.SetLeftMargin(0.15); frame4.GetYaxis().SetTitleOffset(1.4); frame5.Draw(); ; c.SaveAs(""rf102_dataimport.png""); Printvoid Print(GNN_Data &d, std::string txt="""")Definition TMVA_SOFIE_GNN_Application.C:59; [#1] INFO:Fitting -- RooAbsPdf::fitTo(gauss_over_gauss_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_gauss_over_gauss_Int[x]_dh) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #0 because y cannot accommodate the value 14.424; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #3 because y cannot accommodate the value -12.0022; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #5 because y cannot accommodate the value 13.8261; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #6 because y cannot accommodate the value -14.9925; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping ...; [#0] WARNING:DataHandling -- RooTreeDataStore::loadValues(ds) Ignored 36 out-of-range events; [#1] INFO:DataHandling -- RooDataSet::read: reading file rf102_testData.txt; [#1] INFO:DataHandling -- RooDataSet::r",MatchSource.WIKI,doc/master/rf102__dataimport_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8py.html
https://root.cern/doc/master/rf102__dataimport_8py.html:6569,Performance,load,loadValues,6569,"TCanvas(""rf102_dataimport"", ""rf102_dataimport"", 800, 800); c.Divide(3, 2); c.cd(1); ROOT.gPad.SetLeftMargin(0.15); frame.GetYaxis().SetTitleOffset(1.4); frame.Draw(); c.cd(2); ROOT.gPad.SetLeftMargin(0.15); frame2.GetYaxis().SetTitleOffset(1.4); frame2.Draw(); c.cd(4); ROOT.gPad.SetLeftMargin(0.15); frame3.GetYaxis().SetTitleOffset(1.4); frame3.Draw(); c.cd(5); ROOT.gPad.SetLeftMargin(0.15); frame4.GetYaxis().SetTitleOffset(1.4); frame4.Draw(); c.cd(6); ROOT.gPad.SetLeftMargin(0.15); frame4.GetYaxis().SetTitleOffset(1.4); frame5.Draw(); ; c.SaveAs(""rf102_dataimport.png""); Printvoid Print(GNN_Data &d, std::string txt="""")Definition TMVA_SOFIE_GNN_Application.C:59; [#1] INFO:Fitting -- RooAbsPdf::fitTo(gauss_over_gauss_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_gauss_over_gauss_Int[x]_dh) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #0 because y cannot accommodate the value 14.424; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #3 because y cannot accommodate the value -12.0022; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #5 because y cannot accommodate the value 13.8261; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #6 because y cannot accommodate the value -14.9925; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping ...; [#0] WARNING:DataHandling -- RooTreeDataStore::loadValues(ds) Ignored 36 out-of-range events; [#1] INFO:DataHandling -- RooDataSet::read: reading file rf102_testData.txt; [#1] INFO:DataHandling -- RooDataSet::r",MatchSource.WIKI,doc/master/rf102__dataimport_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8py.html
https://root.cern/doc/master/rf102__dataimport_8py.html:6693,Performance,load,loadValues,6693,"me4.GetYaxis().SetTitleOffset(1.4); frame4.Draw(); c.cd(6); ROOT.gPad.SetLeftMargin(0.15); frame4.GetYaxis().SetTitleOffset(1.4); frame5.Draw(); ; c.SaveAs(""rf102_dataimport.png""); Printvoid Print(GNN_Data &d, std::string txt="""")Definition TMVA_SOFIE_GNN_Application.C:59; [#1] INFO:Fitting -- RooAbsPdf::fitTo(gauss_over_gauss_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_gauss_over_gauss_Int[x]_dh) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #0 because y cannot accommodate the value 14.424; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #3 because y cannot accommodate the value -12.0022; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #5 because y cannot accommodate the value 13.8261; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #6 because y cannot accommodate the value -14.9925; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping ...; [#0] WARNING:DataHandling -- RooTreeDataStore::loadValues(ds) Ignored 36 out-of-range events; [#1] INFO:DataHandling -- RooDataSet::read: reading file rf102_testData.txt; [#1] INFO:DataHandling -- RooDataSet::read: read 64 events (ignored 0 out of range events); DataStore dataset (rf102_testData.txt); Contains 64 entries; Observables: ; 1) x = 9.46654 L(-10 - 10) ""x""; 2) y = 0.0174204 L(-10 - 10) ""y""; 3) blindState = Normal(idx = 0); ""Blinding State""; 1) RooRealVar:: y = 0.0106407; 2) RooRealVar:: x = -0.79919; 1) RooRealVar:: x = 0.0106407; 2) RooRealVar:: y = -0.79919; 3) RooCategory:: blindState = ",MatchSource.WIKI,doc/master/rf102__dataimport_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8py.html
https://root.cern/doc/master/rf102__dataimport_8py.html:6819,Performance,load,loadValues,6819,".4); frame5.Draw(); ; c.SaveAs(""rf102_dataimport.png""); Printvoid Print(GNN_Data &d, std::string txt="""")Definition TMVA_SOFIE_GNN_Application.C:59; [#1] INFO:Fitting -- RooAbsPdf::fitTo(gauss_over_gauss_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_gauss_over_gauss_Int[x]_dh) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #0 because y cannot accommodate the value 14.424; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #3 because y cannot accommodate the value -12.0022; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #5 because y cannot accommodate the value 13.8261; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #6 because y cannot accommodate the value -14.9925; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping ...; [#0] WARNING:DataHandling -- RooTreeDataStore::loadValues(ds) Ignored 36 out-of-range events; [#1] INFO:DataHandling -- RooDataSet::read: reading file rf102_testData.txt; [#1] INFO:DataHandling -- RooDataSet::read: read 64 events (ignored 0 out of range events); DataStore dataset (rf102_testData.txt); Contains 64 entries; Observables: ; 1) x = 9.46654 L(-10 - 10) ""x""; 2) y = 0.0174204 L(-10 - 10) ""y""; 3) blindState = Normal(idx = 0); ""Blinding State""; 1) RooRealVar:: y = 0.0106407; 2) RooRealVar:: x = -0.79919; 1) RooRealVar:: x = 0.0106407; 2) RooRealVar:: y = -0.79919; 3) RooCategory:: blindState = Normal(idx = 0); ; RooDataSet::ds[y,x] = 64 entries; ; -----------------------; Reading data from ASCII; ; Original data, lin",MatchSource.WIKI,doc/master/rf102__dataimport_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8py.html
https://root.cern/doc/master/rf102__dataimport_8py.html:6944,Performance,load,loadValues,6944,"GNN_Application.C:59; [#1] INFO:Fitting -- RooAbsPdf::fitTo(gauss_over_gauss_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_gauss_over_gauss_Int[x]_dh) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #0 because y cannot accommodate the value 14.424; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #3 because y cannot accommodate the value -12.0022; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #5 because y cannot accommodate the value 13.8261; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #6 because y cannot accommodate the value -14.9925; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping ...; [#0] WARNING:DataHandling -- RooTreeDataStore::loadValues(ds) Ignored 36 out-of-range events; [#1] INFO:DataHandling -- RooDataSet::read: reading file rf102_testData.txt; [#1] INFO:DataHandling -- RooDataSet::read: read 64 events (ignored 0 out of range events); DataStore dataset (rf102_testData.txt); Contains 64 entries; Observables: ; 1) x = 9.46654 L(-10 - 10) ""x""; 2) y = 0.0174204 L(-10 - 10) ""y""; 3) blindState = Normal(idx = 0); ""Blinding State""; 1) RooRealVar:: y = 0.0106407; 2) RooRealVar:: x = -0.79919; 1) RooRealVar:: x = 0.0106407; 2) RooRealVar:: y = -0.79919; 3) RooCategory:: blindState = Normal(idx = 0); ; RooDataSet::ds[y,x] = 64 entries; ; -----------------------; Reading data from ASCII; ; Original data, line 20:; ; Read-back data, line 20:; DateFebruary 2018 ; AuthorsClemens Lange, Wouter Verkerke (C version) ; Definition in file",MatchSource.WIKI,doc/master/rf102__dataimport_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8py.html
https://root.cern/doc/master/rf102__dataimport_8py.html:7070,Performance,load,loadValues,7070,"ation set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_gauss_over_gauss_Int[x]_dh) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #0 because y cannot accommodate the value 14.424; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #3 because y cannot accommodate the value -12.0022; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #5 because y cannot accommodate the value 13.8261; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #6 because y cannot accommodate the value -14.9925; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping ...; [#0] WARNING:DataHandling -- RooTreeDataStore::loadValues(ds) Ignored 36 out-of-range events; [#1] INFO:DataHandling -- RooDataSet::read: reading file rf102_testData.txt; [#1] INFO:DataHandling -- RooDataSet::read: read 64 events (ignored 0 out of range events); DataStore dataset (rf102_testData.txt); Contains 64 entries; Observables: ; 1) x = 9.46654 L(-10 - 10) ""x""; 2) y = 0.0174204 L(-10 - 10) ""y""; 3) blindState = Normal(idx = 0); ""Blinding State""; 1) RooRealVar:: y = 0.0106407; 2) RooRealVar:: x = -0.79919; 1) RooRealVar:: x = 0.0106407; 2) RooRealVar:: y = -0.79919; 3) RooCategory:: blindState = Normal(idx = 0); ; RooDataSet::ds[y,x] = 64 entries; ; -----------------------; Reading data from ASCII; ; Original data, line 20:; ; Read-back data, line 20:; DateFebruary 2018 ; AuthorsClemens Lange, Wouter Verkerke (C version) ; Definition in file rf102_dataimport.py. tutorialsroofitrf102_dataimport.py. ROOT master - Reference Guide Generated on ",MatchSource.WIKI,doc/master/rf102__dataimport_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8py.html
https://root.cern/doc/master/rf102__dataimport_8py.html:7146,Performance,load,loadValues,7146,"; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_gauss_over_gauss_Int[x]_dh) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #0 because y cannot accommodate the value 14.424; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #3 because y cannot accommodate the value -12.0022; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #5 because y cannot accommodate the value 13.8261; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping event #6 because y cannot accommodate the value -14.9925; [#1] INFO:DataHandling -- RooTreeDataStore::loadValues(ds) Skipping ...; [#0] WARNING:DataHandling -- RooTreeDataStore::loadValues(ds) Ignored 36 out-of-range events; [#1] INFO:DataHandling -- RooDataSet::read: reading file rf102_testData.txt; [#1] INFO:DataHandling -- RooDataSet::read: read 64 events (ignored 0 out of range events); DataStore dataset (rf102_testData.txt); Contains 64 entries; Observables: ; 1) x = 9.46654 L(-10 - 10) ""x""; 2) y = 0.0174204 L(-10 - 10) ""y""; 3) blindState = Normal(idx = 0); ""Blinding State""; 1) RooRealVar:: y = 0.0106407; 2) RooRealVar:: x = -0.79919; 1) RooRealVar:: x = 0.0106407; 2) RooRealVar:: y = -0.79919; 3) RooCategory:: blindState = Normal(idx = 0); ; RooDataSet::ds[y,x] = 64 entries; ; -----------------------; Reading data from ASCII; ; Original data, line 20:; ; Read-back data, line 20:; DateFebruary 2018 ; AuthorsClemens Lange, Wouter Verkerke (C version) ; Definition in file rf102_dataimport.py. tutorialsroofitrf102_dataimport.py. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:30 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/rf102__dataimport_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf102__dataimport_8py.html
https://root.cern/doc/master/rf103__interprfuncs_8C.html:6560,Availability,error,error,6560,"stly switches that change the behaviour of functions of PDFs (or othe...Definition JSONIO.h:26; rf103_interprfuncsDefinition rf103_interprfuncs.py:1; xmlio::Titleconst char * TitleDefinition TXMLSetup.cxx:68; ; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(genpdf_over_genpdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_genpdf_over_genpdf_Int[x]_genpdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(g2_over_g2_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_g2_over_g2_Int[x]_g1Data) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; ; RooFitResult: minimized FCN value: 2551.39, estimated distance to minimum: 4.39288e-06; covariance matrix quality: Full, accurate covariance matrix; Status : MINIMIZE=0 HESSE=0 ; ; Floating Parameter FinalValue +/- Error ; ------------------",MatchSource.WIKI,doc/master/rf103__interprfuncs_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf103__interprfuncs_8C.html
https://root.cern/doc/master/rf103__interprfuncs_8C.html:7287,Availability,error,error,7287,"stly switches that change the behaviour of functions of PDFs (or othe...Definition JSONIO.h:26; rf103_interprfuncsDefinition rf103_interprfuncs.py:1; xmlio::Titleconst char * TitleDefinition TXMLSetup.cxx:68; ; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(genpdf_over_genpdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_genpdf_over_genpdf_Int[x]_genpdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(g2_over_g2_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_g2_over_g2_Int[x]_g1Data) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; ; RooFitResult: minimized FCN value: 2551.39, estimated distance to minimum: 4.39288e-06; covariance matrix quality: Full, accurate covariance matrix; Status : MINIMIZE=0 HESSE=0 ; ; Floating Parameter FinalValue +/- Error ; ------------------",MatchSource.WIKI,doc/master/rf103__interprfuncs_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf103__interprfuncs_8C.html
https://root.cern/doc/master/rf103__interprfuncs_8C.html:6028,Deployability,integrat,integrator,6028,"stly switches that change the behaviour of functions of PDFs (or othe...Definition JSONIO.h:26; rf103_interprfuncsDefinition rf103_interprfuncs.py:1; xmlio::Titleconst char * TitleDefinition TXMLSetup.cxx:68; ; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(genpdf_over_genpdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_genpdf_over_genpdf_Int[x]_genpdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(g2_over_g2_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_g2_over_g2_Int[x]_g1Data) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; ; RooFitResult: minimized FCN value: 2551.39, estimated distance to minimum: 4.39288e-06; covariance matrix quality: Full, accurate covariance matrix; Status : MINIMIZE=0 HESSE=0 ; ; Floating Parameter FinalValue +/- Error ; ------------------",MatchSource.WIKI,doc/master/rf103__interprfuncs_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf103__interprfuncs_8C.html
https://root.cern/doc/master/rf103__interprfuncs_8C.html:6159,Deployability,integrat,integrator,6159,"stly switches that change the behaviour of functions of PDFs (or othe...Definition JSONIO.h:26; rf103_interprfuncsDefinition rf103_interprfuncs.py:1; xmlio::Titleconst char * TitleDefinition TXMLSetup.cxx:68; ; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(genpdf_over_genpdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_genpdf_over_genpdf_Int[x]_genpdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(g2_over_g2_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_g2_over_g2_Int[x]_g1Data) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; ; RooFitResult: minimized FCN value: 2551.39, estimated distance to minimum: 4.39288e-06; covariance matrix quality: Full, accurate covariance matrix; Status : MINIMIZE=0 HESSE=0 ; ; Floating Parameter FinalValue +/- Error ; ------------------",MatchSource.WIKI,doc/master/rf103__interprfuncs_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf103__interprfuncs_8C.html
https://root.cern/doc/master/rf103__interprfuncs_8C.html:6751,Deployability,integrat,integrator,6751,"stly switches that change the behaviour of functions of PDFs (or othe...Definition JSONIO.h:26; rf103_interprfuncsDefinition rf103_interprfuncs.py:1; xmlio::Titleconst char * TitleDefinition TXMLSetup.cxx:68; ; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(genpdf_over_genpdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_genpdf_over_genpdf_Int[x]_genpdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(g2_over_g2_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_g2_over_g2_Int[x]_g1Data) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; ; RooFitResult: minimized FCN value: 2551.39, estimated distance to minimum: 4.39288e-06; covariance matrix quality: Full, accurate covariance matrix; Status : MINIMIZE=0 HESSE=0 ; ; Floating Parameter FinalValue +/- Error ; ------------------",MatchSource.WIKI,doc/master/rf103__interprfuncs_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf103__interprfuncs_8C.html
https://root.cern/doc/master/rf103__interprfuncs_8C.html:6979,Deployability,integrat,integrator,6979,"stly switches that change the behaviour of functions of PDFs (or othe...Definition JSONIO.h:26; rf103_interprfuncsDefinition rf103_interprfuncs.py:1; xmlio::Titleconst char * TitleDefinition TXMLSetup.cxx:68; ; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(genpdf_over_genpdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_genpdf_over_genpdf_Int[x]_genpdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(g2_over_g2_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_g2_over_g2_Int[x]_g1Data) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; ; RooFitResult: minimized FCN value: 2551.39, estimated distance to minimum: 4.39288e-06; covariance matrix quality: Full, accurate covariance matrix; Status : MINIMIZE=0 HESSE=0 ; ; Floating Parameter FinalValue +/- Error ; ------------------",MatchSource.WIKI,doc/master/rf103__interprfuncs_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf103__interprfuncs_8C.html
https://root.cern/doc/master/rf103__interprfuncs_8C.html:6028,Integrability,integrat,integrator,6028,"stly switches that change the behaviour of functions of PDFs (or othe...Definition JSONIO.h:26; rf103_interprfuncsDefinition rf103_interprfuncs.py:1; xmlio::Titleconst char * TitleDefinition TXMLSetup.cxx:68; ; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(genpdf_over_genpdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_genpdf_over_genpdf_Int[x]_genpdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(g2_over_g2_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_g2_over_g2_Int[x]_g1Data) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; ; RooFitResult: minimized FCN value: 2551.39, estimated distance to minimum: 4.39288e-06; covariance matrix quality: Full, accurate covariance matrix; Status : MINIMIZE=0 HESSE=0 ; ; Floating Parameter FinalValue +/- Error ; ------------------",MatchSource.WIKI,doc/master/rf103__interprfuncs_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf103__interprfuncs_8C.html
https://root.cern/doc/master/rf103__interprfuncs_8C.html:6159,Integrability,integrat,integrator,6159,"stly switches that change the behaviour of functions of PDFs (or othe...Definition JSONIO.h:26; rf103_interprfuncsDefinition rf103_interprfuncs.py:1; xmlio::Titleconst char * TitleDefinition TXMLSetup.cxx:68; ; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(genpdf_over_genpdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_genpdf_over_genpdf_Int[x]_genpdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(g2_over_g2_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_g2_over_g2_Int[x]_g1Data) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; ; RooFitResult: minimized FCN value: 2551.39, estimated distance to minimum: 4.39288e-06; covariance matrix quality: Full, accurate covariance matrix; Status : MINIMIZE=0 HESSE=0 ; ; Floating Parameter FinalValue +/- Error ; ------------------",MatchSource.WIKI,doc/master/rf103__interprfuncs_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf103__interprfuncs_8C.html
https://root.cern/doc/master/rf103__interprfuncs_8C.html:6751,Integrability,integrat,integrator,6751,"stly switches that change the behaviour of functions of PDFs (or othe...Definition JSONIO.h:26; rf103_interprfuncsDefinition rf103_interprfuncs.py:1; xmlio::Titleconst char * TitleDefinition TXMLSetup.cxx:68; ; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(genpdf_over_genpdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_genpdf_over_genpdf_Int[x]_genpdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(g2_over_g2_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_g2_over_g2_Int[x]_g1Data) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; ; RooFitResult: minimized FCN value: 2551.39, estimated distance to minimum: 4.39288e-06; covariance matrix quality: Full, accurate covariance matrix; Status : MINIMIZE=0 HESSE=0 ; ; Floating Parameter FinalValue +/- Error ; ------------------",MatchSource.WIKI,doc/master/rf103__interprfuncs_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf103__interprfuncs_8C.html
https://root.cern/doc/master/rf103__interprfuncs_8C.html:6979,Integrability,integrat,integrator,6979,"stly switches that change the behaviour of functions of PDFs (or othe...Definition JSONIO.h:26; rf103_interprfuncsDefinition rf103_interprfuncs.py:1; xmlio::Titleconst char * TitleDefinition TXMLSetup.cxx:68; ; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(genpdf_over_genpdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_genpdf_over_genpdf_Int[x]_genpdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(g2_over_g2_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_g2_over_g2_Int[x]_g1Data) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; ; RooFitResult: minimized FCN value: 2551.39, estimated distance to minimum: 4.39288e-06; covariance matrix quality: Full, accurate covariance matrix; Status : MINIMIZE=0 HESSE=0 ; ; Floating Parameter FinalValue +/- Error ; ------------------",MatchSource.WIKI,doc/master/rf103__interprfuncs_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf103__interprfuncs_8C.html
https://root.cern/doc/master/rf103__interprfuncs_8C.html:4910,Modifiability,variab,variable,4910,":101; RooDataSet.h; RooFitResult.h; RooGaussian.h; RooGenericPdf.h; RooPlot.h; RooRealVar.h; TAxis.h; TCanvas.h; dataOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void dataDefinition TGWin32VirtualXProxy.cxx:104; gPad#define gPadDefinition TVirtualPad.h:308; RooArgSetRooArgSet is a container object that can hold multiple RooAbsArg objects.Definition RooArgSet.h:24; RooFormulaVarA RooFormulaVar is a generic implementation of a real-valued object, which takes a RooArgList of serv...Definition RooFormulaVar.h:30; RooGaussianPlain Gaussian p.d.f.Definition RooGaussian.h:24; RooGenericPdfImplementation of a probability density function that takes a RooArgList of servers and a C++ express...Definition RooGenericPdf.h:25; RooPlotPlot frame and a container for graphics objects within that frame.Definition RooPlot.h:45; RooPlot::framestatic RooPlot * frame(const RooAbsRealLValue &var, double xmin, double xmax, Int_t nBins)Create a new frame for a given variable in x.Definition RooPlot.cxx:225; RooPlot::GetYaxisTAxis * GetYaxis() constDefinition RooPlot.cxx:1264; RooPlot::Drawvoid Draw(Option_t *options=nullptr) overrideDraw this plot and all of the elements it contains.Definition RooPlot.cxx:637; RooRealVarVariable that can be changed from the outside.Definition RooRealVar.h:37; TAttAxis::SetTitleOffsetvirtual void SetTitleOffset(Float_t offset=1)Set distance between the axis and the axis title.Definition TAttAxis.cxx:298; TCanvasThe Canvas class.Definition TCanvas.h:23; RooFit::SaveRooCmdArg Save(bool flag=true)Definition RooGlobalFunc.cxx:649; RooFit::PrintLevelRooCmdArg PrintLevel(Int_t code)Definition RooGlobalFunc.cxx:657; sigmaconst Double_t sigmaDefinition h1analysisProxy.h:11; xDouble_t x[n]Definition legend1.C:17; RooFitThe namespace RooFit contains mostly switches that change the behaviour of functions of PDFs (or othe...Definition JSONIO.h:26; rf103_interprfunc",MatchSource.WIKI,doc/master/rf103__interprfuncs_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf103__interprfuncs_8C.html
https://root.cern/doc/master/rf103__interprfuncs_8C.html:6654,Performance,optimiz,optimization,6654,"stly switches that change the behaviour of functions of PDFs (or othe...Definition JSONIO.h:26; rf103_interprfuncsDefinition rf103_interprfuncs.py:1; xmlio::Titleconst char * TitleDefinition TXMLSetup.cxx:68; ; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(genpdf_over_genpdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_genpdf_over_genpdf_Int[x]_genpdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(g2_over_g2_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_g2_over_g2_Int[x]_g1Data) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; ; RooFitResult: minimized FCN value: 2551.39, estimated distance to minimum: 4.39288e-06; covariance matrix quality: Full, accurate covariance matrix; Status : MINIMIZE=0 HESSE=0 ; ; Floating Parameter FinalValue +/- Error ; ------------------",MatchSource.WIKI,doc/master/rf103__interprfuncs_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf103__interprfuncs_8C.html
https://root.cern/doc/master/rf103__interprfuncs_8C.html:6882,Performance,optimiz,optimization,6882,"stly switches that change the behaviour of functions of PDFs (or othe...Definition JSONIO.h:26; rf103_interprfuncsDefinition rf103_interprfuncs.py:1; xmlio::Titleconst char * TitleDefinition TXMLSetup.cxx:68; ; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(genpdf_over_genpdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_genpdf_over_genpdf_Int[x]_genpdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(g2_over_g2_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_g2_over_g2_Int[x]_g1Data) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; ; RooFitResult: minimized FCN value: 2551.39, estimated distance to minimum: 4.39288e-06; covariance matrix quality: Full, accurate covariance matrix; Status : MINIMIZE=0 HESSE=0 ; ; Floating Parameter FinalValue +/- Error ; ------------------",MatchSource.WIKI,doc/master/rf103__interprfuncs_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf103__interprfuncs_8C.html
https://root.cern/doc/master/rf103__interprfuncs_8C.html:7381,Performance,optimiz,optimization,7381,"stly switches that change the behaviour of functions of PDFs (or othe...Definition JSONIO.h:26; rf103_interprfuncsDefinition rf103_interprfuncs.py:1; xmlio::Titleconst char * TitleDefinition TXMLSetup.cxx:68; ; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(genpdf_over_genpdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_genpdf_over_genpdf_Int[x]_genpdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(g2_over_g2_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_g2_over_g2_Int[x]_g1Data) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; ; RooFitResult: minimized FCN value: 2551.39, estimated distance to minimum: 4.39288e-06; covariance matrix quality: Full, accurate covariance matrix; Status : MINIMIZE=0 HESSE=0 ; ; Floating Parameter FinalValue +/- Error ; ------------------",MatchSource.WIKI,doc/master/rf103__interprfuncs_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf103__interprfuncs_8C.html
https://root.cern/doc/master/rf103__interprfuncs_8C.html:7478,Performance,optimiz,optimization,7478,"stly switches that change the behaviour of functions of PDFs (or othe...Definition JSONIO.h:26; rf103_interprfuncsDefinition rf103_interprfuncs.py:1; xmlio::Titleconst char * TitleDefinition TXMLSetup.cxx:68; ; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(genpdf_over_genpdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_genpdf_over_genpdf_Int[x]_genpdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(g2_over_g2_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_g2_over_g2_Int[x]_g1Data) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; ; RooFitResult: minimized FCN value: 2551.39, estimated distance to minimum: 4.39288e-06; covariance matrix quality: Full, accurate covariance matrix; Status : MINIMIZE=0 HESSE=0 ; ; Floating Parameter FinalValue +/- Error ; ------------------",MatchSource.WIKI,doc/master/rf103__interprfuncs_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf103__interprfuncs_8C.html
https://root.cern/doc/master/rf103__interprfuncs_8py.html:3694,Availability,error,error,3694,"SetLeftMargin(0.15); xframe.GetYaxis().SetTitleOffset(1.4); xframe.Draw(); c.cd(2); ROOT.gPad.SetLeftMargin(0.15); xframe2.GetYaxis().SetTitleOffset(1.4); xframe2.Draw(); ; c.SaveAs(""rf103_interprfuncs.png""); [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(genpdf_over_genpdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_genpdf_over_genpdf_Int[x]_genpdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(g2_over_g2_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_g2_over_g2_Int[x]_g1Data) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; ; RooFitResult: minimized FCN value: 2551.39, estimated distance to minimum: 4.39288e-06; covariance matrix quality: Full, accurate covariance matrix; Status : MINIMIZE=0 HESSE=0 ; ; Floating Parameter FinalValue +/- Error ; -------------------",MatchSource.WIKI,doc/master/rf103__interprfuncs_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf103__interprfuncs_8py.html
https://root.cern/doc/master/rf103__interprfuncs_8py.html:4421,Availability,error,error,4421,"SetLeftMargin(0.15); xframe.GetYaxis().SetTitleOffset(1.4); xframe.Draw(); c.cd(2); ROOT.gPad.SetLeftMargin(0.15); xframe2.GetYaxis().SetTitleOffset(1.4); xframe2.Draw(); ; c.SaveAs(""rf103_interprfuncs.png""); [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(genpdf_over_genpdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_genpdf_over_genpdf_Int[x]_genpdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(g2_over_g2_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_g2_over_g2_Int[x]_g1Data) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; ; RooFitResult: minimized FCN value: 2551.39, estimated distance to minimum: 4.39288e-06; covariance matrix quality: Full, accurate covariance matrix; Status : MINIMIZE=0 HESSE=0 ; ; Floating Parameter FinalValue +/- Error ; -------------------",MatchSource.WIKI,doc/master/rf103__interprfuncs_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf103__interprfuncs_8py.html
https://root.cern/doc/master/rf103__interprfuncs_8py.html:3162,Deployability,integrat,integrator,3162,"SetLeftMargin(0.15); xframe.GetYaxis().SetTitleOffset(1.4); xframe.Draw(); c.cd(2); ROOT.gPad.SetLeftMargin(0.15); xframe2.GetYaxis().SetTitleOffset(1.4); xframe2.Draw(); ; c.SaveAs(""rf103_interprfuncs.png""); [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(genpdf_over_genpdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_genpdf_over_genpdf_Int[x]_genpdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(g2_over_g2_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_g2_over_g2_Int[x]_g1Data) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; ; RooFitResult: minimized FCN value: 2551.39, estimated distance to minimum: 4.39288e-06; covariance matrix quality: Full, accurate covariance matrix; Status : MINIMIZE=0 HESSE=0 ; ; Floating Parameter FinalValue +/- Error ; -------------------",MatchSource.WIKI,doc/master/rf103__interprfuncs_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf103__interprfuncs_8py.html
https://root.cern/doc/master/rf103__interprfuncs_8py.html:3293,Deployability,integrat,integrator,3293,"SetLeftMargin(0.15); xframe.GetYaxis().SetTitleOffset(1.4); xframe.Draw(); c.cd(2); ROOT.gPad.SetLeftMargin(0.15); xframe2.GetYaxis().SetTitleOffset(1.4); xframe2.Draw(); ; c.SaveAs(""rf103_interprfuncs.png""); [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(genpdf_over_genpdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_genpdf_over_genpdf_Int[x]_genpdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(g2_over_g2_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_g2_over_g2_Int[x]_g1Data) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; ; RooFitResult: minimized FCN value: 2551.39, estimated distance to minimum: 4.39288e-06; covariance matrix quality: Full, accurate covariance matrix; Status : MINIMIZE=0 HESSE=0 ; ; Floating Parameter FinalValue +/- Error ; -------------------",MatchSource.WIKI,doc/master/rf103__interprfuncs_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf103__interprfuncs_8py.html
https://root.cern/doc/master/rf103__interprfuncs_8py.html:3885,Deployability,integrat,integrator,3885,"SetLeftMargin(0.15); xframe.GetYaxis().SetTitleOffset(1.4); xframe.Draw(); c.cd(2); ROOT.gPad.SetLeftMargin(0.15); xframe2.GetYaxis().SetTitleOffset(1.4); xframe2.Draw(); ; c.SaveAs(""rf103_interprfuncs.png""); [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(genpdf_over_genpdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_genpdf_over_genpdf_Int[x]_genpdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(g2_over_g2_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_g2_over_g2_Int[x]_g1Data) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; ; RooFitResult: minimized FCN value: 2551.39, estimated distance to minimum: 4.39288e-06; covariance matrix quality: Full, accurate covariance matrix; Status : MINIMIZE=0 HESSE=0 ; ; Floating Parameter FinalValue +/- Error ; -------------------",MatchSource.WIKI,doc/master/rf103__interprfuncs_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf103__interprfuncs_8py.html
https://root.cern/doc/master/rf103__interprfuncs_8py.html:4113,Deployability,integrat,integrator,4113,"SetLeftMargin(0.15); xframe.GetYaxis().SetTitleOffset(1.4); xframe.Draw(); c.cd(2); ROOT.gPad.SetLeftMargin(0.15); xframe2.GetYaxis().SetTitleOffset(1.4); xframe2.Draw(); ; c.SaveAs(""rf103_interprfuncs.png""); [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(genpdf_over_genpdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_genpdf_over_genpdf_Int[x]_genpdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(g2_over_g2_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_g2_over_g2_Int[x]_g1Data) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; ; RooFitResult: minimized FCN value: 2551.39, estimated distance to minimum: 4.39288e-06; covariance matrix quality: Full, accurate covariance matrix; Status : MINIMIZE=0 HESSE=0 ; ; Floating Parameter FinalValue +/- Error ; -------------------",MatchSource.WIKI,doc/master/rf103__interprfuncs_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf103__interprfuncs_8py.html
https://root.cern/doc/master/rf103__interprfuncs_8py.html:3162,Integrability,integrat,integrator,3162,"SetLeftMargin(0.15); xframe.GetYaxis().SetTitleOffset(1.4); xframe.Draw(); c.cd(2); ROOT.gPad.SetLeftMargin(0.15); xframe2.GetYaxis().SetTitleOffset(1.4); xframe2.Draw(); ; c.SaveAs(""rf103_interprfuncs.png""); [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(genpdf_over_genpdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_genpdf_over_genpdf_Int[x]_genpdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(g2_over_g2_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_g2_over_g2_Int[x]_g1Data) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; ; RooFitResult: minimized FCN value: 2551.39, estimated distance to minimum: 4.39288e-06; covariance matrix quality: Full, accurate covariance matrix; Status : MINIMIZE=0 HESSE=0 ; ; Floating Parameter FinalValue +/- Error ; -------------------",MatchSource.WIKI,doc/master/rf103__interprfuncs_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf103__interprfuncs_8py.html
https://root.cern/doc/master/rf103__interprfuncs_8py.html:3293,Integrability,integrat,integrator,3293,"SetLeftMargin(0.15); xframe.GetYaxis().SetTitleOffset(1.4); xframe.Draw(); c.cd(2); ROOT.gPad.SetLeftMargin(0.15); xframe2.GetYaxis().SetTitleOffset(1.4); xframe2.Draw(); ; c.SaveAs(""rf103_interprfuncs.png""); [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(genpdf_over_genpdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_genpdf_over_genpdf_Int[x]_genpdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(g2_over_g2_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_g2_over_g2_Int[x]_g1Data) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; ; RooFitResult: minimized FCN value: 2551.39, estimated distance to minimum: 4.39288e-06; covariance matrix quality: Full, accurate covariance matrix; Status : MINIMIZE=0 HESSE=0 ; ; Floating Parameter FinalValue +/- Error ; -------------------",MatchSource.WIKI,doc/master/rf103__interprfuncs_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf103__interprfuncs_8py.html
https://root.cern/doc/master/rf103__interprfuncs_8py.html:3885,Integrability,integrat,integrator,3885,"SetLeftMargin(0.15); xframe.GetYaxis().SetTitleOffset(1.4); xframe.Draw(); c.cd(2); ROOT.gPad.SetLeftMargin(0.15); xframe2.GetYaxis().SetTitleOffset(1.4); xframe2.Draw(); ; c.SaveAs(""rf103_interprfuncs.png""); [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(genpdf_over_genpdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_genpdf_over_genpdf_Int[x]_genpdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(g2_over_g2_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_g2_over_g2_Int[x]_g1Data) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; ; RooFitResult: minimized FCN value: 2551.39, estimated distance to minimum: 4.39288e-06; covariance matrix quality: Full, accurate covariance matrix; Status : MINIMIZE=0 HESSE=0 ; ; Floating Parameter FinalValue +/- Error ; -------------------",MatchSource.WIKI,doc/master/rf103__interprfuncs_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf103__interprfuncs_8py.html
https://root.cern/doc/master/rf103__interprfuncs_8py.html:4113,Integrability,integrat,integrator,4113,"SetLeftMargin(0.15); xframe.GetYaxis().SetTitleOffset(1.4); xframe.Draw(); c.cd(2); ROOT.gPad.SetLeftMargin(0.15); xframe2.GetYaxis().SetTitleOffset(1.4); xframe2.Draw(); ; c.SaveAs(""rf103_interprfuncs.png""); [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(genpdf_over_genpdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_genpdf_over_genpdf_Int[x]_genpdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(g2_over_g2_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_g2_over_g2_Int[x]_g1Data) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; ; RooFitResult: minimized FCN value: 2551.39, estimated distance to minimum: 4.39288e-06; covariance matrix quality: Full, accurate covariance matrix; Status : MINIMIZE=0 HESSE=0 ; ; Floating Parameter FinalValue +/- Error ; -------------------",MatchSource.WIKI,doc/master/rf103__interprfuncs_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf103__interprfuncs_8py.html
https://root.cern/doc/master/rf103__interprfuncs_8py.html:3788,Performance,optimiz,optimization,3788,"SetLeftMargin(0.15); xframe.GetYaxis().SetTitleOffset(1.4); xframe.Draw(); c.cd(2); ROOT.gPad.SetLeftMargin(0.15); xframe2.GetYaxis().SetTitleOffset(1.4); xframe2.Draw(); ; c.SaveAs(""rf103_interprfuncs.png""); [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(genpdf_over_genpdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_genpdf_over_genpdf_Int[x]_genpdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(g2_over_g2_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_g2_over_g2_Int[x]_g1Data) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; ; RooFitResult: minimized FCN value: 2551.39, estimated distance to minimum: 4.39288e-06; covariance matrix quality: Full, accurate covariance matrix; Status : MINIMIZE=0 HESSE=0 ; ; Floating Parameter FinalValue +/- Error ; -------------------",MatchSource.WIKI,doc/master/rf103__interprfuncs_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf103__interprfuncs_8py.html
https://root.cern/doc/master/rf103__interprfuncs_8py.html:4016,Performance,optimiz,optimization,4016,"SetLeftMargin(0.15); xframe.GetYaxis().SetTitleOffset(1.4); xframe.Draw(); c.cd(2); ROOT.gPad.SetLeftMargin(0.15); xframe2.GetYaxis().SetTitleOffset(1.4); xframe2.Draw(); ; c.SaveAs(""rf103_interprfuncs.png""); [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(genpdf_over_genpdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_genpdf_over_genpdf_Int[x]_genpdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(g2_over_g2_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_g2_over_g2_Int[x]_g1Data) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; ; RooFitResult: minimized FCN value: 2551.39, estimated distance to minimum: 4.39288e-06; covariance matrix quality: Full, accurate covariance matrix; Status : MINIMIZE=0 HESSE=0 ; ; Floating Parameter FinalValue +/- Error ; -------------------",MatchSource.WIKI,doc/master/rf103__interprfuncs_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf103__interprfuncs_8py.html
https://root.cern/doc/master/rf103__interprfuncs_8py.html:4515,Performance,optimiz,optimization,4515,"SetLeftMargin(0.15); xframe.GetYaxis().SetTitleOffset(1.4); xframe.Draw(); c.cd(2); ROOT.gPad.SetLeftMargin(0.15); xframe2.GetYaxis().SetTitleOffset(1.4); xframe2.Draw(); ; c.SaveAs(""rf103_interprfuncs.png""); [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(genpdf_over_genpdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_genpdf_over_genpdf_Int[x]_genpdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(g2_over_g2_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_g2_over_g2_Int[x]_g1Data) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; ; RooFitResult: minimized FCN value: 2551.39, estimated distance to minimum: 4.39288e-06; covariance matrix quality: Full, accurate covariance matrix; Status : MINIMIZE=0 HESSE=0 ; ; Floating Parameter FinalValue +/- Error ; -------------------",MatchSource.WIKI,doc/master/rf103__interprfuncs_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf103__interprfuncs_8py.html
https://root.cern/doc/master/rf103__interprfuncs_8py.html:4612,Performance,optimiz,optimization,4612,"SetLeftMargin(0.15); xframe.GetYaxis().SetTitleOffset(1.4); xframe.Draw(); c.cd(2); ROOT.gPad.SetLeftMargin(0.15); xframe2.GetYaxis().SetTitleOffset(1.4); xframe2.Draw(); ; c.SaveAs(""rf103_interprfuncs.png""); [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(genpdf_over_genpdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_genpdf_over_genpdf_Int[x]_genpdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(genpdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(g2_over_g2_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_g2_over_g2_Int[x]_g1Data) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; ; RooFitResult: minimized FCN value: 2551.39, estimated distance to minimum: 4.39288e-06; covariance matrix quality: Full, accurate covariance matrix; Status : MINIMIZE=0 HESSE=0 ; ; Floating Parameter FinalValue +/- Error ; -------------------",MatchSource.WIKI,doc/master/rf103__interprfuncs_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf103__interprfuncs_8py.html
https://root.cern/doc/master/rf104__classfactory_8C.html:8343,Availability,error,error,8343,"itThe namespace RooFit contains mostly switches that change the behaviour of functions of PDFs (or othe...Definition JSONIO.h:26; xmlio::Titleconst char * TitleDefinition TXMLSetup.cxx:68; ; (MyPdfV3) An instance of MyPdfV3.; [#1] INFO:Fitting -- RooAbsPdf::fitTo(pdf_over_pdf_Int[y]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_pdf_over_pdf_Int[y]_pdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(GenPdf_over_GenPdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_GenPdf_over_GenPdf_Int[x]_GenPdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); DateJuly 2008 ; AuthorWouter Verkerke ; Definition in file rf104_classfactory.C. tutorialsroofitrf104_classfactory.C. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:30 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/rf104__classfactory_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf104__classfactory_8C.html
https://root.cern/doc/master/rf104__classfactory_8C.html:9090,Availability,error,error,9090,"itThe namespace RooFit contains mostly switches that change the behaviour of functions of PDFs (or othe...Definition JSONIO.h:26; xmlio::Titleconst char * TitleDefinition TXMLSetup.cxx:68; ; (MyPdfV3) An instance of MyPdfV3.; [#1] INFO:Fitting -- RooAbsPdf::fitTo(pdf_over_pdf_Int[y]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_pdf_over_pdf_Int[y]_pdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(GenPdf_over_GenPdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_GenPdf_over_GenPdf_Int[x]_GenPdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); DateJuly 2008 ; AuthorWouter Verkerke ; Definition in file rf104_classfactory.C. tutorialsroofitrf104_classfactory.C. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:30 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/rf104__classfactory_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf104__classfactory_8C.html
https://root.cern/doc/master/rf104__classfactory_8C.html:8631,Deployability,integrat,integrator,8631,"itThe namespace RooFit contains mostly switches that change the behaviour of functions of PDFs (or othe...Definition JSONIO.h:26; xmlio::Titleconst char * TitleDefinition TXMLSetup.cxx:68; ; (MyPdfV3) An instance of MyPdfV3.; [#1] INFO:Fitting -- RooAbsPdf::fitTo(pdf_over_pdf_Int[y]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_pdf_over_pdf_Int[y]_pdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(GenPdf_over_GenPdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_GenPdf_over_GenPdf_Int[x]_GenPdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); DateJuly 2008 ; AuthorWouter Verkerke ; Definition in file rf104_classfactory.C. tutorialsroofitrf104_classfactory.C. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:30 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/rf104__classfactory_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf104__classfactory_8C.html
https://root.cern/doc/master/rf104__classfactory_8C.html:8762,Deployability,integrat,integrator,8762,"itThe namespace RooFit contains mostly switches that change the behaviour of functions of PDFs (or othe...Definition JSONIO.h:26; xmlio::Titleconst char * TitleDefinition TXMLSetup.cxx:68; ; (MyPdfV3) An instance of MyPdfV3.; [#1] INFO:Fitting -- RooAbsPdf::fitTo(pdf_over_pdf_Int[y]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_pdf_over_pdf_Int[y]_pdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(GenPdf_over_GenPdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_GenPdf_over_GenPdf_Int[x]_GenPdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); DateJuly 2008 ; AuthorWouter Verkerke ; Definition in file rf104_classfactory.C. tutorialsroofitrf104_classfactory.C. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:30 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/rf104__classfactory_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf104__classfactory_8C.html
https://root.cern/doc/master/rf104__classfactory_8C.html:9281,Deployability,integrat,integrator,9281,"itThe namespace RooFit contains mostly switches that change the behaviour of functions of PDFs (or othe...Definition JSONIO.h:26; xmlio::Titleconst char * TitleDefinition TXMLSetup.cxx:68; ; (MyPdfV3) An instance of MyPdfV3.; [#1] INFO:Fitting -- RooAbsPdf::fitTo(pdf_over_pdf_Int[y]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_pdf_over_pdf_Int[y]_pdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(GenPdf_over_GenPdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_GenPdf_over_GenPdf_Int[x]_GenPdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); DateJuly 2008 ; AuthorWouter Verkerke ; Definition in file rf104_classfactory.C. tutorialsroofitrf104_classfactory.C. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:30 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/rf104__classfactory_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf104__classfactory_8C.html
https://root.cern/doc/master/rf104__classfactory_8C.html:9509,Deployability,integrat,integrator,9509,"itThe namespace RooFit contains mostly switches that change the behaviour of functions of PDFs (or othe...Definition JSONIO.h:26; xmlio::Titleconst char * TitleDefinition TXMLSetup.cxx:68; ; (MyPdfV3) An instance of MyPdfV3.; [#1] INFO:Fitting -- RooAbsPdf::fitTo(pdf_over_pdf_Int[y]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_pdf_over_pdf_Int[y]_pdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(GenPdf_over_GenPdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_GenPdf_over_GenPdf_Int[x]_GenPdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); DateJuly 2008 ; AuthorWouter Verkerke ; Definition in file rf104_classfactory.C. tutorialsroofitrf104_classfactory.C. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:30 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/rf104__classfactory_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf104__classfactory_8C.html
https://root.cern/doc/master/rf104__classfactory_8C.html:4959,Integrability,interface,interface,4959,"sion of pdf of rf103""));; data2->plotOn(frame2);; genpdf->plotOn(frame2);; ; // Draw all frames on a canvas; TCanvas *c = new TCanvas(""rf104_classfactory"", ""rf104_classfactory"", 800, 400);; c->Divide(2);; c->cd(1);; gPad->SetLeftMargin(0.15);; frame1->GetYaxis()->SetTitleOffset(1.4);; frame1->Draw();; c->cd(2);; gPad->SetLeftMargin(0.15);; frame2->GetYaxis()->SetTitleOffset(1.4);; frame2->Draw();; }; b#define b(i)Definition RSha256.hxx:100; c#define c(i)Definition RSha256.hxx:101; a#define a(i)Definition RSha256.hxx:99; RooClassFactory.h; RooDataSet.h; RooGaussian.h; RooPlot.h; RooRealVar.h; TAxis.h; TCanvas.h; wwinID wDefinition TGWin32VirtualGLProxy.cxx:39; dataOption_t Option_t TPoint TPoint const char GetTextMagnitude GetFillStyle GetLineColor GetLineWidth GetMarkerStyle GetTextAlign GetTextColor GetTextSize void dataDefinition TGWin32VirtualXProxy.cxx:104; TROOT.h; gROOT#define gROOTDefinition TROOT.h:406; gPad#define gPadDefinition TVirtualPad.h:308; RooAbsPdfAbstract interface for all probability density functions.Definition RooAbsPdf.h:40; RooAbsPdf::plotOnRooPlot * plotOn(RooPlot *frame, const RooCmdArg &arg1={}, const RooCmdArg &arg2={}, const RooCmdArg &arg3={}, const RooCmdArg &arg4={}, const RooCmdArg &arg5={}, const RooCmdArg &arg6={}, const RooCmdArg &arg7={}, const RooCmdArg &arg8={}, const RooCmdArg &arg9={}, const RooCmdArg &arg10={}) const overrideHelper calling plotOn(RooPlot*, RooLinkedList&) const.Definition RooAbsPdf.h:124; RooAbsPdf::fitToRooFit::OwningPtr< RooFitResult > fitTo(RooAbsData &data, CmdArgs_t const &... cmdArgs)Fit PDF to given dataset.Definition RooAbsPdf.h:157; RooAbsPdf::generateRooFit::OwningPtr< RooDataSet > generate(const RooArgSet &whatVars, Int_t nEvents, const RooCmdArg &arg1, const RooCmdArg &arg2={}, const RooCmdArg &arg3={}, const RooCmdArg &arg4={}, const RooCmdArg &arg5={})See RooAbsPdf::generate(const RooArgSet&,const RooCmdArg&,const RooCmdArg&,const RooCmdArg&,...Definition RooAbsPdf.h:57; RooArgSetRooArgSet is a ",MatchSource.WIKI,doc/master/rf104__classfactory_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf104__classfactory_8C.html
https://root.cern/doc/master/rf104__classfactory_8C.html:8631,Integrability,integrat,integrator,8631,"itThe namespace RooFit contains mostly switches that change the behaviour of functions of PDFs (or othe...Definition JSONIO.h:26; xmlio::Titleconst char * TitleDefinition TXMLSetup.cxx:68; ; (MyPdfV3) An instance of MyPdfV3.; [#1] INFO:Fitting -- RooAbsPdf::fitTo(pdf_over_pdf_Int[y]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_pdf_over_pdf_Int[y]_pdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(GenPdf_over_GenPdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_GenPdf_over_GenPdf_Int[x]_GenPdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); DateJuly 2008 ; AuthorWouter Verkerke ; Definition in file rf104_classfactory.C. tutorialsroofitrf104_classfactory.C. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:30 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/rf104__classfactory_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf104__classfactory_8C.html
https://root.cern/doc/master/rf104__classfactory_8C.html:8762,Integrability,integrat,integrator,8762,"itThe namespace RooFit contains mostly switches that change the behaviour of functions of PDFs (or othe...Definition JSONIO.h:26; xmlio::Titleconst char * TitleDefinition TXMLSetup.cxx:68; ; (MyPdfV3) An instance of MyPdfV3.; [#1] INFO:Fitting -- RooAbsPdf::fitTo(pdf_over_pdf_Int[y]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_pdf_over_pdf_Int[y]_pdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(GenPdf_over_GenPdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_GenPdf_over_GenPdf_Int[x]_GenPdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); DateJuly 2008 ; AuthorWouter Verkerke ; Definition in file rf104_classfactory.C. tutorialsroofitrf104_classfactory.C. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:30 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/rf104__classfactory_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf104__classfactory_8C.html
https://root.cern/doc/master/rf104__classfactory_8C.html:9281,Integrability,integrat,integrator,9281,"itThe namespace RooFit contains mostly switches that change the behaviour of functions of PDFs (or othe...Definition JSONIO.h:26; xmlio::Titleconst char * TitleDefinition TXMLSetup.cxx:68; ; (MyPdfV3) An instance of MyPdfV3.; [#1] INFO:Fitting -- RooAbsPdf::fitTo(pdf_over_pdf_Int[y]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_pdf_over_pdf_Int[y]_pdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(GenPdf_over_GenPdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_GenPdf_over_GenPdf_Int[x]_GenPdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); DateJuly 2008 ; AuthorWouter Verkerke ; Definition in file rf104_classfactory.C. tutorialsroofitrf104_classfactory.C. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:30 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/rf104__classfactory_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf104__classfactory_8C.html
https://root.cern/doc/master/rf104__classfactory_8C.html:9509,Integrability,integrat,integrator,9509,"itThe namespace RooFit contains mostly switches that change the behaviour of functions of PDFs (or othe...Definition JSONIO.h:26; xmlio::Titleconst char * TitleDefinition TXMLSetup.cxx:68; ; (MyPdfV3) An instance of MyPdfV3.; [#1] INFO:Fitting -- RooAbsPdf::fitTo(pdf_over_pdf_Int[y]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_pdf_over_pdf_Int[y]_pdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(GenPdf_over_GenPdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_GenPdf_over_GenPdf_Int[x]_GenPdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); DateJuly 2008 ; AuthorWouter Verkerke ; Definition in file rf104_classfactory.C. tutorialsroofitrf104_classfactory.C. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:30 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/rf104__classfactory_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf104__classfactory_8C.html
https://root.cern/doc/master/rf104__classfactory_8C.html:1065,Modifiability,variab,variable,1065,". ROOT: tutorials/roofit/rf104_classfactory.C File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. rf104_classfactory.C File ReferenceTutorials  RooFit Tutorials. Detailed Description; Basic functionality: The class factory for functions and pdfs ; NOTE: This demo uses code that is generated by the macro, therefore it cannot be compiled in one step by ACliC. To run this macro compiled with ACliC do; root>.x rf104_classfactory.C // run interpreted to generate code; root>.L MyPdfV3.cxx+ // Compile and load created class; root>.x rf104_classfactory.C+ // run compiled code; rf104_classfactoryDefinition rf104_classfactory.py:1. ; #include ""RooRealVar.h""; #include ""RooDataSet.h""; #include ""RooGaussian.h""; #include ""TCanvas.h""; #include ""TAxis.h""; #include ""RooPlot.h""; #include ""RooClassFactory.h""; #include ""TROOT.h""; ; using namespace RooFit;; ; void rf104_classfactory(); {; // W r i t e c l a s s s k e l e t o n c o d e; // --------------------------------------------------; ; // Write skeleton pdf class with variable x,a,b; // To use this class,; // - Edit the file MyPdfV1.cxx and implement the evaluate() method in terms of x,a and b; // - Compile and link class with '.x MyPdfV1.cxx+'; //; RooClassFactory::makePdf(""MyPdfV1"", ""x,A,B"");; ; // W i t h a d d e d i n i t i a l v a l u e e x p r e s s i o n; // ---------------------------------------------------------------------; ; // Write skeleton pdf class with variable x,a,b and given formula expression; // To use this class,; // - Compile and link class with '.x MyPdfV2.cxx+'; //; RooClassFactory::makePdf(""MyPdfV2"", ""x,A,B"", """", ""A*fabs(x)+pow(x-B,2)"");; ; // W i t h a d d e d a n a l y t i c a l i n t e g r a l e x p r e s s i o n; // ---------------------------------------------------------------------------------; ; // Write skeleton pdf class with variable x,a,b, given formula expression _and_; // given expression for analytical integral over x; // To use this class,; // -",MatchSource.WIKI,doc/master/rf104__classfactory_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf104__classfactory_8C.html
https://root.cern/doc/master/rf104__classfactory_8C.html:1474,Modifiability,variab,variable,1474," run this macro compiled with ACliC do; root>.x rf104_classfactory.C // run interpreted to generate code; root>.L MyPdfV3.cxx+ // Compile and load created class; root>.x rf104_classfactory.C+ // run compiled code; rf104_classfactoryDefinition rf104_classfactory.py:1. ; #include ""RooRealVar.h""; #include ""RooDataSet.h""; #include ""RooGaussian.h""; #include ""TCanvas.h""; #include ""TAxis.h""; #include ""RooPlot.h""; #include ""RooClassFactory.h""; #include ""TROOT.h""; ; using namespace RooFit;; ; void rf104_classfactory(); {; // W r i t e c l a s s s k e l e t o n c o d e; // --------------------------------------------------; ; // Write skeleton pdf class with variable x,a,b; // To use this class,; // - Edit the file MyPdfV1.cxx and implement the evaluate() method in terms of x,a and b; // - Compile and link class with '.x MyPdfV1.cxx+'; //; RooClassFactory::makePdf(""MyPdfV1"", ""x,A,B"");; ; // W i t h a d d e d i n i t i a l v a l u e e x p r e s s i o n; // ---------------------------------------------------------------------; ; // Write skeleton pdf class with variable x,a,b and given formula expression; // To use this class,; // - Compile and link class with '.x MyPdfV2.cxx+'; //; RooClassFactory::makePdf(""MyPdfV2"", ""x,A,B"", """", ""A*fabs(x)+pow(x-B,2)"");; ; // W i t h a d d e d a n a l y t i c a l i n t e g r a l e x p r e s s i o n; // ---------------------------------------------------------------------------------; ; // Write skeleton pdf class with variable x,a,b, given formula expression _and_; // given expression for analytical integral over x; // To use this class,; // - Compile and link class with '.x MyPdfV3.cxx+'; //; RooClassFactory::makePdf(""MyPdfV3"", ""x,A,B"", """", ""A*fabs(x)+pow(x-B,2)"", true, false,; ""x:(A/2)*(pow(x.max(rangeName),2)+pow(x.min(rangeName),2))+(1./""; ""3)*(pow(x.max(rangeName)-B,3)-pow(x.min(rangeName)-B,3))"");; ; // U s e i n s t a n c e o f c r e a t e d c l a s s; // ---------------------------------------------------------; ; // Compile MyPdfV3 c",MatchSource.WIKI,doc/master/rf104__classfactory_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf104__classfactory_8C.html
https://root.cern/doc/master/rf104__classfactory_8C.html:1874,Modifiability,variab,variable,1874,"Plot.h""; #include ""RooClassFactory.h""; #include ""TROOT.h""; ; using namespace RooFit;; ; void rf104_classfactory(); {; // W r i t e c l a s s s k e l e t o n c o d e; // --------------------------------------------------; ; // Write skeleton pdf class with variable x,a,b; // To use this class,; // - Edit the file MyPdfV1.cxx and implement the evaluate() method in terms of x,a and b; // - Compile and link class with '.x MyPdfV1.cxx+'; //; RooClassFactory::makePdf(""MyPdfV1"", ""x,A,B"");; ; // W i t h a d d e d i n i t i a l v a l u e e x p r e s s i o n; // ---------------------------------------------------------------------; ; // Write skeleton pdf class with variable x,a,b and given formula expression; // To use this class,; // - Compile and link class with '.x MyPdfV2.cxx+'; //; RooClassFactory::makePdf(""MyPdfV2"", ""x,A,B"", """", ""A*fabs(x)+pow(x-B,2)"");; ; // W i t h a d d e d a n a l y t i c a l i n t e g r a l e x p r e s s i o n; // ---------------------------------------------------------------------------------; ; // Write skeleton pdf class with variable x,a,b, given formula expression _and_; // given expression for analytical integral over x; // To use this class,; // - Compile and link class with '.x MyPdfV3.cxx+'; //; RooClassFactory::makePdf(""MyPdfV3"", ""x,A,B"", """", ""A*fabs(x)+pow(x-B,2)"", true, false,; ""x:(A/2)*(pow(x.max(rangeName),2)+pow(x.min(rangeName),2))+(1./""; ""3)*(pow(x.max(rangeName)-B,3)-pow(x.min(rangeName)-B,3))"");; ; // U s e i n s t a n c e o f c r e a t e d c l a s s; // ---------------------------------------------------------; ; // Compile MyPdfV3 class; gROOT->ProcessLineSync("".x MyPdfV3.cxx+"");; ; // Create instance of MyPdfV3 class; RooRealVar a(""a"", ""a"", 1);; RooRealVar b(""b"", ""b"", 2, -10, 10);; RooRealVar y(""y"", ""y"", -10, 10);; ; // We need to hide the type to run in a ROOT macro; RooWorkspace w(""w"");; w.factory(""MyPdfV3::pdf(y[-10,10], a[1], b[2,-10,10])"");; auto pdf = w.pdf(""pdf"");; ; // Generate toy data from pdf and plot data and pdf ",MatchSource.WIKI,doc/master/rf104__classfactory_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf104__classfactory_8C.html
https://root.cern/doc/master/rf104__classfactory_8C.html:7000,Modifiability,variab,variable,7000,"sPdf.h:57; RooArgSetRooArgSet is a container object that can hold multiple RooAbsArg objects.Definition RooArgSet.h:24; RooClassFactory::makePdfstatic bool makePdf(std::string const &name, std::string const &realArgNames="""", std::string const &catArgNames="""", std::string const &expression=""1.0"", bool hasAnaInt=false, bool hasIntGen=false, std::string const &intExpression="""")Write code for a RooAbsPdf implementation with class name 'name'.Definition RooClassFactory.cxx:335; RooClassFactory::makePdfInstancestatic RooAbsPdf * makePdfInstance(std::string const &className, std::string const &name, std::string const &expression, const RooArgList &vars, std::string const &intExpression="""")Write, compile and load code and instantiate object for a RooAbsPdf implementation with class name 'n...Definition RooClassFactory.cxx:320; RooPlotPlot frame and a container for graphics objects within that frame.Definition RooPlot.h:45; RooPlot::framestatic RooPlot * frame(const RooAbsRealLValue &var, double xmin, double xmax, Int_t nBins)Create a new frame for a given variable in x.Definition RooPlot.cxx:225; RooPlot::GetYaxisTAxis * GetYaxis() constDefinition RooPlot.cxx:1264; RooPlot::Drawvoid Draw(Option_t *options=nullptr) overrideDraw this plot and all of the elements it contains.Definition RooPlot.cxx:637; RooRealVarVariable that can be changed from the outside.Definition RooRealVar.h:37; RooWorkspacePersistable container for RooFit projects.Definition RooWorkspace.h:43; TAttAxis::SetTitleOffsetvirtual void SetTitleOffset(Float_t offset=1)Set distance between the axis and the axis title.Definition TAttAxis.cxx:298; TCanvasThe Canvas class.Definition TCanvas.h:23; RooFit::PrintLevelRooCmdArg PrintLevel(Int_t code)Definition RooGlobalFunc.cxx:657; yDouble_t y[n]Definition legend1.C:17; xDouble_t x[n]Definition legend1.C:17; RooFitThe namespace RooFit contains mostly switches that change the behaviour of functions of PDFs (or othe...Definition JSONIO.h:26; xmlio::Titleconst char * Tit",MatchSource.WIKI,doc/master/rf104__classfactory_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf104__classfactory_8C.html
https://root.cern/doc/master/rf104__classfactory_8C.html:550,Performance,load,load,550,". ROOT: tutorials/roofit/rf104_classfactory.C File Reference. ; ROOT ; . master. Reference Guide ; . . Loading...; Searching...; No Matches. rf104_classfactory.C File ReferenceTutorials  RooFit Tutorials. Detailed Description; Basic functionality: The class factory for functions and pdfs ; NOTE: This demo uses code that is generated by the macro, therefore it cannot be compiled in one step by ACliC. To run this macro compiled with ACliC do; root>.x rf104_classfactory.C // run interpreted to generate code; root>.L MyPdfV3.cxx+ // Compile and load created class; root>.x rf104_classfactory.C+ // run compiled code; rf104_classfactoryDefinition rf104_classfactory.py:1. ; #include ""RooRealVar.h""; #include ""RooDataSet.h""; #include ""RooGaussian.h""; #include ""TCanvas.h""; #include ""TAxis.h""; #include ""RooPlot.h""; #include ""RooClassFactory.h""; #include ""TROOT.h""; ; using namespace RooFit;; ; void rf104_classfactory(); {; // W r i t e c l a s s s k e l e t o n c o d e; // --------------------------------------------------; ; // Write skeleton pdf class with variable x,a,b; // To use this class,; // - Edit the file MyPdfV1.cxx and implement the evaluate() method in terms of x,a and b; // - Compile and link class with '.x MyPdfV1.cxx+'; //; RooClassFactory::makePdf(""MyPdfV1"", ""x,A,B"");; ; // W i t h a d d e d i n i t i a l v a l u e e x p r e s s i o n; // ---------------------------------------------------------------------; ; // Write skeleton pdf class with variable x,a,b and given formula expression; // To use this class,; // - Compile and link class with '.x MyPdfV2.cxx+'; //; RooClassFactory::makePdf(""MyPdfV2"", ""x,A,B"", """", ""A*fabs(x)+pow(x-B,2)"");; ; // W i t h a d d e d a n a l y t i c a l i n t e g r a l e x p r e s s i o n; // ---------------------------------------------------------------------------------; ; // Write skeleton pdf class with variable x,a,b, given formula expression _and_; // given expression for analytical integral over x; // To use this class,; // -",MatchSource.WIKI,doc/master/rf104__classfactory_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf104__classfactory_8C.html
https://root.cern/doc/master/rf104__classfactory_8C.html:3339,Performance,perform,performs,3339,"min(rangeName),2))+(1./""; ""3)*(pow(x.max(rangeName)-B,3)-pow(x.min(rangeName)-B,3))"");; ; // U s e i n s t a n c e o f c r e a t e d c l a s s; // ---------------------------------------------------------; ; // Compile MyPdfV3 class; gROOT->ProcessLineSync("".x MyPdfV3.cxx+"");; ; // Create instance of MyPdfV3 class; RooRealVar a(""a"", ""a"", 1);; RooRealVar b(""b"", ""b"", 2, -10, 10);; RooRealVar y(""y"", ""y"", -10, 10);; ; // We need to hide the type to run in a ROOT macro; RooWorkspace w(""w"");; w.factory(""MyPdfV3::pdf(y[-10,10], a[1], b[2,-10,10])"");; auto pdf = w.pdf(""pdf"");; ; // Generate toy data from pdf and plot data and pdf on frame; RooPlot *frame1 = y.frame(Title(""Compiled class MyPdfV3""));; std::unique_ptr<RooDataSet> data{pdf->generate(y, 1000)};; pdf->fitTo(*data, PrintLevel(-1));; data->plotOn(frame1);; pdf->plotOn(frame1);; ; // -----------------------------------------------------------------; // C o m p i l e d v e r s i o n o f e x a m p l e r f 1 0 3; // =================================================================; ; // Declare observable x; RooRealVar x(""x"", ""x"", -20, 20);; ; // The RooClassFactory::makePdfInstance() function performs code writing, compiling, linking; // and object instantiation in one go and can serve as a straight replacement of RooGenericPdf; ; RooRealVar alpha(""alpha"", ""alpha"", 5, 0.1, 10);; RooAbsPdf *genpdf =; RooClassFactory::makePdfInstance(""GenPdf"", ""(1+0.1*fabs(x)+sin(sqrt(fabs(x*alpha+0.1))))"", RooArgSet(x, alpha));; ; // Generate a toy dataset from the interpreted pdf; std::unique_ptr<RooDataSet> data2{genpdf->generate(x, 50000)};; ; // Fit the interpreted pdf to the generated data; genpdf->fitTo(*data2, PrintLevel(-1));; ; // Make a plot of the data and the pdf overlaid; RooPlot *frame2 = x.frame(Title(""Compiled version of pdf of rf103""));; data2->plotOn(frame2);; genpdf->plotOn(frame2);; ; // Draw all frames on a canvas; TCanvas *c = new TCanvas(""rf104_classfactory"", ""rf104_classfactory"", 800, 400);; c->Divide(2);; c->cd",MatchSource.WIKI,doc/master/rf104__classfactory_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf104__classfactory_8C.html
https://root.cern/doc/master/rf104__classfactory_8C.html:6646,Performance,load,load,6646,"t.Definition RooAbsPdf.h:157; RooAbsPdf::generateRooFit::OwningPtr< RooDataSet > generate(const RooArgSet &whatVars, Int_t nEvents, const RooCmdArg &arg1, const RooCmdArg &arg2={}, const RooCmdArg &arg3={}, const RooCmdArg &arg4={}, const RooCmdArg &arg5={})See RooAbsPdf::generate(const RooArgSet&,const RooCmdArg&,const RooCmdArg&,const RooCmdArg&,...Definition RooAbsPdf.h:57; RooArgSetRooArgSet is a container object that can hold multiple RooAbsArg objects.Definition RooArgSet.h:24; RooClassFactory::makePdfstatic bool makePdf(std::string const &name, std::string const &realArgNames="""", std::string const &catArgNames="""", std::string const &expression=""1.0"", bool hasAnaInt=false, bool hasIntGen=false, std::string const &intExpression="""")Write code for a RooAbsPdf implementation with class name 'name'.Definition RooClassFactory.cxx:335; RooClassFactory::makePdfInstancestatic RooAbsPdf * makePdfInstance(std::string const &className, std::string const &name, std::string const &expression, const RooArgList &vars, std::string const &intExpression="""")Write, compile and load code and instantiate object for a RooAbsPdf implementation with class name 'n...Definition RooClassFactory.cxx:320; RooPlotPlot frame and a container for graphics objects within that frame.Definition RooPlot.h:45; RooPlot::framestatic RooPlot * frame(const RooAbsRealLValue &var, double xmin, double xmax, Int_t nBins)Create a new frame for a given variable in x.Definition RooPlot.cxx:225; RooPlot::GetYaxisTAxis * GetYaxis() constDefinition RooPlot.cxx:1264; RooPlot::Drawvoid Draw(Option_t *options=nullptr) overrideDraw this plot and all of the elements it contains.Definition RooPlot.cxx:637; RooRealVarVariable that can be changed from the outside.Definition RooRealVar.h:37; RooWorkspacePersistable container for RooFit projects.Definition RooWorkspace.h:43; TAttAxis::SetTitleOffsetvirtual void SetTitleOffset(Float_t offset=1)Set distance between the axis and the axis title.Definition TAttAxis.cxx:298; TCa",MatchSource.WIKI,doc/master/rf104__classfactory_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf104__classfactory_8C.html
https://root.cern/doc/master/rf104__classfactory_8C.html:8437,Performance,optimiz,optimization,8437,"itThe namespace RooFit contains mostly switches that change the behaviour of functions of PDFs (or othe...Definition JSONIO.h:26; xmlio::Titleconst char * TitleDefinition TXMLSetup.cxx:68; ; (MyPdfV3) An instance of MyPdfV3.; [#1] INFO:Fitting -- RooAbsPdf::fitTo(pdf_over_pdf_Int[y]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_pdf_over_pdf_Int[y]_pdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(GenPdf_over_GenPdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_GenPdf_over_GenPdf_Int[x]_GenPdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); DateJuly 2008 ; AuthorWouter Verkerke ; Definition in file rf104_classfactory.C. tutorialsroofitrf104_classfactory.C. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:30 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/rf104__classfactory_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf104__classfactory_8C.html
https://root.cern/doc/master/rf104__classfactory_8C.html:8534,Performance,optimiz,optimization,8534,"itThe namespace RooFit contains mostly switches that change the behaviour of functions of PDFs (or othe...Definition JSONIO.h:26; xmlio::Titleconst char * TitleDefinition TXMLSetup.cxx:68; ; (MyPdfV3) An instance of MyPdfV3.; [#1] INFO:Fitting -- RooAbsPdf::fitTo(pdf_over_pdf_Int[y]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_pdf_over_pdf_Int[y]_pdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(GenPdf_over_GenPdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_GenPdf_over_GenPdf_Int[x]_GenPdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); DateJuly 2008 ; AuthorWouter Verkerke ; Definition in file rf104_classfactory.C. tutorialsroofitrf104_classfactory.C. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:30 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/rf104__classfactory_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf104__classfactory_8C.html
https://root.cern/doc/master/rf104__classfactory_8C.html:9184,Performance,optimiz,optimization,9184,"itThe namespace RooFit contains mostly switches that change the behaviour of functions of PDFs (or othe...Definition JSONIO.h:26; xmlio::Titleconst char * TitleDefinition TXMLSetup.cxx:68; ; (MyPdfV3) An instance of MyPdfV3.; [#1] INFO:Fitting -- RooAbsPdf::fitTo(pdf_over_pdf_Int[y]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_pdf_over_pdf_Int[y]_pdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(GenPdf_over_GenPdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_GenPdf_over_GenPdf_Int[x]_GenPdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); DateJuly 2008 ; AuthorWouter Verkerke ; Definition in file rf104_classfactory.C. tutorialsroofitrf104_classfactory.C. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:30 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/rf104__classfactory_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf104__classfactory_8C.html
https://root.cern/doc/master/rf104__classfactory_8C.html:9412,Performance,optimiz,optimization,9412,"itThe namespace RooFit contains mostly switches that change the behaviour of functions of PDFs (or othe...Definition JSONIO.h:26; xmlio::Titleconst char * TitleDefinition TXMLSetup.cxx:68; ; (MyPdfV3) An instance of MyPdfV3.; [#1] INFO:Fitting -- RooAbsPdf::fitTo(pdf_over_pdf_Int[y]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_pdf_over_pdf_Int[y]_pdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(GenPdf_over_GenPdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_GenPdf_over_GenPdf_Int[x]_GenPdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); DateJuly 2008 ; AuthorWouter Verkerke ; Definition in file rf104_classfactory.C. tutorialsroofitrf104_classfactory.C. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:30 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/rf104__classfactory_8C.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf104__classfactory_8C.html
https://root.cern/doc/master/rf104__classfactory_8py.html:3911,Availability,error,error,3911,"t(1.4); frame1.Draw(); c.cd(2); ROOT.gPad.SetLeftMargin(0.15); frame2.GetYaxis().SetTitleOffset(1.4); frame2.Draw(); ; c.SaveAs(""rf104_classfactory.png""); (MyPdfV3) An instance of MyPdfV3.; [#1] INFO:Fitting -- RooAbsPdf::fitTo(pdf_over_pdf_Int[y]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_pdf_over_pdf_Int[y]_pdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(GenPdf_over_GenPdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_GenPdf_over_GenPdf_Int[x]_GenPdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); DateFebruary 2018 ; AuthorsClemens Lange, Wouter Verkerke (C++ version) ; Definition in file rf104_classfactory.py. tutorialsroofitrf104_classfactory.py. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:30 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/rf104__classfactory_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf104__classfactory_8py.html
https://root.cern/doc/master/rf104__classfactory_8py.html:4658,Availability,error,error,4658,"t(1.4); frame1.Draw(); c.cd(2); ROOT.gPad.SetLeftMargin(0.15); frame2.GetYaxis().SetTitleOffset(1.4); frame2.Draw(); ; c.SaveAs(""rf104_classfactory.png""); (MyPdfV3) An instance of MyPdfV3.; [#1] INFO:Fitting -- RooAbsPdf::fitTo(pdf_over_pdf_Int[y]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_pdf_over_pdf_Int[y]_pdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(GenPdf_over_GenPdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_GenPdf_over_GenPdf_Int[x]_GenPdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); DateFebruary 2018 ; AuthorsClemens Lange, Wouter Verkerke (C++ version) ; Definition in file rf104_classfactory.py. tutorialsroofitrf104_classfactory.py. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:30 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/rf104__classfactory_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf104__classfactory_8py.html
https://root.cern/doc/master/rf104__classfactory_8py.html:4199,Deployability,integrat,integrator,4199,"t(1.4); frame1.Draw(); c.cd(2); ROOT.gPad.SetLeftMargin(0.15); frame2.GetYaxis().SetTitleOffset(1.4); frame2.Draw(); ; c.SaveAs(""rf104_classfactory.png""); (MyPdfV3) An instance of MyPdfV3.; [#1] INFO:Fitting -- RooAbsPdf::fitTo(pdf_over_pdf_Int[y]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_pdf_over_pdf_Int[y]_pdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(GenPdf_over_GenPdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_GenPdf_over_GenPdf_Int[x]_GenPdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); DateFebruary 2018 ; AuthorsClemens Lange, Wouter Verkerke (C++ version) ; Definition in file rf104_classfactory.py. tutorialsroofitrf104_classfactory.py. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:30 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/rf104__classfactory_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf104__classfactory_8py.html
https://root.cern/doc/master/rf104__classfactory_8py.html:4330,Deployability,integrat,integrator,4330,"t(1.4); frame1.Draw(); c.cd(2); ROOT.gPad.SetLeftMargin(0.15); frame2.GetYaxis().SetTitleOffset(1.4); frame2.Draw(); ; c.SaveAs(""rf104_classfactory.png""); (MyPdfV3) An instance of MyPdfV3.; [#1] INFO:Fitting -- RooAbsPdf::fitTo(pdf_over_pdf_Int[y]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_pdf_over_pdf_Int[y]_pdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(GenPdf_over_GenPdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_GenPdf_over_GenPdf_Int[x]_GenPdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); DateFebruary 2018 ; AuthorsClemens Lange, Wouter Verkerke (C++ version) ; Definition in file rf104_classfactory.py. tutorialsroofitrf104_classfactory.py. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:30 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/rf104__classfactory_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf104__classfactory_8py.html
https://root.cern/doc/master/rf104__classfactory_8py.html:4849,Deployability,integrat,integrator,4849,"t(1.4); frame1.Draw(); c.cd(2); ROOT.gPad.SetLeftMargin(0.15); frame2.GetYaxis().SetTitleOffset(1.4); frame2.Draw(); ; c.SaveAs(""rf104_classfactory.png""); (MyPdfV3) An instance of MyPdfV3.; [#1] INFO:Fitting -- RooAbsPdf::fitTo(pdf_over_pdf_Int[y]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_pdf_over_pdf_Int[y]_pdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(GenPdf_over_GenPdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_GenPdf_over_GenPdf_Int[x]_GenPdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); DateFebruary 2018 ; AuthorsClemens Lange, Wouter Verkerke (C++ version) ; Definition in file rf104_classfactory.py. tutorialsroofitrf104_classfactory.py. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:30 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/rf104__classfactory_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf104__classfactory_8py.html
https://root.cern/doc/master/rf104__classfactory_8py.html:5077,Deployability,integrat,integrator,5077,"t(1.4); frame1.Draw(); c.cd(2); ROOT.gPad.SetLeftMargin(0.15); frame2.GetYaxis().SetTitleOffset(1.4); frame2.Draw(); ; c.SaveAs(""rf104_classfactory.png""); (MyPdfV3) An instance of MyPdfV3.; [#1] INFO:Fitting -- RooAbsPdf::fitTo(pdf_over_pdf_Int[y]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_pdf_over_pdf_Int[y]_pdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(GenPdf_over_GenPdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_GenPdf_over_GenPdf_Int[x]_GenPdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); DateFebruary 2018 ; AuthorsClemens Lange, Wouter Verkerke (C++ version) ; Definition in file rf104_classfactory.py. tutorialsroofitrf104_classfactory.py. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:30 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/rf104__classfactory_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf104__classfactory_8py.html
https://root.cern/doc/master/rf104__classfactory_8py.html:4199,Integrability,integrat,integrator,4199,"t(1.4); frame1.Draw(); c.cd(2); ROOT.gPad.SetLeftMargin(0.15); frame2.GetYaxis().SetTitleOffset(1.4); frame2.Draw(); ; c.SaveAs(""rf104_classfactory.png""); (MyPdfV3) An instance of MyPdfV3.; [#1] INFO:Fitting -- RooAbsPdf::fitTo(pdf_over_pdf_Int[y]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- using CPU computation library compiled with -mavx2; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_pdf_over_pdf_Int[y]_pdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Fitting -- RooAbsPdf::fitTo(GenPdf_over_GenPdf_Int[x]) fixing normalization set for coefficient determination to observables in data; [#1] INFO:Fitting -- RooAddition::defaultErrorLevel(nll_GenPdf_over_GenPdf_Int[x]_GenPdfData) Summation contains a RooNLLVar, using its error level; [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: activating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); [#1] INFO:Minimization -- RooAbsMinimizerFcn::setOptimizeConst: deactivating const optimization; [#1] INFO:NumericIntegration -- RooRealIntegral::init(GenPdf_Int[x]) using numeric integrator RooIntegrator1D to calculate Int(x); DateFebruary 2018 ; AuthorsClemens Lange, Wouter Verkerke (C++ version) ; Definition in file rf104_classfactory.py. tutorialsroofitrf104_classfactory.py. ROOT master - Reference Guide Generated on Tue Nov 5 2024 09:41:30 (GVA Time) using Doxygen 1.9.8 ; . ",MatchSource.WIKI,doc/master/rf104__classfactory_8py.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/doc/master/rf104__classfactory_8py.html
