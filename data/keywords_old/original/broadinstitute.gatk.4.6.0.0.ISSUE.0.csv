id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/broadinstitute/gatk/issues/1:31,Security,access,access,31,We need to understand the data access patterns in the existing engines: Picard/GATK/Foghorn; @lbergelson and @kshakir already started doing it. Can you move the list here?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1
https://github.com/broadinstitute/gatk/issues/3:58,Testability,test,test,58,"no filters, no -L, just count reads and make a regression test for it (with a small bam); Can we 'register' a hellbender tool as a picard tool if we have it in a different package?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3
https://github.com/broadinstitute/gatk/issues/4:124,Integrability,interface,interface,124,"Implement -L system, enable access to it for tools that request it (define how they 'request it' - maybe by implementing an interface or calling a function or overriding some generic hook - part of this issue is to design it).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4
https://github.com/broadinstitute/gatk/issues/4:28,Security,access,access,28,"Implement -L system, enable access to it for tools that request it (define how they 'request it' - maybe by implementing an interface or calling a function or overriding some generic hook - part of this issue is to design it).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4
https://github.com/broadinstitute/gatk/issues/5:61,Availability,avail,available,61,"ReadFilter system needs to be ported from GATK. It should be available to tools by ""request"". The specifics are to be figured out as part of addressing this issue.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5
https://github.com/broadinstitute/gatk/issues/6:35,Availability,avail,available,35,ReadTransformer system needs to be available to hellbender tools. The mechanism of how it gets enabled needs to be coordinated with ReadFilters (issue #5 ),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6
https://github.com/broadinstitute/gatk/issues/9:49,Security,access,accessing,49,We need to look into Java 8 java.util.stream for accessing Read and Variant data,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/9
https://github.com/broadinstitute/gatk/issues/10:143,Availability,avail,available,143,a Bam file is to be traversed in a sliding window fashion - 2 parameters are widow size and skip length. All reads in the window are then made available to the user. HaplotypeCaller will be the main user of this functionality,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/10
https://github.com/broadinstitute/gatk/issues/12:18,Usability,simpl,simple,18,"This should be as simple as PrintReads + VariantFilters , see issue #7",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/12
https://github.com/broadinstitute/gatk/issues/15:54,Testability,test,tests,54,The requirement is to port the GenotypeGVCFs tool and tests. Test data should be made public whenever possible.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/15
https://github.com/broadinstitute/gatk/issues/15:61,Testability,Test,Test,61,The requirement is to port the GenotypeGVCFs tool and tests. Test data should be made public whenever possible.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/15
https://github.com/broadinstitute/gatk/issues/19:267,Availability,down,downstream,267,"DepthOfCoverage ; DiagnoseTargets . From @vdauwera ; It would probably make sense to write one really good tool for coverage analysis to replace these two. DoC is great at providing per-locus coverage counts, and the main output table is straightforward and easy for downstream scripts to consume. The summary results table is also ok. But the functionality for aggregating results over intervals and refseq gene lists is super confusing; intervals and genelists interact in an counterintuitive way, and the refseq format requirements are a little vague. In contrast, DT is great at providing per-interval results that give you a go/no-go for callability (+ a culprit metric e.g. MAPQ0, DP etc. in case of a no-go call), but the output is terrible (a pseudo-VCF, which users dont like) and it does not give any per-site counts. There are related tools that users find somewhat useful like CallableLoci, CompareCallableLoci, QualifyMissingIntervals, FindCoveredIntervals, CoveredByNSamplesSites etc. which have overlapping functionality with the coverage tools, and whose functionalities could perhaps be folded into a pan-coverage tool.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/19
https://github.com/broadinstitute/gatk/issues/20:30,Energy Efficiency,reduce,reduce,30,"we need a simple abstract map/reduce tool that would just loop over data and call map, reduce in a sequence. It'll make it easier to migrate walkers that way.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/20
https://github.com/broadinstitute/gatk/issues/20:87,Energy Efficiency,reduce,reduce,87,"we need a simple abstract map/reduce tool that would just loop over data and call map, reduce in a sequence. It'll make it easier to migrate walkers that way.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/20
https://github.com/broadinstitute/gatk/issues/20:10,Usability,simpl,simple,10,"we need a simple abstract map/reduce tool that would just loop over data and call map, reduce in a sequence. It'll make it easier to migrate walkers that way.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/20
https://github.com/broadinstitute/gatk/issues/38:62,Testability,test,tests,62,"the requirement is to port the VariantFiltration tool and the tests. Tests use Broad-only data but the data seems sharable (please review when porting) and should be made public. Additionally, Picard tool `FilterVCF` should be removed in favor of this tool.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/38
https://github.com/broadinstitute/gatk/issues/38:69,Testability,Test,Tests,69,"the requirement is to port the VariantFiltration tool and the tests. Tests use Broad-only data but the data seems sharable (please review when porting) and should be made public. Additionally, Picard tool `FilterVCF` should be removed in favor of this tool.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/38
https://github.com/broadinstitute/gatk/issues/54:30,Usability,simpl,simplicity,30,entering as an issue here for simplicity,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/54
https://github.com/broadinstitute/gatk/issues/61:146,Usability,simpl,simplified,146,The current GenomeLoc needs a not-so-aptly-named GenomeLocParser to create it (making this more of a factor than a parser). Hopefully this can be simplified in the new engine.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/61
https://github.com/broadinstitute/gatk/issues/62:194,Testability,test,tests,194,"we'll work on unifying these two, starting with the engine. For example CommandLineProgram (and the whole picard.cmdline package (and picard.cmdline.programgroups) should be migrated over (with tests).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/62
https://github.com/broadinstitute/gatk/issues/63:50,Testability,test,tests,50,"Selected tools will be migrated from picard, with tests. This issue will serve a placeholder for any discussion as to which tools etc. For now, the working assumption is that all public tools will migrate (some exceptions may be tools in picard.illumina which may be too specialized) The package name will remain picard, at least for now. When migrating, put the specific commit name here for reference.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/63
https://github.com/broadinstitute/gatk/issues/69:511,Deployability,patch,patch,511,"Many of the pull requests are not using [`CommandLineProgramTest.runCommandLine()`](https://github.com/broadinstitute/hellbender/blob/c6b41e6da8c9ea3f03206a25ce4ad74312b154f0/src/test/java/org/broadinstitute/gatk/CommandLineProgramTest.java). I'm assuming this is because we have not settled on a way to `Assert` that outputs are similar after running a hellbender command line. This issue should resolve with a definition how far one should test before a pull request is accepted. After an arbitrary low level patch to the codebase, I believe the GATK [`MD5DB`](https://github.com/broadgsa/gatk/blob/3b67b448072e24c80779b2e1cbc9dcfcb5dce4cf/public/gatk-tools-public/src/test/java/org/broadinstitute/gatk/utils/MD5DB.java) and [`DiffEngine`](https://github.com/broadgsa/gatk/blob/3b67b448072e24c80779b2e1cbc9dcfcb5dce4cf/public/gatk-tools-public/src/main/java/org/broadinstitute/gatk/engine/walkers/diffengine/DiffEngine.java) are considered too hard to verify-and-update en masse. This limitation would also apply to external framework test utilities, such as TestNG's `FileAssert.assertLength()`. A 2009 discussion of file comparators is archived [here](http://stackoverflow.com/questions/466841/comparing-text-files-w-junit). Ultimately, I believe the biggest pain point with the `MD5DB` is that there does not exist a quick way to a) diagnose what has changed and b) to then update all hundreds of expected outputs. As in `DiffEngine`, we could define a way to regression test that only certain aspects of common file types aren't changing (exact number of reads in BAMs, or exact number of variants in BCF), or that values are falling within a certain range (number of quality scores all above 30 under 60), etc. As for updating results, instead of embedding the expected `MD5DB` outputs in a hundreds of java test files, one could also externalize _all_ of the expected outputs to another file (json, flat text, etc.) such that this singular sorted file for the entire test suite may be updated ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/69
https://github.com/broadinstitute/gatk/issues/69:965,Deployability,update,update,965,"Many of the pull requests are not using [`CommandLineProgramTest.runCommandLine()`](https://github.com/broadinstitute/hellbender/blob/c6b41e6da8c9ea3f03206a25ce4ad74312b154f0/src/test/java/org/broadinstitute/gatk/CommandLineProgramTest.java). I'm assuming this is because we have not settled on a way to `Assert` that outputs are similar after running a hellbender command line. This issue should resolve with a definition how far one should test before a pull request is accepted. After an arbitrary low level patch to the codebase, I believe the GATK [`MD5DB`](https://github.com/broadgsa/gatk/blob/3b67b448072e24c80779b2e1cbc9dcfcb5dce4cf/public/gatk-tools-public/src/test/java/org/broadinstitute/gatk/utils/MD5DB.java) and [`DiffEngine`](https://github.com/broadgsa/gatk/blob/3b67b448072e24c80779b2e1cbc9dcfcb5dce4cf/public/gatk-tools-public/src/main/java/org/broadinstitute/gatk/engine/walkers/diffengine/DiffEngine.java) are considered too hard to verify-and-update en masse. This limitation would also apply to external framework test utilities, such as TestNG's `FileAssert.assertLength()`. A 2009 discussion of file comparators is archived [here](http://stackoverflow.com/questions/466841/comparing-text-files-w-junit). Ultimately, I believe the biggest pain point with the `MD5DB` is that there does not exist a quick way to a) diagnose what has changed and b) to then update all hundreds of expected outputs. As in `DiffEngine`, we could define a way to regression test that only certain aspects of common file types aren't changing (exact number of reads in BAMs, or exact number of variants in BCF), or that values are falling within a certain range (number of quality scores all above 30 under 60), etc. As for updating results, instead of embedding the expected `MD5DB` outputs in a hundreds of java test files, one could also externalize _all_ of the expected outputs to another file (json, flat text, etc.) such that this singular sorted file for the entire test suite may be updated ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/69
https://github.com/broadinstitute/gatk/issues/69:1379,Deployability,update,update,1379,"institute/hellbender/blob/c6b41e6da8c9ea3f03206a25ce4ad74312b154f0/src/test/java/org/broadinstitute/gatk/CommandLineProgramTest.java). I'm assuming this is because we have not settled on a way to `Assert` that outputs are similar after running a hellbender command line. This issue should resolve with a definition how far one should test before a pull request is accepted. After an arbitrary low level patch to the codebase, I believe the GATK [`MD5DB`](https://github.com/broadgsa/gatk/blob/3b67b448072e24c80779b2e1cbc9dcfcb5dce4cf/public/gatk-tools-public/src/test/java/org/broadinstitute/gatk/utils/MD5DB.java) and [`DiffEngine`](https://github.com/broadgsa/gatk/blob/3b67b448072e24c80779b2e1cbc9dcfcb5dce4cf/public/gatk-tools-public/src/main/java/org/broadinstitute/gatk/engine/walkers/diffengine/DiffEngine.java) are considered too hard to verify-and-update en masse. This limitation would also apply to external framework test utilities, such as TestNG's `FileAssert.assertLength()`. A 2009 discussion of file comparators is archived [here](http://stackoverflow.com/questions/466841/comparing-text-files-w-junit). Ultimately, I believe the biggest pain point with the `MD5DB` is that there does not exist a quick way to a) diagnose what has changed and b) to then update all hundreds of expected outputs. As in `DiffEngine`, we could define a way to regression test that only certain aspects of common file types aren't changing (exact number of reads in BAMs, or exact number of variants in BCF), or that values are falling within a certain range (number of quality scores all above 30 under 60), etc. As for updating results, instead of embedding the expected `MD5DB` outputs in a hundreds of java test files, one could also externalize _all_ of the expected outputs to another file (json, flat text, etc.) such that this singular sorted file for the entire test suite may be updated once. Or, we can decide that none of this is required at all and just delete `CommandLineProgramTest.java`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/69
https://github.com/broadinstitute/gatk/issues/69:1993,Deployability,update,updated,1993,"institute/hellbender/blob/c6b41e6da8c9ea3f03206a25ce4ad74312b154f0/src/test/java/org/broadinstitute/gatk/CommandLineProgramTest.java). I'm assuming this is because we have not settled on a way to `Assert` that outputs are similar after running a hellbender command line. This issue should resolve with a definition how far one should test before a pull request is accepted. After an arbitrary low level patch to the codebase, I believe the GATK [`MD5DB`](https://github.com/broadgsa/gatk/blob/3b67b448072e24c80779b2e1cbc9dcfcb5dce4cf/public/gatk-tools-public/src/test/java/org/broadinstitute/gatk/utils/MD5DB.java) and [`DiffEngine`](https://github.com/broadgsa/gatk/blob/3b67b448072e24c80779b2e1cbc9dcfcb5dce4cf/public/gatk-tools-public/src/main/java/org/broadinstitute/gatk/engine/walkers/diffengine/DiffEngine.java) are considered too hard to verify-and-update en masse. This limitation would also apply to external framework test utilities, such as TestNG's `FileAssert.assertLength()`. A 2009 discussion of file comparators is archived [here](http://stackoverflow.com/questions/466841/comparing-text-files-w-junit). Ultimately, I believe the biggest pain point with the `MD5DB` is that there does not exist a quick way to a) diagnose what has changed and b) to then update all hundreds of expected outputs. As in `DiffEngine`, we could define a way to regression test that only certain aspects of common file types aren't changing (exact number of reads in BAMs, or exact number of variants in BCF), or that values are falling within a certain range (number of quality scores all above 30 under 60), etc. As for updating results, instead of embedding the expected `MD5DB` outputs in a hundreds of java test files, one could also externalize _all_ of the expected outputs to another file (json, flat text, etc.) such that this singular sorted file for the entire test suite may be updated once. Or, we can decide that none of this is required at all and just delete `CommandLineProgramTest.java`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/69
https://github.com/broadinstitute/gatk/issues/69:179,Testability,test,test,179,"Many of the pull requests are not using [`CommandLineProgramTest.runCommandLine()`](https://github.com/broadinstitute/hellbender/blob/c6b41e6da8c9ea3f03206a25ce4ad74312b154f0/src/test/java/org/broadinstitute/gatk/CommandLineProgramTest.java). I'm assuming this is because we have not settled on a way to `Assert` that outputs are similar after running a hellbender command line. This issue should resolve with a definition how far one should test before a pull request is accepted. After an arbitrary low level patch to the codebase, I believe the GATK [`MD5DB`](https://github.com/broadgsa/gatk/blob/3b67b448072e24c80779b2e1cbc9dcfcb5dce4cf/public/gatk-tools-public/src/test/java/org/broadinstitute/gatk/utils/MD5DB.java) and [`DiffEngine`](https://github.com/broadgsa/gatk/blob/3b67b448072e24c80779b2e1cbc9dcfcb5dce4cf/public/gatk-tools-public/src/main/java/org/broadinstitute/gatk/engine/walkers/diffengine/DiffEngine.java) are considered too hard to verify-and-update en masse. This limitation would also apply to external framework test utilities, such as TestNG's `FileAssert.assertLength()`. A 2009 discussion of file comparators is archived [here](http://stackoverflow.com/questions/466841/comparing-text-files-w-junit). Ultimately, I believe the biggest pain point with the `MD5DB` is that there does not exist a quick way to a) diagnose what has changed and b) to then update all hundreds of expected outputs. As in `DiffEngine`, we could define a way to regression test that only certain aspects of common file types aren't changing (exact number of reads in BAMs, or exact number of variants in BCF), or that values are falling within a certain range (number of quality scores all above 30 under 60), etc. As for updating results, instead of embedding the expected `MD5DB` outputs in a hundreds of java test files, one could also externalize _all_ of the expected outputs to another file (json, flat text, etc.) such that this singular sorted file for the entire test suite may be updated ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/69
https://github.com/broadinstitute/gatk/issues/69:305,Testability,Assert,Assert,305,"Many of the pull requests are not using [`CommandLineProgramTest.runCommandLine()`](https://github.com/broadinstitute/hellbender/blob/c6b41e6da8c9ea3f03206a25ce4ad74312b154f0/src/test/java/org/broadinstitute/gatk/CommandLineProgramTest.java). I'm assuming this is because we have not settled on a way to `Assert` that outputs are similar after running a hellbender command line. This issue should resolve with a definition how far one should test before a pull request is accepted. After an arbitrary low level patch to the codebase, I believe the GATK [`MD5DB`](https://github.com/broadgsa/gatk/blob/3b67b448072e24c80779b2e1cbc9dcfcb5dce4cf/public/gatk-tools-public/src/test/java/org/broadinstitute/gatk/utils/MD5DB.java) and [`DiffEngine`](https://github.com/broadgsa/gatk/blob/3b67b448072e24c80779b2e1cbc9dcfcb5dce4cf/public/gatk-tools-public/src/main/java/org/broadinstitute/gatk/engine/walkers/diffengine/DiffEngine.java) are considered too hard to verify-and-update en masse. This limitation would also apply to external framework test utilities, such as TestNG's `FileAssert.assertLength()`. A 2009 discussion of file comparators is archived [here](http://stackoverflow.com/questions/466841/comparing-text-files-w-junit). Ultimately, I believe the biggest pain point with the `MD5DB` is that there does not exist a quick way to a) diagnose what has changed and b) to then update all hundreds of expected outputs. As in `DiffEngine`, we could define a way to regression test that only certain aspects of common file types aren't changing (exact number of reads in BAMs, or exact number of variants in BCF), or that values are falling within a certain range (number of quality scores all above 30 under 60), etc. As for updating results, instead of embedding the expected `MD5DB` outputs in a hundreds of java test files, one could also externalize _all_ of the expected outputs to another file (json, flat text, etc.) such that this singular sorted file for the entire test suite may be updated ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/69
https://github.com/broadinstitute/gatk/issues/69:442,Testability,test,test,442,"Many of the pull requests are not using [`CommandLineProgramTest.runCommandLine()`](https://github.com/broadinstitute/hellbender/blob/c6b41e6da8c9ea3f03206a25ce4ad74312b154f0/src/test/java/org/broadinstitute/gatk/CommandLineProgramTest.java). I'm assuming this is because we have not settled on a way to `Assert` that outputs are similar after running a hellbender command line. This issue should resolve with a definition how far one should test before a pull request is accepted. After an arbitrary low level patch to the codebase, I believe the GATK [`MD5DB`](https://github.com/broadgsa/gatk/blob/3b67b448072e24c80779b2e1cbc9dcfcb5dce4cf/public/gatk-tools-public/src/test/java/org/broadinstitute/gatk/utils/MD5DB.java) and [`DiffEngine`](https://github.com/broadgsa/gatk/blob/3b67b448072e24c80779b2e1cbc9dcfcb5dce4cf/public/gatk-tools-public/src/main/java/org/broadinstitute/gatk/engine/walkers/diffengine/DiffEngine.java) are considered too hard to verify-and-update en masse. This limitation would also apply to external framework test utilities, such as TestNG's `FileAssert.assertLength()`. A 2009 discussion of file comparators is archived [here](http://stackoverflow.com/questions/466841/comparing-text-files-w-junit). Ultimately, I believe the biggest pain point with the `MD5DB` is that there does not exist a quick way to a) diagnose what has changed and b) to then update all hundreds of expected outputs. As in `DiffEngine`, we could define a way to regression test that only certain aspects of common file types aren't changing (exact number of reads in BAMs, or exact number of variants in BCF), or that values are falling within a certain range (number of quality scores all above 30 under 60), etc. As for updating results, instead of embedding the expected `MD5DB` outputs in a hundreds of java test files, one could also externalize _all_ of the expected outputs to another file (json, flat text, etc.) such that this singular sorted file for the entire test suite may be updated ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/69
https://github.com/broadinstitute/gatk/issues/69:671,Testability,test,test,671,"Many of the pull requests are not using [`CommandLineProgramTest.runCommandLine()`](https://github.com/broadinstitute/hellbender/blob/c6b41e6da8c9ea3f03206a25ce4ad74312b154f0/src/test/java/org/broadinstitute/gatk/CommandLineProgramTest.java). I'm assuming this is because we have not settled on a way to `Assert` that outputs are similar after running a hellbender command line. This issue should resolve with a definition how far one should test before a pull request is accepted. After an arbitrary low level patch to the codebase, I believe the GATK [`MD5DB`](https://github.com/broadgsa/gatk/blob/3b67b448072e24c80779b2e1cbc9dcfcb5dce4cf/public/gatk-tools-public/src/test/java/org/broadinstitute/gatk/utils/MD5DB.java) and [`DiffEngine`](https://github.com/broadgsa/gatk/blob/3b67b448072e24c80779b2e1cbc9dcfcb5dce4cf/public/gatk-tools-public/src/main/java/org/broadinstitute/gatk/engine/walkers/diffengine/DiffEngine.java) are considered too hard to verify-and-update en masse. This limitation would also apply to external framework test utilities, such as TestNG's `FileAssert.assertLength()`. A 2009 discussion of file comparators is archived [here](http://stackoverflow.com/questions/466841/comparing-text-files-w-junit). Ultimately, I believe the biggest pain point with the `MD5DB` is that there does not exist a quick way to a) diagnose what has changed and b) to then update all hundreds of expected outputs. As in `DiffEngine`, we could define a way to regression test that only certain aspects of common file types aren't changing (exact number of reads in BAMs, or exact number of variants in BCF), or that values are falling within a certain range (number of quality scores all above 30 under 60), etc. As for updating results, instead of embedding the expected `MD5DB` outputs in a hundreds of java test files, one could also externalize _all_ of the expected outputs to another file (json, flat text, etc.) such that this singular sorted file for the entire test suite may be updated ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/69
https://github.com/broadinstitute/gatk/issues/69:1037,Testability,test,test,1037,"ot using [`CommandLineProgramTest.runCommandLine()`](https://github.com/broadinstitute/hellbender/blob/c6b41e6da8c9ea3f03206a25ce4ad74312b154f0/src/test/java/org/broadinstitute/gatk/CommandLineProgramTest.java). I'm assuming this is because we have not settled on a way to `Assert` that outputs are similar after running a hellbender command line. This issue should resolve with a definition how far one should test before a pull request is accepted. After an arbitrary low level patch to the codebase, I believe the GATK [`MD5DB`](https://github.com/broadgsa/gatk/blob/3b67b448072e24c80779b2e1cbc9dcfcb5dce4cf/public/gatk-tools-public/src/test/java/org/broadinstitute/gatk/utils/MD5DB.java) and [`DiffEngine`](https://github.com/broadgsa/gatk/blob/3b67b448072e24c80779b2e1cbc9dcfcb5dce4cf/public/gatk-tools-public/src/main/java/org/broadinstitute/gatk/engine/walkers/diffengine/DiffEngine.java) are considered too hard to verify-and-update en masse. This limitation would also apply to external framework test utilities, such as TestNG's `FileAssert.assertLength()`. A 2009 discussion of file comparators is archived [here](http://stackoverflow.com/questions/466841/comparing-text-files-w-junit). Ultimately, I believe the biggest pain point with the `MD5DB` is that there does not exist a quick way to a) diagnose what has changed and b) to then update all hundreds of expected outputs. As in `DiffEngine`, we could define a way to regression test that only certain aspects of common file types aren't changing (exact number of reads in BAMs, or exact number of variants in BCF), or that values are falling within a certain range (number of quality scores all above 30 under 60), etc. As for updating results, instead of embedding the expected `MD5DB` outputs in a hundreds of java test files, one could also externalize _all_ of the expected outputs to another file (json, flat text, etc.) such that this singular sorted file for the entire test suite may be updated once. Or, we can decide that no",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/69
https://github.com/broadinstitute/gatk/issues/69:1061,Testability,Test,TestNG,1061,"ot using [`CommandLineProgramTest.runCommandLine()`](https://github.com/broadinstitute/hellbender/blob/c6b41e6da8c9ea3f03206a25ce4ad74312b154f0/src/test/java/org/broadinstitute/gatk/CommandLineProgramTest.java). I'm assuming this is because we have not settled on a way to `Assert` that outputs are similar after running a hellbender command line. This issue should resolve with a definition how far one should test before a pull request is accepted. After an arbitrary low level patch to the codebase, I believe the GATK [`MD5DB`](https://github.com/broadgsa/gatk/blob/3b67b448072e24c80779b2e1cbc9dcfcb5dce4cf/public/gatk-tools-public/src/test/java/org/broadinstitute/gatk/utils/MD5DB.java) and [`DiffEngine`](https://github.com/broadgsa/gatk/blob/3b67b448072e24c80779b2e1cbc9dcfcb5dce4cf/public/gatk-tools-public/src/main/java/org/broadinstitute/gatk/engine/walkers/diffengine/DiffEngine.java) are considered too hard to verify-and-update en masse. This limitation would also apply to external framework test utilities, such as TestNG's `FileAssert.assertLength()`. A 2009 discussion of file comparators is archived [here](http://stackoverflow.com/questions/466841/comparing-text-files-w-junit). Ultimately, I believe the biggest pain point with the `MD5DB` is that there does not exist a quick way to a) diagnose what has changed and b) to then update all hundreds of expected outputs. As in `DiffEngine`, we could define a way to regression test that only certain aspects of common file types aren't changing (exact number of reads in BAMs, or exact number of variants in BCF), or that values are falling within a certain range (number of quality scores all above 30 under 60), etc. As for updating results, instead of embedding the expected `MD5DB` outputs in a hundreds of java test files, one could also externalize _all_ of the expected outputs to another file (json, flat text, etc.) such that this singular sorted file for the entire test suite may be updated once. Or, we can decide that no",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/69
https://github.com/broadinstitute/gatk/issues/69:1082,Testability,assert,assertLength,1082,"//github.com/broadinstitute/hellbender/blob/c6b41e6da8c9ea3f03206a25ce4ad74312b154f0/src/test/java/org/broadinstitute/gatk/CommandLineProgramTest.java). I'm assuming this is because we have not settled on a way to `Assert` that outputs are similar after running a hellbender command line. This issue should resolve with a definition how far one should test before a pull request is accepted. After an arbitrary low level patch to the codebase, I believe the GATK [`MD5DB`](https://github.com/broadgsa/gatk/blob/3b67b448072e24c80779b2e1cbc9dcfcb5dce4cf/public/gatk-tools-public/src/test/java/org/broadinstitute/gatk/utils/MD5DB.java) and [`DiffEngine`](https://github.com/broadgsa/gatk/blob/3b67b448072e24c80779b2e1cbc9dcfcb5dce4cf/public/gatk-tools-public/src/main/java/org/broadinstitute/gatk/engine/walkers/diffengine/DiffEngine.java) are considered too hard to verify-and-update en masse. This limitation would also apply to external framework test utilities, such as TestNG's `FileAssert.assertLength()`. A 2009 discussion of file comparators is archived [here](http://stackoverflow.com/questions/466841/comparing-text-files-w-junit). Ultimately, I believe the biggest pain point with the `MD5DB` is that there does not exist a quick way to a) diagnose what has changed and b) to then update all hundreds of expected outputs. As in `DiffEngine`, we could define a way to regression test that only certain aspects of common file types aren't changing (exact number of reads in BAMs, or exact number of variants in BCF), or that values are falling within a certain range (number of quality scores all above 30 under 60), etc. As for updating results, instead of embedding the expected `MD5DB` outputs in a hundreds of java test files, one could also externalize _all_ of the expected outputs to another file (json, flat text, etc.) such that this singular sorted file for the entire test suite may be updated once. Or, we can decide that none of this is required at all and just delete `CommandLine",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/69
https://github.com/broadinstitute/gatk/issues/69:1476,Testability,test,test,1476,"institute/hellbender/blob/c6b41e6da8c9ea3f03206a25ce4ad74312b154f0/src/test/java/org/broadinstitute/gatk/CommandLineProgramTest.java). I'm assuming this is because we have not settled on a way to `Assert` that outputs are similar after running a hellbender command line. This issue should resolve with a definition how far one should test before a pull request is accepted. After an arbitrary low level patch to the codebase, I believe the GATK [`MD5DB`](https://github.com/broadgsa/gatk/blob/3b67b448072e24c80779b2e1cbc9dcfcb5dce4cf/public/gatk-tools-public/src/test/java/org/broadinstitute/gatk/utils/MD5DB.java) and [`DiffEngine`](https://github.com/broadgsa/gatk/blob/3b67b448072e24c80779b2e1cbc9dcfcb5dce4cf/public/gatk-tools-public/src/main/java/org/broadinstitute/gatk/engine/walkers/diffengine/DiffEngine.java) are considered too hard to verify-and-update en masse. This limitation would also apply to external framework test utilities, such as TestNG's `FileAssert.assertLength()`. A 2009 discussion of file comparators is archived [here](http://stackoverflow.com/questions/466841/comparing-text-files-w-junit). Ultimately, I believe the biggest pain point with the `MD5DB` is that there does not exist a quick way to a) diagnose what has changed and b) to then update all hundreds of expected outputs. As in `DiffEngine`, we could define a way to regression test that only certain aspects of common file types aren't changing (exact number of reads in BAMs, or exact number of variants in BCF), or that values are falling within a certain range (number of quality scores all above 30 under 60), etc. As for updating results, instead of embedding the expected `MD5DB` outputs in a hundreds of java test files, one could also externalize _all_ of the expected outputs to another file (json, flat text, etc.) such that this singular sorted file for the entire test suite may be updated once. Or, we can decide that none of this is required at all and just delete `CommandLineProgramTest.java`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/69
https://github.com/broadinstitute/gatk/issues/69:1815,Testability,test,test,1815,"institute/hellbender/blob/c6b41e6da8c9ea3f03206a25ce4ad74312b154f0/src/test/java/org/broadinstitute/gatk/CommandLineProgramTest.java). I'm assuming this is because we have not settled on a way to `Assert` that outputs are similar after running a hellbender command line. This issue should resolve with a definition how far one should test before a pull request is accepted. After an arbitrary low level patch to the codebase, I believe the GATK [`MD5DB`](https://github.com/broadgsa/gatk/blob/3b67b448072e24c80779b2e1cbc9dcfcb5dce4cf/public/gatk-tools-public/src/test/java/org/broadinstitute/gatk/utils/MD5DB.java) and [`DiffEngine`](https://github.com/broadgsa/gatk/blob/3b67b448072e24c80779b2e1cbc9dcfcb5dce4cf/public/gatk-tools-public/src/main/java/org/broadinstitute/gatk/engine/walkers/diffengine/DiffEngine.java) are considered too hard to verify-and-update en masse. This limitation would also apply to external framework test utilities, such as TestNG's `FileAssert.assertLength()`. A 2009 discussion of file comparators is archived [here](http://stackoverflow.com/questions/466841/comparing-text-files-w-junit). Ultimately, I believe the biggest pain point with the `MD5DB` is that there does not exist a quick way to a) diagnose what has changed and b) to then update all hundreds of expected outputs. As in `DiffEngine`, we could define a way to regression test that only certain aspects of common file types aren't changing (exact number of reads in BAMs, or exact number of variants in BCF), or that values are falling within a certain range (number of quality scores all above 30 under 60), etc. As for updating results, instead of embedding the expected `MD5DB` outputs in a hundreds of java test files, one could also externalize _all_ of the expected outputs to another file (json, flat text, etc.) such that this singular sorted file for the entire test suite may be updated once. Or, we can decide that none of this is required at all and just delete `CommandLineProgramTest.java`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/69
https://github.com/broadinstitute/gatk/issues/69:1975,Testability,test,test,1975,"institute/hellbender/blob/c6b41e6da8c9ea3f03206a25ce4ad74312b154f0/src/test/java/org/broadinstitute/gatk/CommandLineProgramTest.java). I'm assuming this is because we have not settled on a way to `Assert` that outputs are similar after running a hellbender command line. This issue should resolve with a definition how far one should test before a pull request is accepted. After an arbitrary low level patch to the codebase, I believe the GATK [`MD5DB`](https://github.com/broadgsa/gatk/blob/3b67b448072e24c80779b2e1cbc9dcfcb5dce4cf/public/gatk-tools-public/src/test/java/org/broadinstitute/gatk/utils/MD5DB.java) and [`DiffEngine`](https://github.com/broadgsa/gatk/blob/3b67b448072e24c80779b2e1cbc9dcfcb5dce4cf/public/gatk-tools-public/src/main/java/org/broadinstitute/gatk/engine/walkers/diffengine/DiffEngine.java) are considered too hard to verify-and-update en masse. This limitation would also apply to external framework test utilities, such as TestNG's `FileAssert.assertLength()`. A 2009 discussion of file comparators is archived [here](http://stackoverflow.com/questions/466841/comparing-text-files-w-junit). Ultimately, I believe the biggest pain point with the `MD5DB` is that there does not exist a quick way to a) diagnose what has changed and b) to then update all hundreds of expected outputs. As in `DiffEngine`, we could define a way to regression test that only certain aspects of common file types aren't changing (exact number of reads in BAMs, or exact number of variants in BCF), or that values are falling within a certain range (number of quality scores all above 30 under 60), etc. As for updating results, instead of embedding the expected `MD5DB` outputs in a hundreds of java test files, one could also externalize _all_ of the expected outputs to another file (json, flat text, etc.) such that this singular sorted file for the entire test suite may be updated once. Or, we can decide that none of this is required at all and just delete `CommandLineProgramTest.java`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/69
https://github.com/broadinstitute/gatk/issues/71:41,Availability,error,error,41,Let's use Exceptions instead to indicate error conditions. The main program can return a error status but not internal classes. Return values are too valuable to use them for error codes.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/71
https://github.com/broadinstitute/gatk/issues/71:89,Availability,error,error,89,Let's use Exceptions instead to indicate error conditions. The main program can return a error status but not internal classes. Return values are too valuable to use them for error codes.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/71
https://github.com/broadinstitute/gatk/issues/71:175,Availability,error,error,175,Let's use Exceptions instead to indicate error conditions. The main program can return a error status but not internal classes. Return values are too valuable to use them for error codes.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/71
https://github.com/broadinstitute/gatk/pull/75:24,Testability,test,testing,24,... so we can use it in testing.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/75
https://github.com/broadinstitute/gatk/issues/77:82,Availability,down,down,82,a bunch of methods in the GATKSAMRecord are generally useful and should be pushed down to SAMRecord,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/77
https://github.com/broadinstitute/gatk/pull/79:89,Modifiability,plugin,plugin,89,Edited .travis.yml to add upload a report to coveralls. We're using the coveralls gradle plugin from https://github.com/kt3k/coveralls-gradle-plugin.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/79
https://github.com/broadinstitute/gatk/pull/79:142,Modifiability,plugin,plugin,142,Edited .travis.yml to add upload a report to coveralls. We're using the coveralls gradle plugin from https://github.com/kt3k/coveralls-gradle-plugin.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/79
https://github.com/broadinstitute/gatk/issues/80:71,Testability,log,logical,71,"These are arguments of the form: -V:tag filename. Needed for assigning logical names to sources of Sam/variant/etc. records (eg., ""tumor"" and ""normal"").",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/80
https://github.com/broadinstitute/gatk/issues/82:368,Security,access,access,368,"Will include a top-level abstract Tool class, subclasses for each of the standard traversal types (ReadWalker, LocusWalker, etc.), and a class for each kind of data source (ReadDataSource, ReferenceDataSource, etc.). Initial framework will have placeholders/stub implementations for some functionality, but will support at least traversal by reads with the ability to access overlapping reference bases.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/82
https://github.com/broadinstitute/gatk/issues/82:258,Testability,stub,stub,258,"Will include a top-level abstract Tool class, subclasses for each of the standard traversal types (ReadWalker, LocusWalker, etc.), and a class for each kind of data source (ReadDataSource, ReferenceDataSource, etc.). Initial framework will have placeholders/stub implementations for some functionality, but will support at least traversal by reads with the ability to access overlapping reference bases.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/82
https://github.com/broadinstitute/gatk/issues/83:119,Testability,log,logging,119,"CommandLineProgram should include only functionality common to all command-line programs, such as argument parsing and logging. Functionality specific to particular file formats should be moved into a subclass (PicardCommandLineProgram?).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/83
https://github.com/broadinstitute/gatk/pull/84:234,Security,hash,hash,234,"I suppressed the warnings we were getting. If we can't fix them lets at least not see them.; It seemed like it was ok to suppress the serialization warnings rather than provide a UUID, since java will fill one in for us. We can add a hash value instead if that's better.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/84
https://github.com/broadinstitute/gatk/pull/85:204,Availability,failure,failures,204,"The important distinction is not between ""reviewed"" and ""unreviewed"" exceptions (all; use of exceptions should be reviewed in code review, after all), but between user mistakes; and internal sanity check failures. To this end, I've ported UserException from the old GATK codebase (preserving only the; most generally useful subclasses -- we can add more later if needed), removed the silly; ReviewedHellbenderException, and renamed HellbenderException to GATKException, which is; what should be thrown for all errors that are not the user's fault.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/85
https://github.com/broadinstitute/gatk/pull/85:510,Availability,error,errors,510,"The important distinction is not between ""reviewed"" and ""unreviewed"" exceptions (all; use of exceptions should be reviewed in code review, after all), but between user mistakes; and internal sanity check failures. To this end, I've ported UserException from the old GATK codebase (preserving only the; most generally useful subclasses -- we can add more later if needed), removed the silly; ReviewedHellbenderException, and renamed HellbenderException to GATKException, which is; what should be thrown for all errors that are not the user's fault.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/85
https://github.com/broadinstitute/gatk/pull/85:541,Availability,fault,fault,541,"The important distinction is not between ""reviewed"" and ""unreviewed"" exceptions (all; use of exceptions should be reviewed in code review, after all), but between user mistakes; and internal sanity check failures. To this end, I've ported UserException from the old GATK codebase (preserving only the; most generally useful subclasses -- we can add more later if needed), removed the silly; ReviewedHellbenderException, and renamed HellbenderException to GATKException, which is; what should be thrown for all errors that are not the user's fault.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/85
https://github.com/broadinstitute/gatk/pull/85:191,Safety,sanity check,sanity check,191,"The important distinction is not between ""reviewed"" and ""unreviewed"" exceptions (all; use of exceptions should be reviewed in code review, after all), but between user mistakes; and internal sanity check failures. To this end, I've ported UserException from the old GATK codebase (preserving only the; most generally useful subclasses -- we can add more later if needed), removed the silly; ReviewedHellbenderException, and renamed HellbenderException to GATKException, which is; what should be thrown for all errors that are not the user's fault.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/85
https://github.com/broadinstitute/gatk/issues/86:133,Availability,error,error,133,"Now that UserException has been ported, we should eventually make an effort to wrap exceptions in htsjdk that are the result of user error in UserExceptions.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/86
https://github.com/broadinstitute/gatk/issues/86:79,Integrability,wrap,wrap,79,"Now that UserException has been ported, we should eventually make an effort to wrap exceptions in htsjdk that are the result of user error in UserExceptions.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/86
https://github.com/broadinstitute/gatk/issues/89:73,Availability,down,down,73,We can simplify it by removing thread safety guarantees and then push it down into htsjdk,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/89
https://github.com/broadinstitute/gatk/issues/89:38,Safety,safe,safety,38,We can simplify it by removing thread safety guarantees and then push it down into htsjdk,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/89
https://github.com/broadinstitute/gatk/issues/89:7,Usability,simpl,simplify,7,We can simplify it by removing thread safety guarantees and then push it down into htsjdk,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/89
https://github.com/broadinstitute/gatk/issues/90:19,Testability,test,tests,19,There are a lot of tests for these and some of them are not very fast. Definitely some things that could be deleted.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/90
https://github.com/broadinstitute/gatk/pull/91:78,Deployability,update,updated,78,Adam moved the code for SplitNCigarReads and all supporting utils over.; I've updated the tests so that they all use a small snippet of the reference instead of the entire hg19 (hg19mini.fasta),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/91
https://github.com/broadinstitute/gatk/pull/91:90,Testability,test,tests,90,Adam moved the code for SplitNCigarReads and all supporting utils over.; I've updated the tests so that they all use a small snippet of the reference instead of the entire hg19 (hg19mini.fasta),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/91
https://github.com/broadinstitute/gatk/issues/93:82,Integrability,interface,interface,82,"Port the needed pieces of the old ROD system over to the new framework. The basic interface should be a map from logical names to lazy queries over the current interval for each source of variants. Unlike ReadsDataSource, VariantsDataSource should not merge variants from different sources into a single stream. Initial implementation may only need to support VCF/BCF, with support for arbitrary codecs added later.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/93
https://github.com/broadinstitute/gatk/issues/93:113,Testability,log,logical,113,"Port the needed pieces of the old ROD system over to the new framework. The basic interface should be a map from logical names to lazy queries over the current interval for each source of variants. Unlike ReadsDataSource, VariantsDataSource should not merge variants from different sources into a single stream. Initial implementation may only need to support VCF/BCF, with support for arbitrary codecs added later.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/93
https://github.com/broadinstitute/gatk/issues/94:31,Testability,log,logical,31,"Add the ability to tag (assign logical names to) inputs (eg., -I:tumor tumor.bam). Needed by https://github.com/broadinstitute/hellbender/issues/93",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/94
https://github.com/broadinstitute/gatk/issues/96:108,Safety,avoid,avoid,108,"We need the ability to store command-line argument definitions in @ArgumentCollections like in the GATK, to avoid duplicate definitions, and to provide a standard way of accessing the argument values.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/96
https://github.com/broadinstitute/gatk/issues/96:170,Security,access,accessing,170,"We need the ability to store command-line argument definitions in @ArgumentCollections like in the GATK, to avoid duplicate definitions, and to provide a standard way of accessing the argument values.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/96
https://github.com/broadinstitute/gatk/issues/100:150,Security,validat,validation,150,"Currently, in order to create a GenomeLoc, you need to create a GenomeLocParser, which requires either a reference fasta or a sequence dictionary for validation. Sometimes, however, you don't want this level of validation (perhaps you have already checked that the interval is within bounds, making the extra validation wasteful -- this happens in a few places in the new engine). There should be a way to instantiate a GenomeLoc directly, without the need to pass around a GenomeLocParser.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/100
https://github.com/broadinstitute/gatk/issues/100:211,Security,validat,validation,211,"Currently, in order to create a GenomeLoc, you need to create a GenomeLocParser, which requires either a reference fasta or a sequence dictionary for validation. Sometimes, however, you don't want this level of validation (perhaps you have already checked that the interval is within bounds, making the extra validation wasteful -- this happens in a few places in the new engine). There should be a way to instantiate a GenomeLoc directly, without the need to pass around a GenomeLocParser.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/100
https://github.com/broadinstitute/gatk/issues/100:309,Security,validat,validation,309,"Currently, in order to create a GenomeLoc, you need to create a GenomeLocParser, which requires either a reference fasta or a sequence dictionary for validation. Sometimes, however, you don't want this level of validation (perhaps you have already checked that the interval is within bounds, making the extra validation wasteful -- this happens in a few places in the new engine). There should be a way to instantiate a GenomeLoc directly, without the need to pass around a GenomeLocParser.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/100
https://github.com/broadinstitute/gatk/issues/106:54,Deployability,install,install,54,"Currently our build generates a shell script in build/install/hellbender/bin/hellbender which sets up the Java classpath to point to the various individual jars. We need the ability to package a monolithic jar for distribution, ease of debugging, etc.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/106
https://github.com/broadinstitute/gatk/issues/107:92,Integrability,inject,injected,92,"Currently, we're instantiating our CommandLineProgram before we've parsed its arguments and injected them into the appropriate member variables. This means that the constructors for our tools (eg., the ReadWalker constructor) cannot use argument values during initialization, which is a big problem. We need to delay instantiation until after arguments are parsed and injected.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/107
https://github.com/broadinstitute/gatk/issues/107:368,Integrability,inject,injected,368,"Currently, we're instantiating our CommandLineProgram before we've parsed its arguments and injected them into the appropriate member variables. This means that the constructors for our tools (eg., the ReadWalker constructor) cannot use argument values during initialization, which is a big problem. We need to delay instantiation until after arguments are parsed and injected.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/107
https://github.com/broadinstitute/gatk/issues/107:134,Modifiability,variab,variables,134,"Currently, we're instantiating our CommandLineProgram before we've parsed its arguments and injected them into the appropriate member variables. This means that the constructors for our tools (eg., the ReadWalker constructor) cannot use argument values during initialization, which is a big problem. We need to delay instantiation until after arguments are parsed and injected.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/107
https://github.com/broadinstitute/gatk/issues/107:92,Security,inject,injected,92,"Currently, we're instantiating our CommandLineProgram before we've parsed its arguments and injected them into the appropriate member variables. This means that the constructors for our tools (eg., the ReadWalker constructor) cannot use argument values during initialization, which is a big problem. We need to delay instantiation until after arguments are parsed and injected.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/107
https://github.com/broadinstitute/gatk/issues/107:368,Security,inject,injected,368,"Currently, we're instantiating our CommandLineProgram before we've parsed its arguments and injected them into the appropriate member variables. This means that the constructors for our tools (eg., the ReadWalker constructor) cannot use argument values during initialization, which is a big problem. We need to delay instantiation until after arguments are parsed and injected.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/107
https://github.com/broadinstitute/gatk/issues/109:53,Integrability,depend,depend,53,the usecase is depth of coverage per exon (for CNV); depend on #98,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/109
https://github.com/broadinstitute/gatk/issues/110:439,Availability,error,error,439,Some times in the past I found that it would have been useful to be able to determine whether the user gave a value to an argument or not. I.e. the argument default value may be different based on the circumstances (by different tools if shared across tools or the same tool based on other argument values) and so it is important to make sure that we are not overriding the user request (or at least we can emit the appropriate warning or error message).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/110
https://github.com/broadinstitute/gatk/issues/110:445,Integrability,message,message,445,Some times in the past I found that it would have been useful to be able to determine whether the user gave a value to an argument or not. I.e. the argument default value may be different based on the circumstances (by different tools if shared across tools or the same tool based on other argument values) and so it is important to make sure that we are not overriding the user request (or at least we can emit the appropriate warning or error message).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/110
https://github.com/broadinstitute/gatk/issues/111:196,Modifiability,variab,variable,196,"If you manually specify the fullName attribute for an argument in an Option annotation, it is not respected, and instead the full name of the argument gets set to the name of the annotated member variable.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/111
https://github.com/broadinstitute/gatk/pull/112:27,Integrability,interface,interface,27,"ReadWalker: initial walker interface with support for iteration over reads with optional reference; contextual information. ```; PrintReadsWithReference is provided as an example ReadWalker; ```. ReadsDataSource: full support for iteration and queries over multiple SAM/BAM files, optionally; bounded by intervals. ReferenceDataSource: support for targeted queries by interval (full iteration over the reference not; yet supported). Comprehensive unit tests",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/112
https://github.com/broadinstitute/gatk/pull/112:452,Testability,test,tests,452,"ReadWalker: initial walker interface with support for iteration over reads with optional reference; contextual information. ```; PrintReadsWithReference is provided as an example ReadWalker; ```. ReadsDataSource: full support for iteration and queries over multiple SAM/BAM files, optionally; bounded by intervals. ReferenceDataSource: support for targeted queries by interval (full iteration over the reference not; yet supported). Comprehensive unit tests",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/112
https://github.com/broadinstitute/gatk/issues/114:175,Energy Efficiency,reduce,reduce,175,"The current, early-stage ReadWalker interface has only an apply()/map operation. We need to determine whether the GATK engine should accumulate map output and/or provide full reduce functionality, or whether this should be done externally by a separate framework that runs the tools (a la Queue).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/114
https://github.com/broadinstitute/gatk/issues/114:36,Integrability,interface,interface,36,"The current, early-stage ReadWalker interface has only an apply()/map operation. We need to determine whether the GATK engine should accumulate map output and/or provide full reduce functionality, or whether this should be done externally by a separate framework that runs the tools (a la Queue).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/114
https://github.com/broadinstitute/gatk/issues/114:289,Performance,Queue,Queue,289,"The current, early-stage ReadWalker interface has only an apply()/map operation. We need to determine whether the GATK engine should accumulate map output and/or provide full reduce functionality, or whether this should be done externally by a separate framework that runs the tools (a la Queue).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/114
https://github.com/broadinstitute/gatk/issues/115:18,Performance,perform,performance,18,Lets see what the performance difference is. It's pretty awkward to pass raw bytes around.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/115
https://github.com/broadinstitute/gatk/pull/117:77,Testability,test,tests,77,@akiezun This should fix it so that it prints the stacktraces of the failing tests on travis in a readable way.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/117
https://github.com/broadinstitute/gatk/issues/118:119,Deployability,release,release,119,I think we should make an effort to keep the project at 0 warnings. We could do this during the bugfixing freeze every release.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/118
https://github.com/broadinstitute/gatk/pull/119:22,Deployability,integrat,integration,22,First cut of BQSR. No integration tests yet because of the file size issue. Will add another ticked. The pull req is mostly for the utils etc.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/119
https://github.com/broadinstitute/gatk/pull/119:22,Integrability,integrat,integration,22,First cut of BQSR. No integration tests yet because of the file size issue. Will add another ticked. The pull req is mostly for the utils etc.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/119
https://github.com/broadinstitute/gatk/pull/119:34,Testability,test,tests,34,First cut of BQSR. No integration tests yet because of the file size issue. Will add another ticked. The pull req is mostly for the utils etc.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/119
https://github.com/broadinstitute/gatk/issues/120:130,Modifiability,inherit,inherited,130,"If a tool requires a reference, for example, it should be able to indicate so via an annotation, instead of manually checking the inherited argument value for null. The engine should perform the check on behalf of the tool.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/120
https://github.com/broadinstitute/gatk/issues/120:183,Performance,perform,perform,183,"If a tool requires a reference, for example, it should be able to indicate so via an annotation, instead of manually checking the inherited argument value for null. The engine should perform the check on behalf of the tool.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/120
https://github.com/broadinstitute/gatk/pull/122:188,Modifiability,refactor,refactoring,188,"-CompareSAMs not ported because ReadWalker traversal is not suited; for it. -SplitNCigarReads not ported because of the way it uses the reference; (could be ported to ReadWalker with some refactoring, however). There were a few engine changes as well to accomodate the new ReadWalker tools:. -Method to allow walkers to access the SAM header from the reads data source. -No longer require an index for BAM/SAM files when no intervals are; provided and no queries are performed. -onTraversalDone() now allows tools to return a value, which is printed; out by the engine. Resolves #113",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/122
https://github.com/broadinstitute/gatk/pull/122:467,Performance,perform,performed,467,"-CompareSAMs not ported because ReadWalker traversal is not suited; for it. -SplitNCigarReads not ported because of the way it uses the reference; (could be ported to ReadWalker with some refactoring, however). There were a few engine changes as well to accomodate the new ReadWalker tools:. -Method to allow walkers to access the SAM header from the reads data source. -No longer require an index for BAM/SAM files when no intervals are; provided and no queries are performed. -onTraversalDone() now allows tools to return a value, which is printed; out by the engine. Resolves #113",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/122
https://github.com/broadinstitute/gatk/pull/122:320,Security,access,access,320,"-CompareSAMs not ported because ReadWalker traversal is not suited; for it. -SplitNCigarReads not ported because of the way it uses the reference; (could be ported to ReadWalker with some refactoring, however). There were a few engine changes as well to accomodate the new ReadWalker tools:. -Method to allow walkers to access the SAM header from the reads data source. -No longer require an index for BAM/SAM files when no intervals are; provided and no queries are performed. -onTraversalDone() now allows tools to return a value, which is printed; out by the engine. Resolves #113",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/122
https://github.com/broadinstitute/gatk/issues/123:144,Integrability,interface,interface,144,"This tool should be a ReadWalker, but because of the way it uses the reference it may require a bit of refactoring to port it to the ReadWalker interface.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/123
https://github.com/broadinstitute/gatk/issues/123:103,Modifiability,refactor,refactoring,103,"This tool should be a ReadWalker, but because of the way it uses the reference it may require a bit of refactoring to port it to the ReadWalker interface.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/123
https://github.com/broadinstitute/gatk/pull/124:178,Modifiability,Extend,Extend,178,"This PR only has a subset of the tools, but I wanted put something out there quickly to get comments and make sure I'm on the right track.; - Created tools.picard subpackage.; - Extend CommandLineProgram with PicardCommandLineProgram.; - Ported the following CLPs, with tests and small test files from Picard:; - AddCommentsToBam; - CleanSam; - CreateSequenceDictionary; - FastqToSam; - MergeBamAlignment; - RevertSam; - SamFormatConverter; - SamToFastq; - ValidateSamFile. Some notes:; - doWork() returns null for most CLPs. The exception is ValidateSam; in Picard, it returns a meaningful exit code (0 if input SAM is valid, 1 if not). Various unit tests were relying on this behavior. For now, I preserved it by returning a boolean.; - MergeBamAlignment actually involves a fair amount of logic, a la MarkDuplicates. It combines an aligned BAM with an unmapped BAM. Its helper classes have been placed in utils.sam.mergealignment. More information can be found there.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/124
https://github.com/broadinstitute/gatk/pull/124:457,Security,Validat,ValidateSamFile,457,"This PR only has a subset of the tools, but I wanted put something out there quickly to get comments and make sure I'm on the right track.; - Created tools.picard subpackage.; - Extend CommandLineProgram with PicardCommandLineProgram.; - Ported the following CLPs, with tests and small test files from Picard:; - AddCommentsToBam; - CleanSam; - CreateSequenceDictionary; - FastqToSam; - MergeBamAlignment; - RevertSam; - SamFormatConverter; - SamToFastq; - ValidateSamFile. Some notes:; - doWork() returns null for most CLPs. The exception is ValidateSam; in Picard, it returns a meaningful exit code (0 if input SAM is valid, 1 if not). Various unit tests were relying on this behavior. For now, I preserved it by returning a boolean.; - MergeBamAlignment actually involves a fair amount of logic, a la MarkDuplicates. It combines an aligned BAM with an unmapped BAM. Its helper classes have been placed in utils.sam.mergealignment. More information can be found there.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/124
https://github.com/broadinstitute/gatk/pull/124:543,Security,Validat,ValidateSam,543,"This PR only has a subset of the tools, but I wanted put something out there quickly to get comments and make sure I'm on the right track.; - Created tools.picard subpackage.; - Extend CommandLineProgram with PicardCommandLineProgram.; - Ported the following CLPs, with tests and small test files from Picard:; - AddCommentsToBam; - CleanSam; - CreateSequenceDictionary; - FastqToSam; - MergeBamAlignment; - RevertSam; - SamFormatConverter; - SamToFastq; - ValidateSamFile. Some notes:; - doWork() returns null for most CLPs. The exception is ValidateSam; in Picard, it returns a meaningful exit code (0 if input SAM is valid, 1 if not). Various unit tests were relying on this behavior. For now, I preserved it by returning a boolean.; - MergeBamAlignment actually involves a fair amount of logic, a la MarkDuplicates. It combines an aligned BAM with an unmapped BAM. Its helper classes have been placed in utils.sam.mergealignment. More information can be found there.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/124
https://github.com/broadinstitute/gatk/pull/124:270,Testability,test,tests,270,"This PR only has a subset of the tools, but I wanted put something out there quickly to get comments and make sure I'm on the right track.; - Created tools.picard subpackage.; - Extend CommandLineProgram with PicardCommandLineProgram.; - Ported the following CLPs, with tests and small test files from Picard:; - AddCommentsToBam; - CleanSam; - CreateSequenceDictionary; - FastqToSam; - MergeBamAlignment; - RevertSam; - SamFormatConverter; - SamToFastq; - ValidateSamFile. Some notes:; - doWork() returns null for most CLPs. The exception is ValidateSam; in Picard, it returns a meaningful exit code (0 if input SAM is valid, 1 if not). Various unit tests were relying on this behavior. For now, I preserved it by returning a boolean.; - MergeBamAlignment actually involves a fair amount of logic, a la MarkDuplicates. It combines an aligned BAM with an unmapped BAM. Its helper classes have been placed in utils.sam.mergealignment. More information can be found there.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/124
https://github.com/broadinstitute/gatk/pull/124:286,Testability,test,test,286,"This PR only has a subset of the tools, but I wanted put something out there quickly to get comments and make sure I'm on the right track.; - Created tools.picard subpackage.; - Extend CommandLineProgram with PicardCommandLineProgram.; - Ported the following CLPs, with tests and small test files from Picard:; - AddCommentsToBam; - CleanSam; - CreateSequenceDictionary; - FastqToSam; - MergeBamAlignment; - RevertSam; - SamFormatConverter; - SamToFastq; - ValidateSamFile. Some notes:; - doWork() returns null for most CLPs. The exception is ValidateSam; in Picard, it returns a meaningful exit code (0 if input SAM is valid, 1 if not). Various unit tests were relying on this behavior. For now, I preserved it by returning a boolean.; - MergeBamAlignment actually involves a fair amount of logic, a la MarkDuplicates. It combines an aligned BAM with an unmapped BAM. Its helper classes have been placed in utils.sam.mergealignment. More information can be found there.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/124
https://github.com/broadinstitute/gatk/pull/124:651,Testability,test,tests,651,"This PR only has a subset of the tools, but I wanted put something out there quickly to get comments and make sure I'm on the right track.; - Created tools.picard subpackage.; - Extend CommandLineProgram with PicardCommandLineProgram.; - Ported the following CLPs, with tests and small test files from Picard:; - AddCommentsToBam; - CleanSam; - CreateSequenceDictionary; - FastqToSam; - MergeBamAlignment; - RevertSam; - SamFormatConverter; - SamToFastq; - ValidateSamFile. Some notes:; - doWork() returns null for most CLPs. The exception is ValidateSam; in Picard, it returns a meaningful exit code (0 if input SAM is valid, 1 if not). Various unit tests were relying on this behavior. For now, I preserved it by returning a boolean.; - MergeBamAlignment actually involves a fair amount of logic, a la MarkDuplicates. It combines an aligned BAM with an unmapped BAM. Its helper classes have been placed in utils.sam.mergealignment. More information can be found there.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/124
https://github.com/broadinstitute/gatk/pull/124:792,Testability,log,logic,792,"This PR only has a subset of the tools, but I wanted put something out there quickly to get comments and make sure I'm on the right track.; - Created tools.picard subpackage.; - Extend CommandLineProgram with PicardCommandLineProgram.; - Ported the following CLPs, with tests and small test files from Picard:; - AddCommentsToBam; - CleanSam; - CreateSequenceDictionary; - FastqToSam; - MergeBamAlignment; - RevertSam; - SamFormatConverter; - SamToFastq; - ValidateSamFile. Some notes:; - doWork() returns null for most CLPs. The exception is ValidateSam; in Picard, it returns a meaningful exit code (0 if input SAM is valid, 1 if not). Various unit tests were relying on this behavior. For now, I preserved it by returning a boolean.; - MergeBamAlignment actually involves a fair amount of logic, a la MarkDuplicates. It combines an aligned BAM with an unmapped BAM. Its helper classes have been placed in utils.sam.mergealignment. More information can be found there.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/124
https://github.com/broadinstitute/gatk/issues/132:89,Usability,simpl,simpleMerge,89,"Currently there are two types of vc merging implemented in GATKVariantContextUtils. One (simpleMerge) is use for combine vcfs whereas the other (referenceConfidenceMerge) is used for combining gvcfs (also regenotyping). Despite differences between these two types of merge it seems that both should share quite a bit of code. Moreover it might be useful to sand away some of the differences as long as they don't change the current default behavior of CombineVariants or GenotypeGVCFs. . For example, why not allow annotation merging using means/medians in CombineVariants as an (advanced) option. Or could GenotypeGVCF bee seen as. first a CombineVariant's simple Merge, followed by a regenotyping and <NON_REF> clearing step?. Also these two functionalities seem to be rather complex as merging VCF's VC is a meaningful manner is not as trivial as it seems as you can see in the code. As a result they are cluttering GATKVCUtils code brining it over 2000 lines. Please consider to move them out to their own helping class or hierarchy.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/132
https://github.com/broadinstitute/gatk/issues/132:658,Usability,simpl,simple,658,"Currently there are two types of vc merging implemented in GATKVariantContextUtils. One (simpleMerge) is use for combine vcfs whereas the other (referenceConfidenceMerge) is used for combining gvcfs (also regenotyping). Despite differences between these two types of merge it seems that both should share quite a bit of code. Moreover it might be useful to sand away some of the differences as long as they don't change the current default behavior of CombineVariants or GenotypeGVCFs. . For example, why not allow annotation merging using means/medians in CombineVariants as an (advanced) option. Or could GenotypeGVCF bee seen as. first a CombineVariant's simple Merge, followed by a regenotyping and <NON_REF> clearing step?. Also these two functionalities seem to be rather complex as merging VCF's VC is a meaningful manner is not as trivial as it seems as you can see in the code. As a result they are cluttering GATKVCUtils code brining it over 2000 lines. Please consider to move them out to their own helping class or hierarchy.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/132
https://github.com/broadinstitute/gatk/issues/132:713,Usability,clear,clearing,713,"Currently there are two types of vc merging implemented in GATKVariantContextUtils. One (simpleMerge) is use for combine vcfs whereas the other (referenceConfidenceMerge) is used for combining gvcfs (also regenotyping). Despite differences between these two types of merge it seems that both should share quite a bit of code. Moreover it might be useful to sand away some of the differences as long as they don't change the current default behavior of CombineVariants or GenotypeGVCFs. . For example, why not allow annotation merging using means/medians in CombineVariants as an (advanced) option. Or could GenotypeGVCF bee seen as. first a CombineVariant's simple Merge, followed by a regenotyping and <NON_REF> clearing step?. Also these two functionalities seem to be rather complex as merging VCF's VC is a meaningful manner is not as trivial as it seems as you can see in the code. As a result they are cluttering GATKVCUtils code brining it over 2000 lines. Please consider to move them out to their own helping class or hierarchy.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/132
https://github.com/broadinstitute/gatk/pull/135:882,Testability,test,test,882,"using jopt-simple to do the actual parsing. Right now it's just been dropped in to handle decomposing the arguments into key->value pairs. . supports short (-h) and long (--help) styles; supports boolean flags with or without an argument; options are now case sensitive. argument collections can be specified with `@ArgumentCollection`; `NestedOptions` removed -> replaced by `ArgumentCollection`. `Option.fullName()` is now respected if specified, if it isn't it defaults to use the field name; `Overrideable` has been removed from `Option`; Arguments must now be uniquely specified (no arguments targeting multiple fields any more) and no redefining existing ones.; The ability to override a specified option is a useful one, so it might need to be reimplemented at some point.; Collection defaults are now replaced rather than appended too. also opportunistically fixed a broken test in `CreateSequenceDictionaryTest`using jopt-simple to do the actual parsing. Right now it's just been dropped in to handle decomposing the arguments into key->value pairs. In future it could also handle more of the argument checking and help formatting. supports short (-h) and long (--help) styles; supports boolean flags with or without an argument; options are now case sensitive. argument collections can be specified with `@ArgumentCollection`; `NestedOptions` removed -> replaced by `ArgumentCollection`. `Option.fullName()` is now respected if specified, if it isn't it defaults to use the field name; `Overrideable` has been removed from `Option`; Arguments must now be uniquely specified (no arguments targeting multiple fields any more) and no redefining existing ones.; The ability to override a specified option is a useful one, so it might need to be reimplemented at some point.; Collection defaults are now replaced rather than appended too. also opportunistically fixed a broken test in `CreateSequenceDictionaryTest`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/135
https://github.com/broadinstitute/gatk/pull/135:1882,Testability,test,test,1882,"using jopt-simple to do the actual parsing. Right now it's just been dropped in to handle decomposing the arguments into key->value pairs. . supports short (-h) and long (--help) styles; supports boolean flags with or without an argument; options are now case sensitive. argument collections can be specified with `@ArgumentCollection`; `NestedOptions` removed -> replaced by `ArgumentCollection`. `Option.fullName()` is now respected if specified, if it isn't it defaults to use the field name; `Overrideable` has been removed from `Option`; Arguments must now be uniquely specified (no arguments targeting multiple fields any more) and no redefining existing ones.; The ability to override a specified option is a useful one, so it might need to be reimplemented at some point.; Collection defaults are now replaced rather than appended too. also opportunistically fixed a broken test in `CreateSequenceDictionaryTest`using jopt-simple to do the actual parsing. Right now it's just been dropped in to handle decomposing the arguments into key->value pairs. In future it could also handle more of the argument checking and help formatting. supports short (-h) and long (--help) styles; supports boolean flags with or without an argument; options are now case sensitive. argument collections can be specified with `@ArgumentCollection`; `NestedOptions` removed -> replaced by `ArgumentCollection`. `Option.fullName()` is now respected if specified, if it isn't it defaults to use the field name; `Overrideable` has been removed from `Option`; Arguments must now be uniquely specified (no arguments targeting multiple fields any more) and no redefining existing ones.; The ability to override a specified option is a useful one, so it might need to be reimplemented at some point.; Collection defaults are now replaced rather than appended too. also opportunistically fixed a broken test in `CreateSequenceDictionaryTest`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/135
https://github.com/broadinstitute/gatk/pull/135:11,Usability,simpl,simple,11,"using jopt-simple to do the actual parsing. Right now it's just been dropped in to handle decomposing the arguments into key->value pairs. . supports short (-h) and long (--help) styles; supports boolean flags with or without an argument; options are now case sensitive. argument collections can be specified with `@ArgumentCollection`; `NestedOptions` removed -> replaced by `ArgumentCollection`. `Option.fullName()` is now respected if specified, if it isn't it defaults to use the field name; `Overrideable` has been removed from `Option`; Arguments must now be uniquely specified (no arguments targeting multiple fields any more) and no redefining existing ones.; The ability to override a specified option is a useful one, so it might need to be reimplemented at some point.; Collection defaults are now replaced rather than appended too. also opportunistically fixed a broken test in `CreateSequenceDictionaryTest`using jopt-simple to do the actual parsing. Right now it's just been dropped in to handle decomposing the arguments into key->value pairs. In future it could also handle more of the argument checking and help formatting. supports short (-h) and long (--help) styles; supports boolean flags with or without an argument; options are now case sensitive. argument collections can be specified with `@ArgumentCollection`; `NestedOptions` removed -> replaced by `ArgumentCollection`. `Option.fullName()` is now respected if specified, if it isn't it defaults to use the field name; `Overrideable` has been removed from `Option`; Arguments must now be uniquely specified (no arguments targeting multiple fields any more) and no redefining existing ones.; The ability to override a specified option is a useful one, so it might need to be reimplemented at some point.; Collection defaults are now replaced rather than appended too. also opportunistically fixed a broken test in `CreateSequenceDictionaryTest`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/135
https://github.com/broadinstitute/gatk/pull/135:931,Usability,simpl,simple,931,"using jopt-simple to do the actual parsing. Right now it's just been dropped in to handle decomposing the arguments into key->value pairs. . supports short (-h) and long (--help) styles; supports boolean flags with or without an argument; options are now case sensitive. argument collections can be specified with `@ArgumentCollection`; `NestedOptions` removed -> replaced by `ArgumentCollection`. `Option.fullName()` is now respected if specified, if it isn't it defaults to use the field name; `Overrideable` has been removed from `Option`; Arguments must now be uniquely specified (no arguments targeting multiple fields any more) and no redefining existing ones.; The ability to override a specified option is a useful one, so it might need to be reimplemented at some point.; Collection defaults are now replaced rather than appended too. also opportunistically fixed a broken test in `CreateSequenceDictionaryTest`using jopt-simple to do the actual parsing. Right now it's just been dropped in to handle decomposing the arguments into key->value pairs. In future it could also handle more of the argument checking and help formatting. supports short (-h) and long (--help) styles; supports boolean flags with or without an argument; options are now case sensitive. argument collections can be specified with `@ArgumentCollection`; `NestedOptions` removed -> replaced by `ArgumentCollection`. `Option.fullName()` is now respected if specified, if it isn't it defaults to use the field name; `Overrideable` has been removed from `Option`; Arguments must now be uniquely specified (no arguments targeting multiple fields any more) and no redefining existing ones.; The ability to override a specified option is a useful one, so it might need to be reimplemented at some point.; Collection defaults are now replaced rather than appended too. also opportunistically fixed a broken test in `CreateSequenceDictionaryTest`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/135
https://github.com/broadinstitute/gatk/pull/136:430,Performance,cache,caches,430,"Some tools need to dynamically resize the reference context window based upon other; input. This commit exposes a setWindow() method to allow tools to do this. -To change the reference context size, tools should invoke setWindow() on the; ReferenceContext provided by the engine before invoking getBases()/getBasesIterator(). -Hopefully eliminates the need for tools to create their own reference readers. -ReferenceContext still caches previous query results, but cache gets invalidated; every time the window size changes. Resolves #131",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/136
https://github.com/broadinstitute/gatk/pull/136:465,Performance,cache,cache,465,"Some tools need to dynamically resize the reference context window based upon other; input. This commit exposes a setWindow() method to allow tools to do this. -To change the reference context size, tools should invoke setWindow() on the; ReferenceContext provided by the engine before invoking getBases()/getBasesIterator(). -Hopefully eliminates the need for tools to create their own reference readers. -ReferenceContext still caches previous query results, but cache gets invalidated; every time the window size changes. Resolves #131",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/136
https://github.com/broadinstitute/gatk/pull/136:104,Security,expose,exposes,104,"Some tools need to dynamically resize the reference context window based upon other; input. This commit exposes a setWindow() method to allow tools to do this. -To change the reference context size, tools should invoke setWindow() on the; ReferenceContext provided by the engine before invoking getBases()/getBasesIterator(). -Hopefully eliminates the need for tools to create their own reference readers. -ReferenceContext still caches previous query results, but cache gets invalidated; every time the window size changes. Resolves #131",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/136
https://github.com/broadinstitute/gatk/issues/137:1266,Testability,test,testNonUniqueSequenceName,1266,The following example fasta file causes an exception if TRUNCATE_NAMES_AT_WHITESPACE is set to false. This option should possibly be removed. ```; > chr1 12lk; ACGTACGT; > chr2 567; TGCATCGA; ```. ```; Caused by: htsjdk.samtools.SAMException: Sequence name contains invalid character: chr1 12lk; at htsjdk.samtools.SAMSequenceRecord.<init>(SAMSequenceRecord.java:85); at org.broadinstitute.hellbender.tools.picard.CreateSequenceDictionary.makeSequenceRecord(CreateSequenceDictionary.java:104); at org.broadinstitute.hellbender.tools.picard.CreateSequenceDictionary.makeSequenceDictionary(CreateSequenceDictionary.java:95); at org.broadinstitute.hellbender.tools.picard.CreateSequenceDictionary.doWork(CreateSequenceDictionary.java:71); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:148); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgram.instanceMain(PicardCommandLineProgram.java:51); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:101); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:108); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:55); at org.broadinstitute.hellbender.tools.picard.CreateSequenceDictionaryTest.testNonUniqueSequenceName(CreateSequenceDictionaryTest.java:50); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:84); at org.testng.internal.Invoker.invokeMethod(Invoker.java:714); ... 24 more; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/137
https://github.com/broadinstitute/gatk/issues/137:1627,Testability,test,testng,1627,The following example fasta file causes an exception if TRUNCATE_NAMES_AT_WHITESPACE is set to false. This option should possibly be removed. ```; > chr1 12lk; ACGTACGT; > chr2 567; TGCATCGA; ```. ```; Caused by: htsjdk.samtools.SAMException: Sequence name contains invalid character: chr1 12lk; at htsjdk.samtools.SAMSequenceRecord.<init>(SAMSequenceRecord.java:85); at org.broadinstitute.hellbender.tools.picard.CreateSequenceDictionary.makeSequenceRecord(CreateSequenceDictionary.java:104); at org.broadinstitute.hellbender.tools.picard.CreateSequenceDictionary.makeSequenceDictionary(CreateSequenceDictionary.java:95); at org.broadinstitute.hellbender.tools.picard.CreateSequenceDictionary.doWork(CreateSequenceDictionary.java:71); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:148); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgram.instanceMain(PicardCommandLineProgram.java:51); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:101); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:108); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:55); at org.broadinstitute.hellbender.tools.picard.CreateSequenceDictionaryTest.testNonUniqueSequenceName(CreateSequenceDictionaryTest.java:50); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:84); at org.testng.internal.Invoker.invokeMethod(Invoker.java:714); ... 24 more; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/137
https://github.com/broadinstitute/gatk/issues/137:1719,Testability,test,testng,1719,The following example fasta file causes an exception if TRUNCATE_NAMES_AT_WHITESPACE is set to false. This option should possibly be removed. ```; > chr1 12lk; ACGTACGT; > chr2 567; TGCATCGA; ```. ```; Caused by: htsjdk.samtools.SAMException: Sequence name contains invalid character: chr1 12lk; at htsjdk.samtools.SAMSequenceRecord.<init>(SAMSequenceRecord.java:85); at org.broadinstitute.hellbender.tools.picard.CreateSequenceDictionary.makeSequenceRecord(CreateSequenceDictionary.java:104); at org.broadinstitute.hellbender.tools.picard.CreateSequenceDictionary.makeSequenceDictionary(CreateSequenceDictionary.java:95); at org.broadinstitute.hellbender.tools.picard.CreateSequenceDictionary.doWork(CreateSequenceDictionary.java:71); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:148); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgram.instanceMain(PicardCommandLineProgram.java:51); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:101); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:108); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:55); at org.broadinstitute.hellbender.tools.picard.CreateSequenceDictionaryTest.testNonUniqueSequenceName(CreateSequenceDictionaryTest.java:50); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:84); at org.testng.internal.Invoker.invokeMethod(Invoker.java:714); ... 24 more; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/137
https://github.com/broadinstitute/gatk/issues/143:251,Availability,error,errors,251,"This is something we got to only in a rather basic way in GATK but is very useful to enable in order to save users from themselves. This would involve three components:. 1) Hard min/max values that correspond to limits beyond which values could cause errors/program failures; violation should throw a User Exception;. 2) Recommended min/max values that correspond to limits beyond which values do not make sense for a given analysis functionality for standard use cases; violation should log a WARN entry. 3) Behavior-disabling value if applicable. Let's say we have an argument that provides a threshold for filtering; and it takes min. 4, max. 20. We may want to set it up so that passing -1 disables the behavior controlled by the argument (so in the filtering case, ""-1"" means ""don't filter at all"") without tripping the min value check. . These should all be accessible to the GATKDoclet (or equivalent) for documentation purposes.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/143
https://github.com/broadinstitute/gatk/issues/143:266,Availability,failure,failures,266,"This is something we got to only in a rather basic way in GATK but is very useful to enable in order to save users from themselves. This would involve three components:. 1) Hard min/max values that correspond to limits beyond which values could cause errors/program failures; violation should throw a User Exception;. 2) Recommended min/max values that correspond to limits beyond which values do not make sense for a given analysis functionality for standard use cases; violation should log a WARN entry. 3) Behavior-disabling value if applicable. Let's say we have an argument that provides a threshold for filtering; and it takes min. 4, max. 20. We may want to set it up so that passing -1 disables the behavior controlled by the argument (so in the filtering case, ""-1"" means ""don't filter at all"") without tripping the min value check. . These should all be accessible to the GATKDoclet (or equivalent) for documentation purposes.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/143
https://github.com/broadinstitute/gatk/issues/143:864,Security,access,accessible,864,"This is something we got to only in a rather basic way in GATK but is very useful to enable in order to save users from themselves. This would involve three components:. 1) Hard min/max values that correspond to limits beyond which values could cause errors/program failures; violation should throw a User Exception;. 2) Recommended min/max values that correspond to limits beyond which values do not make sense for a given analysis functionality for standard use cases; violation should log a WARN entry. 3) Behavior-disabling value if applicable. Let's say we have an argument that provides a threshold for filtering; and it takes min. 4, max. 20. We may want to set it up so that passing -1 disables the behavior controlled by the argument (so in the filtering case, ""-1"" means ""don't filter at all"") without tripping the min value check. . These should all be accessible to the GATKDoclet (or equivalent) for documentation purposes.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/143
https://github.com/broadinstitute/gatk/issues/143:488,Testability,log,log,488,"This is something we got to only in a rather basic way in GATK but is very useful to enable in order to save users from themselves. This would involve three components:. 1) Hard min/max values that correspond to limits beyond which values could cause errors/program failures; violation should throw a User Exception;. 2) Recommended min/max values that correspond to limits beyond which values do not make sense for a given analysis functionality for standard use cases; violation should log a WARN entry. 3) Behavior-disabling value if applicable. Let's say we have an argument that provides a threshold for filtering; and it takes min. 4, max. 20. We may want to set it up so that passing -1 disables the behavior controlled by the argument (so in the filtering case, ""-1"" means ""don't filter at all"") without tripping the min value check. . These should all be accessible to the GATKDoclet (or equivalent) for documentation purposes.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/143
https://github.com/broadinstitute/gatk/issues/144:276,Availability,Down,DownsampleSam,276,Many of the Picard tools we'd like to port have no existing unit tests. We should write them and then backport them to Picard. Let's keep track of them here:. picard.sam:; AddOrReplaceReadGroups; BamIndexStats; BuildBamIndex; CalculateReadGroupChecksum; CheckTerminatorBlock; DownsampleSam; EstimateLibraryComplexity?; FilterReads; FixMateInformation; ReorderSam; ReplaceSamHeader; RevertOriginalBaseQualitiesAndAddMateCigar; SortSam. TODO other packages,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/144
https://github.com/broadinstitute/gatk/issues/144:65,Testability,test,tests,65,Many of the Picard tools we'd like to port have no existing unit tests. We should write them and then backport them to Picard. Let's keep track of them here:. picard.sam:; AddOrReplaceReadGroups; BamIndexStats; BuildBamIndex; CalculateReadGroupChecksum; CheckTerminatorBlock; DownsampleSam; EstimateLibraryComplexity?; FilterReads; FixMateInformation; ReorderSam; ReplaceSamHeader; RevertOriginalBaseQualitiesAndAddMateCigar; SortSam. TODO other packages,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/144
https://github.com/broadinstitute/gatk/issues/145:273,Integrability,wrap,wrappers,273,"Unit tests for tool X should not rely on the behavior of instanceMain or doWork in tool Y. . In particular, unit tests that involve comparing/validating outputs should not reference CLPs like CompareSAMs or ValidateSamFile directly. Instead, these CLPs should just be thin wrappers around other classes that have the actual logic. This is already the case for ValidateSamFile, which is just a wrapper for SamFileValidator in HTSJDK. CompareSAMs should be refactored to match this.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/145
https://github.com/broadinstitute/gatk/issues/145:393,Integrability,wrap,wrapper,393,"Unit tests for tool X should not rely on the behavior of instanceMain or doWork in tool Y. . In particular, unit tests that involve comparing/validating outputs should not reference CLPs like CompareSAMs or ValidateSamFile directly. Instead, these CLPs should just be thin wrappers around other classes that have the actual logic. This is already the case for ValidateSamFile, which is just a wrapper for SamFileValidator in HTSJDK. CompareSAMs should be refactored to match this.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/145
https://github.com/broadinstitute/gatk/issues/145:455,Modifiability,refactor,refactored,455,"Unit tests for tool X should not rely on the behavior of instanceMain or doWork in tool Y. . In particular, unit tests that involve comparing/validating outputs should not reference CLPs like CompareSAMs or ValidateSamFile directly. Instead, these CLPs should just be thin wrappers around other classes that have the actual logic. This is already the case for ValidateSamFile, which is just a wrapper for SamFileValidator in HTSJDK. CompareSAMs should be refactored to match this.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/145
https://github.com/broadinstitute/gatk/issues/145:142,Security,validat,validating,142,"Unit tests for tool X should not rely on the behavior of instanceMain or doWork in tool Y. . In particular, unit tests that involve comparing/validating outputs should not reference CLPs like CompareSAMs or ValidateSamFile directly. Instead, these CLPs should just be thin wrappers around other classes that have the actual logic. This is already the case for ValidateSamFile, which is just a wrapper for SamFileValidator in HTSJDK. CompareSAMs should be refactored to match this.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/145
https://github.com/broadinstitute/gatk/issues/145:207,Security,Validat,ValidateSamFile,207,"Unit tests for tool X should not rely on the behavior of instanceMain or doWork in tool Y. . In particular, unit tests that involve comparing/validating outputs should not reference CLPs like CompareSAMs or ValidateSamFile directly. Instead, these CLPs should just be thin wrappers around other classes that have the actual logic. This is already the case for ValidateSamFile, which is just a wrapper for SamFileValidator in HTSJDK. CompareSAMs should be refactored to match this.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/145
https://github.com/broadinstitute/gatk/issues/145:360,Security,Validat,ValidateSamFile,360,"Unit tests for tool X should not rely on the behavior of instanceMain or doWork in tool Y. . In particular, unit tests that involve comparing/validating outputs should not reference CLPs like CompareSAMs or ValidateSamFile directly. Instead, these CLPs should just be thin wrappers around other classes that have the actual logic. This is already the case for ValidateSamFile, which is just a wrapper for SamFileValidator in HTSJDK. CompareSAMs should be refactored to match this.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/145
https://github.com/broadinstitute/gatk/issues/145:5,Testability,test,tests,5,"Unit tests for tool X should not rely on the behavior of instanceMain or doWork in tool Y. . In particular, unit tests that involve comparing/validating outputs should not reference CLPs like CompareSAMs or ValidateSamFile directly. Instead, these CLPs should just be thin wrappers around other classes that have the actual logic. This is already the case for ValidateSamFile, which is just a wrapper for SamFileValidator in HTSJDK. CompareSAMs should be refactored to match this.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/145
https://github.com/broadinstitute/gatk/issues/145:113,Testability,test,tests,113,"Unit tests for tool X should not rely on the behavior of instanceMain or doWork in tool Y. . In particular, unit tests that involve comparing/validating outputs should not reference CLPs like CompareSAMs or ValidateSamFile directly. Instead, these CLPs should just be thin wrappers around other classes that have the actual logic. This is already the case for ValidateSamFile, which is just a wrapper for SamFileValidator in HTSJDK. CompareSAMs should be refactored to match this.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/145
https://github.com/broadinstitute/gatk/issues/145:324,Testability,log,logic,324,"Unit tests for tool X should not rely on the behavior of instanceMain or doWork in tool Y. . In particular, unit tests that involve comparing/validating outputs should not reference CLPs like CompareSAMs or ValidateSamFile directly. Instead, these CLPs should just be thin wrappers around other classes that have the actual logic. This is already the case for ValidateSamFile, which is just a wrapper for SamFileValidator in HTSJDK. CompareSAMs should be refactored to match this.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/145
https://github.com/broadinstitute/gatk/issues/146:70,Testability,Log,Log,70,"Currently, all GATK tools use log4j and all Picard tools use HTSJDK's Log. We should decide on one of these and use it for everything.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/146
https://github.com/broadinstitute/gatk/issues/147:290,Availability,ERROR,ERROR,290,"(this is mainly relevant for Picard tools, which often have lots of log.info() calls). CommandLineProgram's VERBOSITY is set to INFO by default, which is reasonable when you're actually interacting with a tool, but quickly gets spammy when running unit tests. I propose injecting VERBOSITY=ERROR (the strictest setting) into CommandLineProgramTest to avoid this. This would fix https://github.com/broadinstitute/hellbender/issues/134",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/147
https://github.com/broadinstitute/gatk/issues/147:270,Integrability,inject,injecting,270,"(this is mainly relevant for Picard tools, which often have lots of log.info() calls). CommandLineProgram's VERBOSITY is set to INFO by default, which is reasonable when you're actually interacting with a tool, but quickly gets spammy when running unit tests. I propose injecting VERBOSITY=ERROR (the strictest setting) into CommandLineProgramTest to avoid this. This would fix https://github.com/broadinstitute/hellbender/issues/134",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/147
https://github.com/broadinstitute/gatk/issues/147:351,Safety,avoid,avoid,351,"(this is mainly relevant for Picard tools, which often have lots of log.info() calls). CommandLineProgram's VERBOSITY is set to INFO by default, which is reasonable when you're actually interacting with a tool, but quickly gets spammy when running unit tests. I propose injecting VERBOSITY=ERROR (the strictest setting) into CommandLineProgramTest to avoid this. This would fix https://github.com/broadinstitute/hellbender/issues/134",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/147
https://github.com/broadinstitute/gatk/issues/147:270,Security,inject,injecting,270,"(this is mainly relevant for Picard tools, which often have lots of log.info() calls). CommandLineProgram's VERBOSITY is set to INFO by default, which is reasonable when you're actually interacting with a tool, but quickly gets spammy when running unit tests. I propose injecting VERBOSITY=ERROR (the strictest setting) into CommandLineProgramTest to avoid this. This would fix https://github.com/broadinstitute/hellbender/issues/134",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/147
https://github.com/broadinstitute/gatk/issues/147:68,Testability,log,log,68,"(this is mainly relevant for Picard tools, which often have lots of log.info() calls). CommandLineProgram's VERBOSITY is set to INFO by default, which is reasonable when you're actually interacting with a tool, but quickly gets spammy when running unit tests. I propose injecting VERBOSITY=ERROR (the strictest setting) into CommandLineProgramTest to avoid this. This would fix https://github.com/broadinstitute/hellbender/issues/134",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/147
https://github.com/broadinstitute/gatk/issues/147:253,Testability,test,tests,253,"(this is mainly relevant for Picard tools, which often have lots of log.info() calls). CommandLineProgram's VERBOSITY is set to INFO by default, which is reasonable when you're actually interacting with a tool, but quickly gets spammy when running unit tests. I propose injecting VERBOSITY=ERROR (the strictest setting) into CommandLineProgramTest to avoid this. This would fix https://github.com/broadinstitute/hellbender/issues/134",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/147
https://github.com/broadinstitute/gatk/issues/149:60,Modifiability,inherit,inherited,60,Tools be able to override the behavior of options they have inherited?. How should this work? Should you be able to change a required field to an optional one? Or only the other way around? . If you override the a field that has an `@Option` annotation does it effectively replace it?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/149
https://github.com/broadinstitute/gatk/issues/150:71,Testability,test,tests,71,"there were none in GATK, need to make some in hellbender. include cram tests",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/150
https://github.com/broadinstitute/gatk/pull/156:62,Availability,redundant,redundant,62,"Port the remainder of tools in picard.sam, excluding ViewSam (redundant with PrintReads) and SplitSamByLibrary (see https://github.com/broadinstitute/hellbender/issues/140). . Note that new unit tests will have to be written for some of these tools (see https://github.com/broadinstitute/hellbender/issues/144).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/156
https://github.com/broadinstitute/gatk/pull/156:62,Safety,redund,redundant,62,"Port the remainder of tools in picard.sam, excluding ViewSam (redundant with PrintReads) and SplitSamByLibrary (see https://github.com/broadinstitute/hellbender/issues/140). . Note that new unit tests will have to be written for some of these tools (see https://github.com/broadinstitute/hellbender/issues/144).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/156
https://github.com/broadinstitute/gatk/pull/156:195,Testability,test,tests,195,"Port the remainder of tools in picard.sam, excluding ViewSam (redundant with PrintReads) and SplitSamByLibrary (see https://github.com/broadinstitute/hellbender/issues/140). . Note that new unit tests will have to be written for some of these tools (see https://github.com/broadinstitute/hellbender/issues/144).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/156
https://github.com/broadinstitute/gatk/issues/159:143,Integrability,interface,interface,143,"Currently in Hellbender we have:. GenomeLoc; |-->UnvalidatingGenomeLoc . htsjdk has:; Feature (not conceptually an interval, but it's the same interface as an interval and bed features are nothing but intervals). htsjdk.samtools.QueryInterval -- interval for querying a bam file. htsjdk.samtools.util.Interval -- a named genomic interval, similar to genome loc; |--> Gene; |--> Bait. htsjdk.tribble.index.interval.Interval -- a simple range. We also have the HasGenomeLocation interface which many classes in GATK implement. There's a whole bunch of interval related classes:. We have two different interval trees:; htsjdk.tribble.index.interval.IntervalTree; htsjdk.samtools.util.IntervalTree. a couple of interval utils:; htsjdk.samtools.util.IntervalUtil; org.broadinstitute.hellbender.utils.IntervalUtils",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/159
https://github.com/broadinstitute/gatk/issues/159:477,Integrability,interface,interface,477,"Currently in Hellbender we have:. GenomeLoc; |-->UnvalidatingGenomeLoc . htsjdk has:; Feature (not conceptually an interval, but it's the same interface as an interval and bed features are nothing but intervals). htsjdk.samtools.QueryInterval -- interval for querying a bam file. htsjdk.samtools.util.Interval -- a named genomic interval, similar to genome loc; |--> Gene; |--> Bait. htsjdk.tribble.index.interval.Interval -- a simple range. We also have the HasGenomeLocation interface which many classes in GATK implement. There's a whole bunch of interval related classes:. We have two different interval trees:; htsjdk.tribble.index.interval.IntervalTree; htsjdk.samtools.util.IntervalTree. a couple of interval utils:; htsjdk.samtools.util.IntervalUtil; org.broadinstitute.hellbender.utils.IntervalUtils",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/159
https://github.com/broadinstitute/gatk/issues/159:428,Usability,simpl,simple,428,"Currently in Hellbender we have:. GenomeLoc; |-->UnvalidatingGenomeLoc . htsjdk has:; Feature (not conceptually an interval, but it's the same interface as an interval and bed features are nothing but intervals). htsjdk.samtools.QueryInterval -- interval for querying a bam file. htsjdk.samtools.util.Interval -- a named genomic interval, similar to genome loc; |--> Gene; |--> Bait. htsjdk.tribble.index.interval.Interval -- a simple range. We also have the HasGenomeLocation interface which many classes in GATK implement. There's a whole bunch of interval related classes:. We have two different interval trees:; htsjdk.tribble.index.interval.IntervalTree; htsjdk.samtools.util.IntervalTree. a couple of interval utils:; htsjdk.samtools.util.IntervalUtil; org.broadinstitute.hellbender.utils.IntervalUtils",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/159
https://github.com/broadinstitute/gatk/issues/162:80,Modifiability,refactor,refactor,80,We ported a bunch of code that is marked as deprecated. We should delete it and refactor anything that relies on it.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/162
https://github.com/broadinstitute/gatk/pull/164:149,Integrability,interface,interface,149,I've added an `IntervalArgumentsCollection` which includes all of the interval related arguments. ; It and `SpecialArguments` implement a new marker interface `ArgumentCollectionDefinition`. . ReadWalker has been modified to respect intervals.; Tests for this are in CountReadsTest . This should close #98,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/164
https://github.com/broadinstitute/gatk/pull/164:245,Testability,Test,Tests,245,I've added an `IntervalArgumentsCollection` which includes all of the interval related arguments. ; It and `SpecialArguments` implement a new marker interface `ArgumentCollectionDefinition`. . ReadWalker has been modified to respect intervals.; Tests for this are in CountReadsTest . This should close #98,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/164
https://github.com/broadinstitute/gatk/pull/168:17,Testability,test,tests,17,also fixing some tests that were not actually testing anything in CommandLineParserTest. closes #142,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/168
https://github.com/broadinstitute/gatk/pull/168:46,Testability,test,testing,46,also fixing some tests that were not actually testing anything in CommandLineParserTest. closes #142,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/168
https://github.com/broadinstitute/gatk/issues/169:14,Availability,error,error,14,Currently the error messages are very vague. They should be as specific as possible.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/169
https://github.com/broadinstitute/gatk/issues/169:20,Integrability,message,messages,20,Currently the error messages are very vague. They should be as specific as possible.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/169
https://github.com/broadinstitute/gatk/pull/170:381,Usability,simpl,simple,381,"Currently command line boolean flags can optionally accept an argument. This plays poorly with PositionalArguments in the current version of our parser. . `--flag 1 2` is currently parsed as `(--flag 1) 2` which is then fails; it can be worked around by specifying `--flag true 1 2`, but this is suboptimal. A solution to this has been introduced in the 4.9 snapshot build of jopt-simple see here https://github.com/pholser/jopt-simple/issues/76.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/170
https://github.com/broadinstitute/gatk/pull/170:429,Usability,simpl,simple,429,"Currently command line boolean flags can optionally accept an argument. This plays poorly with PositionalArguments in the current version of our parser. . `--flag 1 2` is currently parsed as `(--flag 1) 2` which is then fails; it can be worked around by specifying `--flag true 1 2`, but this is suboptimal. A solution to this has been introduced in the 4.9 snapshot build of jopt-simple see here https://github.com/pholser/jopt-simple/issues/76.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/170
https://github.com/broadinstitute/gatk/pull/171:390,Availability,ERROR,ERROR,390,"Small PR containing fixes for various issues:; - Move CompareSAMs to picard package (fixes https://github.com/broadinstitute/hellbender/issues/139); - Move most of `CompareSAMs.doWork()` into a separate public method, to be used by external unit tests; - Use HTSJDK's SamFileValidator in assorted unit tests, rather than ValidateSamFile (which is just a CLP wrapper); - Insert `--VERBOSITY ERROR` into CommandLineProgramTest, which suppresses most logging output for CLPs that use HTSJDK-based logging (fixes https://github.com/broadinstitute/hellbender/issues/134)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/171
https://github.com/broadinstitute/gatk/pull/171:358,Integrability,wrap,wrapper,358,"Small PR containing fixes for various issues:; - Move CompareSAMs to picard package (fixes https://github.com/broadinstitute/hellbender/issues/139); - Move most of `CompareSAMs.doWork()` into a separate public method, to be used by external unit tests; - Use HTSJDK's SamFileValidator in assorted unit tests, rather than ValidateSamFile (which is just a CLP wrapper); - Insert `--VERBOSITY ERROR` into CommandLineProgramTest, which suppresses most logging output for CLPs that use HTSJDK-based logging (fixes https://github.com/broadinstitute/hellbender/issues/134)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/171
https://github.com/broadinstitute/gatk/pull/171:321,Security,Validat,ValidateSamFile,321,"Small PR containing fixes for various issues:; - Move CompareSAMs to picard package (fixes https://github.com/broadinstitute/hellbender/issues/139); - Move most of `CompareSAMs.doWork()` into a separate public method, to be used by external unit tests; - Use HTSJDK's SamFileValidator in assorted unit tests, rather than ValidateSamFile (which is just a CLP wrapper); - Insert `--VERBOSITY ERROR` into CommandLineProgramTest, which suppresses most logging output for CLPs that use HTSJDK-based logging (fixes https://github.com/broadinstitute/hellbender/issues/134)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/171
https://github.com/broadinstitute/gatk/pull/171:246,Testability,test,tests,246,"Small PR containing fixes for various issues:; - Move CompareSAMs to picard package (fixes https://github.com/broadinstitute/hellbender/issues/139); - Move most of `CompareSAMs.doWork()` into a separate public method, to be used by external unit tests; - Use HTSJDK's SamFileValidator in assorted unit tests, rather than ValidateSamFile (which is just a CLP wrapper); - Insert `--VERBOSITY ERROR` into CommandLineProgramTest, which suppresses most logging output for CLPs that use HTSJDK-based logging (fixes https://github.com/broadinstitute/hellbender/issues/134)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/171
https://github.com/broadinstitute/gatk/pull/171:302,Testability,test,tests,302,"Small PR containing fixes for various issues:; - Move CompareSAMs to picard package (fixes https://github.com/broadinstitute/hellbender/issues/139); - Move most of `CompareSAMs.doWork()` into a separate public method, to be used by external unit tests; - Use HTSJDK's SamFileValidator in assorted unit tests, rather than ValidateSamFile (which is just a CLP wrapper); - Insert `--VERBOSITY ERROR` into CommandLineProgramTest, which suppresses most logging output for CLPs that use HTSJDK-based logging (fixes https://github.com/broadinstitute/hellbender/issues/134)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/171
https://github.com/broadinstitute/gatk/pull/171:448,Testability,log,logging,448,"Small PR containing fixes for various issues:; - Move CompareSAMs to picard package (fixes https://github.com/broadinstitute/hellbender/issues/139); - Move most of `CompareSAMs.doWork()` into a separate public method, to be used by external unit tests; - Use HTSJDK's SamFileValidator in assorted unit tests, rather than ValidateSamFile (which is just a CLP wrapper); - Insert `--VERBOSITY ERROR` into CommandLineProgramTest, which suppresses most logging output for CLPs that use HTSJDK-based logging (fixes https://github.com/broadinstitute/hellbender/issues/134)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/171
https://github.com/broadinstitute/gatk/pull/171:494,Testability,log,logging,494,"Small PR containing fixes for various issues:; - Move CompareSAMs to picard package (fixes https://github.com/broadinstitute/hellbender/issues/139); - Move most of `CompareSAMs.doWork()` into a separate public method, to be used by external unit tests; - Use HTSJDK's SamFileValidator in assorted unit tests, rather than ValidateSamFile (which is just a CLP wrapper); - Insert `--VERBOSITY ERROR` into CommandLineProgramTest, which suppresses most logging output for CLPs that use HTSJDK-based logging (fixes https://github.com/broadinstitute/hellbender/issues/134)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/171
https://github.com/broadinstitute/gatk/pull/172:0,Deployability,upgrade,upgraded,0,"upgraded from 1.127 to 1.128; removed the local repo entirely, we now have no non-maven dependencies!. there was a small API change so I updated all those files",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/172
https://github.com/broadinstitute/gatk/pull/172:137,Deployability,update,updated,137,"upgraded from 1.127 to 1.128; removed the local repo entirely, we now have no non-maven dependencies!. there was a small API change so I updated all those files",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/172
https://github.com/broadinstitute/gatk/pull/172:88,Integrability,depend,dependencies,88,"upgraded from 1.127 to 1.128; removed the local repo entirely, we now have no non-maven dependencies!. there was a small API change so I updated all those files",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/172
https://github.com/broadinstitute/gatk/pull/174:255,Testability,test,tests,255,deleting a few methods with have been deprecated by java 8. removed `getCigarOperatorForAllBases()`; it is only used in CountReadEvents which isn't coming over. remove getBothReadToLociMappings() which is never used anywhere in hellbender or gatk. adding tests to some trivial methods so coverage looks less bad,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/174
https://github.com/broadinstitute/gatk/issues/175:330,Deployability,patch,patch,330,"Picard style was to have arguments with default collection values be appended to rather than replaced if that argument is also specified on the command line. to remove the defaults you have to specifically pass in `null` and then the new options. this seems like totally bizarre behavior, I thought I had fixed it with my initial patch but it slipped through unchanged. `RevertSam` relies on this functionality, so its interface will need to change slightly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/175
https://github.com/broadinstitute/gatk/issues/175:419,Integrability,interface,interface,419,"Picard style was to have arguments with default collection values be appended to rather than replaced if that argument is also specified on the command line. to remove the defaults you have to specifically pass in `null` and then the new options. this seems like totally bizarre behavior, I thought I had fixed it with my initial patch but it slipped through unchanged. `RevertSam` relies on this functionality, so its interface will need to change slightly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/175
https://github.com/broadinstitute/gatk/pull/179:132,Availability,redundant,redundant,132,I've added back in `ReadTransformer` and `ReadFilter`; I moved the all the default ReadFilters into `ReadFilter` instead of the now redundant `ReadFilters`; The `ReadFilter`s now come pre-negated.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/179
https://github.com/broadinstitute/gatk/pull/179:132,Safety,redund,redundant,132,I've added back in `ReadTransformer` and `ReadFilter`; I moved the all the default ReadFilters into `ReadFilter` instead of the now redundant `ReadFilters`; The `ReadFilter`s now come pre-negated.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/179
https://github.com/broadinstitute/gatk/issues/180:74,Testability,test,tests,74,"MalformedReadFilter should be on by default but that requires fixing some tests. . from @droazen ""Also, there was some level of discontent in the past with the fact that MalformedReadFilter could not be disabled without modifying source code. We should at least provide something like a --disable_all_read_filters argument (assuming we're not going to bother for now with the ability to control read filters in a more fine-grained fashion from the command line).""",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/180
https://github.com/broadinstitute/gatk/issues/182:362,Deployability,update,update,362,"there are comments like:; "" \* java -Xmx4g -jar GenomeAnalysisTK.jar \; - -T BaseRecalibrator \; - -I my_reads.bam \; - -R resources/Homo_sapiens_assembly18.fasta \; - -knownSites bundle/hg18/dbsnp_132.hg18.vcf \; - -knownSites another/optional/setOfSitesToMask.vcf \; - -o recal_data.table"". which are wrong. There needs to be a pass over all usage examples to update them once we settle on the usage.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/182
https://github.com/broadinstitute/gatk/pull/183:727,Modifiability,refactor,refactoring,727,"This fixes several bugs in CompareSAMs, and adds test coverage:; - Bug 1: Program couldn't handle multiple reads with the same read name + start coordinate. To get around this, we add a UniquePrimaryAlignmentKey class and use that. ; - As a consequence of this, some unit tests were incorrect (they relied on the existence of the aforementioned bug). A test file was modified to fix this.; - Bug 2: When comparing unsorted files, if the read names stop being equal at any point, the program would throw an exception. Instead, it should finish but return ""false"".; - Bug 3: The case of queryname-sorted or unsorted inputs were not tested. At all. That counts as a bug, IMO.; - Added unit tests for all these cases. ; - Did some refactoring (I had initially hoped to abstract out the traversal method, but that will have to wait).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/183
https://github.com/broadinstitute/gatk/pull/183:49,Testability,test,test,49,"This fixes several bugs in CompareSAMs, and adds test coverage:; - Bug 1: Program couldn't handle multiple reads with the same read name + start coordinate. To get around this, we add a UniquePrimaryAlignmentKey class and use that. ; - As a consequence of this, some unit tests were incorrect (they relied on the existence of the aforementioned bug). A test file was modified to fix this.; - Bug 2: When comparing unsorted files, if the read names stop being equal at any point, the program would throw an exception. Instead, it should finish but return ""false"".; - Bug 3: The case of queryname-sorted or unsorted inputs were not tested. At all. That counts as a bug, IMO.; - Added unit tests for all these cases. ; - Did some refactoring (I had initially hoped to abstract out the traversal method, but that will have to wait).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/183
https://github.com/broadinstitute/gatk/pull/183:272,Testability,test,tests,272,"This fixes several bugs in CompareSAMs, and adds test coverage:; - Bug 1: Program couldn't handle multiple reads with the same read name + start coordinate. To get around this, we add a UniquePrimaryAlignmentKey class and use that. ; - As a consequence of this, some unit tests were incorrect (they relied on the existence of the aforementioned bug). A test file was modified to fix this.; - Bug 2: When comparing unsorted files, if the read names stop being equal at any point, the program would throw an exception. Instead, it should finish but return ""false"".; - Bug 3: The case of queryname-sorted or unsorted inputs were not tested. At all. That counts as a bug, IMO.; - Added unit tests for all these cases. ; - Did some refactoring (I had initially hoped to abstract out the traversal method, but that will have to wait).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/183
https://github.com/broadinstitute/gatk/pull/183:353,Testability,test,test,353,"This fixes several bugs in CompareSAMs, and adds test coverage:; - Bug 1: Program couldn't handle multiple reads with the same read name + start coordinate. To get around this, we add a UniquePrimaryAlignmentKey class and use that. ; - As a consequence of this, some unit tests were incorrect (they relied on the existence of the aforementioned bug). A test file was modified to fix this.; - Bug 2: When comparing unsorted files, if the read names stop being equal at any point, the program would throw an exception. Instead, it should finish but return ""false"".; - Bug 3: The case of queryname-sorted or unsorted inputs were not tested. At all. That counts as a bug, IMO.; - Added unit tests for all these cases. ; - Did some refactoring (I had initially hoped to abstract out the traversal method, but that will have to wait).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/183
https://github.com/broadinstitute/gatk/pull/183:630,Testability,test,tested,630,"This fixes several bugs in CompareSAMs, and adds test coverage:; - Bug 1: Program couldn't handle multiple reads with the same read name + start coordinate. To get around this, we add a UniquePrimaryAlignmentKey class and use that. ; - As a consequence of this, some unit tests were incorrect (they relied on the existence of the aforementioned bug). A test file was modified to fix this.; - Bug 2: When comparing unsorted files, if the read names stop being equal at any point, the program would throw an exception. Instead, it should finish but return ""false"".; - Bug 3: The case of queryname-sorted or unsorted inputs were not tested. At all. That counts as a bug, IMO.; - Added unit tests for all these cases. ; - Did some refactoring (I had initially hoped to abstract out the traversal method, but that will have to wait).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/183
https://github.com/broadinstitute/gatk/pull/183:687,Testability,test,tests,687,"This fixes several bugs in CompareSAMs, and adds test coverage:; - Bug 1: Program couldn't handle multiple reads with the same read name + start coordinate. To get around this, we add a UniquePrimaryAlignmentKey class and use that. ; - As a consequence of this, some unit tests were incorrect (they relied on the existence of the aforementioned bug). A test file was modified to fix this.; - Bug 2: When comparing unsorted files, if the read names stop being equal at any point, the program would throw an exception. Instead, it should finish but return ""false"".; - Bug 3: The case of queryname-sorted or unsorted inputs were not tested. At all. That counts as a bug, IMO.; - Added unit tests for all these cases. ; - Did some refactoring (I had initially hoped to abstract out the traversal method, but that will have to wait).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/183
https://github.com/broadinstitute/gatk/issues/184:26,Deployability,update,update,26,Figure out how to set and update the version numbers. Git-describe with manually set tags seems like a good start.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/184
https://github.com/broadinstitute/gatk/issues/186:46,Security,Validat,ValidationExclusion,46,FILTER_READS_WITH_N_CIGAR_ARGUMENT_FULL_NAME; ValidationExclusion.TYPE.ALLOW_N_CIGAR_READS. See TODO in MalformedReadFilter::checkCigarIsSupported,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/186
https://github.com/broadinstitute/gatk/issues/187:20,Availability,down,down,20,We're going to trim down to ILLUMINA only for now. We can delete a bunch of code that is for other kinds,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/187
https://github.com/broadinstitute/gatk/issues/190:209,Availability,failure,failures,209,IntegrationTestSpec is hardwired to text files and bam files but compares them byte-by-byte. We need more digested way of comparing files to remove the brittleness of md5 while retaining the ability to notice failures.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/190
https://github.com/broadinstitute/gatk/issues/190:0,Deployability,Integrat,IntegrationTestSpec,0,IntegrationTestSpec is hardwired to text files and bam files but compares them byte-by-byte. We need more digested way of comparing files to remove the brittleness of md5 while retaining the ability to notice failures.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/190
https://github.com/broadinstitute/gatk/issues/190:0,Integrability,Integrat,IntegrationTestSpec,0,IntegrationTestSpec is hardwired to text files and bam files but compares them byte-by-byte. We need more digested way of comparing files to remove the brittleness of md5 while retaining the ability to notice failures.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/190
https://github.com/broadinstitute/gatk/issues/194:37,Testability,test,tests,37,These should each be covered by unit tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/194
https://github.com/broadinstitute/gatk/pull/195:111,Testability,test,tested,111,"`gradle fatJar` will build a new jar build/libs/called hellbender-all-1.0.jar. It seems to work, but I haven't tested it in any systematic way.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/195
https://github.com/broadinstitute/gatk/pull/196:155,Deployability,integrat,integration,155,making the version number depend on the git hash using a gradle git plugin from https://github.com/ajoberstar/gradle-git. It seems like the top gradle-git integration library. There are lots of pre-baked things in it to help with releases and such that we can grow into.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/196
https://github.com/broadinstitute/gatk/pull/196:230,Deployability,release,releases,230,making the version number depend on the git hash using a gradle git plugin from https://github.com/ajoberstar/gradle-git. It seems like the top gradle-git integration library. There are lots of pre-baked things in it to help with releases and such that we can grow into.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/196
https://github.com/broadinstitute/gatk/pull/196:26,Integrability,depend,depend,26,making the version number depend on the git hash using a gradle git plugin from https://github.com/ajoberstar/gradle-git. It seems like the top gradle-git integration library. There are lots of pre-baked things in it to help with releases and such that we can grow into.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/196
https://github.com/broadinstitute/gatk/pull/196:155,Integrability,integrat,integration,155,making the version number depend on the git hash using a gradle git plugin from https://github.com/ajoberstar/gradle-git. It seems like the top gradle-git integration library. There are lots of pre-baked things in it to help with releases and such that we can grow into.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/196
https://github.com/broadinstitute/gatk/pull/196:68,Modifiability,plugin,plugin,68,making the version number depend on the git hash using a gradle git plugin from https://github.com/ajoberstar/gradle-git. It seems like the top gradle-git integration library. There are lots of pre-baked things in it to help with releases and such that we can grow into.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/196
https://github.com/broadinstitute/gatk/pull/196:44,Security,hash,hash,44,making the version number depend on the git hash using a gradle git plugin from https://github.com/ajoberstar/gradle-git. It seems like the top gradle-git integration library. There are lots of pre-baked things in it to help with releases and such that we can grow into.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/196
https://github.com/broadinstitute/gatk/issues/204:29,Testability,test,test,29,the task is to enumerate and test all use cases. Include CRAM tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/204
https://github.com/broadinstitute/gatk/issues/204:62,Testability,test,tests,62,the task is to enumerate and test all use cases. Include CRAM tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/204
https://github.com/broadinstitute/gatk/issues/209:62,Testability,test,tests,62,the task is to enumerate and implement all usecases. add CRAM tests too,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/209
https://github.com/broadinstitute/gatk/issues/211:40,Availability,error,error-prone,40,"Creating test files by hand is tedious, error-prone, and bloats the repo. When writing new tests, we should try to generate test data in-memory where possible. Picard has SamFileTester, which is a wrapper around HTSJDK's SAMRecordSetBuilder. GATK has ArtificialSAMUtils. SamFileTester/SAMRecordSetBuilder is only used in a few places (e.g. MarkDuplicates), whereas ArtificialSAMUtils is heavily used, so I would say stick with the latter.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/211
https://github.com/broadinstitute/gatk/issues/211:197,Integrability,wrap,wrapper,197,"Creating test files by hand is tedious, error-prone, and bloats the repo. When writing new tests, we should try to generate test data in-memory where possible. Picard has SamFileTester, which is a wrapper around HTSJDK's SAMRecordSetBuilder. GATK has ArtificialSAMUtils. SamFileTester/SAMRecordSetBuilder is only used in a few places (e.g. MarkDuplicates), whereas ArtificialSAMUtils is heavily used, so I would say stick with the latter.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/211
https://github.com/broadinstitute/gatk/issues/211:9,Testability,test,test,9,"Creating test files by hand is tedious, error-prone, and bloats the repo. When writing new tests, we should try to generate test data in-memory where possible. Picard has SamFileTester, which is a wrapper around HTSJDK's SAMRecordSetBuilder. GATK has ArtificialSAMUtils. SamFileTester/SAMRecordSetBuilder is only used in a few places (e.g. MarkDuplicates), whereas ArtificialSAMUtils is heavily used, so I would say stick with the latter.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/211
https://github.com/broadinstitute/gatk/issues/211:91,Testability,test,tests,91,"Creating test files by hand is tedious, error-prone, and bloats the repo. When writing new tests, we should try to generate test data in-memory where possible. Picard has SamFileTester, which is a wrapper around HTSJDK's SAMRecordSetBuilder. GATK has ArtificialSAMUtils. SamFileTester/SAMRecordSetBuilder is only used in a few places (e.g. MarkDuplicates), whereas ArtificialSAMUtils is heavily used, so I would say stick with the latter.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/211
https://github.com/broadinstitute/gatk/issues/211:124,Testability,test,test,124,"Creating test files by hand is tedious, error-prone, and bloats the repo. When writing new tests, we should try to generate test data in-memory where possible. Picard has SamFileTester, which is a wrapper around HTSJDK's SAMRecordSetBuilder. GATK has ArtificialSAMUtils. SamFileTester/SAMRecordSetBuilder is only used in a few places (e.g. MarkDuplicates), whereas ArtificialSAMUtils is heavily used, so I would say stick with the latter.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/211
https://github.com/broadinstitute/gatk/issues/215:72,Availability,down,down,72,There are many useful utilities in there. Some of them should be pushed down to HTSJDK; some of them should be moved to Hellbender; and some of them are redundant with existing GATK utilities (e.g. MathUtil) and should be combined or skipped as necessary.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/215
https://github.com/broadinstitute/gatk/issues/215:153,Availability,redundant,redundant,153,There are many useful utilities in there. Some of them should be pushed down to HTSJDK; some of them should be moved to Hellbender; and some of them are redundant with existing GATK utilities (e.g. MathUtil) and should be combined or skipped as necessary.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/215
https://github.com/broadinstitute/gatk/issues/215:153,Safety,redund,redundant,153,There are many useful utilities in there. Some of them should be pushed down to HTSJDK; some of them should be moved to Hellbender; and some of them are redundant with existing GATK utilities (e.g. MathUtil) and should be combined or skipped as necessary.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/215
https://github.com/broadinstitute/gatk/issues/216:5,Availability,ERROR,ERROR,5,"```; ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console.; ```. shows up at the top of every run, we should fix this",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/216
https://github.com/broadinstitute/gatk/issues/216:102,Availability,error,errors,102,"```; ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console.; ```. shows up at the top of every run, we should fix this",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/216
https://github.com/broadinstitute/gatk/issues/216:34,Deployability,configurat,configuration,34,"```; ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console.; ```. shows up at the top of every run, we should fix this",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/216
https://github.com/broadinstitute/gatk/issues/216:74,Deployability,configurat,configuration,74,"```; ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console.; ```. shows up at the top of every run, we should fix this",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/216
https://github.com/broadinstitute/gatk/issues/216:34,Modifiability,config,configuration,34,"```; ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console.; ```. shows up at the top of every run, we should fix this",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/216
https://github.com/broadinstitute/gatk/issues/216:74,Modifiability,config,configuration,74,"```; ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console.; ```. shows up at the top of every run, we should fix this",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/216
https://github.com/broadinstitute/gatk/issues/216:89,Testability,log,logging,89,"```; ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console.; ```. shows up at the top of every run, we should fix this",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/216
https://github.com/broadinstitute/gatk/pull/217:20,Availability,failure,failures,20,This should fix the failures.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/217
https://github.com/broadinstitute/gatk/issues/221:615,Deployability,install,installing,615,"currently the travis build is at ~10minutes. There are several options, and we should probably do all of them:; 1. Speedup individual tests:; The top offenders are:; `SplitNCigarReadsIntegrationTest`: this 1 test takes a minute, we can probably do something about this; `MarkDuplicatesIntegrationTest`: 56 tests each taking ~1 second, unclear what we could do; `AnalyzeCovariatesIntegrationTests` 13 tests taking ~40 seconds. Some take longer than others, not sure what we can do about these; `CachingIndexedFastaSequenceFileUnitTest` 21 tests taking a minute. Lets push this to htsjdk.; 2. We lose several minutes installing R libraries (2-3). We could parallelize our travis build and split it into 2 builds, so that 1 branch of the build installs R libraries and then runs the tests that depend on those, and the other branch runs all the other tests. This would probably make the R installation effectively free provided we have sufficient worker nodes.; 3. Run tests in parallel. Travis gives us more than 1 core. I tested running with cores set to 2, and the actual test time dropped nearly in half.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/221
https://github.com/broadinstitute/gatk/issues/221:741,Deployability,install,installs,741,"currently the travis build is at ~10minutes. There are several options, and we should probably do all of them:; 1. Speedup individual tests:; The top offenders are:; `SplitNCigarReadsIntegrationTest`: this 1 test takes a minute, we can probably do something about this; `MarkDuplicatesIntegrationTest`: 56 tests each taking ~1 second, unclear what we could do; `AnalyzeCovariatesIntegrationTests` 13 tests taking ~40 seconds. Some take longer than others, not sure what we can do about these; `CachingIndexedFastaSequenceFileUnitTest` 21 tests taking a minute. Lets push this to htsjdk.; 2. We lose several minutes installing R libraries (2-3). We could parallelize our travis build and split it into 2 builds, so that 1 branch of the build installs R libraries and then runs the tests that depend on those, and the other branch runs all the other tests. This would probably make the R installation effectively free provided we have sufficient worker nodes.; 3. Run tests in parallel. Travis gives us more than 1 core. I tested running with cores set to 2, and the actual test time dropped nearly in half.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/221
https://github.com/broadinstitute/gatk/issues/221:886,Deployability,install,installation,886,"currently the travis build is at ~10minutes. There are several options, and we should probably do all of them:; 1. Speedup individual tests:; The top offenders are:; `SplitNCigarReadsIntegrationTest`: this 1 test takes a minute, we can probably do something about this; `MarkDuplicatesIntegrationTest`: 56 tests each taking ~1 second, unclear what we could do; `AnalyzeCovariatesIntegrationTests` 13 tests taking ~40 seconds. Some take longer than others, not sure what we can do about these; `CachingIndexedFastaSequenceFileUnitTest` 21 tests taking a minute. Lets push this to htsjdk.; 2. We lose several minutes installing R libraries (2-3). We could parallelize our travis build and split it into 2 builds, so that 1 branch of the build installs R libraries and then runs the tests that depend on those, and the other branch runs all the other tests. This would probably make the R installation effectively free provided we have sufficient worker nodes.; 3. Run tests in parallel. Travis gives us more than 1 core. I tested running with cores set to 2, and the actual test time dropped nearly in half.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/221
https://github.com/broadinstitute/gatk/issues/221:791,Integrability,depend,depend,791,"currently the travis build is at ~10minutes. There are several options, and we should probably do all of them:; 1. Speedup individual tests:; The top offenders are:; `SplitNCigarReadsIntegrationTest`: this 1 test takes a minute, we can probably do something about this; `MarkDuplicatesIntegrationTest`: 56 tests each taking ~1 second, unclear what we could do; `AnalyzeCovariatesIntegrationTests` 13 tests taking ~40 seconds. Some take longer than others, not sure what we can do about these; `CachingIndexedFastaSequenceFileUnitTest` 21 tests taking a minute. Lets push this to htsjdk.; 2. We lose several minutes installing R libraries (2-3). We could parallelize our travis build and split it into 2 builds, so that 1 branch of the build installs R libraries and then runs the tests that depend on those, and the other branch runs all the other tests. This would probably make the R installation effectively free provided we have sufficient worker nodes.; 3. Run tests in parallel. Travis gives us more than 1 core. I tested running with cores set to 2, and the actual test time dropped nearly in half.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/221
https://github.com/broadinstitute/gatk/issues/221:134,Testability,test,tests,134,"currently the travis build is at ~10minutes. There are several options, and we should probably do all of them:; 1. Speedup individual tests:; The top offenders are:; `SplitNCigarReadsIntegrationTest`: this 1 test takes a minute, we can probably do something about this; `MarkDuplicatesIntegrationTest`: 56 tests each taking ~1 second, unclear what we could do; `AnalyzeCovariatesIntegrationTests` 13 tests taking ~40 seconds. Some take longer than others, not sure what we can do about these; `CachingIndexedFastaSequenceFileUnitTest` 21 tests taking a minute. Lets push this to htsjdk.; 2. We lose several minutes installing R libraries (2-3). We could parallelize our travis build and split it into 2 builds, so that 1 branch of the build installs R libraries and then runs the tests that depend on those, and the other branch runs all the other tests. This would probably make the R installation effectively free provided we have sufficient worker nodes.; 3. Run tests in parallel. Travis gives us more than 1 core. I tested running with cores set to 2, and the actual test time dropped nearly in half.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/221
https://github.com/broadinstitute/gatk/issues/221:208,Testability,test,test,208,"currently the travis build is at ~10minutes. There are several options, and we should probably do all of them:; 1. Speedup individual tests:; The top offenders are:; `SplitNCigarReadsIntegrationTest`: this 1 test takes a minute, we can probably do something about this; `MarkDuplicatesIntegrationTest`: 56 tests each taking ~1 second, unclear what we could do; `AnalyzeCovariatesIntegrationTests` 13 tests taking ~40 seconds. Some take longer than others, not sure what we can do about these; `CachingIndexedFastaSequenceFileUnitTest` 21 tests taking a minute. Lets push this to htsjdk.; 2. We lose several minutes installing R libraries (2-3). We could parallelize our travis build and split it into 2 builds, so that 1 branch of the build installs R libraries and then runs the tests that depend on those, and the other branch runs all the other tests. This would probably make the R installation effectively free provided we have sufficient worker nodes.; 3. Run tests in parallel. Travis gives us more than 1 core. I tested running with cores set to 2, and the actual test time dropped nearly in half.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/221
https://github.com/broadinstitute/gatk/issues/221:306,Testability,test,tests,306,"currently the travis build is at ~10minutes. There are several options, and we should probably do all of them:; 1. Speedup individual tests:; The top offenders are:; `SplitNCigarReadsIntegrationTest`: this 1 test takes a minute, we can probably do something about this; `MarkDuplicatesIntegrationTest`: 56 tests each taking ~1 second, unclear what we could do; `AnalyzeCovariatesIntegrationTests` 13 tests taking ~40 seconds. Some take longer than others, not sure what we can do about these; `CachingIndexedFastaSequenceFileUnitTest` 21 tests taking a minute. Lets push this to htsjdk.; 2. We lose several minutes installing R libraries (2-3). We could parallelize our travis build and split it into 2 builds, so that 1 branch of the build installs R libraries and then runs the tests that depend on those, and the other branch runs all the other tests. This would probably make the R installation effectively free provided we have sufficient worker nodes.; 3. Run tests in parallel. Travis gives us more than 1 core. I tested running with cores set to 2, and the actual test time dropped nearly in half.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/221
https://github.com/broadinstitute/gatk/issues/221:400,Testability,test,tests,400,"currently the travis build is at ~10minutes. There are several options, and we should probably do all of them:; 1. Speedup individual tests:; The top offenders are:; `SplitNCigarReadsIntegrationTest`: this 1 test takes a minute, we can probably do something about this; `MarkDuplicatesIntegrationTest`: 56 tests each taking ~1 second, unclear what we could do; `AnalyzeCovariatesIntegrationTests` 13 tests taking ~40 seconds. Some take longer than others, not sure what we can do about these; `CachingIndexedFastaSequenceFileUnitTest` 21 tests taking a minute. Lets push this to htsjdk.; 2. We lose several minutes installing R libraries (2-3). We could parallelize our travis build and split it into 2 builds, so that 1 branch of the build installs R libraries and then runs the tests that depend on those, and the other branch runs all the other tests. This would probably make the R installation effectively free provided we have sufficient worker nodes.; 3. Run tests in parallel. Travis gives us more than 1 core. I tested running with cores set to 2, and the actual test time dropped nearly in half.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/221
https://github.com/broadinstitute/gatk/issues/221:538,Testability,test,tests,538,"currently the travis build is at ~10minutes. There are several options, and we should probably do all of them:; 1. Speedup individual tests:; The top offenders are:; `SplitNCigarReadsIntegrationTest`: this 1 test takes a minute, we can probably do something about this; `MarkDuplicatesIntegrationTest`: 56 tests each taking ~1 second, unclear what we could do; `AnalyzeCovariatesIntegrationTests` 13 tests taking ~40 seconds. Some take longer than others, not sure what we can do about these; `CachingIndexedFastaSequenceFileUnitTest` 21 tests taking a minute. Lets push this to htsjdk.; 2. We lose several minutes installing R libraries (2-3). We could parallelize our travis build and split it into 2 builds, so that 1 branch of the build installs R libraries and then runs the tests that depend on those, and the other branch runs all the other tests. This would probably make the R installation effectively free provided we have sufficient worker nodes.; 3. Run tests in parallel. Travis gives us more than 1 core. I tested running with cores set to 2, and the actual test time dropped nearly in half.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/221
https://github.com/broadinstitute/gatk/issues/221:780,Testability,test,tests,780,"currently the travis build is at ~10minutes. There are several options, and we should probably do all of them:; 1. Speedup individual tests:; The top offenders are:; `SplitNCigarReadsIntegrationTest`: this 1 test takes a minute, we can probably do something about this; `MarkDuplicatesIntegrationTest`: 56 tests each taking ~1 second, unclear what we could do; `AnalyzeCovariatesIntegrationTests` 13 tests taking ~40 seconds. Some take longer than others, not sure what we can do about these; `CachingIndexedFastaSequenceFileUnitTest` 21 tests taking a minute. Lets push this to htsjdk.; 2. We lose several minutes installing R libraries (2-3). We could parallelize our travis build and split it into 2 builds, so that 1 branch of the build installs R libraries and then runs the tests that depend on those, and the other branch runs all the other tests. This would probably make the R installation effectively free provided we have sufficient worker nodes.; 3. Run tests in parallel. Travis gives us more than 1 core. I tested running with cores set to 2, and the actual test time dropped nearly in half.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/221
https://github.com/broadinstitute/gatk/issues/221:848,Testability,test,tests,848,"currently the travis build is at ~10minutes. There are several options, and we should probably do all of them:; 1. Speedup individual tests:; The top offenders are:; `SplitNCigarReadsIntegrationTest`: this 1 test takes a minute, we can probably do something about this; `MarkDuplicatesIntegrationTest`: 56 tests each taking ~1 second, unclear what we could do; `AnalyzeCovariatesIntegrationTests` 13 tests taking ~40 seconds. Some take longer than others, not sure what we can do about these; `CachingIndexedFastaSequenceFileUnitTest` 21 tests taking a minute. Lets push this to htsjdk.; 2. We lose several minutes installing R libraries (2-3). We could parallelize our travis build and split it into 2 builds, so that 1 branch of the build installs R libraries and then runs the tests that depend on those, and the other branch runs all the other tests. This would probably make the R installation effectively free provided we have sufficient worker nodes.; 3. Run tests in parallel. Travis gives us more than 1 core. I tested running with cores set to 2, and the actual test time dropped nearly in half.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/221
https://github.com/broadinstitute/gatk/issues/221:966,Testability,test,tests,966,"currently the travis build is at ~10minutes. There are several options, and we should probably do all of them:; 1. Speedup individual tests:; The top offenders are:; `SplitNCigarReadsIntegrationTest`: this 1 test takes a minute, we can probably do something about this; `MarkDuplicatesIntegrationTest`: 56 tests each taking ~1 second, unclear what we could do; `AnalyzeCovariatesIntegrationTests` 13 tests taking ~40 seconds. Some take longer than others, not sure what we can do about these; `CachingIndexedFastaSequenceFileUnitTest` 21 tests taking a minute. Lets push this to htsjdk.; 2. We lose several minutes installing R libraries (2-3). We could parallelize our travis build and split it into 2 builds, so that 1 branch of the build installs R libraries and then runs the tests that depend on those, and the other branch runs all the other tests. This would probably make the R installation effectively free provided we have sufficient worker nodes.; 3. Run tests in parallel. Travis gives us more than 1 core. I tested running with cores set to 2, and the actual test time dropped nearly in half.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/221
https://github.com/broadinstitute/gatk/issues/221:1021,Testability,test,tested,1021,"currently the travis build is at ~10minutes. There are several options, and we should probably do all of them:; 1. Speedup individual tests:; The top offenders are:; `SplitNCigarReadsIntegrationTest`: this 1 test takes a minute, we can probably do something about this; `MarkDuplicatesIntegrationTest`: 56 tests each taking ~1 second, unclear what we could do; `AnalyzeCovariatesIntegrationTests` 13 tests taking ~40 seconds. Some take longer than others, not sure what we can do about these; `CachingIndexedFastaSequenceFileUnitTest` 21 tests taking a minute. Lets push this to htsjdk.; 2. We lose several minutes installing R libraries (2-3). We could parallelize our travis build and split it into 2 builds, so that 1 branch of the build installs R libraries and then runs the tests that depend on those, and the other branch runs all the other tests. This would probably make the R installation effectively free provided we have sufficient worker nodes.; 3. Run tests in parallel. Travis gives us more than 1 core. I tested running with cores set to 2, and the actual test time dropped nearly in half.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/221
https://github.com/broadinstitute/gatk/issues/221:1072,Testability,test,test,1072,"currently the travis build is at ~10minutes. There are several options, and we should probably do all of them:; 1. Speedup individual tests:; The top offenders are:; `SplitNCigarReadsIntegrationTest`: this 1 test takes a minute, we can probably do something about this; `MarkDuplicatesIntegrationTest`: 56 tests each taking ~1 second, unclear what we could do; `AnalyzeCovariatesIntegrationTests` 13 tests taking ~40 seconds. Some take longer than others, not sure what we can do about these; `CachingIndexedFastaSequenceFileUnitTest` 21 tests taking a minute. Lets push this to htsjdk.; 2. We lose several minutes installing R libraries (2-3). We could parallelize our travis build and split it into 2 builds, so that 1 branch of the build installs R libraries and then runs the tests that depend on those, and the other branch runs all the other tests. This would probably make the R installation effectively free provided we have sufficient worker nodes.; 3. Run tests in parallel. Travis gives us more than 1 core. I tested running with cores set to 2, and the actual test time dropped nearly in half.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/221
https://github.com/broadinstitute/gatk/issues/222:90,Deployability,install,installed,90,"Should we add this to the gradle build? Unit test require R and various R libraries to be installed, but this isn't mentioned in the documentation or performed by the build script. . I suggest we ; 1. tag all tests that require R in some way so that they can be disabled a system that doesn't have R; 2. add documentation to the readme explaining you need R and a number of r libraries; 3. either document that you must run install_R_packages.R or have gradle do it",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/222
https://github.com/broadinstitute/gatk/issues/222:150,Performance,perform,performed,150,"Should we add this to the gradle build? Unit test require R and various R libraries to be installed, but this isn't mentioned in the documentation or performed by the build script. . I suggest we ; 1. tag all tests that require R in some way so that they can be disabled a system that doesn't have R; 2. add documentation to the readme explaining you need R and a number of r libraries; 3. either document that you must run install_R_packages.R or have gradle do it",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/222
https://github.com/broadinstitute/gatk/issues/222:45,Testability,test,test,45,"Should we add this to the gradle build? Unit test require R and various R libraries to be installed, but this isn't mentioned in the documentation or performed by the build script. . I suggest we ; 1. tag all tests that require R in some way so that they can be disabled a system that doesn't have R; 2. add documentation to the readme explaining you need R and a number of r libraries; 3. either document that you must run install_R_packages.R or have gradle do it",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/222
https://github.com/broadinstitute/gatk/issues/222:209,Testability,test,tests,209,"Should we add this to the gradle build? Unit test require R and various R libraries to be installed, but this isn't mentioned in the documentation or performed by the build script. . I suggest we ; 1. tag all tests that require R in some way so that they can be disabled a system that doesn't have R; 2. add documentation to the readme explaining you need R and a number of r libraries; 3. either document that you must run install_R_packages.R or have gradle do it",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/222
https://github.com/broadinstitute/gatk/issues/223:117,Availability,error,errors,117,"Currently it just tells you that an R script exited with value 1. This is totally worthless, it should tell you what errors it actually failed with.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/223
https://github.com/broadinstitute/gatk/pull/224:343,Integrability,interface,interface,343,"Replicates most of the functionality of the old ROD system in ~5% of the; code. The incomprehensible tangle of nested iterators, bindings, views, states,; tracks, trackers, builders etc., etc., is gone, replaced by about 4 core classes:; FeatureContext, FeatureDataSource, FeatureInput, and FeatureManager. FeatureContext: This is tool-facing interface (replaces RefMetaDataTracker).; Allows particular sources of Features to be queried. FeatureDataSource: Handles the low-level details of querying a source of Features.; Uses a caching scheme optimized for the use case of queries over; intervals with gradually increasing start/stop positions. FeatureInput: This is used to declare Feature arguments in tools (replaces RodBinding).; The engine discovers all FeatureInput arguments declared in the tool's class; hierarchy, and initializes data sources for each one that was specified; on the command line. FeatureManager: Manages the pool of data sources, as well as codec and file format; discovery and type checking. -ReadWalker interface has changed: apply() now takes a FeatureContext argument; (will be null if there are no sources of Features). -Included an example tool PrintReadsWithVariants to demonstrate use of the new; ReadWalker interface. -Since Feature files must be indexed in order to query them, I have provided a; tool IndexFeatureFile that can index any Feature-containing file. -Made required changes to the argument-parsing system. Feature argument discovery; is as de-coupled as possible from the main arg parser. -Made required changes to BQSR, and eliminated the temporary HACKRefMetaDataTracker. -Comprehensive tests",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/224
https://github.com/broadinstitute/gatk/pull/224:1032,Integrability,interface,interface,1032,"Replicates most of the functionality of the old ROD system in ~5% of the; code. The incomprehensible tangle of nested iterators, bindings, views, states,; tracks, trackers, builders etc., etc., is gone, replaced by about 4 core classes:; FeatureContext, FeatureDataSource, FeatureInput, and FeatureManager. FeatureContext: This is tool-facing interface (replaces RefMetaDataTracker).; Allows particular sources of Features to be queried. FeatureDataSource: Handles the low-level details of querying a source of Features.; Uses a caching scheme optimized for the use case of queries over; intervals with gradually increasing start/stop positions. FeatureInput: This is used to declare Feature arguments in tools (replaces RodBinding).; The engine discovers all FeatureInput arguments declared in the tool's class; hierarchy, and initializes data sources for each one that was specified; on the command line. FeatureManager: Manages the pool of data sources, as well as codec and file format; discovery and type checking. -ReadWalker interface has changed: apply() now takes a FeatureContext argument; (will be null if there are no sources of Features). -Included an example tool PrintReadsWithVariants to demonstrate use of the new; ReadWalker interface. -Since Feature files must be indexed in order to query them, I have provided a; tool IndexFeatureFile that can index any Feature-containing file. -Made required changes to the argument-parsing system. Feature argument discovery; is as de-coupled as possible from the main arg parser. -Made required changes to BQSR, and eliminated the temporary HACKRefMetaDataTracker. -Comprehensive tests",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/224
https://github.com/broadinstitute/gatk/pull/224:1243,Integrability,interface,interface,1243,"Replicates most of the functionality of the old ROD system in ~5% of the; code. The incomprehensible tangle of nested iterators, bindings, views, states,; tracks, trackers, builders etc., etc., is gone, replaced by about 4 core classes:; FeatureContext, FeatureDataSource, FeatureInput, and FeatureManager. FeatureContext: This is tool-facing interface (replaces RefMetaDataTracker).; Allows particular sources of Features to be queried. FeatureDataSource: Handles the low-level details of querying a source of Features.; Uses a caching scheme optimized for the use case of queries over; intervals with gradually increasing start/stop positions. FeatureInput: This is used to declare Feature arguments in tools (replaces RodBinding).; The engine discovers all FeatureInput arguments declared in the tool's class; hierarchy, and initializes data sources for each one that was specified; on the command line. FeatureManager: Manages the pool of data sources, as well as codec and file format; discovery and type checking. -ReadWalker interface has changed: apply() now takes a FeatureContext argument; (will be null if there are no sources of Features). -Included an example tool PrintReadsWithVariants to demonstrate use of the new; ReadWalker interface. -Since Feature files must be indexed in order to query them, I have provided a; tool IndexFeatureFile that can index any Feature-containing file. -Made required changes to the argument-parsing system. Feature argument discovery; is as de-coupled as possible from the main arg parser. -Made required changes to BQSR, and eliminated the temporary HACKRefMetaDataTracker. -Comprehensive tests",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/224
https://github.com/broadinstitute/gatk/pull/224:544,Performance,optimiz,optimized,544,"Replicates most of the functionality of the old ROD system in ~5% of the; code. The incomprehensible tangle of nested iterators, bindings, views, states,; tracks, trackers, builders etc., etc., is gone, replaced by about 4 core classes:; FeatureContext, FeatureDataSource, FeatureInput, and FeatureManager. FeatureContext: This is tool-facing interface (replaces RefMetaDataTracker).; Allows particular sources of Features to be queried. FeatureDataSource: Handles the low-level details of querying a source of Features.; Uses a caching scheme optimized for the use case of queries over; intervals with gradually increasing start/stop positions. FeatureInput: This is used to declare Feature arguments in tools (replaces RodBinding).; The engine discovers all FeatureInput arguments declared in the tool's class; hierarchy, and initializes data sources for each one that was specified; on the command line. FeatureManager: Manages the pool of data sources, as well as codec and file format; discovery and type checking. -ReadWalker interface has changed: apply() now takes a FeatureContext argument; (will be null if there are no sources of Features). -Included an example tool PrintReadsWithVariants to demonstrate use of the new; ReadWalker interface. -Since Feature files must be indexed in order to query them, I have provided a; tool IndexFeatureFile that can index any Feature-containing file. -Made required changes to the argument-parsing system. Feature argument discovery; is as de-coupled as possible from the main arg parser. -Made required changes to BQSR, and eliminated the temporary HACKRefMetaDataTracker. -Comprehensive tests",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/224
https://github.com/broadinstitute/gatk/pull/224:1638,Testability,test,tests,1638,"Replicates most of the functionality of the old ROD system in ~5% of the; code. The incomprehensible tangle of nested iterators, bindings, views, states,; tracks, trackers, builders etc., etc., is gone, replaced by about 4 core classes:; FeatureContext, FeatureDataSource, FeatureInput, and FeatureManager. FeatureContext: This is tool-facing interface (replaces RefMetaDataTracker).; Allows particular sources of Features to be queried. FeatureDataSource: Handles the low-level details of querying a source of Features.; Uses a caching scheme optimized for the use case of queries over; intervals with gradually increasing start/stop positions. FeatureInput: This is used to declare Feature arguments in tools (replaces RodBinding).; The engine discovers all FeatureInput arguments declared in the tool's class; hierarchy, and initializes data sources for each one that was specified; on the command line. FeatureManager: Manages the pool of data sources, as well as codec and file format; discovery and type checking. -ReadWalker interface has changed: apply() now takes a FeatureContext argument; (will be null if there are no sources of Features). -Included an example tool PrintReadsWithVariants to demonstrate use of the new; ReadWalker interface. -Since Feature files must be indexed in order to query them, I have provided a; tool IndexFeatureFile that can index any Feature-containing file. -Made required changes to the argument-parsing system. Feature argument discovery; is as de-coupled as possible from the main arg parser. -Made required changes to BQSR, and eliminated the temporary HACKRefMetaDataTracker. -Comprehensive tests",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/224
https://github.com/broadinstitute/gatk/issues/225:125,Integrability,depend,depends,125,"Some annotations may use as input some other annotations. In this case the former's code should be applied after the all the depends have been applied. For example QD uses AD and if not present defaults into other sources to determine the read-depth. It can be the case that QD is applied before AD an in the resulting output these two are inconsistent. . In this case if AD is to be annotated, this should take place before QD is annotated to avoid inconsistencies depending of request list order. . Here we may consider either to fail if the dependences are not in the list of requested annotations or force the application of those given the list of requested annotations. Non requested annotations could be subsequently stripped from the final output (perhaps this should be explicitly requested by the user). We could use Java @Annotations to indicate depends between variant annotations (e.g. listing reference to the annotion class object).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/225
https://github.com/broadinstitute/gatk/issues/225:466,Integrability,depend,depending,466,"Some annotations may use as input some other annotations. In this case the former's code should be applied after the all the depends have been applied. For example QD uses AD and if not present defaults into other sources to determine the read-depth. It can be the case that QD is applied before AD an in the resulting output these two are inconsistent. . In this case if AD is to be annotated, this should take place before QD is annotated to avoid inconsistencies depending of request list order. . Here we may consider either to fail if the dependences are not in the list of requested annotations or force the application of those given the list of requested annotations. Non requested annotations could be subsequently stripped from the final output (perhaps this should be explicitly requested by the user). We could use Java @Annotations to indicate depends between variant annotations (e.g. listing reference to the annotion class object).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/225
https://github.com/broadinstitute/gatk/issues/225:544,Integrability,depend,dependences,544,"Some annotations may use as input some other annotations. In this case the former's code should be applied after the all the depends have been applied. For example QD uses AD and if not present defaults into other sources to determine the read-depth. It can be the case that QD is applied before AD an in the resulting output these two are inconsistent. . In this case if AD is to be annotated, this should take place before QD is annotated to avoid inconsistencies depending of request list order. . Here we may consider either to fail if the dependences are not in the list of requested annotations or force the application of those given the list of requested annotations. Non requested annotations could be subsequently stripped from the final output (perhaps this should be explicitly requested by the user). We could use Java @Annotations to indicate depends between variant annotations (e.g. listing reference to the annotion class object).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/225
https://github.com/broadinstitute/gatk/issues/225:857,Integrability,depend,depends,857,"Some annotations may use as input some other annotations. In this case the former's code should be applied after the all the depends have been applied. For example QD uses AD and if not present defaults into other sources to determine the read-depth. It can be the case that QD is applied before AD an in the resulting output these two are inconsistent. . In this case if AD is to be annotated, this should take place before QD is annotated to avoid inconsistencies depending of request list order. . Here we may consider either to fail if the dependences are not in the list of requested annotations or force the application of those given the list of requested annotations. Non requested annotations could be subsequently stripped from the final output (perhaps this should be explicitly requested by the user). We could use Java @Annotations to indicate depends between variant annotations (e.g. listing reference to the annotion class object).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/225
https://github.com/broadinstitute/gatk/issues/225:444,Safety,avoid,avoid,444,"Some annotations may use as input some other annotations. In this case the former's code should be applied after the all the depends have been applied. For example QD uses AD and if not present defaults into other sources to determine the read-depth. It can be the case that QD is applied before AD an in the resulting output these two are inconsistent. . In this case if AD is to be annotated, this should take place before QD is annotated to avoid inconsistencies depending of request list order. . Here we may consider either to fail if the dependences are not in the list of requested annotations or force the application of those given the list of requested annotations. Non requested annotations could be subsequently stripped from the final output (perhaps this should be explicitly requested by the user). We could use Java @Annotations to indicate depends between variant annotations (e.g. listing reference to the annotion class object).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/225
https://github.com/broadinstitute/gatk/pull/228:122,Deployability,update,update,122,"There is now no deprecated code in hellbender. This is probably a good way to start a new project. Closes #162 . I had to update `MergeBamAlignmentIntegrationTest` to remove references to a deprecated parameter, so I also fixed most of intellij's style complaints on it.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/228
https://github.com/broadinstitute/gatk/issues/230:53,Testability,test,test,53,"`canDecode()` is now the exclusive means by which we test whether a codec can decode a particular file (can no longer specify the codec manually on the command line as in the old GATK). All codecs should therefore implement this method (currently, only some do). We should:. -Make `canDecode()` abstract in `AbstractFeatureCodec` to force all codec authors to provide an implementation. -Write implementations of `canDecode()` for all codecs that currently lack it. These can be file-extension-based in most cases. Eg., for `BEDCodec`:. ```; @Override; public boolean canDecode(final String path) {; return path.toLowerCase().endsWith("".bed"");; }; ```. Only some codecs need to examine file contents to determine whether it can decode a file (`VCFCodec` is one such codec, since there are different magic values at file start for different versions of VCF files).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/230
https://github.com/broadinstitute/gatk/issues/231:93,Testability,test,tests,93,"Now that BQSR supports multiple known sites files (as it did in the old GATK), we should add tests for the multi-file case (eg., known SNPs and known indels as separate inputs).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/231
https://github.com/broadinstitute/gatk/issues/233:154,Performance,perform,performance,154,"`DEFAULT_QUERY_LOOKAHEAD_BASES` in `FeatureDataSource` is currently set to 1000. We should empirically determine whether this value results in acceptable performance for typical traversals involving queries over intervals with gradually increasing start/stop positions. This value controls the number of additional bases by which to expand the END of each query interval that results in a cache miss. Larger values will result in a larger number of cached Features, which will increase the number of cache hits between cache misses, provided query intervals follow the typical pattern of slowly increasing positions. On the other hand, larger values will also increase the cost associated with cache misses, which happen when we jump forward by a large number of bases, switch contigs, or move backwards.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/233
https://github.com/broadinstitute/gatk/issues/233:389,Performance,cache,cache,389,"`DEFAULT_QUERY_LOOKAHEAD_BASES` in `FeatureDataSource` is currently set to 1000. We should empirically determine whether this value results in acceptable performance for typical traversals involving queries over intervals with gradually increasing start/stop positions. This value controls the number of additional bases by which to expand the END of each query interval that results in a cache miss. Larger values will result in a larger number of cached Features, which will increase the number of cache hits between cache misses, provided query intervals follow the typical pattern of slowly increasing positions. On the other hand, larger values will also increase the cost associated with cache misses, which happen when we jump forward by a large number of bases, switch contigs, or move backwards.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/233
https://github.com/broadinstitute/gatk/issues/233:449,Performance,cache,cached,449,"`DEFAULT_QUERY_LOOKAHEAD_BASES` in `FeatureDataSource` is currently set to 1000. We should empirically determine whether this value results in acceptable performance for typical traversals involving queries over intervals with gradually increasing start/stop positions. This value controls the number of additional bases by which to expand the END of each query interval that results in a cache miss. Larger values will result in a larger number of cached Features, which will increase the number of cache hits between cache misses, provided query intervals follow the typical pattern of slowly increasing positions. On the other hand, larger values will also increase the cost associated with cache misses, which happen when we jump forward by a large number of bases, switch contigs, or move backwards.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/233
https://github.com/broadinstitute/gatk/issues/233:500,Performance,cache,cache,500,"`DEFAULT_QUERY_LOOKAHEAD_BASES` in `FeatureDataSource` is currently set to 1000. We should empirically determine whether this value results in acceptable performance for typical traversals involving queries over intervals with gradually increasing start/stop positions. This value controls the number of additional bases by which to expand the END of each query interval that results in a cache miss. Larger values will result in a larger number of cached Features, which will increase the number of cache hits between cache misses, provided query intervals follow the typical pattern of slowly increasing positions. On the other hand, larger values will also increase the cost associated with cache misses, which happen when we jump forward by a large number of bases, switch contigs, or move backwards.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/233
https://github.com/broadinstitute/gatk/issues/233:519,Performance,cache,cache,519,"`DEFAULT_QUERY_LOOKAHEAD_BASES` in `FeatureDataSource` is currently set to 1000. We should empirically determine whether this value results in acceptable performance for typical traversals involving queries over intervals with gradually increasing start/stop positions. This value controls the number of additional bases by which to expand the END of each query interval that results in a cache miss. Larger values will result in a larger number of cached Features, which will increase the number of cache hits between cache misses, provided query intervals follow the typical pattern of slowly increasing positions. On the other hand, larger values will also increase the cost associated with cache misses, which happen when we jump forward by a large number of bases, switch contigs, or move backwards.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/233
https://github.com/broadinstitute/gatk/issues/233:694,Performance,cache,cache,694,"`DEFAULT_QUERY_LOOKAHEAD_BASES` in `FeatureDataSource` is currently set to 1000. We should empirically determine whether this value results in acceptable performance for typical traversals involving queries over intervals with gradually increasing start/stop positions. This value controls the number of additional bases by which to expand the END of each query interval that results in a cache miss. Larger values will result in a larger number of cached Features, which will increase the number of cache hits between cache misses, provided query intervals follow the typical pattern of slowly increasing positions. On the other hand, larger values will also increase the cost associated with cache misses, which happen when we jump forward by a large number of bases, switch contigs, or move backwards.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/233
https://github.com/broadinstitute/gatk/issues/234:337,Integrability,interface,interface,337,"These codecs require a `GenomeLocParser` (and therefore a sequence dictionary), and so are currently broken in hellbender, which does not assume the presence of a sequence dictionary for Feature-containing files. We need to either refactor these codecs to not require a `GenomeLocParser` (and remove the `ReferenceDependentFeatureCodec` interface), or delete them if they are no longer needed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/234
https://github.com/broadinstitute/gatk/issues/234:231,Modifiability,refactor,refactor,231,"These codecs require a `GenomeLocParser` (and therefore a sequence dictionary), and so are currently broken in hellbender, which does not assume the presence of a sequence dictionary for Feature-containing files. We need to either refactor these codecs to not require a `GenomeLocParser` (and remove the `ReferenceDependentFeatureCodec` interface), or delete them if they are no longer needed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/234
https://github.com/broadinstitute/gatk/issues/235:53,Deployability,integrat,integration,53,The new index creation tool `IndexFeatureFile` needs integration tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/235
https://github.com/broadinstitute/gatk/issues/235:53,Integrability,integrat,integration,53,The new index creation tool `IndexFeatureFile` needs integration tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/235
https://github.com/broadinstitute/gatk/issues/235:65,Testability,test,tests,65,The new index creation tool `IndexFeatureFile` needs integration tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/235
https://github.com/broadinstitute/gatk/pull/237:79,Availability,failure,failure,79,changing the default behavior of `RScriptExecutor` from logging a warning on a failure to crashing on failure. the exception message will include output from the failed Rscript; closes #223,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/237
https://github.com/broadinstitute/gatk/pull/237:102,Availability,failure,failure,102,changing the default behavior of `RScriptExecutor` from logging a warning on a failure to crashing on failure. the exception message will include output from the failed Rscript; closes #223,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/237
https://github.com/broadinstitute/gatk/pull/237:125,Integrability,message,message,125,changing the default behavior of `RScriptExecutor` from logging a warning on a failure to crashing on failure. the exception message will include output from the failed Rscript; closes #223,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/237
https://github.com/broadinstitute/gatk/pull/237:56,Testability,log,logging,56,changing the default behavior of `RScriptExecutor` from logging a warning on a failure to crashing on failure. the exception message will include output from the failed Rscript; closes #223,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/237
https://github.com/broadinstitute/gatk/pull/240:123,Testability,test,test,123,"Tidying up the directory structure a bit:; - Move picard tools into picard.sam, to make way for the other packages; - Move test files into subdirectories accordingly.; - Have unit tests use `CommandLineProgramTest.getTestDataDir()` instead of specifying the full path.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/240
https://github.com/broadinstitute/gatk/pull/240:180,Testability,test,tests,180,"Tidying up the directory structure a bit:; - Move picard tools into picard.sam, to make way for the other packages; - Move test files into subdirectories accordingly.; - Have unit tests use `CommandLineProgramTest.getTestDataDir()` instead of specifying the full path.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/240
https://github.com/broadinstitute/gatk/issues/241:564,Testability,log,logic,564,"It would be wonderful to be able to use SelectVariants with a query like -select ""AF > 0.1"" on a VCF containing multiallelics and have it filter multiallelics by the allele with the highest AF. (Possibly conversely for ""AF < X""queries. Right now it crashes unless you use a crazy JEXL or pull out the multiallelics. Maybe we could make a maxAF/minAF in htsjdk/JEXLmap.java which equals AF for biallelics?. Internally, it might be nice to have a Map<Allele, Double> with the AF (or AC) for each allele for the SelectVariants issue and to simplify some of the crazy logic already in VariantAnnotator to deal with different allele ordering. As part of this task, we should also make 100% sure that allele ordering is preserved so that AF/AC array ordering is preserved during VC reading/writing/manipulation.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/241
https://github.com/broadinstitute/gatk/issues/241:537,Usability,simpl,simplify,537,"It would be wonderful to be able to use SelectVariants with a query like -select ""AF > 0.1"" on a VCF containing multiallelics and have it filter multiallelics by the allele with the highest AF. (Possibly conversely for ""AF < X""queries. Right now it crashes unless you use a crazy JEXL or pull out the multiallelics. Maybe we could make a maxAF/minAF in htsjdk/JEXLmap.java which equals AF for biallelics?. Internally, it might be nice to have a Map<Allele, Double> with the AF (or AC) for each allele for the SelectVariants issue and to simplify some of the crazy logic already in VariantAnnotator to deal with different allele ordering. As part of this task, we should also make 100% sure that allele ordering is preserved so that AF/AC array ordering is preserved during VC reading/writing/manipulation.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/241
https://github.com/broadinstitute/gatk/issues/242:21,Integrability,inject,injecting,21,"Since we are already injecting Arguments including FeatureInputs and referenceDictionaries... why we need to pass ReferenceContext or FeatureContext in the apply method? . If a tool requires some features, it could access it directly from the feature-input that is already declaring as a member field (of course, once the query api is provided there)... . What is the Optional<FeatureContext> giving us that could not be perfectly supported by an API-enriched FeatureInput object?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/242
https://github.com/broadinstitute/gatk/issues/242:21,Security,inject,injecting,21,"Since we are already injecting Arguments including FeatureInputs and referenceDictionaries... why we need to pass ReferenceContext or FeatureContext in the apply method? . If a tool requires some features, it could access it directly from the feature-input that is already declaring as a member field (of course, once the query api is provided there)... . What is the Optional<FeatureContext> giving us that could not be perfectly supported by an API-enriched FeatureInput object?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/242
https://github.com/broadinstitute/gatk/issues/242:215,Security,access,access,215,"Since we are already injecting Arguments including FeatureInputs and referenceDictionaries... why we need to pass ReferenceContext or FeatureContext in the apply method? . If a tool requires some features, it could access it directly from the feature-input that is already declaring as a member field (of course, once the query api is provided there)... . What is the Optional<FeatureContext> giving us that could not be perfectly supported by an API-enriched FeatureInput object?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/242
https://github.com/broadinstitute/gatk/issues/243:317,Availability,error,error,317,Our current logging level argument (VERBOSITY) is only hooked up to the legacy Picard logger. We need to hook this up to log4j as well. Related to:; https://github.com/broadinstitute/hellbender/issues/146 (standardize on log4j across GATK + Picard); https://github.com/broadinstitute/hellbender/issues/216 (fix log4j error that happens on every run),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/243
https://github.com/broadinstitute/gatk/issues/243:12,Testability,log,logging,12,Our current logging level argument (VERBOSITY) is only hooked up to the legacy Picard logger. We need to hook this up to log4j as well. Related to:; https://github.com/broadinstitute/hellbender/issues/146 (standardize on log4j across GATK + Picard); https://github.com/broadinstitute/hellbender/issues/216 (fix log4j error that happens on every run),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/243
https://github.com/broadinstitute/gatk/issues/243:86,Testability,log,logger,86,Our current logging level argument (VERBOSITY) is only hooked up to the legacy Picard logger. We need to hook this up to log4j as well. Related to:; https://github.com/broadinstitute/hellbender/issues/146 (standardize on log4j across GATK + Picard); https://github.com/broadinstitute/hellbender/issues/216 (fix log4j error that happens on every run),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/243
https://github.com/broadinstitute/gatk/issues/245:296,Performance,perform,perform,296,"There may be a general need to allow tools to request additional context around the current locus/interval. This currently is implemented for `ReferenceContext` via `setWindow()`, but could be expanded to the other *Context classes as well. . Note, however, that we should not encourage tools to perform arbitrary queries as a general rule, since it would be difficult or impossible to optimize a traversal in which the access pattern is random. If a tool needs to group disparate data items together (eg., mates on different contigs), there should be an initial grouping step to prepare the required data for the main analysis, instead of random queries within the main analysis.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/245
https://github.com/broadinstitute/gatk/issues/245:386,Performance,optimiz,optimize,386,"There may be a general need to allow tools to request additional context around the current locus/interval. This currently is implemented for `ReferenceContext` via `setWindow()`, but could be expanded to the other *Context classes as well. . Note, however, that we should not encourage tools to perform arbitrary queries as a general rule, since it would be difficult or impossible to optimize a traversal in which the access pattern is random. If a tool needs to group disparate data items together (eg., mates on different contigs), there should be an initial grouping step to prepare the required data for the main analysis, instead of random queries within the main analysis.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/245
https://github.com/broadinstitute/gatk/issues/245:420,Security,access,access,420,"There may be a general need to allow tools to request additional context around the current locus/interval. This currently is implemented for `ReferenceContext` via `setWindow()`, but could be expanded to the other *Context classes as well. . Note, however, that we should not encourage tools to perform arbitrary queries as a general rule, since it would be difficult or impossible to optimize a traversal in which the access pattern is random. If a tool needs to group disparate data items together (eg., mates on different contigs), there should be an initial grouping step to prepare the required data for the main analysis, instead of random queries within the main analysis.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/245
https://github.com/broadinstitute/gatk/issues/247:11,Testability,test,test,11,"Thoroughly test htsjdk code to make sure the alternate allele ordering in the input VCF (for multiallelic variants) is preserved during VC reading/writing/manipulation. As part of this task, while whoever is doing is it making changes, it would be wonderful to take out the allele alphabetizing in the VariantContext::toString method because that makes debugging this issue less straight forward.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/247
https://github.com/broadinstitute/gatk/issues/248:188,Availability,down,downsides,188,"Our R dependency is primarily for producing plots. It could be possible to create plots using javascript instead. Javascript plots have several potential advantages but also several major downsides. The biggest and most obvious drawback is that we don't have any code to produce them yet, and they are likely harder to generate and experiment with than R scripts. . The advantage would be that we could avoid requiring an R installation to run hellbender scripts, we could potentially also include interactive plotting or other neat tricks to make the plots more useful. I see 2 possible routes to replacing Rscripts with javascript. The first would be for tools that require graphs to perform some html generation and produce html reports with embedded javascript. The user could then open these in their browser and view the plots ( much like how our test suite report and jacoco is done). . A different option would be to use javascript plotting libraries directly within the jvm to generate SVG. Java 8 has a new javascript engine which is supposed to be reasonably fast and offers access to java objects from within it. Unfortunately it doesn't offer a full DOM like a browser does, so most existing javascript libraries will fall over. It seems like it would take a lot of hacking to get something like d3 to run directly on the jvm. (someone has done something of the kind here: http://jazdw.net/content/server-side-svg-generation-using-d3js) . Other options would be to use the javafx web panes to display a browser directly, or to plot directly on a canvas. Either of these options seem like they would be painful and awful.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/248
https://github.com/broadinstitute/gatk/issues/248:424,Deployability,install,installation,424,"Our R dependency is primarily for producing plots. It could be possible to create plots using javascript instead. Javascript plots have several potential advantages but also several major downsides. The biggest and most obvious drawback is that we don't have any code to produce them yet, and they are likely harder to generate and experiment with than R scripts. . The advantage would be that we could avoid requiring an R installation to run hellbender scripts, we could potentially also include interactive plotting or other neat tricks to make the plots more useful. I see 2 possible routes to replacing Rscripts with javascript. The first would be for tools that require graphs to perform some html generation and produce html reports with embedded javascript. The user could then open these in their browser and view the plots ( much like how our test suite report and jacoco is done). . A different option would be to use javascript plotting libraries directly within the jvm to generate SVG. Java 8 has a new javascript engine which is supposed to be reasonably fast and offers access to java objects from within it. Unfortunately it doesn't offer a full DOM like a browser does, so most existing javascript libraries will fall over. It seems like it would take a lot of hacking to get something like d3 to run directly on the jvm. (someone has done something of the kind here: http://jazdw.net/content/server-side-svg-generation-using-d3js) . Other options would be to use the javafx web panes to display a browser directly, or to plot directly on a canvas. Either of these options seem like they would be painful and awful.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/248
https://github.com/broadinstitute/gatk/issues/248:6,Integrability,depend,dependency,6,"Our R dependency is primarily for producing plots. It could be possible to create plots using javascript instead. Javascript plots have several potential advantages but also several major downsides. The biggest and most obvious drawback is that we don't have any code to produce them yet, and they are likely harder to generate and experiment with than R scripts. . The advantage would be that we could avoid requiring an R installation to run hellbender scripts, we could potentially also include interactive plotting or other neat tricks to make the plots more useful. I see 2 possible routes to replacing Rscripts with javascript. The first would be for tools that require graphs to perform some html generation and produce html reports with embedded javascript. The user could then open these in their browser and view the plots ( much like how our test suite report and jacoco is done). . A different option would be to use javascript plotting libraries directly within the jvm to generate SVG. Java 8 has a new javascript engine which is supposed to be reasonably fast and offers access to java objects from within it. Unfortunately it doesn't offer a full DOM like a browser does, so most existing javascript libraries will fall over. It seems like it would take a lot of hacking to get something like d3 to run directly on the jvm. (someone has done something of the kind here: http://jazdw.net/content/server-side-svg-generation-using-d3js) . Other options would be to use the javafx web panes to display a browser directly, or to plot directly on a canvas. Either of these options seem like they would be painful and awful.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/248
https://github.com/broadinstitute/gatk/issues/248:588,Integrability,rout,routes,588,"Our R dependency is primarily for producing plots. It could be possible to create plots using javascript instead. Javascript plots have several potential advantages but also several major downsides. The biggest and most obvious drawback is that we don't have any code to produce them yet, and they are likely harder to generate and experiment with than R scripts. . The advantage would be that we could avoid requiring an R installation to run hellbender scripts, we could potentially also include interactive plotting or other neat tricks to make the plots more useful. I see 2 possible routes to replacing Rscripts with javascript. The first would be for tools that require graphs to perform some html generation and produce html reports with embedded javascript. The user could then open these in their browser and view the plots ( much like how our test suite report and jacoco is done). . A different option would be to use javascript plotting libraries directly within the jvm to generate SVG. Java 8 has a new javascript engine which is supposed to be reasonably fast and offers access to java objects from within it. Unfortunately it doesn't offer a full DOM like a browser does, so most existing javascript libraries will fall over. It seems like it would take a lot of hacking to get something like d3 to run directly on the jvm. (someone has done something of the kind here: http://jazdw.net/content/server-side-svg-generation-using-d3js) . Other options would be to use the javafx web panes to display a browser directly, or to plot directly on a canvas. Either of these options seem like they would be painful and awful.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/248
https://github.com/broadinstitute/gatk/issues/248:686,Performance,perform,perform,686,"Our R dependency is primarily for producing plots. It could be possible to create plots using javascript instead. Javascript plots have several potential advantages but also several major downsides. The biggest and most obvious drawback is that we don't have any code to produce them yet, and they are likely harder to generate and experiment with than R scripts. . The advantage would be that we could avoid requiring an R installation to run hellbender scripts, we could potentially also include interactive plotting or other neat tricks to make the plots more useful. I see 2 possible routes to replacing Rscripts with javascript. The first would be for tools that require graphs to perform some html generation and produce html reports with embedded javascript. The user could then open these in their browser and view the plots ( much like how our test suite report and jacoco is done). . A different option would be to use javascript plotting libraries directly within the jvm to generate SVG. Java 8 has a new javascript engine which is supposed to be reasonably fast and offers access to java objects from within it. Unfortunately it doesn't offer a full DOM like a browser does, so most existing javascript libraries will fall over. It seems like it would take a lot of hacking to get something like d3 to run directly on the jvm. (someone has done something of the kind here: http://jazdw.net/content/server-side-svg-generation-using-d3js) . Other options would be to use the javafx web panes to display a browser directly, or to plot directly on a canvas. Either of these options seem like they would be painful and awful.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/248
https://github.com/broadinstitute/gatk/issues/248:403,Safety,avoid,avoid,403,"Our R dependency is primarily for producing plots. It could be possible to create plots using javascript instead. Javascript plots have several potential advantages but also several major downsides. The biggest and most obvious drawback is that we don't have any code to produce them yet, and they are likely harder to generate and experiment with than R scripts. . The advantage would be that we could avoid requiring an R installation to run hellbender scripts, we could potentially also include interactive plotting or other neat tricks to make the plots more useful. I see 2 possible routes to replacing Rscripts with javascript. The first would be for tools that require graphs to perform some html generation and produce html reports with embedded javascript. The user could then open these in their browser and view the plots ( much like how our test suite report and jacoco is done). . A different option would be to use javascript plotting libraries directly within the jvm to generate SVG. Java 8 has a new javascript engine which is supposed to be reasonably fast and offers access to java objects from within it. Unfortunately it doesn't offer a full DOM like a browser does, so most existing javascript libraries will fall over. It seems like it would take a lot of hacking to get something like d3 to run directly on the jvm. (someone has done something of the kind here: http://jazdw.net/content/server-side-svg-generation-using-d3js) . Other options would be to use the javafx web panes to display a browser directly, or to plot directly on a canvas. Either of these options seem like they would be painful and awful.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/248
https://github.com/broadinstitute/gatk/issues/248:1086,Security,access,access,1086,"Our R dependency is primarily for producing plots. It could be possible to create plots using javascript instead. Javascript plots have several potential advantages but also several major downsides. The biggest and most obvious drawback is that we don't have any code to produce them yet, and they are likely harder to generate and experiment with than R scripts. . The advantage would be that we could avoid requiring an R installation to run hellbender scripts, we could potentially also include interactive plotting or other neat tricks to make the plots more useful. I see 2 possible routes to replacing Rscripts with javascript. The first would be for tools that require graphs to perform some html generation and produce html reports with embedded javascript. The user could then open these in their browser and view the plots ( much like how our test suite report and jacoco is done). . A different option would be to use javascript plotting libraries directly within the jvm to generate SVG. Java 8 has a new javascript engine which is supposed to be reasonably fast and offers access to java objects from within it. Unfortunately it doesn't offer a full DOM like a browser does, so most existing javascript libraries will fall over. It seems like it would take a lot of hacking to get something like d3 to run directly on the jvm. (someone has done something of the kind here: http://jazdw.net/content/server-side-svg-generation-using-d3js) . Other options would be to use the javafx web panes to display a browser directly, or to plot directly on a canvas. Either of these options seem like they would be painful and awful.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/248
https://github.com/broadinstitute/gatk/issues/248:853,Testability,test,test,853,"Our R dependency is primarily for producing plots. It could be possible to create plots using javascript instead. Javascript plots have several potential advantages but also several major downsides. The biggest and most obvious drawback is that we don't have any code to produce them yet, and they are likely harder to generate and experiment with than R scripts. . The advantage would be that we could avoid requiring an R installation to run hellbender scripts, we could potentially also include interactive plotting or other neat tricks to make the plots more useful. I see 2 possible routes to replacing Rscripts with javascript. The first would be for tools that require graphs to perform some html generation and produce html reports with embedded javascript. The user could then open these in their browser and view the plots ( much like how our test suite report and jacoco is done). . A different option would be to use javascript plotting libraries directly within the jvm to generate SVG. Java 8 has a new javascript engine which is supposed to be reasonably fast and offers access to java objects from within it. Unfortunately it doesn't offer a full DOM like a browser does, so most existing javascript libraries will fall over. It seems like it would take a lot of hacking to get something like d3 to run directly on the jvm. (someone has done something of the kind here: http://jazdw.net/content/server-side-svg-generation-using-d3js) . Other options would be to use the javafx web panes to display a browser directly, or to plot directly on a canvas. Either of these options seem like they would be painful and awful.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/248
https://github.com/broadinstitute/gatk/pull/249:203,Integrability,wrap,wrapped,203,"-ReferenceContext and FeatureContext are now guaranteed to be non-null in ReadWalker.apply(),; and simply return empty Collections/iterators when there is no backing data source (previously,; these were wrapped in Optional objects, and would be Optional.empty() if there was no source; of reference and/or Feature data). This spares tool authors from having to explicitly check for the existence of reference/Feature; contextual data before using it. -For tools that care about the distinction between the ""no data source"" case and the ""no records; overlapping the current interval"" case, there is now a hasBackingDataSource() method in both; ReferenceContext and FeatureContext. Requested by Valentin!. Resolves #244",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/249
https://github.com/broadinstitute/gatk/pull/249:99,Usability,simpl,simply,99,"-ReferenceContext and FeatureContext are now guaranteed to be non-null in ReadWalker.apply(),; and simply return empty Collections/iterators when there is no backing data source (previously,; these were wrapped in Optional objects, and would be Optional.empty() if there was no source; of reference and/or Feature data). This spares tool authors from having to explicitly check for the existence of reference/Feature; contextual data before using it. -For tools that care about the distinction between the ""no data source"" case and the ""no records; overlapping the current interval"" case, there is now a hasBackingDataSource() method in both; ReferenceContext and FeatureContext. Requested by Valentin!. Resolves #244",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/249
https://github.com/broadinstitute/gatk/issues/250:233,Integrability,message,messages,233,"Valentin reported that hellbender currently takes ~2 minutes to load BAM index data for a WEx BAM + WEx interval list. We should see if there is some obvious inefficiency here that we can optimize out. At the very least, we need log messages to signal the start and end of index loading/processing. On the plus side, Valentin reports that the actual WEx traversal takes only 12 minutes with his new walker, which seems pretty reasonable.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/250
https://github.com/broadinstitute/gatk/issues/250:64,Performance,load,load,64,"Valentin reported that hellbender currently takes ~2 minutes to load BAM index data for a WEx BAM + WEx interval list. We should see if there is some obvious inefficiency here that we can optimize out. At the very least, we need log messages to signal the start and end of index loading/processing. On the plus side, Valentin reports that the actual WEx traversal takes only 12 minutes with his new walker, which seems pretty reasonable.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/250
https://github.com/broadinstitute/gatk/issues/250:188,Performance,optimiz,optimize,188,"Valentin reported that hellbender currently takes ~2 minutes to load BAM index data for a WEx BAM + WEx interval list. We should see if there is some obvious inefficiency here that we can optimize out. At the very least, we need log messages to signal the start and end of index loading/processing. On the plus side, Valentin reports that the actual WEx traversal takes only 12 minutes with his new walker, which seems pretty reasonable.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/250
https://github.com/broadinstitute/gatk/issues/250:279,Performance,load,loading,279,"Valentin reported that hellbender currently takes ~2 minutes to load BAM index data for a WEx BAM + WEx interval list. We should see if there is some obvious inefficiency here that we can optimize out. At the very least, we need log messages to signal the start and end of index loading/processing. On the plus side, Valentin reports that the actual WEx traversal takes only 12 minutes with his new walker, which seems pretty reasonable.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/250
https://github.com/broadinstitute/gatk/issues/250:229,Testability,log,log,229,"Valentin reported that hellbender currently takes ~2 minutes to load BAM index data for a WEx BAM + WEx interval list. We should see if there is some obvious inefficiency here that we can optimize out. At the very least, we need log messages to signal the start and end of index loading/processing. On the plus side, Valentin reports that the actual WEx traversal takes only 12 minutes with his new walker, which seems pretty reasonable.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/250
https://github.com/broadinstitute/gatk/issues/263:621,Integrability,depend,depending,621,"Found this improvement request in the Classic GATK Pivotal. Would be good to check whether this is satisfied by the ported version. ---. Quality-based clipping should be more straightforward than it is. As explained by Mauricio in relation to this forum question:. http://gatk.vanillaforums.com/discussion/comment/13108#Comment_13108. ""As implemented it doesn't really clip all bases below a certain threshold. It does something gnarly. It keeps a running sum and sets the clipping point to where the running sum exceeds the threshold after subtracting the qual for each base. It only traverses from the end of the read (depending on read orientation). . Essentially , this is a tool to hard clip bad read ends from the sequencer (meaning, the last few cycles) in case the sum of their qualities is not large enough. Not at all what our user wanted. Instead, he was looking for a very simple if statement here. Which I also think would be much more useful."". Here are Mark's comments:. ```; * Clip bases from the read in clipper from; * <p/>; * argmax_x{ \sum{i = x + 1}^l (qTrimmingThreshold - qual); * <p/>; * to the end of the read. This is blatantly stolen from BWA.; * <p/>; * Walk through the read from the end (in machine cycle order) to the beginning, calculating the; * running sum of qTrimmingThreshold - qual. While we do this, we track the maximum value of this; * sum where the delta > 0. After the loop, clipPoint is either -1 (don't do anything) or the; * clipping index in the read (from the end).; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/263
https://github.com/broadinstitute/gatk/issues/263:885,Usability,simpl,simple,885,"Found this improvement request in the Classic GATK Pivotal. Would be good to check whether this is satisfied by the ported version. ---. Quality-based clipping should be more straightforward than it is. As explained by Mauricio in relation to this forum question:. http://gatk.vanillaforums.com/discussion/comment/13108#Comment_13108. ""As implemented it doesn't really clip all bases below a certain threshold. It does something gnarly. It keeps a running sum and sets the clipping point to where the running sum exceeds the threshold after subtracting the qual for each base. It only traverses from the end of the read (depending on read orientation). . Essentially , this is a tool to hard clip bad read ends from the sequencer (meaning, the last few cycles) in case the sum of their qualities is not large enough. Not at all what our user wanted. Instead, he was looking for a very simple if statement here. Which I also think would be much more useful."". Here are Mark's comments:. ```; * Clip bases from the read in clipper from; * <p/>; * argmax_x{ \sum{i = x + 1}^l (qTrimmingThreshold - qual); * <p/>; * to the end of the read. This is blatantly stolen from BWA.; * <p/>; * Walk through the read from the end (in machine cycle order) to the beginning, calculating the; * running sum of qTrimmingThreshold - qual. While we do this, we track the maximum value of this; * sum where the delta > 0. After the loop, clipPoint is either -1 (don't do anything) or the; * clipping index in the read (from the end).; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/263
https://github.com/broadinstitute/gatk/issues/264:250,Availability,recover,recover,250,"Originally by @vruano in Classic GATK Pivotal. Improve the read threading process in order to minimize loss of information without affecting the accuracy of calls. . Here I list a few details and ideas to take in consideration:. A. Currently (unless recover of dangling heads is active) we start threading at the first unique kmer of the read (sequence). There are at least two unsound aspect to this approach:. A.1 Since we are generating those vertices as we thread the resulting graph and edge weights may be different depending of the sequence (read) threading order. . A.2 We are throwing away information located at the beginning of the read before the first unique (and existing) k-mer in each sequence is found. This is partly fixed by the approach taken when we recover dangling heads yet it seems to have other problems downstream when selecting or pruning haplotypes:. ```; https://www.pivotaltracker.com/story/show/67601310; ```. B. Low support chain pruning might not be longer needed. Now we have a newer approach to select best haplotypes that can handle complex graph we might well not need to prune low supported hap early as they seemly they won't be selected if the are not amongst the best haplotypes. . B.1 Now that still would produce a considerable number of unlikely haplotypes that would cause a CPU burden. That can be changed by imposing another kinds of limit, For example we include all haplotypes with scores (likelihoods) that are Q0 - Q40 or we include haplotypes until the sum of their likelihoods is larger than the 99.99% probability mass. . B.2 This could provide a downstream solution to the problem caused by ranging heads recovery (explained above in A.2). B.3 If pruning is to be maintained, it makes more sense to do it at the very end after all dangling ends hav been recovered and the edges supports are finalized. Of course I assuming here that dangling end recovery does the sensible think of updating those supports are the graphs is modified. C. The use ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/264
https://github.com/broadinstitute/gatk/issues/264:771,Availability,recover,recover,771,"Originally by @vruano in Classic GATK Pivotal. Improve the read threading process in order to minimize loss of information without affecting the accuracy of calls. . Here I list a few details and ideas to take in consideration:. A. Currently (unless recover of dangling heads is active) we start threading at the first unique kmer of the read (sequence). There are at least two unsound aspect to this approach:. A.1 Since we are generating those vertices as we thread the resulting graph and edge weights may be different depending of the sequence (read) threading order. . A.2 We are throwing away information located at the beginning of the read before the first unique (and existing) k-mer in each sequence is found. This is partly fixed by the approach taken when we recover dangling heads yet it seems to have other problems downstream when selecting or pruning haplotypes:. ```; https://www.pivotaltracker.com/story/show/67601310; ```. B. Low support chain pruning might not be longer needed. Now we have a newer approach to select best haplotypes that can handle complex graph we might well not need to prune low supported hap early as they seemly they won't be selected if the are not amongst the best haplotypes. . B.1 Now that still would produce a considerable number of unlikely haplotypes that would cause a CPU burden. That can be changed by imposing another kinds of limit, For example we include all haplotypes with scores (likelihoods) that are Q0 - Q40 or we include haplotypes until the sum of their likelihoods is larger than the 99.99% probability mass. . B.2 This could provide a downstream solution to the problem caused by ranging heads recovery (explained above in A.2). B.3 If pruning is to be maintained, it makes more sense to do it at the very end after all dangling ends hav been recovered and the edges supports are finalized. Of course I assuming here that dangling end recovery does the sensible think of updating those supports are the graphs is modified. C. The use ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/264
https://github.com/broadinstitute/gatk/issues/264:830,Availability,down,downstream,830,"Originally by @vruano in Classic GATK Pivotal. Improve the read threading process in order to minimize loss of information without affecting the accuracy of calls. . Here I list a few details and ideas to take in consideration:. A. Currently (unless recover of dangling heads is active) we start threading at the first unique kmer of the read (sequence). There are at least two unsound aspect to this approach:. A.1 Since we are generating those vertices as we thread the resulting graph and edge weights may be different depending of the sequence (read) threading order. . A.2 We are throwing away information located at the beginning of the read before the first unique (and existing) k-mer in each sequence is found. This is partly fixed by the approach taken when we recover dangling heads yet it seems to have other problems downstream when selecting or pruning haplotypes:. ```; https://www.pivotaltracker.com/story/show/67601310; ```. B. Low support chain pruning might not be longer needed. Now we have a newer approach to select best haplotypes that can handle complex graph we might well not need to prune low supported hap early as they seemly they won't be selected if the are not amongst the best haplotypes. . B.1 Now that still would produce a considerable number of unlikely haplotypes that would cause a CPU burden. That can be changed by imposing another kinds of limit, For example we include all haplotypes with scores (likelihoods) that are Q0 - Q40 or we include haplotypes until the sum of their likelihoods is larger than the 99.99% probability mass. . B.2 This could provide a downstream solution to the problem caused by ranging heads recovery (explained above in A.2). B.3 If pruning is to be maintained, it makes more sense to do it at the very end after all dangling ends hav been recovered and the edges supports are finalized. Of course I assuming here that dangling end recovery does the sensible think of updating those supports are the graphs is modified. C. The use ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/264
https://github.com/broadinstitute/gatk/issues/264:1602,Availability,down,downstream,1602," of the read before the first unique (and existing) k-mer in each sequence is found. This is partly fixed by the approach taken when we recover dangling heads yet it seems to have other problems downstream when selecting or pruning haplotypes:. ```; https://www.pivotaltracker.com/story/show/67601310; ```. B. Low support chain pruning might not be longer needed. Now we have a newer approach to select best haplotypes that can handle complex graph we might well not need to prune low supported hap early as they seemly they won't be selected if the are not amongst the best haplotypes. . B.1 Now that still would produce a considerable number of unlikely haplotypes that would cause a CPU burden. That can be changed by imposing another kinds of limit, For example we include all haplotypes with scores (likelihoods) that are Q0 - Q40 or we include haplotypes until the sum of their likelihoods is larger than the 99.99% probability mass. . B.2 This could provide a downstream solution to the problem caused by ranging heads recovery (explained above in A.2). B.3 If pruning is to be maintained, it makes more sense to do it at the very end after all dangling ends hav been recovered and the edges supports are finalized. Of course I assuming here that dangling end recovery does the sensible think of updating those supports are the graphs is modified. C. The use of Smith-Waterman in dangling end recovery does not seem totally optimal or even needed. . C.1 Recovering tails quite often this finish with the same sequence as the reference path because in fact they are supposed to end like that by construction (reads are trimmed by AR coordinates). For example, this can be cause because due to the k-mer size there is not enough based after variation for the paths to merge back. In this case you can simply merge the last vertices of the tail and the reference, faster and potentially more accurate. . C.2 Similarly dangling heads, at least part of the sequence of those dangling heads are clear",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/264
https://github.com/broadinstitute/gatk/issues/264:1661,Availability,recover,recovery,1661," of the read before the first unique (and existing) k-mer in each sequence is found. This is partly fixed by the approach taken when we recover dangling heads yet it seems to have other problems downstream when selecting or pruning haplotypes:. ```; https://www.pivotaltracker.com/story/show/67601310; ```. B. Low support chain pruning might not be longer needed. Now we have a newer approach to select best haplotypes that can handle complex graph we might well not need to prune low supported hap early as they seemly they won't be selected if the are not amongst the best haplotypes. . B.1 Now that still would produce a considerable number of unlikely haplotypes that would cause a CPU burden. That can be changed by imposing another kinds of limit, For example we include all haplotypes with scores (likelihoods) that are Q0 - Q40 or we include haplotypes until the sum of their likelihoods is larger than the 99.99% probability mass. . B.2 This could provide a downstream solution to the problem caused by ranging heads recovery (explained above in A.2). B.3 If pruning is to be maintained, it makes more sense to do it at the very end after all dangling ends hav been recovered and the edges supports are finalized. Of course I assuming here that dangling end recovery does the sensible think of updating those supports are the graphs is modified. C. The use of Smith-Waterman in dangling end recovery does not seem totally optimal or even needed. . C.1 Recovering tails quite often this finish with the same sequence as the reference path because in fact they are supposed to end like that by construction (reads are trimmed by AR coordinates). For example, this can be cause because due to the k-mer size there is not enough based after variation for the paths to merge back. In this case you can simply merge the last vertices of the tail and the reference, faster and potentially more accurate. . C.2 Similarly dangling heads, at least part of the sequence of those dangling heads are clear",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/264
https://github.com/broadinstitute/gatk/issues/264:1810,Availability,recover,recovered,1810,"r dangling heads yet it seems to have other problems downstream when selecting or pruning haplotypes:. ```; https://www.pivotaltracker.com/story/show/67601310; ```. B. Low support chain pruning might not be longer needed. Now we have a newer approach to select best haplotypes that can handle complex graph we might well not need to prune low supported hap early as they seemly they won't be selected if the are not amongst the best haplotypes. . B.1 Now that still would produce a considerable number of unlikely haplotypes that would cause a CPU burden. That can be changed by imposing another kinds of limit, For example we include all haplotypes with scores (likelihoods) that are Q0 - Q40 or we include haplotypes until the sum of their likelihoods is larger than the 99.99% probability mass. . B.2 This could provide a downstream solution to the problem caused by ranging heads recovery (explained above in A.2). B.3 If pruning is to be maintained, it makes more sense to do it at the very end after all dangling ends hav been recovered and the edges supports are finalized. Of course I assuming here that dangling end recovery does the sensible think of updating those supports are the graphs is modified. C. The use of Smith-Waterman in dangling end recovery does not seem totally optimal or even needed. . C.1 Recovering tails quite often this finish with the same sequence as the reference path because in fact they are supposed to end like that by construction (reads are trimmed by AR coordinates). For example, this can be cause because due to the k-mer size there is not enough based after variation for the paths to merge back. In this case you can simply merge the last vertices of the tail and the reference, faster and potentially more accurate. . C.2 Similarly dangling heads, at least part of the sequence of those dangling heads are clearly threadable back into the graph without the need of SW. For example look at the AA…AAAAAGA sequence in the picture below. . C.3 PairHMM runs",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/264
https://github.com/broadinstitute/gatk/issues/264:1902,Availability,recover,recovery,1902,"how/67601310; ```. B. Low support chain pruning might not be longer needed. Now we have a newer approach to select best haplotypes that can handle complex graph we might well not need to prune low supported hap early as they seemly they won't be selected if the are not amongst the best haplotypes. . B.1 Now that still would produce a considerable number of unlikely haplotypes that would cause a CPU burden. That can be changed by imposing another kinds of limit, For example we include all haplotypes with scores (likelihoods) that are Q0 - Q40 or we include haplotypes until the sum of their likelihoods is larger than the 99.99% probability mass. . B.2 This could provide a downstream solution to the problem caused by ranging heads recovery (explained above in A.2). B.3 If pruning is to be maintained, it makes more sense to do it at the very end after all dangling ends hav been recovered and the edges supports are finalized. Of course I assuming here that dangling end recovery does the sensible think of updating those supports are the graphs is modified. C. The use of Smith-Waterman in dangling end recovery does not seem totally optimal or even needed. . C.1 Recovering tails quite often this finish with the same sequence as the reference path because in fact they are supposed to end like that by construction (reads are trimmed by AR coordinates). For example, this can be cause because due to the k-mer size there is not enough based after variation for the paths to merge back. In this case you can simply merge the last vertices of the tail and the reference, faster and potentially more accurate. . C.2 Similarly dangling heads, at least part of the sequence of those dangling heads are clearly threadable back into the graph without the need of SW. For example look at the AA…AAAAAGA sequence in the picture below. . C.3 PairHMM runs in effect are performing SW kind of computations and so it is totally possible to use its partial result to find good alignment of dangling ends",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/264
https://github.com/broadinstitute/gatk/issues/264:2035,Availability,recover,recovery,2035,"er approach to select best haplotypes that can handle complex graph we might well not need to prune low supported hap early as they seemly they won't be selected if the are not amongst the best haplotypes. . B.1 Now that still would produce a considerable number of unlikely haplotypes that would cause a CPU burden. That can be changed by imposing another kinds of limit, For example we include all haplotypes with scores (likelihoods) that are Q0 - Q40 or we include haplotypes until the sum of their likelihoods is larger than the 99.99% probability mass. . B.2 This could provide a downstream solution to the problem caused by ranging heads recovery (explained above in A.2). B.3 If pruning is to be maintained, it makes more sense to do it at the very end after all dangling ends hav been recovered and the edges supports are finalized. Of course I assuming here that dangling end recovery does the sensible think of updating those supports are the graphs is modified. C. The use of Smith-Waterman in dangling end recovery does not seem totally optimal or even needed. . C.1 Recovering tails quite often this finish with the same sequence as the reference path because in fact they are supposed to end like that by construction (reads are trimmed by AR coordinates). For example, this can be cause because due to the k-mer size there is not enough based after variation for the paths to merge back. In this case you can simply merge the last vertices of the tail and the reference, faster and potentially more accurate. . C.2 Similarly dangling heads, at least part of the sequence of those dangling heads are clearly threadable back into the graph without the need of SW. For example look at the AA…AAAAAGA sequence in the picture below. . C.3 PairHMM runs in effect are performing SW kind of computations and so it is totally possible to use its partial result to find good alignment of dangling ends back to other parts of the graph without the need of running a separate SW thus saving time.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/264
https://github.com/broadinstitute/gatk/issues/264:2096,Availability,Recover,Recovering,2096,"er approach to select best haplotypes that can handle complex graph we might well not need to prune low supported hap early as they seemly they won't be selected if the are not amongst the best haplotypes. . B.1 Now that still would produce a considerable number of unlikely haplotypes that would cause a CPU burden. That can be changed by imposing another kinds of limit, For example we include all haplotypes with scores (likelihoods) that are Q0 - Q40 or we include haplotypes until the sum of their likelihoods is larger than the 99.99% probability mass. . B.2 This could provide a downstream solution to the problem caused by ranging heads recovery (explained above in A.2). B.3 If pruning is to be maintained, it makes more sense to do it at the very end after all dangling ends hav been recovered and the edges supports are finalized. Of course I assuming here that dangling end recovery does the sensible think of updating those supports are the graphs is modified. C. The use of Smith-Waterman in dangling end recovery does not seem totally optimal or even needed. . C.1 Recovering tails quite often this finish with the same sequence as the reference path because in fact they are supposed to end like that by construction (reads are trimmed by AR coordinates). For example, this can be cause because due to the k-mer size there is not enough based after variation for the paths to merge back. In this case you can simply merge the last vertices of the tail and the reference, faster and potentially more accurate. . C.2 Similarly dangling heads, at least part of the sequence of those dangling heads are clearly threadable back into the graph without the need of SW. For example look at the AA…AAAAAGA sequence in the picture below. . C.3 PairHMM runs in effect are performing SW kind of computations and so it is totally possible to use its partial result to find good alignment of dangling ends back to other parts of the graph without the need of running a separate SW thus saving time.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/264
https://github.com/broadinstitute/gatk/issues/264:522,Integrability,depend,depending,522,"Originally by @vruano in Classic GATK Pivotal. Improve the read threading process in order to minimize loss of information without affecting the accuracy of calls. . Here I list a few details and ideas to take in consideration:. A. Currently (unless recover of dangling heads is active) we start threading at the first unique kmer of the read (sequence). There are at least two unsound aspect to this approach:. A.1 Since we are generating those vertices as we thread the resulting graph and edge weights may be different depending of the sequence (read) threading order. . A.2 We are throwing away information located at the beginning of the read before the first unique (and existing) k-mer in each sequence is found. This is partly fixed by the approach taken when we recover dangling heads yet it seems to have other problems downstream when selecting or pruning haplotypes:. ```; https://www.pivotaltracker.com/story/show/67601310; ```. B. Low support chain pruning might not be longer needed. Now we have a newer approach to select best haplotypes that can handle complex graph we might well not need to prune low supported hap early as they seemly they won't be selected if the are not amongst the best haplotypes. . B.1 Now that still would produce a considerable number of unlikely haplotypes that would cause a CPU burden. That can be changed by imposing another kinds of limit, For example we include all haplotypes with scores (likelihoods) that are Q0 - Q40 or we include haplotypes until the sum of their likelihoods is larger than the 99.99% probability mass. . B.2 This could provide a downstream solution to the problem caused by ranging heads recovery (explained above in A.2). B.3 If pruning is to be maintained, it makes more sense to do it at the very end after all dangling ends hav been recovered and the edges supports are finalized. Of course I assuming here that dangling end recovery does the sensible think of updating those supports are the graphs is modified. C. The use ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/264
https://github.com/broadinstitute/gatk/issues/264:2793,Performance,perform,performing,2793,"er approach to select best haplotypes that can handle complex graph we might well not need to prune low supported hap early as they seemly they won't be selected if the are not amongst the best haplotypes. . B.1 Now that still would produce a considerable number of unlikely haplotypes that would cause a CPU burden. That can be changed by imposing another kinds of limit, For example we include all haplotypes with scores (likelihoods) that are Q0 - Q40 or we include haplotypes until the sum of their likelihoods is larger than the 99.99% probability mass. . B.2 This could provide a downstream solution to the problem caused by ranging heads recovery (explained above in A.2). B.3 If pruning is to be maintained, it makes more sense to do it at the very end after all dangling ends hav been recovered and the edges supports are finalized. Of course I assuming here that dangling end recovery does the sensible think of updating those supports are the graphs is modified. C. The use of Smith-Waterman in dangling end recovery does not seem totally optimal or even needed. . C.1 Recovering tails quite often this finish with the same sequence as the reference path because in fact they are supposed to end like that by construction (reads are trimmed by AR coordinates). For example, this can be cause because due to the k-mer size there is not enough based after variation for the paths to merge back. In this case you can simply merge the last vertices of the tail and the reference, faster and potentially more accurate. . C.2 Similarly dangling heads, at least part of the sequence of those dangling heads are clearly threadable back into the graph without the need of SW. For example look at the AA…AAAAAGA sequence in the picture below. . C.3 PairHMM runs in effect are performing SW kind of computations and so it is totally possible to use its partial result to find good alignment of dangling ends back to other parts of the graph without the need of running a separate SW thus saving time.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/264
https://github.com/broadinstitute/gatk/issues/264:250,Safety,recover,recover,250,"Originally by @vruano in Classic GATK Pivotal. Improve the read threading process in order to minimize loss of information without affecting the accuracy of calls. . Here I list a few details and ideas to take in consideration:. A. Currently (unless recover of dangling heads is active) we start threading at the first unique kmer of the read (sequence). There are at least two unsound aspect to this approach:. A.1 Since we are generating those vertices as we thread the resulting graph and edge weights may be different depending of the sequence (read) threading order. . A.2 We are throwing away information located at the beginning of the read before the first unique (and existing) k-mer in each sequence is found. This is partly fixed by the approach taken when we recover dangling heads yet it seems to have other problems downstream when selecting or pruning haplotypes:. ```; https://www.pivotaltracker.com/story/show/67601310; ```. B. Low support chain pruning might not be longer needed. Now we have a newer approach to select best haplotypes that can handle complex graph we might well not need to prune low supported hap early as they seemly they won't be selected if the are not amongst the best haplotypes. . B.1 Now that still would produce a considerable number of unlikely haplotypes that would cause a CPU burden. That can be changed by imposing another kinds of limit, For example we include all haplotypes with scores (likelihoods) that are Q0 - Q40 or we include haplotypes until the sum of their likelihoods is larger than the 99.99% probability mass. . B.2 This could provide a downstream solution to the problem caused by ranging heads recovery (explained above in A.2). B.3 If pruning is to be maintained, it makes more sense to do it at the very end after all dangling ends hav been recovered and the edges supports are finalized. Of course I assuming here that dangling end recovery does the sensible think of updating those supports are the graphs is modified. C. The use ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/264
https://github.com/broadinstitute/gatk/issues/264:771,Safety,recover,recover,771,"Originally by @vruano in Classic GATK Pivotal. Improve the read threading process in order to minimize loss of information without affecting the accuracy of calls. . Here I list a few details and ideas to take in consideration:. A. Currently (unless recover of dangling heads is active) we start threading at the first unique kmer of the read (sequence). There are at least two unsound aspect to this approach:. A.1 Since we are generating those vertices as we thread the resulting graph and edge weights may be different depending of the sequence (read) threading order. . A.2 We are throwing away information located at the beginning of the read before the first unique (and existing) k-mer in each sequence is found. This is partly fixed by the approach taken when we recover dangling heads yet it seems to have other problems downstream when selecting or pruning haplotypes:. ```; https://www.pivotaltracker.com/story/show/67601310; ```. B. Low support chain pruning might not be longer needed. Now we have a newer approach to select best haplotypes that can handle complex graph we might well not need to prune low supported hap early as they seemly they won't be selected if the are not amongst the best haplotypes. . B.1 Now that still would produce a considerable number of unlikely haplotypes that would cause a CPU burden. That can be changed by imposing another kinds of limit, For example we include all haplotypes with scores (likelihoods) that are Q0 - Q40 or we include haplotypes until the sum of their likelihoods is larger than the 99.99% probability mass. . B.2 This could provide a downstream solution to the problem caused by ranging heads recovery (explained above in A.2). B.3 If pruning is to be maintained, it makes more sense to do it at the very end after all dangling ends hav been recovered and the edges supports are finalized. Of course I assuming here that dangling end recovery does the sensible think of updating those supports are the graphs is modified. C. The use ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/264
https://github.com/broadinstitute/gatk/issues/264:1661,Safety,recover,recovery,1661," of the read before the first unique (and existing) k-mer in each sequence is found. This is partly fixed by the approach taken when we recover dangling heads yet it seems to have other problems downstream when selecting or pruning haplotypes:. ```; https://www.pivotaltracker.com/story/show/67601310; ```. B. Low support chain pruning might not be longer needed. Now we have a newer approach to select best haplotypes that can handle complex graph we might well not need to prune low supported hap early as they seemly they won't be selected if the are not amongst the best haplotypes. . B.1 Now that still would produce a considerable number of unlikely haplotypes that would cause a CPU burden. That can be changed by imposing another kinds of limit, For example we include all haplotypes with scores (likelihoods) that are Q0 - Q40 or we include haplotypes until the sum of their likelihoods is larger than the 99.99% probability mass. . B.2 This could provide a downstream solution to the problem caused by ranging heads recovery (explained above in A.2). B.3 If pruning is to be maintained, it makes more sense to do it at the very end after all dangling ends hav been recovered and the edges supports are finalized. Of course I assuming here that dangling end recovery does the sensible think of updating those supports are the graphs is modified. C. The use of Smith-Waterman in dangling end recovery does not seem totally optimal or even needed. . C.1 Recovering tails quite often this finish with the same sequence as the reference path because in fact they are supposed to end like that by construction (reads are trimmed by AR coordinates). For example, this can be cause because due to the k-mer size there is not enough based after variation for the paths to merge back. In this case you can simply merge the last vertices of the tail and the reference, faster and potentially more accurate. . C.2 Similarly dangling heads, at least part of the sequence of those dangling heads are clear",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/264
https://github.com/broadinstitute/gatk/issues/264:1810,Safety,recover,recovered,1810,"r dangling heads yet it seems to have other problems downstream when selecting or pruning haplotypes:. ```; https://www.pivotaltracker.com/story/show/67601310; ```. B. Low support chain pruning might not be longer needed. Now we have a newer approach to select best haplotypes that can handle complex graph we might well not need to prune low supported hap early as they seemly they won't be selected if the are not amongst the best haplotypes. . B.1 Now that still would produce a considerable number of unlikely haplotypes that would cause a CPU burden. That can be changed by imposing another kinds of limit, For example we include all haplotypes with scores (likelihoods) that are Q0 - Q40 or we include haplotypes until the sum of their likelihoods is larger than the 99.99% probability mass. . B.2 This could provide a downstream solution to the problem caused by ranging heads recovery (explained above in A.2). B.3 If pruning is to be maintained, it makes more sense to do it at the very end after all dangling ends hav been recovered and the edges supports are finalized. Of course I assuming here that dangling end recovery does the sensible think of updating those supports are the graphs is modified. C. The use of Smith-Waterman in dangling end recovery does not seem totally optimal or even needed. . C.1 Recovering tails quite often this finish with the same sequence as the reference path because in fact they are supposed to end like that by construction (reads are trimmed by AR coordinates). For example, this can be cause because due to the k-mer size there is not enough based after variation for the paths to merge back. In this case you can simply merge the last vertices of the tail and the reference, faster and potentially more accurate. . C.2 Similarly dangling heads, at least part of the sequence of those dangling heads are clearly threadable back into the graph without the need of SW. For example look at the AA…AAAAAGA sequence in the picture below. . C.3 PairHMM runs",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/264
https://github.com/broadinstitute/gatk/issues/264:1902,Safety,recover,recovery,1902,"how/67601310; ```. B. Low support chain pruning might not be longer needed. Now we have a newer approach to select best haplotypes that can handle complex graph we might well not need to prune low supported hap early as they seemly they won't be selected if the are not amongst the best haplotypes. . B.1 Now that still would produce a considerable number of unlikely haplotypes that would cause a CPU burden. That can be changed by imposing another kinds of limit, For example we include all haplotypes with scores (likelihoods) that are Q0 - Q40 or we include haplotypes until the sum of their likelihoods is larger than the 99.99% probability mass. . B.2 This could provide a downstream solution to the problem caused by ranging heads recovery (explained above in A.2). B.3 If pruning is to be maintained, it makes more sense to do it at the very end after all dangling ends hav been recovered and the edges supports are finalized. Of course I assuming here that dangling end recovery does the sensible think of updating those supports are the graphs is modified. C. The use of Smith-Waterman in dangling end recovery does not seem totally optimal or even needed. . C.1 Recovering tails quite often this finish with the same sequence as the reference path because in fact they are supposed to end like that by construction (reads are trimmed by AR coordinates). For example, this can be cause because due to the k-mer size there is not enough based after variation for the paths to merge back. In this case you can simply merge the last vertices of the tail and the reference, faster and potentially more accurate. . C.2 Similarly dangling heads, at least part of the sequence of those dangling heads are clearly threadable back into the graph without the need of SW. For example look at the AA…AAAAAGA sequence in the picture below. . C.3 PairHMM runs in effect are performing SW kind of computations and so it is totally possible to use its partial result to find good alignment of dangling ends",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/264
https://github.com/broadinstitute/gatk/issues/264:2035,Safety,recover,recovery,2035,"er approach to select best haplotypes that can handle complex graph we might well not need to prune low supported hap early as they seemly they won't be selected if the are not amongst the best haplotypes. . B.1 Now that still would produce a considerable number of unlikely haplotypes that would cause a CPU burden. That can be changed by imposing another kinds of limit, For example we include all haplotypes with scores (likelihoods) that are Q0 - Q40 or we include haplotypes until the sum of their likelihoods is larger than the 99.99% probability mass. . B.2 This could provide a downstream solution to the problem caused by ranging heads recovery (explained above in A.2). B.3 If pruning is to be maintained, it makes more sense to do it at the very end after all dangling ends hav been recovered and the edges supports are finalized. Of course I assuming here that dangling end recovery does the sensible think of updating those supports are the graphs is modified. C. The use of Smith-Waterman in dangling end recovery does not seem totally optimal or even needed. . C.1 Recovering tails quite often this finish with the same sequence as the reference path because in fact they are supposed to end like that by construction (reads are trimmed by AR coordinates). For example, this can be cause because due to the k-mer size there is not enough based after variation for the paths to merge back. In this case you can simply merge the last vertices of the tail and the reference, faster and potentially more accurate. . C.2 Similarly dangling heads, at least part of the sequence of those dangling heads are clearly threadable back into the graph without the need of SW. For example look at the AA…AAAAAGA sequence in the picture below. . C.3 PairHMM runs in effect are performing SW kind of computations and so it is totally possible to use its partial result to find good alignment of dangling ends back to other parts of the graph without the need of running a separate SW thus saving time.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/264
https://github.com/broadinstitute/gatk/issues/264:2096,Safety,Recover,Recovering,2096,"er approach to select best haplotypes that can handle complex graph we might well not need to prune low supported hap early as they seemly they won't be selected if the are not amongst the best haplotypes. . B.1 Now that still would produce a considerable number of unlikely haplotypes that would cause a CPU burden. That can be changed by imposing another kinds of limit, For example we include all haplotypes with scores (likelihoods) that are Q0 - Q40 or we include haplotypes until the sum of their likelihoods is larger than the 99.99% probability mass. . B.2 This could provide a downstream solution to the problem caused by ranging heads recovery (explained above in A.2). B.3 If pruning is to be maintained, it makes more sense to do it at the very end after all dangling ends hav been recovered and the edges supports are finalized. Of course I assuming here that dangling end recovery does the sensible think of updating those supports are the graphs is modified. C. The use of Smith-Waterman in dangling end recovery does not seem totally optimal or even needed. . C.1 Recovering tails quite often this finish with the same sequence as the reference path because in fact they are supposed to end like that by construction (reads are trimmed by AR coordinates). For example, this can be cause because due to the k-mer size there is not enough based after variation for the paths to merge back. In this case you can simply merge the last vertices of the tail and the reference, faster and potentially more accurate. . C.2 Similarly dangling heads, at least part of the sequence of those dangling heads are clearly threadable back into the graph without the need of SW. For example look at the AA…AAAAAGA sequence in the picture below. . C.3 PairHMM runs in effect are performing SW kind of computations and so it is totally possible to use its partial result to find good alignment of dangling ends back to other parts of the graph without the need of running a separate SW thus saving time.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/264
https://github.com/broadinstitute/gatk/issues/264:2441,Usability,simpl,simply,2441,"er approach to select best haplotypes that can handle complex graph we might well not need to prune low supported hap early as they seemly they won't be selected if the are not amongst the best haplotypes. . B.1 Now that still would produce a considerable number of unlikely haplotypes that would cause a CPU burden. That can be changed by imposing another kinds of limit, For example we include all haplotypes with scores (likelihoods) that are Q0 - Q40 or we include haplotypes until the sum of their likelihoods is larger than the 99.99% probability mass. . B.2 This could provide a downstream solution to the problem caused by ranging heads recovery (explained above in A.2). B.3 If pruning is to be maintained, it makes more sense to do it at the very end after all dangling ends hav been recovered and the edges supports are finalized. Of course I assuming here that dangling end recovery does the sensible think of updating those supports are the graphs is modified. C. The use of Smith-Waterman in dangling end recovery does not seem totally optimal or even needed. . C.1 Recovering tails quite often this finish with the same sequence as the reference path because in fact they are supposed to end like that by construction (reads are trimmed by AR coordinates). For example, this can be cause because due to the k-mer size there is not enough based after variation for the paths to merge back. In this case you can simply merge the last vertices of the tail and the reference, faster and potentially more accurate. . C.2 Similarly dangling heads, at least part of the sequence of those dangling heads are clearly threadable back into the graph without the need of SW. For example look at the AA…AAAAAGA sequence in the picture below. . C.3 PairHMM runs in effect are performing SW kind of computations and so it is totally possible to use its partial result to find good alignment of dangling ends back to other parts of the graph without the need of running a separate SW thus saving time.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/264
https://github.com/broadinstitute/gatk/issues/264:2631,Usability,clear,clearly,2631,"er approach to select best haplotypes that can handle complex graph we might well not need to prune low supported hap early as they seemly they won't be selected if the are not amongst the best haplotypes. . B.1 Now that still would produce a considerable number of unlikely haplotypes that would cause a CPU burden. That can be changed by imposing another kinds of limit, For example we include all haplotypes with scores (likelihoods) that are Q0 - Q40 or we include haplotypes until the sum of their likelihoods is larger than the 99.99% probability mass. . B.2 This could provide a downstream solution to the problem caused by ranging heads recovery (explained above in A.2). B.3 If pruning is to be maintained, it makes more sense to do it at the very end after all dangling ends hav been recovered and the edges supports are finalized. Of course I assuming here that dangling end recovery does the sensible think of updating those supports are the graphs is modified. C. The use of Smith-Waterman in dangling end recovery does not seem totally optimal or even needed. . C.1 Recovering tails quite often this finish with the same sequence as the reference path because in fact they are supposed to end like that by construction (reads are trimmed by AR coordinates). For example, this can be cause because due to the k-mer size there is not enough based after variation for the paths to merge back. In this case you can simply merge the last vertices of the tail and the reference, faster and potentially more accurate. . C.2 Similarly dangling heads, at least part of the sequence of those dangling heads are clearly threadable back into the graph without the need of SW. For example look at the AA…AAAAAGA sequence in the picture below. . C.3 PairHMM runs in effect are performing SW kind of computations and so it is totally possible to use its partial result to find good alignment of dangling ends back to other parts of the graph without the need of running a separate SW thus saving time.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/264
https://github.com/broadinstitute/gatk/issues/265:172,Testability,test,testing,172,"Original ticket by @jmthibault79 . CombineGVCFs with --convertToBasePairResolution doesn't fully cover the intervals given. I'm trying to create very small files (for NAVS testing) from GVCFs. An input file has these reference blocks. Let's call them Blocks 1,2,3:. ```; 1 10189399 . A <NON_REF> . . END=10189558 GT:DP:GQ:MIN_DP:PL 0/0:94:99:46:0,96,1440; 1 10190507 . A <NON_REF> . . END=10190923 GT:DP:GQ:MIN_DP:PL 0/0:214:99:45:0,105,1575; 1 10192376 . C <NON_REF> . . END=10192406 GT:DP:GQ:MIN_DP:PL 0/0:14:42:8:0,21,297; ```. This command line with an interval entirely contained in Block 2 produces nothing:. ```; java -jar <GATK> \; -T CombineGVCFs \; -L 1:10,190,850-10,190,889 \; --convertToBasePairResolution \; -V <infile> -o <outfile>; ```. Expanding the interval to overlap portions of Block 1 and Block 3 produces results for Block 2 and the portion of Block 3 which corresponds to my intervals. It appears that only reference blocks which begin in the supplied intervals are processed. ---. > @jmthibault79:; > This may be a more general problem with processing GVCFs, and it may also relate to the CombineGVCFs bug @valentinruanorubio is working on.; > ; > @vruano:; > I suspect that this is rather something to do with the VCF RodBinding processing code not using the END info field to determine whether a record overlaps a position. I guess it relies on the POS value and the length of the REF string to do that. That should be fixed in the (VCF) ROD traversal code. Perhaps we could have a GVCF specific code if it does help.; > Also if it were possible to explicitly get the previous record that does not overlap the position programmatically, that would be enough to address this issue. However the other solution above would be cleaner.; > ; > @eitanbanks:; > To fix this problem the getEnd() method of VariantContext would need to check for the presence of the ""END"" annotation in the INFO field. However, I'm not sure the INFO field is always decoded at this point (and doing s",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/265
https://github.com/broadinstitute/gatk/issues/266:61,Availability,recover,recovery,61,Originally by @vruano . Currently the dangling head and tail recovery algorithm only handle simple paths without furcations from the dangling source/sink vertex and the reference path. . However some variation that fail in complex dangling subgraphs can be lost. For example. https://www.pivotaltracker.com/story/show/80381400 ; So this story is about implementing an improved algorithm to handle these cases.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/266
https://github.com/broadinstitute/gatk/issues/266:61,Safety,recover,recovery,61,Originally by @vruano . Currently the dangling head and tail recovery algorithm only handle simple paths without furcations from the dangling source/sink vertex and the reference path. . However some variation that fail in complex dangling subgraphs can be lost. For example. https://www.pivotaltracker.com/story/show/80381400 ; So this story is about implementing an improved algorithm to handle these cases.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/266
https://github.com/broadinstitute/gatk/issues/266:92,Usability,simpl,simple,92,Originally by @vruano . Currently the dangling head and tail recovery algorithm only handle simple paths without furcations from the dangling source/sink vertex and the reference path. . However some variation that fail in complex dangling subgraphs can be lost. For example. https://www.pivotaltracker.com/story/show/80381400 ; So this story is about implementing an improved algorithm to handle these cases.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/266
https://github.com/broadinstitute/gatk/issues/267:206,Availability,robust,robustness,206,"Originally from @vruano . Depending of what ploidy we use AR may return different active region boundaries. This differences cause the haploid assembly to fail with the larger region hightlight the lack of robustness of the current approach. More concretely the problem seem to be the presence of cycle in the larger region. Files are located in . ```; /humgen/gsa-hpprojects/dev/valentin/bug-reports/non-rubsassembly-with-ploidy4. cd $THAT_DIR; sh ./run.sh; ```. in CEUTrio*ploidy4.vcf the variant 20:22064431 is missing (as some other in the same region) which is a TP in knowledge base. . If you look into the debug output ploidy2.err and ploidy4.err, the latter attempts to assemble a larger region failing due to a cycle. . AR traversal comes out with different active region boundaries because the engine used takes as a parameter the ploidy. That is not by itself a bug and a bad think is just that the assembly fails for the extended region. . The task here is to improve the assembly algorithm to cope with this situations better (perhaps handle cycles appropriately).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/267
https://github.com/broadinstitute/gatk/issues/267:26,Integrability,Depend,Depending,26,"Originally from @vruano . Depending of what ploidy we use AR may return different active region boundaries. This differences cause the haploid assembly to fail with the larger region hightlight the lack of robustness of the current approach. More concretely the problem seem to be the presence of cycle in the larger region. Files are located in . ```; /humgen/gsa-hpprojects/dev/valentin/bug-reports/non-rubsassembly-with-ploidy4. cd $THAT_DIR; sh ./run.sh; ```. in CEUTrio*ploidy4.vcf the variant 20:22064431 is missing (as some other in the same region) which is a TP in knowledge base. . If you look into the debug output ploidy2.err and ploidy4.err, the latter attempts to assemble a larger region failing due to a cycle. . AR traversal comes out with different active region boundaries because the engine used takes as a parameter the ploidy. That is not by itself a bug and a bad think is just that the assembly fails for the extended region. . The task here is to improve the assembly algorithm to cope with this situations better (perhaps handle cycles appropriately).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/267
https://github.com/broadinstitute/gatk/issues/267:933,Modifiability,extend,extended,933,"Originally from @vruano . Depending of what ploidy we use AR may return different active region boundaries. This differences cause the haploid assembly to fail with the larger region hightlight the lack of robustness of the current approach. More concretely the problem seem to be the presence of cycle in the larger region. Files are located in . ```; /humgen/gsa-hpprojects/dev/valentin/bug-reports/non-rubsassembly-with-ploidy4. cd $THAT_DIR; sh ./run.sh; ```. in CEUTrio*ploidy4.vcf the variant 20:22064431 is missing (as some other in the same region) which is a TP in knowledge base. . If you look into the debug output ploidy2.err and ploidy4.err, the latter attempts to assemble a larger region failing due to a cycle. . AR traversal comes out with different active region boundaries because the engine used takes as a parameter the ploidy. That is not by itself a bug and a bad think is just that the assembly fails for the extended region. . The task here is to improve the assembly algorithm to cope with this situations better (perhaps handle cycles appropriately).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/267
https://github.com/broadinstitute/gatk/issues/268:85,Availability,error,error,85,"It seems that insQual and delQual score may produce by BQSR or modified by the Indel error model may sum more than 1. Eg. IQ = 1, DQ = 1 so 0.9 prob of an insertion and 0.9 prob of a deletion. This would result Prob > 1 in PairHMM (a different bug from the previously reported to this regard). . The question is how to fix this… must be controlled by BQSR/ index error model… should result in a warning and the qual adjusted to a maximum error probability.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/268
https://github.com/broadinstitute/gatk/issues/268:363,Availability,error,error,363,"It seems that insQual and delQual score may produce by BQSR or modified by the Indel error model may sum more than 1. Eg. IQ = 1, DQ = 1 so 0.9 prob of an insertion and 0.9 prob of a deletion. This would result Prob > 1 in PairHMM (a different bug from the previously reported to this regard). . The question is how to fix this… must be controlled by BQSR/ index error model… should result in a warning and the qual adjusted to a maximum error probability.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/268
https://github.com/broadinstitute/gatk/issues/268:438,Availability,error,error,438,"It seems that insQual and delQual score may produce by BQSR or modified by the Indel error model may sum more than 1. Eg. IQ = 1, DQ = 1 so 0.9 prob of an insertion and 0.9 prob of a deletion. This would result Prob > 1 in PairHMM (a different bug from the previously reported to this regard). . The question is how to fix this… must be controlled by BQSR/ index error model… should result in a warning and the qual adjusted to a maximum error probability.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/268
https://github.com/broadinstitute/gatk/issues/275:51,Integrability,depend,dependent,51,PrintReads is a trivial walker but it has an order dependent output which may be less trivial in dataflow.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/275
https://github.com/broadinstitute/gatk/issues/276:107,Availability,error,errors,107,How do we do this? What happens if a job runs locally but fails in the cloud? How do we log and understand errors?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/276
https://github.com/broadinstitute/gatk/issues/276:88,Testability,log,log,88,How do we do this? What happens if a job runs locally but fails in the cloud? How do we log and understand errors?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/276
https://github.com/broadinstitute/gatk/issues/280:11,Deployability,pipeline,pipeline,11,A full bam pipeline scattered n ways.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/280
https://github.com/broadinstitute/gatk/issues/283:0,Integrability,Wrap,Wrap,0,Wrap Reads within object containing commonly-needed API methods for reads; Convert between Reads and SAMRecords (for legacy code),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/283
https://github.com/broadinstitute/gatk/issues/284:31,Performance,bottleneck,bottlenecks,31,How do we profile and identify bottlenecks?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/284
https://github.com/broadinstitute/gatk/pull/287:5,Safety,avoid,avoid,5,lets avoid those 5-10 seconds of waiting for cran on every build,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/287
https://github.com/broadinstitute/gatk/pull/296:475,Availability,down,download,475,"changes to build.gradle; R package installation is now part of the gradle build; install_R_packages.R no longer reinstalls existing packages; a warning will be emitted if this fails. compilation no longer depends on R installation, installation does. test run in parallel now; this is set to use 2 cores on travis and 4 locally. adding a note about our R dependency to the readme. travis changes; adding caching to travis for dramatic R installation speedup; updating gradle download because it was using an out of date link. misc changes:; adding an additional flag to mark duplicates to avoid the garbage collection statistics while integration testing; tagging tests that depend on R for future use",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/296
https://github.com/broadinstitute/gatk/pull/296:35,Deployability,install,installation,35,"changes to build.gradle; R package installation is now part of the gradle build; install_R_packages.R no longer reinstalls existing packages; a warning will be emitted if this fails. compilation no longer depends on R installation, installation does. test run in parallel now; this is set to use 2 cores on travis and 4 locally. adding a note about our R dependency to the readme. travis changes; adding caching to travis for dramatic R installation speedup; updating gradle download because it was using an out of date link. misc changes:; adding an additional flag to mark duplicates to avoid the garbage collection statistics while integration testing; tagging tests that depend on R for future use",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/296
https://github.com/broadinstitute/gatk/pull/296:218,Deployability,install,installation,218,"changes to build.gradle; R package installation is now part of the gradle build; install_R_packages.R no longer reinstalls existing packages; a warning will be emitted if this fails. compilation no longer depends on R installation, installation does. test run in parallel now; this is set to use 2 cores on travis and 4 locally. adding a note about our R dependency to the readme. travis changes; adding caching to travis for dramatic R installation speedup; updating gradle download because it was using an out of date link. misc changes:; adding an additional flag to mark duplicates to avoid the garbage collection statistics while integration testing; tagging tests that depend on R for future use",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/296
https://github.com/broadinstitute/gatk/pull/296:232,Deployability,install,installation,232,"changes to build.gradle; R package installation is now part of the gradle build; install_R_packages.R no longer reinstalls existing packages; a warning will be emitted if this fails. compilation no longer depends on R installation, installation does. test run in parallel now; this is set to use 2 cores on travis and 4 locally. adding a note about our R dependency to the readme. travis changes; adding caching to travis for dramatic R installation speedup; updating gradle download because it was using an out of date link. misc changes:; adding an additional flag to mark duplicates to avoid the garbage collection statistics while integration testing; tagging tests that depend on R for future use",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/296
https://github.com/broadinstitute/gatk/pull/296:437,Deployability,install,installation,437,"changes to build.gradle; R package installation is now part of the gradle build; install_R_packages.R no longer reinstalls existing packages; a warning will be emitted if this fails. compilation no longer depends on R installation, installation does. test run in parallel now; this is set to use 2 cores on travis and 4 locally. adding a note about our R dependency to the readme. travis changes; adding caching to travis for dramatic R installation speedup; updating gradle download because it was using an out of date link. misc changes:; adding an additional flag to mark duplicates to avoid the garbage collection statistics while integration testing; tagging tests that depend on R for future use",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/296
https://github.com/broadinstitute/gatk/pull/296:635,Deployability,integrat,integration,635,"changes to build.gradle; R package installation is now part of the gradle build; install_R_packages.R no longer reinstalls existing packages; a warning will be emitted if this fails. compilation no longer depends on R installation, installation does. test run in parallel now; this is set to use 2 cores on travis and 4 locally. adding a note about our R dependency to the readme. travis changes; adding caching to travis for dramatic R installation speedup; updating gradle download because it was using an out of date link. misc changes:; adding an additional flag to mark duplicates to avoid the garbage collection statistics while integration testing; tagging tests that depend on R for future use",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/296
https://github.com/broadinstitute/gatk/pull/296:205,Integrability,depend,depends,205,"changes to build.gradle; R package installation is now part of the gradle build; install_R_packages.R no longer reinstalls existing packages; a warning will be emitted if this fails. compilation no longer depends on R installation, installation does. test run in parallel now; this is set to use 2 cores on travis and 4 locally. adding a note about our R dependency to the readme. travis changes; adding caching to travis for dramatic R installation speedup; updating gradle download because it was using an out of date link. misc changes:; adding an additional flag to mark duplicates to avoid the garbage collection statistics while integration testing; tagging tests that depend on R for future use",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/296
https://github.com/broadinstitute/gatk/pull/296:355,Integrability,depend,dependency,355,"changes to build.gradle; R package installation is now part of the gradle build; install_R_packages.R no longer reinstalls existing packages; a warning will be emitted if this fails. compilation no longer depends on R installation, installation does. test run in parallel now; this is set to use 2 cores on travis and 4 locally. adding a note about our R dependency to the readme. travis changes; adding caching to travis for dramatic R installation speedup; updating gradle download because it was using an out of date link. misc changes:; adding an additional flag to mark duplicates to avoid the garbage collection statistics while integration testing; tagging tests that depend on R for future use",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/296
https://github.com/broadinstitute/gatk/pull/296:635,Integrability,integrat,integration,635,"changes to build.gradle; R package installation is now part of the gradle build; install_R_packages.R no longer reinstalls existing packages; a warning will be emitted if this fails. compilation no longer depends on R installation, installation does. test run in parallel now; this is set to use 2 cores on travis and 4 locally. adding a note about our R dependency to the readme. travis changes; adding caching to travis for dramatic R installation speedup; updating gradle download because it was using an out of date link. misc changes:; adding an additional flag to mark duplicates to avoid the garbage collection statistics while integration testing; tagging tests that depend on R for future use",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/296
https://github.com/broadinstitute/gatk/pull/296:675,Integrability,depend,depend,675,"changes to build.gradle; R package installation is now part of the gradle build; install_R_packages.R no longer reinstalls existing packages; a warning will be emitted if this fails. compilation no longer depends on R installation, installation does. test run in parallel now; this is set to use 2 cores on travis and 4 locally. adding a note about our R dependency to the readme. travis changes; adding caching to travis for dramatic R installation speedup; updating gradle download because it was using an out of date link. misc changes:; adding an additional flag to mark duplicates to avoid the garbage collection statistics while integration testing; tagging tests that depend on R for future use",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/296
https://github.com/broadinstitute/gatk/pull/296:589,Safety,avoid,avoid,589,"changes to build.gradle; R package installation is now part of the gradle build; install_R_packages.R no longer reinstalls existing packages; a warning will be emitted if this fails. compilation no longer depends on R installation, installation does. test run in parallel now; this is set to use 2 cores on travis and 4 locally. adding a note about our R dependency to the readme. travis changes; adding caching to travis for dramatic R installation speedup; updating gradle download because it was using an out of date link. misc changes:; adding an additional flag to mark duplicates to avoid the garbage collection statistics while integration testing; tagging tests that depend on R for future use",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/296
https://github.com/broadinstitute/gatk/pull/296:251,Testability,test,test,251,"changes to build.gradle; R package installation is now part of the gradle build; install_R_packages.R no longer reinstalls existing packages; a warning will be emitted if this fails. compilation no longer depends on R installation, installation does. test run in parallel now; this is set to use 2 cores on travis and 4 locally. adding a note about our R dependency to the readme. travis changes; adding caching to travis for dramatic R installation speedup; updating gradle download because it was using an out of date link. misc changes:; adding an additional flag to mark duplicates to avoid the garbage collection statistics while integration testing; tagging tests that depend on R for future use",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/296
https://github.com/broadinstitute/gatk/pull/296:647,Testability,test,testing,647,"changes to build.gradle; R package installation is now part of the gradle build; install_R_packages.R no longer reinstalls existing packages; a warning will be emitted if this fails. compilation no longer depends on R installation, installation does. test run in parallel now; this is set to use 2 cores on travis and 4 locally. adding a note about our R dependency to the readme. travis changes; adding caching to travis for dramatic R installation speedup; updating gradle download because it was using an out of date link. misc changes:; adding an additional flag to mark duplicates to avoid the garbage collection statistics while integration testing; tagging tests that depend on R for future use",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/296
https://github.com/broadinstitute/gatk/pull/296:664,Testability,test,tests,664,"changes to build.gradle; R package installation is now part of the gradle build; install_R_packages.R no longer reinstalls existing packages; a warning will be emitted if this fails. compilation no longer depends on R installation, installation does. test run in parallel now; this is set to use 2 cores on travis and 4 locally. adding a note about our R dependency to the readme. travis changes; adding caching to travis for dramatic R installation speedup; updating gradle download because it was using an out of date link. misc changes:; adding an additional flag to mark duplicates to avoid the garbage collection statistics while integration testing; tagging tests that depend on R for future use",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/296
https://github.com/broadinstitute/gatk/pull/297:658,Availability,avail,available,658,"-Created a new class of tool, IntervalWalker, that processes a single interval at a time,; with the ability to query optional overlapping sources of reads, reference data, and/or; features/variants. Current implementation is simple/naive with no special caching;; performance issues will be addressed once we port this traversal type to dataflow. -Added the ability for VariantWalkers to access contextual reads/reference/feature data. -To enable the above changes, migrated most of the engine to use SimpleIntervals rather; than GenomeLocs. This allows for the creation of Context objects in traversals where there; is not necessarily a sequence dictionary available (eg., VariantWalker). -Moved shared arguments/code from Walker classes up into GATKTool. Still some issues; related to marking engine-wide arguments as optional/required on a per-traversal or; per-tool basis, but tickets have been created for these. -Since there isn't yet an htsjdk release that contains SimpleInterval, temporarily; checked a copy of it into our repo, which we can remove the next time we; rev htsjdk. TODOs:. -We currently still require a sequence dictionary to actually parse intervals in; IntervalArgumentCollection. This is due entirely to our support of intervals without; specific stop positions (eg., ""chr1"" and ""chr1:1+"") -- for these intervals we must; look up the stop position in a sequence dictionary. This means that IntervalWalkers; currently require at least one input that contains a sequence dictionary (although; VariantWalkers do not). We should look into ways of relaxing this restriction. Resolves #109",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/297
https://github.com/broadinstitute/gatk/pull/297:951,Deployability,release,release,951,"-Created a new class of tool, IntervalWalker, that processes a single interval at a time,; with the ability to query optional overlapping sources of reads, reference data, and/or; features/variants. Current implementation is simple/naive with no special caching;; performance issues will be addressed once we port this traversal type to dataflow. -Added the ability for VariantWalkers to access contextual reads/reference/feature data. -To enable the above changes, migrated most of the engine to use SimpleIntervals rather; than GenomeLocs. This allows for the creation of Context objects in traversals where there; is not necessarily a sequence dictionary available (eg., VariantWalker). -Moved shared arguments/code from Walker classes up into GATKTool. Still some issues; related to marking engine-wide arguments as optional/required on a per-traversal or; per-tool basis, but tickets have been created for these. -Since there isn't yet an htsjdk release that contains SimpleInterval, temporarily; checked a copy of it into our repo, which we can remove the next time we; rev htsjdk. TODOs:. -We currently still require a sequence dictionary to actually parse intervals in; IntervalArgumentCollection. This is due entirely to our support of intervals without; specific stop positions (eg., ""chr1"" and ""chr1:1+"") -- for these intervals we must; look up the stop position in a sequence dictionary. This means that IntervalWalkers; currently require at least one input that contains a sequence dictionary (although; VariantWalkers do not). We should look into ways of relaxing this restriction. Resolves #109",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/297
https://github.com/broadinstitute/gatk/pull/297:264,Performance,perform,performance,264,"-Created a new class of tool, IntervalWalker, that processes a single interval at a time,; with the ability to query optional overlapping sources of reads, reference data, and/or; features/variants. Current implementation is simple/naive with no special caching;; performance issues will be addressed once we port this traversal type to dataflow. -Added the ability for VariantWalkers to access contextual reads/reference/feature data. -To enable the above changes, migrated most of the engine to use SimpleIntervals rather; than GenomeLocs. This allows for the creation of Context objects in traversals where there; is not necessarily a sequence dictionary available (eg., VariantWalker). -Moved shared arguments/code from Walker classes up into GATKTool. Still some issues; related to marking engine-wide arguments as optional/required on a per-traversal or; per-tool basis, but tickets have been created for these. -Since there isn't yet an htsjdk release that contains SimpleInterval, temporarily; checked a copy of it into our repo, which we can remove the next time we; rev htsjdk. TODOs:. -We currently still require a sequence dictionary to actually parse intervals in; IntervalArgumentCollection. This is due entirely to our support of intervals without; specific stop positions (eg., ""chr1"" and ""chr1:1+"") -- for these intervals we must; look up the stop position in a sequence dictionary. This means that IntervalWalkers; currently require at least one input that contains a sequence dictionary (although; VariantWalkers do not). We should look into ways of relaxing this restriction. Resolves #109",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/297
https://github.com/broadinstitute/gatk/pull/297:388,Security,access,access,388,"-Created a new class of tool, IntervalWalker, that processes a single interval at a time,; with the ability to query optional overlapping sources of reads, reference data, and/or; features/variants. Current implementation is simple/naive with no special caching;; performance issues will be addressed once we port this traversal type to dataflow. -Added the ability for VariantWalkers to access contextual reads/reference/feature data. -To enable the above changes, migrated most of the engine to use SimpleIntervals rather; than GenomeLocs. This allows for the creation of Context objects in traversals where there; is not necessarily a sequence dictionary available (eg., VariantWalker). -Moved shared arguments/code from Walker classes up into GATKTool. Still some issues; related to marking engine-wide arguments as optional/required on a per-traversal or; per-tool basis, but tickets have been created for these. -Since there isn't yet an htsjdk release that contains SimpleInterval, temporarily; checked a copy of it into our repo, which we can remove the next time we; rev htsjdk. TODOs:. -We currently still require a sequence dictionary to actually parse intervals in; IntervalArgumentCollection. This is due entirely to our support of intervals without; specific stop positions (eg., ""chr1"" and ""chr1:1+"") -- for these intervals we must; look up the stop position in a sequence dictionary. This means that IntervalWalkers; currently require at least one input that contains a sequence dictionary (although; VariantWalkers do not). We should look into ways of relaxing this restriction. Resolves #109",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/297
https://github.com/broadinstitute/gatk/pull/297:225,Usability,simpl,simple,225,"-Created a new class of tool, IntervalWalker, that processes a single interval at a time,; with the ability to query optional overlapping sources of reads, reference data, and/or; features/variants. Current implementation is simple/naive with no special caching;; performance issues will be addressed once we port this traversal type to dataflow. -Added the ability for VariantWalkers to access contextual reads/reference/feature data. -To enable the above changes, migrated most of the engine to use SimpleIntervals rather; than GenomeLocs. This allows for the creation of Context objects in traversals where there; is not necessarily a sequence dictionary available (eg., VariantWalker). -Moved shared arguments/code from Walker classes up into GATKTool. Still some issues; related to marking engine-wide arguments as optional/required on a per-traversal or; per-tool basis, but tickets have been created for these. -Since there isn't yet an htsjdk release that contains SimpleInterval, temporarily; checked a copy of it into our repo, which we can remove the next time we; rev htsjdk. TODOs:. -We currently still require a sequence dictionary to actually parse intervals in; IntervalArgumentCollection. This is due entirely to our support of intervals without; specific stop positions (eg., ""chr1"" and ""chr1:1+"") -- for these intervals we must; look up the stop position in a sequence dictionary. This means that IntervalWalkers; currently require at least one input that contains a sequence dictionary (although; VariantWalkers do not). We should look into ways of relaxing this restriction. Resolves #109",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/297
https://github.com/broadinstitute/gatk/pull/297:501,Usability,Simpl,SimpleIntervals,501,"-Created a new class of tool, IntervalWalker, that processes a single interval at a time,; with the ability to query optional overlapping sources of reads, reference data, and/or; features/variants. Current implementation is simple/naive with no special caching;; performance issues will be addressed once we port this traversal type to dataflow. -Added the ability for VariantWalkers to access contextual reads/reference/feature data. -To enable the above changes, migrated most of the engine to use SimpleIntervals rather; than GenomeLocs. This allows for the creation of Context objects in traversals where there; is not necessarily a sequence dictionary available (eg., VariantWalker). -Moved shared arguments/code from Walker classes up into GATKTool. Still some issues; related to marking engine-wide arguments as optional/required on a per-traversal or; per-tool basis, but tickets have been created for these. -Since there isn't yet an htsjdk release that contains SimpleInterval, temporarily; checked a copy of it into our repo, which we can remove the next time we; rev htsjdk. TODOs:. -We currently still require a sequence dictionary to actually parse intervals in; IntervalArgumentCollection. This is due entirely to our support of intervals without; specific stop positions (eg., ""chr1"" and ""chr1:1+"") -- for these intervals we must; look up the stop position in a sequence dictionary. This means that IntervalWalkers; currently require at least one input that contains a sequence dictionary (although; VariantWalkers do not). We should look into ways of relaxing this restriction. Resolves #109",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/297
https://github.com/broadinstitute/gatk/pull/297:973,Usability,Simpl,SimpleInterval,973,"-Created a new class of tool, IntervalWalker, that processes a single interval at a time,; with the ability to query optional overlapping sources of reads, reference data, and/or; features/variants. Current implementation is simple/naive with no special caching;; performance issues will be addressed once we port this traversal type to dataflow. -Added the ability for VariantWalkers to access contextual reads/reference/feature data. -To enable the above changes, migrated most of the engine to use SimpleIntervals rather; than GenomeLocs. This allows for the creation of Context objects in traversals where there; is not necessarily a sequence dictionary available (eg., VariantWalker). -Moved shared arguments/code from Walker classes up into GATKTool. Still some issues; related to marking engine-wide arguments as optional/required on a per-traversal or; per-tool basis, but tickets have been created for these. -Since there isn't yet an htsjdk release that contains SimpleInterval, temporarily; checked a copy of it into our repo, which we can remove the next time we; rev htsjdk. TODOs:. -We currently still require a sequence dictionary to actually parse intervals in; IntervalArgumentCollection. This is due entirely to our support of intervals without; specific stop positions (eg., ""chr1"" and ""chr1:1+"") -- for these intervals we must; look up the stop position in a sequence dictionary. This means that IntervalWalkers; currently require at least one input that contains a sequence dictionary (although; VariantWalkers do not). We should look into ways of relaxing this restriction. Resolves #109",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/297
https://github.com/broadinstitute/gatk/issues/298:754,Availability,robust,robust,754,"Currently, `IntervalArgumentCollection` still uses `GenomeLocs` internally during parsing, despite the rest of the engine using `SimpleIntervals`. This forces us to provide a sequence dictionary when interval arguments are present even if the only input is an interval list (eg., an `IntervalWalker` that purely processes/transforms intervals). We should provide a mode in `IntervalArgumentCollection` in which intervals can be parsed into `SimpleIntervals` without a sequence dictionary. This will require us to fill in a special value such as `Integer.MAX_VALUE` for the stop position of intervals that don't contain a stop position (eg., ""chr1"" or ""chr1:1+""), since we won't know the true contig lengths, but our future query interfaces should all be robust to requests for locations outside of contig boundaries (and not blow up given such requests). This will also require adding some way of determining whether or not an interval has been validated against a sequence dictionary -- perhaps `ValidatedInterval` could be a subclass of `SimpleInterval`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/298
https://github.com/broadinstitute/gatk/issues/298:729,Integrability,interface,interfaces,729,"Currently, `IntervalArgumentCollection` still uses `GenomeLocs` internally during parsing, despite the rest of the engine using `SimpleIntervals`. This forces us to provide a sequence dictionary when interval arguments are present even if the only input is an interval list (eg., an `IntervalWalker` that purely processes/transforms intervals). We should provide a mode in `IntervalArgumentCollection` in which intervals can be parsed into `SimpleIntervals` without a sequence dictionary. This will require us to fill in a special value such as `Integer.MAX_VALUE` for the stop position of intervals that don't contain a stop position (eg., ""chr1"" or ""chr1:1+""), since we won't know the true contig lengths, but our future query interfaces should all be robust to requests for locations outside of contig boundaries (and not blow up given such requests). This will also require adding some way of determining whether or not an interval has been validated against a sequence dictionary -- perhaps `ValidatedInterval` could be a subclass of `SimpleInterval`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/298
https://github.com/broadinstitute/gatk/issues/298:945,Security,validat,validated,945,"Currently, `IntervalArgumentCollection` still uses `GenomeLocs` internally during parsing, despite the rest of the engine using `SimpleIntervals`. This forces us to provide a sequence dictionary when interval arguments are present even if the only input is an interval list (eg., an `IntervalWalker` that purely processes/transforms intervals). We should provide a mode in `IntervalArgumentCollection` in which intervals can be parsed into `SimpleIntervals` without a sequence dictionary. This will require us to fill in a special value such as `Integer.MAX_VALUE` for the stop position of intervals that don't contain a stop position (eg., ""chr1"" or ""chr1:1+""), since we won't know the true contig lengths, but our future query interfaces should all be robust to requests for locations outside of contig boundaries (and not blow up given such requests). This will also require adding some way of determining whether or not an interval has been validated against a sequence dictionary -- perhaps `ValidatedInterval` could be a subclass of `SimpleInterval`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/298
https://github.com/broadinstitute/gatk/issues/298:997,Security,Validat,ValidatedInterval,997,"Currently, `IntervalArgumentCollection` still uses `GenomeLocs` internally during parsing, despite the rest of the engine using `SimpleIntervals`. This forces us to provide a sequence dictionary when interval arguments are present even if the only input is an interval list (eg., an `IntervalWalker` that purely processes/transforms intervals). We should provide a mode in `IntervalArgumentCollection` in which intervals can be parsed into `SimpleIntervals` without a sequence dictionary. This will require us to fill in a special value such as `Integer.MAX_VALUE` for the stop position of intervals that don't contain a stop position (eg., ""chr1"" or ""chr1:1+""), since we won't know the true contig lengths, but our future query interfaces should all be robust to requests for locations outside of contig boundaries (and not blow up given such requests). This will also require adding some way of determining whether or not an interval has been validated against a sequence dictionary -- perhaps `ValidatedInterval` could be a subclass of `SimpleInterval`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/298
https://github.com/broadinstitute/gatk/issues/298:129,Usability,Simpl,SimpleIntervals,129,"Currently, `IntervalArgumentCollection` still uses `GenomeLocs` internally during parsing, despite the rest of the engine using `SimpleIntervals`. This forces us to provide a sequence dictionary when interval arguments are present even if the only input is an interval list (eg., an `IntervalWalker` that purely processes/transforms intervals). We should provide a mode in `IntervalArgumentCollection` in which intervals can be parsed into `SimpleIntervals` without a sequence dictionary. This will require us to fill in a special value such as `Integer.MAX_VALUE` for the stop position of intervals that don't contain a stop position (eg., ""chr1"" or ""chr1:1+""), since we won't know the true contig lengths, but our future query interfaces should all be robust to requests for locations outside of contig boundaries (and not blow up given such requests). This will also require adding some way of determining whether or not an interval has been validated against a sequence dictionary -- perhaps `ValidatedInterval` could be a subclass of `SimpleInterval`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/298
https://github.com/broadinstitute/gatk/issues/298:441,Usability,Simpl,SimpleIntervals,441,"Currently, `IntervalArgumentCollection` still uses `GenomeLocs` internally during parsing, despite the rest of the engine using `SimpleIntervals`. This forces us to provide a sequence dictionary when interval arguments are present even if the only input is an interval list (eg., an `IntervalWalker` that purely processes/transforms intervals). We should provide a mode in `IntervalArgumentCollection` in which intervals can be parsed into `SimpleIntervals` without a sequence dictionary. This will require us to fill in a special value such as `Integer.MAX_VALUE` for the stop position of intervals that don't contain a stop position (eg., ""chr1"" or ""chr1:1+""), since we won't know the true contig lengths, but our future query interfaces should all be robust to requests for locations outside of contig boundaries (and not blow up given such requests). This will also require adding some way of determining whether or not an interval has been validated against a sequence dictionary -- perhaps `ValidatedInterval` could be a subclass of `SimpleInterval`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/298
https://github.com/broadinstitute/gatk/issues/298:1040,Usability,Simpl,SimpleInterval,1040,"Currently, `IntervalArgumentCollection` still uses `GenomeLocs` internally during parsing, despite the rest of the engine using `SimpleIntervals`. This forces us to provide a sequence dictionary when interval arguments are present even if the only input is an interval list (eg., an `IntervalWalker` that purely processes/transforms intervals). We should provide a mode in `IntervalArgumentCollection` in which intervals can be parsed into `SimpleIntervals` without a sequence dictionary. This will require us to fill in a special value such as `Integer.MAX_VALUE` for the stop position of intervals that don't contain a stop position (eg., ""chr1"" or ""chr1:1+""), since we won't know the true contig lengths, but our future query interfaces should all be robust to requests for locations outside of contig boundaries (and not blow up given such requests). This will also require adding some way of determining whether or not an interval has been validated against a sequence dictionary -- perhaps `ValidatedInterval` could be a subclass of `SimpleInterval`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/298
https://github.com/broadinstitute/gatk/issues/300:195,Performance,perform,perform,195,"Currently, Feature arguments for each tool are discovered automatically through reflection via FeatureManager and initialized/added to a query pool. Perhaps for the sake of consistency we should perform the same kind of auto-discovery for all common kinds of input arguments (reads, reference, etc.)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/300
https://github.com/broadinstitute/gatk/issues/301:197,Availability,avail,available,197,"Some kinds of interval files contain a sequence dictionary (eg., Picard-style interval files). We should use these sequence dictionaries when they're present and no other sequence dictionaries are available from the other inputs.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/301
https://github.com/broadinstitute/gatk/issues/303:312,Modifiability,config,configurable,312,"Will proposed a novel approach to filtering that could prove useful: instead of running a sequence of filters and discarding items as soon as they fail a filter, use `com.google.cloud.dataflow.sdk.transforms.Partition<T>` to group items into `PCollections` according to which filters they fail, and then allow a configurable transform to be run on each partition. By default we might just count the number of items failing each filter, but we could have the option of doing things like saving the failing items somewhere for debugging purposes, or outputting for each item the list of ALL filters that it fails.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/303
https://github.com/broadinstitute/gatk/issues/305:51,Usability,Simpl,SimpleInterval,51,Add the most commonly-used interval operations to `SimpleInterval` in htsjdk (without going too crazy -- it is called SIMPLEInterval after all...),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/305
https://github.com/broadinstitute/gatk/issues/305:118,Usability,SIMPL,SIMPLEInterval,118,Add the most commonly-used interval operations to `SimpleInterval` in htsjdk (without going too crazy -- it is called SIMPLEInterval after all...),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/305
https://github.com/broadinstitute/gatk/issues/306:135,Testability,test,tested,135,it is a mix of distribution code and model code. distro code should come from Apache commons and the remainder needs to be renamed and tested,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/306
https://github.com/broadinstitute/gatk/pull/307:51,Availability,failure,failures,51,"We've been experiencing intermittent, inexplicable failures in the test suite.; In a recent travis build, an assertion in MisencodedBaseQualityReadTransformerUnitTest; failed for no reason at all, then passed on the re-run (with no code changes). My initial suspect is the new test suite parallelism, which based on my experience; with TestNG is a potentially inexhaustible source of weird, impossible-to-reproduce errors.; Let's turn this off for now and see if these intermittent failures go away. The; extra speed isn't worth it if we can't trust the results of our travis builds!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/307
https://github.com/broadinstitute/gatk/pull/307:415,Availability,error,errors,415,"We've been experiencing intermittent, inexplicable failures in the test suite.; In a recent travis build, an assertion in MisencodedBaseQualityReadTransformerUnitTest; failed for no reason at all, then passed on the re-run (with no code changes). My initial suspect is the new test suite parallelism, which based on my experience; with TestNG is a potentially inexhaustible source of weird, impossible-to-reproduce errors.; Let's turn this off for now and see if these intermittent failures go away. The; extra speed isn't worth it if we can't trust the results of our travis builds!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/307
https://github.com/broadinstitute/gatk/pull/307:482,Availability,failure,failures,482,"We've been experiencing intermittent, inexplicable failures in the test suite.; In a recent travis build, an assertion in MisencodedBaseQualityReadTransformerUnitTest; failed for no reason at all, then passed on the re-run (with no code changes). My initial suspect is the new test suite parallelism, which based on my experience; with TestNG is a potentially inexhaustible source of weird, impossible-to-reproduce errors.; Let's turn this off for now and see if these intermittent failures go away. The; extra speed isn't worth it if we can't trust the results of our travis builds!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/307
https://github.com/broadinstitute/gatk/pull/307:67,Testability,test,test,67,"We've been experiencing intermittent, inexplicable failures in the test suite.; In a recent travis build, an assertion in MisencodedBaseQualityReadTransformerUnitTest; failed for no reason at all, then passed on the re-run (with no code changes). My initial suspect is the new test suite parallelism, which based on my experience; with TestNG is a potentially inexhaustible source of weird, impossible-to-reproduce errors.; Let's turn this off for now and see if these intermittent failures go away. The; extra speed isn't worth it if we can't trust the results of our travis builds!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/307
https://github.com/broadinstitute/gatk/pull/307:109,Testability,assert,assertion,109,"We've been experiencing intermittent, inexplicable failures in the test suite.; In a recent travis build, an assertion in MisencodedBaseQualityReadTransformerUnitTest; failed for no reason at all, then passed on the re-run (with no code changes). My initial suspect is the new test suite parallelism, which based on my experience; with TestNG is a potentially inexhaustible source of weird, impossible-to-reproduce errors.; Let's turn this off for now and see if these intermittent failures go away. The; extra speed isn't worth it if we can't trust the results of our travis builds!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/307
https://github.com/broadinstitute/gatk/pull/307:277,Testability,test,test,277,"We've been experiencing intermittent, inexplicable failures in the test suite.; In a recent travis build, an assertion in MisencodedBaseQualityReadTransformerUnitTest; failed for no reason at all, then passed on the re-run (with no code changes). My initial suspect is the new test suite parallelism, which based on my experience; with TestNG is a potentially inexhaustible source of weird, impossible-to-reproduce errors.; Let's turn this off for now and see if these intermittent failures go away. The; extra speed isn't worth it if we can't trust the results of our travis builds!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/307
https://github.com/broadinstitute/gatk/pull/307:336,Testability,Test,TestNG,336,"We've been experiencing intermittent, inexplicable failures in the test suite.; In a recent travis build, an assertion in MisencodedBaseQualityReadTransformerUnitTest; failed for no reason at all, then passed on the re-run (with no code changes). My initial suspect is the new test suite parallelism, which based on my experience; with TestNG is a potentially inexhaustible source of weird, impossible-to-reproduce errors.; Let's turn this off for now and see if these intermittent failures go away. The; extra speed isn't worth it if we can't trust the results of our travis builds!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/307
https://github.com/broadinstitute/gatk/pull/308:103,Modifiability,inherit,inherited,103,"-Within a tool, Feature headers can now be obtained from a FeatureContext within apply(),; or from the inherited method getHeaderForFeatures() outside of apply() (eg., in onTraversalStart()). -VariantWalkers have the additional inherited convenience method getHeaderForVariants(); that returns the header for the driving source of variants typed as a VCFHeader. -Engine-facing classes FeatureManager and FeatureDataSource now also expose headers. Requested by Adam",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/308
https://github.com/broadinstitute/gatk/pull/308:228,Modifiability,inherit,inherited,228,"-Within a tool, Feature headers can now be obtained from a FeatureContext within apply(),; or from the inherited method getHeaderForFeatures() outside of apply() (eg., in onTraversalStart()). -VariantWalkers have the additional inherited convenience method getHeaderForVariants(); that returns the header for the driving source of variants typed as a VCFHeader. -Engine-facing classes FeatureManager and FeatureDataSource now also expose headers. Requested by Adam",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/308
https://github.com/broadinstitute/gatk/pull/308:431,Security,expose,expose,431,"-Within a tool, Feature headers can now be obtained from a FeatureContext within apply(),; or from the inherited method getHeaderForFeatures() outside of apply() (eg., in onTraversalStart()). -VariantWalkers have the additional inherited convenience method getHeaderForVariants(); that returns the header for the driving source of variants typed as a VCFHeader. -Engine-facing classes FeatureManager and FeatureDataSource now also expose headers. Requested by Adam",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/308
https://github.com/broadinstitute/gatk/issues/311:628,Availability,FAILURE,FAILURE,628,"> Gradle test org.broadinstitute.hellbender.transformers.MisencodedBaseQualityReadTransformerUnitTest.testFixBadQuals FAILED; > ; > ```; > java.lang.AssertionError: arrays differ firstly at element [0]; expected value is <28> but was <-3>. ; > at org.testng.Assert.fail(Assert.java:94); > at org.testng.Assert.assertEquals(Assert.java:772); > at org.testng.Assert.assertEquals(Assert.java:746); > at org.broadinstitute.hellbender.transformers.MisencodedBaseQualityReadTransformerUnitTest.testFixBadQuals(MisencodedBaseQualityReadTransformerUnitTest.java:73); > ```; > ; > 180309 tests completed, 1 failed; > :test FAILED; > ; > FAILURE: Build failed with an exception. This was running on the current master without parallelism. . @droazen Is this the same failure you saw before?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/311
https://github.com/broadinstitute/gatk/issues/311:757,Availability,failure,failure,757,"> Gradle test org.broadinstitute.hellbender.transformers.MisencodedBaseQualityReadTransformerUnitTest.testFixBadQuals FAILED; > ; > ```; > java.lang.AssertionError: arrays differ firstly at element [0]; expected value is <28> but was <-3>. ; > at org.testng.Assert.fail(Assert.java:94); > at org.testng.Assert.assertEquals(Assert.java:772); > at org.testng.Assert.assertEquals(Assert.java:746); > at org.broadinstitute.hellbender.transformers.MisencodedBaseQualityReadTransformerUnitTest.testFixBadQuals(MisencodedBaseQualityReadTransformerUnitTest.java:73); > ```; > ; > 180309 tests completed, 1 failed; > :test FAILED; > ; > FAILURE: Build failed with an exception. This was running on the current master without parallelism. . @droazen Is this the same failure you saw before?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/311
https://github.com/broadinstitute/gatk/issues/311:9,Testability,test,test,9,"> Gradle test org.broadinstitute.hellbender.transformers.MisencodedBaseQualityReadTransformerUnitTest.testFixBadQuals FAILED; > ; > ```; > java.lang.AssertionError: arrays differ firstly at element [0]; expected value is <28> but was <-3>. ; > at org.testng.Assert.fail(Assert.java:94); > at org.testng.Assert.assertEquals(Assert.java:772); > at org.testng.Assert.assertEquals(Assert.java:746); > at org.broadinstitute.hellbender.transformers.MisencodedBaseQualityReadTransformerUnitTest.testFixBadQuals(MisencodedBaseQualityReadTransformerUnitTest.java:73); > ```; > ; > 180309 tests completed, 1 failed; > :test FAILED; > ; > FAILURE: Build failed with an exception. This was running on the current master without parallelism. . @droazen Is this the same failure you saw before?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/311
https://github.com/broadinstitute/gatk/issues/311:102,Testability,test,testFixBadQuals,102,"> Gradle test org.broadinstitute.hellbender.transformers.MisencodedBaseQualityReadTransformerUnitTest.testFixBadQuals FAILED; > ; > ```; > java.lang.AssertionError: arrays differ firstly at element [0]; expected value is <28> but was <-3>. ; > at org.testng.Assert.fail(Assert.java:94); > at org.testng.Assert.assertEquals(Assert.java:772); > at org.testng.Assert.assertEquals(Assert.java:746); > at org.broadinstitute.hellbender.transformers.MisencodedBaseQualityReadTransformerUnitTest.testFixBadQuals(MisencodedBaseQualityReadTransformerUnitTest.java:73); > ```; > ; > 180309 tests completed, 1 failed; > :test FAILED; > ; > FAILURE: Build failed with an exception. This was running on the current master without parallelism. . @droazen Is this the same failure you saw before?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/311
https://github.com/broadinstitute/gatk/issues/311:149,Testability,Assert,AssertionError,149,"> Gradle test org.broadinstitute.hellbender.transformers.MisencodedBaseQualityReadTransformerUnitTest.testFixBadQuals FAILED; > ; > ```; > java.lang.AssertionError: arrays differ firstly at element [0]; expected value is <28> but was <-3>. ; > at org.testng.Assert.fail(Assert.java:94); > at org.testng.Assert.assertEquals(Assert.java:772); > at org.testng.Assert.assertEquals(Assert.java:746); > at org.broadinstitute.hellbender.transformers.MisencodedBaseQualityReadTransformerUnitTest.testFixBadQuals(MisencodedBaseQualityReadTransformerUnitTest.java:73); > ```; > ; > 180309 tests completed, 1 failed; > :test FAILED; > ; > FAILURE: Build failed with an exception. This was running on the current master without parallelism. . @droazen Is this the same failure you saw before?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/311
https://github.com/broadinstitute/gatk/issues/311:251,Testability,test,testng,251,"> Gradle test org.broadinstitute.hellbender.transformers.MisencodedBaseQualityReadTransformerUnitTest.testFixBadQuals FAILED; > ; > ```; > java.lang.AssertionError: arrays differ firstly at element [0]; expected value is <28> but was <-3>. ; > at org.testng.Assert.fail(Assert.java:94); > at org.testng.Assert.assertEquals(Assert.java:772); > at org.testng.Assert.assertEquals(Assert.java:746); > at org.broadinstitute.hellbender.transformers.MisencodedBaseQualityReadTransformerUnitTest.testFixBadQuals(MisencodedBaseQualityReadTransformerUnitTest.java:73); > ```; > ; > 180309 tests completed, 1 failed; > :test FAILED; > ; > FAILURE: Build failed with an exception. This was running on the current master without parallelism. . @droazen Is this the same failure you saw before?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/311
https://github.com/broadinstitute/gatk/issues/311:258,Testability,Assert,Assert,258,"> Gradle test org.broadinstitute.hellbender.transformers.MisencodedBaseQualityReadTransformerUnitTest.testFixBadQuals FAILED; > ; > ```; > java.lang.AssertionError: arrays differ firstly at element [0]; expected value is <28> but was <-3>. ; > at org.testng.Assert.fail(Assert.java:94); > at org.testng.Assert.assertEquals(Assert.java:772); > at org.testng.Assert.assertEquals(Assert.java:746); > at org.broadinstitute.hellbender.transformers.MisencodedBaseQualityReadTransformerUnitTest.testFixBadQuals(MisencodedBaseQualityReadTransformerUnitTest.java:73); > ```; > ; > 180309 tests completed, 1 failed; > :test FAILED; > ; > FAILURE: Build failed with an exception. This was running on the current master without parallelism. . @droazen Is this the same failure you saw before?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/311
https://github.com/broadinstitute/gatk/issues/311:270,Testability,Assert,Assert,270,"> Gradle test org.broadinstitute.hellbender.transformers.MisencodedBaseQualityReadTransformerUnitTest.testFixBadQuals FAILED; > ; > ```; > java.lang.AssertionError: arrays differ firstly at element [0]; expected value is <28> but was <-3>. ; > at org.testng.Assert.fail(Assert.java:94); > at org.testng.Assert.assertEquals(Assert.java:772); > at org.testng.Assert.assertEquals(Assert.java:746); > at org.broadinstitute.hellbender.transformers.MisencodedBaseQualityReadTransformerUnitTest.testFixBadQuals(MisencodedBaseQualityReadTransformerUnitTest.java:73); > ```; > ; > 180309 tests completed, 1 failed; > :test FAILED; > ; > FAILURE: Build failed with an exception. This was running on the current master without parallelism. . @droazen Is this the same failure you saw before?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/311
https://github.com/broadinstitute/gatk/issues/311:296,Testability,test,testng,296,"> Gradle test org.broadinstitute.hellbender.transformers.MisencodedBaseQualityReadTransformerUnitTest.testFixBadQuals FAILED; > ; > ```; > java.lang.AssertionError: arrays differ firstly at element [0]; expected value is <28> but was <-3>. ; > at org.testng.Assert.fail(Assert.java:94); > at org.testng.Assert.assertEquals(Assert.java:772); > at org.testng.Assert.assertEquals(Assert.java:746); > at org.broadinstitute.hellbender.transformers.MisencodedBaseQualityReadTransformerUnitTest.testFixBadQuals(MisencodedBaseQualityReadTransformerUnitTest.java:73); > ```; > ; > 180309 tests completed, 1 failed; > :test FAILED; > ; > FAILURE: Build failed with an exception. This was running on the current master without parallelism. . @droazen Is this the same failure you saw before?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/311
https://github.com/broadinstitute/gatk/issues/311:303,Testability,Assert,Assert,303,"> Gradle test org.broadinstitute.hellbender.transformers.MisencodedBaseQualityReadTransformerUnitTest.testFixBadQuals FAILED; > ; > ```; > java.lang.AssertionError: arrays differ firstly at element [0]; expected value is <28> but was <-3>. ; > at org.testng.Assert.fail(Assert.java:94); > at org.testng.Assert.assertEquals(Assert.java:772); > at org.testng.Assert.assertEquals(Assert.java:746); > at org.broadinstitute.hellbender.transformers.MisencodedBaseQualityReadTransformerUnitTest.testFixBadQuals(MisencodedBaseQualityReadTransformerUnitTest.java:73); > ```; > ; > 180309 tests completed, 1 failed; > :test FAILED; > ; > FAILURE: Build failed with an exception. This was running on the current master without parallelism. . @droazen Is this the same failure you saw before?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/311
https://github.com/broadinstitute/gatk/issues/311:310,Testability,assert,assertEquals,310,"> Gradle test org.broadinstitute.hellbender.transformers.MisencodedBaseQualityReadTransformerUnitTest.testFixBadQuals FAILED; > ; > ```; > java.lang.AssertionError: arrays differ firstly at element [0]; expected value is <28> but was <-3>. ; > at org.testng.Assert.fail(Assert.java:94); > at org.testng.Assert.assertEquals(Assert.java:772); > at org.testng.Assert.assertEquals(Assert.java:746); > at org.broadinstitute.hellbender.transformers.MisencodedBaseQualityReadTransformerUnitTest.testFixBadQuals(MisencodedBaseQualityReadTransformerUnitTest.java:73); > ```; > ; > 180309 tests completed, 1 failed; > :test FAILED; > ; > FAILURE: Build failed with an exception. This was running on the current master without parallelism. . @droazen Is this the same failure you saw before?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/311
https://github.com/broadinstitute/gatk/issues/311:323,Testability,Assert,Assert,323,"> Gradle test org.broadinstitute.hellbender.transformers.MisencodedBaseQualityReadTransformerUnitTest.testFixBadQuals FAILED; > ; > ```; > java.lang.AssertionError: arrays differ firstly at element [0]; expected value is <28> but was <-3>. ; > at org.testng.Assert.fail(Assert.java:94); > at org.testng.Assert.assertEquals(Assert.java:772); > at org.testng.Assert.assertEquals(Assert.java:746); > at org.broadinstitute.hellbender.transformers.MisencodedBaseQualityReadTransformerUnitTest.testFixBadQuals(MisencodedBaseQualityReadTransformerUnitTest.java:73); > ```; > ; > 180309 tests completed, 1 failed; > :test FAILED; > ; > FAILURE: Build failed with an exception. This was running on the current master without parallelism. . @droazen Is this the same failure you saw before?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/311
https://github.com/broadinstitute/gatk/issues/311:350,Testability,test,testng,350,"> Gradle test org.broadinstitute.hellbender.transformers.MisencodedBaseQualityReadTransformerUnitTest.testFixBadQuals FAILED; > ; > ```; > java.lang.AssertionError: arrays differ firstly at element [0]; expected value is <28> but was <-3>. ; > at org.testng.Assert.fail(Assert.java:94); > at org.testng.Assert.assertEquals(Assert.java:772); > at org.testng.Assert.assertEquals(Assert.java:746); > at org.broadinstitute.hellbender.transformers.MisencodedBaseQualityReadTransformerUnitTest.testFixBadQuals(MisencodedBaseQualityReadTransformerUnitTest.java:73); > ```; > ; > 180309 tests completed, 1 failed; > :test FAILED; > ; > FAILURE: Build failed with an exception. This was running on the current master without parallelism. . @droazen Is this the same failure you saw before?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/311
https://github.com/broadinstitute/gatk/issues/311:357,Testability,Assert,Assert,357,"> Gradle test org.broadinstitute.hellbender.transformers.MisencodedBaseQualityReadTransformerUnitTest.testFixBadQuals FAILED; > ; > ```; > java.lang.AssertionError: arrays differ firstly at element [0]; expected value is <28> but was <-3>. ; > at org.testng.Assert.fail(Assert.java:94); > at org.testng.Assert.assertEquals(Assert.java:772); > at org.testng.Assert.assertEquals(Assert.java:746); > at org.broadinstitute.hellbender.transformers.MisencodedBaseQualityReadTransformerUnitTest.testFixBadQuals(MisencodedBaseQualityReadTransformerUnitTest.java:73); > ```; > ; > 180309 tests completed, 1 failed; > :test FAILED; > ; > FAILURE: Build failed with an exception. This was running on the current master without parallelism. . @droazen Is this the same failure you saw before?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/311
https://github.com/broadinstitute/gatk/issues/311:364,Testability,assert,assertEquals,364,"> Gradle test org.broadinstitute.hellbender.transformers.MisencodedBaseQualityReadTransformerUnitTest.testFixBadQuals FAILED; > ; > ```; > java.lang.AssertionError: arrays differ firstly at element [0]; expected value is <28> but was <-3>. ; > at org.testng.Assert.fail(Assert.java:94); > at org.testng.Assert.assertEquals(Assert.java:772); > at org.testng.Assert.assertEquals(Assert.java:746); > at org.broadinstitute.hellbender.transformers.MisencodedBaseQualityReadTransformerUnitTest.testFixBadQuals(MisencodedBaseQualityReadTransformerUnitTest.java:73); > ```; > ; > 180309 tests completed, 1 failed; > :test FAILED; > ; > FAILURE: Build failed with an exception. This was running on the current master without parallelism. . @droazen Is this the same failure you saw before?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/311
https://github.com/broadinstitute/gatk/issues/311:377,Testability,Assert,Assert,377,"> Gradle test org.broadinstitute.hellbender.transformers.MisencodedBaseQualityReadTransformerUnitTest.testFixBadQuals FAILED; > ; > ```; > java.lang.AssertionError: arrays differ firstly at element [0]; expected value is <28> but was <-3>. ; > at org.testng.Assert.fail(Assert.java:94); > at org.testng.Assert.assertEquals(Assert.java:772); > at org.testng.Assert.assertEquals(Assert.java:746); > at org.broadinstitute.hellbender.transformers.MisencodedBaseQualityReadTransformerUnitTest.testFixBadQuals(MisencodedBaseQualityReadTransformerUnitTest.java:73); > ```; > ; > 180309 tests completed, 1 failed; > :test FAILED; > ; > FAILURE: Build failed with an exception. This was running on the current master without parallelism. . @droazen Is this the same failure you saw before?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/311
https://github.com/broadinstitute/gatk/issues/311:488,Testability,test,testFixBadQuals,488,"> Gradle test org.broadinstitute.hellbender.transformers.MisencodedBaseQualityReadTransformerUnitTest.testFixBadQuals FAILED; > ; > ```; > java.lang.AssertionError: arrays differ firstly at element [0]; expected value is <28> but was <-3>. ; > at org.testng.Assert.fail(Assert.java:94); > at org.testng.Assert.assertEquals(Assert.java:772); > at org.testng.Assert.assertEquals(Assert.java:746); > at org.broadinstitute.hellbender.transformers.MisencodedBaseQualityReadTransformerUnitTest.testFixBadQuals(MisencodedBaseQualityReadTransformerUnitTest.java:73); > ```; > ; > 180309 tests completed, 1 failed; > :test FAILED; > ; > FAILURE: Build failed with an exception. This was running on the current master without parallelism. . @droazen Is this the same failure you saw before?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/311
https://github.com/broadinstitute/gatk/issues/311:579,Testability,test,tests,579,"> Gradle test org.broadinstitute.hellbender.transformers.MisencodedBaseQualityReadTransformerUnitTest.testFixBadQuals FAILED; > ; > ```; > java.lang.AssertionError: arrays differ firstly at element [0]; expected value is <28> but was <-3>. ; > at org.testng.Assert.fail(Assert.java:94); > at org.testng.Assert.assertEquals(Assert.java:772); > at org.testng.Assert.assertEquals(Assert.java:746); > at org.broadinstitute.hellbender.transformers.MisencodedBaseQualityReadTransformerUnitTest.testFixBadQuals(MisencodedBaseQualityReadTransformerUnitTest.java:73); > ```; > ; > 180309 tests completed, 1 failed; > :test FAILED; > ; > FAILURE: Build failed with an exception. This was running on the current master without parallelism. . @droazen Is this the same failure you saw before?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/311
https://github.com/broadinstitute/gatk/issues/311:609,Testability,test,test,609,"> Gradle test org.broadinstitute.hellbender.transformers.MisencodedBaseQualityReadTransformerUnitTest.testFixBadQuals FAILED; > ; > ```; > java.lang.AssertionError: arrays differ firstly at element [0]; expected value is <28> but was <-3>. ; > at org.testng.Assert.fail(Assert.java:94); > at org.testng.Assert.assertEquals(Assert.java:772); > at org.testng.Assert.assertEquals(Assert.java:746); > at org.broadinstitute.hellbender.transformers.MisencodedBaseQualityReadTransformerUnitTest.testFixBadQuals(MisencodedBaseQualityReadTransformerUnitTest.java:73); > ```; > ; > 180309 tests completed, 1 failed; > :test FAILED; > ; > FAILURE: Build failed with an exception. This was running on the current master without parallelism. . @droazen Is this the same failure you saw before?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/311
https://github.com/broadinstitute/gatk/issues/312:290,Usability,clear,clear,290,"Currently read transformers are `read -> read`, but they often work by mutating their input parameter and returning it. We should either change it to a more functional style, with a new read returned and the passed in read left unchanged, or we should make them `void` functions to make it clear that they are intended to mutate their input read.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/312
https://github.com/broadinstitute/gatk/pull/313:32,Availability,error,errors,32,hopeful this will fix transient errors in MisencodedBaseQualityReadTransformerTest (see #311),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/313
https://github.com/broadinstitute/gatk/pull/314:0,Security,Validat,ValidateVariants,0,ValidateVariants + tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/314
https://github.com/broadinstitute/gatk/pull/314:19,Testability,test,tests,19,ValidateVariants + tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/314
https://github.com/broadinstitute/gatk/pull/316:223,Integrability,interface,interface,223,"-We've decided to develop SimpleInterval in hellbender for now so that we don't; have to deal with the tricky politics of standardization across htsjdk (though; we will eventually address this when we're ready). -Locatable interface remains in htsjdk, so a small victory there. -Added overlaps()/contains()/size() methods to SimpleInterval. -Removed support for zero-length intervals for now, since none of our current; query interfaces support it, and it complicates basic interval operations.; Will open a ticket to investigate whether support for zero-length intervals; will be needed given GA4GH query interfaces, future representation of; insertions, etc. Resolves #305",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/316
https://github.com/broadinstitute/gatk/pull/316:426,Integrability,interface,interfaces,426,"-We've decided to develop SimpleInterval in hellbender for now so that we don't; have to deal with the tricky politics of standardization across htsjdk (though; we will eventually address this when we're ready). -Locatable interface remains in htsjdk, so a small victory there. -Added overlaps()/contains()/size() methods to SimpleInterval. -Removed support for zero-length intervals for now, since none of our current; query interfaces support it, and it complicates basic interval operations.; Will open a ticket to investigate whether support for zero-length intervals; will be needed given GA4GH query interfaces, future representation of; insertions, etc. Resolves #305",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/316
https://github.com/broadinstitute/gatk/pull/316:606,Integrability,interface,interfaces,606,"-We've decided to develop SimpleInterval in hellbender for now so that we don't; have to deal with the tricky politics of standardization across htsjdk (though; we will eventually address this when we're ready). -Locatable interface remains in htsjdk, so a small victory there. -Added overlaps()/contains()/size() methods to SimpleInterval. -Removed support for zero-length intervals for now, since none of our current; query interfaces support it, and it complicates basic interval operations.; Will open a ticket to investigate whether support for zero-length intervals; will be needed given GA4GH query interfaces, future representation of; insertions, etc. Resolves #305",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/316
https://github.com/broadinstitute/gatk/pull/316:26,Usability,Simpl,SimpleInterval,26,"-We've decided to develop SimpleInterval in hellbender for now so that we don't; have to deal with the tricky politics of standardization across htsjdk (though; we will eventually address this when we're ready). -Locatable interface remains in htsjdk, so a small victory there. -Added overlaps()/contains()/size() methods to SimpleInterval. -Removed support for zero-length intervals for now, since none of our current; query interfaces support it, and it complicates basic interval operations.; Will open a ticket to investigate whether support for zero-length intervals; will be needed given GA4GH query interfaces, future representation of; insertions, etc. Resolves #305",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/316
https://github.com/broadinstitute/gatk/pull/316:325,Usability,Simpl,SimpleInterval,325,"-We've decided to develop SimpleInterval in hellbender for now so that we don't; have to deal with the tricky politics of standardization across htsjdk (though; we will eventually address this when we're ready). -Locatable interface remains in htsjdk, so a small victory there. -Added overlaps()/contains()/size() methods to SimpleInterval. -Removed support for zero-length intervals for now, since none of our current; query interfaces support it, and it complicates basic interval operations.; Will open a ticket to investigate whether support for zero-length intervals; will be needed given GA4GH query interfaces, future representation of; insertions, etc. Resolves #305",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/316
https://github.com/broadinstitute/gatk/issues/317:92,Availability,error,error-prone,92,"Some factors to consider in making this decision:. -Operations on zero-length intervals are error-prone due to lack of understanding/consensus about expected results (eg., should a query on a zero-length interval return records that abut it on either side?). -We need to determine how a query involving a zero-length interval is supposed to behave in the GA4GH API, as this does not seem to be clearly defined in the API documentation (eg., http://ga4gh.org/documentation/api/v0.5.1/ga4gh_api.html#/schema/%2FUsers%2Fkeenan%2FDropbox%2Fgit-checkouts%2Fschemas%2Fsrc%2Fmain%2Fresources%2Favro%2Ftarget%2Fall.avpr/org.ga4gh.GASearchReadsRequest). The representation is 0-based closed-open (like BED), which means zero-length intervals are possible, but their behavior appears undefined. -None of our current query interfaces (tribble/samtools) support computing overlap with zero-length intervals (although they don't throw an error when given such an interval -- they just never return any records for such queries). -It seems unlikely that we'll be moving anytime soon to representing insertions using zero-length intervals, given that the VCF spec requires insertions to be represented in terms of the preceding reference base.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/317
https://github.com/broadinstitute/gatk/issues/317:925,Availability,error,error,925,"Some factors to consider in making this decision:. -Operations on zero-length intervals are error-prone due to lack of understanding/consensus about expected results (eg., should a query on a zero-length interval return records that abut it on either side?). -We need to determine how a query involving a zero-length interval is supposed to behave in the GA4GH API, as this does not seem to be clearly defined in the API documentation (eg., http://ga4gh.org/documentation/api/v0.5.1/ga4gh_api.html#/schema/%2FUsers%2Fkeenan%2FDropbox%2Fgit-checkouts%2Fschemas%2Fsrc%2Fmain%2Fresources%2Favro%2Ftarget%2Fall.avpr/org.ga4gh.GASearchReadsRequest). The representation is 0-based closed-open (like BED), which means zero-length intervals are possible, but their behavior appears undefined. -None of our current query interfaces (tribble/samtools) support computing overlap with zero-length intervals (although they don't throw an error when given such an interval -- they just never return any records for such queries). -It seems unlikely that we'll be moving anytime soon to representing insertions using zero-length intervals, given that the VCF spec requires insertions to be represented in terms of the preceding reference base.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/317
https://github.com/broadinstitute/gatk/issues/317:812,Integrability,interface,interfaces,812,"Some factors to consider in making this decision:. -Operations on zero-length intervals are error-prone due to lack of understanding/consensus about expected results (eg., should a query on a zero-length interval return records that abut it on either side?). -We need to determine how a query involving a zero-length interval is supposed to behave in the GA4GH API, as this does not seem to be clearly defined in the API documentation (eg., http://ga4gh.org/documentation/api/v0.5.1/ga4gh_api.html#/schema/%2FUsers%2Fkeenan%2FDropbox%2Fgit-checkouts%2Fschemas%2Fsrc%2Fmain%2Fresources%2Favro%2Ftarget%2Fall.avpr/org.ga4gh.GASearchReadsRequest). The representation is 0-based closed-open (like BED), which means zero-length intervals are possible, but their behavior appears undefined. -None of our current query interfaces (tribble/samtools) support computing overlap with zero-length intervals (although they don't throw an error when given such an interval -- they just never return any records for such queries). -It seems unlikely that we'll be moving anytime soon to representing insertions using zero-length intervals, given that the VCF spec requires insertions to be represented in terms of the preceding reference base.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/317
https://github.com/broadinstitute/gatk/issues/317:394,Usability,clear,clearly,394,"Some factors to consider in making this decision:. -Operations on zero-length intervals are error-prone due to lack of understanding/consensus about expected results (eg., should a query on a zero-length interval return records that abut it on either side?). -We need to determine how a query involving a zero-length interval is supposed to behave in the GA4GH API, as this does not seem to be clearly defined in the API documentation (eg., http://ga4gh.org/documentation/api/v0.5.1/ga4gh_api.html#/schema/%2FUsers%2Fkeenan%2FDropbox%2Fgit-checkouts%2Fschemas%2Fsrc%2Fmain%2Fresources%2Favro%2Ftarget%2Fall.avpr/org.ga4gh.GASearchReadsRequest). The representation is 0-based closed-open (like BED), which means zero-length intervals are possible, but their behavior appears undefined. -None of our current query interfaces (tribble/samtools) support computing overlap with zero-length intervals (although they don't throw an error when given such an interval -- they just never return any records for such queries). -It seems unlikely that we'll be moving anytime soon to representing insertions using zero-length intervals, given that the VCF spec requires insertions to be represented in terms of the preceding reference base.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/317
https://github.com/broadinstitute/gatk/issues/318:37,Security,Validat,ValidateVariantsIntegrationTest,37,"executing `gradle test -Dtest.single=ValidateVariantsIntegrationTest`; produces, among other things, this:. testBadID2_OKif_notInDBSNP(org.broadinstitute.hellbender.tools.walkers.ValidateVariantsIntegrationTest) produced standard out/err: [Wed Mar 18 21:15:38 EDT 2015] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants --dbsnp **org.broadinstitute.hellbender.engine.FeatureInput@4c4054af** **--validationTypeToExclude [REF, ALLELES, CHR_COUNTS]**. Two problems:; 1) FeatureInput needs a meaningful toString; 2) the argument that is a list of enum values should be printed as multiples of 'validationTypeToExclude' each with a value (so that the commandline is copy-paste-able)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/318
https://github.com/broadinstitute/gatk/issues/318:179,Security,Validat,ValidateVariantsIntegrationTest,179,"executing `gradle test -Dtest.single=ValidateVariantsIntegrationTest`; produces, among other things, this:. testBadID2_OKif_notInDBSNP(org.broadinstitute.hellbender.tools.walkers.ValidateVariantsIntegrationTest) produced standard out/err: [Wed Mar 18 21:15:38 EDT 2015] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants --dbsnp **org.broadinstitute.hellbender.engine.FeatureInput@4c4054af** **--validationTypeToExclude [REF, ALLELES, CHR_COUNTS]**. Two problems:; 1) FeatureInput needs a meaningful toString; 2) the argument that is a list of enum values should be printed as multiples of 'validationTypeToExclude' each with a value (so that the commandline is copy-paste-able)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/318
https://github.com/broadinstitute/gatk/issues/318:327,Security,Validat,ValidateVariants,327,"executing `gradle test -Dtest.single=ValidateVariantsIntegrationTest`; produces, among other things, this:. testBadID2_OKif_notInDBSNP(org.broadinstitute.hellbender.tools.walkers.ValidateVariantsIntegrationTest) produced standard out/err: [Wed Mar 18 21:15:38 EDT 2015] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants --dbsnp **org.broadinstitute.hellbender.engine.FeatureInput@4c4054af** **--validationTypeToExclude [REF, ALLELES, CHR_COUNTS]**. Two problems:; 1) FeatureInput needs a meaningful toString; 2) the argument that is a list of enum values should be printed as multiples of 'validationTypeToExclude' each with a value (so that the commandline is copy-paste-able)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/318
https://github.com/broadinstitute/gatk/issues/318:419,Security,validat,validationTypeToExclude,419,"executing `gradle test -Dtest.single=ValidateVariantsIntegrationTest`; produces, among other things, this:. testBadID2_OKif_notInDBSNP(org.broadinstitute.hellbender.tools.walkers.ValidateVariantsIntegrationTest) produced standard out/err: [Wed Mar 18 21:15:38 EDT 2015] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants --dbsnp **org.broadinstitute.hellbender.engine.FeatureInput@4c4054af** **--validationTypeToExclude [REF, ALLELES, CHR_COUNTS]**. Two problems:; 1) FeatureInput needs a meaningful toString; 2) the argument that is a list of enum values should be printed as multiples of 'validationTypeToExclude' each with a value (so that the commandline is copy-paste-able)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/318
https://github.com/broadinstitute/gatk/issues/318:614,Security,validat,validationTypeToExclude,614,"executing `gradle test -Dtest.single=ValidateVariantsIntegrationTest`; produces, among other things, this:. testBadID2_OKif_notInDBSNP(org.broadinstitute.hellbender.tools.walkers.ValidateVariantsIntegrationTest) produced standard out/err: [Wed Mar 18 21:15:38 EDT 2015] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants --dbsnp **org.broadinstitute.hellbender.engine.FeatureInput@4c4054af** **--validationTypeToExclude [REF, ALLELES, CHR_COUNTS]**. Two problems:; 1) FeatureInput needs a meaningful toString; 2) the argument that is a list of enum values should be printed as multiples of 'validationTypeToExclude' each with a value (so that the commandline is copy-paste-able)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/318
https://github.com/broadinstitute/gatk/issues/318:18,Testability,test,test,18,"executing `gradle test -Dtest.single=ValidateVariantsIntegrationTest`; produces, among other things, this:. testBadID2_OKif_notInDBSNP(org.broadinstitute.hellbender.tools.walkers.ValidateVariantsIntegrationTest) produced standard out/err: [Wed Mar 18 21:15:38 EDT 2015] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants --dbsnp **org.broadinstitute.hellbender.engine.FeatureInput@4c4054af** **--validationTypeToExclude [REF, ALLELES, CHR_COUNTS]**. Two problems:; 1) FeatureInput needs a meaningful toString; 2) the argument that is a list of enum values should be printed as multiples of 'validationTypeToExclude' each with a value (so that the commandline is copy-paste-able)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/318
https://github.com/broadinstitute/gatk/issues/320:229,Energy Efficiency,efficient,efficiently,229,"It would be good to be able to annotate walkers as ""scatterable by sample"" so that tools that only need to see each sample to collect statistics (possibly then collating the results afterwards) would be able to be scattered more efficiently.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/320
https://github.com/broadinstitute/gatk/pull/324:234,Testability,test,test,234,"removing min/max element options in argument; these sound nice, but they were only ever used to indicate that an argument was required or not.; they did not play nicely with optional, which is already confusing enough. fixed a broken test that wasn't actually testing anything. closes #315",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/324
https://github.com/broadinstitute/gatk/pull/324:260,Testability,test,testing,260,"removing min/max element options in argument; these sound nice, but they were only ever used to indicate that an argument was required or not.; they did not play nicely with optional, which is already confusing enough. fixed a broken test that wasn't actually testing anything. closes #315",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/324
https://github.com/broadinstitute/gatk/pull/326:270,Deployability,update,updates,270,"VariantWalker was the only remaining Walker type that didn't support full traversal by; intervals using -L/-XL due to lack of underlying FeatureDataSource support for traversal; by intervals (it only supported individual queries by one interval at a time). This; commit updates FeatureDataSource to allow traversal across all Features overlapping a set; of intervals, and enables -L support in VariantWalker. -Added support for full traversal by a set of intervals to FeatureDataSource; (+ tests). -Enabled -L/-XL support in VariantWalker. Resolves #232",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/326
https://github.com/broadinstitute/gatk/pull/326:490,Testability,test,tests,490,"VariantWalker was the only remaining Walker type that didn't support full traversal by; intervals using -L/-XL due to lack of underlying FeatureDataSource support for traversal; by intervals (it only supported individual queries by one interval at a time). This; commit updates FeatureDataSource to allow traversal across all Features overlapping a set; of intervals, and enables -L support in VariantWalker. -Added support for full traversal by a set of intervals to FeatureDataSource; (+ tests). -Enabled -L/-XL support in VariantWalker. Resolves #232",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/326
https://github.com/broadinstitute/gatk/issues/329:23,Deployability,update,update,23,"It just moved to 1.30, update once it's on maven central.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/329
https://github.com/broadinstitute/gatk/pull/330:47,Deployability,update,updated,47,closes #329 . Removed our copy of `Locatable`; updated `getChr()` and `getSequence()` to standardized `getContig()`,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/330
https://github.com/broadinstitute/gatk/issues/331:104,Deployability,release,released,104,"This issue is to keep a record that we're going to base the initial porting of Picard on version 1.130, released on 3/24/15. This will make it easy to re-sync the tools later on by just diffing against that version to see what changes need to be made.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/331
https://github.com/broadinstitute/gatk/pull/332:6,Deployability,update,updates,6,Minor updates to picard.sam package to reflect latest version.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/332
https://github.com/broadinstitute/gatk/pull/333:148,Testability,test,tests,148,This pull request is about the mixture of gaussians model fitting. Most of the code is a port of GATK3 but I make many changes and added a bunch of tests. I hid the MultivariateGaussian class inside of the model fitting class because it is not a general purpose MultivariateGaussian and just part of the fitting. Adding @cseed as reviewer. @rpoplin can you help too?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/333
https://github.com/broadinstitute/gatk/issues/337:370,Deployability,update,update,370,"Following our recommended IntelliJ setup instructions in our README leads to an IntelliJ project that does not respect the user's PATH environment variable when, eg., building via gradle. We instead end up with a default PATH that includes only a few directories such as `/usr/bin/`. . We need to find a way to get IntelliJ to respect the user's PATH when building, and update our README accordingly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/337
https://github.com/broadinstitute/gatk/issues/337:147,Modifiability,variab,variable,147,"Following our recommended IntelliJ setup instructions in our README leads to an IntelliJ project that does not respect the user's PATH environment variable when, eg., building via gradle. We instead end up with a default PATH that includes only a few directories such as `/usr/bin/`. . We need to find a way to get IntelliJ to respect the user's PATH when building, and update our README accordingly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/337
https://github.com/broadinstitute/gatk/pull/338:134,Usability,simpl,simple,134,VQSR tranche functionality. I had to add the VRAC and VariantDatum (also present on another branch) to make things compile. These are simple classes. @droazen please review,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/338
https://github.com/broadinstitute/gatk/issues/340:196,Deployability,update,updated,196,no-one should be calling close() by themselves. All Closables are Autoclosables and all should be converted to the modern style. Code migrated from Java 6 is full of the old idiom and needs to be updated.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/340
https://github.com/broadinstitute/gatk/issues/342:99,Availability,failure,failure,99,"If I make a tool fail, e.g. a bad argument. the process exit status is 0 making difficult to track failure in including scripts, SGE and (perhaps?) Queue?. Failure should result in a non-zero exit status.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/342
https://github.com/broadinstitute/gatk/issues/342:156,Availability,Failure,Failure,156,"If I make a tool fail, e.g. a bad argument. the process exit status is 0 making difficult to track failure in including scripts, SGE and (perhaps?) Queue?. Failure should result in a non-zero exit status.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/342
https://github.com/broadinstitute/gatk/issues/342:148,Performance,Queue,Queue,148,"If I make a tool fail, e.g. a bad argument. the process exit status is 0 making difficult to track failure in including scripts, SGE and (perhaps?) Queue?. Failure should result in a non-zero exit status.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/342
https://github.com/broadinstitute/gatk/pull/343:97,Availability,error,error,97,surpressing tool output statement if the tool returned null; exiting with 1 if the tool threw an error. should fix #341 and #342 . @vruano Please review,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/343
https://github.com/broadinstitute/gatk/issues/344:61,Usability,simpl,simply,61,Add a tool to count reads that overlap exons (aka targets or simply arbitrary intervals),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/344
https://github.com/broadinstitute/gatk/pull/345:63,Testability,test,tests,63,"Next part of VQSR - the data manager and trainingSet manager + tests.; VariantDatum and VariantRecalibratorArgumentCollection are included here but only to make things compile, no to be reviewed (they are part of another branch). @droazen please review",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/345
https://github.com/broadinstitute/gatk/pull/347:149,Availability,down,down,149,"Here it is. An overview of what's been added:; - metrics package; - a few general metrics classes (e.g. MultiLevelMetrics); - may want to push these down into HTSJDK later; - added some utils; - utils.gene: gene annotation; - utils.illumina: general Illumina-related utils (adapters, etc); - utils.text.parsers: text parsing; - utils.variant: added dbSNP stuff; - MathUtils: added a few basic things (mean, stddev, etc) with unit tests; - tools; - three major packages:; - analysis: metrics + analyses (including necessary Rscripts); - illumina: Illumina parsing + validation; - vcf: VCF manipulation + GenotypeConcordance; - also two smaller packages, fastq and intervals, containing a few tools each; - tests; - all existing tests were ported; still, overall test coverage goes down by ~6%; - all CLP integration tests have been ported to the new argument system; - test data has also been carried over, and is neatly organized; - there are no huge files, and very few above 100KB (just a few VCFs I think); - however, the Illumina test data is pretty big - ~6MB spread over ~1700 files",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/347
https://github.com/broadinstitute/gatk/pull/347:780,Availability,down,down,780,"Here it is. An overview of what's been added:; - metrics package; - a few general metrics classes (e.g. MultiLevelMetrics); - may want to push these down into HTSJDK later; - added some utils; - utils.gene: gene annotation; - utils.illumina: general Illumina-related utils (adapters, etc); - utils.text.parsers: text parsing; - utils.variant: added dbSNP stuff; - MathUtils: added a few basic things (mean, stddev, etc) with unit tests; - tools; - three major packages:; - analysis: metrics + analyses (including necessary Rscripts); - illumina: Illumina parsing + validation; - vcf: VCF manipulation + GenotypeConcordance; - also two smaller packages, fastq and intervals, containing a few tools each; - tests; - all existing tests were ported; still, overall test coverage goes down by ~6%; - all CLP integration tests have been ported to the new argument system; - test data has also been carried over, and is neatly organized; - there are no huge files, and very few above 100KB (just a few VCFs I think); - however, the Illumina test data is pretty big - ~6MB spread over ~1700 files",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/347
https://github.com/broadinstitute/gatk/pull/347:803,Deployability,integrat,integration,803,"Here it is. An overview of what's been added:; - metrics package; - a few general metrics classes (e.g. MultiLevelMetrics); - may want to push these down into HTSJDK later; - added some utils; - utils.gene: gene annotation; - utils.illumina: general Illumina-related utils (adapters, etc); - utils.text.parsers: text parsing; - utils.variant: added dbSNP stuff; - MathUtils: added a few basic things (mean, stddev, etc) with unit tests; - tools; - three major packages:; - analysis: metrics + analyses (including necessary Rscripts); - illumina: Illumina parsing + validation; - vcf: VCF manipulation + GenotypeConcordance; - also two smaller packages, fastq and intervals, containing a few tools each; - tests; - all existing tests were ported; still, overall test coverage goes down by ~6%; - all CLP integration tests have been ported to the new argument system; - test data has also been carried over, and is neatly organized; - there are no huge files, and very few above 100KB (just a few VCFs I think); - however, the Illumina test data is pretty big - ~6MB spread over ~1700 files",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/347
https://github.com/broadinstitute/gatk/pull/347:274,Energy Efficiency,adapt,adapters,274,"Here it is. An overview of what's been added:; - metrics package; - a few general metrics classes (e.g. MultiLevelMetrics); - may want to push these down into HTSJDK later; - added some utils; - utils.gene: gene annotation; - utils.illumina: general Illumina-related utils (adapters, etc); - utils.text.parsers: text parsing; - utils.variant: added dbSNP stuff; - MathUtils: added a few basic things (mean, stddev, etc) with unit tests; - tools; - three major packages:; - analysis: metrics + analyses (including necessary Rscripts); - illumina: Illumina parsing + validation; - vcf: VCF manipulation + GenotypeConcordance; - also two smaller packages, fastq and intervals, containing a few tools each; - tests; - all existing tests were ported; still, overall test coverage goes down by ~6%; - all CLP integration tests have been ported to the new argument system; - test data has also been carried over, and is neatly organized; - there are no huge files, and very few above 100KB (just a few VCFs I think); - however, the Illumina test data is pretty big - ~6MB spread over ~1700 files",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/347
https://github.com/broadinstitute/gatk/pull/347:274,Integrability,adapter,adapters,274,"Here it is. An overview of what's been added:; - metrics package; - a few general metrics classes (e.g. MultiLevelMetrics); - may want to push these down into HTSJDK later; - added some utils; - utils.gene: gene annotation; - utils.illumina: general Illumina-related utils (adapters, etc); - utils.text.parsers: text parsing; - utils.variant: added dbSNP stuff; - MathUtils: added a few basic things (mean, stddev, etc) with unit tests; - tools; - three major packages:; - analysis: metrics + analyses (including necessary Rscripts); - illumina: Illumina parsing + validation; - vcf: VCF manipulation + GenotypeConcordance; - also two smaller packages, fastq and intervals, containing a few tools each; - tests; - all existing tests were ported; still, overall test coverage goes down by ~6%; - all CLP integration tests have been ported to the new argument system; - test data has also been carried over, and is neatly organized; - there are no huge files, and very few above 100KB (just a few VCFs I think); - however, the Illumina test data is pretty big - ~6MB spread over ~1700 files",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/347
https://github.com/broadinstitute/gatk/pull/347:803,Integrability,integrat,integration,803,"Here it is. An overview of what's been added:; - metrics package; - a few general metrics classes (e.g. MultiLevelMetrics); - may want to push these down into HTSJDK later; - added some utils; - utils.gene: gene annotation; - utils.illumina: general Illumina-related utils (adapters, etc); - utils.text.parsers: text parsing; - utils.variant: added dbSNP stuff; - MathUtils: added a few basic things (mean, stddev, etc) with unit tests; - tools; - three major packages:; - analysis: metrics + analyses (including necessary Rscripts); - illumina: Illumina parsing + validation; - vcf: VCF manipulation + GenotypeConcordance; - also two smaller packages, fastq and intervals, containing a few tools each; - tests; - all existing tests were ported; still, overall test coverage goes down by ~6%; - all CLP integration tests have been ported to the new argument system; - test data has also been carried over, and is neatly organized; - there are no huge files, and very few above 100KB (just a few VCFs I think); - however, the Illumina test data is pretty big - ~6MB spread over ~1700 files",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/347
https://github.com/broadinstitute/gatk/pull/347:274,Modifiability,adapt,adapters,274,"Here it is. An overview of what's been added:; - metrics package; - a few general metrics classes (e.g. MultiLevelMetrics); - may want to push these down into HTSJDK later; - added some utils; - utils.gene: gene annotation; - utils.illumina: general Illumina-related utils (adapters, etc); - utils.text.parsers: text parsing; - utils.variant: added dbSNP stuff; - MathUtils: added a few basic things (mean, stddev, etc) with unit tests; - tools; - three major packages:; - analysis: metrics + analyses (including necessary Rscripts); - illumina: Illumina parsing + validation; - vcf: VCF manipulation + GenotypeConcordance; - also two smaller packages, fastq and intervals, containing a few tools each; - tests; - all existing tests were ported; still, overall test coverage goes down by ~6%; - all CLP integration tests have been ported to the new argument system; - test data has also been carried over, and is neatly organized; - there are no huge files, and very few above 100KB (just a few VCFs I think); - however, the Illumina test data is pretty big - ~6MB spread over ~1700 files",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/347
https://github.com/broadinstitute/gatk/pull/347:565,Security,validat,validation,565,"Here it is. An overview of what's been added:; - metrics package; - a few general metrics classes (e.g. MultiLevelMetrics); - may want to push these down into HTSJDK later; - added some utils; - utils.gene: gene annotation; - utils.illumina: general Illumina-related utils (adapters, etc); - utils.text.parsers: text parsing; - utils.variant: added dbSNP stuff; - MathUtils: added a few basic things (mean, stddev, etc) with unit tests; - tools; - three major packages:; - analysis: metrics + analyses (including necessary Rscripts); - illumina: Illumina parsing + validation; - vcf: VCF manipulation + GenotypeConcordance; - also two smaller packages, fastq and intervals, containing a few tools each; - tests; - all existing tests were ported; still, overall test coverage goes down by ~6%; - all CLP integration tests have been ported to the new argument system; - test data has also been carried over, and is neatly organized; - there are no huge files, and very few above 100KB (just a few VCFs I think); - however, the Illumina test data is pretty big - ~6MB spread over ~1700 files",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/347
https://github.com/broadinstitute/gatk/pull/347:430,Testability,test,tests,430,"Here it is. An overview of what's been added:; - metrics package; - a few general metrics classes (e.g. MultiLevelMetrics); - may want to push these down into HTSJDK later; - added some utils; - utils.gene: gene annotation; - utils.illumina: general Illumina-related utils (adapters, etc); - utils.text.parsers: text parsing; - utils.variant: added dbSNP stuff; - MathUtils: added a few basic things (mean, stddev, etc) with unit tests; - tools; - three major packages:; - analysis: metrics + analyses (including necessary Rscripts); - illumina: Illumina parsing + validation; - vcf: VCF manipulation + GenotypeConcordance; - also two smaller packages, fastq and intervals, containing a few tools each; - tests; - all existing tests were ported; still, overall test coverage goes down by ~6%; - all CLP integration tests have been ported to the new argument system; - test data has also been carried over, and is neatly organized; - there are no huge files, and very few above 100KB (just a few VCFs I think); - however, the Illumina test data is pretty big - ~6MB spread over ~1700 files",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/347
https://github.com/broadinstitute/gatk/pull/347:705,Testability,test,tests,705,"Here it is. An overview of what's been added:; - metrics package; - a few general metrics classes (e.g. MultiLevelMetrics); - may want to push these down into HTSJDK later; - added some utils; - utils.gene: gene annotation; - utils.illumina: general Illumina-related utils (adapters, etc); - utils.text.parsers: text parsing; - utils.variant: added dbSNP stuff; - MathUtils: added a few basic things (mean, stddev, etc) with unit tests; - tools; - three major packages:; - analysis: metrics + analyses (including necessary Rscripts); - illumina: Illumina parsing + validation; - vcf: VCF manipulation + GenotypeConcordance; - also two smaller packages, fastq and intervals, containing a few tools each; - tests; - all existing tests were ported; still, overall test coverage goes down by ~6%; - all CLP integration tests have been ported to the new argument system; - test data has also been carried over, and is neatly organized; - there are no huge files, and very few above 100KB (just a few VCFs I think); - however, the Illumina test data is pretty big - ~6MB spread over ~1700 files",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/347
https://github.com/broadinstitute/gatk/pull/347:727,Testability,test,tests,727,"Here it is. An overview of what's been added:; - metrics package; - a few general metrics classes (e.g. MultiLevelMetrics); - may want to push these down into HTSJDK later; - added some utils; - utils.gene: gene annotation; - utils.illumina: general Illumina-related utils (adapters, etc); - utils.text.parsers: text parsing; - utils.variant: added dbSNP stuff; - MathUtils: added a few basic things (mean, stddev, etc) with unit tests; - tools; - three major packages:; - analysis: metrics + analyses (including necessary Rscripts); - illumina: Illumina parsing + validation; - vcf: VCF manipulation + GenotypeConcordance; - also two smaller packages, fastq and intervals, containing a few tools each; - tests; - all existing tests were ported; still, overall test coverage goes down by ~6%; - all CLP integration tests have been ported to the new argument system; - test data has also been carried over, and is neatly organized; - there are no huge files, and very few above 100KB (just a few VCFs I think); - however, the Illumina test data is pretty big - ~6MB spread over ~1700 files",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/347
https://github.com/broadinstitute/gatk/pull/347:761,Testability,test,test,761,"Here it is. An overview of what's been added:; - metrics package; - a few general metrics classes (e.g. MultiLevelMetrics); - may want to push these down into HTSJDK later; - added some utils; - utils.gene: gene annotation; - utils.illumina: general Illumina-related utils (adapters, etc); - utils.text.parsers: text parsing; - utils.variant: added dbSNP stuff; - MathUtils: added a few basic things (mean, stddev, etc) with unit tests; - tools; - three major packages:; - analysis: metrics + analyses (including necessary Rscripts); - illumina: Illumina parsing + validation; - vcf: VCF manipulation + GenotypeConcordance; - also two smaller packages, fastq and intervals, containing a few tools each; - tests; - all existing tests were ported; still, overall test coverage goes down by ~6%; - all CLP integration tests have been ported to the new argument system; - test data has also been carried over, and is neatly organized; - there are no huge files, and very few above 100KB (just a few VCFs I think); - however, the Illumina test data is pretty big - ~6MB spread over ~1700 files",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/347
https://github.com/broadinstitute/gatk/pull/347:815,Testability,test,tests,815,"Here it is. An overview of what's been added:; - metrics package; - a few general metrics classes (e.g. MultiLevelMetrics); - may want to push these down into HTSJDK later; - added some utils; - utils.gene: gene annotation; - utils.illumina: general Illumina-related utils (adapters, etc); - utils.text.parsers: text parsing; - utils.variant: added dbSNP stuff; - MathUtils: added a few basic things (mean, stddev, etc) with unit tests; - tools; - three major packages:; - analysis: metrics + analyses (including necessary Rscripts); - illumina: Illumina parsing + validation; - vcf: VCF manipulation + GenotypeConcordance; - also two smaller packages, fastq and intervals, containing a few tools each; - tests; - all existing tests were ported; still, overall test coverage goes down by ~6%; - all CLP integration tests have been ported to the new argument system; - test data has also been carried over, and is neatly organized; - there are no huge files, and very few above 100KB (just a few VCFs I think); - however, the Illumina test data is pretty big - ~6MB spread over ~1700 files",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/347
https://github.com/broadinstitute/gatk/pull/347:868,Testability,test,test,868,"Here it is. An overview of what's been added:; - metrics package; - a few general metrics classes (e.g. MultiLevelMetrics); - may want to push these down into HTSJDK later; - added some utils; - utils.gene: gene annotation; - utils.illumina: general Illumina-related utils (adapters, etc); - utils.text.parsers: text parsing; - utils.variant: added dbSNP stuff; - MathUtils: added a few basic things (mean, stddev, etc) with unit tests; - tools; - three major packages:; - analysis: metrics + analyses (including necessary Rscripts); - illumina: Illumina parsing + validation; - vcf: VCF manipulation + GenotypeConcordance; - also two smaller packages, fastq and intervals, containing a few tools each; - tests; - all existing tests were ported; still, overall test coverage goes down by ~6%; - all CLP integration tests have been ported to the new argument system; - test data has also been carried over, and is neatly organized; - there are no huge files, and very few above 100KB (just a few VCFs I think); - however, the Illumina test data is pretty big - ~6MB spread over ~1700 files",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/347
https://github.com/broadinstitute/gatk/pull/347:1034,Testability,test,test,1034,"Here it is. An overview of what's been added:; - metrics package; - a few general metrics classes (e.g. MultiLevelMetrics); - may want to push these down into HTSJDK later; - added some utils; - utils.gene: gene annotation; - utils.illumina: general Illumina-related utils (adapters, etc); - utils.text.parsers: text parsing; - utils.variant: added dbSNP stuff; - MathUtils: added a few basic things (mean, stddev, etc) with unit tests; - tools; - three major packages:; - analysis: metrics + analyses (including necessary Rscripts); - illumina: Illumina parsing + validation; - vcf: VCF manipulation + GenotypeConcordance; - also two smaller packages, fastq and intervals, containing a few tools each; - tests; - all existing tests were ported; still, overall test coverage goes down by ~6%; - all CLP integration tests have been ported to the new argument system; - test data has also been carried over, and is neatly organized; - there are no huge files, and very few above 100KB (just a few VCFs I think); - however, the Illumina test data is pretty big - ~6MB spread over ~1700 files",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/347
https://github.com/broadinstitute/gatk/pull/352:43,Modifiability,refactor,refactoring,43,"Preparation for upcoming SAMRecord -> Read refactoring. Wanted to; separate out this trivial package rename, as it was cluttering; the diff on my main branch.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/352
https://github.com/broadinstitute/gatk/issues/355:98,Testability,test,test,98,"@jean-philippe-martin reported a null pointer running the following. ```; BaseRecalibrator -I src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.bam -R hs37d5.fa --RECAL_TABLE_FILE output.table -knownSites src/test/resources/empty.vcf; ```. or . ```; BaseRecalibrator -I src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.bam -R hs37d5.fa --RECAL_TABLE_FILE output.table -knownSites src/test/resources/Homo_sapiens_assembly19.dbsnp135.chr1_1M.exome_intervals.vcf; ```. > Exception in thread ""main"" java.lang.NullPointerException; > at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.getSubsequenceAt(CachingIndexedFastaSequenceFile.java:286); > (...)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/355
https://github.com/broadinstitute/gatk/issues/355:242,Testability,test,test,242,"@jean-philippe-martin reported a null pointer running the following. ```; BaseRecalibrator -I src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.bam -R hs37d5.fa --RECAL_TABLE_FILE output.table -knownSites src/test/resources/empty.vcf; ```. or . ```; BaseRecalibrator -I src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.bam -R hs37d5.fa --RECAL_TABLE_FILE output.table -knownSites src/test/resources/Homo_sapiens_assembly19.dbsnp135.chr1_1M.exome_intervals.vcf; ```. > Exception in thread ""main"" java.lang.NullPointerException; > at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.getSubsequenceAt(CachingIndexedFastaSequenceFile.java:286); > (...)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/355
https://github.com/broadinstitute/gatk/issues/355:307,Testability,test,test,307,"@jean-philippe-martin reported a null pointer running the following. ```; BaseRecalibrator -I src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.bam -R hs37d5.fa --RECAL_TABLE_FILE output.table -knownSites src/test/resources/empty.vcf; ```. or . ```; BaseRecalibrator -I src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.bam -R hs37d5.fa --RECAL_TABLE_FILE output.table -knownSites src/test/resources/Homo_sapiens_assembly19.dbsnp135.chr1_1M.exome_intervals.vcf; ```. > Exception in thread ""main"" java.lang.NullPointerException; > at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.getSubsequenceAt(CachingIndexedFastaSequenceFile.java:286); > (...)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/355
https://github.com/broadinstitute/gatk/issues/355:451,Testability,test,test,451,"@jean-philippe-martin reported a null pointer running the following. ```; BaseRecalibrator -I src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.bam -R hs37d5.fa --RECAL_TABLE_FILE output.table -knownSites src/test/resources/empty.vcf; ```. or . ```; BaseRecalibrator -I src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.bam -R hs37d5.fa --RECAL_TABLE_FILE output.table -knownSites src/test/resources/Homo_sapiens_assembly19.dbsnp135.chr1_1M.exome_intervals.vcf; ```. > Exception in thread ""main"" java.lang.NullPointerException; > at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.getSubsequenceAt(CachingIndexedFastaSequenceFile.java:286); > (...)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/355
https://github.com/broadinstitute/gatk/pull/357:265,Availability,ERROR,ERROR,265,Fixed bug #355.; The problem was that reads and reference file had incompatible sequence dictionaries. ; @jean-philippe-martin please review and confirm that the NPE is fixed. @lbergelson please review for merging. . The result now is something like this:; `A USER ERROR has occurred: Contig chr1 not present in the sequence dictionary [17]`,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/357
https://github.com/broadinstitute/gatk/issues/358:448,Availability,error,error,448,"Currently, the engine-level shutdown routine `onShutdown()` is always invoked, even when an exception occurs during traversal, but the tool-level shutdown routine `onTraversalDone()` is not wrapped within a `finally` block and so not invoked when an exception occurs. Do we want it to always be invoked? Some tools might be designed on the assumption that `onTraversalDone()` will only be reached if the traversal completed start to finish without error (and so it's appropriate to generate certain final output, etc.), while other tools might prefer it to always be invoked so that resources can be closed. Thoughts?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/358
https://github.com/broadinstitute/gatk/issues/358:37,Integrability,rout,routine,37,"Currently, the engine-level shutdown routine `onShutdown()` is always invoked, even when an exception occurs during traversal, but the tool-level shutdown routine `onTraversalDone()` is not wrapped within a `finally` block and so not invoked when an exception occurs. Do we want it to always be invoked? Some tools might be designed on the assumption that `onTraversalDone()` will only be reached if the traversal completed start to finish without error (and so it's appropriate to generate certain final output, etc.), while other tools might prefer it to always be invoked so that resources can be closed. Thoughts?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/358
https://github.com/broadinstitute/gatk/issues/358:155,Integrability,rout,routine,155,"Currently, the engine-level shutdown routine `onShutdown()` is always invoked, even when an exception occurs during traversal, but the tool-level shutdown routine `onTraversalDone()` is not wrapped within a `finally` block and so not invoked when an exception occurs. Do we want it to always be invoked? Some tools might be designed on the assumption that `onTraversalDone()` will only be reached if the traversal completed start to finish without error (and so it's appropriate to generate certain final output, etc.), while other tools might prefer it to always be invoked so that resources can be closed. Thoughts?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/358
https://github.com/broadinstitute/gatk/issues/358:190,Integrability,wrap,wrapped,190,"Currently, the engine-level shutdown routine `onShutdown()` is always invoked, even when an exception occurs during traversal, but the tool-level shutdown routine `onTraversalDone()` is not wrapped within a `finally` block and so not invoked when an exception occurs. Do we want it to always be invoked? Some tools might be designed on the assumption that `onTraversalDone()` will only be reached if the traversal completed start to finish without error (and so it's appropriate to generate certain final output, etc.), while other tools might prefer it to always be invoked so that resources can be closed. Thoughts?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/358
https://github.com/broadinstitute/gatk/pull/360:140,Testability,log,log,140,"This includes general engine initialization, interval processing, and; SAM/BAM reader querying. Also remove puzzling ""FRED"" prefix from our log output :). Resolves #250",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/360
https://github.com/broadinstitute/gatk/pull/362:121,Integrability,depend,dependency,121,"closes #230 . deleted useless codecs, left only TableCodec (per @ldgauthier's request), removed GenomeLoc (and reference dependency), simplified parsing code and added tests for the codec (and corresponding `TableFeature`). @droazen please review",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/362
https://github.com/broadinstitute/gatk/pull/362:168,Testability,test,tests,168,"closes #230 . deleted useless codecs, left only TableCodec (per @ldgauthier's request), removed GenomeLoc (and reference dependency), simplified parsing code and added tests for the codec (and corresponding `TableFeature`). @droazen please review",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/362
https://github.com/broadinstitute/gatk/pull/362:134,Usability,simpl,simplified,134,"closes #230 . deleted useless codecs, left only TableCodec (per @ldgauthier's request), removed GenomeLoc (and reference dependency), simplified parsing code and added tests for the codec (and corresponding `TableFeature`). @droazen please review",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/362
https://github.com/broadinstitute/gatk/pull/363:120,Integrability,depend,dependency,120,"closes #230. deleted useless codecs, left only TableCodec (per @ldgauthier's request), removed GenomeLoc (and reference dependency), simplified parsing code and added tests for the codec (and corresponding TableFeature). @droazen please review",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/363
https://github.com/broadinstitute/gatk/pull/363:167,Testability,test,tests,167,"closes #230. deleted useless codecs, left only TableCodec (per @ldgauthier's request), removed GenomeLoc (and reference dependency), simplified parsing code and added tests for the codec (and corresponding TableFeature). @droazen please review",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/363
https://github.com/broadinstitute/gatk/pull/363:133,Usability,simpl,simplified,133,"closes #230. deleted useless codecs, left only TableCodec (per @ldgauthier's request), removed GenomeLoc (and reference dependency), simplified parsing code and added tests for the codec (and corresponding TableFeature). @droazen please review",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/363
https://github.com/broadinstitute/gatk/issues/364:2,Testability,test,tests,2,"3 tests fail, sometimes. They often pass on a rerun of the build. Here's one example. ```; org.broadinstitute.hellbender.tools.picard.illumina.IlluminaBasecallsToSamTest.testMultiplexedWithAlternateBarcodeName FAILED; java.lang.AssertionError: SAM file output differs from expected output expected [true] but found [false]; at org.testng.Assert.fail(Assert.java:94); at org.testng.Assert.failNotEquals(Assert.java:494); at org.testng.Assert.assertTrue(Assert.java:42); at org.broadinstitute.hellbender.utils.read.SamAssertionUtils.assertSamsEqual(SamAssertionUtils.java:27); at ; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/364
https://github.com/broadinstitute/gatk/issues/364:170,Testability,test,testMultiplexedWithAlternateBarcodeName,170,"3 tests fail, sometimes. They often pass on a rerun of the build. Here's one example. ```; org.broadinstitute.hellbender.tools.picard.illumina.IlluminaBasecallsToSamTest.testMultiplexedWithAlternateBarcodeName FAILED; java.lang.AssertionError: SAM file output differs from expected output expected [true] but found [false]; at org.testng.Assert.fail(Assert.java:94); at org.testng.Assert.failNotEquals(Assert.java:494); at org.testng.Assert.assertTrue(Assert.java:42); at org.broadinstitute.hellbender.utils.read.SamAssertionUtils.assertSamsEqual(SamAssertionUtils.java:27); at ; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/364
https://github.com/broadinstitute/gatk/issues/364:228,Testability,Assert,AssertionError,228,"3 tests fail, sometimes. They often pass on a rerun of the build. Here's one example. ```; org.broadinstitute.hellbender.tools.picard.illumina.IlluminaBasecallsToSamTest.testMultiplexedWithAlternateBarcodeName FAILED; java.lang.AssertionError: SAM file output differs from expected output expected [true] but found [false]; at org.testng.Assert.fail(Assert.java:94); at org.testng.Assert.failNotEquals(Assert.java:494); at org.testng.Assert.assertTrue(Assert.java:42); at org.broadinstitute.hellbender.utils.read.SamAssertionUtils.assertSamsEqual(SamAssertionUtils.java:27); at ; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/364
https://github.com/broadinstitute/gatk/issues/364:331,Testability,test,testng,331,"3 tests fail, sometimes. They often pass on a rerun of the build. Here's one example. ```; org.broadinstitute.hellbender.tools.picard.illumina.IlluminaBasecallsToSamTest.testMultiplexedWithAlternateBarcodeName FAILED; java.lang.AssertionError: SAM file output differs from expected output expected [true] but found [false]; at org.testng.Assert.fail(Assert.java:94); at org.testng.Assert.failNotEquals(Assert.java:494); at org.testng.Assert.assertTrue(Assert.java:42); at org.broadinstitute.hellbender.utils.read.SamAssertionUtils.assertSamsEqual(SamAssertionUtils.java:27); at ; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/364
https://github.com/broadinstitute/gatk/issues/364:338,Testability,Assert,Assert,338,"3 tests fail, sometimes. They often pass on a rerun of the build. Here's one example. ```; org.broadinstitute.hellbender.tools.picard.illumina.IlluminaBasecallsToSamTest.testMultiplexedWithAlternateBarcodeName FAILED; java.lang.AssertionError: SAM file output differs from expected output expected [true] but found [false]; at org.testng.Assert.fail(Assert.java:94); at org.testng.Assert.failNotEquals(Assert.java:494); at org.testng.Assert.assertTrue(Assert.java:42); at org.broadinstitute.hellbender.utils.read.SamAssertionUtils.assertSamsEqual(SamAssertionUtils.java:27); at ; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/364
https://github.com/broadinstitute/gatk/issues/364:350,Testability,Assert,Assert,350,"3 tests fail, sometimes. They often pass on a rerun of the build. Here's one example. ```; org.broadinstitute.hellbender.tools.picard.illumina.IlluminaBasecallsToSamTest.testMultiplexedWithAlternateBarcodeName FAILED; java.lang.AssertionError: SAM file output differs from expected output expected [true] but found [false]; at org.testng.Assert.fail(Assert.java:94); at org.testng.Assert.failNotEquals(Assert.java:494); at org.testng.Assert.assertTrue(Assert.java:42); at org.broadinstitute.hellbender.utils.read.SamAssertionUtils.assertSamsEqual(SamAssertionUtils.java:27); at ; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/364
https://github.com/broadinstitute/gatk/issues/364:374,Testability,test,testng,374,"3 tests fail, sometimes. They often pass on a rerun of the build. Here's one example. ```; org.broadinstitute.hellbender.tools.picard.illumina.IlluminaBasecallsToSamTest.testMultiplexedWithAlternateBarcodeName FAILED; java.lang.AssertionError: SAM file output differs from expected output expected [true] but found [false]; at org.testng.Assert.fail(Assert.java:94); at org.testng.Assert.failNotEquals(Assert.java:494); at org.testng.Assert.assertTrue(Assert.java:42); at org.broadinstitute.hellbender.utils.read.SamAssertionUtils.assertSamsEqual(SamAssertionUtils.java:27); at ; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/364
https://github.com/broadinstitute/gatk/issues/364:381,Testability,Assert,Assert,381,"3 tests fail, sometimes. They often pass on a rerun of the build. Here's one example. ```; org.broadinstitute.hellbender.tools.picard.illumina.IlluminaBasecallsToSamTest.testMultiplexedWithAlternateBarcodeName FAILED; java.lang.AssertionError: SAM file output differs from expected output expected [true] but found [false]; at org.testng.Assert.fail(Assert.java:94); at org.testng.Assert.failNotEquals(Assert.java:494); at org.testng.Assert.assertTrue(Assert.java:42); at org.broadinstitute.hellbender.utils.read.SamAssertionUtils.assertSamsEqual(SamAssertionUtils.java:27); at ; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/364
https://github.com/broadinstitute/gatk/issues/364:402,Testability,Assert,Assert,402,"3 tests fail, sometimes. They often pass on a rerun of the build. Here's one example. ```; org.broadinstitute.hellbender.tools.picard.illumina.IlluminaBasecallsToSamTest.testMultiplexedWithAlternateBarcodeName FAILED; java.lang.AssertionError: SAM file output differs from expected output expected [true] but found [false]; at org.testng.Assert.fail(Assert.java:94); at org.testng.Assert.failNotEquals(Assert.java:494); at org.testng.Assert.assertTrue(Assert.java:42); at org.broadinstitute.hellbender.utils.read.SamAssertionUtils.assertSamsEqual(SamAssertionUtils.java:27); at ; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/364
https://github.com/broadinstitute/gatk/issues/364:427,Testability,test,testng,427,"3 tests fail, sometimes. They often pass on a rerun of the build. Here's one example. ```; org.broadinstitute.hellbender.tools.picard.illumina.IlluminaBasecallsToSamTest.testMultiplexedWithAlternateBarcodeName FAILED; java.lang.AssertionError: SAM file output differs from expected output expected [true] but found [false]; at org.testng.Assert.fail(Assert.java:94); at org.testng.Assert.failNotEquals(Assert.java:494); at org.testng.Assert.assertTrue(Assert.java:42); at org.broadinstitute.hellbender.utils.read.SamAssertionUtils.assertSamsEqual(SamAssertionUtils.java:27); at ; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/364
https://github.com/broadinstitute/gatk/issues/364:434,Testability,Assert,Assert,434,"3 tests fail, sometimes. They often pass on a rerun of the build. Here's one example. ```; org.broadinstitute.hellbender.tools.picard.illumina.IlluminaBasecallsToSamTest.testMultiplexedWithAlternateBarcodeName FAILED; java.lang.AssertionError: SAM file output differs from expected output expected [true] but found [false]; at org.testng.Assert.fail(Assert.java:94); at org.testng.Assert.failNotEquals(Assert.java:494); at org.testng.Assert.assertTrue(Assert.java:42); at org.broadinstitute.hellbender.utils.read.SamAssertionUtils.assertSamsEqual(SamAssertionUtils.java:27); at ; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/364
https://github.com/broadinstitute/gatk/issues/364:441,Testability,assert,assertTrue,441,"3 tests fail, sometimes. They often pass on a rerun of the build. Here's one example. ```; org.broadinstitute.hellbender.tools.picard.illumina.IlluminaBasecallsToSamTest.testMultiplexedWithAlternateBarcodeName FAILED; java.lang.AssertionError: SAM file output differs from expected output expected [true] but found [false]; at org.testng.Assert.fail(Assert.java:94); at org.testng.Assert.failNotEquals(Assert.java:494); at org.testng.Assert.assertTrue(Assert.java:42); at org.broadinstitute.hellbender.utils.read.SamAssertionUtils.assertSamsEqual(SamAssertionUtils.java:27); at ; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/364
https://github.com/broadinstitute/gatk/issues/364:452,Testability,Assert,Assert,452,"3 tests fail, sometimes. They often pass on a rerun of the build. Here's one example. ```; org.broadinstitute.hellbender.tools.picard.illumina.IlluminaBasecallsToSamTest.testMultiplexedWithAlternateBarcodeName FAILED; java.lang.AssertionError: SAM file output differs from expected output expected [true] but found [false]; at org.testng.Assert.fail(Assert.java:94); at org.testng.Assert.failNotEquals(Assert.java:494); at org.testng.Assert.assertTrue(Assert.java:42); at org.broadinstitute.hellbender.utils.read.SamAssertionUtils.assertSamsEqual(SamAssertionUtils.java:27); at ; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/364
https://github.com/broadinstitute/gatk/issues/364:531,Testability,assert,assertSamsEqual,531,"3 tests fail, sometimes. They often pass on a rerun of the build. Here's one example. ```; org.broadinstitute.hellbender.tools.picard.illumina.IlluminaBasecallsToSamTest.testMultiplexedWithAlternateBarcodeName FAILED; java.lang.AssertionError: SAM file output differs from expected output expected [true] but found [false]; at org.testng.Assert.fail(Assert.java:94); at org.testng.Assert.failNotEquals(Assert.java:494); at org.testng.Assert.assertTrue(Assert.java:42); at org.broadinstitute.hellbender.utils.read.SamAssertionUtils.assertSamsEqual(SamAssertionUtils.java:27); at ; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/364
https://github.com/broadinstitute/gatk/issues/373:26,Testability,test,testing,26,Doing some empirical data testing I found some instance of reads that have no single based aligned with the reference. E.g. CIGAR: 50I2S so insertion followed by soft-clip. That causes ReadWalker to crash when trying to create SimpleInterval on the read with a IAE. I guess the solution is to add additional Wellformed filter.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/373
https://github.com/broadinstitute/gatk/issues/373:227,Usability,Simpl,SimpleInterval,227,Doing some empirical data testing I found some instance of reads that have no single based aligned with the reference. E.g. CIGAR: 50I2S so insertion followed by soft-clip. That causes ReadWalker to crash when trying to create SimpleInterval on the read with a IAE. I guess the solution is to add additional Wellformed filter.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/373
https://github.com/broadinstitute/gatk/issues/375:313,Availability,error,error,313,"Currently `SamAssertionUtils.assertSamsEqual` fails with `""SAM file output differs from expected output""`. It uses `SamComparison`, which prints a lot of helpful information about how the files differ to stdout. This output is often hidden when running it in a test suite though. It's also a bit strange to print error messages to stdout. `SamComparison` should capture this information and provide an accessor to retrieve it instead of dumping it to stdout.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/375
https://github.com/broadinstitute/gatk/issues/375:319,Integrability,message,messages,319,"Currently `SamAssertionUtils.assertSamsEqual` fails with `""SAM file output differs from expected output""`. It uses `SamComparison`, which prints a lot of helpful information about how the files differ to stdout. This output is often hidden when running it in a test suite though. It's also a bit strange to print error messages to stdout. `SamComparison` should capture this information and provide an accessor to retrieve it instead of dumping it to stdout.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/375
https://github.com/broadinstitute/gatk/issues/375:402,Security,access,accessor,402,"Currently `SamAssertionUtils.assertSamsEqual` fails with `""SAM file output differs from expected output""`. It uses `SamComparison`, which prints a lot of helpful information about how the files differ to stdout. This output is often hidden when running it in a test suite though. It's also a bit strange to print error messages to stdout. `SamComparison` should capture this information and provide an accessor to retrieve it instead of dumping it to stdout.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/375
https://github.com/broadinstitute/gatk/issues/375:29,Testability,assert,assertSamsEqual,29,"Currently `SamAssertionUtils.assertSamsEqual` fails with `""SAM file output differs from expected output""`. It uses `SamComparison`, which prints a lot of helpful information about how the files differ to stdout. This output is often hidden when running it in a test suite though. It's also a bit strange to print error messages to stdout. `SamComparison` should capture this information and provide an accessor to retrieve it instead of dumping it to stdout.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/375
https://github.com/broadinstitute/gatk/issues/375:261,Testability,test,test,261,"Currently `SamAssertionUtils.assertSamsEqual` fails with `""SAM file output differs from expected output""`. It uses `SamComparison`, which prints a lot of helpful information about how the files differ to stdout. This output is often hidden when running it in a test suite though. It's also a bit strange to print error messages to stdout. `SamComparison` should capture this information and provide an accessor to retrieve it instead of dumping it to stdout.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/375
https://github.com/broadinstitute/gatk/issues/376:66,Testability,test,tests,66,"the task is to find all find Picard classes in hellbender with no tests (or very low coverage < 10%) and enter a ticket for each of them. @nh13 please mark this as high priority - lower than the testing bug, higher than writing missing tests (I need to see how much testing we're missing).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/376
https://github.com/broadinstitute/gatk/issues/376:195,Testability,test,testing,195,"the task is to find all find Picard classes in hellbender with no tests (or very low coverage < 10%) and enter a ticket for each of them. @nh13 please mark this as high priority - lower than the testing bug, higher than writing missing tests (I need to see how much testing we're missing).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/376
https://github.com/broadinstitute/gatk/issues/376:236,Testability,test,tests,236,"the task is to find all find Picard classes in hellbender with no tests (or very low coverage < 10%) and enter a ticket for each of them. @nh13 please mark this as high priority - lower than the testing bug, higher than writing missing tests (I need to see how much testing we're missing).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/376
https://github.com/broadinstitute/gatk/issues/376:266,Testability,test,testing,266,"the task is to find all find Picard classes in hellbender with no tests (or very low coverage < 10%) and enter a ticket for each of them. @nh13 please mark this as high priority - lower than the testing bug, higher than writing missing tests (I need to see how much testing we're missing).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/376
https://github.com/broadinstitute/gatk/issues/378:95,Testability,test,tests,95,IlluminaBasecallsConverter used multiple threads which has already led to sporadically failing tests (issie #364) Multithreading needs to be removed from Hellbender.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/378
https://github.com/broadinstitute/gatk/pull/379:21,Testability,test,tests,21,"due to broken picard tests, we need to disable them. https://github.com/broadinstitute/hellbender/issues/364. fixing them is the highest priority item for the next iteration. @lbergelson please review",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/379
https://github.com/broadinstitute/gatk/pull/380:111,Testability,test,tests,111,"ported BadCigarFilter (in Hellbender filters have positive names, in concordance with Java filter semantics) + tests (added 2 tests to cover 2 more branches, 1 branch seems unreachable). @vruano please review; addresses https://github.com/broadinstitute/hellbender/issues/373",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/380
https://github.com/broadinstitute/gatk/pull/380:126,Testability,test,tests,126,"ported BadCigarFilter (in Hellbender filters have positive names, in concordance with Java filter semantics) + tests (added 2 tests to cover 2 more branches, 1 branch seems unreachable). @vruano please review; addresses https://github.com/broadinstitute/hellbender/issues/373",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/380
https://github.com/broadinstitute/gatk/issues/381:76,Security,access,access,76,"Since the migration from travis-ci.org to travis-ci.com I've been unable to access our coveralls page. The coverage badge on the repo is broken as well. Others seem to be able to access the https://coveralls.io/r/broadinstitute/hellbender page, but I get an ""Access Denied"". It's still commenting on our posts, but it's not very useful without the actual coverage display. . I know @droazen can still see the page, @akiezun, can you? . I filed an issue with coveralls here: https://github.com/lemurheavy/coveralls-public/issues/497 but haven't heard anything back from them.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/381
https://github.com/broadinstitute/gatk/issues/381:179,Security,access,access,179,"Since the migration from travis-ci.org to travis-ci.com I've been unable to access our coveralls page. The coverage badge on the repo is broken as well. Others seem to be able to access the https://coveralls.io/r/broadinstitute/hellbender page, but I get an ""Access Denied"". It's still commenting on our posts, but it's not very useful without the actual coverage display. . I know @droazen can still see the page, @akiezun, can you? . I filed an issue with coveralls here: https://github.com/lemurheavy/coveralls-public/issues/497 but haven't heard anything back from them.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/381
https://github.com/broadinstitute/gatk/issues/381:259,Security,Access,Access,259,"Since the migration from travis-ci.org to travis-ci.com I've been unable to access our coveralls page. The coverage badge on the repo is broken as well. Others seem to be able to access the https://coveralls.io/r/broadinstitute/hellbender page, but I get an ""Access Denied"". It's still commenting on our posts, but it's not very useful without the actual coverage display. . I know @droazen can still see the page, @akiezun, can you? . I filed an issue with coveralls here: https://github.com/lemurheavy/coveralls-public/issues/497 but haven't heard anything back from them.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/381
https://github.com/broadinstitute/gatk/pull/382:183,Modifiability,flexible,flexible,183,"There have been requests for some additional clarity on ""how; much test coverage is enough"" for hellbender tools. Rather than; mandate a particular coverage target, I proposed a more flexible; set of guidelines which I've added to the README in this commit.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/382
https://github.com/broadinstitute/gatk/pull/382:67,Testability,test,test,67,"There have been requests for some additional clarity on ""how; much test coverage is enough"" for hellbender tools. Rather than; mandate a particular coverage target, I proposed a more flexible; set of guidelines which I've added to the README in this commit.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/382
https://github.com/broadinstitute/gatk/pull/382:200,Usability,guid,guidelines,200,"There have been requests for some additional clarity on ""how; much test coverage is enough"" for hellbender tools. Rather than; mandate a particular coverage target, I proposed a more flexible; set of guidelines which I've added to the README in this commit.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/382
https://github.com/broadinstitute/gatk/issues/384:42,Integrability,depend,dependent,42,"we need to be able to create repositories dependent on hellbender and the best way is to make a jar and pot in on maven central. @lbergelson can you look into it? It's pretty high priority because it blocks work on those new repositories. (if there's a solution without maven central, i'm open to it too)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/384
https://github.com/broadinstitute/gatk/issues/385:353,Availability,down,down,353,"In GATK3, the VQSR tools have specific expectations for novel Ti/Tv that are based on what was known at the time before the 1000 Genomes project results were added to dbsnp. If you use the corresponding ""old"" dbsnp version, the expectations are fulfilled and your QC plots come out looking shiny. If you use a more recent version, key assumptions break down and it screws up the VQSR's QC routines (which produce the plots). Would be good to be able to handle whatever version of dbsnp users use. . This Issue was generated from your [forums](http://gatkforums.broadinstitute.org/discussion/comment/20493#Comment_20493)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/385
https://github.com/broadinstitute/gatk/issues/385:389,Integrability,rout,routines,389,"In GATK3, the VQSR tools have specific expectations for novel Ti/Tv that are based on what was known at the time before the 1000 Genomes project results were added to dbsnp. If you use the corresponding ""old"" dbsnp version, the expectations are fulfilled and your QC plots come out looking shiny. If you use a more recent version, key assumptions break down and it screws up the VQSR's QC routines (which produce the plots). Would be good to be able to handle whatever version of dbsnp users use. . This Issue was generated from your [forums](http://gatkforums.broadinstitute.org/discussion/comment/20493#Comment_20493)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/385
https://github.com/broadinstitute/gatk/pull/386:33,Testability,test,test,33,Adding documentation as a way to test the process.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/386
https://github.com/broadinstitute/gatk/pull/387:251,Testability,test,tested,251,"the code should be reviewed with Murphy's Machine Learning book, chapter 21.6; @davidbenjamin @yfarjoun @cseed please review and comment - there are some not optimal decisions left over from the gatk3 implementation but the focus here is on getting a tested version that matches a known textbook or paper that we can build upon",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/387
https://github.com/broadinstitute/gatk/pull/387:50,Usability,Learn,Learning,50,"the code should be reviewed with Murphy's Machine Learning book, chapter 21.6; @davidbenjamin @yfarjoun @cseed please review and comment - there are some not optimal decisions left over from the gatk3 implementation but the focus here is on getting a tested version that matches a known textbook or paper that we can build upon",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/387
https://github.com/broadinstitute/gatk/issues/388:27,Deployability,integrat,integration,27,This is very important for integration tests. Not being able to use large files is significantly slowing porting of existing tools to hellbender. Maybe this will work https://git-lfs.github.com/ maybe something else.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/388
https://github.com/broadinstitute/gatk/issues/388:27,Integrability,integrat,integration,27,This is very important for integration tests. Not being able to use large files is significantly slowing porting of existing tools to hellbender. Maybe this will work https://git-lfs.github.com/ maybe something else.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/388
https://github.com/broadinstitute/gatk/issues/388:39,Testability,test,tests,39,This is very important for integration tests. Not being able to use large files is significantly slowing porting of existing tools to hellbender. Maybe this will work https://git-lfs.github.com/ maybe something else.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/388
https://github.com/broadinstitute/gatk/issues/398:43,Safety,avoid,avoid,43,Picard CollectMultipleMetrics's goal is to avoid reading the file multiple times. In dataflow this should be simple - compute metrics independently from the same pcollection of reads. We need a generic way of doing it and a specific example that implements CollectMultipleMetrics's functionality,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/398
https://github.com/broadinstitute/gatk/issues/398:109,Usability,simpl,simple,109,Picard CollectMultipleMetrics's goal is to avoid reading the file multiple times. In dataflow this should be simple - compute metrics independently from the same pcollection of reads. We need a generic way of doing it and a specific example that implements CollectMultipleMetrics's functionality,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/398
https://github.com/broadinstitute/gatk/issues/400:30,Availability,redundant,redundant,30,"many methods in MathUtils are redundant with ApacheCommons/Math or JDK. We should remove those methods.; For example, `MathUtils.lnGamma` should be deleted in favor of `Gamma.logGamma' unless there's a severe speed penalty.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/400
https://github.com/broadinstitute/gatk/issues/400:30,Safety,redund,redundant,30,"many methods in MathUtils are redundant with ApacheCommons/Math or JDK. We should remove those methods.; For example, `MathUtils.lnGamma` should be deleted in favor of `Gamma.logGamma' unless there's a severe speed penalty.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/400
https://github.com/broadinstitute/gatk/issues/400:175,Testability,log,logGamma,175,"many methods in MathUtils are redundant with ApacheCommons/Math or JDK. We should remove those methods.; For example, `MathUtils.lnGamma` should be deleted in favor of `Gamma.logGamma' unless there's a severe speed penalty.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/400
https://github.com/broadinstitute/gatk/issues/401:79,Usability,simpl,simplified,79,multithreading needs to be removed from Hellbender code. Code then needs to be simplified accordingly.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/401
https://github.com/broadinstitute/gatk/issues/402:32,Availability,error,errors,32,Multithreading is not worth the errors and must be removed from hellbender code. GATK4 is a single-thread toolkit.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/402
https://github.com/broadinstitute/gatk/issues/403:24,Testability,test,test,24,Requires enumeration of test cases and implementing each of them.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/403
https://github.com/broadinstitute/gatk/issues/404:18,Testability,test,tests,18,need to enumerate tests cases and implement each of them.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/404
https://github.com/broadinstitute/gatk/issues/405:18,Testability,test,test,18,need to enumerate test cases and implement each,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/405
https://github.com/broadinstitute/gatk/issues/406:18,Testability,test,test,18,need to enumerate test cases and implement each,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/406
https://github.com/broadinstitute/gatk/issues/407:18,Testability,test,test,18,need to enumerate test cases and implement each,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/407
https://github.com/broadinstitute/gatk/issues/408:18,Testability,test,test,18,need to enumerate test cases and implement each,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/408
https://github.com/broadinstitute/gatk/issues/409:18,Testability,test,test,18,need to enumerate test cases and implement each,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/409
https://github.com/broadinstitute/gatk/issues/410:64,Integrability,depend,depends,64,add tests for FastaAlternateReferenceMaker because it has none. depends on #105 and #36,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/410
https://github.com/broadinstitute/gatk/issues/410:4,Testability,test,tests,4,add tests for FastaAlternateReferenceMaker because it has none. depends on #105 and #36,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/410
https://github.com/broadinstitute/gatk/issues/412:0,Testability,test,tests,0,tests for ReadCovariatesUnitTest are disabled (they were disabled in GATK3 too). We need them back or we need new ones.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/412
https://github.com/broadinstitute/gatk/pull/413:82,Testability,test,tests,82,Simplifies BQSR covariates - use only 4 standard ones. Remove magic indexing. Add tests. Addresses #258 . @droazen please review,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/413
https://github.com/broadinstitute/gatk/pull/413:0,Usability,Simpl,Simplifies,0,Simplifies BQSR covariates - use only 4 standard ones. Remove magic indexing. Add tests. Addresses #258 . @droazen please review,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/413
https://github.com/broadinstitute/gatk/issues/418:248,Availability,ERROR,ERROR,248,I run `build/install/hellbender/bin/hellbender BaseRecalibrator`; and I get this scary message (notice the three colons (`:`) on that line and lots of UPPERCASE). ```; ***********************************************************************. A USER ERROR has occurred: Invalid command line: Argument RECAL_TABLE_FILE was missing: Argument 'RECAL_TABLE_FILE' is required. ***********************************************************************; ```. I think it should say something like this:. ```; ***********************************************************************. Invalid command line for BaseRecalibrator: Required argument RECAL_TABLE_FILE was missing. Run BaseRecalibrator -h to see all arguments. ***********************************************************************; ```. @vdauwera please weigh in on what's most useful,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/418
https://github.com/broadinstitute/gatk/issues/418:13,Deployability,install,install,13,I run `build/install/hellbender/bin/hellbender BaseRecalibrator`; and I get this scary message (notice the three colons (`:`) on that line and lots of UPPERCASE). ```; ***********************************************************************. A USER ERROR has occurred: Invalid command line: Argument RECAL_TABLE_FILE was missing: Argument 'RECAL_TABLE_FILE' is required. ***********************************************************************; ```. I think it should say something like this:. ```; ***********************************************************************. Invalid command line for BaseRecalibrator: Required argument RECAL_TABLE_FILE was missing. Run BaseRecalibrator -h to see all arguments. ***********************************************************************; ```. @vdauwera please weigh in on what's most useful,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/418
https://github.com/broadinstitute/gatk/issues/418:87,Integrability,message,message,87,I run `build/install/hellbender/bin/hellbender BaseRecalibrator`; and I get this scary message (notice the three colons (`:`) on that line and lots of UPPERCASE). ```; ***********************************************************************. A USER ERROR has occurred: Invalid command line: Argument RECAL_TABLE_FILE was missing: Argument 'RECAL_TABLE_FILE' is required. ***********************************************************************; ```. I think it should say something like this:. ```; ***********************************************************************. Invalid command line for BaseRecalibrator: Required argument RECAL_TABLE_FILE was missing. Run BaseRecalibrator -h to see all arguments. ***********************************************************************; ```. @vdauwera please weigh in on what's most useful,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/418
https://github.com/broadinstitute/gatk/issues/419:412,Availability,error,error,412,"CompareSAMs ignores validation stringency. Running this. ```; build/install/hellbender/bin/hellbender CompareSAMs src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam --VALIDATION_STRINGENCY SILENT; ```. results in this. ```; htsjdk.samtools.SAMFormatException: SAM validation error: ERROR: Record 130, Read name 809R9ABXX101220:5:6:17918:145992, Mate Alignment start should be 0 because reference name = *.; at htsjdk.samtools.SAMUtils.processValidationErrors(SAMUtils.java:439); at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:643); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:628); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:598); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:544); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:518); at htsjdk.samtools.util.PeekIterator.peek(PeekIterator.java:67); at htsjdk.samtools.SecondaryOrSupplementarySkippingIterator.skipAnyNotprimary(SecondaryOrSupplementarySkippingIterator.java:36); at htsjdk.samtools.SecondaryOrSupplementarySkippingIterator.advance(SecondaryOrSupplementarySkippingIterator.java:31); at org.broadinstitute.hellbender.utils.read.SamComparison.compareCoordinateSortedAlignments(SamComparison.java:111); at org.broadinstitute.hellbender.utils.read.SamComparison.compareAlignments(SamComparison.java:68); at org.broadinstitute.hellbender.utils.read.SamComparison.<init>(SamComparison.java:44); at org.broadinstitute.hellbender.tools.picard.sam.CompareSAMs.doWork(CompareSAMs.java:34); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:94); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:144); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgram.instanceMain(PicardComm",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/419
https://github.com/broadinstitute/gatk/issues/419:419,Availability,ERROR,ERROR,419,"CompareSAMs ignores validation stringency. Running this. ```; build/install/hellbender/bin/hellbender CompareSAMs src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam --VALIDATION_STRINGENCY SILENT; ```. results in this. ```; htsjdk.samtools.SAMFormatException: SAM validation error: ERROR: Record 130, Read name 809R9ABXX101220:5:6:17918:145992, Mate Alignment start should be 0 because reference name = *.; at htsjdk.samtools.SAMUtils.processValidationErrors(SAMUtils.java:439); at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:643); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:628); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:598); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:544); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:518); at htsjdk.samtools.util.PeekIterator.peek(PeekIterator.java:67); at htsjdk.samtools.SecondaryOrSupplementarySkippingIterator.skipAnyNotprimary(SecondaryOrSupplementarySkippingIterator.java:36); at htsjdk.samtools.SecondaryOrSupplementarySkippingIterator.advance(SecondaryOrSupplementarySkippingIterator.java:31); at org.broadinstitute.hellbender.utils.read.SamComparison.compareCoordinateSortedAlignments(SamComparison.java:111); at org.broadinstitute.hellbender.utils.read.SamComparison.compareAlignments(SamComparison.java:68); at org.broadinstitute.hellbender.utils.read.SamComparison.<init>(SamComparison.java:44); at org.broadinstitute.hellbender.tools.picard.sam.CompareSAMs.doWork(CompareSAMs.java:34); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:94); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:144); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgram.instanceMain(PicardComm",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/419
https://github.com/broadinstitute/gatk/issues/419:68,Deployability,install,install,68,"CompareSAMs ignores validation stringency. Running this. ```; build/install/hellbender/bin/hellbender CompareSAMs src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam --VALIDATION_STRINGENCY SILENT; ```. results in this. ```; htsjdk.samtools.SAMFormatException: SAM validation error: ERROR: Record 130, Read name 809R9ABXX101220:5:6:17918:145992, Mate Alignment start should be 0 because reference name = *.; at htsjdk.samtools.SAMUtils.processValidationErrors(SAMUtils.java:439); at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:643); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:628); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:598); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:544); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:518); at htsjdk.samtools.util.PeekIterator.peek(PeekIterator.java:67); at htsjdk.samtools.SecondaryOrSupplementarySkippingIterator.skipAnyNotprimary(SecondaryOrSupplementarySkippingIterator.java:36); at htsjdk.samtools.SecondaryOrSupplementarySkippingIterator.advance(SecondaryOrSupplementarySkippingIterator.java:31); at org.broadinstitute.hellbender.utils.read.SamComparison.compareCoordinateSortedAlignments(SamComparison.java:111); at org.broadinstitute.hellbender.utils.read.SamComparison.compareAlignments(SamComparison.java:68); at org.broadinstitute.hellbender.utils.read.SamComparison.<init>(SamComparison.java:44); at org.broadinstitute.hellbender.tools.picard.sam.CompareSAMs.doWork(CompareSAMs.java:34); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:94); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:144); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgram.instanceMain(PicardComm",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/419
https://github.com/broadinstitute/gatk/issues/419:2419,Deployability,Integrat,IntegrationTestSpec,2419,"se reference name = *.; at htsjdk.samtools.SAMUtils.processValidationErrors(SAMUtils.java:439); at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:643); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:628); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:598); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:544); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:518); at htsjdk.samtools.util.PeekIterator.peek(PeekIterator.java:67); at htsjdk.samtools.SecondaryOrSupplementarySkippingIterator.skipAnyNotprimary(SecondaryOrSupplementarySkippingIterator.java:36); at htsjdk.samtools.SecondaryOrSupplementarySkippingIterator.advance(SecondaryOrSupplementarySkippingIterator.java:31); at org.broadinstitute.hellbender.utils.read.SamComparison.compareCoordinateSortedAlignments(SamComparison.java:111); at org.broadinstitute.hellbender.utils.read.SamComparison.compareAlignments(SamComparison.java:68); at org.broadinstitute.hellbender.utils.read.SamComparison.<init>(SamComparison.java:44); at org.broadinstitute.hellbender.tools.picard.sam.CompareSAMs.doWork(CompareSAMs.java:34); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:94); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:144); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgram.instanceMain(PicardCommandLineProgram.java:51); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:77); at org.broadinstitute.hellbender.Main.main(Main.java:92); ```. Same command on original picard passes validation (though claims the bam is different from itself: https://github.com/broadinstitute/picard/issues/160). Note to whoever fixes this: once this is fixed, re-enable code in BaseRecalibratorIntegrationTest.java. ```; //IntegrationTestSpec.compareBamFiles(actualHiSeqBam_recalibrated, expectedHiSeqBam_recalibrated);; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/419
https://github.com/broadinstitute/gatk/issues/419:2419,Integrability,Integrat,IntegrationTestSpec,2419,"se reference name = *.; at htsjdk.samtools.SAMUtils.processValidationErrors(SAMUtils.java:439); at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:643); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:628); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:598); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:544); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:518); at htsjdk.samtools.util.PeekIterator.peek(PeekIterator.java:67); at htsjdk.samtools.SecondaryOrSupplementarySkippingIterator.skipAnyNotprimary(SecondaryOrSupplementarySkippingIterator.java:36); at htsjdk.samtools.SecondaryOrSupplementarySkippingIterator.advance(SecondaryOrSupplementarySkippingIterator.java:31); at org.broadinstitute.hellbender.utils.read.SamComparison.compareCoordinateSortedAlignments(SamComparison.java:111); at org.broadinstitute.hellbender.utils.read.SamComparison.compareAlignments(SamComparison.java:68); at org.broadinstitute.hellbender.utils.read.SamComparison.<init>(SamComparison.java:44); at org.broadinstitute.hellbender.tools.picard.sam.CompareSAMs.doWork(CompareSAMs.java:34); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:94); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:144); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgram.instanceMain(PicardCommandLineProgram.java:51); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:77); at org.broadinstitute.hellbender.Main.main(Main.java:92); ```. Same command on original picard passes validation (though claims the bam is different from itself: https://github.com/broadinstitute/picard/issues/160). Note to whoever fixes this: once this is fixed, re-enable code in BaseRecalibratorIntegrationTest.java. ```; //IntegrationTestSpec.compareBamFiles(actualHiSeqBam_recalibrated, expectedHiSeqBam_recalibrated);; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/419
https://github.com/broadinstitute/gatk/issues/419:20,Security,validat,validation,20,"CompareSAMs ignores validation stringency. Running this. ```; build/install/hellbender/bin/hellbender CompareSAMs src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam --VALIDATION_STRINGENCY SILENT; ```. results in this. ```; htsjdk.samtools.SAMFormatException: SAM validation error: ERROR: Record 130, Read name 809R9ABXX101220:5:6:17918:145992, Mate Alignment start should be 0 because reference name = *.; at htsjdk.samtools.SAMUtils.processValidationErrors(SAMUtils.java:439); at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:643); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:628); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:598); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:544); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:518); at htsjdk.samtools.util.PeekIterator.peek(PeekIterator.java:67); at htsjdk.samtools.SecondaryOrSupplementarySkippingIterator.skipAnyNotprimary(SecondaryOrSupplementarySkippingIterator.java:36); at htsjdk.samtools.SecondaryOrSupplementarySkippingIterator.advance(SecondaryOrSupplementarySkippingIterator.java:31); at org.broadinstitute.hellbender.utils.read.SamComparison.compareCoordinateSortedAlignments(SamComparison.java:111); at org.broadinstitute.hellbender.utils.read.SamComparison.compareAlignments(SamComparison.java:68); at org.broadinstitute.hellbender.utils.read.SamComparison.<init>(SamComparison.java:44); at org.broadinstitute.hellbender.tools.picard.sam.CompareSAMs.doWork(CompareSAMs.java:34); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:94); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:144); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgram.instanceMain(PicardComm",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/419
https://github.com/broadinstitute/gatk/issues/419:401,Security,validat,validation,401,"CompareSAMs ignores validation stringency. Running this. ```; build/install/hellbender/bin/hellbender CompareSAMs src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam --VALIDATION_STRINGENCY SILENT; ```. results in this. ```; htsjdk.samtools.SAMFormatException: SAM validation error: ERROR: Record 130, Read name 809R9ABXX101220:5:6:17918:145992, Mate Alignment start should be 0 because reference name = *.; at htsjdk.samtools.SAMUtils.processValidationErrors(SAMUtils.java:439); at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:643); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:628); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:598); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:544); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:518); at htsjdk.samtools.util.PeekIterator.peek(PeekIterator.java:67); at htsjdk.samtools.SecondaryOrSupplementarySkippingIterator.skipAnyNotprimary(SecondaryOrSupplementarySkippingIterator.java:36); at htsjdk.samtools.SecondaryOrSupplementarySkippingIterator.advance(SecondaryOrSupplementarySkippingIterator.java:31); at org.broadinstitute.hellbender.utils.read.SamComparison.compareCoordinateSortedAlignments(SamComparison.java:111); at org.broadinstitute.hellbender.utils.read.SamComparison.compareAlignments(SamComparison.java:68); at org.broadinstitute.hellbender.utils.read.SamComparison.<init>(SamComparison.java:44); at org.broadinstitute.hellbender.tools.picard.sam.CompareSAMs.doWork(CompareSAMs.java:34); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:94); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:144); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgram.instanceMain(PicardComm",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/419
https://github.com/broadinstitute/gatk/issues/419:2194,Security,validat,validation,2194,"se reference name = *.; at htsjdk.samtools.SAMUtils.processValidationErrors(SAMUtils.java:439); at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:643); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:628); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:598); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:544); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:518); at htsjdk.samtools.util.PeekIterator.peek(PeekIterator.java:67); at htsjdk.samtools.SecondaryOrSupplementarySkippingIterator.skipAnyNotprimary(SecondaryOrSupplementarySkippingIterator.java:36); at htsjdk.samtools.SecondaryOrSupplementarySkippingIterator.advance(SecondaryOrSupplementarySkippingIterator.java:31); at org.broadinstitute.hellbender.utils.read.SamComparison.compareCoordinateSortedAlignments(SamComparison.java:111); at org.broadinstitute.hellbender.utils.read.SamComparison.compareAlignments(SamComparison.java:68); at org.broadinstitute.hellbender.utils.read.SamComparison.<init>(SamComparison.java:44); at org.broadinstitute.hellbender.tools.picard.sam.CompareSAMs.doWork(CompareSAMs.java:34); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:94); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:144); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgram.instanceMain(PicardCommandLineProgram.java:51); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:77); at org.broadinstitute.hellbender.Main.main(Main.java:92); ```. Same command on original picard passes validation (though claims the bam is different from itself: https://github.com/broadinstitute/picard/issues/160). Note to whoever fixes this: once this is fixed, re-enable code in BaseRecalibratorIntegrationTest.java. ```; //IntegrationTestSpec.compareBamFiles(actualHiSeqBam_recalibrated, expectedHiSeqBam_recalibrated);; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/419
https://github.com/broadinstitute/gatk/issues/419:118,Testability,test,test,118,"CompareSAMs ignores validation stringency. Running this. ```; build/install/hellbender/bin/hellbender CompareSAMs src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam --VALIDATION_STRINGENCY SILENT; ```. results in this. ```; htsjdk.samtools.SAMFormatException: SAM validation error: ERROR: Record 130, Read name 809R9ABXX101220:5:6:17918:145992, Mate Alignment start should be 0 because reference name = *.; at htsjdk.samtools.SAMUtils.processValidationErrors(SAMUtils.java:439); at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:643); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:628); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:598); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:544); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:518); at htsjdk.samtools.util.PeekIterator.peek(PeekIterator.java:67); at htsjdk.samtools.SecondaryOrSupplementarySkippingIterator.skipAnyNotprimary(SecondaryOrSupplementarySkippingIterator.java:36); at htsjdk.samtools.SecondaryOrSupplementarySkippingIterator.advance(SecondaryOrSupplementarySkippingIterator.java:31); at org.broadinstitute.hellbender.utils.read.SamComparison.compareCoordinateSortedAlignments(SamComparison.java:111); at org.broadinstitute.hellbender.utils.read.SamComparison.compareAlignments(SamComparison.java:68); at org.broadinstitute.hellbender.utils.read.SamComparison.<init>(SamComparison.java:44); at org.broadinstitute.hellbender.tools.picard.sam.CompareSAMs.doWork(CompareSAMs.java:34); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:94); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:144); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgram.instanceMain(PicardComm",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/419
https://github.com/broadinstitute/gatk/issues/419:212,Testability,test,test,212,"CompareSAMs ignores validation stringency. Running this. ```; build/install/hellbender/bin/hellbender CompareSAMs src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam --VALIDATION_STRINGENCY SILENT; ```. results in this. ```; htsjdk.samtools.SAMFormatException: SAM validation error: ERROR: Record 130, Read name 809R9ABXX101220:5:6:17918:145992, Mate Alignment start should be 0 because reference name = *.; at htsjdk.samtools.SAMUtils.processValidationErrors(SAMUtils.java:439); at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:643); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:628); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:598); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:544); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:518); at htsjdk.samtools.util.PeekIterator.peek(PeekIterator.java:67); at htsjdk.samtools.SecondaryOrSupplementarySkippingIterator.skipAnyNotprimary(SecondaryOrSupplementarySkippingIterator.java:36); at htsjdk.samtools.SecondaryOrSupplementarySkippingIterator.advance(SecondaryOrSupplementarySkippingIterator.java:31); at org.broadinstitute.hellbender.utils.read.SamComparison.compareCoordinateSortedAlignments(SamComparison.java:111); at org.broadinstitute.hellbender.utils.read.SamComparison.compareAlignments(SamComparison.java:68); at org.broadinstitute.hellbender.utils.read.SamComparison.<init>(SamComparison.java:44); at org.broadinstitute.hellbender.tools.picard.sam.CompareSAMs.doWork(CompareSAMs.java:34); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:94); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:144); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgram.instanceMain(PicardComm",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/419
https://github.com/broadinstitute/gatk/issues/419:885,Testability,Assert,AssertingIterator,885,"CompareSAMs ignores validation stringency. Running this. ```; build/install/hellbender/bin/hellbender CompareSAMs src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam --VALIDATION_STRINGENCY SILENT; ```. results in this. ```; htsjdk.samtools.SAMFormatException: SAM validation error: ERROR: Record 130, Read name 809R9ABXX101220:5:6:17918:145992, Mate Alignment start should be 0 because reference name = *.; at htsjdk.samtools.SAMUtils.processValidationErrors(SAMUtils.java:439); at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:643); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:628); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:598); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:544); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:518); at htsjdk.samtools.util.PeekIterator.peek(PeekIterator.java:67); at htsjdk.samtools.SecondaryOrSupplementarySkippingIterator.skipAnyNotprimary(SecondaryOrSupplementarySkippingIterator.java:36); at htsjdk.samtools.SecondaryOrSupplementarySkippingIterator.advance(SecondaryOrSupplementarySkippingIterator.java:31); at org.broadinstitute.hellbender.utils.read.SamComparison.compareCoordinateSortedAlignments(SamComparison.java:111); at org.broadinstitute.hellbender.utils.read.SamComparison.compareAlignments(SamComparison.java:68); at org.broadinstitute.hellbender.utils.read.SamComparison.<init>(SamComparison.java:44); at org.broadinstitute.hellbender.tools.picard.sam.CompareSAMs.doWork(CompareSAMs.java:34); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:94); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:144); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgram.instanceMain(PicardComm",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/419
https://github.com/broadinstitute/gatk/issues/419:958,Testability,Assert,AssertingIterator,958,"CompareSAMs ignores validation stringency. Running this. ```; build/install/hellbender/bin/hellbender CompareSAMs src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam --VALIDATION_STRINGENCY SILENT; ```. results in this. ```; htsjdk.samtools.SAMFormatException: SAM validation error: ERROR: Record 130, Read name 809R9ABXX101220:5:6:17918:145992, Mate Alignment start should be 0 because reference name = *.; at htsjdk.samtools.SAMUtils.processValidationErrors(SAMUtils.java:439); at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:643); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:628); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:598); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:544); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:518); at htsjdk.samtools.util.PeekIterator.peek(PeekIterator.java:67); at htsjdk.samtools.SecondaryOrSupplementarySkippingIterator.skipAnyNotprimary(SecondaryOrSupplementarySkippingIterator.java:36); at htsjdk.samtools.SecondaryOrSupplementarySkippingIterator.advance(SecondaryOrSupplementarySkippingIterator.java:31); at org.broadinstitute.hellbender.utils.read.SamComparison.compareCoordinateSortedAlignments(SamComparison.java:111); at org.broadinstitute.hellbender.utils.read.SamComparison.compareAlignments(SamComparison.java:68); at org.broadinstitute.hellbender.utils.read.SamComparison.<init>(SamComparison.java:44); at org.broadinstitute.hellbender.tools.picard.sam.CompareSAMs.doWork(CompareSAMs.java:34); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:94); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:144); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgram.instanceMain(PicardComm",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/419
https://github.com/broadinstitute/gatk/issues/423:0,Integrability,depend,depends,0,depends on #294. the requirement is to replicate the current functionality of the walker and make all tests pass,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/423
https://github.com/broadinstitute/gatk/issues/423:102,Testability,test,tests,102,depends on #294. the requirement is to replicate the current functionality of the walker and make all tests pass,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/423
https://github.com/broadinstitute/gatk/issues/424:149,Deployability,pipeline,pipeline,149,The acceptance criteria are to replicate the gatk3 functionality and tests. depends on #293 . there's code for some of it at googlegenomics/genomics-pipeline. @jean-philippe-martin can you describe the status of that code?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/424
https://github.com/broadinstitute/gatk/issues/424:76,Integrability,depend,depends,76,The acceptance criteria are to replicate the gatk3 functionality and tests. depends on #293 . there's code for some of it at googlegenomics/genomics-pipeline. @jean-philippe-martin can you describe the status of that code?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/424
https://github.com/broadinstitute/gatk/issues/424:69,Testability,test,tests,69,The acceptance criteria are to replicate the gatk3 functionality and tests. depends on #293 . there's code for some of it at googlegenomics/genomics-pipeline. @jean-philippe-martin can you describe the status of that code?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/424
https://github.com/broadinstitute/gatk/issues/426:86,Testability,test,tests,86,requirement for this ticket is to replicate the current gatk4 functionality (and make tests pass). We'll work from text-based recalibration tables for now.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/426
https://github.com/broadinstitute/gatk/issues/427:63,Deployability,pipeline,pipeline,63,"we should select and migrate code from googlegenomics/genomics-pipeline and move development to the hellbender repository. For now, move everything and we'll clean it up once it's in.; Assigning to @wbrockman to decide when it can be done (it's a private repo).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/427
https://github.com/broadinstitute/gatk/issues/436:100,Usability,Simpl,SimpleInterval,100,"@lbergelson noticed that in parts of the code it would be useful to have a Locatable constructor of SimpleInterval so that:. ``` java; SimpleInterval x = new SimpleInterval(l.getContig(),l.getStart(),l.getEnd()); ```. would be written like:. ``` java; SimpleInterval x = new SimpleInterval(l);; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/436
https://github.com/broadinstitute/gatk/issues/436:135,Usability,Simpl,SimpleInterval,135,"@lbergelson noticed that in parts of the code it would be useful to have a Locatable constructor of SimpleInterval so that:. ``` java; SimpleInterval x = new SimpleInterval(l.getContig(),l.getStart(),l.getEnd()); ```. would be written like:. ``` java; SimpleInterval x = new SimpleInterval(l);; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/436
https://github.com/broadinstitute/gatk/issues/436:158,Usability,Simpl,SimpleInterval,158,"@lbergelson noticed that in parts of the code it would be useful to have a Locatable constructor of SimpleInterval so that:. ``` java; SimpleInterval x = new SimpleInterval(l.getContig(),l.getStart(),l.getEnd()); ```. would be written like:. ``` java; SimpleInterval x = new SimpleInterval(l);; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/436
https://github.com/broadinstitute/gatk/issues/436:252,Usability,Simpl,SimpleInterval,252,"@lbergelson noticed that in parts of the code it would be useful to have a Locatable constructor of SimpleInterval so that:. ``` java; SimpleInterval x = new SimpleInterval(l.getContig(),l.getStart(),l.getEnd()); ```. would be written like:. ``` java; SimpleInterval x = new SimpleInterval(l);; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/436
https://github.com/broadinstitute/gatk/issues/436:275,Usability,Simpl,SimpleInterval,275,"@lbergelson noticed that in parts of the code it would be useful to have a Locatable constructor of SimpleInterval so that:. ``` java; SimpleInterval x = new SimpleInterval(l.getContig(),l.getStart(),l.getEnd()); ```. would be written like:. ``` java; SimpleInterval x = new SimpleInterval(l);; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/436
https://github.com/broadinstitute/gatk/issues/438:14,Usability,Simpl,SimpleInterval,14,It seems that SimpleInterval(String) constructor does not check that the start and end positions make sense (greater than 0 and end >= start).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/438
https://github.com/broadinstitute/gatk/pull/441:7,Security,validat,validation,7,"Adding validation to the SimpleInterval(String) constructor; Making GenomeLoc implement Locatable; Replacing all instances of SimpleInterval( locatable.getContig(), locatable.getStart(), locatable.getEnd()) with the new constructor. fixes #438 and #436",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/441
https://github.com/broadinstitute/gatk/pull/441:25,Usability,Simpl,SimpleInterval,25,"Adding validation to the SimpleInterval(String) constructor; Making GenomeLoc implement Locatable; Replacing all instances of SimpleInterval( locatable.getContig(), locatable.getStart(), locatable.getEnd()) with the new constructor. fixes #438 and #436",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/441
https://github.com/broadinstitute/gatk/pull/441:126,Usability,Simpl,SimpleInterval,126,"Adding validation to the SimpleInterval(String) constructor; Making GenomeLoc implement Locatable; Replacing all instances of SimpleInterval( locatable.getContig(), locatable.getStart(), locatable.getEnd()) with the new constructor. fixes #438 and #436",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/441
https://github.com/broadinstitute/gatk/pull/442:30,Testability,test,tests,30,I reenabled ReadCovariateUnit tests (disabled in GATK3 because it was failing) and added a bunch of code to make it tests the right thing. A lot of testing problems with reverse-strand reads is fixed now. fixes #412,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/442
https://github.com/broadinstitute/gatk/pull/442:116,Testability,test,tests,116,I reenabled ReadCovariateUnit tests (disabled in GATK3 because it was failing) and added a bunch of code to make it tests the right thing. A lot of testing problems with reverse-strand reads is fixed now. fixes #412,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/442
https://github.com/broadinstitute/gatk/pull/442:148,Testability,test,testing,148,I reenabled ReadCovariateUnit tests (disabled in GATK3 because it was failing) and added a bunch of code to make it tests the right thing. A lot of testing problems with reverse-strand reads is fixed now. fixes #412,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/442
https://github.com/broadinstitute/gatk/pull/443:749,Deployability,pipeline,pipeline,749,"This includes wrappers to present `SAMRecords` to the tools; Also adding 4 simple tools as examples; `FlagStatsDataflow`; It makes use of dataflow's built in hierarchical aggregation; `CountBasesDataflow`; Simple walker that makes use of the SAMRecord conversion; `CountReadsDataflow`; Does what it says; `PrintReadsDataflow`; This is a very limited version of our print reads walker; It prints `SAMRecords` as strings to an unordered text file; It could potentially be useful as method for examining bam output before we have a proper bam writer. These tools exist in two parts:; A transform extending from `PTransformSAM` (A subclass of `PTransform<Read,O>` which facilitates conversion to `SAMRecord`; A command line tool implementing a complete pipeline; These pipelines can apply arbitrary `ReadFilter`s/ `ReadTransformer`s which are applied before the main transform; (a list of transforms and a list of filters can be applied, it's currently not handled very efficiently though, better to pre-comine them into a single meta transform). Currently, only tests which use local files are running on travis.; There is code included to run on files in buckets, but the tests for it are currently disabled due to travis configuration issues (will be resolved in a seperate ticket). Some changes were made to existing classes to make them Serialize properly; Some test files were moved to help normalize test data locations (although not all tests are normalized, should be done in separate ticket); the new storage locations are based on the complete package name rather than just the tool name",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/443
https://github.com/broadinstitute/gatk/pull/443:765,Deployability,pipeline,pipelines,765,"This includes wrappers to present `SAMRecords` to the tools; Also adding 4 simple tools as examples; `FlagStatsDataflow`; It makes use of dataflow's built in hierarchical aggregation; `CountBasesDataflow`; Simple walker that makes use of the SAMRecord conversion; `CountReadsDataflow`; Does what it says; `PrintReadsDataflow`; This is a very limited version of our print reads walker; It prints `SAMRecords` as strings to an unordered text file; It could potentially be useful as method for examining bam output before we have a proper bam writer. These tools exist in two parts:; A transform extending from `PTransformSAM` (A subclass of `PTransform<Read,O>` which facilitates conversion to `SAMRecord`; A command line tool implementing a complete pipeline; These pipelines can apply arbitrary `ReadFilter`s/ `ReadTransformer`s which are applied before the main transform; (a list of transforms and a list of filters can be applied, it's currently not handled very efficiently though, better to pre-comine them into a single meta transform). Currently, only tests which use local files are running on travis.; There is code included to run on files in buckets, but the tests for it are currently disabled due to travis configuration issues (will be resolved in a seperate ticket). Some changes were made to existing classes to make them Serialize properly; Some test files were moved to help normalize test data locations (although not all tests are normalized, should be done in separate ticket); the new storage locations are based on the complete package name rather than just the tool name",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/443
https://github.com/broadinstitute/gatk/pull/443:1220,Deployability,configurat,configuration,1220,"This includes wrappers to present `SAMRecords` to the tools; Also adding 4 simple tools as examples; `FlagStatsDataflow`; It makes use of dataflow's built in hierarchical aggregation; `CountBasesDataflow`; Simple walker that makes use of the SAMRecord conversion; `CountReadsDataflow`; Does what it says; `PrintReadsDataflow`; This is a very limited version of our print reads walker; It prints `SAMRecords` as strings to an unordered text file; It could potentially be useful as method for examining bam output before we have a proper bam writer. These tools exist in two parts:; A transform extending from `PTransformSAM` (A subclass of `PTransform<Read,O>` which facilitates conversion to `SAMRecord`; A command line tool implementing a complete pipeline; These pipelines can apply arbitrary `ReadFilter`s/ `ReadTransformer`s which are applied before the main transform; (a list of transforms and a list of filters can be applied, it's currently not handled very efficiently though, better to pre-comine them into a single meta transform). Currently, only tests which use local files are running on travis.; There is code included to run on files in buckets, but the tests for it are currently disabled due to travis configuration issues (will be resolved in a seperate ticket). Some changes were made to existing classes to make them Serialize properly; Some test files were moved to help normalize test data locations (although not all tests are normalized, should be done in separate ticket); the new storage locations are based on the complete package name rather than just the tool name",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/443
https://github.com/broadinstitute/gatk/pull/443:966,Energy Efficiency,efficient,efficiently,966,"This includes wrappers to present `SAMRecords` to the tools; Also adding 4 simple tools as examples; `FlagStatsDataflow`; It makes use of dataflow's built in hierarchical aggregation; `CountBasesDataflow`; Simple walker that makes use of the SAMRecord conversion; `CountReadsDataflow`; Does what it says; `PrintReadsDataflow`; This is a very limited version of our print reads walker; It prints `SAMRecords` as strings to an unordered text file; It could potentially be useful as method for examining bam output before we have a proper bam writer. These tools exist in two parts:; A transform extending from `PTransformSAM` (A subclass of `PTransform<Read,O>` which facilitates conversion to `SAMRecord`; A command line tool implementing a complete pipeline; These pipelines can apply arbitrary `ReadFilter`s/ `ReadTransformer`s which are applied before the main transform; (a list of transforms and a list of filters can be applied, it's currently not handled very efficiently though, better to pre-comine them into a single meta transform). Currently, only tests which use local files are running on travis.; There is code included to run on files in buckets, but the tests for it are currently disabled due to travis configuration issues (will be resolved in a seperate ticket). Some changes were made to existing classes to make them Serialize properly; Some test files were moved to help normalize test data locations (although not all tests are normalized, should be done in separate ticket); the new storage locations are based on the complete package name rather than just the tool name",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/443
https://github.com/broadinstitute/gatk/pull/443:14,Integrability,wrap,wrappers,14,"This includes wrappers to present `SAMRecords` to the tools; Also adding 4 simple tools as examples; `FlagStatsDataflow`; It makes use of dataflow's built in hierarchical aggregation; `CountBasesDataflow`; Simple walker that makes use of the SAMRecord conversion; `CountReadsDataflow`; Does what it says; `PrintReadsDataflow`; This is a very limited version of our print reads walker; It prints `SAMRecords` as strings to an unordered text file; It could potentially be useful as method for examining bam output before we have a proper bam writer. These tools exist in two parts:; A transform extending from `PTransformSAM` (A subclass of `PTransform<Read,O>` which facilitates conversion to `SAMRecord`; A command line tool implementing a complete pipeline; These pipelines can apply arbitrary `ReadFilter`s/ `ReadTransformer`s which are applied before the main transform; (a list of transforms and a list of filters can be applied, it's currently not handled very efficiently though, better to pre-comine them into a single meta transform). Currently, only tests which use local files are running on travis.; There is code included to run on files in buckets, but the tests for it are currently disabled due to travis configuration issues (will be resolved in a seperate ticket). Some changes were made to existing classes to make them Serialize properly; Some test files were moved to help normalize test data locations (although not all tests are normalized, should be done in separate ticket); the new storage locations are based on the complete package name rather than just the tool name",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/443
https://github.com/broadinstitute/gatk/pull/443:593,Modifiability,extend,extending,593,"This includes wrappers to present `SAMRecords` to the tools; Also adding 4 simple tools as examples; `FlagStatsDataflow`; It makes use of dataflow's built in hierarchical aggregation; `CountBasesDataflow`; Simple walker that makes use of the SAMRecord conversion; `CountReadsDataflow`; Does what it says; `PrintReadsDataflow`; This is a very limited version of our print reads walker; It prints `SAMRecords` as strings to an unordered text file; It could potentially be useful as method for examining bam output before we have a proper bam writer. These tools exist in two parts:; A transform extending from `PTransformSAM` (A subclass of `PTransform<Read,O>` which facilitates conversion to `SAMRecord`; A command line tool implementing a complete pipeline; These pipelines can apply arbitrary `ReadFilter`s/ `ReadTransformer`s which are applied before the main transform; (a list of transforms and a list of filters can be applied, it's currently not handled very efficiently though, better to pre-comine them into a single meta transform). Currently, only tests which use local files are running on travis.; There is code included to run on files in buckets, but the tests for it are currently disabled due to travis configuration issues (will be resolved in a seperate ticket). Some changes were made to existing classes to make them Serialize properly; Some test files were moved to help normalize test data locations (although not all tests are normalized, should be done in separate ticket); the new storage locations are based on the complete package name rather than just the tool name",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/443
https://github.com/broadinstitute/gatk/pull/443:1220,Modifiability,config,configuration,1220,"This includes wrappers to present `SAMRecords` to the tools; Also adding 4 simple tools as examples; `FlagStatsDataflow`; It makes use of dataflow's built in hierarchical aggregation; `CountBasesDataflow`; Simple walker that makes use of the SAMRecord conversion; `CountReadsDataflow`; Does what it says; `PrintReadsDataflow`; This is a very limited version of our print reads walker; It prints `SAMRecords` as strings to an unordered text file; It could potentially be useful as method for examining bam output before we have a proper bam writer. These tools exist in two parts:; A transform extending from `PTransformSAM` (A subclass of `PTransform<Read,O>` which facilitates conversion to `SAMRecord`; A command line tool implementing a complete pipeline; These pipelines can apply arbitrary `ReadFilter`s/ `ReadTransformer`s which are applied before the main transform; (a list of transforms and a list of filters can be applied, it's currently not handled very efficiently though, better to pre-comine them into a single meta transform). Currently, only tests which use local files are running on travis.; There is code included to run on files in buckets, but the tests for it are currently disabled due to travis configuration issues (will be resolved in a seperate ticket). Some changes were made to existing classes to make them Serialize properly; Some test files were moved to help normalize test data locations (although not all tests are normalized, should be done in separate ticket); the new storage locations are based on the complete package name rather than just the tool name",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/443
https://github.com/broadinstitute/gatk/pull/443:1059,Testability,test,tests,1059,"This includes wrappers to present `SAMRecords` to the tools; Also adding 4 simple tools as examples; `FlagStatsDataflow`; It makes use of dataflow's built in hierarchical aggregation; `CountBasesDataflow`; Simple walker that makes use of the SAMRecord conversion; `CountReadsDataflow`; Does what it says; `PrintReadsDataflow`; This is a very limited version of our print reads walker; It prints `SAMRecords` as strings to an unordered text file; It could potentially be useful as method for examining bam output before we have a proper bam writer. These tools exist in two parts:; A transform extending from `PTransformSAM` (A subclass of `PTransform<Read,O>` which facilitates conversion to `SAMRecord`; A command line tool implementing a complete pipeline; These pipelines can apply arbitrary `ReadFilter`s/ `ReadTransformer`s which are applied before the main transform; (a list of transforms and a list of filters can be applied, it's currently not handled very efficiently though, better to pre-comine them into a single meta transform). Currently, only tests which use local files are running on travis.; There is code included to run on files in buckets, but the tests for it are currently disabled due to travis configuration issues (will be resolved in a seperate ticket). Some changes were made to existing classes to make them Serialize properly; Some test files were moved to help normalize test data locations (although not all tests are normalized, should be done in separate ticket); the new storage locations are based on the complete package name rather than just the tool name",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/443
https://github.com/broadinstitute/gatk/pull/443:1170,Testability,test,tests,1170,"This includes wrappers to present `SAMRecords` to the tools; Also adding 4 simple tools as examples; `FlagStatsDataflow`; It makes use of dataflow's built in hierarchical aggregation; `CountBasesDataflow`; Simple walker that makes use of the SAMRecord conversion; `CountReadsDataflow`; Does what it says; `PrintReadsDataflow`; This is a very limited version of our print reads walker; It prints `SAMRecords` as strings to an unordered text file; It could potentially be useful as method for examining bam output before we have a proper bam writer. These tools exist in two parts:; A transform extending from `PTransformSAM` (A subclass of `PTransform<Read,O>` which facilitates conversion to `SAMRecord`; A command line tool implementing a complete pipeline; These pipelines can apply arbitrary `ReadFilter`s/ `ReadTransformer`s which are applied before the main transform; (a list of transforms and a list of filters can be applied, it's currently not handled very efficiently though, better to pre-comine them into a single meta transform). Currently, only tests which use local files are running on travis.; There is code included to run on files in buckets, but the tests for it are currently disabled due to travis configuration issues (will be resolved in a seperate ticket). Some changes were made to existing classes to make them Serialize properly; Some test files were moved to help normalize test data locations (although not all tests are normalized, should be done in separate ticket); the new storage locations are based on the complete package name rather than just the tool name",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/443
https://github.com/broadinstitute/gatk/pull/443:1363,Testability,test,test,1363,"This includes wrappers to present `SAMRecords` to the tools; Also adding 4 simple tools as examples; `FlagStatsDataflow`; It makes use of dataflow's built in hierarchical aggregation; `CountBasesDataflow`; Simple walker that makes use of the SAMRecord conversion; `CountReadsDataflow`; Does what it says; `PrintReadsDataflow`; This is a very limited version of our print reads walker; It prints `SAMRecords` as strings to an unordered text file; It could potentially be useful as method for examining bam output before we have a proper bam writer. These tools exist in two parts:; A transform extending from `PTransformSAM` (A subclass of `PTransform<Read,O>` which facilitates conversion to `SAMRecord`; A command line tool implementing a complete pipeline; These pipelines can apply arbitrary `ReadFilter`s/ `ReadTransformer`s which are applied before the main transform; (a list of transforms and a list of filters can be applied, it's currently not handled very efficiently though, better to pre-comine them into a single meta transform). Currently, only tests which use local files are running on travis.; There is code included to run on files in buckets, but the tests for it are currently disabled due to travis configuration issues (will be resolved in a seperate ticket). Some changes were made to existing classes to make them Serialize properly; Some test files were moved to help normalize test data locations (although not all tests are normalized, should be done in separate ticket); the new storage locations are based on the complete package name rather than just the tool name",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/443
https://github.com/broadinstitute/gatk/pull/443:1403,Testability,test,test,1403,"This includes wrappers to present `SAMRecords` to the tools; Also adding 4 simple tools as examples; `FlagStatsDataflow`; It makes use of dataflow's built in hierarchical aggregation; `CountBasesDataflow`; Simple walker that makes use of the SAMRecord conversion; `CountReadsDataflow`; Does what it says; `PrintReadsDataflow`; This is a very limited version of our print reads walker; It prints `SAMRecords` as strings to an unordered text file; It could potentially be useful as method for examining bam output before we have a proper bam writer. These tools exist in two parts:; A transform extending from `PTransformSAM` (A subclass of `PTransform<Read,O>` which facilitates conversion to `SAMRecord`; A command line tool implementing a complete pipeline; These pipelines can apply arbitrary `ReadFilter`s/ `ReadTransformer`s which are applied before the main transform; (a list of transforms and a list of filters can be applied, it's currently not handled very efficiently though, better to pre-comine them into a single meta transform). Currently, only tests which use local files are running on travis.; There is code included to run on files in buckets, but the tests for it are currently disabled due to travis configuration issues (will be resolved in a seperate ticket). Some changes were made to existing classes to make them Serialize properly; Some test files were moved to help normalize test data locations (although not all tests are normalized, should be done in separate ticket); the new storage locations are based on the complete package name rather than just the tool name",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/443
https://github.com/broadinstitute/gatk/pull/443:1441,Testability,test,tests,1441,"This includes wrappers to present `SAMRecords` to the tools; Also adding 4 simple tools as examples; `FlagStatsDataflow`; It makes use of dataflow's built in hierarchical aggregation; `CountBasesDataflow`; Simple walker that makes use of the SAMRecord conversion; `CountReadsDataflow`; Does what it says; `PrintReadsDataflow`; This is a very limited version of our print reads walker; It prints `SAMRecords` as strings to an unordered text file; It could potentially be useful as method for examining bam output before we have a proper bam writer. These tools exist in two parts:; A transform extending from `PTransformSAM` (A subclass of `PTransform<Read,O>` which facilitates conversion to `SAMRecord`; A command line tool implementing a complete pipeline; These pipelines can apply arbitrary `ReadFilter`s/ `ReadTransformer`s which are applied before the main transform; (a list of transforms and a list of filters can be applied, it's currently not handled very efficiently though, better to pre-comine them into a single meta transform). Currently, only tests which use local files are running on travis.; There is code included to run on files in buckets, but the tests for it are currently disabled due to travis configuration issues (will be resolved in a seperate ticket). Some changes were made to existing classes to make them Serialize properly; Some test files were moved to help normalize test data locations (although not all tests are normalized, should be done in separate ticket); the new storage locations are based on the complete package name rather than just the tool name",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/443
https://github.com/broadinstitute/gatk/pull/443:75,Usability,simpl,simple,75,"This includes wrappers to present `SAMRecords` to the tools; Also adding 4 simple tools as examples; `FlagStatsDataflow`; It makes use of dataflow's built in hierarchical aggregation; `CountBasesDataflow`; Simple walker that makes use of the SAMRecord conversion; `CountReadsDataflow`; Does what it says; `PrintReadsDataflow`; This is a very limited version of our print reads walker; It prints `SAMRecords` as strings to an unordered text file; It could potentially be useful as method for examining bam output before we have a proper bam writer. These tools exist in two parts:; A transform extending from `PTransformSAM` (A subclass of `PTransform<Read,O>` which facilitates conversion to `SAMRecord`; A command line tool implementing a complete pipeline; These pipelines can apply arbitrary `ReadFilter`s/ `ReadTransformer`s which are applied before the main transform; (a list of transforms and a list of filters can be applied, it's currently not handled very efficiently though, better to pre-comine them into a single meta transform). Currently, only tests which use local files are running on travis.; There is code included to run on files in buckets, but the tests for it are currently disabled due to travis configuration issues (will be resolved in a seperate ticket). Some changes were made to existing classes to make them Serialize properly; Some test files were moved to help normalize test data locations (although not all tests are normalized, should be done in separate ticket); the new storage locations are based on the complete package name rather than just the tool name",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/443
https://github.com/broadinstitute/gatk/pull/443:206,Usability,Simpl,Simple,206,"This includes wrappers to present `SAMRecords` to the tools; Also adding 4 simple tools as examples; `FlagStatsDataflow`; It makes use of dataflow's built in hierarchical aggregation; `CountBasesDataflow`; Simple walker that makes use of the SAMRecord conversion; `CountReadsDataflow`; Does what it says; `PrintReadsDataflow`; This is a very limited version of our print reads walker; It prints `SAMRecords` as strings to an unordered text file; It could potentially be useful as method for examining bam output before we have a proper bam writer. These tools exist in two parts:; A transform extending from `PTransformSAM` (A subclass of `PTransform<Read,O>` which facilitates conversion to `SAMRecord`; A command line tool implementing a complete pipeline; These pipelines can apply arbitrary `ReadFilter`s/ `ReadTransformer`s which are applied before the main transform; (a list of transforms and a list of filters can be applied, it's currently not handled very efficiently though, better to pre-comine them into a single meta transform). Currently, only tests which use local files are running on travis.; There is code included to run on files in buckets, but the tests for it are currently disabled due to travis configuration issues (will be resolved in a seperate ticket). Some changes were made to existing classes to make them Serialize properly; Some test files were moved to help normalize test data locations (although not all tests are normalized, should be done in separate ticket); the new storage locations are based on the complete package name rather than just the tool name",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/443
https://github.com/broadinstitute/gatk/issues/444:23,Security,access,access,23,Any test that tries to access a bucket seems to stall indefinitely. I think this has to do with gcloud not accepting our credentials file on travis. I suspect it's trying to open a web browser. I suspect it may need to be reconfigured with a service account key and an explicit authorization step before the build.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/444
https://github.com/broadinstitute/gatk/issues/444:278,Security,authoriz,authorization,278,Any test that tries to access a bucket seems to stall indefinitely. I think this has to do with gcloud not accepting our credentials file on travis. I suspect it's trying to open a web browser. I suspect it may need to be reconfigured with a service account key and an explicit authorization step before the build.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/444
https://github.com/broadinstitute/gatk/issues/444:4,Testability,test,test,4,Any test that tries to access a bucket seems to stall indefinitely. I think this has to do with gcloud not accepting our credentials file on travis. I suspect it's trying to open a web browser. I suspect it may need to be reconfigured with a service account key and an explicit authorization step before the build.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/444
https://github.com/broadinstitute/gatk/issues/445:10,Testability,test,tests,10,Different tests store their test data in different places. Some still have common files dumped into the base test resources folder. I think we should standardize all the test data paths. I propose `src/test/resources/<package name>/<class being tested>/` as the base path for all test files for a specific class. . What do others think?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/445
https://github.com/broadinstitute/gatk/issues/445:28,Testability,test,test,28,Different tests store their test data in different places. Some still have common files dumped into the base test resources folder. I think we should standardize all the test data paths. I propose `src/test/resources/<package name>/<class being tested>/` as the base path for all test files for a specific class. . What do others think?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/445
https://github.com/broadinstitute/gatk/issues/445:109,Testability,test,test,109,Different tests store their test data in different places. Some still have common files dumped into the base test resources folder. I think we should standardize all the test data paths. I propose `src/test/resources/<package name>/<class being tested>/` as the base path for all test files for a specific class. . What do others think?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/445
https://github.com/broadinstitute/gatk/issues/445:170,Testability,test,test,170,Different tests store their test data in different places. Some still have common files dumped into the base test resources folder. I think we should standardize all the test data paths. I propose `src/test/resources/<package name>/<class being tested>/` as the base path for all test files for a specific class. . What do others think?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/445
https://github.com/broadinstitute/gatk/issues/445:202,Testability,test,test,202,Different tests store their test data in different places. Some still have common files dumped into the base test resources folder. I think we should standardize all the test data paths. I propose `src/test/resources/<package name>/<class being tested>/` as the base path for all test files for a specific class. . What do others think?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/445
https://github.com/broadinstitute/gatk/issues/445:245,Testability,test,tested,245,Different tests store their test data in different places. Some still have common files dumped into the base test resources folder. I think we should standardize all the test data paths. I propose `src/test/resources/<package name>/<class being tested>/` as the base path for all test files for a specific class. . What do others think?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/445
https://github.com/broadinstitute/gatk/issues/445:280,Testability,test,test,280,Different tests store their test data in different places. Some still have common files dumped into the base test resources folder. I think we should standardize all the test data paths. I propose `src/test/resources/<package name>/<class being tested>/` as the base path for all test files for a specific class. . What do others think?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/445
https://github.com/broadinstitute/gatk/issues/451:90,Testability,test,tests,90,came up in review of #449 . the following classes are unused code. they need examples and tests to show how to use them. OptionalFeatureInputArgumentCollection; RequiredFeatureInputArgumentCollection; RequiredReadInputArgumentCollection; RequiredReferenceInputArgumentCollection; RequiredVariantInputArgumentCollection,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/451
https://github.com/broadinstitute/gatk/issues/452:41,Testability,test,tests,41,GATKTool.getHeaderForFeatures needs unit tests to check the behavior,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/452
https://github.com/broadinstitute/gatk/issues/453:66,Testability,test,tests,66,The TableFeature class has almost no documentation and barely any tests. those two are completely unused and untested.; getAllValues; getValuesTo(int columnPosition) . Both doc and testing needs to improve for this class.; Came up in review of #449,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/453
https://github.com/broadinstitute/gatk/issues/453:181,Testability,test,testing,181,The TableFeature class has almost no documentation and barely any tests. those two are completely unused and untested.; getAllValues; getValuesTo(int columnPosition) . Both doc and testing needs to improve for this class.; Came up in review of #449,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/453
https://github.com/broadinstitute/gatk/pull/454:62,Testability,test,tests,62,ported all filters requested by @vdauwera in #429 ; and added tests for all of them.; @lbergelson please review,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/454
https://github.com/broadinstitute/gatk/pull/455:23,Modifiability,refactor,refactored,23,tests for CigarUtils + refactored methods in CigarUtils. ; Did not add tests to isValid because pull req #380 is addressing this method. There's a potential issue in countRefBasesBasedOnCigar - it's not clear why the implementation does what it does. @amilev can you comment on the intended semantics of this method and whether it can/should use `CigarOperator.consumesReferenceBases`?. addresses #153 and #450 ; @vruano please review.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/455
https://github.com/broadinstitute/gatk/pull/455:0,Testability,test,tests,0,tests for CigarUtils + refactored methods in CigarUtils. ; Did not add tests to isValid because pull req #380 is addressing this method. There's a potential issue in countRefBasesBasedOnCigar - it's not clear why the implementation does what it does. @amilev can you comment on the intended semantics of this method and whether it can/should use `CigarOperator.consumesReferenceBases`?. addresses #153 and #450 ; @vruano please review.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/455
https://github.com/broadinstitute/gatk/pull/455:71,Testability,test,tests,71,tests for CigarUtils + refactored methods in CigarUtils. ; Did not add tests to isValid because pull req #380 is addressing this method. There's a potential issue in countRefBasesBasedOnCigar - it's not clear why the implementation does what it does. @amilev can you comment on the intended semantics of this method and whether it can/should use `CigarOperator.consumesReferenceBases`?. addresses #153 and #450 ; @vruano please review.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/455
https://github.com/broadinstitute/gatk/pull/455:203,Usability,clear,clear,203,tests for CigarUtils + refactored methods in CigarUtils. ; Did not add tests to isValid because pull req #380 is addressing this method. There's a potential issue in countRefBasesBasedOnCigar - it's not clear why the implementation does what it does. @amilev can you comment on the intended semantics of this method and whether it can/should use `CigarOperator.consumesReferenceBases`?. addresses #153 and #450 ; @vruano please review.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/455
https://github.com/broadinstitute/gatk/issues/459:26,Deployability,pipeline,pipeline,26,Write a hardcoded one-off pipeline with stubs for each tool in the read pre-processing pipeline.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/459
https://github.com/broadinstitute/gatk/issues/459:87,Deployability,pipeline,pipeline,87,Write a hardcoded one-off pipeline with stubs for each tool in the read pre-processing pipeline.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/459
https://github.com/broadinstitute/gatk/issues/459:40,Testability,stub,stubs,40,Write a hardcoded one-off pipeline with stubs for each tool in the read pre-processing pipeline.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/459
https://github.com/broadinstitute/gatk/issues/466:84,Testability,test,tests,84,"the requirement is to port all PairHMM code (the public, non-protected classes) and tests for them.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/466
https://github.com/broadinstitute/gatk/issues/468:72,Testability,test,tests,72,"We're going to be having duplicates of our tools, but we don't want the tests to drift apart. We need a mechanism for running the same tests against both the dataflow and non-dataflow versions of a tool.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/468
https://github.com/broadinstitute/gatk/issues/468:135,Testability,test,tests,135,"We're going to be having duplicates of our tools, but we don't want the tests to drift apart. We need a mechanism for running the same tests against both the dataflow and non-dataflow versions of a tool.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/468
https://github.com/broadinstitute/gatk/pull/470:415,Deployability,Update,UpdateVcfSequenceDictionary,415,"As per internal discussions, we're removing the illumina package from hellbender's scope (for now at least) so I deleted all those classes. Also, for the following tools I wasn't able to get enough userbase/usecases so they are going away too. ```; ScatterIntervalsByNs ; BaitDesigner; BamIndexStats; CheckTerminatorBlock; ConvertSequencingArtifactToOxoG; ExtractSequences; FifoBuffer; MarkDuplicatesWithMateCigar; UpdateVcfSequenceDictionary; VcfFormatConverter; ViewSam; ```. @lbergelson please review",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/470
https://github.com/broadinstitute/gatk/issues/471:63,Testability,test,test,63,This snuck in at the base of our project. Lets put it with the test code.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/471
https://github.com/broadinstitute/gatk/pull/475:53,Testability,assert,assert,53,Adding a new `Utils.nonNull` which is a fluent style assert to throw `IllegalArgumentException` on nulls.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/475
https://github.com/broadinstitute/gatk/pull/476:72,Availability,avail,available,72,"This class is now needed by other pipelines, so let's make it generally available; in the engine.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/476
https://github.com/broadinstitute/gatk/pull/476:34,Deployability,pipeline,pipelines,34,"This class is now needed by other pipelines, so let's make it generally available; in the engine.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/476
https://github.com/broadinstitute/gatk/issues/477:241,Deployability,integrat,integrate,241,"We don't want users to have to prepend ""file://"" to their input/output files. Let's create a class that wraps URI, and prepends ""file://"" by default when there's no explicit prefix. It should have a constructor that takes a single String to integrate with our argument parsing system.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/477
https://github.com/broadinstitute/gatk/issues/477:104,Integrability,wrap,wraps,104,"We don't want users to have to prepend ""file://"" to their input/output files. Let's create a class that wraps URI, and prepends ""file://"" by default when there's no explicit prefix. It should have a constructor that takes a single String to integrate with our argument parsing system.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/477
https://github.com/broadinstitute/gatk/issues/477:241,Integrability,integrat,integrate,241,"We don't want users to have to prepend ""file://"" to their input/output files. Let's create a class that wraps URI, and prepends ""file://"" by default when there's no explicit prefix. It should have a constructor that takes a single String to integrate with our argument parsing system.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/477
https://github.com/broadinstitute/gatk/pull/478:127,Availability,redundant,redundant,127,"This request removes all calls to getChr() in the code by replacing calls to getChr() with calls to getContig() and removing a redundant assertion that contains a call to getChr(). To complete the removal of getChr() from the code, we could:. Remove the getChr() method overrides in the TableFeature and ArtificialTestFeature classes and convert these classes from implementing the Feature interface to implementing the Locatable interface. Remove the definition of the Feature interface from htsjdk.tribble (since all Feature does is add getChr() to the Locatable interface), and replace all references to the Feature interface in the tools and libraries with references to the Locatable interface. These steps will also remove the deprecation warnings for getChr() (part of #377).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/478
https://github.com/broadinstitute/gatk/pull/478:390,Integrability,interface,interface,390,"This request removes all calls to getChr() in the code by replacing calls to getChr() with calls to getContig() and removing a redundant assertion that contains a call to getChr(). To complete the removal of getChr() from the code, we could:. Remove the getChr() method overrides in the TableFeature and ArtificialTestFeature classes and convert these classes from implementing the Feature interface to implementing the Locatable interface. Remove the definition of the Feature interface from htsjdk.tribble (since all Feature does is add getChr() to the Locatable interface), and replace all references to the Feature interface in the tools and libraries with references to the Locatable interface. These steps will also remove the deprecation warnings for getChr() (part of #377).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/478
https://github.com/broadinstitute/gatk/pull/478:430,Integrability,interface,interface,430,"This request removes all calls to getChr() in the code by replacing calls to getChr() with calls to getContig() and removing a redundant assertion that contains a call to getChr(). To complete the removal of getChr() from the code, we could:. Remove the getChr() method overrides in the TableFeature and ArtificialTestFeature classes and convert these classes from implementing the Feature interface to implementing the Locatable interface. Remove the definition of the Feature interface from htsjdk.tribble (since all Feature does is add getChr() to the Locatable interface), and replace all references to the Feature interface in the tools and libraries with references to the Locatable interface. These steps will also remove the deprecation warnings for getChr() (part of #377).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/478
https://github.com/broadinstitute/gatk/pull/478:478,Integrability,interface,interface,478,"This request removes all calls to getChr() in the code by replacing calls to getChr() with calls to getContig() and removing a redundant assertion that contains a call to getChr(). To complete the removal of getChr() from the code, we could:. Remove the getChr() method overrides in the TableFeature and ArtificialTestFeature classes and convert these classes from implementing the Feature interface to implementing the Locatable interface. Remove the definition of the Feature interface from htsjdk.tribble (since all Feature does is add getChr() to the Locatable interface), and replace all references to the Feature interface in the tools and libraries with references to the Locatable interface. These steps will also remove the deprecation warnings for getChr() (part of #377).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/478
https://github.com/broadinstitute/gatk/pull/478:565,Integrability,interface,interface,565,"This request removes all calls to getChr() in the code by replacing calls to getChr() with calls to getContig() and removing a redundant assertion that contains a call to getChr(). To complete the removal of getChr() from the code, we could:. Remove the getChr() method overrides in the TableFeature and ArtificialTestFeature classes and convert these classes from implementing the Feature interface to implementing the Locatable interface. Remove the definition of the Feature interface from htsjdk.tribble (since all Feature does is add getChr() to the Locatable interface), and replace all references to the Feature interface in the tools and libraries with references to the Locatable interface. These steps will also remove the deprecation warnings for getChr() (part of #377).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/478
https://github.com/broadinstitute/gatk/pull/478:619,Integrability,interface,interface,619,"This request removes all calls to getChr() in the code by replacing calls to getChr() with calls to getContig() and removing a redundant assertion that contains a call to getChr(). To complete the removal of getChr() from the code, we could:. Remove the getChr() method overrides in the TableFeature and ArtificialTestFeature classes and convert these classes from implementing the Feature interface to implementing the Locatable interface. Remove the definition of the Feature interface from htsjdk.tribble (since all Feature does is add getChr() to the Locatable interface), and replace all references to the Feature interface in the tools and libraries with references to the Locatable interface. These steps will also remove the deprecation warnings for getChr() (part of #377).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/478
https://github.com/broadinstitute/gatk/pull/478:689,Integrability,interface,interface,689,"This request removes all calls to getChr() in the code by replacing calls to getChr() with calls to getContig() and removing a redundant assertion that contains a call to getChr(). To complete the removal of getChr() from the code, we could:. Remove the getChr() method overrides in the TableFeature and ArtificialTestFeature classes and convert these classes from implementing the Feature interface to implementing the Locatable interface. Remove the definition of the Feature interface from htsjdk.tribble (since all Feature does is add getChr() to the Locatable interface), and replace all references to the Feature interface in the tools and libraries with references to the Locatable interface. These steps will also remove the deprecation warnings for getChr() (part of #377).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/478
https://github.com/broadinstitute/gatk/pull/478:127,Safety,redund,redundant,127,"This request removes all calls to getChr() in the code by replacing calls to getChr() with calls to getContig() and removing a redundant assertion that contains a call to getChr(). To complete the removal of getChr() from the code, we could:. Remove the getChr() method overrides in the TableFeature and ArtificialTestFeature classes and convert these classes from implementing the Feature interface to implementing the Locatable interface. Remove the definition of the Feature interface from htsjdk.tribble (since all Feature does is add getChr() to the Locatable interface), and replace all references to the Feature interface in the tools and libraries with references to the Locatable interface. These steps will also remove the deprecation warnings for getChr() (part of #377).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/478
https://github.com/broadinstitute/gatk/pull/478:137,Testability,assert,assertion,137,"This request removes all calls to getChr() in the code by replacing calls to getChr() with calls to getContig() and removing a redundant assertion that contains a call to getChr(). To complete the removal of getChr() from the code, we could:. Remove the getChr() method overrides in the TableFeature and ArtificialTestFeature classes and convert these classes from implementing the Feature interface to implementing the Locatable interface. Remove the definition of the Feature interface from htsjdk.tribble (since all Feature does is add getChr() to the Locatable interface), and replace all references to the Feature interface in the tools and libraries with references to the Locatable interface. These steps will also remove the deprecation warnings for getChr() (part of #377).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/478
https://github.com/broadinstitute/gatk/pull/480:24,Testability,test,tests,24,I've added some doc and tests for what we can test in ReadSource. ; @droazen Please review,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/480
https://github.com/broadinstitute/gatk/pull/480:46,Testability,test,test,46,I've added some doc and tests for what we can test in ReadSource. ; @droazen Please review,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/480
https://github.com/broadinstitute/gatk/pull/481:16,Testability,test,test,16,"It looks like a test was generating a top level `testSortingFile.txt every time it ran, which accidentally got committed.; I've replaced this with a tmp file. I took the opportunity to make a few cosmetic improvements to the test file as well. Fixes #471",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/481
https://github.com/broadinstitute/gatk/pull/481:49,Testability,test,testSortingFile,49,"It looks like a test was generating a top level `testSortingFile.txt every time it ran, which accidentally got committed.; I've replaced this with a tmp file. I took the opportunity to make a few cosmetic improvements to the test file as well. Fixes #471",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/481
https://github.com/broadinstitute/gatk/pull/481:225,Testability,test,test,225,"It looks like a test was generating a top level `testSortingFile.txt every time it ran, which accidentally got committed.; I've replaced this with a tmp file. I took the opportunity to make a few cosmetic improvements to the test file as well. Fixes #471",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/481
https://github.com/broadinstitute/gatk/pull/482:43,Deployability,release,release,43,"gradle uploadArchives will perform a maven release (currently a snapshot release). Unfortunately the maven plugin has an ""install"" task which installs to the local repo, so it's now necessary to specify `installApp` or `installDist` instead of just `gradle install`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/482
https://github.com/broadinstitute/gatk/pull/482:73,Deployability,release,release,73,"gradle uploadArchives will perform a maven release (currently a snapshot release). Unfortunately the maven plugin has an ""install"" task which installs to the local repo, so it's now necessary to specify `installApp` or `installDist` instead of just `gradle install`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/482
https://github.com/broadinstitute/gatk/pull/482:122,Deployability,install,install,122,"gradle uploadArchives will perform a maven release (currently a snapshot release). Unfortunately the maven plugin has an ""install"" task which installs to the local repo, so it's now necessary to specify `installApp` or `installDist` instead of just `gradle install`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/482
https://github.com/broadinstitute/gatk/pull/482:142,Deployability,install,installs,142,"gradle uploadArchives will perform a maven release (currently a snapshot release). Unfortunately the maven plugin has an ""install"" task which installs to the local repo, so it's now necessary to specify `installApp` or `installDist` instead of just `gradle install`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/482
https://github.com/broadinstitute/gatk/pull/482:204,Deployability,install,installApp,204,"gradle uploadArchives will perform a maven release (currently a snapshot release). Unfortunately the maven plugin has an ""install"" task which installs to the local repo, so it's now necessary to specify `installApp` or `installDist` instead of just `gradle install`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/482
https://github.com/broadinstitute/gatk/pull/482:220,Deployability,install,installDist,220,"gradle uploadArchives will perform a maven release (currently a snapshot release). Unfortunately the maven plugin has an ""install"" task which installs to the local repo, so it's now necessary to specify `installApp` or `installDist` instead of just `gradle install`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/482
https://github.com/broadinstitute/gatk/pull/482:257,Deployability,install,install,257,"gradle uploadArchives will perform a maven release (currently a snapshot release). Unfortunately the maven plugin has an ""install"" task which installs to the local repo, so it's now necessary to specify `installApp` or `installDist` instead of just `gradle install`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/482
https://github.com/broadinstitute/gatk/pull/482:107,Modifiability,plugin,plugin,107,"gradle uploadArchives will perform a maven release (currently a snapshot release). Unfortunately the maven plugin has an ""install"" task which installs to the local repo, so it's now necessary to specify `installApp` or `installDist` instead of just `gradle install`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/482
https://github.com/broadinstitute/gatk/pull/482:27,Performance,perform,perform,27,"gradle uploadArchives will perform a maven release (currently a snapshot release). Unfortunately the maven plugin has an ""install"" task which installs to the local repo, so it's now necessary to specify `installApp` or `installDist` instead of just `gradle install`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/482
https://github.com/broadinstitute/gatk/issues/488:69,Deployability,integrat,integration,69,the requirement is to make MD fully work in a tested way (all Picard integration tests must work - perhaps by comparing the sets of reads that got marked as 'duplicate'). Note: we'll migrate this code from genomics-pipeline and adapt it to our needs and style.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/488
https://github.com/broadinstitute/gatk/issues/488:215,Deployability,pipeline,pipeline,215,the requirement is to make MD fully work in a tested way (all Picard integration tests must work - perhaps by comparing the sets of reads that got marked as 'duplicate'). Note: we'll migrate this code from genomics-pipeline and adapt it to our needs and style.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/488
https://github.com/broadinstitute/gatk/issues/488:228,Energy Efficiency,adapt,adapt,228,the requirement is to make MD fully work in a tested way (all Picard integration tests must work - perhaps by comparing the sets of reads that got marked as 'duplicate'). Note: we'll migrate this code from genomics-pipeline and adapt it to our needs and style.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/488
https://github.com/broadinstitute/gatk/issues/488:69,Integrability,integrat,integration,69,the requirement is to make MD fully work in a tested way (all Picard integration tests must work - perhaps by comparing the sets of reads that got marked as 'duplicate'). Note: we'll migrate this code from genomics-pipeline and adapt it to our needs and style.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/488
https://github.com/broadinstitute/gatk/issues/488:228,Modifiability,adapt,adapt,228,the requirement is to make MD fully work in a tested way (all Picard integration tests must work - perhaps by comparing the sets of reads that got marked as 'duplicate'). Note: we'll migrate this code from genomics-pipeline and adapt it to our needs and style.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/488
https://github.com/broadinstitute/gatk/issues/488:46,Testability,test,tested,46,the requirement is to make MD fully work in a tested way (all Picard integration tests must work - perhaps by comparing the sets of reads that got marked as 'duplicate'). Note: we'll migrate this code from genomics-pipeline and adapt it to our needs and style.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/488
https://github.com/broadinstitute/gatk/issues/488:81,Testability,test,tests,81,the requirement is to make MD fully work in a tested way (all Picard integration tests must work - perhaps by comparing the sets of reads that got marked as 'duplicate'). Note: we'll migrate this code from genomics-pipeline and adapt it to our needs and style.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/488
https://github.com/broadinstitute/gatk/issues/489:97,Availability,error,error,97,"I have Java 8 installed, but it's not my _default_ Java version, so `gradle check` gives me this error message:. ```; :compileJava FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':compileJava'.; > invalid source release: 1.8; ```. `JAVA_HOME=$JAVA8_HOME gradle check` succeeded. . I would prefer an error message like ""Hellbender requires JAVA_HOME to point to a valid Java 8 installation"" to make it immediately obvious what needs to be done.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/489
https://github.com/broadinstitute/gatk/issues/489:139,Availability,FAILURE,FAILURE,139,"I have Java 8 installed, but it's not my _default_ Java version, so `gradle check` gives me this error message:. ```; :compileJava FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':compileJava'.; > invalid source release: 1.8; ```. `JAVA_HOME=$JAVA8_HOME gradle check` succeeded. . I would prefer an error message like ""Hellbender requires JAVA_HOME to point to a valid Java 8 installation"" to make it immediately obvious what needs to be done.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/489
https://github.com/broadinstitute/gatk/issues/489:347,Availability,error,error,347,"I have Java 8 installed, but it's not my _default_ Java version, so `gradle check` gives me this error message:. ```; :compileJava FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':compileJava'.; > invalid source release: 1.8; ```. `JAVA_HOME=$JAVA8_HOME gradle check` succeeded. . I would prefer an error message like ""Hellbender requires JAVA_HOME to point to a valid Java 8 installation"" to make it immediately obvious what needs to be done.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/489
https://github.com/broadinstitute/gatk/issues/489:14,Deployability,install,installed,14,"I have Java 8 installed, but it's not my _default_ Java version, so `gradle check` gives me this error message:. ```; :compileJava FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':compileJava'.; > invalid source release: 1.8; ```. `JAVA_HOME=$JAVA8_HOME gradle check` succeeded. . I would prefer an error message like ""Hellbender requires JAVA_HOME to point to a valid Java 8 installation"" to make it immediately obvious what needs to be done.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/489
https://github.com/broadinstitute/gatk/issues/489:260,Deployability,release,release,260,"I have Java 8 installed, but it's not my _default_ Java version, so `gradle check` gives me this error message:. ```; :compileJava FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':compileJava'.; > invalid source release: 1.8; ```. `JAVA_HOME=$JAVA8_HOME gradle check` succeeded. . I would prefer an error message like ""Hellbender requires JAVA_HOME to point to a valid Java 8 installation"" to make it immediately obvious what needs to be done.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/489
https://github.com/broadinstitute/gatk/issues/489:424,Deployability,install,installation,424,"I have Java 8 installed, but it's not my _default_ Java version, so `gradle check` gives me this error message:. ```; :compileJava FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':compileJava'.; > invalid source release: 1.8; ```. `JAVA_HOME=$JAVA8_HOME gradle check` succeeded. . I would prefer an error message like ""Hellbender requires JAVA_HOME to point to a valid Java 8 installation"" to make it immediately obvious what needs to be done.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/489
https://github.com/broadinstitute/gatk/issues/489:103,Integrability,message,message,103,"I have Java 8 installed, but it's not my _default_ Java version, so `gradle check` gives me this error message:. ```; :compileJava FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':compileJava'.; > invalid source release: 1.8; ```. `JAVA_HOME=$JAVA8_HOME gradle check` succeeded. . I would prefer an error message like ""Hellbender requires JAVA_HOME to point to a valid Java 8 installation"" to make it immediately obvious what needs to be done.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/489
https://github.com/broadinstitute/gatk/issues/489:353,Integrability,message,message,353,"I have Java 8 installed, but it's not my _default_ Java version, so `gradle check` gives me this error message:. ```; :compileJava FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':compileJava'.; > invalid source release: 1.8; ```. `JAVA_HOME=$JAVA8_HOME gradle check` succeeded. . I would prefer an error message like ""Hellbender requires JAVA_HOME to point to a valid Java 8 installation"" to make it immediately obvious what needs to be done.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/489
https://github.com/broadinstitute/gatk/issues/491:155,Usability,simpl,simple,155,Implement a version of CollectInsertSizeMetrics that runs on dataflow and produces the same output as the current picard version. . It seems like a pretty simple and fairly representative metric. . Should deal with #468 as part of this.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/491
https://github.com/broadinstitute/gatk/pull/493:69,Testability,test,test,69,"A utility class to go from Read to SAMRecord, with an initial simple test.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/493
https://github.com/broadinstitute/gatk/pull/493:62,Usability,simpl,simple,62,"A utility class to go from Read to SAMRecord, with an initial simple test.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/493
https://github.com/broadinstitute/gatk/issues/498:85,Deployability,integrat,integration,85,ReCapSeg uses HD5F to store matrix data. This issue is about addressing hdf5 library integration in Hellbender. . Time estimate of 5 man days.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/498
https://github.com/broadinstitute/gatk/issues/498:85,Integrability,integrat,integration,85,ReCapSeg uses HD5F to store matrix data. This issue is about addressing hdf5 library integration in Hellbender. . Time estimate of 5 man days.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/498
https://github.com/broadinstitute/gatk/issues/508:117,Modifiability,config,config,117,"Would be nice if common, rarely-changing dataflow options like the project and client secret could be specified in a config file rather than as part of every hellbender command.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/508
https://github.com/broadinstitute/gatk/issues/509:116,Deployability,pipeline,pipelines,116,`ReadBAMTransform.getReadsFromBAMFilesSharded()` (which we rely upon to produce initial `PCollection<Read>`s in our pipelines) relies on flawed conversion from `SAMRecord` to `Read` (`ReadConverter.makeRead()`) that (among other things) does not encode attributes correctly. It also does not support unmapped reads. We should fix these issues.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/509
https://github.com/broadinstitute/gatk/issues/510:25,Testability,test,test,25,delete all data from src/test/resources/org/broadinstitute/hellbender/tools/picard/illumina/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/510
https://github.com/broadinstitute/gatk/pull/511:1079,Availability,avail,available,1079,"This code wraps around BaseRecalibrator and presents a very basic interface (set up, add reads, teardown) that's going to be used at each Dataflow worker. Challenges here:; (1) I need to convert the intervals to Features because that's what the BaseRecalibrator class uses, and SimpleInterval is not a subclass of Feature. This may change in the future.; (2) BaseRecalibrator takes Features as inputs - the only simple Feature class I found I could reuse is ArtificialTestFeature. Please let me know if there is a better choice (solving (1) also solves this); (3) I didn't find code to test overlap between a SimpleInterval and a Feature. Rather than roll my own I chose to use the SimpleInterval overlap test and convert to Feature lazily instead of eagerly. This may cause an interval to be converted more than once. So please consider this the start of a discussion on ""here is something that works, but surely there's a better way?"" I'm not so much looking for every performance opportunity, but ideally I'd like to avoid using ArtificialTestFeature if a better candidate is available.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/511
https://github.com/broadinstitute/gatk/pull/511:10,Integrability,wrap,wraps,10,"This code wraps around BaseRecalibrator and presents a very basic interface (set up, add reads, teardown) that's going to be used at each Dataflow worker. Challenges here:; (1) I need to convert the intervals to Features because that's what the BaseRecalibrator class uses, and SimpleInterval is not a subclass of Feature. This may change in the future.; (2) BaseRecalibrator takes Features as inputs - the only simple Feature class I found I could reuse is ArtificialTestFeature. Please let me know if there is a better choice (solving (1) also solves this); (3) I didn't find code to test overlap between a SimpleInterval and a Feature. Rather than roll my own I chose to use the SimpleInterval overlap test and convert to Feature lazily instead of eagerly. This may cause an interval to be converted more than once. So please consider this the start of a discussion on ""here is something that works, but surely there's a better way?"" I'm not so much looking for every performance opportunity, but ideally I'd like to avoid using ArtificialTestFeature if a better candidate is available.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/511
https://github.com/broadinstitute/gatk/pull/511:66,Integrability,interface,interface,66,"This code wraps around BaseRecalibrator and presents a very basic interface (set up, add reads, teardown) that's going to be used at each Dataflow worker. Challenges here:; (1) I need to convert the intervals to Features because that's what the BaseRecalibrator class uses, and SimpleInterval is not a subclass of Feature. This may change in the future.; (2) BaseRecalibrator takes Features as inputs - the only simple Feature class I found I could reuse is ArtificialTestFeature. Please let me know if there is a better choice (solving (1) also solves this); (3) I didn't find code to test overlap between a SimpleInterval and a Feature. Rather than roll my own I chose to use the SimpleInterval overlap test and convert to Feature lazily instead of eagerly. This may cause an interval to be converted more than once. So please consider this the start of a discussion on ""here is something that works, but surely there's a better way?"" I'm not so much looking for every performance opportunity, but ideally I'd like to avoid using ArtificialTestFeature if a better candidate is available.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/511
https://github.com/broadinstitute/gatk/pull/511:971,Performance,perform,performance,971,"This code wraps around BaseRecalibrator and presents a very basic interface (set up, add reads, teardown) that's going to be used at each Dataflow worker. Challenges here:; (1) I need to convert the intervals to Features because that's what the BaseRecalibrator class uses, and SimpleInterval is not a subclass of Feature. This may change in the future.; (2) BaseRecalibrator takes Features as inputs - the only simple Feature class I found I could reuse is ArtificialTestFeature. Please let me know if there is a better choice (solving (1) also solves this); (3) I didn't find code to test overlap between a SimpleInterval and a Feature. Rather than roll my own I chose to use the SimpleInterval overlap test and convert to Feature lazily instead of eagerly. This may cause an interval to be converted more than once. So please consider this the start of a discussion on ""here is something that works, but surely there's a better way?"" I'm not so much looking for every performance opportunity, but ideally I'd like to avoid using ArtificialTestFeature if a better candidate is available.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/511
https://github.com/broadinstitute/gatk/pull/511:1020,Safety,avoid,avoid,1020,"This code wraps around BaseRecalibrator and presents a very basic interface (set up, add reads, teardown) that's going to be used at each Dataflow worker. Challenges here:; (1) I need to convert the intervals to Features because that's what the BaseRecalibrator class uses, and SimpleInterval is not a subclass of Feature. This may change in the future.; (2) BaseRecalibrator takes Features as inputs - the only simple Feature class I found I could reuse is ArtificialTestFeature. Please let me know if there is a better choice (solving (1) also solves this); (3) I didn't find code to test overlap between a SimpleInterval and a Feature. Rather than roll my own I chose to use the SimpleInterval overlap test and convert to Feature lazily instead of eagerly. This may cause an interval to be converted more than once. So please consider this the start of a discussion on ""here is something that works, but surely there's a better way?"" I'm not so much looking for every performance opportunity, but ideally I'd like to avoid using ArtificialTestFeature if a better candidate is available.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/511
https://github.com/broadinstitute/gatk/pull/511:586,Testability,test,test,586,"This code wraps around BaseRecalibrator and presents a very basic interface (set up, add reads, teardown) that's going to be used at each Dataflow worker. Challenges here:; (1) I need to convert the intervals to Features because that's what the BaseRecalibrator class uses, and SimpleInterval is not a subclass of Feature. This may change in the future.; (2) BaseRecalibrator takes Features as inputs - the only simple Feature class I found I could reuse is ArtificialTestFeature. Please let me know if there is a better choice (solving (1) also solves this); (3) I didn't find code to test overlap between a SimpleInterval and a Feature. Rather than roll my own I chose to use the SimpleInterval overlap test and convert to Feature lazily instead of eagerly. This may cause an interval to be converted more than once. So please consider this the start of a discussion on ""here is something that works, but surely there's a better way?"" I'm not so much looking for every performance opportunity, but ideally I'd like to avoid using ArtificialTestFeature if a better candidate is available.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/511
https://github.com/broadinstitute/gatk/pull/511:705,Testability,test,test,705,"This code wraps around BaseRecalibrator and presents a very basic interface (set up, add reads, teardown) that's going to be used at each Dataflow worker. Challenges here:; (1) I need to convert the intervals to Features because that's what the BaseRecalibrator class uses, and SimpleInterval is not a subclass of Feature. This may change in the future.; (2) BaseRecalibrator takes Features as inputs - the only simple Feature class I found I could reuse is ArtificialTestFeature. Please let me know if there is a better choice (solving (1) also solves this); (3) I didn't find code to test overlap between a SimpleInterval and a Feature. Rather than roll my own I chose to use the SimpleInterval overlap test and convert to Feature lazily instead of eagerly. This may cause an interval to be converted more than once. So please consider this the start of a discussion on ""here is something that works, but surely there's a better way?"" I'm not so much looking for every performance opportunity, but ideally I'd like to avoid using ArtificialTestFeature if a better candidate is available.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/511
https://github.com/broadinstitute/gatk/pull/511:278,Usability,Simpl,SimpleInterval,278,"This code wraps around BaseRecalibrator and presents a very basic interface (set up, add reads, teardown) that's going to be used at each Dataflow worker. Challenges here:; (1) I need to convert the intervals to Features because that's what the BaseRecalibrator class uses, and SimpleInterval is not a subclass of Feature. This may change in the future.; (2) BaseRecalibrator takes Features as inputs - the only simple Feature class I found I could reuse is ArtificialTestFeature. Please let me know if there is a better choice (solving (1) also solves this); (3) I didn't find code to test overlap between a SimpleInterval and a Feature. Rather than roll my own I chose to use the SimpleInterval overlap test and convert to Feature lazily instead of eagerly. This may cause an interval to be converted more than once. So please consider this the start of a discussion on ""here is something that works, but surely there's a better way?"" I'm not so much looking for every performance opportunity, but ideally I'd like to avoid using ArtificialTestFeature if a better candidate is available.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/511
https://github.com/broadinstitute/gatk/pull/511:412,Usability,simpl,simple,412,"This code wraps around BaseRecalibrator and presents a very basic interface (set up, add reads, teardown) that's going to be used at each Dataflow worker. Challenges here:; (1) I need to convert the intervals to Features because that's what the BaseRecalibrator class uses, and SimpleInterval is not a subclass of Feature. This may change in the future.; (2) BaseRecalibrator takes Features as inputs - the only simple Feature class I found I could reuse is ArtificialTestFeature. Please let me know if there is a better choice (solving (1) also solves this); (3) I didn't find code to test overlap between a SimpleInterval and a Feature. Rather than roll my own I chose to use the SimpleInterval overlap test and convert to Feature lazily instead of eagerly. This may cause an interval to be converted more than once. So please consider this the start of a discussion on ""here is something that works, but surely there's a better way?"" I'm not so much looking for every performance opportunity, but ideally I'd like to avoid using ArtificialTestFeature if a better candidate is available.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/511
https://github.com/broadinstitute/gatk/pull/511:609,Usability,Simpl,SimpleInterval,609,"This code wraps around BaseRecalibrator and presents a very basic interface (set up, add reads, teardown) that's going to be used at each Dataflow worker. Challenges here:; (1) I need to convert the intervals to Features because that's what the BaseRecalibrator class uses, and SimpleInterval is not a subclass of Feature. This may change in the future.; (2) BaseRecalibrator takes Features as inputs - the only simple Feature class I found I could reuse is ArtificialTestFeature. Please let me know if there is a better choice (solving (1) also solves this); (3) I didn't find code to test overlap between a SimpleInterval and a Feature. Rather than roll my own I chose to use the SimpleInterval overlap test and convert to Feature lazily instead of eagerly. This may cause an interval to be converted more than once. So please consider this the start of a discussion on ""here is something that works, but surely there's a better way?"" I'm not so much looking for every performance opportunity, but ideally I'd like to avoid using ArtificialTestFeature if a better candidate is available.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/511
https://github.com/broadinstitute/gatk/pull/511:682,Usability,Simpl,SimpleInterval,682,"This code wraps around BaseRecalibrator and presents a very basic interface (set up, add reads, teardown) that's going to be used at each Dataflow worker. Challenges here:; (1) I need to convert the intervals to Features because that's what the BaseRecalibrator class uses, and SimpleInterval is not a subclass of Feature. This may change in the future.; (2) BaseRecalibrator takes Features as inputs - the only simple Feature class I found I could reuse is ArtificialTestFeature. Please let me know if there is a better choice (solving (1) also solves this); (3) I didn't find code to test overlap between a SimpleInterval and a Feature. Rather than roll my own I chose to use the SimpleInterval overlap test and convert to Feature lazily instead of eagerly. This may cause an interval to be converted more than once. So please consider this the start of a discussion on ""here is something that works, but surely there's a better way?"" I'm not so much looking for every performance opportunity, but ideally I'd like to avoid using ArtificialTestFeature if a better candidate is available.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/511
https://github.com/broadinstitute/gatk/pull/512:156,Security,Hash,HashedListExonCollection,156,"… ""abstract"" keyword to classes that are not instantiated. Classes that can be neither final nor abstract include: UserException, GATKException, GenomeLoc, HashedListExonCollection, LocusIteratorByStateBaseTest, ReadClipper, OverhangFixingManager, BasicInputParser",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/512
https://github.com/broadinstitute/gatk/pull/513:168,Deployability,pipeline,pipeline,168,"I created a minimal branch to clean up the way we were passing around credentials. We create a GCSOptions class instead of a DataflowPipelineOptions when we create the pipeline and pass in secrets in at the point instead at the ReadSources level. ReadSources now takes a pipeline instead of the secrets file location. This isn't a long term solution. We should switch the code to get rid of the GenomicsSecret and instead use the more general secret. I think much of the secets factory junk can go away now (they dated from a time when the Dataflow API wasn't built out much. All tests passed locally. Oddly, I now am sometimes getting a dialog about DSDE needing access to basic information about my Google account, not sure source of the issue (maybe the secret I grabbed?), if it's repeatable, or blocking. I recommend the reviewer patch my branch and test locally.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/513
https://github.com/broadinstitute/gatk/pull/513:271,Deployability,pipeline,pipeline,271,"I created a minimal branch to clean up the way we were passing around credentials. We create a GCSOptions class instead of a DataflowPipelineOptions when we create the pipeline and pass in secrets in at the point instead at the ReadSources level. ReadSources now takes a pipeline instead of the secrets file location. This isn't a long term solution. We should switch the code to get rid of the GenomicsSecret and instead use the more general secret. I think much of the secets factory junk can go away now (they dated from a time when the Dataflow API wasn't built out much. All tests passed locally. Oddly, I now am sometimes getting a dialog about DSDE needing access to basic information about my Google account, not sure source of the issue (maybe the secret I grabbed?), if it's repeatable, or blocking. I recommend the reviewer patch my branch and test locally.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/513
https://github.com/broadinstitute/gatk/pull/513:835,Deployability,patch,patch,835,"I created a minimal branch to clean up the way we were passing around credentials. We create a GCSOptions class instead of a DataflowPipelineOptions when we create the pipeline and pass in secrets in at the point instead at the ReadSources level. ReadSources now takes a pipeline instead of the secrets file location. This isn't a long term solution. We should switch the code to get rid of the GenomicsSecret and instead use the more general secret. I think much of the secets factory junk can go away now (they dated from a time when the Dataflow API wasn't built out much. All tests passed locally. Oddly, I now am sometimes getting a dialog about DSDE needing access to basic information about my Google account, not sure source of the issue (maybe the secret I grabbed?), if it's repeatable, or blocking. I recommend the reviewer patch my branch and test locally.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/513
https://github.com/broadinstitute/gatk/pull/513:664,Security,access,access,664,"I created a minimal branch to clean up the way we were passing around credentials. We create a GCSOptions class instead of a DataflowPipelineOptions when we create the pipeline and pass in secrets in at the point instead at the ReadSources level. ReadSources now takes a pipeline instead of the secrets file location. This isn't a long term solution. We should switch the code to get rid of the GenomicsSecret and instead use the more general secret. I think much of the secets factory junk can go away now (they dated from a time when the Dataflow API wasn't built out much. All tests passed locally. Oddly, I now am sometimes getting a dialog about DSDE needing access to basic information about my Google account, not sure source of the issue (maybe the secret I grabbed?), if it's repeatable, or blocking. I recommend the reviewer patch my branch and test locally.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/513
https://github.com/broadinstitute/gatk/pull/513:580,Testability,test,tests,580,"I created a minimal branch to clean up the way we were passing around credentials. We create a GCSOptions class instead of a DataflowPipelineOptions when we create the pipeline and pass in secrets in at the point instead at the ReadSources level. ReadSources now takes a pipeline instead of the secrets file location. This isn't a long term solution. We should switch the code to get rid of the GenomicsSecret and instead use the more general secret. I think much of the secets factory junk can go away now (they dated from a time when the Dataflow API wasn't built out much. All tests passed locally. Oddly, I now am sometimes getting a dialog about DSDE needing access to basic information about my Google account, not sure source of the issue (maybe the secret I grabbed?), if it's repeatable, or blocking. I recommend the reviewer patch my branch and test locally.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/513
https://github.com/broadinstitute/gatk/pull/513:855,Testability,test,test,855,"I created a minimal branch to clean up the way we were passing around credentials. We create a GCSOptions class instead of a DataflowPipelineOptions when we create the pipeline and pass in secrets in at the point instead at the ReadSources level. ReadSources now takes a pipeline instead of the secrets file location. This isn't a long term solution. We should switch the code to get rid of the GenomicsSecret and instead use the more general secret. I think much of the secets factory junk can go away now (they dated from a time when the Dataflow API wasn't built out much. All tests passed locally. Oddly, I now am sometimes getting a dialog about DSDE needing access to basic information about my Google account, not sure source of the issue (maybe the secret I grabbed?), if it's repeatable, or blocking. I recommend the reviewer patch my branch and test locally.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/513
https://github.com/broadinstitute/gatk/pull/518:32,Deployability,install,installation,32,This allow us to simplify our R installation in Travis. . R tests now only test Rscript executor; Using standard ubuntu R in travis instead of the more up to date one; Removing installation of R packages as part of gradle and travis builds; Updating readme,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/518
https://github.com/broadinstitute/gatk/pull/518:177,Deployability,install,installation,177,This allow us to simplify our R installation in Travis. . R tests now only test Rscript executor; Using standard ubuntu R in travis instead of the more up to date one; Removing installation of R packages as part of gradle and travis builds; Updating readme,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/518
https://github.com/broadinstitute/gatk/pull/518:60,Testability,test,tests,60,This allow us to simplify our R installation in Travis. . R tests now only test Rscript executor; Using standard ubuntu R in travis instead of the more up to date one; Removing installation of R packages as part of gradle and travis builds; Updating readme,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/518
https://github.com/broadinstitute/gatk/pull/518:75,Testability,test,test,75,This allow us to simplify our R installation in Travis. . R tests now only test Rscript executor; Using standard ubuntu R in travis instead of the more up to date one; Removing installation of R packages as part of gradle and travis builds; Updating readme,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/518
https://github.com/broadinstitute/gatk/pull/518:17,Usability,simpl,simplify,17,This allow us to simplify our R installation in Travis. . R tests now only test Rscript executor; Using standard ubuntu R in travis instead of the more up to date one; Removing installation of R packages as part of gradle and travis builds; Updating readme,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/518
https://github.com/broadinstitute/gatk/pull/519:10,Integrability,interface,interface,10,"We need a interface for variants that can be backed by the Google variant as well as VariantContext (from htsjdk). At first, we only need interval and isSNP/isIndel, so that's the interface right now. This shouldn't impact clients much as the interface interface grows because it will initially only be filled by Hellbender code.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/519
https://github.com/broadinstitute/gatk/pull/519:180,Integrability,interface,interface,180,"We need a interface for variants that can be backed by the Google variant as well as VariantContext (from htsjdk). At first, we only need interval and isSNP/isIndel, so that's the interface right now. This shouldn't impact clients much as the interface interface grows because it will initially only be filled by Hellbender code.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/519
https://github.com/broadinstitute/gatk/pull/519:243,Integrability,interface,interface,243,"We need a interface for variants that can be backed by the Google variant as well as VariantContext (from htsjdk). At first, we only need interval and isSNP/isIndel, so that's the interface right now. This shouldn't impact clients much as the interface interface grows because it will initially only be filled by Hellbender code.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/519
https://github.com/broadinstitute/gatk/pull/519:253,Integrability,interface,interface,253,"We need a interface for variants that can be backed by the Google variant as well as VariantContext (from htsjdk). At first, we only need interval and isSNP/isIndel, so that's the interface right now. This shouldn't impact clients much as the interface interface grows because it will initially only be filled by Hellbender code.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/519
https://github.com/broadinstitute/gatk/pull/520:58,Integrability,wrap,wrappers,58,Adding a circle.yml file; Adding the autogenerated gradle wrappers because CircleCI uses them to figure out how to gradle properly; Removing parallel tests once again because the CircleCI containers crash due to 2 jvms consuming too much memory.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/520
https://github.com/broadinstitute/gatk/pull/520:150,Testability,test,tests,150,Adding a circle.yml file; Adding the autogenerated gradle wrappers because CircleCI uses them to figure out how to gradle properly; Removing parallel tests once again because the CircleCI containers crash due to 2 jvms consuming too much memory.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/520
https://github.com/broadinstitute/gatk/pull/522:77,Testability,test,testable,77,"This is how the dataflow process merges the intermediate results. Since it's testable independently, I thought I'd check it in as a unit.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/522
https://github.com/broadinstitute/gatk/pull/523:120,Deployability,integrat,integration,120,"- DF_BaseRecalibrator tool, can be called from the command line. Same syntax as BaseRecalibrator.; - BaseRecalibrator's integration tests ported to this Dataflow version.; - Small changes to make types serializable.; - Note that this pull request is an intermediate step as it only works for local computations. (this depends on [PR#522](https://github.com/broadinstitute/hellbender/pull/522))",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/523
https://github.com/broadinstitute/gatk/pull/523:120,Integrability,integrat,integration,120,"- DF_BaseRecalibrator tool, can be called from the command line. Same syntax as BaseRecalibrator.; - BaseRecalibrator's integration tests ported to this Dataflow version.; - Small changes to make types serializable.; - Note that this pull request is an intermediate step as it only works for local computations. (this depends on [PR#522](https://github.com/broadinstitute/hellbender/pull/522))",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/523
https://github.com/broadinstitute/gatk/pull/523:318,Integrability,depend,depends,318,"- DF_BaseRecalibrator tool, can be called from the command line. Same syntax as BaseRecalibrator.; - BaseRecalibrator's integration tests ported to this Dataflow version.; - Small changes to make types serializable.; - Note that this pull request is an intermediate step as it only works for local computations. (this depends on [PR#522](https://github.com/broadinstitute/hellbender/pull/522))",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/523
https://github.com/broadinstitute/gatk/pull/523:132,Testability,test,tests,132,"- DF_BaseRecalibrator tool, can be called from the command line. Same syntax as BaseRecalibrator.; - BaseRecalibrator's integration tests ported to this Dataflow version.; - Small changes to make types serializable.; - Note that this pull request is an intermediate step as it only works for local computations. (this depends on [PR#522](https://github.com/broadinstitute/hellbender/pull/522))",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/523
https://github.com/broadinstitute/gatk/pull/527:128,Availability,avail,available,128,Moving classes that tests depend on from the test folders into the src folders in the utils.test package. This way they will be available to projects that depend on hellbender. Fixes #525 . Updating to the newest testng release.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/527
https://github.com/broadinstitute/gatk/pull/527:220,Deployability,release,release,220,Moving classes that tests depend on from the test folders into the src folders in the utils.test package. This way they will be available to projects that depend on hellbender. Fixes #525 . Updating to the newest testng release.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/527
https://github.com/broadinstitute/gatk/pull/527:26,Integrability,depend,depend,26,Moving classes that tests depend on from the test folders into the src folders in the utils.test package. This way they will be available to projects that depend on hellbender. Fixes #525 . Updating to the newest testng release.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/527
https://github.com/broadinstitute/gatk/pull/527:155,Integrability,depend,depend,155,Moving classes that tests depend on from the test folders into the src folders in the utils.test package. This way they will be available to projects that depend on hellbender. Fixes #525 . Updating to the newest testng release.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/527
https://github.com/broadinstitute/gatk/pull/527:20,Testability,test,tests,20,Moving classes that tests depend on from the test folders into the src folders in the utils.test package. This way they will be available to projects that depend on hellbender. Fixes #525 . Updating to the newest testng release.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/527
https://github.com/broadinstitute/gatk/pull/527:45,Testability,test,test,45,Moving classes that tests depend on from the test folders into the src folders in the utils.test package. This way they will be available to projects that depend on hellbender. Fixes #525 . Updating to the newest testng release.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/527
https://github.com/broadinstitute/gatk/pull/527:92,Testability,test,test,92,Moving classes that tests depend on from the test folders into the src folders in the utils.test package. This way they will be available to projects that depend on hellbender. Fixes #525 . Updating to the newest testng release.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/527
https://github.com/broadinstitute/gatk/pull/527:213,Testability,test,testng,213,Moving classes that tests depend on from the test folders into the src folders in the utils.test package. This way they will be available to projects that depend on hellbender. Fixes #525 . Updating to the newest testng release.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/527
https://github.com/broadinstitute/gatk/issues/528:42,Availability,mask,masks,42,"The current runTool method implementation masks exception occurring in either onStartup or doWork if there is a exception in onShutdown. It is more important to report the exception in onStartup or doWork that any occurring in onShutdown. . Apart from this, developers are supposed to make onShutdown robust to failure in onStartup?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/528
https://github.com/broadinstitute/gatk/issues/528:301,Availability,robust,robust,301,"The current runTool method implementation masks exception occurring in either onStartup or doWork if there is a exception in onShutdown. It is more important to report the exception in onStartup or doWork that any occurring in onShutdown. . Apart from this, developers are supposed to make onShutdown robust to failure in onStartup?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/528
https://github.com/broadinstitute/gatk/issues/528:311,Availability,failure,failure,311,"The current runTool method implementation masks exception occurring in either onStartup or doWork if there is a exception in onShutdown. It is more important to report the exception in onStartup or doWork that any occurring in onShutdown. . Apart from this, developers are supposed to make onShutdown robust to failure in onStartup?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/528
https://github.com/broadinstitute/gatk/pull/529:531,Deployability,release,released,531,"This version can compute on either locally, or on the cloud. There are a few things still on the table: it can't read dbSNP from GCS yet (no point in doing that since the skeleton team's working on the same thing) and it repatriates the recalTables even if the report is meant to be on the cloud (I expect many things to change, so better to do that once things are more stable. Besides, report on the cloud is an edge case, normally we want the textual report on the client's machine. This relies on dataflow-java 0.9; it has now released so we're good.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/529
https://github.com/broadinstitute/gatk/issues/530:80,Deployability,pipeline,pipelines,80,"For two reasons, ; 1. I guess that it belongs there until non exome CNV calling pipelines will make use of it.; 2. Would make it easier to share code between elements of the exome CNV pipeline.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/530
https://github.com/broadinstitute/gatk/issues/530:184,Deployability,pipeline,pipeline,184,"For two reasons, ; 1. I guess that it belongs there until non exome CNV calling pipelines will make use of it.; 2. Would make it easier to share code between elements of the exome CNV pipeline.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/530
https://github.com/broadinstitute/gatk/pull/531:166,Testability,test,tests,166,"These take several minutes currently, reducing the number of iterations by an order of magnitude speeds them up and shouldn't greatly impact the effectiveness of the tests.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/531
https://github.com/broadinstitute/gatk/pull/535:124,Availability,failure,failure,124,"This version introduces a change that (at least on my machine) fixes the mysterious ""happens only on the command line"" test failure. Also uses a newer version of genomics-dataflow because I had to fix a bug there for API_KEY to work in our setting. Finally, this version also moves the files around so they match the local tree, and changes the environment variables naming scheme to be a little more consistent.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/535
https://github.com/broadinstitute/gatk/pull/535:357,Modifiability,variab,variables,357,"This version introduces a change that (at least on my machine) fixes the mysterious ""happens only on the command line"" test failure. Also uses a newer version of genomics-dataflow because I had to fix a bug there for API_KEY to work in our setting. Finally, this version also moves the files around so they match the local tree, and changes the environment variables naming scheme to be a little more consistent.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/535
https://github.com/broadinstitute/gatk/pull/535:119,Testability,test,test,119,"This version introduces a change that (at least on my machine) fixes the mysterious ""happens only on the command line"" test failure. Also uses a newer version of genomics-dataflow because I had to fix a bug there for API_KEY to work in our setting. Finally, this version also moves the files around so they match the local tree, and changes the environment variables naming scheme to be a little more consistent.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/535
https://github.com/broadinstitute/gatk/issues/536:562,Availability,error,errors,562,"NVAR, or Number of genotyped VARiants. Description:. [minor/major allele] A minor (respectively major) allele is an allele present in less than (respectively, in at least) half the alleles from all the genotyped samples. Description:. [NMIN] NMIN is the number of variants of the given sample with a genotype that is not major/major. Influenced by:. Ethnicity (the distribution of NMIN is usually bimodal with Africans in one mode in the higher values). Remark:. Since this metric focuses of minor alleles, the proportion of rare variants considered (where more errors are expected) is higher. This makes NMIN more sensitive to errors than NALT, which is a desirable feature. Calculated by:. pseq i-stats (NMIN)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/536
https://github.com/broadinstitute/gatk/issues/536:628,Availability,error,errors,628,"NVAR, or Number of genotyped VARiants. Description:. [minor/major allele] A minor (respectively major) allele is an allele present in less than (respectively, in at least) half the alleles from all the genotyped samples. Description:. [NMIN] NMIN is the number of variants of the given sample with a genotype that is not major/major. Influenced by:. Ethnicity (the distribution of NMIN is usually bimodal with Africans in one mode in the higher values). Remark:. Since this metric focuses of minor alleles, the proportion of rare variants considered (where more errors are expected) is higher. This makes NMIN more sensitive to errors than NALT, which is a desirable feature. Calculated by:. pseq i-stats (NMIN)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/536
https://github.com/broadinstitute/gatk/issues/538:669,Availability,error,errors,669,"The Hardy-Weinberg equilibrium (HWE) theorem characterizes the distributions of genotype frequencies in populations that are not evolving. Let’s recall it in its simplest form. [Hardy-Weinberg] Let ( A ) and ( a ) be alleles at a single locus in a non-evolving population with random mating. Let ( p ) and ( q ) be their respective frequencies in that population. ( p ) and ( q ) will remain constant in average from generation to generation. The expected frequencies of the genotypes, ( AA ), ( Aa ) and ( aa ), will also remain constant and are respectively ( p^2 ), ( 2pq ), and (q^2 ). Description:. Use Wigginton’s exact test because it adequately controls type I errors in large and small samples. Calculated by:. Pedstats and vcftools use efficient implementations from Wigginton et al.; use code by Wigginton as your starting point (need to translate to java i think). Remark:. Deviations from HWE can indicate inbreeding, admixture, or population stratification. In order to avoid the latter, HWE tests should be run for each ethnicity/population separately. Typically a variant is filtered out if, for any of the ethnicities, the P-value is lower than (10^\textrm{-6}). HWE tests can also identify loci with systematic genotyping errors, which makes HWE useful for QC.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/538
https://github.com/broadinstitute/gatk/issues/538:1240,Availability,error,errors,1240,"The Hardy-Weinberg equilibrium (HWE) theorem characterizes the distributions of genotype frequencies in populations that are not evolving. Let’s recall it in its simplest form. [Hardy-Weinberg] Let ( A ) and ( a ) be alleles at a single locus in a non-evolving population with random mating. Let ( p ) and ( q ) be their respective frequencies in that population. ( p ) and ( q ) will remain constant in average from generation to generation. The expected frequencies of the genotypes, ( AA ), ( Aa ) and ( aa ), will also remain constant and are respectively ( p^2 ), ( 2pq ), and (q^2 ). Description:. Use Wigginton’s exact test because it adequately controls type I errors in large and small samples. Calculated by:. Pedstats and vcftools use efficient implementations from Wigginton et al.; use code by Wigginton as your starting point (need to translate to java i think). Remark:. Deviations from HWE can indicate inbreeding, admixture, or population stratification. In order to avoid the latter, HWE tests should be run for each ethnicity/population separately. Typically a variant is filtered out if, for any of the ethnicities, the P-value is lower than (10^\textrm{-6}). HWE tests can also identify loci with systematic genotyping errors, which makes HWE useful for QC.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/538
https://github.com/broadinstitute/gatk/issues/538:746,Energy Efficiency,efficient,efficient,746,"The Hardy-Weinberg equilibrium (HWE) theorem characterizes the distributions of genotype frequencies in populations that are not evolving. Let’s recall it in its simplest form. [Hardy-Weinberg] Let ( A ) and ( a ) be alleles at a single locus in a non-evolving population with random mating. Let ( p ) and ( q ) be their respective frequencies in that population. ( p ) and ( q ) will remain constant in average from generation to generation. The expected frequencies of the genotypes, ( AA ), ( Aa ) and ( aa ), will also remain constant and are respectively ( p^2 ), ( 2pq ), and (q^2 ). Description:. Use Wigginton’s exact test because it adequately controls type I errors in large and small samples. Calculated by:. Pedstats and vcftools use efficient implementations from Wigginton et al.; use code by Wigginton as your starting point (need to translate to java i think). Remark:. Deviations from HWE can indicate inbreeding, admixture, or population stratification. In order to avoid the latter, HWE tests should be run for each ethnicity/population separately. Typically a variant is filtered out if, for any of the ethnicities, the P-value is lower than (10^\textrm{-6}). HWE tests can also identify loci with systematic genotyping errors, which makes HWE useful for QC.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/538
https://github.com/broadinstitute/gatk/issues/538:984,Safety,avoid,avoid,984,"The Hardy-Weinberg equilibrium (HWE) theorem characterizes the distributions of genotype frequencies in populations that are not evolving. Let’s recall it in its simplest form. [Hardy-Weinberg] Let ( A ) and ( a ) be alleles at a single locus in a non-evolving population with random mating. Let ( p ) and ( q ) be their respective frequencies in that population. ( p ) and ( q ) will remain constant in average from generation to generation. The expected frequencies of the genotypes, ( AA ), ( Aa ) and ( aa ), will also remain constant and are respectively ( p^2 ), ( 2pq ), and (q^2 ). Description:. Use Wigginton’s exact test because it adequately controls type I errors in large and small samples. Calculated by:. Pedstats and vcftools use efficient implementations from Wigginton et al.; use code by Wigginton as your starting point (need to translate to java i think). Remark:. Deviations from HWE can indicate inbreeding, admixture, or population stratification. In order to avoid the latter, HWE tests should be run for each ethnicity/population separately. Typically a variant is filtered out if, for any of the ethnicities, the P-value is lower than (10^\textrm{-6}). HWE tests can also identify loci with systematic genotyping errors, which makes HWE useful for QC.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/538
https://github.com/broadinstitute/gatk/issues/538:626,Testability,test,test,626,"The Hardy-Weinberg equilibrium (HWE) theorem characterizes the distributions of genotype frequencies in populations that are not evolving. Let’s recall it in its simplest form. [Hardy-Weinberg] Let ( A ) and ( a ) be alleles at a single locus in a non-evolving population with random mating. Let ( p ) and ( q ) be their respective frequencies in that population. ( p ) and ( q ) will remain constant in average from generation to generation. The expected frequencies of the genotypes, ( AA ), ( Aa ) and ( aa ), will also remain constant and are respectively ( p^2 ), ( 2pq ), and (q^2 ). Description:. Use Wigginton’s exact test because it adequately controls type I errors in large and small samples. Calculated by:. Pedstats and vcftools use efficient implementations from Wigginton et al.; use code by Wigginton as your starting point (need to translate to java i think). Remark:. Deviations from HWE can indicate inbreeding, admixture, or population stratification. In order to avoid the latter, HWE tests should be run for each ethnicity/population separately. Typically a variant is filtered out if, for any of the ethnicities, the P-value is lower than (10^\textrm{-6}). HWE tests can also identify loci with systematic genotyping errors, which makes HWE useful for QC.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/538
https://github.com/broadinstitute/gatk/issues/538:1006,Testability,test,tests,1006,"The Hardy-Weinberg equilibrium (HWE) theorem characterizes the distributions of genotype frequencies in populations that are not evolving. Let’s recall it in its simplest form. [Hardy-Weinberg] Let ( A ) and ( a ) be alleles at a single locus in a non-evolving population with random mating. Let ( p ) and ( q ) be their respective frequencies in that population. ( p ) and ( q ) will remain constant in average from generation to generation. The expected frequencies of the genotypes, ( AA ), ( Aa ) and ( aa ), will also remain constant and are respectively ( p^2 ), ( 2pq ), and (q^2 ). Description:. Use Wigginton’s exact test because it adequately controls type I errors in large and small samples. Calculated by:. Pedstats and vcftools use efficient implementations from Wigginton et al.; use code by Wigginton as your starting point (need to translate to java i think). Remark:. Deviations from HWE can indicate inbreeding, admixture, or population stratification. In order to avoid the latter, HWE tests should be run for each ethnicity/population separately. Typically a variant is filtered out if, for any of the ethnicities, the P-value is lower than (10^\textrm{-6}). HWE tests can also identify loci with systematic genotyping errors, which makes HWE useful for QC.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/538
https://github.com/broadinstitute/gatk/issues/538:1184,Testability,test,tests,1184,"The Hardy-Weinberg equilibrium (HWE) theorem characterizes the distributions of genotype frequencies in populations that are not evolving. Let’s recall it in its simplest form. [Hardy-Weinberg] Let ( A ) and ( a ) be alleles at a single locus in a non-evolving population with random mating. Let ( p ) and ( q ) be their respective frequencies in that population. ( p ) and ( q ) will remain constant in average from generation to generation. The expected frequencies of the genotypes, ( AA ), ( Aa ) and ( aa ), will also remain constant and are respectively ( p^2 ), ( 2pq ), and (q^2 ). Description:. Use Wigginton’s exact test because it adequately controls type I errors in large and small samples. Calculated by:. Pedstats and vcftools use efficient implementations from Wigginton et al.; use code by Wigginton as your starting point (need to translate to java i think). Remark:. Deviations from HWE can indicate inbreeding, admixture, or population stratification. In order to avoid the latter, HWE tests should be run for each ethnicity/population separately. Typically a variant is filtered out if, for any of the ethnicities, the P-value is lower than (10^\textrm{-6}). HWE tests can also identify loci with systematic genotyping errors, which makes HWE useful for QC.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/538
https://github.com/broadinstitute/gatk/issues/538:162,Usability,simpl,simplest,162,"The Hardy-Weinberg equilibrium (HWE) theorem characterizes the distributions of genotype frequencies in populations that are not evolving. Let’s recall it in its simplest form. [Hardy-Weinberg] Let ( A ) and ( a ) be alleles at a single locus in a non-evolving population with random mating. Let ( p ) and ( q ) be their respective frequencies in that population. ( p ) and ( q ) will remain constant in average from generation to generation. The expected frequencies of the genotypes, ( AA ), ( Aa ) and ( aa ), will also remain constant and are respectively ( p^2 ), ( 2pq ), and (q^2 ). Description:. Use Wigginton’s exact test because it adequately controls type I errors in large and small samples. Calculated by:. Pedstats and vcftools use efficient implementations from Wigginton et al.; use code by Wigginton as your starting point (need to translate to java i think). Remark:. Deviations from HWE can indicate inbreeding, admixture, or population stratification. In order to avoid the latter, HWE tests should be run for each ethnicity/population separately. Typically a variant is filtered out if, for any of the ethnicities, the P-value is lower than (10^\textrm{-6}). HWE tests can also identify loci with systematic genotyping errors, which makes HWE useful for QC.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/538
https://github.com/broadinstitute/gatk/issues/539:251,Availability,failure,failures,251,"Description:. The proportion of samples that have missing data (and hence no genotype) for a given site. Influenced by:. Common structural variation, repetitive region, extreme GC content (hard to sequence), capture bias or general sample preparation failures. Remark:. This QC highlights issues with the region if many samples have missing data there. It is important to flag these sites. The GVCFs contain this information in the genotype fields. A sample with a no call (./.) or a sample with very low GQ is a sample whose data is missing. All other samples will have a genotype. Alternatively we could use a per-site PGEN metric defined as ( 1 - PMISS ). Typical threshold: The site is filtered out if PMISS is higher than (50\%).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/539
https://github.com/broadinstitute/gatk/issues/540:237,Performance,perform,perform,237,"implement a tool that computes median coverage (AD) per genotype: homRef/het/homVar (actually, compute it for all possible genotypes at the site). For good variants, the coverage should be independent of genotype so it's a good check to perform.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/540
https://github.com/broadinstitute/gatk/pull/541:263,Deployability,pipeline,pipeline,263,"mark duplicates in dataflow - based on the code by garrickevans . The main work is done in; `private static final class MarkDuplicatesDataflowTransform extends PTransform<PCollection<Read>, PCollection<Read>>` - the sigrature conforms to the main read processing pipeline. Limitations:; - no optical duplicates; - only integration tests (would be good to have unit tests that check dup detection logic on very specific reads - ideally those from picard's tests). @droazen please review",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/541
https://github.com/broadinstitute/gatk/pull/541:319,Deployability,integrat,integration,319,"mark duplicates in dataflow - based on the code by garrickevans . The main work is done in; `private static final class MarkDuplicatesDataflowTransform extends PTransform<PCollection<Read>, PCollection<Read>>` - the sigrature conforms to the main read processing pipeline. Limitations:; - no optical duplicates; - only integration tests (would be good to have unit tests that check dup detection logic on very specific reads - ideally those from picard's tests). @droazen please review",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/541
https://github.com/broadinstitute/gatk/pull/541:319,Integrability,integrat,integration,319,"mark duplicates in dataflow - based on the code by garrickevans . The main work is done in; `private static final class MarkDuplicatesDataflowTransform extends PTransform<PCollection<Read>, PCollection<Read>>` - the sigrature conforms to the main read processing pipeline. Limitations:; - no optical duplicates; - only integration tests (would be good to have unit tests that check dup detection logic on very specific reads - ideally those from picard's tests). @droazen please review",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/541
https://github.com/broadinstitute/gatk/pull/541:152,Modifiability,extend,extends,152,"mark duplicates in dataflow - based on the code by garrickevans . The main work is done in; `private static final class MarkDuplicatesDataflowTransform extends PTransform<PCollection<Read>, PCollection<Read>>` - the sigrature conforms to the main read processing pipeline. Limitations:; - no optical duplicates; - only integration tests (would be good to have unit tests that check dup detection logic on very specific reads - ideally those from picard's tests). @droazen please review",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/541
https://github.com/broadinstitute/gatk/pull/541:386,Safety,detect,detection,386,"mark duplicates in dataflow - based on the code by garrickevans . The main work is done in; `private static final class MarkDuplicatesDataflowTransform extends PTransform<PCollection<Read>, PCollection<Read>>` - the sigrature conforms to the main read processing pipeline. Limitations:; - no optical duplicates; - only integration tests (would be good to have unit tests that check dup detection logic on very specific reads - ideally those from picard's tests). @droazen please review",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/541
https://github.com/broadinstitute/gatk/pull/541:331,Testability,test,tests,331,"mark duplicates in dataflow - based on the code by garrickevans . The main work is done in; `private static final class MarkDuplicatesDataflowTransform extends PTransform<PCollection<Read>, PCollection<Read>>` - the sigrature conforms to the main read processing pipeline. Limitations:; - no optical duplicates; - only integration tests (would be good to have unit tests that check dup detection logic on very specific reads - ideally those from picard's tests). @droazen please review",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/541
https://github.com/broadinstitute/gatk/pull/541:365,Testability,test,tests,365,"mark duplicates in dataflow - based on the code by garrickevans . The main work is done in; `private static final class MarkDuplicatesDataflowTransform extends PTransform<PCollection<Read>, PCollection<Read>>` - the sigrature conforms to the main read processing pipeline. Limitations:; - no optical duplicates; - only integration tests (would be good to have unit tests that check dup detection logic on very specific reads - ideally those from picard's tests). @droazen please review",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/541
https://github.com/broadinstitute/gatk/pull/541:396,Testability,log,logic,396,"mark duplicates in dataflow - based on the code by garrickevans . The main work is done in; `private static final class MarkDuplicatesDataflowTransform extends PTransform<PCollection<Read>, PCollection<Read>>` - the sigrature conforms to the main read processing pipeline. Limitations:; - no optical duplicates; - only integration tests (would be good to have unit tests that check dup detection logic on very specific reads - ideally those from picard's tests). @droazen please review",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/541
https://github.com/broadinstitute/gatk/pull/541:455,Testability,test,tests,455,"mark duplicates in dataflow - based on the code by garrickevans . The main work is done in; `private static final class MarkDuplicatesDataflowTransform extends PTransform<PCollection<Read>, PCollection<Read>>` - the sigrature conforms to the main read processing pipeline. Limitations:; - no optical duplicates; - only integration tests (would be good to have unit tests that check dup detection logic on very specific reads - ideally those from picard's tests). @droazen please review",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/541
https://github.com/broadinstitute/gatk/pull/544:45,Deployability,install,installation,45,travis got their act together and enabled at installation of the base R packages in their container build; this removes all uses of sudo so we can make use of the container builds which have faster dispatch,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/544
https://github.com/broadinstitute/gatk/pull/545:36,Testability,test,tests,36,PCollection<Read> -> BAM file. With tests.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/545
https://github.com/broadinstitute/gatk/pull/546:109,Testability,test,test,109,Set the system property 'dataflowRunner' to the simple classname of the; runner you wish to use. E.g. gradle test -Dtest.single=CountBasesDataflowUnitTest -DdataflowRunner=SparkPipelineRunner,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/546
https://github.com/broadinstitute/gatk/pull/546:48,Usability,simpl,simple,48,Set the system property 'dataflowRunner' to the simple classname of the; runner you wish to use. E.g. gradle test -Dtest.single=CountBasesDataflowUnitTest -DdataflowRunner=SparkPipelineRunner,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/546
https://github.com/broadinstitute/gatk/pull/547:60,Availability,down,download,60,"travis is now using the gradlew wrapper, which handles this download for us",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/547
https://github.com/broadinstitute/gatk/pull/547:32,Integrability,wrap,wrapper,32,"travis is now using the gradlew wrapper, which handles this download for us",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/547
https://github.com/broadinstitute/gatk/issues/551:169,Availability,failure,failure,169,"We should run all of our dataflow tests on spark local runner as well as the dataflow direct pipeline runner. The plan is to run these as ""optional"" tests so that spark failure doesn't block our builds but we will be aware of any differences between the spark and google implementations.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/551
https://github.com/broadinstitute/gatk/issues/551:93,Deployability,pipeline,pipeline,93,"We should run all of our dataflow tests on spark local runner as well as the dataflow direct pipeline runner. The plan is to run these as ""optional"" tests so that spark failure doesn't block our builds but we will be aware of any differences between the spark and google implementations.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/551
https://github.com/broadinstitute/gatk/issues/551:34,Testability,test,tests,34,"We should run all of our dataflow tests on spark local runner as well as the dataflow direct pipeline runner. The plan is to run these as ""optional"" tests so that spark failure doesn't block our builds but we will be aware of any differences between the spark and google implementations.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/551
https://github.com/broadinstitute/gatk/issues/551:149,Testability,test,tests,149,"We should run all of our dataflow tests on spark local runner as well as the dataflow direct pipeline runner. The plan is to run these as ""optional"" tests so that spark failure doesn't block our builds but we will be aware of any differences between the spark and google implementations.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/551
https://github.com/broadinstitute/gatk/issues/552:48,Testability,test,tests,48,"These should be run in parallel to our existing tests since they're very slow at the moment. We need to provide a private key for these, so they will not succeed on external pull requests. On external pull requests someone will have to manually sign off on these.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/552
https://github.com/broadinstitute/gatk/pull/553:236,Safety,avoid,avoid,236,"This is achieved by i) using HadoopBAM to read BAM files from HDFS, and; ii) adding a shadowJar target to build app JAR suitable for running with Spark. Note that this uses Spark's spark-submit script to run on the cluster - this is to avoid including the Spark classes in the hellbender JAR itself, so that it can run on different versions of Spark. We might consider making a runnable JAR at some point in the future though. I tested this on a standalone cluster (running with Java 8) as follows:. ``` bash; export SPARK_HOME=~/sw/spark-1.3.1-bin-hadoop2.6/ ; PATH=$PATH:$SPARK_HOME/bin ; $SPARK_HOME/sbin/start-all.sh. export HADOOP_HOME=~/sw/hadoop-2.7.0; export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop.pseudo/; export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin; (cd $HADOOP_HOME; start-hdfs2); hadoop fs -mkdir -p /user/$USER ; hadoop fs -put ~/workspace/hellbender/src/test/resources/org/broadinstitute/hellbender/tools/flag_stat.bam flag_stat.bam; hadoop fs -rmr out. SPARK_MASTER=spark://localhost:7077; spark-submit \; --class org.broadinstitute.hellbender.Main \; --master $SPARK_MASTER \; build/libs/hellbender-GATK.4.alpha-*-all.jar CountBasesDataflow \; --input hdfs://localhost/user/$USER/flag_stat.bam \; --output hdfs://localhost/user/$USER/out/countbases \; --runner SPARK \; --sparkMaster $SPARK_MASTER; hadoop fs -getmerge out out; cat out; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/553
https://github.com/broadinstitute/gatk/pull/553:429,Testability,test,tested,429,"This is achieved by i) using HadoopBAM to read BAM files from HDFS, and; ii) adding a shadowJar target to build app JAR suitable for running with Spark. Note that this uses Spark's spark-submit script to run on the cluster - this is to avoid including the Spark classes in the hellbender JAR itself, so that it can run on different versions of Spark. We might consider making a runnable JAR at some point in the future though. I tested this on a standalone cluster (running with Java 8) as follows:. ``` bash; export SPARK_HOME=~/sw/spark-1.3.1-bin-hadoop2.6/ ; PATH=$PATH:$SPARK_HOME/bin ; $SPARK_HOME/sbin/start-all.sh. export HADOOP_HOME=~/sw/hadoop-2.7.0; export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop.pseudo/; export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin; (cd $HADOOP_HOME; start-hdfs2); hadoop fs -mkdir -p /user/$USER ; hadoop fs -put ~/workspace/hellbender/src/test/resources/org/broadinstitute/hellbender/tools/flag_stat.bam flag_stat.bam; hadoop fs -rmr out. SPARK_MASTER=spark://localhost:7077; spark-submit \; --class org.broadinstitute.hellbender.Main \; --master $SPARK_MASTER \; build/libs/hellbender-GATK.4.alpha-*-all.jar CountBasesDataflow \; --input hdfs://localhost/user/$USER/flag_stat.bam \; --output hdfs://localhost/user/$USER/out/countbases \; --runner SPARK \; --sparkMaster $SPARK_MASTER; hadoop fs -getmerge out out; cat out; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/553
https://github.com/broadinstitute/gatk/pull/553:878,Testability,test,test,878,"This is achieved by i) using HadoopBAM to read BAM files from HDFS, and; ii) adding a shadowJar target to build app JAR suitable for running with Spark. Note that this uses Spark's spark-submit script to run on the cluster - this is to avoid including the Spark classes in the hellbender JAR itself, so that it can run on different versions of Spark. We might consider making a runnable JAR at some point in the future though. I tested this on a standalone cluster (running with Java 8) as follows:. ``` bash; export SPARK_HOME=~/sw/spark-1.3.1-bin-hadoop2.6/ ; PATH=$PATH:$SPARK_HOME/bin ; $SPARK_HOME/sbin/start-all.sh. export HADOOP_HOME=~/sw/hadoop-2.7.0; export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop.pseudo/; export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin; (cd $HADOOP_HOME; start-hdfs2); hadoop fs -mkdir -p /user/$USER ; hadoop fs -put ~/workspace/hellbender/src/test/resources/org/broadinstitute/hellbender/tools/flag_stat.bam flag_stat.bam; hadoop fs -rmr out. SPARK_MASTER=spark://localhost:7077; spark-submit \; --class org.broadinstitute.hellbender.Main \; --master $SPARK_MASTER \; build/libs/hellbender-GATK.4.alpha-*-all.jar CountBasesDataflow \; --input hdfs://localhost/user/$USER/flag_stat.bam \; --output hdfs://localhost/user/$USER/out/countbases \; --runner SPARK \; --sparkMaster $SPARK_MASTER; hadoop fs -getmerge out out; cat out; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/553
https://github.com/broadinstitute/gatk/pull/555:0,Testability,test,test,0,test and fix for issue #554,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/555
https://github.com/broadinstitute/gatk/pull/556:117,Testability,test,tested,117,"The second phase of BQSR (for Dataflow). Note that even though in principle this should work on the cloud, I haven't tested that yet (those tests and any matching fixes will be a later PR). There's also a bit of work left to do to link the two phases. I created new test inputs and corresponding ""known-good"" outputs. The new test inputs omit reads that were rejected by the converter; I generated the new outputs by running the existing ApplyBQSR on them.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/556
https://github.com/broadinstitute/gatk/pull/556:140,Testability,test,tests,140,"The second phase of BQSR (for Dataflow). Note that even though in principle this should work on the cloud, I haven't tested that yet (those tests and any matching fixes will be a later PR). There's also a bit of work left to do to link the two phases. I created new test inputs and corresponding ""known-good"" outputs. The new test inputs omit reads that were rejected by the converter; I generated the new outputs by running the existing ApplyBQSR on them.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/556
https://github.com/broadinstitute/gatk/pull/556:266,Testability,test,test,266,"The second phase of BQSR (for Dataflow). Note that even though in principle this should work on the cloud, I haven't tested that yet (those tests and any matching fixes will be a later PR). There's also a bit of work left to do to link the two phases. I created new test inputs and corresponding ""known-good"" outputs. The new test inputs omit reads that were rejected by the converter; I generated the new outputs by running the existing ApplyBQSR on them.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/556
https://github.com/broadinstitute/gatk/pull/556:326,Testability,test,test,326,"The second phase of BQSR (for Dataflow). Note that even though in principle this should work on the cloud, I haven't tested that yet (those tests and any matching fixes will be a later PR). There's also a bit of work left to do to link the two phases. I created new test inputs and corresponding ""known-good"" outputs. The new test inputs omit reads that were rejected by the converter; I generated the new outputs by running the existing ApplyBQSR on them.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/556
https://github.com/broadinstitute/gatk/issues/557:41,Deployability,update,update,41,There's some bad input in the BQSR test; update the input validation test to make sure it can find reads that are malformed in that way.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/557
https://github.com/broadinstitute/gatk/issues/557:58,Security,validat,validation,58,There's some bad input in the BQSR test; update the input validation test to make sure it can find reads that are malformed in that way.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/557
https://github.com/broadinstitute/gatk/issues/557:35,Testability,test,test,35,There's some bad input in the BQSR test; update the input validation test to make sure it can find reads that are malformed in that way.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/557
https://github.com/broadinstitute/gatk/issues/557:69,Testability,test,test,69,There's some bad input in the BQSR test; update the input validation test to make sure it can find reads that are malformed in that way.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/557
https://github.com/broadinstitute/gatk/issues/558:9,Testability,test,tests,9,dataflow tests should use SmallBamWriter and compare the resulting bam files rather than outputting a text file with reads encoded as json,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/558
https://github.com/broadinstitute/gatk/issues/559:19,Energy Efficiency,adapt,adapt,19,"We should probably adapt the IntervalTree from htsjdk to work for us. We've run into a number of cases where this is needed, in Valentine's exome code and in Tom's hadoop reader. We could use both. `boolean overlaps(Locatable locatable, IntervalTree<Locatable> locatables)`. and . `Set<Locatable> getOverlapping(Locatable locatable, IntervalTree<Locatable> locatables)`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/559
https://github.com/broadinstitute/gatk/issues/559:19,Modifiability,adapt,adapt,19,"We should probably adapt the IntervalTree from htsjdk to work for us. We've run into a number of cases where this is needed, in Valentine's exome code and in Tom's hadoop reader. We could use both. `boolean overlaps(Locatable locatable, IntervalTree<Locatable> locatables)`. and . `Set<Locatable> getOverlapping(Locatable locatable, IntervalTree<Locatable> locatables)`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/559
https://github.com/broadinstitute/gatk/issues/561:71,Integrability,depend,depend,71,"This could either be implemented by making the default dataflow runner depend on a system property, and not specifying any runner in the tests, or by having tests authors explicitly specify a new `TestLocal` or `TestRemote` runner for their tests as appropriate.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/561
https://github.com/broadinstitute/gatk/issues/561:137,Testability,test,tests,137,"This could either be implemented by making the default dataflow runner depend on a system property, and not specifying any runner in the tests, or by having tests authors explicitly specify a new `TestLocal` or `TestRemote` runner for their tests as appropriate.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/561
https://github.com/broadinstitute/gatk/issues/561:157,Testability,test,tests,157,"This could either be implemented by making the default dataflow runner depend on a system property, and not specifying any runner in the tests, or by having tests authors explicitly specify a new `TestLocal` or `TestRemote` runner for their tests as appropriate.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/561
https://github.com/broadinstitute/gatk/issues/561:197,Testability,Test,TestLocal,197,"This could either be implemented by making the default dataflow runner depend on a system property, and not specifying any runner in the tests, or by having tests authors explicitly specify a new `TestLocal` or `TestRemote` runner for their tests as appropriate.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/561
https://github.com/broadinstitute/gatk/issues/561:212,Testability,Test,TestRemote,212,"This could either be implemented by making the default dataflow runner depend on a system property, and not specifying any runner in the tests, or by having tests authors explicitly specify a new `TestLocal` or `TestRemote` runner for their tests as appropriate.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/561
https://github.com/broadinstitute/gatk/issues/561:241,Testability,test,tests,241,"This could either be implemented by making the default dataflow runner depend on a system property, and not specifying any runner in the tests, or by having tests authors explicitly specify a new `TestLocal` or `TestRemote` runner for their tests as appropriate.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/561
https://github.com/broadinstitute/gatk/pull/563:171,Safety,avoid,avoid,171,if doWork or onStartup in CommandLineProgram throw an exception then suppress any exception throw in onShutdown; fixes #528 . I still think every effort should be made to avoid an exception in onShutdown though.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/563
https://github.com/broadinstitute/gatk/pull/564:19,Testability,Test,TestPipeline,19,a few instances of TestPipeline were being used instead of GATKTestPipeline still,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/564
https://github.com/broadinstitute/gatk/pull/565:179,Integrability,protocol,protocol,179,"Based on the TODO that was in ReadsDataSource.java, I exposed a SamReaderFactory parameter for ReadsDataSource rather than limit it to just validation stringency. Whats the right protocol for adding a test that uses a test file from another package (I'm reaching into the picard test data for a data file for an engine test). Alternatively, is there a better way to test this change ?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/565
https://github.com/broadinstitute/gatk/pull/565:54,Security,expose,exposed,54,"Based on the TODO that was in ReadsDataSource.java, I exposed a SamReaderFactory parameter for ReadsDataSource rather than limit it to just validation stringency. Whats the right protocol for adding a test that uses a test file from another package (I'm reaching into the picard test data for a data file for an engine test). Alternatively, is there a better way to test this change ?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/565
https://github.com/broadinstitute/gatk/pull/565:140,Security,validat,validation,140,"Based on the TODO that was in ReadsDataSource.java, I exposed a SamReaderFactory parameter for ReadsDataSource rather than limit it to just validation stringency. Whats the right protocol for adding a test that uses a test file from another package (I'm reaching into the picard test data for a data file for an engine test). Alternatively, is there a better way to test this change ?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/565
https://github.com/broadinstitute/gatk/pull/565:201,Testability,test,test,201,"Based on the TODO that was in ReadsDataSource.java, I exposed a SamReaderFactory parameter for ReadsDataSource rather than limit it to just validation stringency. Whats the right protocol for adding a test that uses a test file from another package (I'm reaching into the picard test data for a data file for an engine test). Alternatively, is there a better way to test this change ?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/565
https://github.com/broadinstitute/gatk/pull/565:218,Testability,test,test,218,"Based on the TODO that was in ReadsDataSource.java, I exposed a SamReaderFactory parameter for ReadsDataSource rather than limit it to just validation stringency. Whats the right protocol for adding a test that uses a test file from another package (I'm reaching into the picard test data for a data file for an engine test). Alternatively, is there a better way to test this change ?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/565
https://github.com/broadinstitute/gatk/pull/565:279,Testability,test,test,279,"Based on the TODO that was in ReadsDataSource.java, I exposed a SamReaderFactory parameter for ReadsDataSource rather than limit it to just validation stringency. Whats the right protocol for adding a test that uses a test file from another package (I'm reaching into the picard test data for a data file for an engine test). Alternatively, is there a better way to test this change ?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/565
https://github.com/broadinstitute/gatk/pull/565:319,Testability,test,test,319,"Based on the TODO that was in ReadsDataSource.java, I exposed a SamReaderFactory parameter for ReadsDataSource rather than limit it to just validation stringency. Whats the right protocol for adding a test that uses a test file from another package (I'm reaching into the picard test data for a data file for an engine test). Alternatively, is there a better way to test this change ?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/565
https://github.com/broadinstitute/gatk/pull/565:366,Testability,test,test,366,"Based on the TODO that was in ReadsDataSource.java, I exposed a SamReaderFactory parameter for ReadsDataSource rather than limit it to just validation stringency. Whats the right protocol for adding a test that uses a test file from another package (I'm reaching into the picard test data for a data file for an engine test). Alternatively, is there a better way to test this change ?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/565
https://github.com/broadinstitute/gatk/issues/568:87,Availability,error,error,87,"This test input is malformed. When I try to read it with the Dataflow code, I get this error:. htsjdk.samtools.SAMFormatException: SAM validation error: ERROR: Record 129, Read name 809R9ABXX101220:5:6:17918:145992, Mate Alignment start should be 0 because reference name = *. Here's the corresponding read:. 809R9ABXX101220:5:6:17918:145992 97 17 69400 37 67M9S \* 71202348 0 ACTCCCCACCTTACCTGACTCCTTCCAGGGTTTGTCGCCTTTCCGGTCCCTGACCCCAGTGGATGGGAGTCTGTCC ?ABDDEEABEECBDBDAB=DEDCDEEBFADABCEAD?EEEDCFE?ABEEE@FCDEEEBF@F?C<E@########## MD:Z:67 PG:Z:BWA RG:Z:809R9.5 AM:i:0 NM:i:0 SM:i:37 MQ:i:0 OQ:Z:DGEGGGGBFGGGGGDF8@@FGFBGGGBGCECCEEDFGGGFGFGGGBDGGF9DBFFGFBF;@>A4@@########## UQ:i:0. @droazen confirms that Picard's ValidateSAMFile utility reports that this bam has multiple errors. We should replace it with a clean input, and update the ""known good"" output accordingly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/568
https://github.com/broadinstitute/gatk/issues/568:146,Availability,error,error,146,"This test input is malformed. When I try to read it with the Dataflow code, I get this error:. htsjdk.samtools.SAMFormatException: SAM validation error: ERROR: Record 129, Read name 809R9ABXX101220:5:6:17918:145992, Mate Alignment start should be 0 because reference name = *. Here's the corresponding read:. 809R9ABXX101220:5:6:17918:145992 97 17 69400 37 67M9S \* 71202348 0 ACTCCCCACCTTACCTGACTCCTTCCAGGGTTTGTCGCCTTTCCGGTCCCTGACCCCAGTGGATGGGAGTCTGTCC ?ABDDEEABEECBDBDAB=DEDCDEEBFADABCEAD?EEEDCFE?ABEEE@FCDEEEBF@F?C<E@########## MD:Z:67 PG:Z:BWA RG:Z:809R9.5 AM:i:0 NM:i:0 SM:i:37 MQ:i:0 OQ:Z:DGEGGGGBFGGGGGDF8@@FGFBGGGBGCECCEEDFGGGFGFGGGBDGGF9DBFFGFBF;@>A4@@########## UQ:i:0. @droazen confirms that Picard's ValidateSAMFile utility reports that this bam has multiple errors. We should replace it with a clean input, and update the ""known good"" output accordingly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/568
https://github.com/broadinstitute/gatk/issues/568:153,Availability,ERROR,ERROR,153,"This test input is malformed. When I try to read it with the Dataflow code, I get this error:. htsjdk.samtools.SAMFormatException: SAM validation error: ERROR: Record 129, Read name 809R9ABXX101220:5:6:17918:145992, Mate Alignment start should be 0 because reference name = *. Here's the corresponding read:. 809R9ABXX101220:5:6:17918:145992 97 17 69400 37 67M9S \* 71202348 0 ACTCCCCACCTTACCTGACTCCTTCCAGGGTTTGTCGCCTTTCCGGTCCCTGACCCCAGTGGATGGGAGTCTGTCC ?ABDDEEABEECBDBDAB=DEDCDEEBFADABCEAD?EEEDCFE?ABEEE@FCDEEEBF@F?C<E@########## MD:Z:67 PG:Z:BWA RG:Z:809R9.5 AM:i:0 NM:i:0 SM:i:37 MQ:i:0 OQ:Z:DGEGGGGBFGGGGGDF8@@FGFBGGGBGCECCEEDFGGGFGFGGGBDGGF9DBFFGFBF;@>A4@@########## UQ:i:0. @droazen confirms that Picard's ValidateSAMFile utility reports that this bam has multiple errors. We should replace it with a clean input, and update the ""known good"" output accordingly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/568
https://github.com/broadinstitute/gatk/issues/568:771,Availability,error,errors,771,"This test input is malformed. When I try to read it with the Dataflow code, I get this error:. htsjdk.samtools.SAMFormatException: SAM validation error: ERROR: Record 129, Read name 809R9ABXX101220:5:6:17918:145992, Mate Alignment start should be 0 because reference name = *. Here's the corresponding read:. 809R9ABXX101220:5:6:17918:145992 97 17 69400 37 67M9S \* 71202348 0 ACTCCCCACCTTACCTGACTCCTTCCAGGGTTTGTCGCCTTTCCGGTCCCTGACCCCAGTGGATGGGAGTCTGTCC ?ABDDEEABEECBDBDAB=DEDCDEEBFADABCEAD?EEEDCFE?ABEEE@FCDEEEBF@F?C<E@########## MD:Z:67 PG:Z:BWA RG:Z:809R9.5 AM:i:0 NM:i:0 SM:i:37 MQ:i:0 OQ:Z:DGEGGGGBFGGGGGDF8@@FGFBGGGBGCECCEEDFGGGFGFGGGBDGGF9DBFFGFBF;@>A4@@########## UQ:i:0. @droazen confirms that Picard's ValidateSAMFile utility reports that this bam has multiple errors. We should replace it with a clean input, and update the ""known good"" output accordingly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/568
https://github.com/broadinstitute/gatk/issues/568:824,Deployability,update,update,824,"This test input is malformed. When I try to read it with the Dataflow code, I get this error:. htsjdk.samtools.SAMFormatException: SAM validation error: ERROR: Record 129, Read name 809R9ABXX101220:5:6:17918:145992, Mate Alignment start should be 0 because reference name = *. Here's the corresponding read:. 809R9ABXX101220:5:6:17918:145992 97 17 69400 37 67M9S \* 71202348 0 ACTCCCCACCTTACCTGACTCCTTCCAGGGTTTGTCGCCTTTCCGGTCCCTGACCCCAGTGGATGGGAGTCTGTCC ?ABDDEEABEECBDBDAB=DEDCDEEBFADABCEAD?EEEDCFE?ABEEE@FCDEEEBF@F?C<E@########## MD:Z:67 PG:Z:BWA RG:Z:809R9.5 AM:i:0 NM:i:0 SM:i:37 MQ:i:0 OQ:Z:DGEGGGGBFGGGGGDF8@@FGFBGGGBGCECCEEDFGGGFGFGGGBDGGF9DBFFGFBF;@>A4@@########## UQ:i:0. @droazen confirms that Picard's ValidateSAMFile utility reports that this bam has multiple errors. We should replace it with a clean input, and update the ""known good"" output accordingly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/568
https://github.com/broadinstitute/gatk/issues/568:135,Security,validat,validation,135,"This test input is malformed. When I try to read it with the Dataflow code, I get this error:. htsjdk.samtools.SAMFormatException: SAM validation error: ERROR: Record 129, Read name 809R9ABXX101220:5:6:17918:145992, Mate Alignment start should be 0 because reference name = *. Here's the corresponding read:. 809R9ABXX101220:5:6:17918:145992 97 17 69400 37 67M9S \* 71202348 0 ACTCCCCACCTTACCTGACTCCTTCCAGGGTTTGTCGCCTTTCCGGTCCCTGACCCCAGTGGATGGGAGTCTGTCC ?ABDDEEABEECBDBDAB=DEDCDEEBFADABCEAD?EEEDCFE?ABEEE@FCDEEEBF@F?C<E@########## MD:Z:67 PG:Z:BWA RG:Z:809R9.5 AM:i:0 NM:i:0 SM:i:37 MQ:i:0 OQ:Z:DGEGGGGBFGGGGGDF8@@FGFBGGGBGCECCEEDFGGGFGFGGGBDGGF9DBFFGFBF;@>A4@@########## UQ:i:0. @droazen confirms that Picard's ValidateSAMFile utility reports that this bam has multiple errors. We should replace it with a clean input, and update the ""known good"" output accordingly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/568
https://github.com/broadinstitute/gatk/issues/568:712,Security,Validat,ValidateSAMFile,712,"This test input is malformed. When I try to read it with the Dataflow code, I get this error:. htsjdk.samtools.SAMFormatException: SAM validation error: ERROR: Record 129, Read name 809R9ABXX101220:5:6:17918:145992, Mate Alignment start should be 0 because reference name = *. Here's the corresponding read:. 809R9ABXX101220:5:6:17918:145992 97 17 69400 37 67M9S \* 71202348 0 ACTCCCCACCTTACCTGACTCCTTCCAGGGTTTGTCGCCTTTCCGGTCCCTGACCCCAGTGGATGGGAGTCTGTCC ?ABDDEEABEECBDBDAB=DEDCDEEBFADABCEAD?EEEDCFE?ABEEE@FCDEEEBF@F?C<E@########## MD:Z:67 PG:Z:BWA RG:Z:809R9.5 AM:i:0 NM:i:0 SM:i:37 MQ:i:0 OQ:Z:DGEGGGGBFGGGGGDF8@@FGFBGGGBGCECCEEDFGGGFGFGGGBDGGF9DBFFGFBF;@>A4@@########## UQ:i:0. @droazen confirms that Picard's ValidateSAMFile utility reports that this bam has multiple errors. We should replace it with a clean input, and update the ""known good"" output accordingly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/568
https://github.com/broadinstitute/gatk/issues/568:5,Testability,test,test,5,"This test input is malformed. When I try to read it with the Dataflow code, I get this error:. htsjdk.samtools.SAMFormatException: SAM validation error: ERROR: Record 129, Read name 809R9ABXX101220:5:6:17918:145992, Mate Alignment start should be 0 because reference name = *. Here's the corresponding read:. 809R9ABXX101220:5:6:17918:145992 97 17 69400 37 67M9S \* 71202348 0 ACTCCCCACCTTACCTGACTCCTTCCAGGGTTTGTCGCCTTTCCGGTCCCTGACCCCAGTGGATGGGAGTCTGTCC ?ABDDEEABEECBDBDAB=DEDCDEEBFADABCEAD?EEEDCFE?ABEEE@FCDEEEBF@F?C<E@########## MD:Z:67 PG:Z:BWA RG:Z:809R9.5 AM:i:0 NM:i:0 SM:i:37 MQ:i:0 OQ:Z:DGEGGGGBFGGGGGDF8@@FGFBGGGBGCECCEEDFGGGFGFGGGBDGGF9DBFFGFBF;@>A4@@########## UQ:i:0. @droazen confirms that Picard's ValidateSAMFile utility reports that this bam has multiple errors. We should replace it with a clean input, and update the ""known good"" output accordingly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/568
https://github.com/broadinstitute/gatk/issues/569:508,Availability,error,error,508,"We've discovered a number of bam files being used in tests which are not valid BAM files. We should go through all the checked in BAMs, validate them, and replace broken ones. (Except ones that are intentionally broken for testing.) . (added later by @akiezun); In particular, copied from https://github.com/broadinstitute/hellbender/issues/568, NA12878.chr17_69k_70k.dictFix.bam has a problem:; whoever fixes this ticket needs to take care of this input. `htsjdk.samtools.SAMFormatException: SAM validation error: ERROR: Record 129, Read name 809R9ABXX101220:5:6:17918:145992, Mate Alignment start should be 0 because reference name = *.`. Here's the corresponding read:; `809R9ABXX101220:5:6:17918:145992 97 17 69400 37 67M9S * 71202348 0 ACTCCCCACCTTACCTGACTCCTTCCAGGGTTTGTCGCCTTTCCGGTCCCTGACCCCAGTGGATGGGAGTCTGTCC ?ABDDEEABEECBDBDAB=DEDCDEEBFADABCEAD?EEEDCFE?ABEEE@FCDEEEBF@F?CA4@@########## UQ:i:0`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/569
https://github.com/broadinstitute/gatk/issues/569:515,Availability,ERROR,ERROR,515,"We've discovered a number of bam files being used in tests which are not valid BAM files. We should go through all the checked in BAMs, validate them, and replace broken ones. (Except ones that are intentionally broken for testing.) . (added later by @akiezun); In particular, copied from https://github.com/broadinstitute/hellbender/issues/568, NA12878.chr17_69k_70k.dictFix.bam has a problem:; whoever fixes this ticket needs to take care of this input. `htsjdk.samtools.SAMFormatException: SAM validation error: ERROR: Record 129, Read name 809R9ABXX101220:5:6:17918:145992, Mate Alignment start should be 0 because reference name = *.`. Here's the corresponding read:; `809R9ABXX101220:5:6:17918:145992 97 17 69400 37 67M9S * 71202348 0 ACTCCCCACCTTACCTGACTCCTTCCAGGGTTTGTCGCCTTTCCGGTCCCTGACCCCAGTGGATGGGAGTCTGTCC ?ABDDEEABEECBDBDAB=DEDCDEEBFADABCEAD?EEEDCFE?ABEEE@FCDEEEBF@F?CA4@@########## UQ:i:0`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/569
https://github.com/broadinstitute/gatk/issues/569:136,Security,validat,validate,136,"We've discovered a number of bam files being used in tests which are not valid BAM files. We should go through all the checked in BAMs, validate them, and replace broken ones. (Except ones that are intentionally broken for testing.) . (added later by @akiezun); In particular, copied from https://github.com/broadinstitute/hellbender/issues/568, NA12878.chr17_69k_70k.dictFix.bam has a problem:; whoever fixes this ticket needs to take care of this input. `htsjdk.samtools.SAMFormatException: SAM validation error: ERROR: Record 129, Read name 809R9ABXX101220:5:6:17918:145992, Mate Alignment start should be 0 because reference name = *.`. Here's the corresponding read:; `809R9ABXX101220:5:6:17918:145992 97 17 69400 37 67M9S * 71202348 0 ACTCCCCACCTTACCTGACTCCTTCCAGGGTTTGTCGCCTTTCCGGTCCCTGACCCCAGTGGATGGGAGTCTGTCC ?ABDDEEABEECBDBDAB=DEDCDEEBFADABCEAD?EEEDCFE?ABEEE@FCDEEEBF@F?CA4@@########## UQ:i:0`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/569
https://github.com/broadinstitute/gatk/issues/569:497,Security,validat,validation,497,"We've discovered a number of bam files being used in tests which are not valid BAM files. We should go through all the checked in BAMs, validate them, and replace broken ones. (Except ones that are intentionally broken for testing.) . (added later by @akiezun); In particular, copied from https://github.com/broadinstitute/hellbender/issues/568, NA12878.chr17_69k_70k.dictFix.bam has a problem:; whoever fixes this ticket needs to take care of this input. `htsjdk.samtools.SAMFormatException: SAM validation error: ERROR: Record 129, Read name 809R9ABXX101220:5:6:17918:145992, Mate Alignment start should be 0 because reference name = *.`. Here's the corresponding read:; `809R9ABXX101220:5:6:17918:145992 97 17 69400 37 67M9S * 71202348 0 ACTCCCCACCTTACCTGACTCCTTCCAGGGTTTGTCGCCTTTCCGGTCCCTGACCCCAGTGGATGGGAGTCTGTCC ?ABDDEEABEECBDBDAB=DEDCDEEBFADABCEAD?EEEDCFE?ABEEE@FCDEEEBF@F?CA4@@########## UQ:i:0`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/569
https://github.com/broadinstitute/gatk/issues/569:53,Testability,test,tests,53,"We've discovered a number of bam files being used in tests which are not valid BAM files. We should go through all the checked in BAMs, validate them, and replace broken ones. (Except ones that are intentionally broken for testing.) . (added later by @akiezun); In particular, copied from https://github.com/broadinstitute/hellbender/issues/568, NA12878.chr17_69k_70k.dictFix.bam has a problem:; whoever fixes this ticket needs to take care of this input. `htsjdk.samtools.SAMFormatException: SAM validation error: ERROR: Record 129, Read name 809R9ABXX101220:5:6:17918:145992, Mate Alignment start should be 0 because reference name = *.`. Here's the corresponding read:; `809R9ABXX101220:5:6:17918:145992 97 17 69400 37 67M9S * 71202348 0 ACTCCCCACCTTACCTGACTCCTTCCAGGGTTTGTCGCCTTTCCGGTCCCTGACCCCAGTGGATGGGAGTCTGTCC ?ABDDEEABEECBDBDAB=DEDCDEEBFADABCEAD?EEEDCFE?ABEEE@FCDEEEBF@F?CA4@@########## UQ:i:0`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/569
https://github.com/broadinstitute/gatk/issues/569:223,Testability,test,testing,223,"We've discovered a number of bam files being used in tests which are not valid BAM files. We should go through all the checked in BAMs, validate them, and replace broken ones. (Except ones that are intentionally broken for testing.) . (added later by @akiezun); In particular, copied from https://github.com/broadinstitute/hellbender/issues/568, NA12878.chr17_69k_70k.dictFix.bam has a problem:; whoever fixes this ticket needs to take care of this input. `htsjdk.samtools.SAMFormatException: SAM validation error: ERROR: Record 129, Read name 809R9ABXX101220:5:6:17918:145992, Mate Alignment start should be 0 because reference name = *.`. Here's the corresponding read:; `809R9ABXX101220:5:6:17918:145992 97 17 69400 37 67M9S * 71202348 0 ACTCCCCACCTTACCTGACTCCTTCCAGGGTTTGTCGCCTTTCCGGTCCCTGACCCCAGTGGATGGGAGTCTGTCC ?ABDDEEABEECBDBDAB=DEDCDEEBFADABCEAD?EEEDCFE?ABEEE@FCDEEEBF@F?CA4@@########## UQ:i:0`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/569
https://github.com/broadinstitute/gatk/issues/571:22,Modifiability,variab,variable,22,"A missing environment variable reports as `DATAFLOW_TEST_PROJECT`, the actual environment variable is `HELLBENDER_TEST_PROJECT`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/571
https://github.com/broadinstitute/gatk/issues/571:90,Modifiability,variab,variable,90,"A missing environment variable reports as `DATAFLOW_TEST_PROJECT`, the actual environment variable is `HELLBENDER_TEST_PROJECT`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/571
https://github.com/broadinstitute/gatk/pull/572:9,Integrability,message,message,9,"The help message was wrong when an environment variable was missing. I've changed it so the same string is used to lookup the variable and report it missing so that can't ever be broken again. This does change it from loading the variables once at startup to loading them every time they are queried. I assumed that isn't an issue, but I can change it to cache them if someone can see a problem with that.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/572
https://github.com/broadinstitute/gatk/pull/572:47,Modifiability,variab,variable,47,"The help message was wrong when an environment variable was missing. I've changed it so the same string is used to lookup the variable and report it missing so that can't ever be broken again. This does change it from loading the variables once at startup to loading them every time they are queried. I assumed that isn't an issue, but I can change it to cache them if someone can see a problem with that.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/572
https://github.com/broadinstitute/gatk/pull/572:126,Modifiability,variab,variable,126,"The help message was wrong when an environment variable was missing. I've changed it so the same string is used to lookup the variable and report it missing so that can't ever be broken again. This does change it from loading the variables once at startup to loading them every time they are queried. I assumed that isn't an issue, but I can change it to cache them if someone can see a problem with that.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/572
https://github.com/broadinstitute/gatk/pull/572:230,Modifiability,variab,variables,230,"The help message was wrong when an environment variable was missing. I've changed it so the same string is used to lookup the variable and report it missing so that can't ever be broken again. This does change it from loading the variables once at startup to loading them every time they are queried. I assumed that isn't an issue, but I can change it to cache them if someone can see a problem with that.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/572
https://github.com/broadinstitute/gatk/pull/572:218,Performance,load,loading,218,"The help message was wrong when an environment variable was missing. I've changed it so the same string is used to lookup the variable and report it missing so that can't ever be broken again. This does change it from loading the variables once at startup to loading them every time they are queried. I assumed that isn't an issue, but I can change it to cache them if someone can see a problem with that.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/572
https://github.com/broadinstitute/gatk/pull/572:259,Performance,load,loading,259,"The help message was wrong when an environment variable was missing. I've changed it so the same string is used to lookup the variable and report it missing so that can't ever be broken again. This does change it from loading the variables once at startup to loading them every time they are queried. I assumed that isn't an issue, but I can change it to cache them if someone can see a problem with that.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/572
https://github.com/broadinstitute/gatk/pull/572:355,Performance,cache,cache,355,"The help message was wrong when an environment variable was missing. I've changed it so the same string is used to lookup the variable and report it missing so that can't ever be broken again. This does change it from loading the variables once at startup to loading them every time they are queried. I assumed that isn't an issue, but I can change it to cache them if someone can see a problem with that.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/572
https://github.com/broadinstitute/gatk/pull/574:207,Deployability,upgrade,upgrade,207,"…en running on Spark. These are tests that rely on user exceptions being returned to the driver, which Spark does not yet support. (If there's a better way of excluding tests, then please let me know.). The upgrade includes some changes to the runner that fix some of the failing tests too.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/574
https://github.com/broadinstitute/gatk/pull/574:32,Testability,test,tests,32,"…en running on Spark. These are tests that rely on user exceptions being returned to the driver, which Spark does not yet support. (If there's a better way of excluding tests, then please let me know.). The upgrade includes some changes to the runner that fix some of the failing tests too.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/574
https://github.com/broadinstitute/gatk/pull/574:169,Testability,test,tests,169,"…en running on Spark. These are tests that rely on user exceptions being returned to the driver, which Spark does not yet support. (If there's a better way of excluding tests, then please let me know.). The upgrade includes some changes to the runner that fix some of the failing tests too.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/574
https://github.com/broadinstitute/gatk/pull/574:280,Testability,test,tests,280,"…en running on Spark. These are tests that rely on user exceptions being returned to the driver, which Spark does not yet support. (If there's a better way of excluding tests, then please let me know.). The upgrade includes some changes to the runner that fix some of the failing tests too.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/574
https://github.com/broadinstitute/gatk/issues/575:320,Availability,error,error,320,"Dataflow and spark both wrap thrown exceptions in their own exceptions before transmitting them back to the client. Spark doesn't maintain the cause field for the new exception, which makes it difficult to unwrap and retrieve the original exception type. . The ability to do this is important because we want to present error's differently to the user depending on if they have a known `UserException` or some other type of exception. It also makes our testing much more robust if we can test for specific failure conditions rather than the error prone `RuntimeException`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/575
https://github.com/broadinstitute/gatk/issues/575:471,Availability,robust,robust,471,"Dataflow and spark both wrap thrown exceptions in their own exceptions before transmitting them back to the client. Spark doesn't maintain the cause field for the new exception, which makes it difficult to unwrap and retrieve the original exception type. . The ability to do this is important because we want to present error's differently to the user depending on if they have a known `UserException` or some other type of exception. It also makes our testing much more robust if we can test for specific failure conditions rather than the error prone `RuntimeException`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/575
https://github.com/broadinstitute/gatk/issues/575:506,Availability,failure,failure,506,"Dataflow and spark both wrap thrown exceptions in their own exceptions before transmitting them back to the client. Spark doesn't maintain the cause field for the new exception, which makes it difficult to unwrap and retrieve the original exception type. . The ability to do this is important because we want to present error's differently to the user depending on if they have a known `UserException` or some other type of exception. It also makes our testing much more robust if we can test for specific failure conditions rather than the error prone `RuntimeException`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/575
https://github.com/broadinstitute/gatk/issues/575:541,Availability,error,error,541,"Dataflow and spark both wrap thrown exceptions in their own exceptions before transmitting them back to the client. Spark doesn't maintain the cause field for the new exception, which makes it difficult to unwrap and retrieve the original exception type. . The ability to do this is important because we want to present error's differently to the user depending on if they have a known `UserException` or some other type of exception. It also makes our testing much more robust if we can test for specific failure conditions rather than the error prone `RuntimeException`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/575
https://github.com/broadinstitute/gatk/issues/575:24,Integrability,wrap,wrap,24,"Dataflow and spark both wrap thrown exceptions in their own exceptions before transmitting them back to the client. Spark doesn't maintain the cause field for the new exception, which makes it difficult to unwrap and retrieve the original exception type. . The ability to do this is important because we want to present error's differently to the user depending on if they have a known `UserException` or some other type of exception. It also makes our testing much more robust if we can test for specific failure conditions rather than the error prone `RuntimeException`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/575
https://github.com/broadinstitute/gatk/issues/575:352,Integrability,depend,depending,352,"Dataflow and spark both wrap thrown exceptions in their own exceptions before transmitting them back to the client. Spark doesn't maintain the cause field for the new exception, which makes it difficult to unwrap and retrieve the original exception type. . The ability to do this is important because we want to present error's differently to the user depending on if they have a known `UserException` or some other type of exception. It also makes our testing much more robust if we can test for specific failure conditions rather than the error prone `RuntimeException`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/575
https://github.com/broadinstitute/gatk/issues/575:453,Testability,test,testing,453,"Dataflow and spark both wrap thrown exceptions in their own exceptions before transmitting them back to the client. Spark doesn't maintain the cause field for the new exception, which makes it difficult to unwrap and retrieve the original exception type. . The ability to do this is important because we want to present error's differently to the user depending on if they have a known `UserException` or some other type of exception. It also makes our testing much more robust if we can test for specific failure conditions rather than the error prone `RuntimeException`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/575
https://github.com/broadinstitute/gatk/issues/575:488,Testability,test,test,488,"Dataflow and spark both wrap thrown exceptions in their own exceptions before transmitting them back to the client. Spark doesn't maintain the cause field for the new exception, which makes it difficult to unwrap and retrieve the original exception type. . The ability to do this is important because we want to present error's differently to the user depending on if they have a known `UserException` or some other type of exception. It also makes our testing much more robust if we can test for specific failure conditions rather than the error prone `RuntimeException`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/575
https://github.com/broadinstitute/gatk/issues/578:174,Energy Efficiency,efficient,efficient,174,Median.java presorts lists in order to find the median. This is inefficient because there exists a single-pass linear time method. Since v 2.2 apache commons implements this efficient algorithm.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/578
https://github.com/broadinstitute/gatk/issues/580:195,Deployability,pipeline,pipeline,195,"One of our tests (BaseRecalibratorDataflow, on cloud) started failing. It turns out that the culprit is a Dataflow limitation. This is what I got back from the DF team:. _I examined logs of this pipeline on the service and in this case, metadata.items[3] is the pipelineOptions item, whose biggest part is --filesToStage, built from the classpath: it seems you have too many .jar's in classpath, or the jars have too long (absolute) filenames.; It seems that you are using Gradle and all the absolute filenames point deep inside gradle cache directories.; So, as a work-around, you could consider asking Gradle to build a self-contained distribution of your application, put it in a less deep directory, and run that._. We may run into this problem for other tests as well, so it's good to know about the issue.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/580
https://github.com/broadinstitute/gatk/issues/580:262,Deployability,pipeline,pipelineOptions,262,"One of our tests (BaseRecalibratorDataflow, on cloud) started failing. It turns out that the culprit is a Dataflow limitation. This is what I got back from the DF team:. _I examined logs of this pipeline on the service and in this case, metadata.items[3] is the pipelineOptions item, whose biggest part is --filesToStage, built from the classpath: it seems you have too many .jar's in classpath, or the jars have too long (absolute) filenames.; It seems that you are using Gradle and all the absolute filenames point deep inside gradle cache directories.; So, as a work-around, you could consider asking Gradle to build a self-contained distribution of your application, put it in a less deep directory, and run that._. We may run into this problem for other tests as well, so it's good to know about the issue.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/580
https://github.com/broadinstitute/gatk/issues/580:536,Performance,cache,cache,536,"One of our tests (BaseRecalibratorDataflow, on cloud) started failing. It turns out that the culprit is a Dataflow limitation. This is what I got back from the DF team:. _I examined logs of this pipeline on the service and in this case, metadata.items[3] is the pipelineOptions item, whose biggest part is --filesToStage, built from the classpath: it seems you have too many .jar's in classpath, or the jars have too long (absolute) filenames.; It seems that you are using Gradle and all the absolute filenames point deep inside gradle cache directories.; So, as a work-around, you could consider asking Gradle to build a self-contained distribution of your application, put it in a less deep directory, and run that._. We may run into this problem for other tests as well, so it's good to know about the issue.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/580
https://github.com/broadinstitute/gatk/issues/580:11,Testability,test,tests,11,"One of our tests (BaseRecalibratorDataflow, on cloud) started failing. It turns out that the culprit is a Dataflow limitation. This is what I got back from the DF team:. _I examined logs of this pipeline on the service and in this case, metadata.items[3] is the pipelineOptions item, whose biggest part is --filesToStage, built from the classpath: it seems you have too many .jar's in classpath, or the jars have too long (absolute) filenames.; It seems that you are using Gradle and all the absolute filenames point deep inside gradle cache directories.; So, as a work-around, you could consider asking Gradle to build a self-contained distribution of your application, put it in a less deep directory, and run that._. We may run into this problem for other tests as well, so it's good to know about the issue.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/580
https://github.com/broadinstitute/gatk/issues/580:182,Testability,log,logs,182,"One of our tests (BaseRecalibratorDataflow, on cloud) started failing. It turns out that the culprit is a Dataflow limitation. This is what I got back from the DF team:. _I examined logs of this pipeline on the service and in this case, metadata.items[3] is the pipelineOptions item, whose biggest part is --filesToStage, built from the classpath: it seems you have too many .jar's in classpath, or the jars have too long (absolute) filenames.; It seems that you are using Gradle and all the absolute filenames point deep inside gradle cache directories.; So, as a work-around, you could consider asking Gradle to build a self-contained distribution of your application, put it in a less deep directory, and run that._. We may run into this problem for other tests as well, so it's good to know about the issue.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/580
https://github.com/broadinstitute/gatk/issues/580:759,Testability,test,tests,759,"One of our tests (BaseRecalibratorDataflow, on cloud) started failing. It turns out that the culprit is a Dataflow limitation. This is what I got back from the DF team:. _I examined logs of this pipeline on the service and in this case, metadata.items[3] is the pipelineOptions item, whose biggest part is --filesToStage, built from the classpath: it seems you have too many .jar's in classpath, or the jars have too long (absolute) filenames.; It seems that you are using Gradle and all the absolute filenames point deep inside gradle cache directories.; So, as a work-around, you could consider asking Gradle to build a self-contained distribution of your application, put it in a less deep directory, and run that._. We may run into this problem for other tests as well, so it's good to know about the issue.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/580
https://github.com/broadinstitute/gatk/issues/581:42,Deployability,update,updated,42,`testGetReadsFromHadoopBam` broke when we updated dataflow. I've placed this test into the new group 'broken-spark` which will be ignored in travis. When https://github.com/cloudera/spark-dataflow/issues/49 is complete we should re-enable this test.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/581
https://github.com/broadinstitute/gatk/issues/581:1,Testability,test,testGetReadsFromHadoopBam,1,`testGetReadsFromHadoopBam` broke when we updated dataflow. I've placed this test into the new group 'broken-spark` which will be ignored in travis. When https://github.com/cloudera/spark-dataflow/issues/49 is complete we should re-enable this test.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/581
https://github.com/broadinstitute/gatk/issues/581:77,Testability,test,test,77,`testGetReadsFromHadoopBam` broke when we updated dataflow. I've placed this test into the new group 'broken-spark` which will be ignored in travis. When https://github.com/cloudera/spark-dataflow/issues/49 is complete we should re-enable this test.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/581
https://github.com/broadinstitute/gatk/issues/581:244,Testability,test,test,244,`testGetReadsFromHadoopBam` broke when we updated dataflow. I've placed this test into the new group 'broken-spark` which will be ignored in travis. When https://github.com/cloudera/spark-dataflow/issues/49 is complete we should re-enable this test.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/581
https://github.com/broadinstitute/gatk/pull/582:127,Deployability,update,updates,127,updating dataflow and htsjdk to newest versions; adding gradle versions plugin to help with identifying dependencies that need updates. This broke one of our spark related tests so I've excluded it for now. See #581. It should be reeneabled when https://github.com/cloudera/spark-dataflow/issues/49 is complete.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/582
https://github.com/broadinstitute/gatk/pull/582:104,Integrability,depend,dependencies,104,updating dataflow and htsjdk to newest versions; adding gradle versions plugin to help with identifying dependencies that need updates. This broke one of our spark related tests so I've excluded it for now. See #581. It should be reeneabled when https://github.com/cloudera/spark-dataflow/issues/49 is complete.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/582
https://github.com/broadinstitute/gatk/pull/582:72,Modifiability,plugin,plugin,72,updating dataflow and htsjdk to newest versions; adding gradle versions plugin to help with identifying dependencies that need updates. This broke one of our spark related tests so I've excluded it for now. See #581. It should be reeneabled when https://github.com/cloudera/spark-dataflow/issues/49 is complete.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/582
https://github.com/broadinstitute/gatk/pull/582:172,Testability,test,tests,172,updating dataflow and htsjdk to newest versions; adding gradle versions plugin to help with identifying dependencies that need updates. This broke one of our spark related tests so I've excluded it for now. See #581. It should be reeneabled when https://github.com/cloudera/spark-dataflow/issues/49 is complete.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/582
https://github.com/broadinstitute/gatk/pull/583:277,Testability,test,test,277,"All right - sorry for the grief with this. This is a new pull request for these changes, squashed and rebased on Hellbender master, including changes for the code review comments for 3 files:; src/main/java/org/broadinstitute/hellbender/tools/picard/sam/FilterReads.java:; src/test/java/org/broadinstitute/hellbender/tools/exome/ExomeReadCountIntegrationTest.java:; src/test/java/org/broadinstitute/hellbender/tools/picard/vcf/AbstractVcfMergingClpTester.java:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/583
https://github.com/broadinstitute/gatk/pull/583:370,Testability,test,test,370,"All right - sorry for the grief with this. This is a new pull request for these changes, squashed and rebased on Hellbender master, including changes for the code review comments for 3 files:; src/main/java/org/broadinstitute/hellbender/tools/picard/sam/FilterReads.java:; src/test/java/org/broadinstitute/hellbender/tools/exome/ExomeReadCountIntegrationTest.java:; src/test/java/org/broadinstitute/hellbender/tools/picard/vcf/AbstractVcfMergingClpTester.java:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/583
https://github.com/broadinstitute/gatk/pull/585:95,Testability,test,test,95,"New PR for these changes; including changes for @akiezun 's comment about making a copy of the test file and @droazen 's comment about naming the SamReaderFactory param ""customSamReaderFactory"".",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/585
https://github.com/broadinstitute/gatk/pull/586:91,Testability,test,tests,91,"This pull requests includes includes assembly graph code and surrounding utility classes + tests. I added a whole bunch of tests and tweaked a whole bunch of code (some more, some much less). . @vruano please review",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/586
https://github.com/broadinstitute/gatk/pull/586:123,Testability,test,tests,123,"This pull requests includes includes assembly graph code and surrounding utility classes + tests. I added a whole bunch of tests and tweaked a whole bunch of code (some more, some much less). . @vruano please review",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/586
https://github.com/broadinstitute/gatk/pull/587:10,Testability,test,testing,10,…. Better testing is needed!,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/587
https://github.com/broadinstitute/gatk/issues/590:590,Deployability,integrat,integration,590,"GATK4 needs to work on cram files. We need to add tests to check that we can process CRAM files and get results equivalent to BAM. At the minimum, this needs to cover adding tests for:; - [x] MarkDuplicates; - [x] BQSR; - [x] PrintReads; - [x] CountReads ; - [x] CountBases; - [x] MeanQualityByCycle; - [x] QualityScoreDistribution; - [ ] CalculateHsMetrics; - [ ] CollectGCBiasMetrics; - [x] CollectBaseDistributionByCycle; - [x] CollectQualityYieldMetrics; - [x] CollectInsertSizeMetrics; - [x] CollectAlignmentSummaryMetrics; - [ ] all picard tools in the sam package. Ideally also unit/integration tests for :; - [ ] HaplotypeCaller; - [ ] CNV coverage collection. (Make sure to use non-lossy settings when converting our BAMs to CRAM)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/590
https://github.com/broadinstitute/gatk/issues/590:590,Integrability,integrat,integration,590,"GATK4 needs to work on cram files. We need to add tests to check that we can process CRAM files and get results equivalent to BAM. At the minimum, this needs to cover adding tests for:; - [x] MarkDuplicates; - [x] BQSR; - [x] PrintReads; - [x] CountReads ; - [x] CountBases; - [x] MeanQualityByCycle; - [x] QualityScoreDistribution; - [ ] CalculateHsMetrics; - [ ] CollectGCBiasMetrics; - [x] CollectBaseDistributionByCycle; - [x] CollectQualityYieldMetrics; - [x] CollectInsertSizeMetrics; - [x] CollectAlignmentSummaryMetrics; - [ ] all picard tools in the sam package. Ideally also unit/integration tests for :; - [ ] HaplotypeCaller; - [ ] CNV coverage collection. (Make sure to use non-lossy settings when converting our BAMs to CRAM)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/590
https://github.com/broadinstitute/gatk/issues/590:50,Testability,test,tests,50,"GATK4 needs to work on cram files. We need to add tests to check that we can process CRAM files and get results equivalent to BAM. At the minimum, this needs to cover adding tests for:; - [x] MarkDuplicates; - [x] BQSR; - [x] PrintReads; - [x] CountReads ; - [x] CountBases; - [x] MeanQualityByCycle; - [x] QualityScoreDistribution; - [ ] CalculateHsMetrics; - [ ] CollectGCBiasMetrics; - [x] CollectBaseDistributionByCycle; - [x] CollectQualityYieldMetrics; - [x] CollectInsertSizeMetrics; - [x] CollectAlignmentSummaryMetrics; - [ ] all picard tools in the sam package. Ideally also unit/integration tests for :; - [ ] HaplotypeCaller; - [ ] CNV coverage collection. (Make sure to use non-lossy settings when converting our BAMs to CRAM)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/590
https://github.com/broadinstitute/gatk/issues/590:174,Testability,test,tests,174,"GATK4 needs to work on cram files. We need to add tests to check that we can process CRAM files and get results equivalent to BAM. At the minimum, this needs to cover adding tests for:; - [x] MarkDuplicates; - [x] BQSR; - [x] PrintReads; - [x] CountReads ; - [x] CountBases; - [x] MeanQualityByCycle; - [x] QualityScoreDistribution; - [ ] CalculateHsMetrics; - [ ] CollectGCBiasMetrics; - [x] CollectBaseDistributionByCycle; - [x] CollectQualityYieldMetrics; - [x] CollectInsertSizeMetrics; - [x] CollectAlignmentSummaryMetrics; - [ ] all picard tools in the sam package. Ideally also unit/integration tests for :; - [ ] HaplotypeCaller; - [ ] CNV coverage collection. (Make sure to use non-lossy settings when converting our BAMs to CRAM)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/590
https://github.com/broadinstitute/gatk/issues/590:602,Testability,test,tests,602,"GATK4 needs to work on cram files. We need to add tests to check that we can process CRAM files and get results equivalent to BAM. At the minimum, this needs to cover adding tests for:; - [x] MarkDuplicates; - [x] BQSR; - [x] PrintReads; - [x] CountReads ; - [x] CountBases; - [x] MeanQualityByCycle; - [x] QualityScoreDistribution; - [ ] CalculateHsMetrics; - [ ] CollectGCBiasMetrics; - [x] CollectBaseDistributionByCycle; - [x] CollectQualityYieldMetrics; - [x] CollectInsertSizeMetrics; - [x] CollectAlignmentSummaryMetrics; - [ ] all picard tools in the sam package. Ideally also unit/integration tests for :; - [ ] HaplotypeCaller; - [ ] CNV coverage collection. (Make sure to use non-lossy settings when converting our BAMs to CRAM)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/590
https://github.com/broadinstitute/gatk/issues/591:131,Safety,detect,detection,131,we need tests like those in `AbstractMarkDuplicatesCommandLineProgramTest` to run on Spark (this is required because the duplicate-detection logic is reimplemented on Spark and based on uniqueness of generated keys). Also `MarkDuplicatesTest` and probably `OpticalDuplicateFinderTest`,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/591
https://github.com/broadinstitute/gatk/issues/591:8,Testability,test,tests,8,we need tests like those in `AbstractMarkDuplicatesCommandLineProgramTest` to run on Spark (this is required because the duplicate-detection logic is reimplemented on Spark and based on uniqueness of generated keys). Also `MarkDuplicatesTest` and probably `OpticalDuplicateFinderTest`,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/591
https://github.com/broadinstitute/gatk/issues/591:141,Testability,log,logic,141,we need tests like those in `AbstractMarkDuplicatesCommandLineProgramTest` to run on Spark (this is required because the duplicate-detection logic is reimplemented on Spark and based on uniqueness of generated keys). Also `MarkDuplicatesTest` and probably `OpticalDuplicateFinderTest`,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/591
https://github.com/broadinstitute/gatk/issues/592:62,Availability,error,errors,62,"`SamFileValidator`'s `isValid()` flags certain reads as being errors when they should not be. This happens when a read that has flag 0x1 ( read has a mate) set to false has flags 0x2, 0x8, 0x20, 0x40 or 0x80 set to true. . According to sam spec, if flag 0x1 is unset than those fields are uninterpretable and should be ignored. This was identified in #569",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/592
https://github.com/broadinstitute/gatk/pull/593:70,Testability,test,test-table-pre,70,`CalibrationTablesBuilderIntegrationTest` was creating a file called `test-table-pre.txt` in the hellbender root directory. It now creates a temporary file instead.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/593
https://github.com/broadinstitute/gatk/pull/595:252,Availability,error,error,252,"To upgrade ApplyBQSR for cloud execution I had to:. (i) change the input to remove reads with the unaligned flag; (ii) load the recalibration report from GCS instead of shipping it as a serialized object, because Dataflow explodes if we ship too much (error is: ""malformed JSON"").; (iii) for the case of a remote execution with a local output file name, add logic to copy the output via GCS to the client's machine.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/595
https://github.com/broadinstitute/gatk/pull/595:3,Deployability,upgrade,upgrade,3,"To upgrade ApplyBQSR for cloud execution I had to:. (i) change the input to remove reads with the unaligned flag; (ii) load the recalibration report from GCS instead of shipping it as a serialized object, because Dataflow explodes if we ship too much (error is: ""malformed JSON"").; (iii) for the case of a remote execution with a local output file name, add logic to copy the output via GCS to the client's machine.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/595
https://github.com/broadinstitute/gatk/pull/595:119,Performance,load,load,119,"To upgrade ApplyBQSR for cloud execution I had to:. (i) change the input to remove reads with the unaligned flag; (ii) load the recalibration report from GCS instead of shipping it as a serialized object, because Dataflow explodes if we ship too much (error is: ""malformed JSON"").; (iii) for the case of a remote execution with a local output file name, add logic to copy the output via GCS to the client's machine.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/595
https://github.com/broadinstitute/gatk/pull/595:358,Testability,log,logic,358,"To upgrade ApplyBQSR for cloud execution I had to:. (i) change the input to remove reads with the unaligned flag; (ii) load the recalibration report from GCS instead of shipping it as a serialized object, because Dataflow explodes if we ship too much (error is: ""malformed JSON"").; (iii) for the case of a remote execution with a local output file name, add logic to copy the output via GCS to the client's machine.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/595
https://github.com/broadinstitute/gatk/issues/599:10,Security,expose,exposed,10,This test exposed a bug in Spark Dataflow which is being fixed by https://github.com/cloudera/spark-dataflow/pull/57,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/599
https://github.com/broadinstitute/gatk/issues/599:5,Testability,test,test,5,This test exposed a bug in Spark Dataflow which is being fixed by https://github.com/cloudera/spark-dataflow/pull/57,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/599
https://github.com/broadinstitute/gatk/pull/601:61,Integrability,interface,interfaces,61,"-Converted the core of the hellbender codebase to use common interfaces; (GATKRead and MutableGATKRead) for working with reads, whether they; happen to be SAMRecords or Google model reads. -Wrote necessary coders, etc., to allow the new interface types to work with; Google dataflow, and ported the dataflow portion of the codebase to use them. -Picard tools and utilities were not converted, as they proved too tricky; to adjust to the new semantics of the GATKRead interface.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/601
https://github.com/broadinstitute/gatk/pull/601:237,Integrability,interface,interface,237,"-Converted the core of the hellbender codebase to use common interfaces; (GATKRead and MutableGATKRead) for working with reads, whether they; happen to be SAMRecords or Google model reads. -Wrote necessary coders, etc., to allow the new interface types to work with; Google dataflow, and ported the dataflow portion of the codebase to use them. -Picard tools and utilities were not converted, as they proved too tricky; to adjust to the new semantics of the GATKRead interface.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/601
https://github.com/broadinstitute/gatk/pull/601:467,Integrability,interface,interface,467,"-Converted the core of the hellbender codebase to use common interfaces; (GATKRead and MutableGATKRead) for working with reads, whether they; happen to be SAMRecords or Google model reads. -Wrote necessary coders, etc., to allow the new interface types to work with; Google dataflow, and ported the dataflow portion of the codebase to use them. -Picard tools and utilities were not converted, as they proved too tricky; to adjust to the new semantics of the GATKRead interface.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/601
https://github.com/broadinstitute/gatk/pull/602:36,Testability,test,test,36,Fixed the NPE from #273 and added a test for it.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/602
https://github.com/broadinstitute/gatk/pull/603:128,Availability,down,down,128,"This PR dynamically sets the logging level for command line tools at runtime using the current version of log4j (we were headed down a path of downgrading to a previous version of log4j in order to implement this). However, it uses an API that is normally used in code for extending log4j rather than acting as a client to it, and requires an explicit cast of the value returned from LogManager.getContext. The Apache project site illustrates the use of this api in the first line of code in an example here: https://logging.apache.org/log4j/2.x/manual/customconfig.html#AddingToCurrent. We need to decide if we want to take this and stay on the current version or continue with the downgrade…",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/603
https://github.com/broadinstitute/gatk/pull/603:143,Availability,down,downgrading,143,"This PR dynamically sets the logging level for command line tools at runtime using the current version of log4j (we were headed down a path of downgrading to a previous version of log4j in order to implement this). However, it uses an API that is normally used in code for extending log4j rather than acting as a client to it, and requires an explicit cast of the value returned from LogManager.getContext. The Apache project site illustrates the use of this api in the first line of code in an example here: https://logging.apache.org/log4j/2.x/manual/customconfig.html#AddingToCurrent. We need to decide if we want to take this and stay on the current version or continue with the downgrade…",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/603
https://github.com/broadinstitute/gatk/pull/603:683,Availability,down,downgrade,683,"This PR dynamically sets the logging level for command line tools at runtime using the current version of log4j (we were headed down a path of downgrading to a previous version of log4j in order to implement this). However, it uses an API that is normally used in code for extending log4j rather than acting as a client to it, and requires an explicit cast of the value returned from LogManager.getContext. The Apache project site illustrates the use of this api in the first line of code in an example here: https://logging.apache.org/log4j/2.x/manual/customconfig.html#AddingToCurrent. We need to decide if we want to take this and stay on the current version or continue with the downgrade…",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/603
https://github.com/broadinstitute/gatk/pull/603:273,Modifiability,extend,extending,273,"This PR dynamically sets the logging level for command line tools at runtime using the current version of log4j (we were headed down a path of downgrading to a previous version of log4j in order to implement this). However, it uses an API that is normally used in code for extending log4j rather than acting as a client to it, and requires an explicit cast of the value returned from LogManager.getContext. The Apache project site illustrates the use of this api in the first line of code in an example here: https://logging.apache.org/log4j/2.x/manual/customconfig.html#AddingToCurrent. We need to decide if we want to take this and stay on the current version or continue with the downgrade…",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/603
https://github.com/broadinstitute/gatk/pull/603:29,Testability,log,logging,29,"This PR dynamically sets the logging level for command line tools at runtime using the current version of log4j (we were headed down a path of downgrading to a previous version of log4j in order to implement this). However, it uses an API that is normally used in code for extending log4j rather than acting as a client to it, and requires an explicit cast of the value returned from LogManager.getContext. The Apache project site illustrates the use of this api in the first line of code in an example here: https://logging.apache.org/log4j/2.x/manual/customconfig.html#AddingToCurrent. We need to decide if we want to take this and stay on the current version or continue with the downgrade…",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/603
https://github.com/broadinstitute/gatk/pull/603:384,Testability,Log,LogManager,384,"This PR dynamically sets the logging level for command line tools at runtime using the current version of log4j (we were headed down a path of downgrading to a previous version of log4j in order to implement this). However, it uses an API that is normally used in code for extending log4j rather than acting as a client to it, and requires an explicit cast of the value returned from LogManager.getContext. The Apache project site illustrates the use of this api in the first line of code in an example here: https://logging.apache.org/log4j/2.x/manual/customconfig.html#AddingToCurrent. We need to decide if we want to take this and stay on the current version or continue with the downgrade…",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/603
https://github.com/broadinstitute/gatk/pull/603:517,Testability,log,logging,517,"This PR dynamically sets the logging level for command line tools at runtime using the current version of log4j (we were headed down a path of downgrading to a previous version of log4j in order to implement this). However, it uses an API that is normally used in code for extending log4j rather than acting as a client to it, and requires an explicit cast of the value returned from LogManager.getContext. The Apache project site illustrates the use of this api in the first line of code in an example here: https://logging.apache.org/log4j/2.x/manual/customconfig.html#AddingToCurrent. We need to decide if we want to take this and stay on the current version or continue with the downgrade…",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/603
https://github.com/broadinstitute/gatk/pull/604:128,Deployability,integrat,integration,128,…ration tests. The fix for the original bug (CompareSAMs not obeying stringency) is a one line fix in CompareSAMs. The two BQSR integration tests referenced in the issue use a different code path and required a different fix (assuming that relaxing the stringency is the right thing to do in those cases). I also added a new CompareSAMs integration test and changed the CompareSAMs tool to return result of the comparison.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/604
https://github.com/broadinstitute/gatk/pull/604:337,Deployability,integrat,integration,337,…ration tests. The fix for the original bug (CompareSAMs not obeying stringency) is a one line fix in CompareSAMs. The two BQSR integration tests referenced in the issue use a different code path and required a different fix (assuming that relaxing the stringency is the right thing to do in those cases). I also added a new CompareSAMs integration test and changed the CompareSAMs tool to return result of the comparison.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/604
https://github.com/broadinstitute/gatk/pull/604:128,Integrability,integrat,integration,128,…ration tests. The fix for the original bug (CompareSAMs not obeying stringency) is a one line fix in CompareSAMs. The two BQSR integration tests referenced in the issue use a different code path and required a different fix (assuming that relaxing the stringency is the right thing to do in those cases). I also added a new CompareSAMs integration test and changed the CompareSAMs tool to return result of the comparison.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/604
https://github.com/broadinstitute/gatk/pull/604:337,Integrability,integrat,integration,337,…ration tests. The fix for the original bug (CompareSAMs not obeying stringency) is a one line fix in CompareSAMs. The two BQSR integration tests referenced in the issue use a different code path and required a different fix (assuming that relaxing the stringency is the right thing to do in those cases). I also added a new CompareSAMs integration test and changed the CompareSAMs tool to return result of the comparison.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/604
https://github.com/broadinstitute/gatk/pull/604:8,Testability,test,tests,8,…ration tests. The fix for the original bug (CompareSAMs not obeying stringency) is a one line fix in CompareSAMs. The two BQSR integration tests referenced in the issue use a different code path and required a different fix (assuming that relaxing the stringency is the right thing to do in those cases). I also added a new CompareSAMs integration test and changed the CompareSAMs tool to return result of the comparison.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/604
https://github.com/broadinstitute/gatk/pull/604:140,Testability,test,tests,140,…ration tests. The fix for the original bug (CompareSAMs not obeying stringency) is a one line fix in CompareSAMs. The two BQSR integration tests referenced in the issue use a different code path and required a different fix (assuming that relaxing the stringency is the right thing to do in those cases). I also added a new CompareSAMs integration test and changed the CompareSAMs tool to return result of the comparison.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/604
https://github.com/broadinstitute/gatk/pull/604:349,Testability,test,test,349,…ration tests. The fix for the original bug (CompareSAMs not obeying stringency) is a one line fix in CompareSAMs. The two BQSR integration tests referenced in the issue use a different code path and required a different fix (assuming that relaxing the stringency is the right thing to do in those cases). I also added a new CompareSAMs integration test and changed the CompareSAMs tool to return result of the comparison.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/604
https://github.com/broadinstitute/gatk/issues/605:143,Availability,avail,available,143,Gatk3 allowed inputs like `-L some_intervals.vcf`. This functionality should be integrated into the `IntervalArgumentCollection` so that it is available to all tools.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/605
https://github.com/broadinstitute/gatk/issues/605:80,Deployability,integrat,integrated,80,Gatk3 allowed inputs like `-L some_intervals.vcf`. This functionality should be integrated into the `IntervalArgumentCollection` so that it is available to all tools.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/605
https://github.com/broadinstitute/gatk/issues/605:80,Integrability,integrat,integrated,80,Gatk3 allowed inputs like `-L some_intervals.vcf`. This functionality should be integrated into the `IntervalArgumentCollection` so that it is available to all tools.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/605
https://github.com/broadinstitute/gatk/issues/607:229,Modifiability,refactor,refactored,229,"There are a number of skipped tests on a successful run of `AlleleListUtilsUnitTest` These are deliberately skipped because the tests share a single data provider, but each test can only use a subset of the data. These should be refactored to avoid skipping tests. These tests also make use of random number generators. It looks like these may not be properly isolated and may introduce coupling between what should be independent tests.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/607
https://github.com/broadinstitute/gatk/issues/607:387,Modifiability,coupling,coupling,387,"There are a number of skipped tests on a successful run of `AlleleListUtilsUnitTest` These are deliberately skipped because the tests share a single data provider, but each test can only use a subset of the data. These should be refactored to avoid skipping tests. These tests also make use of random number generators. It looks like these may not be properly isolated and may introduce coupling between what should be independent tests.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/607
https://github.com/broadinstitute/gatk/issues/607:243,Safety,avoid,avoid,243,"There are a number of skipped tests on a successful run of `AlleleListUtilsUnitTest` These are deliberately skipped because the tests share a single data provider, but each test can only use a subset of the data. These should be refactored to avoid skipping tests. These tests also make use of random number generators. It looks like these may not be properly isolated and may introduce coupling between what should be independent tests.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/607
https://github.com/broadinstitute/gatk/issues/607:30,Testability,test,tests,30,"There are a number of skipped tests on a successful run of `AlleleListUtilsUnitTest` These are deliberately skipped because the tests share a single data provider, but each test can only use a subset of the data. These should be refactored to avoid skipping tests. These tests also make use of random number generators. It looks like these may not be properly isolated and may introduce coupling between what should be independent tests.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/607
https://github.com/broadinstitute/gatk/issues/607:128,Testability,test,tests,128,"There are a number of skipped tests on a successful run of `AlleleListUtilsUnitTest` These are deliberately skipped because the tests share a single data provider, but each test can only use a subset of the data. These should be refactored to avoid skipping tests. These tests also make use of random number generators. It looks like these may not be properly isolated and may introduce coupling between what should be independent tests.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/607
https://github.com/broadinstitute/gatk/issues/607:173,Testability,test,test,173,"There are a number of skipped tests on a successful run of `AlleleListUtilsUnitTest` These are deliberately skipped because the tests share a single data provider, but each test can only use a subset of the data. These should be refactored to avoid skipping tests. These tests also make use of random number generators. It looks like these may not be properly isolated and may introduce coupling between what should be independent tests.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/607
https://github.com/broadinstitute/gatk/issues/607:258,Testability,test,tests,258,"There are a number of skipped tests on a successful run of `AlleleListUtilsUnitTest` These are deliberately skipped because the tests share a single data provider, but each test can only use a subset of the data. These should be refactored to avoid skipping tests. These tests also make use of random number generators. It looks like these may not be properly isolated and may introduce coupling between what should be independent tests.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/607
https://github.com/broadinstitute/gatk/issues/607:271,Testability,test,tests,271,"There are a number of skipped tests on a successful run of `AlleleListUtilsUnitTest` These are deliberately skipped because the tests share a single data provider, but each test can only use a subset of the data. These should be refactored to avoid skipping tests. These tests also make use of random number generators. It looks like these may not be properly isolated and may introduce coupling between what should be independent tests.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/607
https://github.com/broadinstitute/gatk/issues/607:431,Testability,test,tests,431,"There are a number of skipped tests on a successful run of `AlleleListUtilsUnitTest` These are deliberately skipped because the tests share a single data provider, but each test can only use a subset of the data. These should be refactored to avoid skipping tests. These tests also make use of random number generators. It looks like these may not be properly isolated and may introduce coupling between what should be independent tests.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/607
https://github.com/broadinstitute/gatk/issues/609:68,Deployability,pipeline,pipeline,68,"Some (but not all) users get a warning whenever they run a dataflow pipeline that calls `DataflowWorkarounds.registerGenomicsCoders`. Here is an example:. ```; Jul 01, 2015 2:33:36 PM com.google.cloud.genomics.dataflow.utils.DataflowWorkarounds registerGenomicsCoders; INFO: Registering coders for genomics classes; Jul 01, 2015 2:33:36 PM org.reflections.Reflections scan; WARNING: could not create Vfs.Dir from url. ignoring the exception and continuing; org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/Library/KeyAccess/KeyAccess.app/Contents/SharedFrameworks/KeyAccess.framework/KeyAccess]; either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.; at org.reflections.vfs.Vfs.fromURL(Vfs.java:109); at org.reflections.vfs.Vfs.fromURL(Vfs.java:91); at org.reflections.Reflections.scan(Reflections.java:237); at org.reflections.Reflections.scan(Reflections.java:204); at org.reflections.Reflections.<init>(Reflections.java:129); at com.google.cloud.genomics.dataflow.utils.DataflowWorkarounds.registerGenomicsCoders(DataflowWorkarounds.java:90); at org.broadinstitute.hellbender.tools.dataflow.transforms.InsertSizeMetricsTransformUnitTest.testInsertSizeMetricsTransform(InsertSizeMetricsTransformUnitTest.java:49); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609
https://github.com/broadinstitute/gatk/issues/609:3618,Integrability,depend,dependency,3618,"rg.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.runSuitesLocally(TestNG.java:1124); at org.testng.TestNG.run(TestNG.java:1032); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140). Jul 01, 2015 2:33:37 PM org.reflections.Reflections scan; ```. The fact that it doesn't show up for some users means its likely to be an environmental difference, possibly an underspecified dependency. @davidaadams I understand that you never see this warning, could you confirm/deny that.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609
https://github.com/broadinstitute/gatk/issues/609:1348,Testability,test,testInsertSizeMetricsTransform,1348,": could not create Vfs.Dir from url. ignoring the exception and continuing; org.reflections.ReflectionsException: could not create Vfs.Dir from url, no matching UrlType was found [file:/Library/KeyAccess/KeyAccess.app/Contents/SharedFrameworks/KeyAccess.framework/KeyAccess]; either use fromURL(final URL url, final List<UrlType> urlTypes) or use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.; at org.reflections.vfs.Vfs.fromURL(Vfs.java:109); at org.reflections.vfs.Vfs.fromURL(Vfs.java:91); at org.reflections.Reflections.scan(Reflections.java:237); at org.reflections.Reflections.scan(Reflections.java:204); at org.reflections.Reflections.<init>(Reflections.java:129); at com.google.cloud.genomics.dataflow.utils.DataflowWorkarounds.registerGenomicsCoders(DataflowWorkarounds.java:90); at org.broadinstitute.hellbender.tools.dataflow.transforms.InsertSizeMetricsTransformUnitTest.testInsertSizeMetricsTransform(InsertSizeMetricsTransformUnitTest.java:49); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609
https://github.com/broadinstitute/gatk/issues/609:1720,Testability,test,testng,1720, use the static setDefaultURLTypes(final List<UrlType> urlTypes) or addDefaultURLTypes(UrlType urlType) with your specialized UrlType.; at org.reflections.vfs.Vfs.fromURL(Vfs.java:109); at org.reflections.vfs.Vfs.fromURL(Vfs.java:91); at org.reflections.Reflections.scan(Reflections.java:237); at org.reflections.Reflections.scan(Reflections.java:204); at org.reflections.Reflections.<init>(Reflections.java:129); at com.google.cloud.genomics.dataflow.utils.DataflowWorkarounds.registerGenomicsCoders(DataflowWorkarounds.java:90); at org.broadinstitute.hellbender.tools.dataflow.transforms.InsertSizeMetricsTransformUnitTest.testInsertSizeMetricsTransform(InsertSizeMetricsTransformUnitTest.java:49); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.ru,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609
https://github.com/broadinstitute/gatk/issues/609:1812,Testability,test,testng,1812,pe urlType) with your specialized UrlType.; at org.reflections.vfs.Vfs.fromURL(Vfs.java:109); at org.reflections.vfs.Vfs.fromURL(Vfs.java:91); at org.reflections.Reflections.scan(Reflections.java:237); at org.reflections.Reflections.scan(Reflections.java:204); at org.reflections.Reflections.<init>(Reflections.java:129); at com.google.cloud.genomics.dataflow.utils.DataflowWorkarounds.registerGenomicsCoders(DataflowWorkarounds.java:90); at org.broadinstitute.hellbender.tools.dataflow.transforms.InsertSizeMetricsTransformUnitTest.testInsertSizeMetricsTransform(InsertSizeMetricsTransformUnitTest.java:49); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.runSuitesLocally(TestNG.java:1124); at org.testng.TestNG.run(TestNG.java:1032); at org.testng.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609
https://github.com/broadinstitute/gatk/issues/609:1875,Testability,test,testng,1875,vfs.Vfs.fromURL(Vfs.java:109); at org.reflections.vfs.Vfs.fromURL(Vfs.java:91); at org.reflections.Reflections.scan(Reflections.java:237); at org.reflections.Reflections.scan(Reflections.java:204); at org.reflections.Reflections.<init>(Reflections.java:129); at com.google.cloud.genomics.dataflow.utils.DataflowWorkarounds.registerGenomicsCoders(DataflowWorkarounds.java:90); at org.broadinstitute.hellbender.tools.dataflow.transforms.InsertSizeMetricsTransformUnitTest.testInsertSizeMetricsTransform(InsertSizeMetricsTransformUnitTest.java:49); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.runSuitesLocally(TestNG.java:1124); at org.testng.TestNG.run(TestNG.java:1032); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.r,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609
https://github.com/broadinstitute/gatk/issues/609:1942,Testability,test,testng,1942,fs.java:91); at org.reflections.Reflections.scan(Reflections.java:237); at org.reflections.Reflections.scan(Reflections.java:204); at org.reflections.Reflections.<init>(Reflections.java:129); at com.google.cloud.genomics.dataflow.utils.DataflowWorkarounds.registerGenomicsCoders(DataflowWorkarounds.java:90); at org.broadinstitute.hellbender.tools.dataflow.transforms.InsertSizeMetricsTransformUnitTest.testInsertSizeMetricsTransform(InsertSizeMetricsTransformUnitTest.java:49); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.runSuitesLocally(TestNG.java:1124); at org.testng.TestNG.run(TestNG.java:1032); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609
https://github.com/broadinstitute/gatk/issues/609:2011,Testability,test,testng,2011,); at org.reflections.Reflections.scan(Reflections.java:204); at org.reflections.Reflections.<init>(Reflections.java:129); at com.google.cloud.genomics.dataflow.utils.DataflowWorkarounds.registerGenomicsCoders(DataflowWorkarounds.java:90); at org.broadinstitute.hellbender.tools.dataflow.transforms.InsertSizeMetricsTransformUnitTest.testInsertSizeMetricsTransform(InsertSizeMetricsTransformUnitTest.java:49); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.runSuitesLocally(TestNG.java:1124); at org.testng.TestNG.run(TestNG.java:1032); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.Remot,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609
https://github.com/broadinstitute/gatk/issues/609:2027,Testability,Test,TestMethodWorker,2027,.Reflections.scan(Reflections.java:204); at org.reflections.Reflections.<init>(Reflections.java:129); at com.google.cloud.genomics.dataflow.utils.DataflowWorkarounds.registerGenomicsCoders(DataflowWorkarounds.java:90); at org.broadinstitute.hellbender.tools.dataflow.transforms.InsertSizeMetricsTransformUnitTest.testInsertSizeMetricsTransform(InsertSizeMetricsTransformUnitTest.java:49); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.runSuitesLocally(TestNG.java:1124); at org.testng.TestNG.run(TestNG.java:1032); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(R,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609
https://github.com/broadinstitute/gatk/issues/609:2062,Testability,Test,TestMethodWorker,2062,ons.java:204); at org.reflections.Reflections.<init>(Reflections.java:129); at com.google.cloud.genomics.dataflow.utils.DataflowWorkarounds.registerGenomicsCoders(DataflowWorkarounds.java:90); at org.broadinstitute.hellbender.tools.dataflow.transforms.InsertSizeMetricsTransformUnitTest.testInsertSizeMetricsTransform(InsertSizeMetricsTransformUnitTest.java:49); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.runSuitesLocally(TestNG.java:1124); at org.testng.TestNG.run(TestNG.java:1032); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:12,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609
https://github.com/broadinstitute/gatk/issues/609:2097,Testability,test,testng,2097,ctions.<init>(Reflections.java:129); at com.google.cloud.genomics.dataflow.utils.DataflowWorkarounds.registerGenomicsCoders(DataflowWorkarounds.java:90); at org.broadinstitute.hellbender.tools.dataflow.transforms.InsertSizeMetricsTransformUnitTest.testInsertSizeMetricsTransform(InsertSizeMetricsTransformUnitTest.java:49); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.runSuitesLocally(TestNG.java:1124); at org.testng.TestNG.run(TestNG.java:1032); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessor,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609
https://github.com/broadinstitute/gatk/issues/609:2113,Testability,Test,TestMethodWorker,2113,ions.java:129); at com.google.cloud.genomics.dataflow.utils.DataflowWorkarounds.registerGenomicsCoders(DataflowWorkarounds.java:90); at org.broadinstitute.hellbender.tools.dataflow.transforms.InsertSizeMetricsTransformUnitTest.testInsertSizeMetricsTransform(InsertSizeMetricsTransformUnitTest.java:49); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.runSuitesLocally(TestNG.java:1124); at org.testng.TestNG.run(TestNG.java:1032); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native M,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609
https://github.com/broadinstitute/gatk/issues/609:2134,Testability,Test,TestMethodWorker,2134,com.google.cloud.genomics.dataflow.utils.DataflowWorkarounds.registerGenomicsCoders(DataflowWorkarounds.java:90); at org.broadinstitute.hellbender.tools.dataflow.transforms.InsertSizeMetricsTransformUnitTest.testInsertSizeMetricsTransform(InsertSizeMetricsTransformUnitTest.java:49); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.runSuitesLocally(TestNG.java:1124); at org.testng.TestNG.run(TestNG.java:1032); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.refl,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609
https://github.com/broadinstitute/gatk/issues/609:2169,Testability,test,testng,2169,ow.utils.DataflowWorkarounds.registerGenomicsCoders(DataflowWorkarounds.java:90); at org.broadinstitute.hellbender.tools.dataflow.transforms.InsertSizeMetricsTransformUnitTest.testInsertSizeMetricsTransform(InsertSizeMetricsTransformUnitTest.java:49); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.runSuitesLocally(TestNG.java:1124); at org.testng.TestNG.run(TestNG.java:1032); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.inv,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609
https://github.com/broadinstitute/gatk/issues/609:2176,Testability,Test,TestRunner,2176,DataflowWorkarounds.registerGenomicsCoders(DataflowWorkarounds.java:90); at org.broadinstitute.hellbender.tools.dataflow.transforms.InsertSizeMetricsTransformUnitTest.testInsertSizeMetricsTransform(InsertSizeMetricsTransformUnitTest.java:49); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.runSuitesLocally(TestNG.java:1124); at org.testng.TestNG.run(TestNG.java:1032); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(Nativ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609
https://github.com/broadinstitute/gatk/issues/609:2198,Testability,Test,TestRunner,2198,ds.registerGenomicsCoders(DataflowWorkarounds.java:90); at org.broadinstitute.hellbender.tools.dataflow.transforms.InsertSizeMetricsTransformUnitTest.testInsertSizeMetricsTransform(InsertSizeMetricsTransformUnitTest.java:49); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.runSuitesLocally(TestNG.java:1124); at org.testng.TestNG.run(TestNG.java:1032); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorI,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609
https://github.com/broadinstitute/gatk/issues/609:2227,Testability,test,testng,2227,owWorkarounds.java:90); at org.broadinstitute.hellbender.tools.dataflow.transforms.InsertSizeMetricsTransformUnitTest.testInsertSizeMetricsTransform(InsertSizeMetricsTransformUnitTest.java:49); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.runSuitesLocally(TestNG.java:1124); at org.testng.TestNG.run(TestNG.java:1032); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.Dele,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609
https://github.com/broadinstitute/gatk/issues/609:2234,Testability,Test,TestRunner,2234,unds.java:90); at org.broadinstitute.hellbender.tools.dataflow.transforms.InsertSizeMetricsTransformUnitTest.testInsertSizeMetricsTransform(InsertSizeMetricsTransformUnitTest.java:49); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.runSuitesLocally(TestNG.java:1124); at org.testng.TestNG.run(TestNG.java:1032); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMet,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609
https://github.com/broadinstitute/gatk/issues/609:2249,Testability,Test,TestRunner,2249,; at org.broadinstitute.hellbender.tools.dataflow.transforms.InsertSizeMetricsTransformUnitTest.testInsertSizeMetricsTransform(InsertSizeMetricsTransformUnitTest.java:49); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.runSuitesLocally(TestNG.java:1124); at org.testng.TestNG.run(TestNG.java:1032); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorIm,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609
https://github.com/broadinstitute/gatk/issues/609:2278,Testability,test,testng,2278,ender.tools.dataflow.transforms.InsertSizeMetricsTransformUnitTest.testInsertSizeMetricsTransform(InsertSizeMetricsTransformUnitTest.java:49); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.runSuitesLocally(TestNG.java:1124); at org.testng.TestNG.run(TestNG.java:1032); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAcc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609
https://github.com/broadinstitute/gatk/issues/609:2335,Testability,test,testng,2335,mUnitTest.testInsertSizeMetricsTransform(InsertSizeMetricsTransformUnitTest.java:49); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.runSuitesLocally(TestNG.java:1124); at org.testng.TestNG.run(TestNG.java:1032); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Me,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609
https://github.com/broadinstitute/gatk/issues/609:2400,Testability,test,testng,2400,rmUnitTest.java:49); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.runSuitesLocally(TestNG.java:1124); at org.testng.TestNG.run(TestNG.java:1032); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at com.intellij.rt.execution.application.AppMain.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609
https://github.com/broadinstitute/gatk/issues/609:2460,Testability,test,testng,2460,".invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.runSuitesLocally(TestNG.java:1124); at org.testng.TestNG.run(TestNG.java:1032); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140). Jul 01, 2015 2:33:37 PM org.reflecti",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609
https://github.com/broadinstitute/gatk/issues/609:2513,Testability,test,testng,2513,"ccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.runSuitesLocally(TestNG.java:1124); at org.testng.TestNG.run(TestNG.java:1032); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140). Jul 01, 2015 2:33:37 PM org.reflections.Reflections scan; ```. The fact that it doesn't s",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609
https://github.com/broadinstitute/gatk/issues/609:2582,Testability,test,testng,2582,"DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.runSuitesLocally(TestNG.java:1124); at org.testng.TestNG.run(TestNG.java:1032); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140). Jul 01, 2015 2:33:37 PM org.reflections.Reflections scan; ```. The fact that it doesn't show up for some users means its likely to be an environmental differe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609
https://github.com/broadinstitute/gatk/issues/609:2646,Testability,test,testng,2646,".java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.runSuitesLocally(TestNG.java:1124); at org.testng.TestNG.run(TestNG.java:1032); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140). Jul 01, 2015 2:33:37 PM org.reflections.Reflections scan; ```. The fact that it doesn't show up for some users means its likely to be an environmental difference, possibly an underspecified dependency. @davidaadams I under",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609
https://github.com/broadinstitute/gatk/issues/609:2653,Testability,Test,TestNG,2653,"3); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.runSuitesLocally(TestNG.java:1124); at org.testng.TestNG.run(TestNG.java:1032); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140). Jul 01, 2015 2:33:37 PM org.reflections.Reflections scan; ```. The fact that it doesn't show up for some users means its likely to be an environmental difference, possibly an underspecified dependency. @davidaadams I understand t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609
https://github.com/broadinstitute/gatk/issues/609:2682,Testability,Test,TestNG,2682,"eflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.runSuitesLocally(TestNG.java:1124); at org.testng.TestNG.run(TestNG.java:1032); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140). Jul 01, 2015 2:33:37 PM org.reflections.Reflections scan; ```. The fact that it doesn't show up for some users means its likely to be an environmental difference, possibly an underspecified dependency. @davidaadams I understand that you never see ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609
https://github.com/broadinstitute/gatk/issues/609:2708,Testability,test,testng,2708,"; at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.runSuitesLocally(TestNG.java:1124); at org.testng.TestNG.run(TestNG.java:1032); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140). Jul 01, 2015 2:33:37 PM org.reflections.Reflections scan; ```. The fact that it doesn't show up for some users means its likely to be an environmental difference, possibly an underspecified dependency. @davidaadams I understand that you never see this warning, could you confirm/deny ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609
https://github.com/broadinstitute/gatk/issues/609:2715,Testability,Test,TestNG,2715,"rg.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.runSuitesLocally(TestNG.java:1124); at org.testng.TestNG.run(TestNG.java:1032); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140). Jul 01, 2015 2:33:37 PM org.reflections.Reflections scan; ```. The fact that it doesn't show up for some users means its likely to be an environmental difference, possibly an underspecified dependency. @davidaadams I understand that you never see this warning, could you confirm/deny that.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609
https://github.com/broadinstitute/gatk/issues/609:2739,Testability,Test,TestNG,2739,"rg.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.runSuitesLocally(TestNG.java:1124); at org.testng.TestNG.run(TestNG.java:1032); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140). Jul 01, 2015 2:33:37 PM org.reflections.Reflections scan; ```. The fact that it doesn't show up for some users means its likely to be an environmental difference, possibly an underspecified dependency. @davidaadams I understand that you never see this warning, could you confirm/deny that.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609
https://github.com/broadinstitute/gatk/issues/609:2765,Testability,test,testng,2765,"rg.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.runSuitesLocally(TestNG.java:1124); at org.testng.TestNG.run(TestNG.java:1032); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140). Jul 01, 2015 2:33:37 PM org.reflections.Reflections scan; ```. The fact that it doesn't show up for some users means its likely to be an environmental difference, possibly an underspecified dependency. @davidaadams I understand that you never see this warning, could you confirm/deny that.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609
https://github.com/broadinstitute/gatk/issues/609:2772,Testability,Test,TestNG,2772,"rg.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.runSuitesLocally(TestNG.java:1124); at org.testng.TestNG.run(TestNG.java:1032); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140). Jul 01, 2015 2:33:37 PM org.reflections.Reflections scan; ```. The fact that it doesn't show up for some users means its likely to be an environmental difference, possibly an underspecified dependency. @davidaadams I understand that you never see this warning, could you confirm/deny that.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609
https://github.com/broadinstitute/gatk/issues/609:2783,Testability,Test,TestNG,2783,"rg.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.runSuitesLocally(TestNG.java:1124); at org.testng.TestNG.run(TestNG.java:1032); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140). Jul 01, 2015 2:33:37 PM org.reflections.Reflections scan; ```. The fact that it doesn't show up for some users means its likely to be an environmental difference, possibly an underspecified dependency. @davidaadams I understand that you never see this warning, could you confirm/deny that.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609
https://github.com/broadinstitute/gatk/issues/609:2809,Testability,test,testng,2809,"rg.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.runSuitesLocally(TestNG.java:1124); at org.testng.TestNG.run(TestNG.java:1032); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140). Jul 01, 2015 2:33:37 PM org.reflections.Reflections scan; ```. The fact that it doesn't show up for some users means its likely to be an environmental difference, possibly an underspecified dependency. @davidaadams I understand that you never see this warning, could you confirm/deny that.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609
https://github.com/broadinstitute/gatk/issues/609:2871,Testability,test,testng,2871,"rg.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.runSuitesLocally(TestNG.java:1124); at org.testng.TestNG.run(TestNG.java:1032); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140). Jul 01, 2015 2:33:37 PM org.reflections.Reflections scan; ```. The fact that it doesn't show up for some users means its likely to be an environmental difference, possibly an underspecified dependency. @davidaadams I understand that you never see this warning, could you confirm/deny that.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609
https://github.com/broadinstitute/gatk/issues/609:2940,Testability,test,testng,2940,"rg.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.runSuitesLocally(TestNG.java:1124); at org.testng.TestNG.run(TestNG.java:1032); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140). Jul 01, 2015 2:33:37 PM org.reflections.Reflections scan; ```. The fact that it doesn't show up for some users means its likely to be an environmental difference, possibly an underspecified dependency. @davidaadams I understand that you never see this warning, could you confirm/deny that.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609
https://github.com/broadinstitute/gatk/issues/609:3003,Testability,test,testng,3003,"rg.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:659); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:845); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1153); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:771); at org.testng.TestRunner.run(TestRunner.java:621); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1199); at org.testng.TestNG.runSuitesLocally(TestNG.java:1124); at org.testng.TestNG.run(TestNG.java:1032); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140). Jul 01, 2015 2:33:37 PM org.reflections.Reflections scan; ```. The fact that it doesn't show up for some users means its likely to be an environmental difference, possibly an underspecified dependency. @davidaadams I understand that you never see this warning, could you confirm/deny that.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/609
https://github.com/broadinstitute/gatk/issues/610:143,Integrability,depend,dependencies,143,"Something about the cloudera artifactory server is causing our gradle build to print out ""cookie rejected"" notifications when it checks it for dependencies. ```; :compileJava; Cookie rejected: ""[version: 0][name: JSESSIONID][value: 4A10F85C449AC245A7195508DC597006][domain: repository.cloudera.com][path: /cloudera/][expiry: null]"". Illegal path attribute ""/cloudera/"". Path of origin: ""/artifactory/cloudera-repos/com/google/appengine/appengine-api-1.0-sdk/""; Cookie rejected: ""[version: 0][name: JSESSIONID][value: 75ED0380B9A0ED0358C2B9666BED71A3][domain: repository.cloudera.com][path: /cloudera/][expiry: null]"". Illegal path attribute ""/cloudera/"". Path of origin: ""/artifactory/cloudera-repos/com/google/guava/guava/""; Cookie rejected: ""[version: 0][name: JSESSIONID][value: 7693D886ED54601AF3EB1333359425D9][domain: repository.cloudera.com][path: /cloudera/][expiry: null]"". Illegal path attribute ""/cloudera/"". Path of origin: ""/artifactory/cloudera-repos/com/google/api-client/google-api-client-appengine/""; Cookie rejected: ""[version: 0][name: JSESSIONID][value: 86B716FE5E36C74ABF85424380AEFC03][domain: repository.cloudera.com][path: /cloudera/][expiry: null]"". Illegal path attribute ""/cloudera/"". Path of origin: ""/artifactory/cloudera-repos/com/google/http-client/google-http-client-jackson2/""; ```. We should figure out if this is a meaningful warning at all, and how to prevent it from happening. @tomwhite Any idea what's causing these messages? Not a high priority but they're mildly annoying.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/610
https://github.com/broadinstitute/gatk/issues/610:1455,Integrability,message,messages,1455,"Something about the cloudera artifactory server is causing our gradle build to print out ""cookie rejected"" notifications when it checks it for dependencies. ```; :compileJava; Cookie rejected: ""[version: 0][name: JSESSIONID][value: 4A10F85C449AC245A7195508DC597006][domain: repository.cloudera.com][path: /cloudera/][expiry: null]"". Illegal path attribute ""/cloudera/"". Path of origin: ""/artifactory/cloudera-repos/com/google/appengine/appengine-api-1.0-sdk/""; Cookie rejected: ""[version: 0][name: JSESSIONID][value: 75ED0380B9A0ED0358C2B9666BED71A3][domain: repository.cloudera.com][path: /cloudera/][expiry: null]"". Illegal path attribute ""/cloudera/"". Path of origin: ""/artifactory/cloudera-repos/com/google/guava/guava/""; Cookie rejected: ""[version: 0][name: JSESSIONID][value: 7693D886ED54601AF3EB1333359425D9][domain: repository.cloudera.com][path: /cloudera/][expiry: null]"". Illegal path attribute ""/cloudera/"". Path of origin: ""/artifactory/cloudera-repos/com/google/api-client/google-api-client-appengine/""; Cookie rejected: ""[version: 0][name: JSESSIONID][value: 86B716FE5E36C74ABF85424380AEFC03][domain: repository.cloudera.com][path: /cloudera/][expiry: null]"". Illegal path attribute ""/cloudera/"". Path of origin: ""/artifactory/cloudera-repos/com/google/http-client/google-http-client-jackson2/""; ```. We should figure out if this is a meaningful warning at all, and how to prevent it from happening. @tomwhite Any idea what's causing these messages? Not a high priority but they're mildly annoying.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/610
https://github.com/broadinstitute/gatk/pull/612:662,Modifiability,rewrite,rewrite,662,"This moves all logging to log4j (previously we had a mix of log4j and SAMTools logging). . Questions:There are about 35 places where we were using the SAMTools ProgressLogger, which assumes SAMTools logging. I reproduced that class in hellbender, but implemented the SAMTools ProgressLoggerInterface in order to retain compatibility with SAMWriters, since we use those in a couple of places. The hellbender ProgressLogger class is in utils.runtime, not sure if there is a better place for it. Also I'm not sure how to handle the source code attribution of it since it was lifted from SAMTools but slightly modified for hellbender ? Can I do that or do I need to rewrite it from scratch ?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/612
https://github.com/broadinstitute/gatk/pull/612:15,Testability,log,logging,15,"This moves all logging to log4j (previously we had a mix of log4j and SAMTools logging). . Questions:There are about 35 places where we were using the SAMTools ProgressLogger, which assumes SAMTools logging. I reproduced that class in hellbender, but implemented the SAMTools ProgressLoggerInterface in order to retain compatibility with SAMWriters, since we use those in a couple of places. The hellbender ProgressLogger class is in utils.runtime, not sure if there is a better place for it. Also I'm not sure how to handle the source code attribution of it since it was lifted from SAMTools but slightly modified for hellbender ? Can I do that or do I need to rewrite it from scratch ?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/612
https://github.com/broadinstitute/gatk/pull/612:79,Testability,log,logging,79,"This moves all logging to log4j (previously we had a mix of log4j and SAMTools logging). . Questions:There are about 35 places where we were using the SAMTools ProgressLogger, which assumes SAMTools logging. I reproduced that class in hellbender, but implemented the SAMTools ProgressLoggerInterface in order to retain compatibility with SAMWriters, since we use those in a couple of places. The hellbender ProgressLogger class is in utils.runtime, not sure if there is a better place for it. Also I'm not sure how to handle the source code attribution of it since it was lifted from SAMTools but slightly modified for hellbender ? Can I do that or do I need to rewrite it from scratch ?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/612
https://github.com/broadinstitute/gatk/pull/612:199,Testability,log,logging,199,"This moves all logging to log4j (previously we had a mix of log4j and SAMTools logging). . Questions:There are about 35 places where we were using the SAMTools ProgressLogger, which assumes SAMTools logging. I reproduced that class in hellbender, but implemented the SAMTools ProgressLoggerInterface in order to retain compatibility with SAMWriters, since we use those in a couple of places. The hellbender ProgressLogger class is in utils.runtime, not sure if there is a better place for it. Also I'm not sure how to handle the source code attribution of it since it was lifted from SAMTools but slightly modified for hellbender ? Can I do that or do I need to rewrite it from scratch ?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/612
https://github.com/broadinstitute/gatk/pull/613:31,Deployability,integrat,integrate,31,"Questions: I'm not sure how to integrate the count summary and output from these in hellbender. GATK uses a collection of filters, so it can query each filter individually for a count. Hellbender uses a single filter lambda, which represents a sequence of and'd and or'd filters, so the filter itself needs to report all of the counts based on component filter conditions.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/613
https://github.com/broadinstitute/gatk/pull/613:31,Integrability,integrat,integrate,31,"Questions: I'm not sure how to integrate the count summary and output from these in hellbender. GATK uses a collection of filters, so it can query each filter individually for a count. Hellbender uses a single filter lambda, which represents a sequence of and'd and or'd filters, so the filter itself needs to report all of the counts based on component filter conditions.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/613
https://github.com/broadinstitute/gatk/pull/614:55,Deployability,integrat,integration,55,It is now site-by-site independent (unlike GATK3). All integration tests were ported as is (after ditching the MD5s). The algorithm was changed so that it works on a site-by-site independent basis. Some changes to the engine classes were required to allow queries over intervals in feature data sources. Fixes https://github.com/broadinstitute/hellbender/issues/38,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/614
https://github.com/broadinstitute/gatk/pull/614:55,Integrability,integrat,integration,55,It is now site-by-site independent (unlike GATK3). All integration tests were ported as is (after ditching the MD5s). The algorithm was changed so that it works on a site-by-site independent basis. Some changes to the engine classes were required to allow queries over intervals in feature data sources. Fixes https://github.com/broadinstitute/hellbender/issues/38,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/614
https://github.com/broadinstitute/gatk/pull/614:67,Testability,test,tests,67,It is now site-by-site independent (unlike GATK3). All integration tests were ported as is (after ditching the MD5s). The algorithm was changed so that it works on a site-by-site independent basis. Some changes to the engine classes were required to allow queries over intervals in feature data sources. Fixes https://github.com/broadinstitute/hellbender/issues/38,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/614
https://github.com/broadinstitute/gatk/pull/615:20,Testability,test,tests,20,This fixes the unit tests running on Spark.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/615
https://github.com/broadinstitute/gatk/issues/616:180,Deployability,pipeline,pipeline,180,"the requirement is to port the VariantEval walker and all tests. For now, the combinatorial nature of the eval is to be ported. (later on we may split it into multiple tools and a pipeline)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/616
https://github.com/broadinstitute/gatk/issues/616:58,Testability,test,tests,58,"the requirement is to port the VariantEval walker and all tests. For now, the combinatorial nature of the eval is to be ported. (later on we may split it into multiple tools and a pipeline)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/616
https://github.com/broadinstitute/gatk/issues/617:150,Deployability,Integrat,Integration,150,the requirement is to port DepthOfCoverage or write a new tool that collects coverage information per base (primarily for WGS) and stats as DoC does. Integration tests also need to be ported or created. Current test data is broad-internal but we should move to using public data.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/617
https://github.com/broadinstitute/gatk/issues/617:150,Integrability,Integrat,Integration,150,the requirement is to port DepthOfCoverage or write a new tool that collects coverage information per base (primarily for WGS) and stats as DoC does. Integration tests also need to be ported or created. Current test data is broad-internal but we should move to using public data.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/617
https://github.com/broadinstitute/gatk/issues/617:162,Testability,test,tests,162,the requirement is to port DepthOfCoverage or write a new tool that collects coverage information per base (primarily for WGS) and stats as DoC does. Integration tests also need to be ported or created. Current test data is broad-internal but we should move to using public data.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/617
https://github.com/broadinstitute/gatk/issues/617:211,Testability,test,test,211,the requirement is to port DepthOfCoverage or write a new tool that collects coverage information per base (primarily for WGS) and stats as DoC does. Integration tests also need to be ported or created. Current test data is broad-internal but we should move to using public data.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/617
https://github.com/broadinstitute/gatk/issues/618:265,Integrability,interface,interface,265,"Currently we convert from `GATKRead` to `SAMRecord` whenever we want to write out a SAM/BAM file (see, eg., `PrintReadsDataflowTransform` and `SAMFileGATKReadWriter`). This is wasteful and lossy. Let's write a utility method `toSAMString()`(or add a new `GATKRead` interface method) that can produce a well-formed SAM string from a `GATKRead`. Note that such a method already exists for raw `SAMRecord`s (`getSAMString()`)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/618
https://github.com/broadinstitute/gatk/pull/619:42,Deployability,integrat,integration,42,diff engine port and added hookup for our integration tests; +added PrintVariants as an example variant walker,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/619
https://github.com/broadinstitute/gatk/pull/619:42,Integrability,integrat,integration,42,diff engine port and added hookup for our integration tests; +added PrintVariants as an example variant walker,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/619
https://github.com/broadinstitute/gatk/pull/619:54,Testability,test,tests,54,diff engine port and added hookup for our integration tests; +added PrintVariants as an example variant walker,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/619
https://github.com/broadinstitute/gatk/issues/623:341,Integrability,contract,contract,341,"Currently `GATKRead.copy()` is unable to guarantee a deep copy, since we only have a deep copy method for Google `Read`s (`GenericData.clone()`, which it inherits), not `SAMRecord`s. We should write a deep copy method for `SAMRecord`, hook it up to the `GATKRead.copy()` implementation in `SAMRecordToGATKReadAdapter`, and change the method contract to guarantee that a deep copy will be performed. This is not a huge priority, since `GATKRead` already guarantees that defensive copies will be made of all mutable reference types returned from accessor methods (which means that shallow copies should be safe to use freely), but would be nice for consistency and peace of mind.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/623
https://github.com/broadinstitute/gatk/issues/623:154,Modifiability,inherit,inherits,154,"Currently `GATKRead.copy()` is unable to guarantee a deep copy, since we only have a deep copy method for Google `Read`s (`GenericData.clone()`, which it inherits), not `SAMRecord`s. We should write a deep copy method for `SAMRecord`, hook it up to the `GATKRead.copy()` implementation in `SAMRecordToGATKReadAdapter`, and change the method contract to guarantee that a deep copy will be performed. This is not a huge priority, since `GATKRead` already guarantees that defensive copies will be made of all mutable reference types returned from accessor methods (which means that shallow copies should be safe to use freely), but would be nice for consistency and peace of mind.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/623
https://github.com/broadinstitute/gatk/issues/623:388,Performance,perform,performed,388,"Currently `GATKRead.copy()` is unable to guarantee a deep copy, since we only have a deep copy method for Google `Read`s (`GenericData.clone()`, which it inherits), not `SAMRecord`s. We should write a deep copy method for `SAMRecord`, hook it up to the `GATKRead.copy()` implementation in `SAMRecordToGATKReadAdapter`, and change the method contract to guarantee that a deep copy will be performed. This is not a huge priority, since `GATKRead` already guarantees that defensive copies will be made of all mutable reference types returned from accessor methods (which means that shallow copies should be safe to use freely), but would be nice for consistency and peace of mind.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/623
https://github.com/broadinstitute/gatk/issues/623:604,Safety,safe,safe,604,"Currently `GATKRead.copy()` is unable to guarantee a deep copy, since we only have a deep copy method for Google `Read`s (`GenericData.clone()`, which it inherits), not `SAMRecord`s. We should write a deep copy method for `SAMRecord`, hook it up to the `GATKRead.copy()` implementation in `SAMRecordToGATKReadAdapter`, and change the method contract to guarantee that a deep copy will be performed. This is not a huge priority, since `GATKRead` already guarantees that defensive copies will be made of all mutable reference types returned from accessor methods (which means that shallow copies should be safe to use freely), but would be nice for consistency and peace of mind.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/623
https://github.com/broadinstitute/gatk/issues/623:544,Security,access,accessor,544,"Currently `GATKRead.copy()` is unable to guarantee a deep copy, since we only have a deep copy method for Google `Read`s (`GenericData.clone()`, which it inherits), not `SAMRecord`s. We should write a deep copy method for `SAMRecord`, hook it up to the `GATKRead.copy()` implementation in `SAMRecordToGATKReadAdapter`, and change the method contract to guarantee that a deep copy will be performed. This is not a huge priority, since `GATKRead` already guarantees that defensive copies will be made of all mutable reference types returned from accessor methods (which means that shallow copies should be safe to use freely), but would be nice for consistency and peace of mind.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/623
https://github.com/broadinstitute/gatk/issues/624:87,Energy Efficiency,adapt,adapter,87,"All implementations of `GATKRead` should ideally agree on String representation -- the adapter classes should all implement `toString()`, and do so consistently.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/624
https://github.com/broadinstitute/gatk/issues/624:87,Integrability,adapter,adapter,87,"All implementations of `GATKRead` should ideally agree on String representation -- the adapter classes should all implement `toString()`, and do so consistently.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/624
https://github.com/broadinstitute/gatk/issues/624:87,Modifiability,adapt,adapter,87,"All implementations of `GATKRead` should ideally agree on String representation -- the adapter classes should all implement `toString()`, and do so consistently.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/624
https://github.com/broadinstitute/gatk/issues/625:15,Testability,test,test,15,Re-enable this test once the sequence dictionary work in https://github.com/broadinstitute/hellbender/tree/ek_seqdict_101 is merged. Requires trivial changes to dataflow BQSR.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/625
https://github.com/broadinstitute/gatk/pull/628:291,Availability,down,down,291,"This code adds log statements with ""START"" and ""END"" keywords so that we can then process the logs and see (i) how many times a specific operation was called, (ii) how long the operation took (per call, or in aggregate). In addition it has the notion of intermediate ""steps"" so we can drill down individual operations.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/628
https://github.com/broadinstitute/gatk/pull/628:15,Testability,log,log,15,"This code adds log statements with ""START"" and ""END"" keywords so that we can then process the logs and see (i) how many times a specific operation was called, (ii) how long the operation took (per call, or in aggregate). In addition it has the notion of intermediate ""steps"" so we can drill down individual operations.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/628
https://github.com/broadinstitute/gatk/pull/628:94,Testability,log,logs,94,"This code adds log statements with ""START"" and ""END"" keywords so that we can then process the logs and see (i) how many times a specific operation was called, (ii) how long the operation took (per call, or in aggregate). In addition it has the notion of intermediate ""steps"" so we can drill down individual operations.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/628
https://github.com/broadinstitute/gatk/pull/629:46,Security,validat,validation,46,Finished up the import of sequence dictionary validation.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/629
https://github.com/broadinstitute/gatk/issues/630:142,Energy Efficiency,reduce,reduce,142,PairHMM tests consume about 30% of the test suite runtime. This is probably because they are combinatorial in nature. We should see if we can reduce this intelligently without compromising safety.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/630
https://github.com/broadinstitute/gatk/issues/630:189,Safety,safe,safety,189,PairHMM tests consume about 30% of the test suite runtime. This is probably because they are combinatorial in nature. We should see if we can reduce this intelligently without compromising safety.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/630
https://github.com/broadinstitute/gatk/issues/630:8,Testability,test,tests,8,PairHMM tests consume about 30% of the test suite runtime. This is probably because they are combinatorial in nature. We should see if we can reduce this intelligently without compromising safety.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/630
https://github.com/broadinstitute/gatk/issues/630:39,Testability,test,test,39,PairHMM tests consume about 30% of the test suite runtime. This is probably because they are combinatorial in nature. We should see if we can reduce this intelligently without compromising safety.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/630
https://github.com/broadinstitute/gatk/pull/631:72,Testability,Test,Tests,72,…lean up comments and function names to make the functionality clearer. Tests will be added soon - we need to add more framework for unit testing MarkDuplicatesDataflow and outputting a metrics file; so we can check the number of optical duplicates in tests.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/631
https://github.com/broadinstitute/gatk/pull/631:138,Testability,test,testing,138,…lean up comments and function names to make the functionality clearer. Tests will be added soon - we need to add more framework for unit testing MarkDuplicatesDataflow and outputting a metrics file; so we can check the number of optical duplicates in tests.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/631
https://github.com/broadinstitute/gatk/pull/631:252,Testability,test,tests,252,…lean up comments and function names to make the functionality clearer. Tests will be added soon - we need to add more framework for unit testing MarkDuplicatesDataflow and outputting a metrics file; so we can check the number of optical duplicates in tests.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/631
https://github.com/broadinstitute/gatk/pull/631:63,Usability,clear,clearer,63,…lean up comments and function names to make the functionality clearer. Tests will be added soon - we need to add more framework for unit testing MarkDuplicatesDataflow and outputting a metrics file; so we can check the number of optical duplicates in tests.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/631
https://github.com/broadinstitute/gatk/issues/632:69,Performance,load,loading,69,Right now (in da_genomics_pipeline) VariantsDataSource only supports loading from local files.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/632
https://github.com/broadinstitute/gatk/issues/633:989,Safety,avoid,avoid,989,"Right now we have 9 transforms to remove duplicates :(; We do; (1) pTransform to get PCollection<KV<UUID, UUID>>; (2) remove dupes of (1); (3) GroupByKey of (2) (produces PCollection<UUID,Iterable<UUID>>); (4) create PCollection<UUID, KV<UUID, Beta>>; (5) create KeyedPCollectionTuple of (3) and (4); (6) use (5) to create PCollection<UUID, Iterable<Beta>>; (7) use pKvAB to create PCollection<KV<UUID, Alpha>>; (8) create KeyedPCollectionTuple of (6) and (7); (9) join Alpha back in (using (8)) to get PCollection<Alpha, Iterable<Beta>. Frances suggested roughly the following (which has fewer steps); (1) pTransform to get PCollection<KV<KV<UUID,UUID>, KV<A,B>>>; (2) GroupByKey of (1) to get PCollection<KV<KV<UUID,UUID>, Iterable<KV<A,B>>>>; (3) Make PCollection<KV<UUID, Iterable<KV<A,B>>>; (4) GroupByKey of (3) and get PCollection<KV<UUID, Iterable<Iterable<KV<A,B>>>>; (5) Now back out to get the final result PCollection<KV<A, Iterable<B>>>. Perhaps a better solution would be to avoid having to remove duplicates entirely. The solution would be to find the extent of the longest read and add variants to every shard they overlap (plus a margin of the length of the longest read). The reads would only be mapped to the shard of their start position.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/633
https://github.com/broadinstitute/gatk/pull/635:154,Usability,simpl,simple,154,"The indent there was sometimes 2 spaces, sometimes 4 spaces. The IDE likes to auto-format things sometimes, causing havoc when we're trying to have nice, simple, small commits. One solution is to let the IDE format things its way, so then things are consistent and if someone's IDE takes liberties and auto-formats a function then, well, it has no effect because the function's already the way the IDE likes it. Besides, consistent whitespace makes code easier to read.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/635
https://github.com/broadinstitute/gatk/issues/637:7,Availability,error,errors,7,We get errors like these:. Error: (3760208c5e4fb47a): java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at com.google.cloud.genomics.dataflow.readers.bam.Reader.process(Reader.java:66); at com.google.cloud.genomics.dataflow.readers.bam.ReadBAMTransform$ReadFn.processElement(ReadBAMTransform.java:96),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/637
https://github.com/broadinstitute/gatk/issues/637:27,Availability,Error,Error,27,We get errors like these:. Error: (3760208c5e4fb47a): java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at com.google.cloud.genomics.dataflow.readers.bam.Reader.process(Reader.java:66); at com.google.cloud.genomics.dataflow.readers.bam.ReadBAMTransform$ReadFn.processElement(ReadBAMTransform.java:96),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/637
https://github.com/broadinstitute/gatk/pull/642:13,Testability,test,test,13,Added a unit test to verify that GATKReads are being coded correctly; regardless of backing implementation.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/642
https://github.com/broadinstitute/gatk/issues/647:23,Security,access,access,23,FeatureManager provide access to a feature iterator without querying for a particular interval. This must work without the need for an index file present.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/647
https://github.com/broadinstitute/gatk/issues/650:456,Availability,Error,Error,456,"When we copy a Google read (ie., a `com.google.api.services.genomics.model.Read`), we currently call into the `GenericJson.clone()` method, which uses reflection to deep copy the fields. However, this method seems to incorrectly try to instantiate a `java.util.Arrays$ArrayList` instead of a `java.util.ArrayList`, causing it to blow up during BQSR runs (as reported by @jean-philippe-martin):. ```; [Jul-13 1:36 PM] JP Martin: ; 2015-07-13T17:36:00.151Z: Error: (5361981f0726257c): java.lang.IllegalArgumentException: unable to create new instance of class java.util.Arrays$ArrayList possibly because it is not public; at com.google.api.client.util.Types.handleExceptionForNewInstance(Types.java:165); at com.google.api.client.util.Types.newInstance(Types.java:120); at com.google.api.client.util.Data.clone(Data.java:220); at com.google.api.client.util.Data.deepCopy(Data.java:307); at com.google.api.client.util.Data.clone(Data.java:222); at com.google.api.client.util.Data.deepCopy(Data.java:293); at com.google.api.client.util.GenericData.clone(GenericData.java:172); at com.google.api.client.json.GenericJson.clone(GenericJson.java:90); at com.google.api.services.genomics.model.Read.clone(Read.java:548); at ; org.broadinstitute.hellbender.utils.read.GoogleGenomicsReadToGATKReadAdapter.copy(GoogleGenomicsReadToGATKReadAdapter.java:619); ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/650
https://github.com/broadinstitute/gatk/issues/651:115,Usability,simpl,simple,115,"There should be a package for each top level transform. Right now, transforms are organized haphazardly roughly by simple vs composite.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/651
https://github.com/broadinstitute/gatk/pull/654:44,Availability,error,errors,44,"This should hopefully fix the out of memory errors on CircleCI, although it's hard to test since they happen kind of randomly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/654
https://github.com/broadinstitute/gatk/pull/654:86,Testability,test,test,86,"This should hopefully fix the out of memory errors on CircleCI, although it's hard to test since they happen kind of randomly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/654
https://github.com/broadinstitute/gatk/pull/655:60,Deployability,pipeline,pipeline,60,"This is the barest bones version of the reads preprocessing pipeline. This adds the following:; - loading reference bases from the Google Genomics API; - Joining overlapping variants with reads; - Joining reference bases with reads; - A pipeline outline for reads preprocessing. There PR is ready to get reviewed. Assigning to Louis, but JP will look at Variants and BQSR.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/655
https://github.com/broadinstitute/gatk/pull/655:237,Deployability,pipeline,pipeline,237,"This is the barest bones version of the reads preprocessing pipeline. This adds the following:; - loading reference bases from the Google Genomics API; - Joining overlapping variants with reads; - Joining reference bases with reads; - A pipeline outline for reads preprocessing. There PR is ready to get reviewed. Assigning to Louis, but JP will look at Variants and BQSR.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/655
https://github.com/broadinstitute/gatk/pull/655:98,Performance,load,loading,98,"This is the barest bones version of the reads preprocessing pipeline. This adds the following:; - loading reference bases from the Google Genomics API; - Joining overlapping variants with reads; - Joining reference bases with reads; - A pipeline outline for reads preprocessing. There PR is ready to get reviewed. Assigning to Louis, but JP will look at Variants and BQSR.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/655
https://github.com/broadinstitute/gatk/issues/656:127,Energy Efficiency,schedul,schedule,127,"We don't run the cloud tests on every check-in because they take too long, but we should be running them automatically on some schedule so we catch bugs early rather than late.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/656
https://github.com/broadinstitute/gatk/issues/656:23,Testability,test,tests,23,"We don't run the cloud tests on every check-in because they take too long, but we should be running them automatically on some schedule so we catch bugs early rather than late.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/656
https://github.com/broadinstitute/gatk/issues/658:125,Integrability,wrap,wrap,125,"We have a lot of code in Hellbender that's at its core a simple function, but it needs many lines of Dataflow boilerplate to wrap it into a transform. It would be a great timesaver to create a helper function that goes from function to PTransform. We might for example use it like this:. `PTransform<A,B> myTransform = Map.<A,B>of( a -> new B(a.start+1, a.end));`. references:; lambda syntax: https://docs.oracle.com/javase/tutorial/java/javaOO/lambdaexpressions.html; serializable lambdas: http://stackoverflow.com/questions/22807912/how-to-serialize-a-lambda",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/658
https://github.com/broadinstitute/gatk/issues/658:57,Usability,simpl,simple,57,"We have a lot of code in Hellbender that's at its core a simple function, but it needs many lines of Dataflow boilerplate to wrap it into a transform. It would be a great timesaver to create a helper function that goes from function to PTransform. We might for example use it like this:. `PTransform<A,B> myTransform = Map.<A,B>of( a -> new B(a.start+1, a.end));`. references:; lambda syntax: https://docs.oracle.com/javase/tutorial/java/javaOO/lambdaexpressions.html; serializable lambdas: http://stackoverflow.com/questions/22807912/how-to-serialize-a-lambda",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/658
https://github.com/broadinstitute/gatk/issues/659:36,Security,validat,validation,36,The addition of sequence dictionary validation functionality breaks two tests in ValidateVariantsIntegrationTest. These tests are testBadID and testBadID2_OKif_notInDBSNP.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/659
https://github.com/broadinstitute/gatk/issues/659:81,Security,Validat,ValidateVariantsIntegrationTest,81,The addition of sequence dictionary validation functionality breaks two tests in ValidateVariantsIntegrationTest. These tests are testBadID and testBadID2_OKif_notInDBSNP.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/659
https://github.com/broadinstitute/gatk/issues/659:72,Testability,test,tests,72,The addition of sequence dictionary validation functionality breaks two tests in ValidateVariantsIntegrationTest. These tests are testBadID and testBadID2_OKif_notInDBSNP.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/659
https://github.com/broadinstitute/gatk/issues/659:120,Testability,test,tests,120,The addition of sequence dictionary validation functionality breaks two tests in ValidateVariantsIntegrationTest. These tests are testBadID and testBadID2_OKif_notInDBSNP.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/659
https://github.com/broadinstitute/gatk/issues/659:130,Testability,test,testBadID,130,The addition of sequence dictionary validation functionality breaks two tests in ValidateVariantsIntegrationTest. These tests are testBadID and testBadID2_OKif_notInDBSNP.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/659
https://github.com/broadinstitute/gatk/issues/660:191,Availability,error,error,191,This method (validateSequenceDictionaries) in GATKTool needs to be modified so that the vcf file names associated with each sequence dictionary are passed into validateDictionaries() to make error messages more useful.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/660
https://github.com/broadinstitute/gatk/issues/660:197,Integrability,message,messages,197,This method (validateSequenceDictionaries) in GATKTool needs to be modified so that the vcf file names associated with each sequence dictionary are passed into validateDictionaries() to make error messages more useful.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/660
https://github.com/broadinstitute/gatk/issues/660:13,Security,validat,validateSequenceDictionaries,13,This method (validateSequenceDictionaries) in GATKTool needs to be modified so that the vcf file names associated with each sequence dictionary are passed into validateDictionaries() to make error messages more useful.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/660
https://github.com/broadinstitute/gatk/issues/660:160,Security,validat,validateDictionaries,160,This method (validateSequenceDictionaries) in GATKTool needs to be modified so that the vcf file names associated with each sequence dictionary are passed into validateDictionaries() to make error messages more useful.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/660
https://github.com/broadinstitute/gatk/pull/661:79,Integrability,interface,interface,79,Pileup is going to be needed for variant annotations. Ported over the new read interface. @droazen please review,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/661
https://github.com/broadinstitute/gatk/issues/663:116,Modifiability,extend,extend,116,"Right now, we pair reads with overlapping variants. We can generalize this for any two PCollections of classes that extend Locatable.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/663
https://github.com/broadinstitute/gatk/issues/664:465,Energy Efficiency,reduce,reduce,465,"What we really want in implementations of `Variant`, I think, is what we already have for `GATKRead`: both a strict `equals()` that checks everything including UUID, as well as an `equalsIgnoreUUID()` that checks for value equality and ignores the UUIDs (and allows different implementations of `Variant` to evaluate as equal). While we're at it, we could make both `Variant.equals()` and `Variant.equalsIgnoreUUID()` call into `VariantUtils.variantsAreEqual()` to reduce code duplication.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/664
https://github.com/broadinstitute/gatk/issues/666:22,Testability,test,testing,22,"Right now, we're only testing local files.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/666
https://github.com/broadinstitute/gatk/pull/668:29,Security,validat,validation,29,"Now that sequence dictionary validation is in, we can re-enable this test,; which was previously failing with a java.lang.OutOfMemoryError due to lack; of upfront validation of the reads vs. reference sequence dictionaries.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/668
https://github.com/broadinstitute/gatk/pull/668:163,Security,validat,validation,163,"Now that sequence dictionary validation is in, we can re-enable this test,; which was previously failing with a java.lang.OutOfMemoryError due to lack; of upfront validation of the reads vs. reference sequence dictionaries.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/668
https://github.com/broadinstitute/gatk/pull/668:69,Testability,test,test,69,"Now that sequence dictionary validation is in, we can re-enable this test,; which was previously failing with a java.lang.OutOfMemoryError due to lack; of upfront validation of the reads vs. reference sequence dictionaries.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/668
https://github.com/broadinstitute/gatk/issues/669:66,Performance,perform,performed,66,"All walkers now have comprehensive sequence dictionary validation performed on their inputs (via the `GATKTool` base class, which is aware of all primary tool inputs and so is able to perform this check automatically -- see `GATKTool.validateSequenceDictionaries()`). At present, we need to do this validation manually in dataflow tools, but it would be nice if we could get it to happen automatically in a base class as it does on the walker side of things.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/669
https://github.com/broadinstitute/gatk/issues/669:184,Performance,perform,perform,184,"All walkers now have comprehensive sequence dictionary validation performed on their inputs (via the `GATKTool` base class, which is aware of all primary tool inputs and so is able to perform this check automatically -- see `GATKTool.validateSequenceDictionaries()`). At present, we need to do this validation manually in dataflow tools, but it would be nice if we could get it to happen automatically in a base class as it does on the walker side of things.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/669
https://github.com/broadinstitute/gatk/issues/669:55,Security,validat,validation,55,"All walkers now have comprehensive sequence dictionary validation performed on their inputs (via the `GATKTool` base class, which is aware of all primary tool inputs and so is able to perform this check automatically -- see `GATKTool.validateSequenceDictionaries()`). At present, we need to do this validation manually in dataflow tools, but it would be nice if we could get it to happen automatically in a base class as it does on the walker side of things.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/669
https://github.com/broadinstitute/gatk/issues/669:234,Security,validat,validateSequenceDictionaries,234,"All walkers now have comprehensive sequence dictionary validation performed on their inputs (via the `GATKTool` base class, which is aware of all primary tool inputs and so is able to perform this check automatically -- see `GATKTool.validateSequenceDictionaries()`). At present, we need to do this validation manually in dataflow tools, but it would be nice if we could get it to happen automatically in a base class as it does on the walker side of things.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/669
https://github.com/broadinstitute/gatk/issues/669:299,Security,validat,validation,299,"All walkers now have comprehensive sequence dictionary validation performed on their inputs (via the `GATKTool` base class, which is aware of all primary tool inputs and so is able to perform this check automatically -- see `GATKTool.validateSequenceDictionaries()`). At present, we need to do this validation manually in dataflow tools, but it would be nice if we could get it to happen automatically in a base class as it does on the walker side of things.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/669
https://github.com/broadinstitute/gatk/issues/670:80,Performance,cache,cache,80,"Make the caching in FeatureDataSource more ""window friendly"" (ie., prefetch and cache around the current interval instead of just after it). Came up in the review of https://github.com/broadinstitute/hellbender/pull/614",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/670
https://github.com/broadinstitute/gatk/issues/671:87,Integrability,depend,depending,87,VariantFiltration is hardwired to output vcf - it should be changed to created writers depending on the extension,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/671
https://github.com/broadinstitute/gatk/issues/672:0,Deployability,update,update,0,update `VariantFiltration` code when a version with https://github.com/samtools/htsjdk/pull/273 is released. Argument types can then be changed from `ArrayList` to `List`,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/672
https://github.com/broadinstitute/gatk/issues/672:99,Deployability,release,released,99,update `VariantFiltration` code when a version with https://github.com/samtools/htsjdk/pull/273 is released. Argument types can then be changed from `ArrayList` to `List`,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/672
https://github.com/broadinstitute/gatk/issues/677:144,Availability,down,downloading,144,"Find out if there's a way to disable this awful behavior via `SamReaderFactory` -- if not, let's patch htsjdk itself to turn off reference auto-downloading by default.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/677
https://github.com/broadinstitute/gatk/issues/677:97,Deployability,patch,patch,97,"Find out if there's a way to disable this awful behavior via `SamReaderFactory` -- if not, let's patch htsjdk itself to turn off reference auto-downloading by default.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/677
https://github.com/broadinstitute/gatk/issues/679:73,Availability,error,error,73,"When running BQSR with incompatible references we get an ""out of memory"" error (see #668). This isn't what we were expecting so this issue is a reminder to investigate in case the underlying cause is a bug.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/679
https://github.com/broadinstitute/gatk/issues/680:285,Deployability,integrat,integrate,285,"When we make enhancements to the walker engine (eg., modify the `GATKTool` base class to support CRAM, or to validate the sequence dictionaries of the inputs), it would be good if Spark tools could also reap the benefits of these changes automatically. We may need to unify (or better integrate) the `GATKTool` and `SparkCommandLineProgram` base classes somehow to make this possible, as well as classes like `ReadsDataSource` (for walkers) and `ReadsSparkSource` (for Spark tools).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/680
https://github.com/broadinstitute/gatk/issues/680:285,Integrability,integrat,integrate,285,"When we make enhancements to the walker engine (eg., modify the `GATKTool` base class to support CRAM, or to validate the sequence dictionaries of the inputs), it would be good if Spark tools could also reap the benefits of these changes automatically. We may need to unify (or better integrate) the `GATKTool` and `SparkCommandLineProgram` base classes somehow to make this possible, as well as classes like `ReadsDataSource` (for walkers) and `ReadsSparkSource` (for Spark tools).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/680
https://github.com/broadinstitute/gatk/issues/680:13,Modifiability,enhance,enhancements,13,"When we make enhancements to the walker engine (eg., modify the `GATKTool` base class to support CRAM, or to validate the sequence dictionaries of the inputs), it would be good if Spark tools could also reap the benefits of these changes automatically. We may need to unify (or better integrate) the `GATKTool` and `SparkCommandLineProgram` base classes somehow to make this possible, as well as classes like `ReadsDataSource` (for walkers) and `ReadsSparkSource` (for Spark tools).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/680
https://github.com/broadinstitute/gatk/issues/680:109,Security,validat,validate,109,"When we make enhancements to the walker engine (eg., modify the `GATKTool` base class to support CRAM, or to validate the sequence dictionaries of the inputs), it would be good if Spark tools could also reap the benefits of these changes automatically. We may need to unify (or better integrate) the `GATKTool` and `SparkCommandLineProgram` base classes somehow to make this possible, as well as classes like `ReadsDataSource` (for walkers) and `ReadsSparkSource` (for Spark tools).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/680
https://github.com/broadinstitute/gatk/pull/682:141,Safety,safe,safer,141,Replacing instances of `File.createTempFile` with `BaseTest.createTempFile` since it automatically cleans up it's tmp files and is therefore safer to use. Deleting now extraneous instances of `deleteOnExit`. I left a usage of `File.createTempFile in IOUtils.writeTempResource because it's some thing used only by the`RscriptExcecutor` and I'm afraid it might continue running Rscripts after the java VM shutsdown and will break if we clean up the temp files while it's running. . I Left another usage in `IOUtils.createTempDir`. It's unclear to me if changing the semantics of this method will have any ill effects. We should investigate further. I think we should probably move this method to `BaseTest` as well at some point just for symmetry's sake. Fixes #667,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/682
https://github.com/broadinstitute/gatk/issues/683:148,Deployability,patch,patch,148,The recently-added sequence dictionary validation in `BaseRecalibratorDataflow` does not work when the reference is stored in a bucket -- we should patch it so that it does.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/683
https://github.com/broadinstitute/gatk/issues/683:39,Security,validat,validation,39,The recently-added sequence dictionary validation in `BaseRecalibratorDataflow` does not work when the reference is stored in a bucket -- we should patch it so that it does.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/683
https://github.com/broadinstitute/gatk/issues/684:24,Deployability,pipeline,pipeline,24,"Currently, every single pipeline shows up as ""dataflowcommandlineprogram-jpmartin-(number)"" in the cloud console. It would be helpful if workers could somehow get a name into options.setAppName so it's easier to determine which run is which.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/684
https://github.com/broadinstitute/gatk/pull/685:87,Testability,test,tests,87,we now have a 1+3 matrix which is as follows:. required to pass:; non-cloud non-bucket tests on google dataflow. not required to pass:; non cloud non-bucket tests on spark; cloud and bucket tests on google; cloud and bucket tests on spark. moving TERM out of matrix; setting up service account with guide from https://github.com/GoogleCloudPlatform/appengine-try-python-webapp2/blob/master/.travis.yml; adding install_gcloud.sh copied from a google repo; fixing gs:path; adding key for bucket tests. resolves #656 . Once the google cloud tests are all passing we should move them to the required to pass section,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/685
https://github.com/broadinstitute/gatk/pull/685:157,Testability,test,tests,157,we now have a 1+3 matrix which is as follows:. required to pass:; non-cloud non-bucket tests on google dataflow. not required to pass:; non cloud non-bucket tests on spark; cloud and bucket tests on google; cloud and bucket tests on spark. moving TERM out of matrix; setting up service account with guide from https://github.com/GoogleCloudPlatform/appengine-try-python-webapp2/blob/master/.travis.yml; adding install_gcloud.sh copied from a google repo; fixing gs:path; adding key for bucket tests. resolves #656 . Once the google cloud tests are all passing we should move them to the required to pass section,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/685
https://github.com/broadinstitute/gatk/pull/685:190,Testability,test,tests,190,we now have a 1+3 matrix which is as follows:. required to pass:; non-cloud non-bucket tests on google dataflow. not required to pass:; non cloud non-bucket tests on spark; cloud and bucket tests on google; cloud and bucket tests on spark. moving TERM out of matrix; setting up service account with guide from https://github.com/GoogleCloudPlatform/appengine-try-python-webapp2/blob/master/.travis.yml; adding install_gcloud.sh copied from a google repo; fixing gs:path; adding key for bucket tests. resolves #656 . Once the google cloud tests are all passing we should move them to the required to pass section,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/685
https://github.com/broadinstitute/gatk/pull/685:224,Testability,test,tests,224,we now have a 1+3 matrix which is as follows:. required to pass:; non-cloud non-bucket tests on google dataflow. not required to pass:; non cloud non-bucket tests on spark; cloud and bucket tests on google; cloud and bucket tests on spark. moving TERM out of matrix; setting up service account with guide from https://github.com/GoogleCloudPlatform/appengine-try-python-webapp2/blob/master/.travis.yml; adding install_gcloud.sh copied from a google repo; fixing gs:path; adding key for bucket tests. resolves #656 . Once the google cloud tests are all passing we should move them to the required to pass section,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/685
https://github.com/broadinstitute/gatk/pull/685:493,Testability,test,tests,493,we now have a 1+3 matrix which is as follows:. required to pass:; non-cloud non-bucket tests on google dataflow. not required to pass:; non cloud non-bucket tests on spark; cloud and bucket tests on google; cloud and bucket tests on spark. moving TERM out of matrix; setting up service account with guide from https://github.com/GoogleCloudPlatform/appengine-try-python-webapp2/blob/master/.travis.yml; adding install_gcloud.sh copied from a google repo; fixing gs:path; adding key for bucket tests. resolves #656 . Once the google cloud tests are all passing we should move them to the required to pass section,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/685
https://github.com/broadinstitute/gatk/pull/685:538,Testability,test,tests,538,we now have a 1+3 matrix which is as follows:. required to pass:; non-cloud non-bucket tests on google dataflow. not required to pass:; non cloud non-bucket tests on spark; cloud and bucket tests on google; cloud and bucket tests on spark. moving TERM out of matrix; setting up service account with guide from https://github.com/GoogleCloudPlatform/appengine-try-python-webapp2/blob/master/.travis.yml; adding install_gcloud.sh copied from a google repo; fixing gs:path; adding key for bucket tests. resolves #656 . Once the google cloud tests are all passing we should move them to the required to pass section,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/685
https://github.com/broadinstitute/gatk/pull/685:299,Usability,guid,guide,299,we now have a 1+3 matrix which is as follows:. required to pass:; non-cloud non-bucket tests on google dataflow. not required to pass:; non cloud non-bucket tests on spark; cloud and bucket tests on google; cloud and bucket tests on spark. moving TERM out of matrix; setting up service account with guide from https://github.com/GoogleCloudPlatform/appengine-try-python-webapp2/blob/master/.travis.yml; adding install_gcloud.sh copied from a google repo; fixing gs:path; adding key for bucket tests. resolves #656 . Once the google cloud tests are all passing we should move them to the required to pass section,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/685
https://github.com/broadinstitute/gatk/issues/686:32,Testability,test,test,32,"Right now, we only have a local test.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/686
https://github.com/broadinstitute/gatk/issues/688:17,Testability,test,tests,17,"We need to write tests that have several contigs, unfortunately we can't currently do this with the existing ArtificialReadUtils functions (we can do it for Google Read). This would require making a new artificial header and a few other settings.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/688
https://github.com/broadinstitute/gatk/issues/689:11,Testability,test,tests,11,"All of our tests use contig ""1"". This is fragile, we should add tests that include two contigs. This is not currently possible with ArtificialReadUtils (issue #688).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/689
https://github.com/broadinstitute/gatk/issues/689:64,Testability,test,tests,64,"All of our tests use contig ""1"". This is fragile, we should add tests that include two contigs. This is not currently possible with ArtificialReadUtils (issue #688).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/689
https://github.com/broadinstitute/gatk/issues/690:54,Security,validat,validation,54,came up in review of #614. ; Because of sequence dict validation we needed to hardwire bogus contig lengths in the tests. This issue is about how to resolve this - keep validation and not having to lie about the lengths (and ideally not having to commit the whole reference into the repository).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/690
https://github.com/broadinstitute/gatk/issues/690:169,Security,validat,validation,169,came up in review of #614. ; Because of sequence dict validation we needed to hardwire bogus contig lengths in the tests. This issue is about how to resolve this - keep validation and not having to lie about the lengths (and ideally not having to commit the whole reference into the repository).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/690
https://github.com/broadinstitute/gatk/issues/690:115,Testability,test,tests,115,came up in review of #614. ; Because of sequence dict validation we needed to hardwire bogus contig lengths in the tests. This issue is about how to resolve this - keep validation and not having to lie about the lengths (and ideally not having to commit the whole reference into the repository).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/690
https://github.com/broadinstitute/gatk/issues/692:191,Performance,queue,queue,191,"The requirement here is to write a new type of walker that takes multiple (FeatureInputs) as the driving data type. The engine will then traverse all those at the same time (using a priority queue, @droazen) and present variants to the tool (all variants starting at the given position). The is a prerequisite for GenotypeGVCFs.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/692
https://github.com/broadinstitute/gatk/issues/696:42,Testability,test,tests,42,Should probably be started only after the tests in https://github.com/broadinstitute/hellbender/issues/695 are in place.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/696
https://github.com/broadinstitute/gatk/issues/701:77,Modifiability,variab,variable,77,The client secret file or the api should be able to be set as an environment variable or in a properties file somewhere so they don't have to be entered every single time someone runs a program.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/701
https://github.com/broadinstitute/gatk/issues/702:351,Integrability,interface,interface,351,"Options include:. -Do nothing, and enforce via coding conventions (and hope the dataflow team comes to its senses). -Making a copy of the input before every `apply()` / `processElement()` / etc. (only affects dataflow code, but is inefficient (since it copies even when there's no mutation) and brittle since it only affects tools that go through our interface). -Make our types immutable, and add builders for mutation that perform copies (affects/penalizes non-dataflow code as well, since it will no longer be possible to modify in place). -Have both mutable and immutable views of each type, plus a builder (hard to manage given dataflow's poor support for polymorphism)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/702
https://github.com/broadinstitute/gatk/issues/702:661,Modifiability,polymorphi,polymorphism,661,"Options include:. -Do nothing, and enforce via coding conventions (and hope the dataflow team comes to its senses). -Making a copy of the input before every `apply()` / `processElement()` / etc. (only affects dataflow code, but is inefficient (since it copies even when there's no mutation) and brittle since it only affects tools that go through our interface). -Make our types immutable, and add builders for mutation that perform copies (affects/penalizes non-dataflow code as well, since it will no longer be possible to modify in place). -Have both mutable and immutable views of each type, plus a builder (hard to manage given dataflow's poor support for polymorphism)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/702
https://github.com/broadinstitute/gatk/issues/702:425,Performance,perform,perform,425,"Options include:. -Do nothing, and enforce via coding conventions (and hope the dataflow team comes to its senses). -Making a copy of the input before every `apply()` / `processElement()` / etc. (only affects dataflow code, but is inefficient (since it copies even when there's no mutation) and brittle since it only affects tools that go through our interface). -Make our types immutable, and add builders for mutation that perform copies (affects/penalizes non-dataflow code as well, since it will no longer be possible to modify in place). -Have both mutable and immutable views of each type, plus a builder (hard to manage given dataflow's poor support for polymorphism)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/702
https://github.com/broadinstitute/gatk/pull/704:143,Security,access,accessible,143,Every travis build will upload it's test results to gs://hellbender/test/build_reports/<somepath>. The end of the build log shows the publicly accessible url for the test results.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/704
https://github.com/broadinstitute/gatk/pull/704:36,Testability,test,test,36,Every travis build will upload it's test results to gs://hellbender/test/build_reports/<somepath>. The end of the build log shows the publicly accessible url for the test results.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/704
https://github.com/broadinstitute/gatk/pull/704:68,Testability,test,test,68,Every travis build will upload it's test results to gs://hellbender/test/build_reports/<somepath>. The end of the build log shows the publicly accessible url for the test results.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/704
https://github.com/broadinstitute/gatk/pull/704:120,Testability,log,log,120,Every travis build will upload it's test results to gs://hellbender/test/build_reports/<somepath>. The end of the build log shows the publicly accessible url for the test results.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/704
https://github.com/broadinstitute/gatk/pull/704:166,Testability,test,test,166,Every travis build will upload it's test results to gs://hellbender/test/build_reports/<somepath>. The end of the build log shows the publicly accessible url for the test results.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/704
https://github.com/broadinstitute/gatk/issues/705:124,Availability,avail,available,124,all picard tools should be synched before we go to alpha release. We are now at some version and need to sync to the latest available by the alpha release.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/705
https://github.com/broadinstitute/gatk/issues/705:57,Deployability,release,release,57,all picard tools should be synched before we go to alpha release. We are now at some version and need to sync to the latest available by the alpha release.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/705
https://github.com/broadinstitute/gatk/issues/705:147,Deployability,release,release,147,all picard tools should be synched before we go to alpha release. We are now at some version and need to sync to the latest available by the alpha release.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/705
https://github.com/broadinstitute/gatk/issues/707:10,Testability,test,tests,10,it has no tests and it's a step required only for an obsolete aligner MAQ.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/707
https://github.com/broadinstitute/gatk/issues/714:9,Testability,test,tests,9,add CRAM tests too,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/714
https://github.com/broadinstitute/gatk/issues/715:13,Testability,test,tests,13,include CRAM tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/715
https://github.com/broadinstitute/gatk/pull/730:53,Testability,test,tests,53,fixes #707 . there's no code so I'll just merge when tests pass,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/730
https://github.com/broadinstitute/gatk/issues/739:167,Modifiability,variab,variable,167,"Right now, when we create a bucket-based test, we upload files into `gs://hellbender/test/resources/`, which Travis uses for `HELLBENDER_TEST_INPUTS` (the environment variable used by dataflow tests). These files are currently unversioned, which is bad -- we need to come up with a better way of managing our dataflow test inputs.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/739
https://github.com/broadinstitute/gatk/issues/739:41,Testability,test,test,41,"Right now, when we create a bucket-based test, we upload files into `gs://hellbender/test/resources/`, which Travis uses for `HELLBENDER_TEST_INPUTS` (the environment variable used by dataflow tests). These files are currently unversioned, which is bad -- we need to come up with a better way of managing our dataflow test inputs.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/739
https://github.com/broadinstitute/gatk/issues/739:85,Testability,test,test,85,"Right now, when we create a bucket-based test, we upload files into `gs://hellbender/test/resources/`, which Travis uses for `HELLBENDER_TEST_INPUTS` (the environment variable used by dataflow tests). These files are currently unversioned, which is bad -- we need to come up with a better way of managing our dataflow test inputs.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/739
https://github.com/broadinstitute/gatk/issues/739:193,Testability,test,tests,193,"Right now, when we create a bucket-based test, we upload files into `gs://hellbender/test/resources/`, which Travis uses for `HELLBENDER_TEST_INPUTS` (the environment variable used by dataflow tests). These files are currently unversioned, which is bad -- we need to come up with a better way of managing our dataflow test inputs.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/739
https://github.com/broadinstitute/gatk/issues/739:318,Testability,test,test,318,"Right now, when we create a bucket-based test, we upload files into `gs://hellbender/test/resources/`, which Travis uses for `HELLBENDER_TEST_INPUTS` (the environment variable used by dataflow tests). These files are currently unversioned, which is bad -- we need to come up with a better way of managing our dataflow test inputs.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/739
https://github.com/broadinstitute/gatk/issues/740:35,Security,access,access,35,I think we need someone with admin access to do this.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/740
https://github.com/broadinstitute/gatk/pull/742:70,Deployability,pipeline,pipeline,70,Tests that need to access data in a GCS bucket (but not run an actual pipeline); need a PipelineOptions object containing our API key. This new method makes; it for them.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/742
https://github.com/broadinstitute/gatk/pull/742:88,Deployability,Pipeline,PipelineOptions,88,Tests that need to access data in a GCS bucket (but not run an actual pipeline); need a PipelineOptions object containing our API key. This new method makes; it for them.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/742
https://github.com/broadinstitute/gatk/pull/742:19,Security,access,access,19,Tests that need to access data in a GCS bucket (but not run an actual pipeline); need a PipelineOptions object containing our API key. This new method makes; it for them.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/742
https://github.com/broadinstitute/gatk/pull/742:0,Testability,Test,Tests,0,Tests that need to access data in a GCS bucket (but not run an actual pipeline); need a PipelineOptions object containing our API key. This new method makes; it for them.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/742
https://github.com/broadinstitute/gatk/issues/745:1,Performance,Load,LoadReadsFromFileFn,1,`LoadReadsFromFileFn` has a `ValidationStringency` argument that is currently ignored. This line needs to be changed to pass in a customized SamReaderFactory that respects validation . ```; ReadsDataSource bam = new ReadsDataSource(c.element());; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/745
https://github.com/broadinstitute/gatk/issues/745:29,Security,Validat,ValidationStringency,29,`LoadReadsFromFileFn` has a `ValidationStringency` argument that is currently ignored. This line needs to be changed to pass in a customized SamReaderFactory that respects validation . ```; ReadsDataSource bam = new ReadsDataSource(c.element());; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/745
https://github.com/broadinstitute/gatk/issues/745:172,Security,validat,validation,172,`LoadReadsFromFileFn` has a `ValidationStringency` argument that is currently ignored. This line needs to be changed to pass in a customized SamReaderFactory that respects validation . ```; ReadsDataSource bam = new ReadsDataSource(c.element());; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/745
https://github.com/broadinstitute/gatk/pull/746:75,Usability,Simpl,Simple,75,@lbergelson please review. These are results of running intelliJ cleanups. Simple stuff.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/746
https://github.com/broadinstitute/gatk/pull/747:22,Testability,test,tests,22,"Now, we many Dataflow tests have reads, variants, and reference bases on contig ""2"" as well as ""1"". I also added a useful utility DoFn: PrintCollection.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/747
https://github.com/broadinstitute/gatk/issues/750:514,Availability,Error,Error,514,"The cloud tests are timing out after 10 minutes without emitting any output. It seems like `ApplyBQSRDataflowIntegrationTest.testPR_Cloud` is responsible. It looks like something is crashing in dataflow but the runner is never stopped so it keeps waiting indefinitely (or at least 10 minutes..) See the dataflow log [here](https://console.developers.google.com/project/broad-dsde-dev/dataflow/job/2015-07-24_12_44_26-17415749601435236766). . Executing locally also seems to hang forever, with messages like . ```; Error: (b65a2091061bf0f9): Workflow failed. Causes: (71540087aac21e37): Unable to create VMs. Causes: (71540087aac21994): Error:; Test: Test method testPR_Cloud[0](ApplyBQSR(args=''))(org.broadinstitute.hellbender.tools.walkers.bqsr.ApplyBQSRDataflowIntegrationTest) produced standard out/err: Message: Value for field 'resource.metadata.items[1].value' is too large; ```. Seems like this is possibly a dataflow bug. If the workflow fails in some way the client should be released.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/750
https://github.com/broadinstitute/gatk/issues/750:636,Availability,Error,Error,636,"The cloud tests are timing out after 10 minutes without emitting any output. It seems like `ApplyBQSRDataflowIntegrationTest.testPR_Cloud` is responsible. It looks like something is crashing in dataflow but the runner is never stopped so it keeps waiting indefinitely (or at least 10 minutes..) See the dataflow log [here](https://console.developers.google.com/project/broad-dsde-dev/dataflow/job/2015-07-24_12_44_26-17415749601435236766). . Executing locally also seems to hang forever, with messages like . ```; Error: (b65a2091061bf0f9): Workflow failed. Causes: (71540087aac21e37): Unable to create VMs. Causes: (71540087aac21994): Error:; Test: Test method testPR_Cloud[0](ApplyBQSR(args=''))(org.broadinstitute.hellbender.tools.walkers.bqsr.ApplyBQSRDataflowIntegrationTest) produced standard out/err: Message: Value for field 'resource.metadata.items[1].value' is too large; ```. Seems like this is possibly a dataflow bug. If the workflow fails in some way the client should be released.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/750
https://github.com/broadinstitute/gatk/issues/750:986,Deployability,release,released,986,"The cloud tests are timing out after 10 minutes without emitting any output. It seems like `ApplyBQSRDataflowIntegrationTest.testPR_Cloud` is responsible. It looks like something is crashing in dataflow but the runner is never stopped so it keeps waiting indefinitely (or at least 10 minutes..) See the dataflow log [here](https://console.developers.google.com/project/broad-dsde-dev/dataflow/job/2015-07-24_12_44_26-17415749601435236766). . Executing locally also seems to hang forever, with messages like . ```; Error: (b65a2091061bf0f9): Workflow failed. Causes: (71540087aac21e37): Unable to create VMs. Causes: (71540087aac21994): Error:; Test: Test method testPR_Cloud[0](ApplyBQSR(args=''))(org.broadinstitute.hellbender.tools.walkers.bqsr.ApplyBQSRDataflowIntegrationTest) produced standard out/err: Message: Value for field 'resource.metadata.items[1].value' is too large; ```. Seems like this is possibly a dataflow bug. If the workflow fails in some way the client should be released.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/750
https://github.com/broadinstitute/gatk/issues/750:493,Integrability,message,messages,493,"The cloud tests are timing out after 10 minutes without emitting any output. It seems like `ApplyBQSRDataflowIntegrationTest.testPR_Cloud` is responsible. It looks like something is crashing in dataflow but the runner is never stopped so it keeps waiting indefinitely (or at least 10 minutes..) See the dataflow log [here](https://console.developers.google.com/project/broad-dsde-dev/dataflow/job/2015-07-24_12_44_26-17415749601435236766). . Executing locally also seems to hang forever, with messages like . ```; Error: (b65a2091061bf0f9): Workflow failed. Causes: (71540087aac21e37): Unable to create VMs. Causes: (71540087aac21994): Error:; Test: Test method testPR_Cloud[0](ApplyBQSR(args=''))(org.broadinstitute.hellbender.tools.walkers.bqsr.ApplyBQSRDataflowIntegrationTest) produced standard out/err: Message: Value for field 'resource.metadata.items[1].value' is too large; ```. Seems like this is possibly a dataflow bug. If the workflow fails in some way the client should be released.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/750
https://github.com/broadinstitute/gatk/issues/750:808,Integrability,Message,Message,808,"The cloud tests are timing out after 10 minutes without emitting any output. It seems like `ApplyBQSRDataflowIntegrationTest.testPR_Cloud` is responsible. It looks like something is crashing in dataflow but the runner is never stopped so it keeps waiting indefinitely (or at least 10 minutes..) See the dataflow log [here](https://console.developers.google.com/project/broad-dsde-dev/dataflow/job/2015-07-24_12_44_26-17415749601435236766). . Executing locally also seems to hang forever, with messages like . ```; Error: (b65a2091061bf0f9): Workflow failed. Causes: (71540087aac21e37): Unable to create VMs. Causes: (71540087aac21994): Error:; Test: Test method testPR_Cloud[0](ApplyBQSR(args=''))(org.broadinstitute.hellbender.tools.walkers.bqsr.ApplyBQSRDataflowIntegrationTest) produced standard out/err: Message: Value for field 'resource.metadata.items[1].value' is too large; ```. Seems like this is possibly a dataflow bug. If the workflow fails in some way the client should be released.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/750
https://github.com/broadinstitute/gatk/issues/750:10,Testability,test,tests,10,"The cloud tests are timing out after 10 minutes without emitting any output. It seems like `ApplyBQSRDataflowIntegrationTest.testPR_Cloud` is responsible. It looks like something is crashing in dataflow but the runner is never stopped so it keeps waiting indefinitely (or at least 10 minutes..) See the dataflow log [here](https://console.developers.google.com/project/broad-dsde-dev/dataflow/job/2015-07-24_12_44_26-17415749601435236766). . Executing locally also seems to hang forever, with messages like . ```; Error: (b65a2091061bf0f9): Workflow failed. Causes: (71540087aac21e37): Unable to create VMs. Causes: (71540087aac21994): Error:; Test: Test method testPR_Cloud[0](ApplyBQSR(args=''))(org.broadinstitute.hellbender.tools.walkers.bqsr.ApplyBQSRDataflowIntegrationTest) produced standard out/err: Message: Value for field 'resource.metadata.items[1].value' is too large; ```. Seems like this is possibly a dataflow bug. If the workflow fails in some way the client should be released.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/750
https://github.com/broadinstitute/gatk/issues/750:312,Testability,log,log,312,"The cloud tests are timing out after 10 minutes without emitting any output. It seems like `ApplyBQSRDataflowIntegrationTest.testPR_Cloud` is responsible. It looks like something is crashing in dataflow but the runner is never stopped so it keeps waiting indefinitely (or at least 10 minutes..) See the dataflow log [here](https://console.developers.google.com/project/broad-dsde-dev/dataflow/job/2015-07-24_12_44_26-17415749601435236766). . Executing locally also seems to hang forever, with messages like . ```; Error: (b65a2091061bf0f9): Workflow failed. Causes: (71540087aac21e37): Unable to create VMs. Causes: (71540087aac21994): Error:; Test: Test method testPR_Cloud[0](ApplyBQSR(args=''))(org.broadinstitute.hellbender.tools.walkers.bqsr.ApplyBQSRDataflowIntegrationTest) produced standard out/err: Message: Value for field 'resource.metadata.items[1].value' is too large; ```. Seems like this is possibly a dataflow bug. If the workflow fails in some way the client should be released.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/750
https://github.com/broadinstitute/gatk/issues/750:644,Testability,Test,Test,644,"The cloud tests are timing out after 10 minutes without emitting any output. It seems like `ApplyBQSRDataflowIntegrationTest.testPR_Cloud` is responsible. It looks like something is crashing in dataflow but the runner is never stopped so it keeps waiting indefinitely (or at least 10 minutes..) See the dataflow log [here](https://console.developers.google.com/project/broad-dsde-dev/dataflow/job/2015-07-24_12_44_26-17415749601435236766). . Executing locally also seems to hang forever, with messages like . ```; Error: (b65a2091061bf0f9): Workflow failed. Causes: (71540087aac21e37): Unable to create VMs. Causes: (71540087aac21994): Error:; Test: Test method testPR_Cloud[0](ApplyBQSR(args=''))(org.broadinstitute.hellbender.tools.walkers.bqsr.ApplyBQSRDataflowIntegrationTest) produced standard out/err: Message: Value for field 'resource.metadata.items[1].value' is too large; ```. Seems like this is possibly a dataflow bug. If the workflow fails in some way the client should be released.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/750
https://github.com/broadinstitute/gatk/issues/750:650,Testability,Test,Test,650,"The cloud tests are timing out after 10 minutes without emitting any output. It seems like `ApplyBQSRDataflowIntegrationTest.testPR_Cloud` is responsible. It looks like something is crashing in dataflow but the runner is never stopped so it keeps waiting indefinitely (or at least 10 minutes..) See the dataflow log [here](https://console.developers.google.com/project/broad-dsde-dev/dataflow/job/2015-07-24_12_44_26-17415749601435236766). . Executing locally also seems to hang forever, with messages like . ```; Error: (b65a2091061bf0f9): Workflow failed. Causes: (71540087aac21e37): Unable to create VMs. Causes: (71540087aac21994): Error:; Test: Test method testPR_Cloud[0](ApplyBQSR(args=''))(org.broadinstitute.hellbender.tools.walkers.bqsr.ApplyBQSRDataflowIntegrationTest) produced standard out/err: Message: Value for field 'resource.metadata.items[1].value' is too large; ```. Seems like this is possibly a dataflow bug. If the workflow fails in some way the client should be released.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/750
https://github.com/broadinstitute/gatk/issues/751:33,Testability,test,tests,33,A number of the cloud and bucket tests are failing on google dataflow. These need to be fixed. ; #750 is a pre-requisite. Once the tests are fixed we should make these tests mandatory.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/751
https://github.com/broadinstitute/gatk/issues/751:131,Testability,test,tests,131,A number of the cloud and bucket tests are failing on google dataflow. These need to be fixed. ; #750 is a pre-requisite. Once the tests are fixed we should make these tests mandatory.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/751
https://github.com/broadinstitute/gatk/issues/751:168,Testability,test,tests,168,A number of the cloud and bucket tests are failing on google dataflow. These need to be fixed. ; #750 is a pre-requisite. Once the tests are fixed we should make these tests mandatory.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/751
https://github.com/broadinstitute/gatk/pull/753:58,Testability,log,logging,58,"Profiling is easier when the stages have names and output logging information. Keeping my branch as close as possible to 'master' means merges are easier, both ways.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/753
https://github.com/broadinstitute/gatk/issues/754:260,Availability,error,error,260,"This isn't just a matter of changing the number. [RegisterCoder was made more stringent](https://cloud.google.com/dataflow/release-notes/java) and this will force some code changes. Hopefully only little ones, but I got only as far as getting an internal Java error and I think that's a sign I should go to bed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/754
https://github.com/broadinstitute/gatk/issues/754:123,Deployability,release,release-notes,123,"This isn't just a matter of changing the number. [RegisterCoder was made more stringent](https://cloud.google.com/dataflow/release-notes/java) and this will force some code changes. Hopefully only little ones, but I got only as far as getting an internal Java error and I think that's a sign I should go to bed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/754
https://github.com/broadinstitute/gatk/issues/755:365,Testability,test,tests,365,"We should read the CRAM spec (http://samtools.github.io/hts-specs/CRAMv3.pdf) to find out:; 1. Whether CRAM files **always** require a reference, or only sometimes based on the compression used (needed for https://github.com/broadinstitute/hellbender/issues/673); 2. When CRAM compression is lossy vs. lossless (we need to understand this so that when we write the tests for https://github.com/broadinstitute/hellbender/issues/590, we can convert our existing BAMs to CRAM without losing any information).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/755
https://github.com/broadinstitute/gatk/issues/756:81,Performance,perform,performance,81,"From an analysis by @jean-philippe-martin:. **The Problem**. Doing a preliminary performance analysis of Hellbender, I found that ReadBAM did not scale with the number of workers. ![image](https://cloud.githubusercontent.com/assets/798637/8913030/757d9552-3464-11e5-8244-46931fed8383.png). Logs indicated it was running on a single worker, regardless of how many were specified for the job. **The Cause**. The underlying cause is a combination of ReadBAM's design and Dataflow's own perhaps over-eager optimization. ReadBAM is implemented as a series of transforms. It could also have been implemented as a Dataflow BoundedSource, but the latter is much more complicated. The transforms are as follows:; Start with a collection of filenames and a collection of contigs.; Transform 1 -- input: filenames, side input: contigs. Generates a list of regions to read (""BAMShard""); Transform 2 -- input: `PCollection<BAMShard>`, output: `PCollection<Read>`. Each worker reads from the BAM file, using the index to find where to read from. Dataflow sees that transform 2 takes as input transform 1's output, and so these two can be run in sequence on the same machines, skipping a serialization/deserialization step. This optimization is called ""fusing"" and it's generally a very good thing. However in this case, the input PCollection has a single element (the file we want to read), so only one worker is involved. Because of the fusion, that same worker then ends up doing all of the reading work, ruining our day. **The Solutions**. There are multiple ways to solve this problem. ; 1. change transform 1 to have the contig collection as a primary input in the hope that we always have more than one contig. ; This solution's very brittle (our benchmark, for example, reads a single chromosome so the contig list has effectively only one element). I did not pursue it.; 2. Insert a groupby step between the two transforms.; pro: this gets all the workers involved again; con: the groupby itself takes some ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/756
https://github.com/broadinstitute/gatk/issues/756:502,Performance,optimiz,optimization,502,"From an analysis by @jean-philippe-martin:. **The Problem**. Doing a preliminary performance analysis of Hellbender, I found that ReadBAM did not scale with the number of workers. ![image](https://cloud.githubusercontent.com/assets/798637/8913030/757d9552-3464-11e5-8244-46931fed8383.png). Logs indicated it was running on a single worker, regardless of how many were specified for the job. **The Cause**. The underlying cause is a combination of ReadBAM's design and Dataflow's own perhaps over-eager optimization. ReadBAM is implemented as a series of transforms. It could also have been implemented as a Dataflow BoundedSource, but the latter is much more complicated. The transforms are as follows:; Start with a collection of filenames and a collection of contigs.; Transform 1 -- input: filenames, side input: contigs. Generates a list of regions to read (""BAMShard""); Transform 2 -- input: `PCollection<BAMShard>`, output: `PCollection<Read>`. Each worker reads from the BAM file, using the index to find where to read from. Dataflow sees that transform 2 takes as input transform 1's output, and so these two can be run in sequence on the same machines, skipping a serialization/deserialization step. This optimization is called ""fusing"" and it's generally a very good thing. However in this case, the input PCollection has a single element (the file we want to read), so only one worker is involved. Because of the fusion, that same worker then ends up doing all of the reading work, ruining our day. **The Solutions**. There are multiple ways to solve this problem. ; 1. change transform 1 to have the contig collection as a primary input in the hope that we always have more than one contig. ; This solution's very brittle (our benchmark, for example, reads a single chromosome so the contig list has effectively only one element). I did not pursue it.; 2. Insert a groupby step between the two transforms.; pro: this gets all the workers involved again; con: the groupby itself takes some ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/756
https://github.com/broadinstitute/gatk/issues/756:1214,Performance,optimiz,optimization,1214,"0/757d9552-3464-11e5-8244-46931fed8383.png). Logs indicated it was running on a single worker, regardless of how many were specified for the job. **The Cause**. The underlying cause is a combination of ReadBAM's design and Dataflow's own perhaps over-eager optimization. ReadBAM is implemented as a series of transforms. It could also have been implemented as a Dataflow BoundedSource, but the latter is much more complicated. The transforms are as follows:; Start with a collection of filenames and a collection of contigs.; Transform 1 -- input: filenames, side input: contigs. Generates a list of regions to read (""BAMShard""); Transform 2 -- input: `PCollection<BAMShard>`, output: `PCollection<Read>`. Each worker reads from the BAM file, using the index to find where to read from. Dataflow sees that transform 2 takes as input transform 1's output, and so these two can be run in sequence on the same machines, skipping a serialization/deserialization step. This optimization is called ""fusing"" and it's generally a very good thing. However in this case, the input PCollection has a single element (the file we want to read), so only one worker is involved. Because of the fusion, that same worker then ends up doing all of the reading work, ruining our day. **The Solutions**. There are multiple ways to solve this problem. ; 1. change transform 1 to have the contig collection as a primary input in the hope that we always have more than one contig. ; This solution's very brittle (our benchmark, for example, reads a single chromosome so the contig list has effectively only one element). I did not pursue it.; 2. Insert a groupby step between the two transforms.; pro: this gets all the workers involved again; con: the groupby itself takes some time, unnecessarily.; 3. Compute the BAMShards at the client and then send those to workers.; pro: this gets all the workers involved again, and they do not have to spend any time on groupby; con: an existing Dataflow bug will cause the program ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/756
https://github.com/broadinstitute/gatk/issues/756:290,Testability,Log,Logs,290,"From an analysis by @jean-philippe-martin:. **The Problem**. Doing a preliminary performance analysis of Hellbender, I found that ReadBAM did not scale with the number of workers. ![image](https://cloud.githubusercontent.com/assets/798637/8913030/757d9552-3464-11e5-8244-46931fed8383.png). Logs indicated it was running on a single worker, regardless of how many were specified for the job. **The Cause**. The underlying cause is a combination of ReadBAM's design and Dataflow's own perhaps over-eager optimization. ReadBAM is implemented as a series of transforms. It could also have been implemented as a Dataflow BoundedSource, but the latter is much more complicated. The transforms are as follows:; Start with a collection of filenames and a collection of contigs.; Transform 1 -- input: filenames, side input: contigs. Generates a list of regions to read (""BAMShard""); Transform 2 -- input: `PCollection<BAMShard>`, output: `PCollection<Read>`. Each worker reads from the BAM file, using the index to find where to read from. Dataflow sees that transform 2 takes as input transform 1's output, and so these two can be run in sequence on the same machines, skipping a serialization/deserialization step. This optimization is called ""fusing"" and it's generally a very good thing. However in this case, the input PCollection has a single element (the file we want to read), so only one worker is involved. Because of the fusion, that same worker then ends up doing all of the reading work, ruining our day. **The Solutions**. There are multiple ways to solve this problem. ; 1. change transform 1 to have the contig collection as a primary input in the hope that we always have more than one contig. ; This solution's very brittle (our benchmark, for example, reads a single chromosome so the contig list has effectively only one element). I did not pursue it.; 2. Insert a groupby step between the two transforms.; pro: this gets all the workers involved again; con: the groupby itself takes some ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/756
https://github.com/broadinstitute/gatk/issues/756:1739,Testability,benchmark,benchmark,1739,"ransform 1 -- input: filenames, side input: contigs. Generates a list of regions to read (""BAMShard""); Transform 2 -- input: `PCollection<BAMShard>`, output: `PCollection<Read>`. Each worker reads from the BAM file, using the index to find where to read from. Dataflow sees that transform 2 takes as input transform 1's output, and so these two can be run in sequence on the same machines, skipping a serialization/deserialization step. This optimization is called ""fusing"" and it's generally a very good thing. However in this case, the input PCollection has a single element (the file we want to read), so only one worker is involved. Because of the fusion, that same worker then ends up doing all of the reading work, ruining our day. **The Solutions**. There are multiple ways to solve this problem. ; 1. change transform 1 to have the contig collection as a primary input in the hope that we always have more than one contig. ; This solution's very brittle (our benchmark, for example, reads a single chromosome so the contig list has effectively only one element). I did not pursue it.; 2. Insert a groupby step between the two transforms.; pro: this gets all the workers involved again; con: the groupby itself takes some time, unnecessarily.; 3. Compute the BAMShards at the client and then send those to workers.; pro: this gets all the workers involved again, and they do not have to spend any time on groupby; con: an existing Dataflow bug will cause the program to crash if the shard list is too long. We can work around this, though, by increasing the shard size when we have many.; 4. Bite the bullet and implement a BoundedSource. I implemented solutions 2 and 3. Solution 3 is the fastest. I suspect solution 4 wouldn't be any faster, though it would be more idiomatic for Dataflow. The graph below shows the time in the Dataflow Read phase with the new code when using the groupby method (this includes sharding, groupby, and actually reading the BAM file). ![image](https://cloud.gi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/756
https://github.com/broadinstitute/gatk/issues/756:3118,Testability,test,testing,3118,"erialization step. This optimization is called ""fusing"" and it's generally a very good thing. However in this case, the input PCollection has a single element (the file we want to read), so only one worker is involved. Because of the fusion, that same worker then ends up doing all of the reading work, ruining our day. **The Solutions**. There are multiple ways to solve this problem. ; 1. change transform 1 to have the contig collection as a primary input in the hope that we always have more than one contig. ; This solution's very brittle (our benchmark, for example, reads a single chromosome so the contig list has effectively only one element). I did not pursue it.; 2. Insert a groupby step between the two transforms.; pro: this gets all the workers involved again; con: the groupby itself takes some time, unnecessarily.; 3. Compute the BAMShards at the client and then send those to workers.; pro: this gets all the workers involved again, and they do not have to spend any time on groupby; con: an existing Dataflow bug will cause the program to crash if the shard list is too long. We can work around this, though, by increasing the shard size when we have many.; 4. Bite the bullet and implement a BoundedSource. I implemented solutions 2 and 3. Solution 3 is the fastest. I suspect solution 4 wouldn't be any faster, though it would be more idiomatic for Dataflow. The graph below shows the time in the Dataflow Read phase with the new code when using the groupby method (this includes sharding, groupby, and actually reading the BAM file). ![image](https://cloud.githubusercontent.com/assets/798637/8913044/8db099d0-3464-11e5-8ee3-f2cbebb6ce2b.png). Next Steps. The next step is to pick either solution 3 or 4 (or 2, I suppose, if we want to be expedient). If 3, then we need to change the sharding to deal with large files. If 4, then we need to spend the time and effort writing the new source (and of course testing that it scales as we're expecting). Comments & feedback welcome!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/756
https://github.com/broadinstitute/gatk/issues/756:3173,Usability,feedback,feedback,3173,"erialization step. This optimization is called ""fusing"" and it's generally a very good thing. However in this case, the input PCollection has a single element (the file we want to read), so only one worker is involved. Because of the fusion, that same worker then ends up doing all of the reading work, ruining our day. **The Solutions**. There are multiple ways to solve this problem. ; 1. change transform 1 to have the contig collection as a primary input in the hope that we always have more than one contig. ; This solution's very brittle (our benchmark, for example, reads a single chromosome so the contig list has effectively only one element). I did not pursue it.; 2. Insert a groupby step between the two transforms.; pro: this gets all the workers involved again; con: the groupby itself takes some time, unnecessarily.; 3. Compute the BAMShards at the client and then send those to workers.; pro: this gets all the workers involved again, and they do not have to spend any time on groupby; con: an existing Dataflow bug will cause the program to crash if the shard list is too long. We can work around this, though, by increasing the shard size when we have many.; 4. Bite the bullet and implement a BoundedSource. I implemented solutions 2 and 3. Solution 3 is the fastest. I suspect solution 4 wouldn't be any faster, though it would be more idiomatic for Dataflow. The graph below shows the time in the Dataflow Read phase with the new code when using the groupby method (this includes sharding, groupby, and actually reading the BAM file). ![image](https://cloud.githubusercontent.com/assets/798637/8913044/8db099d0-3464-11e5-8ee3-f2cbebb6ce2b.png). Next Steps. The next step is to pick either solution 3 or 4 (or 2, I suppose, if we want to be expedient). If 3, then we need to change the sharding to deal with large files. If 4, then we need to spend the time and effort writing the new source (and of course testing that it scales as we're expecting). Comments & feedback welcome!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/756
https://github.com/broadinstitute/gatk/issues/758:193,Deployability,update,update,193,This is a bit of a pain because the sam files produce by htsjdk now all say they're version 1.5. We need to rewrite our sam/bam files to be compliant with the new version (or at the very least update the version strings. ) Alternatively we could change the comparator to ignore versions when comparing.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/758
https://github.com/broadinstitute/gatk/issues/758:108,Modifiability,rewrite,rewrite,108,This is a bit of a pain because the sam files produce by htsjdk now all say they're version 1.5. We need to rewrite our sam/bam files to be compliant with the new version (or at the very least update the version strings. ) Alternatively we could change the comparator to ignore versions when comparing.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/758
https://github.com/broadinstitute/gatk/pull/759:49,Modifiability,refactor,refactoring,49,This is a strict copy-paste job. I'll do further refactoring after this. I'm doing this in two steps so it's easier to read the diffs.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/759
https://github.com/broadinstitute/gatk/pull/760:24,Testability,test,tests,24,run cloud and non cloud tests together with gradle testAll!,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/760
https://github.com/broadinstitute/gatk/pull/760:51,Testability,test,testAll,51,run cloud and non cloud tests together with gradle testAll!,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/760
https://github.com/broadinstitute/gatk/issues/761:48,Deployability,pipeline,pipeline,48,"Doesn't have to check output, just run the full pipeline.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/761
https://github.com/broadinstitute/gatk/issues/762:0,Testability,Test,Tests,0,Tests are writing `.dot` files to the hellbender root directory and not cleaning them up. I'm guessing it's the haplotype assembly tests. ex `fred.dot`,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/762
https://github.com/broadinstitute/gatk/issues/762:131,Testability,test,tests,131,Tests are writing `.dot` files to the hellbender root directory and not cleaning them up. I'm guessing it's the haplotype assembly tests. ex `fred.dot`,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/762
https://github.com/broadinstitute/gatk/pull/763:194,Availability,error,error,194,"updating bams, sams, and cram to sam spec version 1.5 (some invalid bams were not updated); updated interval list headers for bed tests from v 1.4 - 1.5; updating several tests to give a better error message if an index IS present when it's expected to not be",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/763
https://github.com/broadinstitute/gatk/pull/763:82,Deployability,update,updated,82,"updating bams, sams, and cram to sam spec version 1.5 (some invalid bams were not updated); updated interval list headers for bed tests from v 1.4 - 1.5; updating several tests to give a better error message if an index IS present when it's expected to not be",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/763
https://github.com/broadinstitute/gatk/pull/763:92,Deployability,update,updated,92,"updating bams, sams, and cram to sam spec version 1.5 (some invalid bams were not updated); updated interval list headers for bed tests from v 1.4 - 1.5; updating several tests to give a better error message if an index IS present when it's expected to not be",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/763
https://github.com/broadinstitute/gatk/pull/763:200,Integrability,message,message,200,"updating bams, sams, and cram to sam spec version 1.5 (some invalid bams were not updated); updated interval list headers for bed tests from v 1.4 - 1.5; updating several tests to give a better error message if an index IS present when it's expected to not be",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/763
https://github.com/broadinstitute/gatk/pull/763:130,Testability,test,tests,130,"updating bams, sams, and cram to sam spec version 1.5 (some invalid bams were not updated); updated interval list headers for bed tests from v 1.4 - 1.5; updating several tests to give a better error message if an index IS present when it's expected to not be",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/763
https://github.com/broadinstitute/gatk/pull/763:171,Testability,test,tests,171,"updating bams, sams, and cram to sam spec version 1.5 (some invalid bams were not updated); updated interval list headers for bed tests from v 1.4 - 1.5; updating several tests to give a better error message if an index IS present when it's expected to not be",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/763
https://github.com/broadinstitute/gatk/issues/766:183,Testability,test,tests,183,"It appears that when we try to write out a CRAM file in hellbender from input that contains an unmapped read, we produce a malformed CRAM. We need to fix this before we can write the tests in https://github.com/broadinstitute/hellbender/issues/675 and https://github.com/broadinstitute/hellbender/issues/590. To replicate, take a BAM file containing an unmapped read (eg., `src/test/resources/org/broadinstitute/hellbender/tools/print_reads.bam`), run it through hellbender's `PrintReads` with the output set to cram, then run `samtools view` on the resulting cram file.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/766
https://github.com/broadinstitute/gatk/issues/766:378,Testability,test,test,378,"It appears that when we try to write out a CRAM file in hellbender from input that contains an unmapped read, we produce a malformed CRAM. We need to fix this before we can write the tests in https://github.com/broadinstitute/hellbender/issues/675 and https://github.com/broadinstitute/hellbender/issues/590. To replicate, take a BAM file containing an unmapped read (eg., `src/test/resources/org/broadinstitute/hellbender/tools/print_reads.bam`), run it through hellbender's `PrintReads` with the output set to cram, then run `samtools view` on the resulting cram file.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/766
https://github.com/broadinstitute/gatk/pull/770:88,Modifiability,refactor,refactoring,88,I moved Mark duplicates into it's own package (instead of a single file). There is more refactoring that could be done. I might stop here for now and sync with @jean-philippe-martin on his planned changes.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/770
https://github.com/broadinstitute/gatk/issues/771:132,Testability,test,test,132,"Until https://github.com/broadinstitute/hellbender/issues/621 is implemented, we need a quick hack for this in order to effectively test the `ReadsPreprocessingPipeline`:. -Need a way of converting GATKRead -> SAM record line (https://github.com/broadinstitute/hellbender/issues/618). -Add option to ReadsPreprocessingPipeline to bypass `SmallBamWriter` and instead apply a `PCollection<GATKRead>` -> `PCollection<String>` transform, do a `TextIO.Write().to(output).withSuffix()` (might need to disable sharding), then prepend a header, then sort the sam and convert to bam.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/771
https://github.com/broadinstitute/gatk/pull/772:148,Deployability,update,update,148,Just checks that the input and output bams are equal (which is still the; case for a bam with no duplicates). Once BQSR is hooked up we'll have; to update the expected output for this test. This is intended as a starting point for the more meaningful tests we; eventually want to have.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/772
https://github.com/broadinstitute/gatk/pull/772:184,Testability,test,test,184,Just checks that the input and output bams are equal (which is still the; case for a bam with no duplicates). Once BQSR is hooked up we'll have; to update the expected output for this test. This is intended as a starting point for the more meaningful tests we; eventually want to have.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/772
https://github.com/broadinstitute/gatk/pull/772:251,Testability,test,tests,251,Just checks that the input and output bams are equal (which is still the; case for a bam with no duplicates). Once BQSR is hooked up we'll have; to update the expected output for this test. This is intended as a starting point for the more meaningful tests we; eventually want to have.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/772
https://github.com/broadinstitute/gatk/issues/774:25,Testability,test,testGetInvalidPCollectionLocal,25,`ReadsDataflowSourceTest.testGetInvalidPCollectionLocal()` is failing with an exception. ```; java.lang.OutOfMemoryError: GC overhead limit exceeded; at java.util.Arrays.copyOf(Arrays.java:3332); at java.lang.AbstractStringBuilder.expandCapacity(AbstractStringBuilder.java:137); at java.lang.AbstractStringBuilder.ensureCapacityInternal(AbstractStringBuilder.java:121); at java.lang.AbstractStringBuilder.append(AbstractStringBuilder.java:569); at java.lang.StringBuilder.append(StringBuilder.java:190); at java.io.ObjectInputStream$BlockDataInputStream.readUTFSpan(ObjectInputStream.java:3147); at java.io.ObjectInputStream$BlockDataInputStream.readUTFBody(ObjectInputStream.java:3055); at java.io.ObjectInputStream$BlockDataInputStream.readLongUTF(ObjectInputStream.java:3038); at java.io.ObjectInputStream.readString(ObjectInputStream.java:1643); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1342); at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1993); at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1918); at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1801); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1351); at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1993); at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1918); at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1801); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1351); at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1993); at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1918); at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1801); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1351); at java.io.ObjectInputStream.readObject(ObjectInputStream.java:371); at com.google.cloud.dataflow.sdk.coders.SerializableCoder.decode(SerializableCoder.java:124); at org.broadinsti,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/774
https://github.com/broadinstitute/gatk/pull/775:128,Availability,down,downgrade,128,fixes #754. updating spark along side the dataflow jump; also updating other dependencies as well. changing GatkTestPipeline to downgrade a naming error to a warning; replacing calls to setName; replacing calls to setCoder with calls to withCoder when possible. hooking up the validation stringency for local files; fixes #745. disabling failing test and opening #774 to reenable it,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/775
https://github.com/broadinstitute/gatk/pull/775:147,Availability,error,error,147,fixes #754. updating spark along side the dataflow jump; also updating other dependencies as well. changing GatkTestPipeline to downgrade a naming error to a warning; replacing calls to setName; replacing calls to setCoder with calls to withCoder when possible. hooking up the validation stringency for local files; fixes #745. disabling failing test and opening #774 to reenable it,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/775
https://github.com/broadinstitute/gatk/pull/775:77,Integrability,depend,dependencies,77,fixes #754. updating spark along side the dataflow jump; also updating other dependencies as well. changing GatkTestPipeline to downgrade a naming error to a warning; replacing calls to setName; replacing calls to setCoder with calls to withCoder when possible. hooking up the validation stringency for local files; fixes #745. disabling failing test and opening #774 to reenable it,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/775
https://github.com/broadinstitute/gatk/pull/775:277,Security,validat,validation,277,fixes #754. updating spark along side the dataflow jump; also updating other dependencies as well. changing GatkTestPipeline to downgrade a naming error to a warning; replacing calls to setName; replacing calls to setCoder with calls to withCoder when possible. hooking up the validation stringency for local files; fixes #745. disabling failing test and opening #774 to reenable it,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/775
https://github.com/broadinstitute/gatk/pull/775:346,Testability,test,test,346,fixes #754. updating spark along side the dataflow jump; also updating other dependencies as well. changing GatkTestPipeline to downgrade a naming error to a warning; replacing calls to setName; replacing calls to setCoder with calls to withCoder when possible. hooking up the validation stringency for local files; fixes #745. disabling failing test and opening #774 to reenable it,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/775
https://github.com/broadinstitute/gatk/issues/778:8,Testability,log,logarithms,8,Base 10 logarithms are ugly.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/778
https://github.com/broadinstitute/gatk/issues/779:432,Availability,down,download,432,"@davidbenjamin Discovered that importing hellbender as a dependency fails now that we have add spark dependencies. This is easily fixed by including the following (or it's non-gradle equivalent) in your build file, but it shouldn't be necessary. ```; maven {; url ""https://repository.cloudera.com/artifactory/cloudera-repos/"" // spark-dataflow; }; ```. We should update our artifact so that it includes the necessary information to download the spark dependencies.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/779
https://github.com/broadinstitute/gatk/issues/779:363,Deployability,update,update,363,"@davidbenjamin Discovered that importing hellbender as a dependency fails now that we have add spark dependencies. This is easily fixed by including the following (or it's non-gradle equivalent) in your build file, but it shouldn't be necessary. ```; maven {; url ""https://repository.cloudera.com/artifactory/cloudera-repos/"" // spark-dataflow; }; ```. We should update our artifact so that it includes the necessary information to download the spark dependencies.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/779
https://github.com/broadinstitute/gatk/issues/779:57,Integrability,depend,dependency,57,"@davidbenjamin Discovered that importing hellbender as a dependency fails now that we have add spark dependencies. This is easily fixed by including the following (or it's non-gradle equivalent) in your build file, but it shouldn't be necessary. ```; maven {; url ""https://repository.cloudera.com/artifactory/cloudera-repos/"" // spark-dataflow; }; ```. We should update our artifact so that it includes the necessary information to download the spark dependencies.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/779
https://github.com/broadinstitute/gatk/issues/779:101,Integrability,depend,dependencies,101,"@davidbenjamin Discovered that importing hellbender as a dependency fails now that we have add spark dependencies. This is easily fixed by including the following (or it's non-gradle equivalent) in your build file, but it shouldn't be necessary. ```; maven {; url ""https://repository.cloudera.com/artifactory/cloudera-repos/"" // spark-dataflow; }; ```. We should update our artifact so that it includes the necessary information to download the spark dependencies.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/779
https://github.com/broadinstitute/gatk/issues/779:451,Integrability,depend,dependencies,451,"@davidbenjamin Discovered that importing hellbender as a dependency fails now that we have add spark dependencies. This is easily fixed by including the following (or it's non-gradle equivalent) in your build file, but it shouldn't be necessary. ```; maven {; url ""https://repository.cloudera.com/artifactory/cloudera-repos/"" // spark-dataflow; }; ```. We should update our artifact so that it includes the necessary information to download the spark dependencies.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/779
https://github.com/broadinstitute/gatk/pull/780:61,Security,expose,exposed,61,I noticed some classes that were unused in hellbender.; This exposed some others that were only referenced by unused classes. Made slight cosmetic modification to OpticalDuplicateFinder as well,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/780
https://github.com/broadinstitute/gatk/issues/781:676,Modifiability,enhance,enhancement,676,"User writes: . > It's great that the GATK walkers can follow symlinks to bam files. But I've never understood, why GATK UG and HC can't look for the index file in the same location as the bam. Instead one has to also create symlinks to the index files in the same location as the symlinks to the bam files. This prevents one from using as input a file with bam symlinks. There are several ways to work around this, but it's just such an annoying obstacle, which I run into every 3 or 6 months, because I forget about this behaviour. Please please fix and you can come and raid my mini fridge at work full of chocolate (currently also holds LEGO). If you choose to ignore this enhancement request, then GATK is still a pretty good tool :). Sounds legit to me. Not something I think is worth spending time on in GATK3, but sounds like a reasonable feature request for 4. This Issue was generated from your [forums](http://gatkforums.broadinstitute.org/discussion/5944/symlinks-to-bam-files/p1)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/781
https://github.com/broadinstitute/gatk/pull/785:5,Deployability,upgrade,upgrades,5,This upgrades Spark Dataflow to the correct version of Dataflow (Spark Dataflow 0.3.0 targets 0.4.150710). This fixes the runtime exception when running Spark tests due to library mismatches.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/785
https://github.com/broadinstitute/gatk/pull/785:159,Testability,test,tests,159,This upgrades Spark Dataflow to the correct version of Dataflow (Spark Dataflow 0.3.0 targets 0.4.150710). This fixes the runtime exception when running Spark tests due to library mismatches.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/785
https://github.com/broadinstitute/gatk/pull/789:247,Testability,test,tests,247,-Can now request arbitrary windows of reference bases for each read in AddContextDataToRead. -Wrote a reference window function for BQSR that retrieves for each read exactly the reference; bases required by the BQSR algorithm. -Comprehensive unit tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/789
https://github.com/broadinstitute/gatk/issues/791:471,Availability,error,error,471,"When [ReadsDataflowSource.getReadPCollection](https://github.com/broadinstitute/hellbender/blob/master/src/main/java/org/broadinstitute/hellbender/engine/dataflow/datasources/ReadsDataflowSource.java#L129) calls Google Dataflow's [ReadBAMTransform.getReadsFromBAMFilesSharded](https://github.com/googlegenomics/dataflow-java/blob/master/src/main/java/com/google/cloud/genomics/dataflow/readers/bam/ReadBAMTransform.java#L104) we get a **java.lang.VerifyError**. The full error looks like this:. ```; Exception in thread ""main"" java.lang.VerifyError: Bad type on operand stack; Exception Details:; Location:; com/google/cloud/genomics/dataflow/readers/bam/ReadBAMTransform.getReadsFromBAMFilesSharded(Lcom/google/cloud/dataflow/sdk/Pipeline;Lcom/google/cloud/genomics/utils/GenomicsFactory$OfflineAuth;Ljava/lang/Iterable;Lcom/google/cloud/genomics/dataflow/readers/bam/ReaderOptions;Ljava/util/List;)Lcom/google/cloud/dataflow/sdk/values/PCollection; @25: invokevirtual; Reason:; Type 'com/google/cloud/dataflow/sdk/transforms/Create' (current frame, stack[2]) is not assignable to 'com/google/cloud/dataflow/sdk/transforms/PTransform'; Current Frame:; bci: @25; flags: { }; locals: { 'com/google/cloud/dataflow/sdk/Pipeline', 'com/google/cloud/genomics/utils/GenomicsFactory$OfflineAuth', 'java/lang/Iterable', 'com/google/cloud/genomics/dataflow/readers/bam/ReaderOptions', 'java/util/List', 'com/google/cloud/genomics/dataflow/readers/bam/ReadBAMTransform' }; stack: { 'com/google/cloud/dataflow/sdk/values/TupleTag', 'com/google/cloud/dataflow/sdk/Pipeline', 'com/google/cloud/dataflow/sdk/transforms/Create' }; Bytecode:; 0x0000000: bb00 0159 2db7 0002 3a05 1905 2bb6 0003; 0x0000010: b200 042a 1904 b800 05b6 0006 c000 07b8; 0x0000020: 0008 b600 09b8 000a b200 0b2a 2cb8 0005; 0x0000030: b600 06c0 0007 120c b800 0db6 0009 b600; 0x0000040: 0e3a 0619 0519 06b6 000f b0 . at org.broadinstitute.hellbender.engine.dataflow.datasources.ReadsDataflowSource.getReadPCollection(ReadsDataflowSource.java:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/791
https://github.com/broadinstitute/gatk/issues/791:2253,Availability,error,error,2253,"omics/dataflow/readers/bam/ReadBAMTransform.getReadsFromBAMFilesSharded(Lcom/google/cloud/dataflow/sdk/Pipeline;Lcom/google/cloud/genomics/utils/GenomicsFactory$OfflineAuth;Ljava/lang/Iterable;Lcom/google/cloud/genomics/dataflow/readers/bam/ReaderOptions;Ljava/util/List;)Lcom/google/cloud/dataflow/sdk/values/PCollection; @25: invokevirtual; Reason:; Type 'com/google/cloud/dataflow/sdk/transforms/Create' (current frame, stack[2]) is not assignable to 'com/google/cloud/dataflow/sdk/transforms/PTransform'; Current Frame:; bci: @25; flags: { }; locals: { 'com/google/cloud/dataflow/sdk/Pipeline', 'com/google/cloud/genomics/utils/GenomicsFactory$OfflineAuth', 'java/lang/Iterable', 'com/google/cloud/genomics/dataflow/readers/bam/ReaderOptions', 'java/util/List', 'com/google/cloud/genomics/dataflow/readers/bam/ReadBAMTransform' }; stack: { 'com/google/cloud/dataflow/sdk/values/TupleTag', 'com/google/cloud/dataflow/sdk/Pipeline', 'com/google/cloud/dataflow/sdk/transforms/Create' }; Bytecode:; 0x0000000: bb00 0159 2db7 0002 3a05 1905 2bb6 0003; 0x0000010: b200 042a 1904 b800 05b6 0006 c000 07b8; 0x0000020: 0008 b600 09b8 000a b200 0b2a 2cb8 0005; 0x0000030: b600 06c0 0007 120c b800 0db6 0009 b600; 0x0000040: 0e3a 0619 0519 06b6 000f b0 . at org.broadinstitute.hellbender.engine.dataflow.datasources.ReadsDataflowSource.getReadPCollection(ReadsDataflowSource.java:130); at org.broadinstitute.hellbender.dev.tools.walkers.bqsr.BadTypeRepro.ingestReadsAndGrabHeader(BadTypeRepro.java:100); at org.broadinstitute.hellbender.dev.tools.walkers.bqsr.BadTypeRepro.setupPipeline(BadTypeRepro.java:74); ```. This is the same error I saw when upgrading to google-cloud-dataflow-java-sdk-all:0.4.150710 (#754), so perhaps this is caused by a version mismatch somewhere. I wrote a small bug-reproducing class, [BadTypeRepro](https://github.com/broadinstitute/hellbender/blob/jp_badtype_repro/src/main/java/org/broadinstitute/hellbender/dev/tools/walkers/bqsr/BadTypeRepro.java), in its eponymous branch.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/791
https://github.com/broadinstitute/gatk/issues/791:731,Deployability,Pipeline,Pipeline,731,"ed](https://github.com/googlegenomics/dataflow-java/blob/master/src/main/java/com/google/cloud/genomics/dataflow/readers/bam/ReadBAMTransform.java#L104) we get a **java.lang.VerifyError**. The full error looks like this:. ```; Exception in thread ""main"" java.lang.VerifyError: Bad type on operand stack; Exception Details:; Location:; com/google/cloud/genomics/dataflow/readers/bam/ReadBAMTransform.getReadsFromBAMFilesSharded(Lcom/google/cloud/dataflow/sdk/Pipeline;Lcom/google/cloud/genomics/utils/GenomicsFactory$OfflineAuth;Ljava/lang/Iterable;Lcom/google/cloud/genomics/dataflow/readers/bam/ReaderOptions;Ljava/util/List;)Lcom/google/cloud/dataflow/sdk/values/PCollection; @25: invokevirtual; Reason:; Type 'com/google/cloud/dataflow/sdk/transforms/Create' (current frame, stack[2]) is not assignable to 'com/google/cloud/dataflow/sdk/transforms/PTransform'; Current Frame:; bci: @25; flags: { }; locals: { 'com/google/cloud/dataflow/sdk/Pipeline', 'com/google/cloud/genomics/utils/GenomicsFactory$OfflineAuth', 'java/lang/Iterable', 'com/google/cloud/genomics/dataflow/readers/bam/ReaderOptions', 'java/util/List', 'com/google/cloud/genomics/dataflow/readers/bam/ReadBAMTransform' }; stack: { 'com/google/cloud/dataflow/sdk/values/TupleTag', 'com/google/cloud/dataflow/sdk/Pipeline', 'com/google/cloud/dataflow/sdk/transforms/Create' }; Bytecode:; 0x0000000: bb00 0159 2db7 0002 3a05 1905 2bb6 0003; 0x0000010: b200 042a 1904 b800 05b6 0006 c000 07b8; 0x0000020: 0008 b600 09b8 000a b200 0b2a 2cb8 0005; 0x0000030: b600 06c0 0007 120c b800 0db6 0009 b600; 0x0000040: 0e3a 0619 0519 06b6 000f b0 . at org.broadinstitute.hellbender.engine.dataflow.datasources.ReadsDataflowSource.getReadPCollection(ReadsDataflowSource.java:130); at org.broadinstitute.hellbender.dev.tools.walkers.bqsr.BadTypeRepro.ingestReadsAndGrabHeader(BadTypeRepro.java:100); at org.broadinstitute.hellbender.dev.tools.walkers.bqsr.BadTypeRepro.setupPipeline(BadTypeRepro.java:74); ```. This is the same error I saw when upgr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/791
https://github.com/broadinstitute/gatk/issues/791:1216,Deployability,Pipeline,Pipeline,1216,"ed](https://github.com/googlegenomics/dataflow-java/blob/master/src/main/java/com/google/cloud/genomics/dataflow/readers/bam/ReadBAMTransform.java#L104) we get a **java.lang.VerifyError**. The full error looks like this:. ```; Exception in thread ""main"" java.lang.VerifyError: Bad type on operand stack; Exception Details:; Location:; com/google/cloud/genomics/dataflow/readers/bam/ReadBAMTransform.getReadsFromBAMFilesSharded(Lcom/google/cloud/dataflow/sdk/Pipeline;Lcom/google/cloud/genomics/utils/GenomicsFactory$OfflineAuth;Ljava/lang/Iterable;Lcom/google/cloud/genomics/dataflow/readers/bam/ReaderOptions;Ljava/util/List;)Lcom/google/cloud/dataflow/sdk/values/PCollection; @25: invokevirtual; Reason:; Type 'com/google/cloud/dataflow/sdk/transforms/Create' (current frame, stack[2]) is not assignable to 'com/google/cloud/dataflow/sdk/transforms/PTransform'; Current Frame:; bci: @25; flags: { }; locals: { 'com/google/cloud/dataflow/sdk/Pipeline', 'com/google/cloud/genomics/utils/GenomicsFactory$OfflineAuth', 'java/lang/Iterable', 'com/google/cloud/genomics/dataflow/readers/bam/ReaderOptions', 'java/util/List', 'com/google/cloud/genomics/dataflow/readers/bam/ReadBAMTransform' }; stack: { 'com/google/cloud/dataflow/sdk/values/TupleTag', 'com/google/cloud/dataflow/sdk/Pipeline', 'com/google/cloud/dataflow/sdk/transforms/Create' }; Bytecode:; 0x0000000: bb00 0159 2db7 0002 3a05 1905 2bb6 0003; 0x0000010: b200 042a 1904 b800 05b6 0006 c000 07b8; 0x0000020: 0008 b600 09b8 000a b200 0b2a 2cb8 0005; 0x0000030: b600 06c0 0007 120c b800 0db6 0009 b600; 0x0000040: 0e3a 0619 0519 06b6 000f b0 . at org.broadinstitute.hellbender.engine.dataflow.datasources.ReadsDataflowSource.getReadPCollection(ReadsDataflowSource.java:130); at org.broadinstitute.hellbender.dev.tools.walkers.bqsr.BadTypeRepro.ingestReadsAndGrabHeader(BadTypeRepro.java:100); at org.broadinstitute.hellbender.dev.tools.walkers.bqsr.BadTypeRepro.setupPipeline(BadTypeRepro.java:74); ```. This is the same error I saw when upgr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/791
https://github.com/broadinstitute/gatk/issues/791:1552,Deployability,Pipeline,Pipeline,1552,"ed](https://github.com/googlegenomics/dataflow-java/blob/master/src/main/java/com/google/cloud/genomics/dataflow/readers/bam/ReadBAMTransform.java#L104) we get a **java.lang.VerifyError**. The full error looks like this:. ```; Exception in thread ""main"" java.lang.VerifyError: Bad type on operand stack; Exception Details:; Location:; com/google/cloud/genomics/dataflow/readers/bam/ReadBAMTransform.getReadsFromBAMFilesSharded(Lcom/google/cloud/dataflow/sdk/Pipeline;Lcom/google/cloud/genomics/utils/GenomicsFactory$OfflineAuth;Ljava/lang/Iterable;Lcom/google/cloud/genomics/dataflow/readers/bam/ReaderOptions;Ljava/util/List;)Lcom/google/cloud/dataflow/sdk/values/PCollection; @25: invokevirtual; Reason:; Type 'com/google/cloud/dataflow/sdk/transforms/Create' (current frame, stack[2]) is not assignable to 'com/google/cloud/dataflow/sdk/transforms/PTransform'; Current Frame:; bci: @25; flags: { }; locals: { 'com/google/cloud/dataflow/sdk/Pipeline', 'com/google/cloud/genomics/utils/GenomicsFactory$OfflineAuth', 'java/lang/Iterable', 'com/google/cloud/genomics/dataflow/readers/bam/ReaderOptions', 'java/util/List', 'com/google/cloud/genomics/dataflow/readers/bam/ReadBAMTransform' }; stack: { 'com/google/cloud/dataflow/sdk/values/TupleTag', 'com/google/cloud/dataflow/sdk/Pipeline', 'com/google/cloud/dataflow/sdk/transforms/Create' }; Bytecode:; 0x0000000: bb00 0159 2db7 0002 3a05 1905 2bb6 0003; 0x0000010: b200 042a 1904 b800 05b6 0006 c000 07b8; 0x0000020: 0008 b600 09b8 000a b200 0b2a 2cb8 0005; 0x0000030: b600 06c0 0007 120c b800 0db6 0009 b600; 0x0000040: 0e3a 0619 0519 06b6 000f b0 . at org.broadinstitute.hellbender.engine.dataflow.datasources.ReadsDataflowSource.getReadPCollection(ReadsDataflowSource.java:130); at org.broadinstitute.hellbender.dev.tools.walkers.bqsr.BadTypeRepro.ingestReadsAndGrabHeader(BadTypeRepro.java:100); at org.broadinstitute.hellbender.dev.tools.walkers.bqsr.BadTypeRepro.setupPipeline(BadTypeRepro.java:74); ```. This is the same error I saw when upgr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/791
https://github.com/broadinstitute/gatk/issues/799:568,Deployability,pipeline,pipeline,568,"This was mentioned already as a comment in #562 but it should be an issue instead. BQSR on Dataflow can _theoretically_ avoid the step of saving the textual report, instead piping the recalibration analysis results directly to the ApplyBQSR phase. In practice it cannot, because it turns out that **saving a report and immediately loading it back is not a no-op**. it actually changes in some necessary way. It would be great if someone familiar with that part of the code could help factor the mutation apart from the saving/loading, so I could just call that in the pipeline. This would speed things up a bit and the code would be that much cleaner.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/799
https://github.com/broadinstitute/gatk/issues/799:331,Performance,load,loading,331,"This was mentioned already as a comment in #562 but it should be an issue instead. BQSR on Dataflow can _theoretically_ avoid the step of saving the textual report, instead piping the recalibration analysis results directly to the ApplyBQSR phase. In practice it cannot, because it turns out that **saving a report and immediately loading it back is not a no-op**. it actually changes in some necessary way. It would be great if someone familiar with that part of the code could help factor the mutation apart from the saving/loading, so I could just call that in the pipeline. This would speed things up a bit and the code would be that much cleaner.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/799
https://github.com/broadinstitute/gatk/issues/799:526,Performance,load,loading,526,"This was mentioned already as a comment in #562 but it should be an issue instead. BQSR on Dataflow can _theoretically_ avoid the step of saving the textual report, instead piping the recalibration analysis results directly to the ApplyBQSR phase. In practice it cannot, because it turns out that **saving a report and immediately loading it back is not a no-op**. it actually changes in some necessary way. It would be great if someone familiar with that part of the code could help factor the mutation apart from the saving/loading, so I could just call that in the pipeline. This would speed things up a bit and the code would be that much cleaner.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/799
https://github.com/broadinstitute/gatk/issues/799:120,Safety,avoid,avoid,120,"This was mentioned already as a comment in #562 but it should be an issue instead. BQSR on Dataflow can _theoretically_ avoid the step of saving the textual report, instead piping the recalibration analysis results directly to the ApplyBQSR phase. In practice it cannot, because it turns out that **saving a report and immediately loading it back is not a no-op**. it actually changes in some necessary way. It would be great if someone familiar with that part of the code could help factor the mutation apart from the saving/loading, so I could just call that in the pipeline. This would speed things up a bit and the code would be that much cleaner.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/799
https://github.com/broadinstitute/gatk/pull/800:41,Safety,detect,detection,41,This brings in an important fix for auto-detection of indices; for CRAM files.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/800
https://github.com/broadinstitute/gatk/pull/801:122,Availability,avail,available,122,This should resolve #650. This may require a change to the hellbender-protected build to include sonatype snapshots as an available maven repo if it doesn't already. This is the same issue as #779.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/801
https://github.com/broadinstitute/gatk/issues/802:349,Availability,error,errors,349,"Currently we check only that sequence dictionaries have a common subset of equal contigs. When comparing against the reference sequence dictionary, however, we need to check that the ref dictionary contains all contigs from the reads/variants dictionaries. If this is not the case, we can see null pointer exceptions with cram files and other nasty errors.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/802
https://github.com/broadinstitute/gatk/pull/804:658,Performance,cache,cache,658,"This isn't quite finished, but it would be good to get it checked to see if I'm going in the right direction (cc @davidaadams). The main idea is to introduce `ReferenceDataflowSource`, which delegates to `RefAPISource` or the Hadoop source (which streams from HDFS), or a local file source. The tests use a mock `ReferenceDataflowSource` (rather than a mock `RefAPISource`), except for the tests for the actual implementations of each reference source which test the implementation class directly. `RefAPIMetadata` has been subsumed into `RefAPISource`. Also, the singleton has been removed, as I couldn't see what it was gaining. (The important thing is to cache the reference name table, which was stored in `RefAPIMetadata`.) It might make sense to use `@BeforeClass` in `RefAPISourceUnitTest` to ensure that only one `RefAPISource` is created, so only a single reference name table is needed. However, it looks like the test is currently creating a new table for each test case in that class. This will fix https://github.com/broadinstitute/hellbender/issues/567.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/804
https://github.com/broadinstitute/gatk/pull/804:295,Testability,test,tests,295,"This isn't quite finished, but it would be good to get it checked to see if I'm going in the right direction (cc @davidaadams). The main idea is to introduce `ReferenceDataflowSource`, which delegates to `RefAPISource` or the Hadoop source (which streams from HDFS), or a local file source. The tests use a mock `ReferenceDataflowSource` (rather than a mock `RefAPISource`), except for the tests for the actual implementations of each reference source which test the implementation class directly. `RefAPIMetadata` has been subsumed into `RefAPISource`. Also, the singleton has been removed, as I couldn't see what it was gaining. (The important thing is to cache the reference name table, which was stored in `RefAPIMetadata`.) It might make sense to use `@BeforeClass` in `RefAPISourceUnitTest` to ensure that only one `RefAPISource` is created, so only a single reference name table is needed. However, it looks like the test is currently creating a new table for each test case in that class. This will fix https://github.com/broadinstitute/hellbender/issues/567.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/804
https://github.com/broadinstitute/gatk/pull/804:307,Testability,mock,mock,307,"This isn't quite finished, but it would be good to get it checked to see if I'm going in the right direction (cc @davidaadams). The main idea is to introduce `ReferenceDataflowSource`, which delegates to `RefAPISource` or the Hadoop source (which streams from HDFS), or a local file source. The tests use a mock `ReferenceDataflowSource` (rather than a mock `RefAPISource`), except for the tests for the actual implementations of each reference source which test the implementation class directly. `RefAPIMetadata` has been subsumed into `RefAPISource`. Also, the singleton has been removed, as I couldn't see what it was gaining. (The important thing is to cache the reference name table, which was stored in `RefAPIMetadata`.) It might make sense to use `@BeforeClass` in `RefAPISourceUnitTest` to ensure that only one `RefAPISource` is created, so only a single reference name table is needed. However, it looks like the test is currently creating a new table for each test case in that class. This will fix https://github.com/broadinstitute/hellbender/issues/567.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/804
https://github.com/broadinstitute/gatk/pull/804:353,Testability,mock,mock,353,"This isn't quite finished, but it would be good to get it checked to see if I'm going in the right direction (cc @davidaadams). The main idea is to introduce `ReferenceDataflowSource`, which delegates to `RefAPISource` or the Hadoop source (which streams from HDFS), or a local file source. The tests use a mock `ReferenceDataflowSource` (rather than a mock `RefAPISource`), except for the tests for the actual implementations of each reference source which test the implementation class directly. `RefAPIMetadata` has been subsumed into `RefAPISource`. Also, the singleton has been removed, as I couldn't see what it was gaining. (The important thing is to cache the reference name table, which was stored in `RefAPIMetadata`.) It might make sense to use `@BeforeClass` in `RefAPISourceUnitTest` to ensure that only one `RefAPISource` is created, so only a single reference name table is needed. However, it looks like the test is currently creating a new table for each test case in that class. This will fix https://github.com/broadinstitute/hellbender/issues/567.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/804
https://github.com/broadinstitute/gatk/pull/804:390,Testability,test,tests,390,"This isn't quite finished, but it would be good to get it checked to see if I'm going in the right direction (cc @davidaadams). The main idea is to introduce `ReferenceDataflowSource`, which delegates to `RefAPISource` or the Hadoop source (which streams from HDFS), or a local file source. The tests use a mock `ReferenceDataflowSource` (rather than a mock `RefAPISource`), except for the tests for the actual implementations of each reference source which test the implementation class directly. `RefAPIMetadata` has been subsumed into `RefAPISource`. Also, the singleton has been removed, as I couldn't see what it was gaining. (The important thing is to cache the reference name table, which was stored in `RefAPIMetadata`.) It might make sense to use `@BeforeClass` in `RefAPISourceUnitTest` to ensure that only one `RefAPISource` is created, so only a single reference name table is needed. However, it looks like the test is currently creating a new table for each test case in that class. This will fix https://github.com/broadinstitute/hellbender/issues/567.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/804
https://github.com/broadinstitute/gatk/pull/804:458,Testability,test,test,458,"This isn't quite finished, but it would be good to get it checked to see if I'm going in the right direction (cc @davidaadams). The main idea is to introduce `ReferenceDataflowSource`, which delegates to `RefAPISource` or the Hadoop source (which streams from HDFS), or a local file source. The tests use a mock `ReferenceDataflowSource` (rather than a mock `RefAPISource`), except for the tests for the actual implementations of each reference source which test the implementation class directly. `RefAPIMetadata` has been subsumed into `RefAPISource`. Also, the singleton has been removed, as I couldn't see what it was gaining. (The important thing is to cache the reference name table, which was stored in `RefAPIMetadata`.) It might make sense to use `@BeforeClass` in `RefAPISourceUnitTest` to ensure that only one `RefAPISource` is created, so only a single reference name table is needed. However, it looks like the test is currently creating a new table for each test case in that class. This will fix https://github.com/broadinstitute/hellbender/issues/567.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/804
https://github.com/broadinstitute/gatk/pull/804:924,Testability,test,test,924,"This isn't quite finished, but it would be good to get it checked to see if I'm going in the right direction (cc @davidaadams). The main idea is to introduce `ReferenceDataflowSource`, which delegates to `RefAPISource` or the Hadoop source (which streams from HDFS), or a local file source. The tests use a mock `ReferenceDataflowSource` (rather than a mock `RefAPISource`), except for the tests for the actual implementations of each reference source which test the implementation class directly. `RefAPIMetadata` has been subsumed into `RefAPISource`. Also, the singleton has been removed, as I couldn't see what it was gaining. (The important thing is to cache the reference name table, which was stored in `RefAPIMetadata`.) It might make sense to use `@BeforeClass` in `RefAPISourceUnitTest` to ensure that only one `RefAPISource` is created, so only a single reference name table is needed. However, it looks like the test is currently creating a new table for each test case in that class. This will fix https://github.com/broadinstitute/hellbender/issues/567.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/804
https://github.com/broadinstitute/gatk/pull/804:972,Testability,test,test,972,"This isn't quite finished, but it would be good to get it checked to see if I'm going in the right direction (cc @davidaadams). The main idea is to introduce `ReferenceDataflowSource`, which delegates to `RefAPISource` or the Hadoop source (which streams from HDFS), or a local file source. The tests use a mock `ReferenceDataflowSource` (rather than a mock `RefAPISource`), except for the tests for the actual implementations of each reference source which test the implementation class directly. `RefAPIMetadata` has been subsumed into `RefAPISource`. Also, the singleton has been removed, as I couldn't see what it was gaining. (The important thing is to cache the reference name table, which was stored in `RefAPIMetadata`.) It might make sense to use `@BeforeClass` in `RefAPISourceUnitTest` to ensure that only one `RefAPISource` is created, so only a single reference name table is needed. However, it looks like the test is currently creating a new table for each test case in that class. This will fix https://github.com/broadinstitute/hellbender/issues/567.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/804
https://github.com/broadinstitute/gatk/issues/805:268,Deployability,update,update,268,"This is a subtask of #133. Extra code is needed to switch between `""INPUT""` and `""input""` which is unfortunate. Replace ""INPUT""/""OUTPUT"" for `CleanSam` and `MarkDuplicates` (along with any others that I missed.) with `StandardArgumentDefinitions.INPUT_LONG_NAME` Then update `SamFileTester` to only use the standard names.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/805
https://github.com/broadinstitute/gatk/issues/807:12,Integrability,depend,dependencies,12,Some of our dependencies make logging calls to the Java default logger that don't respect our current log level. We should hook up `LoggingUtils.setLoggingLevel` to the java default logging system so that we can control it.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/807
https://github.com/broadinstitute/gatk/issues/807:30,Testability,log,logging,30,Some of our dependencies make logging calls to the Java default logger that don't respect our current log level. We should hook up `LoggingUtils.setLoggingLevel` to the java default logging system so that we can control it.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/807
https://github.com/broadinstitute/gatk/issues/807:64,Testability,log,logger,64,Some of our dependencies make logging calls to the Java default logger that don't respect our current log level. We should hook up `LoggingUtils.setLoggingLevel` to the java default logging system so that we can control it.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/807
https://github.com/broadinstitute/gatk/issues/807:102,Testability,log,log,102,Some of our dependencies make logging calls to the Java default logger that don't respect our current log level. We should hook up `LoggingUtils.setLoggingLevel` to the java default logging system so that we can control it.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/807
https://github.com/broadinstitute/gatk/issues/807:132,Testability,Log,LoggingUtils,132,Some of our dependencies make logging calls to the Java default logger that don't respect our current log level. We should hook up `LoggingUtils.setLoggingLevel` to the java default logging system so that we can control it.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/807
https://github.com/broadinstitute/gatk/issues/807:182,Testability,log,logging,182,Some of our dependencies make logging calls to the Java default logger that don't respect our current log level. We should hook up `LoggingUtils.setLoggingLevel` to the java default logging system so that we can control it.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/807
https://github.com/broadinstitute/gatk/pull/809:49,Availability,error,errors,49,"This addresses issue 569 - the cleanup of format errors in bam and sam files in tests. I will send an archive with a README, validations for the post-modification bams and sams, and diffs for the bams to akiezun.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/809
https://github.com/broadinstitute/gatk/pull/809:125,Security,validat,validations,125,"This addresses issue 569 - the cleanup of format errors in bam and sam files in tests. I will send an archive with a README, validations for the post-modification bams and sams, and diffs for the bams to akiezun.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/809
https://github.com/broadinstitute/gatk/pull/809:80,Testability,test,tests,80,"This addresses issue 569 - the cleanup of format errors in bam and sam files in tests. I will send an archive with a README, validations for the post-modification bams and sams, and diffs for the bams to akiezun.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/809
https://github.com/broadinstitute/gatk/issues/810:93,Deployability,update,updated,93,I broke external forks pull requests when the dataflow tests were turned on. They need to be updated so that tests that don't require keys will run without them.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/810
https://github.com/broadinstitute/gatk/issues/810:55,Testability,test,tests,55,I broke external forks pull requests when the dataflow tests were turned on. They need to be updated so that tests that don't require keys will run without them.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/810
https://github.com/broadinstitute/gatk/issues/810:109,Testability,test,tests,109,I broke external forks pull requests when the dataflow tests were turned on. They need to be updated so that tests that don't require keys will run without them.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/810
https://github.com/broadinstitute/gatk/pull/812:288,Deployability,release,release,288,"- new version of BaseRecalibratorDataflow that fits into the skeleton framework; - new command-line BaseRecalibratorDataflow that uses the same code; - tests and test inputs for BaseRecalibrator. They pass, locally and on the cloud.; - fix for issue #791 via a new genomics-dataflow-java release; - smaller changes, like == -> .equals in SequenceDictionaryUtils and using getInstance() to follow the singleton pattern.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/812
https://github.com/broadinstitute/gatk/pull/812:152,Testability,test,tests,152,"- new version of BaseRecalibratorDataflow that fits into the skeleton framework; - new command-line BaseRecalibratorDataflow that uses the same code; - tests and test inputs for BaseRecalibrator. They pass, locally and on the cloud.; - fix for issue #791 via a new genomics-dataflow-java release; - smaller changes, like == -> .equals in SequenceDictionaryUtils and using getInstance() to follow the singleton pattern.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/812
https://github.com/broadinstitute/gatk/pull/812:162,Testability,test,test,162,"- new version of BaseRecalibratorDataflow that fits into the skeleton framework; - new command-line BaseRecalibratorDataflow that uses the same code; - tests and test inputs for BaseRecalibrator. They pass, locally and on the cloud.; - fix for issue #791 via a new genomics-dataflow-java release; - smaller changes, like == -> .equals in SequenceDictionaryUtils and using getInstance() to follow the singleton pattern.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/812
https://github.com/broadinstitute/gatk/pull/813:17,Testability,test,tests,17,Fixes #802. Unit tests fixed/added.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/813
https://github.com/broadinstitute/gatk/pull/815:45,Deployability,pipeline,pipeline,45,- ApplyBQSR adapted to fit into the Skeleton pipeline; - command-line version still works and passes tests (including cloud); - BaseRecalibrator's testPlottingWorkflow now passes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/815
https://github.com/broadinstitute/gatk/pull/815:12,Energy Efficiency,adapt,adapted,12,- ApplyBQSR adapted to fit into the Skeleton pipeline; - command-line version still works and passes tests (including cloud); - BaseRecalibrator's testPlottingWorkflow now passes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/815
https://github.com/broadinstitute/gatk/pull/815:12,Modifiability,adapt,adapted,12,- ApplyBQSR adapted to fit into the Skeleton pipeline; - command-line version still works and passes tests (including cloud); - BaseRecalibrator's testPlottingWorkflow now passes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/815
https://github.com/broadinstitute/gatk/pull/815:101,Testability,test,tests,101,- ApplyBQSR adapted to fit into the Skeleton pipeline; - command-line version still works and passes tests (including cloud); - BaseRecalibrator's testPlottingWorkflow now passes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/815
https://github.com/broadinstitute/gatk/pull/815:147,Testability,test,testPlottingWorkflow,147,- ApplyBQSR adapted to fit into the Skeleton pipeline; - command-line version still works and passes tests (including cloud); - BaseRecalibrator's testPlottingWorkflow now passes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/815
https://github.com/broadinstitute/gatk/issues/816:14,Testability,test,tests,14,"The following tests failed for me today, on the master branch:. RefAPISourceUnitTest. testDummy; RefAPISourceUnitTest. testReferenceSourceQuery; RefAPISourceUnitTest. testReferenceSourceQueryWithInvalidContig; RefAPISourceUnitTest. testReferenceSourceQueryWithInvalidPosition. (I mentioned this in #751 but it should be its own issue so we can track progress)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/816
https://github.com/broadinstitute/gatk/issues/816:86,Testability,test,testDummy,86,"The following tests failed for me today, on the master branch:. RefAPISourceUnitTest. testDummy; RefAPISourceUnitTest. testReferenceSourceQuery; RefAPISourceUnitTest. testReferenceSourceQueryWithInvalidContig; RefAPISourceUnitTest. testReferenceSourceQueryWithInvalidPosition. (I mentioned this in #751 but it should be its own issue so we can track progress)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/816
https://github.com/broadinstitute/gatk/issues/816:119,Testability,test,testReferenceSourceQuery,119,"The following tests failed for me today, on the master branch:. RefAPISourceUnitTest. testDummy; RefAPISourceUnitTest. testReferenceSourceQuery; RefAPISourceUnitTest. testReferenceSourceQueryWithInvalidContig; RefAPISourceUnitTest. testReferenceSourceQueryWithInvalidPosition. (I mentioned this in #751 but it should be its own issue so we can track progress)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/816
https://github.com/broadinstitute/gatk/issues/816:167,Testability,test,testReferenceSourceQueryWithInvalidContig,167,"The following tests failed for me today, on the master branch:. RefAPISourceUnitTest. testDummy; RefAPISourceUnitTest. testReferenceSourceQuery; RefAPISourceUnitTest. testReferenceSourceQueryWithInvalidContig; RefAPISourceUnitTest. testReferenceSourceQueryWithInvalidPosition. (I mentioned this in #751 but it should be its own issue so we can track progress)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/816
https://github.com/broadinstitute/gatk/issues/816:232,Testability,test,testReferenceSourceQueryWithInvalidPosition,232,"The following tests failed for me today, on the master branch:. RefAPISourceUnitTest. testDummy; RefAPISourceUnitTest. testReferenceSourceQuery; RefAPISourceUnitTest. testReferenceSourceQueryWithInvalidContig; RefAPISourceUnitTest. testReferenceSourceQueryWithInvalidPosition. (I mentioned this in #751 but it should be its own issue so we can track progress)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/816
https://github.com/broadinstitute/gatk/pull/819:21,Testability,test,tests,21,"""cloud"" and ""bucket"" tests now run by default, in order to make progress for issue #751. Moved all existing tests to ""cloud_todo"" and ""bucket_todo"". The plan is to then move back the tests that work (but in a separate PR, to keep this clean and simple).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/819
https://github.com/broadinstitute/gatk/pull/819:108,Testability,test,tests,108,"""cloud"" and ""bucket"" tests now run by default, in order to make progress for issue #751. Moved all existing tests to ""cloud_todo"" and ""bucket_todo"". The plan is to then move back the tests that work (but in a separate PR, to keep this clean and simple).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/819
https://github.com/broadinstitute/gatk/pull/819:183,Testability,test,tests,183,"""cloud"" and ""bucket"" tests now run by default, in order to make progress for issue #751. Moved all existing tests to ""cloud_todo"" and ""bucket_todo"". The plan is to then move back the tests that work (but in a separate PR, to keep this clean and simple).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/819
https://github.com/broadinstitute/gatk/pull/819:245,Usability,simpl,simple,245,"""cloud"" and ""bucket"" tests now run by default, in order to make progress for issue #751. Moved all existing tests to ""cloud_todo"" and ""bucket_todo"". The plan is to then move back the tests that work (but in a separate PR, to keep this clean and simple).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/819
https://github.com/broadinstitute/gatk/pull/821:30,Performance,perform,performance,30,Fixes issue #816 and improves performance. Marking those tests as mandatory since they pass now.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/821
https://github.com/broadinstitute/gatk/pull/821:57,Testability,test,tests,57,Fixes issue #816 and improves performance. Marking those tests as mandatory since they pass now.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/821
https://github.com/broadinstitute/gatk/pull/822:21,Testability,test,tests,21,"""cloud"" and ""bucket"" tests now run by default, in order to make progress for issue #751. Moved all existing tests to ""cloud_todo"" and ""bucket_todo"". The plan is to then move back the tests that work (but in a separate PR, to keep this clean and simple). This is a rebased and fixed version of #819.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/822
https://github.com/broadinstitute/gatk/pull/822:108,Testability,test,tests,108,"""cloud"" and ""bucket"" tests now run by default, in order to make progress for issue #751. Moved all existing tests to ""cloud_todo"" and ""bucket_todo"". The plan is to then move back the tests that work (but in a separate PR, to keep this clean and simple). This is a rebased and fixed version of #819.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/822
https://github.com/broadinstitute/gatk/pull/822:183,Testability,test,tests,183,"""cloud"" and ""bucket"" tests now run by default, in order to make progress for issue #751. Moved all existing tests to ""cloud_todo"" and ""bucket_todo"". The plan is to then move back the tests that work (but in a separate PR, to keep this clean and simple). This is a rebased and fixed version of #819.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/822
https://github.com/broadinstitute/gatk/pull/822:245,Usability,simpl,simple,245,"""cloud"" and ""bucket"" tests now run by default, in order to make progress for issue #751. Moved all existing tests to ""cloud_todo"" and ""bucket_todo"". The plan is to then move back the tests that work (but in a separate PR, to keep this clean and simple). This is a rebased and fixed version of #819.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/822
https://github.com/broadinstitute/gatk/pull/823:94,Testability,test,tests,94,@jean-philippe-martin I think this might be a slightly better approach then merging the cloud tests into the main tests. This just adds another build to the matrix so we have 1 for mandatory cloud tests and 1 for todo cloud tests. That way we don't dramatically increase the build time by mashing the cloud tests into the main ones.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/823
https://github.com/broadinstitute/gatk/pull/823:114,Testability,test,tests,114,@jean-philippe-martin I think this might be a slightly better approach then merging the cloud tests into the main tests. This just adds another build to the matrix so we have 1 for mandatory cloud tests and 1 for todo cloud tests. That way we don't dramatically increase the build time by mashing the cloud tests into the main ones.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/823
https://github.com/broadinstitute/gatk/pull/823:197,Testability,test,tests,197,@jean-philippe-martin I think this might be a slightly better approach then merging the cloud tests into the main tests. This just adds another build to the matrix so we have 1 for mandatory cloud tests and 1 for todo cloud tests. That way we don't dramatically increase the build time by mashing the cloud tests into the main ones.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/823
https://github.com/broadinstitute/gatk/pull/823:224,Testability,test,tests,224,@jean-philippe-martin I think this might be a slightly better approach then merging the cloud tests into the main tests. This just adds another build to the matrix so we have 1 for mandatory cloud tests and 1 for todo cloud tests. That way we don't dramatically increase the build time by mashing the cloud tests into the main ones.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/823
https://github.com/broadinstitute/gatk/pull/823:307,Testability,test,tests,307,@jean-philippe-martin I think this might be a slightly better approach then merging the cloud tests into the main tests. This just adds another build to the matrix so we have 1 for mandatory cloud tests and 1 for todo cloud tests. That way we don't dramatically increase the build time by mashing the cloud tests into the main ones.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/823
https://github.com/broadinstitute/gatk/pull/824:21,Testability,test,tests,21,This enables the two tests that we expect to work.; Based on #822.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/824
https://github.com/broadinstitute/gatk/pull/825:30,Performance,perform,performance,30,Fixes issue #816 and improves performance. Marking those tests as mandatory since they pass now.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/825
https://github.com/broadinstitute/gatk/pull/825:57,Testability,test,tests,57,Fixes issue #816 and improves performance. Marking those tests as mandatory since they pass now.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/825
https://github.com/broadinstitute/gatk/pull/827:67,Integrability,interface,interface,67,"All ways of reading reference sequences are hidden behind a common interface,; ReferenceDataflowSource. See https://github.com/broadinstitute/hellbender/pull/804 for initial discussion of the design, and https://github.com/broadinstitute/hellbender/issues/567 for the issue that this solves. This change adds some HTSJDK extensions to work with Hadoop, these should eventually be added to HTSJDK in some form. I was able to run BQSR on a Spark cluster using this code, by using the following:. ``` bash; # Copy BAM into HDFS; hadoop fs -put ./src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam bam/NA12878.chr17_69k_70k.dictFix.bam. # Copy FASTA (reference) into HDFS; hadoop fs -mkdir fasta ; hadoop fs -put ./src/test/resources/human_g1k_v37.chr17_1Mb.fasta fasta/human_g1k_v37.chr17_1Mb.fasta; hadoop fs -put ./src/test/resources/human_g1k_v37.chr17_1Mb.dict fasta/human_g1k_v37.chr17_1Mb.dict; hadoop fs -put ./src/test/resources/human_g1k_v37.chr17_1Mb.fasta.fai fasta/human_g1k_v37.chr17_1Mb.fasta.fai. spark-submit \; --master $SPARK_MASTER \; --conf spark.driver.userClassPathFirst=true \; --conf spark.executor.userClassPathFirst=true \; --conf spark.io.compression.codec=lzf \; build/libs/hellbender-all-*-spark.jar ApplyWholeBQSRDataflow \; --reference hdfs://$NAMENODE/user/$USER/fasta/human_g1k_v37.chr17_1Mb.fasta \; --input hdfs://$NAMENODE/user/$USER/bam/NA12878.chr17_69k_70k.dictFix.bam \; --output hdfs://$NAMENODE/user/$USER/out/bqsr \; --knownSites $HELLBENDER_HOME/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf \; --RECAL_TABLE_FILE /dev/stdout \; --runner SPARK \; --sparkMaster $SPARK_MASTER ; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/827
https://github.com/broadinstitute/gatk/pull/827:547,Testability,test,test,547,"All ways of reading reference sequences are hidden behind a common interface,; ReferenceDataflowSource. See https://github.com/broadinstitute/hellbender/pull/804 for initial discussion of the design, and https://github.com/broadinstitute/hellbender/issues/567 for the issue that this solves. This change adds some HTSJDK extensions to work with Hadoop, these should eventually be added to HTSJDK in some form. I was able to run BQSR on a Spark cluster using this code, by using the following:. ``` bash; # Copy BAM into HDFS; hadoop fs -put ./src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam bam/NA12878.chr17_69k_70k.dictFix.bam. # Copy FASTA (reference) into HDFS; hadoop fs -mkdir fasta ; hadoop fs -put ./src/test/resources/human_g1k_v37.chr17_1Mb.fasta fasta/human_g1k_v37.chr17_1Mb.fasta; hadoop fs -put ./src/test/resources/human_g1k_v37.chr17_1Mb.dict fasta/human_g1k_v37.chr17_1Mb.dict; hadoop fs -put ./src/test/resources/human_g1k_v37.chr17_1Mb.fasta.fai fasta/human_g1k_v37.chr17_1Mb.fasta.fai. spark-submit \; --master $SPARK_MASTER \; --conf spark.driver.userClassPathFirst=true \; --conf spark.executor.userClassPathFirst=true \; --conf spark.io.compression.codec=lzf \; build/libs/hellbender-all-*-spark.jar ApplyWholeBQSRDataflow \; --reference hdfs://$NAMENODE/user/$USER/fasta/human_g1k_v37.chr17_1Mb.fasta \; --input hdfs://$NAMENODE/user/$USER/bam/NA12878.chr17_69k_70k.dictFix.bam \; --output hdfs://$NAMENODE/user/$USER/out/bqsr \; --knownSites $HELLBENDER_HOME/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf \; --RECAL_TABLE_FILE /dev/stdout \; --runner SPARK \; --sparkMaster $SPARK_MASTER ; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/827
https://github.com/broadinstitute/gatk/pull/827:758,Testability,test,test,758,"All ways of reading reference sequences are hidden behind a common interface,; ReferenceDataflowSource. See https://github.com/broadinstitute/hellbender/pull/804 for initial discussion of the design, and https://github.com/broadinstitute/hellbender/issues/567 for the issue that this solves. This change adds some HTSJDK extensions to work with Hadoop, these should eventually be added to HTSJDK in some form. I was able to run BQSR on a Spark cluster using this code, by using the following:. ``` bash; # Copy BAM into HDFS; hadoop fs -put ./src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam bam/NA12878.chr17_69k_70k.dictFix.bam. # Copy FASTA (reference) into HDFS; hadoop fs -mkdir fasta ; hadoop fs -put ./src/test/resources/human_g1k_v37.chr17_1Mb.fasta fasta/human_g1k_v37.chr17_1Mb.fasta; hadoop fs -put ./src/test/resources/human_g1k_v37.chr17_1Mb.dict fasta/human_g1k_v37.chr17_1Mb.dict; hadoop fs -put ./src/test/resources/human_g1k_v37.chr17_1Mb.fasta.fai fasta/human_g1k_v37.chr17_1Mb.fasta.fai. spark-submit \; --master $SPARK_MASTER \; --conf spark.driver.userClassPathFirst=true \; --conf spark.executor.userClassPathFirst=true \; --conf spark.io.compression.codec=lzf \; build/libs/hellbender-all-*-spark.jar ApplyWholeBQSRDataflow \; --reference hdfs://$NAMENODE/user/$USER/fasta/human_g1k_v37.chr17_1Mb.fasta \; --input hdfs://$NAMENODE/user/$USER/bam/NA12878.chr17_69k_70k.dictFix.bam \; --output hdfs://$NAMENODE/user/$USER/out/bqsr \; --knownSites $HELLBENDER_HOME/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf \; --RECAL_TABLE_FILE /dev/stdout \; --runner SPARK \; --sparkMaster $SPARK_MASTER ; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/827
https://github.com/broadinstitute/gatk/pull/827:861,Testability,test,test,861,"All ways of reading reference sequences are hidden behind a common interface,; ReferenceDataflowSource. See https://github.com/broadinstitute/hellbender/pull/804 for initial discussion of the design, and https://github.com/broadinstitute/hellbender/issues/567 for the issue that this solves. This change adds some HTSJDK extensions to work with Hadoop, these should eventually be added to HTSJDK in some form. I was able to run BQSR on a Spark cluster using this code, by using the following:. ``` bash; # Copy BAM into HDFS; hadoop fs -put ./src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam bam/NA12878.chr17_69k_70k.dictFix.bam. # Copy FASTA (reference) into HDFS; hadoop fs -mkdir fasta ; hadoop fs -put ./src/test/resources/human_g1k_v37.chr17_1Mb.fasta fasta/human_g1k_v37.chr17_1Mb.fasta; hadoop fs -put ./src/test/resources/human_g1k_v37.chr17_1Mb.dict fasta/human_g1k_v37.chr17_1Mb.dict; hadoop fs -put ./src/test/resources/human_g1k_v37.chr17_1Mb.fasta.fai fasta/human_g1k_v37.chr17_1Mb.fasta.fai. spark-submit \; --master $SPARK_MASTER \; --conf spark.driver.userClassPathFirst=true \; --conf spark.executor.userClassPathFirst=true \; --conf spark.io.compression.codec=lzf \; build/libs/hellbender-all-*-spark.jar ApplyWholeBQSRDataflow \; --reference hdfs://$NAMENODE/user/$USER/fasta/human_g1k_v37.chr17_1Mb.fasta \; --input hdfs://$NAMENODE/user/$USER/bam/NA12878.chr17_69k_70k.dictFix.bam \; --output hdfs://$NAMENODE/user/$USER/out/bqsr \; --knownSites $HELLBENDER_HOME/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf \; --RECAL_TABLE_FILE /dev/stdout \; --runner SPARK \; --sparkMaster $SPARK_MASTER ; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/827
https://github.com/broadinstitute/gatk/pull/827:962,Testability,test,test,962,"All ways of reading reference sequences are hidden behind a common interface,; ReferenceDataflowSource. See https://github.com/broadinstitute/hellbender/pull/804 for initial discussion of the design, and https://github.com/broadinstitute/hellbender/issues/567 for the issue that this solves. This change adds some HTSJDK extensions to work with Hadoop, these should eventually be added to HTSJDK in some form. I was able to run BQSR on a Spark cluster using this code, by using the following:. ``` bash; # Copy BAM into HDFS; hadoop fs -put ./src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam bam/NA12878.chr17_69k_70k.dictFix.bam. # Copy FASTA (reference) into HDFS; hadoop fs -mkdir fasta ; hadoop fs -put ./src/test/resources/human_g1k_v37.chr17_1Mb.fasta fasta/human_g1k_v37.chr17_1Mb.fasta; hadoop fs -put ./src/test/resources/human_g1k_v37.chr17_1Mb.dict fasta/human_g1k_v37.chr17_1Mb.dict; hadoop fs -put ./src/test/resources/human_g1k_v37.chr17_1Mb.fasta.fai fasta/human_g1k_v37.chr17_1Mb.fasta.fai. spark-submit \; --master $SPARK_MASTER \; --conf spark.driver.userClassPathFirst=true \; --conf spark.executor.userClassPathFirst=true \; --conf spark.io.compression.codec=lzf \; build/libs/hellbender-all-*-spark.jar ApplyWholeBQSRDataflow \; --reference hdfs://$NAMENODE/user/$USER/fasta/human_g1k_v37.chr17_1Mb.fasta \; --input hdfs://$NAMENODE/user/$USER/bam/NA12878.chr17_69k_70k.dictFix.bam \; --output hdfs://$NAMENODE/user/$USER/out/bqsr \; --knownSites $HELLBENDER_HOME/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf \; --RECAL_TABLE_FILE /dev/stdout \; --runner SPARK \; --sparkMaster $SPARK_MASTER ; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/827
https://github.com/broadinstitute/gatk/pull/827:1534,Testability,test,test,1534,"All ways of reading reference sequences are hidden behind a common interface,; ReferenceDataflowSource. See https://github.com/broadinstitute/hellbender/pull/804 for initial discussion of the design, and https://github.com/broadinstitute/hellbender/issues/567 for the issue that this solves. This change adds some HTSJDK extensions to work with Hadoop, these should eventually be added to HTSJDK in some form. I was able to run BQSR on a Spark cluster using this code, by using the following:. ``` bash; # Copy BAM into HDFS; hadoop fs -put ./src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam bam/NA12878.chr17_69k_70k.dictFix.bam. # Copy FASTA (reference) into HDFS; hadoop fs -mkdir fasta ; hadoop fs -put ./src/test/resources/human_g1k_v37.chr17_1Mb.fasta fasta/human_g1k_v37.chr17_1Mb.fasta; hadoop fs -put ./src/test/resources/human_g1k_v37.chr17_1Mb.dict fasta/human_g1k_v37.chr17_1Mb.dict; hadoop fs -put ./src/test/resources/human_g1k_v37.chr17_1Mb.fasta.fai fasta/human_g1k_v37.chr17_1Mb.fasta.fai. spark-submit \; --master $SPARK_MASTER \; --conf spark.driver.userClassPathFirst=true \; --conf spark.executor.userClassPathFirst=true \; --conf spark.io.compression.codec=lzf \; build/libs/hellbender-all-*-spark.jar ApplyWholeBQSRDataflow \; --reference hdfs://$NAMENODE/user/$USER/fasta/human_g1k_v37.chr17_1Mb.fasta \; --input hdfs://$NAMENODE/user/$USER/bam/NA12878.chr17_69k_70k.dictFix.bam \; --output hdfs://$NAMENODE/user/$USER/out/bqsr \; --knownSites $HELLBENDER_HOME/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf \; --RECAL_TABLE_FILE /dev/stdout \; --runner SPARK \; --sparkMaster $SPARK_MASTER ; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/827
https://github.com/broadinstitute/gatk/issues/828:1254,Integrability,wrap,wrapAndCopyInto,1254,"; (...); [August 17, 2015 2:04:43 PM PDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 0.48 minutes.; Runtime.totalMemory()=412090368; java.lang.IllegalArgumentException: end must be >= start. start:2801961 end:2801960; at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:33); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:45); at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$19(ReadWalker.java:64); at org.broadinstitute.hellbender.engine.ReadWalker$$Lambda$50/1094674892.accept(Unknown Source); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:63); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:370); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:97); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:150); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:71); at org.broadinstitute.hellbender.Main.main(Main.java:86); jpmartin@hiseq:~/prog/GitHub/hellbender-main$",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/828
https://github.com/broadinstitute/gatk/issues/828:439,Security,validat,validatePositions,439,"I didn't expect Hellbender to crash for this command:. `$ ./hb PrintReads -I CEUTrio.HiSeq.WGS.b37.NA12878.bam -O 4m.bam -L 20:1000000-4000000`; (...); [August 17, 2015 2:04:43 PM PDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 0.48 minutes.; Runtime.totalMemory()=412090368; java.lang.IllegalArgumentException: end must be >= start. start:2801961 end:2801960; at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:33); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:45); at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$19(ReadWalker.java:64); at org.broadinstitute.hellbender.engine.ReadWalker$$Lambda$50/1094674892.accept(Unknown Source); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:63); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:370); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:97); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:150); at org.broadinstitute.hellb",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/828
https://github.com/broadinstitute/gatk/issues/828:424,Usability,Simpl,SimpleInterval,424,"I didn't expect Hellbender to crash for this command:. `$ ./hb PrintReads -I CEUTrio.HiSeq.WGS.b37.NA12878.bam -O 4m.bam -L 20:1000000-4000000`; (...); [August 17, 2015 2:04:43 PM PDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 0.48 minutes.; Runtime.totalMemory()=412090368; java.lang.IllegalArgumentException: end must be >= start. start:2801961 end:2801960; at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:33); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:45); at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$19(ReadWalker.java:64); at org.broadinstitute.hellbender.engine.ReadWalker$$Lambda$50/1094674892.accept(Unknown Source); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:63); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:370); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:97); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:150); at org.broadinstitute.hellb",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/828
https://github.com/broadinstitute/gatk/issues/828:457,Usability,Simpl,SimpleInterval,457,"I didn't expect Hellbender to crash for this command:. `$ ./hb PrintReads -I CEUTrio.HiSeq.WGS.b37.NA12878.bam -O 4m.bam -L 20:1000000-4000000`; (...); [August 17, 2015 2:04:43 PM PDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 0.48 minutes.; Runtime.totalMemory()=412090368; java.lang.IllegalArgumentException: end must be >= start. start:2801961 end:2801960; at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:33); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:45); at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$19(ReadWalker.java:64); at org.broadinstitute.hellbender.engine.ReadWalker$$Lambda$50/1094674892.accept(Unknown Source); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:63); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:370); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:97); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:150); at org.broadinstitute.hellb",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/828
https://github.com/broadinstitute/gatk/issues/828:521,Usability,Simpl,SimpleInterval,521,"I didn't expect Hellbender to crash for this command:. `$ ./hb PrintReads -I CEUTrio.HiSeq.WGS.b37.NA12878.bam -O 4m.bam -L 20:1000000-4000000`; (...); [August 17, 2015 2:04:43 PM PDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 0.48 minutes.; Runtime.totalMemory()=412090368; java.lang.IllegalArgumentException: end must be >= start. start:2801961 end:2801960; at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:33); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:45); at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$19(ReadWalker.java:64); at org.broadinstitute.hellbender.engine.ReadWalker$$Lambda$50/1094674892.accept(Unknown Source); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:63); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:370); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:97); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:150); at org.broadinstitute.hellb",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/828
https://github.com/broadinstitute/gatk/issues/828:543,Usability,Simpl,SimpleInterval,543,"I didn't expect Hellbender to crash for this command:. `$ ./hb PrintReads -I CEUTrio.HiSeq.WGS.b37.NA12878.bam -O 4m.bam -L 20:1000000-4000000`; (...); [August 17, 2015 2:04:43 PM PDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 0.48 minutes.; Runtime.totalMemory()=412090368; java.lang.IllegalArgumentException: end must be >= start. start:2801961 end:2801960; at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:33); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:45); at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$19(ReadWalker.java:64); at org.broadinstitute.hellbender.engine.ReadWalker$$Lambda$50/1094674892.accept(Unknown Source); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:63); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:370); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:97); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:150); at org.broadinstitute.hellb",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/828
https://github.com/broadinstitute/gatk/issues/828:607,Usability,Simpl,SimpleInterval,607,"I didn't expect Hellbender to crash for this command:. `$ ./hb PrintReads -I CEUTrio.HiSeq.WGS.b37.NA12878.bam -O 4m.bam -L 20:1000000-4000000`; (...); [August 17, 2015 2:04:43 PM PDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 0.48 minutes.; Runtime.totalMemory()=412090368; java.lang.IllegalArgumentException: end must be >= start. start:2801961 end:2801960; at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:33); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:45); at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$19(ReadWalker.java:64); at org.broadinstitute.hellbender.engine.ReadWalker$$Lambda$50/1094674892.accept(Unknown Source); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:63); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:370); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:97); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:150); at org.broadinstitute.hellb",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/828
https://github.com/broadinstitute/gatk/issues/828:629,Usability,Simpl,SimpleInterval,629,"I didn't expect Hellbender to crash for this command:. `$ ./hb PrintReads -I CEUTrio.HiSeq.WGS.b37.NA12878.bam -O 4m.bam -L 20:1000000-4000000`; (...); [August 17, 2015 2:04:43 PM PDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 0.48 minutes.; Runtime.totalMemory()=412090368; java.lang.IllegalArgumentException: end must be >= start. start:2801961 end:2801960; at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:33); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:45); at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$19(ReadWalker.java:64); at org.broadinstitute.hellbender.engine.ReadWalker$$Lambda$50/1094674892.accept(Unknown Source); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:63); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:370); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:97); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:150); at org.broadinstitute.hellb",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/828
https://github.com/broadinstitute/gatk/issues/829:82,Testability,stub,stub,82,"See pull #812 . > Apply the actual BaseRecalibratorTransform here, and delete the stub. If the ; > ReadsPreprocessingPipelineIntegrationTest fails as a result, temporarily disable the test, ; > create a ticket to fix it, and assign it to me. @droazen",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/829
https://github.com/broadinstitute/gatk/issues/829:184,Testability,test,test,184,"See pull #812 . > Apply the actual BaseRecalibratorTransform here, and delete the stub. If the ; > ReadsPreprocessingPipelineIntegrationTest fails as a result, temporarily disable the test, ; > create a ticket to fix it, and assign it to me. @droazen",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/829
https://github.com/broadinstitute/gatk/issues/831:100,Safety,avoid,avoid,100,@tomwhite wrote code to read in the reference from hdfs. We need to move that logic into htsjdk (to avoid the two getting out of sync). Assigning to @droazen for now.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/831
https://github.com/broadinstitute/gatk/issues/831:78,Testability,log,logic,78,@tomwhite wrote code to read in the reference from hdfs. We need to move that logic into htsjdk (to avoid the two getting out of sync). Assigning to @droazen for now.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/831
https://github.com/broadinstitute/gatk/issues/836:275,Integrability,depend,dependency,275,"It's common for Hadoop JARs to be provided at runtime (e.g. when running the `hadoop` or `spark-submit` commands). This is because the client-server RPC is fragile, so it's important to use the same version of each. To solve this we should make the Hadoop JARs a ['provided' dependency](https://maven.apache.org/guides/introduction/introduction-to-dependency-mechanism.html) (in the Maven sense). Gradle doesn't support 'provided' out of the box, so a workaround may be needed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/836
https://github.com/broadinstitute/gatk/issues/836:348,Integrability,depend,dependency-mechanism,348,"It's common for Hadoop JARs to be provided at runtime (e.g. when running the `hadoop` or `spark-submit` commands). This is because the client-server RPC is fragile, so it's important to use the same version of each. To solve this we should make the Hadoop JARs a ['provided' dependency](https://maven.apache.org/guides/introduction/introduction-to-dependency-mechanism.html) (in the Maven sense). Gradle doesn't support 'provided' out of the box, so a workaround may be needed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/836
https://github.com/broadinstitute/gatk/issues/836:312,Usability,guid,guides,312,"It's common for Hadoop JARs to be provided at runtime (e.g. when running the `hadoop` or `spark-submit` commands). This is because the client-server RPC is fragile, so it's important to use the same version of each. To solve this we should make the Hadoop JARs a ['provided' dependency](https://maven.apache.org/guides/introduction/introduction-to-dependency-mechanism.html) (in the Maven sense). Gradle doesn't support 'provided' out of the box, so a workaround may be needed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/836
https://github.com/broadinstitute/gatk/pull/837:10,Testability,test,testing,10,Clarified testing and code review policy,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/837
https://github.com/broadinstitute/gatk/pull/838:28,Testability,test,tests,28,Note that I re-enabled CRAM tests for this tool and included CRAM files for the new tests since the tool itself happily consumes CRAM files. If for some reason this is the wrong thing to do then we probably should disable the tests and change the tool to reject these.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/838
https://github.com/broadinstitute/gatk/pull/838:84,Testability,test,tests,84,Note that I re-enabled CRAM tests for this tool and included CRAM files for the new tests since the tool itself happily consumes CRAM files. If for some reason this is the wrong thing to do then we probably should disable the tests and change the tool to reject these.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/838
https://github.com/broadinstitute/gatk/pull/838:226,Testability,test,tests,226,Note that I re-enabled CRAM tests for this tool and included CRAM files for the new tests since the tool itself happily consumes CRAM files. If for some reason this is the wrong thing to do then we probably should disable the tests and change the tool to reject these.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/838
https://github.com/broadinstitute/gatk/pull/839:157,Deployability,Update,Updated,157,"-Added a ""large files"" directory to src/test/resoureces containing files managed; by ""git lfs"" rather than checked directly into the hellbender repository.; Updated setup instructions in README appropriately to reflect new requirement; for git lfs. -Added a bam with ~600,000 reads from chromosomes 20 and 21, as well as ~50000; unmapped reads. -Added a snippet of the b37 reference with all of chromosomes 20 and 21. -Added a DBSNP vcf containing variants overlapping the reads in the bam above.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/839
https://github.com/broadinstitute/gatk/pull/839:40,Testability,test,test,40,"-Added a ""large files"" directory to src/test/resoureces containing files managed; by ""git lfs"" rather than checked directly into the hellbender repository.; Updated setup instructions in README appropriately to reflect new requirement; for git lfs. -Added a bam with ~600,000 reads from chromosomes 20 and 21, as well as ~50000; unmapped reads. -Added a snippet of the b37 reference with all of chromosomes 20 and 21. -Added a DBSNP vcf containing variants overlapping the reads in the bam above.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/839
https://github.com/broadinstitute/gatk/issues/840:96,Deployability,install,install,96,"Now that we're using git lfs to manage our large test resources, we need to configure travis to install/init git lfs before running the test suite.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/840
https://github.com/broadinstitute/gatk/issues/840:76,Modifiability,config,configure,76,"Now that we're using git lfs to manage our large test resources, we need to configure travis to install/init git lfs before running the test suite.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/840
https://github.com/broadinstitute/gatk/issues/840:49,Testability,test,test,49,"Now that we're using git lfs to manage our large test resources, we need to configure travis to install/init git lfs before running the test suite.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/840
https://github.com/broadinstitute/gatk/issues/840:136,Testability,test,test,136,"Now that we're using git lfs to manage our large test resources, we need to configure travis to install/init git lfs before running the test suite.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/840
https://github.com/broadinstitute/gatk/pull/841:95,Testability,test,tests,95,(includes classes that are not supposed to be reviewed and added here only to compile and make tests pass. Those classes are being reviewed in other pull requests. I'll mark them on github),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/841
https://github.com/broadinstitute/gatk/pull/845:165,Deployability,integrat,integration,165,"for writing BAM files. This reduces memory usage since the reads; don't need to all be stored in memory. Also add some missing calls to addDataflowRunnerArgs in the integration; tests to ensure the correct dataflow runner is being picked up. This is related to https://github.com/broadinstitute/hellbender/issues/771, for the Spark/Hadoop side.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/845
https://github.com/broadinstitute/gatk/pull/845:28,Energy Efficiency,reduce,reduces,28,"for writing BAM files. This reduces memory usage since the reads; don't need to all be stored in memory. Also add some missing calls to addDataflowRunnerArgs in the integration; tests to ensure the correct dataflow runner is being picked up. This is related to https://github.com/broadinstitute/hellbender/issues/771, for the Spark/Hadoop side.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/845
https://github.com/broadinstitute/gatk/pull/845:165,Integrability,integrat,integration,165,"for writing BAM files. This reduces memory usage since the reads; don't need to all be stored in memory. Also add some missing calls to addDataflowRunnerArgs in the integration; tests to ensure the correct dataflow runner is being picked up. This is related to https://github.com/broadinstitute/hellbender/issues/771, for the Spark/Hadoop side.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/845
https://github.com/broadinstitute/gatk/pull/845:178,Testability,test,tests,178,"for writing BAM files. This reduces memory usage since the reads; don't need to all be stored in memory. Also add some missing calls to addDataflowRunnerArgs in the integration; tests to ensure the correct dataflow runner is being picked up. This is related to https://github.com/broadinstitute/hellbender/issues/771, for the Spark/Hadoop side.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/845
https://github.com/broadinstitute/gatk/pull/850:162,Availability,mask,masked,162,"A few things worth mentioning. 1) This skeleton is mostly a direct port of the existing Dataflow pipeline.; 2) I had to modify some test data because there is a (masked) bug in the Dataflow code, see #795.; 3) Serialization was a slight pain and I had to bump the kryo version to the latest 2.x, as well as add two custom Serializers. If there's a cleaner way to handle any of that I'm all ears.; 4) I'm using Hadoop-bam for reading and writing reads and variants.; 5) There are unit tests for all code except for the skeleton itself. I've run it on a cluster on my machine successfully, but haven't written the tests (which will take a little while to design and get right).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/850
https://github.com/broadinstitute/gatk/pull/850:97,Deployability,pipeline,pipeline,97,"A few things worth mentioning. 1) This skeleton is mostly a direct port of the existing Dataflow pipeline.; 2) I had to modify some test data because there is a (masked) bug in the Dataflow code, see #795.; 3) Serialization was a slight pain and I had to bump the kryo version to the latest 2.x, as well as add two custom Serializers. If there's a cleaner way to handle any of that I'm all ears.; 4) I'm using Hadoop-bam for reading and writing reads and variants.; 5) There are unit tests for all code except for the skeleton itself. I've run it on a cluster on my machine successfully, but haven't written the tests (which will take a little while to design and get right).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/850
https://github.com/broadinstitute/gatk/pull/850:132,Testability,test,test,132,"A few things worth mentioning. 1) This skeleton is mostly a direct port of the existing Dataflow pipeline.; 2) I had to modify some test data because there is a (masked) bug in the Dataflow code, see #795.; 3) Serialization was a slight pain and I had to bump the kryo version to the latest 2.x, as well as add two custom Serializers. If there's a cleaner way to handle any of that I'm all ears.; 4) I'm using Hadoop-bam for reading and writing reads and variants.; 5) There are unit tests for all code except for the skeleton itself. I've run it on a cluster on my machine successfully, but haven't written the tests (which will take a little while to design and get right).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/850
https://github.com/broadinstitute/gatk/pull/850:484,Testability,test,tests,484,"A few things worth mentioning. 1) This skeleton is mostly a direct port of the existing Dataflow pipeline.; 2) I had to modify some test data because there is a (masked) bug in the Dataflow code, see #795.; 3) Serialization was a slight pain and I had to bump the kryo version to the latest 2.x, as well as add two custom Serializers. If there's a cleaner way to handle any of that I'm all ears.; 4) I'm using Hadoop-bam for reading and writing reads and variants.; 5) There are unit tests for all code except for the skeleton itself. I've run it on a cluster on my machine successfully, but haven't written the tests (which will take a little while to design and get right).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/850
https://github.com/broadinstitute/gatk/pull/850:612,Testability,test,tests,612,"A few things worth mentioning. 1) This skeleton is mostly a direct port of the existing Dataflow pipeline.; 2) I had to modify some test data because there is a (masked) bug in the Dataflow code, see #795.; 3) Serialization was a slight pain and I had to bump the kryo version to the latest 2.x, as well as add two custom Serializers. If there's a cleaner way to handle any of that I'm all ears.; 4) I'm using Hadoop-bam for reading and writing reads and variants.; 5) There are unit tests for all code except for the skeleton itself. I've run it on a cluster on my machine successfully, but haven't written the tests (which will take a little while to design and get right).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/850
https://github.com/broadinstitute/gatk/pull/852:334,Availability,error,errors,334,"Arguments may now define `sensitive`. Sensitive arguments will be printed as ***\* instead of as their value.; Removed output of raw command line from IntegrationTestSpec. The censored command line is output by the command line program itself. These changes are far from bulletproof. Sensitive arguments may be leaked stack traces or errors, but it should fix the worst offenders.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/852
https://github.com/broadinstitute/gatk/pull/852:151,Deployability,Integrat,IntegrationTestSpec,151,"Arguments may now define `sensitive`. Sensitive arguments will be printed as ***\* instead of as their value.; Removed output of raw command line from IntegrationTestSpec. The censored command line is output by the command line program itself. These changes are far from bulletproof. Sensitive arguments may be leaked stack traces or errors, but it should fix the worst offenders.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/852
https://github.com/broadinstitute/gatk/pull/852:151,Integrability,Integrat,IntegrationTestSpec,151,"Arguments may now define `sensitive`. Sensitive arguments will be printed as ***\* instead of as their value.; Removed output of raw command line from IntegrationTestSpec. The censored command line is output by the command line program itself. These changes are far from bulletproof. Sensitive arguments may be leaked stack traces or errors, but it should fix the worst offenders.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/852
https://github.com/broadinstitute/gatk/pull/853:192,Deployability,install,install,192,"after the addition of travis_wait gradle check travis was executing gradle check twice; with ./gradlew and one with gradle. This was happening because it was being run onces explicitly in the install phase and once implicitly in the script phase. this was causing some strange issues. instead of using travis_wait, I made the dataflow cloud tests output status information as they go; this similarly prevents travis from timing out due to lack of output, but doesn't need the travis_wait; if we add any really long running dataflow tests, or really highly spammy ones we'll have to revisit this",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/853
https://github.com/broadinstitute/gatk/pull/853:341,Testability,test,tests,341,"after the addition of travis_wait gradle check travis was executing gradle check twice; with ./gradlew and one with gradle. This was happening because it was being run onces explicitly in the install phase and once implicitly in the script phase. this was causing some strange issues. instead of using travis_wait, I made the dataflow cloud tests output status information as they go; this similarly prevents travis from timing out due to lack of output, but doesn't need the travis_wait; if we add any really long running dataflow tests, or really highly spammy ones we'll have to revisit this",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/853
https://github.com/broadinstitute/gatk/pull/853:532,Testability,test,tests,532,"after the addition of travis_wait gradle check travis was executing gradle check twice; with ./gradlew and one with gradle. This was happening because it was being run onces explicitly in the install phase and once implicitly in the script phase. this was causing some strange issues. instead of using travis_wait, I made the dataflow cloud tests output status information as they go; this similarly prevents travis from timing out due to lack of output, but doesn't need the travis_wait; if we add any really long running dataflow tests, or really highly spammy ones we'll have to revisit this",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/853
https://github.com/broadinstitute/gatk/issues/855:148,Performance,perform,performance,148,Look into broadcasting the reference to all of the workers. This would make AddContextDataToReadSpark and the BQSR code simpler and may have better performance than our current code.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/855
https://github.com/broadinstitute/gatk/issues/855:120,Usability,simpl,simpler,120,Look into broadcasting the reference to all of the workers. This would make AddContextDataToReadSpark and the BQSR code simpler and may have better performance than our current code.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/855
https://github.com/broadinstitute/gatk/pull/857:10,Deployability,integrat,integration,10,Completed integration test and added two test files.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/857
https://github.com/broadinstitute/gatk/pull/857:10,Integrability,integrat,integration,10,Completed integration test and added two test files.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/857
https://github.com/broadinstitute/gatk/pull/857:22,Testability,test,test,22,Completed integration test and added two test files.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/857
https://github.com/broadinstitute/gatk/pull/857:41,Testability,test,test,41,Completed integration test and added two test files.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/857
https://github.com/broadinstitute/gatk/pull/858:10,Deployability,integrat,integration,10,Completed integration test. Thanks to @akiezun.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/858
https://github.com/broadinstitute/gatk/pull/858:10,Integrability,integrat,integration,10,Completed integration test. Thanks to @akiezun.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/858
https://github.com/broadinstitute/gatk/pull/858:22,Testability,test,test,22,Completed integration test. Thanks to @akiezun.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/858
https://github.com/broadinstitute/gatk/pull/859:27,Testability,test,tests,27,"Porting the GVCFWriter and tests. the first commit includes the original gatk classes modulo some import statements and package names; the next commit is my changes on top of it. closes #736. <!-- Reviewable:start -->. [<img src=""https://reviewable.io/review_button.png"" height=40 alt=""Review on Reviewable""/>](https://reviewable.io/reviews/broadinstitute/gatk/859). <!-- Reviewable:end -->",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/859
https://github.com/broadinstitute/gatk/pull/860:5,Testability,test,tests,5,"-Add tests with an input cram and an output sam, bam, or cram with various intervals; provided to the -L argument, and check that we get the expected reads in the output; for each set of intervals. -Generalize CRAMReferenceIntegrationTest to CRAMSupportIntegrationTest, and centralize; cram test data in the engine package. Resolves #675",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/860
https://github.com/broadinstitute/gatk/pull/860:291,Testability,test,test,291,"-Add tests with an input cram and an output sam, bam, or cram with various intervals; provided to the -L argument, and check that we get the expected reads in the output; for each set of intervals. -Generalize CRAMReferenceIntegrationTest to CRAMSupportIntegrationTest, and centralize; cram test data in the engine package. Resolves #675",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/860
https://github.com/broadinstitute/gatk/issues/861:0,Usability,Simpl,Simply,0,"Simply take the methods in org.broadinstitute.hellbender.utils.param.ParamUtils and add to org.broadinstitute.hellbender.utils.Utils, since these are all static. Then delete ParamUtils and have all usages use Utils.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/861
https://github.com/broadinstitute/gatk/pull/862:87,Testability,test,test,87,"This gets BaseRecalibratorDataflowIntegrationTest running on Spark. I noticed that the test with ""-knownSites"" from BaseRecalibratorIntegrationTest (i.e. the non-dataflow version) fails with both the Direct and Spark runners. I had a look at the file output and there are a few discrepancies (see diff below). Any thoughts on how to fix this? I've commented out the test in this PR. ```; diff /var/folders/d1/8f5_j4hx04z72w6wgqxkb2l40000gn/T/walktest.tmp_param.02172067147450353519.tmp src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.NA12878.chr17_69k_70k.2inputs.txt; 60c60; < 34 3051 34. ---; > 34 3050 34; 71c71; < 45 46942 45. ---; > 45 46940 45; 124,126c124,126; < 809R9ABXX101220.5 D 45.0000 45.0000 23471 0.00; < 809R9ABXX101220.5 I 45.0000 45.0000 23471 0.00; < 809R9ABXX101220.5 M 27.0000 27.0494 23471 49.13. ---; > 809R9ABXX101220.5 D 45.0000 45.0000 23470 0.00; > 809R9ABXX101220.5 I 45.0000 45.0000 23470 0.00; > 809R9ABXX101220.5 M 27.0000 27.0493 23470 49.13; 155c155; < 809R9ABXX101220.5 34 M 34.0000 3051 2.96. ---; > 809R9ABXX101220.5 34 M 34.0000 3050 2.96; 161,162c161,162; < 809R9ABXX101220.5 45 D 45.0000 23471 0.00; < 809R9ABXX101220.5 45 I 45.0000 23471 0.00. ---; > 809R9ABXX101220.5 45 D 45.0000 23470 0.00; > 809R9ABXX101220.5 45 I 45.0000 23470 0.00; 2714c2714; < 809R9ABXX101220.5 34 29 Cycle M 34.0000 20 0.00. ---; > 809R9ABXX101220.5 34 29 Cycle M 34.0000 19 0.00; 2773c2773; < 809R9ABXX101220.5 34 CA Context M 34.0000 506 0.00. ---; > 809R9ABXX101220.5 34 CA Context M 34.0000 505 0.00; 3464,3465c3464,3465; < 809R9ABXX101220.5 45 29 Cycle D 45.0000 180 0.00; < 809R9ABXX101220.5 45 29 Cycle I 45.0000 180 0.00. ---; > 809R9ABXX101220.5 45 29 Cycle D 45.0000 179 0.00; > 809R9ABXX101220.5 45 29 Cycle I 45.0000 179 0.00; 3634,3635c3634,3635; < 809R9ABXX101220.5 45 GCA Context D 45.0000 278 0.00; < 809R9ABXX101220.5 45 GCA Context I 45.0000 278 0.00. ---; > 809R9ABXX101220.5 45 GCA Context D 45.0000 277 0.00; > 809R9ABXX101220.5 45 GCA Context",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/862
https://github.com/broadinstitute/gatk/pull/862:366,Testability,test,test,366,"This gets BaseRecalibratorDataflowIntegrationTest running on Spark. I noticed that the test with ""-knownSites"" from BaseRecalibratorIntegrationTest (i.e. the non-dataflow version) fails with both the Direct and Spark runners. I had a look at the file output and there are a few discrepancies (see diff below). Any thoughts on how to fix this? I've commented out the test in this PR. ```; diff /var/folders/d1/8f5_j4hx04z72w6wgqxkb2l40000gn/T/walktest.tmp_param.02172067147450353519.tmp src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.NA12878.chr17_69k_70k.2inputs.txt; 60c60; < 34 3051 34. ---; > 34 3050 34; 71c71; < 45 46942 45. ---; > 45 46940 45; 124,126c124,126; < 809R9ABXX101220.5 D 45.0000 45.0000 23471 0.00; < 809R9ABXX101220.5 I 45.0000 45.0000 23471 0.00; < 809R9ABXX101220.5 M 27.0000 27.0494 23471 49.13. ---; > 809R9ABXX101220.5 D 45.0000 45.0000 23470 0.00; > 809R9ABXX101220.5 I 45.0000 45.0000 23470 0.00; > 809R9ABXX101220.5 M 27.0000 27.0493 23470 49.13; 155c155; < 809R9ABXX101220.5 34 M 34.0000 3051 2.96. ---; > 809R9ABXX101220.5 34 M 34.0000 3050 2.96; 161,162c161,162; < 809R9ABXX101220.5 45 D 45.0000 23471 0.00; < 809R9ABXX101220.5 45 I 45.0000 23471 0.00. ---; > 809R9ABXX101220.5 45 D 45.0000 23470 0.00; > 809R9ABXX101220.5 45 I 45.0000 23470 0.00; 2714c2714; < 809R9ABXX101220.5 34 29 Cycle M 34.0000 20 0.00. ---; > 809R9ABXX101220.5 34 29 Cycle M 34.0000 19 0.00; 2773c2773; < 809R9ABXX101220.5 34 CA Context M 34.0000 506 0.00. ---; > 809R9ABXX101220.5 34 CA Context M 34.0000 505 0.00; 3464,3465c3464,3465; < 809R9ABXX101220.5 45 29 Cycle D 45.0000 180 0.00; < 809R9ABXX101220.5 45 29 Cycle I 45.0000 180 0.00. ---; > 809R9ABXX101220.5 45 29 Cycle D 45.0000 179 0.00; > 809R9ABXX101220.5 45 29 Cycle I 45.0000 179 0.00; 3634,3635c3634,3635; < 809R9ABXX101220.5 45 GCA Context D 45.0000 278 0.00; < 809R9ABXX101220.5 45 GCA Context I 45.0000 278 0.00. ---; > 809R9ABXX101220.5 45 GCA Context D 45.0000 277 0.00; > 809R9ABXX101220.5 45 GCA Context",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/862
https://github.com/broadinstitute/gatk/pull/862:490,Testability,test,test,490,"This gets BaseRecalibratorDataflowIntegrationTest running on Spark. I noticed that the test with ""-knownSites"" from BaseRecalibratorIntegrationTest (i.e. the non-dataflow version) fails with both the Direct and Spark runners. I had a look at the file output and there are a few discrepancies (see diff below). Any thoughts on how to fix this? I've commented out the test in this PR. ```; diff /var/folders/d1/8f5_j4hx04z72w6wgqxkb2l40000gn/T/walktest.tmp_param.02172067147450353519.tmp src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.NA12878.chr17_69k_70k.2inputs.txt; 60c60; < 34 3051 34. ---; > 34 3050 34; 71c71; < 45 46942 45. ---; > 45 46940 45; 124,126c124,126; < 809R9ABXX101220.5 D 45.0000 45.0000 23471 0.00; < 809R9ABXX101220.5 I 45.0000 45.0000 23471 0.00; < 809R9ABXX101220.5 M 27.0000 27.0494 23471 49.13. ---; > 809R9ABXX101220.5 D 45.0000 45.0000 23470 0.00; > 809R9ABXX101220.5 I 45.0000 45.0000 23470 0.00; > 809R9ABXX101220.5 M 27.0000 27.0493 23470 49.13; 155c155; < 809R9ABXX101220.5 34 M 34.0000 3051 2.96. ---; > 809R9ABXX101220.5 34 M 34.0000 3050 2.96; 161,162c161,162; < 809R9ABXX101220.5 45 D 45.0000 23471 0.00; < 809R9ABXX101220.5 45 I 45.0000 23471 0.00. ---; > 809R9ABXX101220.5 45 D 45.0000 23470 0.00; > 809R9ABXX101220.5 45 I 45.0000 23470 0.00; 2714c2714; < 809R9ABXX101220.5 34 29 Cycle M 34.0000 20 0.00. ---; > 809R9ABXX101220.5 34 29 Cycle M 34.0000 19 0.00; 2773c2773; < 809R9ABXX101220.5 34 CA Context M 34.0000 506 0.00. ---; > 809R9ABXX101220.5 34 CA Context M 34.0000 505 0.00; 3464,3465c3464,3465; < 809R9ABXX101220.5 45 29 Cycle D 45.0000 180 0.00; < 809R9ABXX101220.5 45 29 Cycle I 45.0000 180 0.00. ---; > 809R9ABXX101220.5 45 29 Cycle D 45.0000 179 0.00; > 809R9ABXX101220.5 45 29 Cycle I 45.0000 179 0.00; 3634,3635c3634,3635; < 809R9ABXX101220.5 45 GCA Context D 45.0000 278 0.00; < 809R9ABXX101220.5 45 GCA Context I 45.0000 278 0.00. ---; > 809R9ABXX101220.5 45 GCA Context D 45.0000 277 0.00; > 809R9ABXX101220.5 45 GCA Context",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/862
https://github.com/broadinstitute/gatk/pull/863:68,Modifiability,refactor,refactor,68,MarkDuplicates performance optimizations. This includes:; - a small refactor of the original MarkDuplicatesDataflow so that most of the core code can be reused directly in the optimized version; - helper classes to keep the optimized code organized and dataflow-like; - reworked input for performance; - the optimized code spends a lot less time moving data across machines; - performance bugfixes:; - UUID generation; - format conversion,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/863
https://github.com/broadinstitute/gatk/pull/863:15,Performance,perform,performance,15,MarkDuplicates performance optimizations. This includes:; - a small refactor of the original MarkDuplicatesDataflow so that most of the core code can be reused directly in the optimized version; - helper classes to keep the optimized code organized and dataflow-like; - reworked input for performance; - the optimized code spends a lot less time moving data across machines; - performance bugfixes:; - UUID generation; - format conversion,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/863
https://github.com/broadinstitute/gatk/pull/863:27,Performance,optimiz,optimizations,27,MarkDuplicates performance optimizations. This includes:; - a small refactor of the original MarkDuplicatesDataflow so that most of the core code can be reused directly in the optimized version; - helper classes to keep the optimized code organized and dataflow-like; - reworked input for performance; - the optimized code spends a lot less time moving data across machines; - performance bugfixes:; - UUID generation; - format conversion,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/863
https://github.com/broadinstitute/gatk/pull/863:176,Performance,optimiz,optimized,176,MarkDuplicates performance optimizations. This includes:; - a small refactor of the original MarkDuplicatesDataflow so that most of the core code can be reused directly in the optimized version; - helper classes to keep the optimized code organized and dataflow-like; - reworked input for performance; - the optimized code spends a lot less time moving data across machines; - performance bugfixes:; - UUID generation; - format conversion,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/863
https://github.com/broadinstitute/gatk/pull/863:224,Performance,optimiz,optimized,224,MarkDuplicates performance optimizations. This includes:; - a small refactor of the original MarkDuplicatesDataflow so that most of the core code can be reused directly in the optimized version; - helper classes to keep the optimized code organized and dataflow-like; - reworked input for performance; - the optimized code spends a lot less time moving data across machines; - performance bugfixes:; - UUID generation; - format conversion,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/863
https://github.com/broadinstitute/gatk/pull/863:289,Performance,perform,performance,289,MarkDuplicates performance optimizations. This includes:; - a small refactor of the original MarkDuplicatesDataflow so that most of the core code can be reused directly in the optimized version; - helper classes to keep the optimized code organized and dataflow-like; - reworked input for performance; - the optimized code spends a lot less time moving data across machines; - performance bugfixes:; - UUID generation; - format conversion,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/863
https://github.com/broadinstitute/gatk/pull/863:308,Performance,optimiz,optimized,308,MarkDuplicates performance optimizations. This includes:; - a small refactor of the original MarkDuplicatesDataflow so that most of the core code can be reused directly in the optimized version; - helper classes to keep the optimized code organized and dataflow-like; - reworked input for performance; - the optimized code spends a lot less time moving data across machines; - performance bugfixes:; - UUID generation; - format conversion,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/863
https://github.com/broadinstitute/gatk/pull/863:377,Performance,perform,performance,377,MarkDuplicates performance optimizations. This includes:; - a small refactor of the original MarkDuplicatesDataflow so that most of the core code can be reused directly in the optimized version; - helper classes to keep the optimized code organized and dataflow-like; - reworked input for performance; - the optimized code spends a lot less time moving data across machines; - performance bugfixes:; - UUID generation; - format conversion,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/863
https://github.com/broadinstitute/gatk/issues/866:110,Availability,error,error,110,"Somewhere between #835 and now, BaseRecalibrator stopped working. When I try to run testBQSRBucket, I get the error below. This test is currently enabled so regression tests should have caught this. ```; java.lang.RuntimeException: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:131); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:104); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:86); at org.broadinstitute.hellbender.tools.dataflow.pipelines.BaseRecalibratorDataflowIntegrationTest.testBQSRBucket(BaseRecalibratorDataflowIntegrationTest.java:176); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:412,Deployability,Integrat,IntegrationTestSpec,412,"Somewhere between #835 and now, BaseRecalibrator stopped working. When I try to run testBQSRBucket, I get the error below. This test is currently enabled so regression tests should have caught this. ```; java.lang.RuntimeException: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:131); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:104); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:86); at org.broadinstitute.hellbender.tools.dataflow.pipelines.BaseRecalibratorDataflowIntegrationTest.testBQSRBucket(BaseRecalibratorDataflowIntegrationTest.java:176); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:444,Deployability,Integrat,IntegrationTestSpec,444,"Somewhere between #835 and now, BaseRecalibrator stopped working. When I try to run testBQSRBucket, I get the error below. This test is currently enabled so regression tests should have caught this. ```; java.lang.RuntimeException: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:131); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:104); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:86); at org.broadinstitute.hellbender.tools.dataflow.pipelines.BaseRecalibratorDataflowIntegrationTest.testBQSRBucket(BaseRecalibratorDataflowIntegrationTest.java:176); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:514,Deployability,Integrat,IntegrationTestSpec,514,"Somewhere between #835 and now, BaseRecalibrator stopped working. When I try to run testBQSRBucket, I get the error below. This test is currently enabled so regression tests should have caught this. ```; java.lang.RuntimeException: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:131); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:104); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:86); at org.broadinstitute.hellbender.tools.dataflow.pipelines.BaseRecalibratorDataflowIntegrationTest.testBQSRBucket(BaseRecalibratorDataflowIntegrationTest.java:176); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:546,Deployability,Integrat,IntegrationTestSpec,546,"Somewhere between #835 and now, BaseRecalibrator stopped working. When I try to run testBQSRBucket, I get the error below. This test is currently enabled so regression tests should have caught this. ```; java.lang.RuntimeException: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:131); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:104); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:86); at org.broadinstitute.hellbender.tools.dataflow.pipelines.BaseRecalibratorDataflowIntegrationTest.testBQSRBucket(BaseRecalibratorDataflowIntegrationTest.java:176); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:616,Deployability,Integrat,IntegrationTestSpec,616,"Somewhere between #835 and now, BaseRecalibrator stopped working. When I try to run testBQSRBucket, I get the error below. This test is currently enabled so regression tests should have caught this. ```; java.lang.RuntimeException: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:131); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:104); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:86); at org.broadinstitute.hellbender.tools.dataflow.pipelines.BaseRecalibratorDataflowIntegrationTest.testBQSRBucket(BaseRecalibratorDataflowIntegrationTest.java:176); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:648,Deployability,Integrat,IntegrationTestSpec,648,"Somewhere between #835 and now, BaseRecalibrator stopped working. When I try to run testBQSRBucket, I get the error below. This test is currently enabled so regression tests should have caught this. ```; java.lang.RuntimeException: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:131); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:104); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:86); at org.broadinstitute.hellbender.tools.dataflow.pipelines.BaseRecalibratorDataflowIntegrationTest.testBQSRBucket(BaseRecalibratorDataflowIntegrationTest.java:176); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:726,Deployability,pipeline,pipelines,726,"Somewhere between #835 and now, BaseRecalibrator stopped working. When I try to run testBQSRBucket, I get the error below. This test is currently enabled so regression tests should have caught this. ```; java.lang.RuntimeException: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:131); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:104); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:86); at org.broadinstitute.hellbender.tools.dataflow.pipelines.BaseRecalibratorDataflowIntegrationTest.testBQSRBucket(BaseRecalibratorDataflowIntegrationTest.java:176); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:3031,Deployability,Pipeline,Pipeline,3031,unnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140); Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at com.google.cloud.dataflow.sdk.Pipeline.run(Pipeline.java:166); at org.broadinstitute.hellbender.engine.dataflow.DataflowCommandLineProgram.runPipeline(DataflowCommandLineProgram.java:145); at org.broadinstitute.hellbender.engine.dataflow.DataflowCommandLineProgram.doWork(DataflowCommandLineProgram.java:107); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:98); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:151); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:71); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:78); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:75); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:126); ... 33 more; Caused by: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at com.google.cloud.genomics.dataflow.readers.bam.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:3044,Deployability,Pipeline,Pipeline,3044,.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140); Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at com.google.cloud.dataflow.sdk.Pipeline.run(Pipeline.java:166); at org.broadinstitute.hellbender.engine.dataflow.DataflowCommandLineProgram.runPipeline(DataflowCommandLineProgram.java:145); at org.broadinstitute.hellbender.engine.dataflow.DataflowCommandLineProgram.doWork(DataflowCommandLineProgram.java:107); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:98); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:151); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:71); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:78); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:75); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:126); ... 33 more; Caused by: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at com.google.cloud.genomics.dataflow.readers.bam.Reader.proc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:3786,Deployability,Integrat,IntegrationTestSpec,3786,ng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140); Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at com.google.cloud.dataflow.sdk.Pipeline.run(Pipeline.java:166); at org.broadinstitute.hellbender.engine.dataflow.DataflowCommandLineProgram.runPipeline(DataflowCommandLineProgram.java:145); at org.broadinstitute.hellbender.engine.dataflow.DataflowCommandLineProgram.doWork(DataflowCommandLineProgram.java:107); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:98); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:151); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:71); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:78); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:75); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:126); ... 33 more; Caused by: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at com.google.cloud.genomics.dataflow.readers.bam.Reader.process(Reader.java:93); at com.google.cloud.genomics.dataflow.readers.bam.ReadBAMTransform$ReadFn.processElement(ReadBAMTransform.java:68); ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:3818,Deployability,Integrat,IntegrationTestSpec,3818,ng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140); Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at com.google.cloud.dataflow.sdk.Pipeline.run(Pipeline.java:166); at org.broadinstitute.hellbender.engine.dataflow.DataflowCommandLineProgram.runPipeline(DataflowCommandLineProgram.java:145); at org.broadinstitute.hellbender.engine.dataflow.DataflowCommandLineProgram.doWork(DataflowCommandLineProgram.java:107); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:98); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:151); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:71); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:78); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:75); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:126); ... 33 more; Caused by: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at com.google.cloud.genomics.dataflow.readers.bam.Reader.process(Reader.java:93); at com.google.cloud.genomics.dataflow.readers.bam.ReadBAMTransform$ReadFn.processElement(ReadBAMTransform.java:68); ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:412,Integrability,Integrat,IntegrationTestSpec,412,"Somewhere between #835 and now, BaseRecalibrator stopped working. When I try to run testBQSRBucket, I get the error below. This test is currently enabled so regression tests should have caught this. ```; java.lang.RuntimeException: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:131); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:104); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:86); at org.broadinstitute.hellbender.tools.dataflow.pipelines.BaseRecalibratorDataflowIntegrationTest.testBQSRBucket(BaseRecalibratorDataflowIntegrationTest.java:176); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:444,Integrability,Integrat,IntegrationTestSpec,444,"Somewhere between #835 and now, BaseRecalibrator stopped working. When I try to run testBQSRBucket, I get the error below. This test is currently enabled so regression tests should have caught this. ```; java.lang.RuntimeException: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:131); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:104); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:86); at org.broadinstitute.hellbender.tools.dataflow.pipelines.BaseRecalibratorDataflowIntegrationTest.testBQSRBucket(BaseRecalibratorDataflowIntegrationTest.java:176); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:514,Integrability,Integrat,IntegrationTestSpec,514,"Somewhere between #835 and now, BaseRecalibrator stopped working. When I try to run testBQSRBucket, I get the error below. This test is currently enabled so regression tests should have caught this. ```; java.lang.RuntimeException: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:131); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:104); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:86); at org.broadinstitute.hellbender.tools.dataflow.pipelines.BaseRecalibratorDataflowIntegrationTest.testBQSRBucket(BaseRecalibratorDataflowIntegrationTest.java:176); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:546,Integrability,Integrat,IntegrationTestSpec,546,"Somewhere between #835 and now, BaseRecalibrator stopped working. When I try to run testBQSRBucket, I get the error below. This test is currently enabled so regression tests should have caught this. ```; java.lang.RuntimeException: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:131); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:104); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:86); at org.broadinstitute.hellbender.tools.dataflow.pipelines.BaseRecalibratorDataflowIntegrationTest.testBQSRBucket(BaseRecalibratorDataflowIntegrationTest.java:176); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:616,Integrability,Integrat,IntegrationTestSpec,616,"Somewhere between #835 and now, BaseRecalibrator stopped working. When I try to run testBQSRBucket, I get the error below. This test is currently enabled so regression tests should have caught this. ```; java.lang.RuntimeException: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:131); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:104); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:86); at org.broadinstitute.hellbender.tools.dataflow.pipelines.BaseRecalibratorDataflowIntegrationTest.testBQSRBucket(BaseRecalibratorDataflowIntegrationTest.java:176); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:648,Integrability,Integrat,IntegrationTestSpec,648,"Somewhere between #835 and now, BaseRecalibrator stopped working. When I try to run testBQSRBucket, I get the error below. This test is currently enabled so regression tests should have caught this. ```; java.lang.RuntimeException: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:131); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:104); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:86); at org.broadinstitute.hellbender.tools.dataflow.pipelines.BaseRecalibratorDataflowIntegrationTest.testBQSRBucket(BaseRecalibratorDataflowIntegrationTest.java:176); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:3786,Integrability,Integrat,IntegrationTestSpec,3786,ng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140); Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at com.google.cloud.dataflow.sdk.Pipeline.run(Pipeline.java:166); at org.broadinstitute.hellbender.engine.dataflow.DataflowCommandLineProgram.runPipeline(DataflowCommandLineProgram.java:145); at org.broadinstitute.hellbender.engine.dataflow.DataflowCommandLineProgram.doWork(DataflowCommandLineProgram.java:107); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:98); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:151); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:71); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:78); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:75); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:126); ... 33 more; Caused by: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at com.google.cloud.genomics.dataflow.readers.bam.Reader.process(Reader.java:93); at com.google.cloud.genomics.dataflow.readers.bam.ReadBAMTransform$ReadFn.processElement(ReadBAMTransform.java:68); ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:3818,Integrability,Integrat,IntegrationTestSpec,3818,ng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140); Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at com.google.cloud.dataflow.sdk.Pipeline.run(Pipeline.java:166); at org.broadinstitute.hellbender.engine.dataflow.DataflowCommandLineProgram.runPipeline(DataflowCommandLineProgram.java:145); at org.broadinstitute.hellbender.engine.dataflow.DataflowCommandLineProgram.doWork(DataflowCommandLineProgram.java:107); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:98); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:151); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:71); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:78); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:75); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:126); ... 33 more; Caused by: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at com.google.cloud.genomics.dataflow.readers.bam.Reader.process(Reader.java:93); at com.google.cloud.genomics.dataflow.readers.bam.ReadBAMTransform$ReadFn.processElement(ReadBAMTransform.java:68); ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:84,Testability,test,testBQSRBucket,84,"Somewhere between #835 and now, BaseRecalibrator stopped working. When I try to run testBQSRBucket, I get the error below. This test is currently enabled so regression tests should have caught this. ```; java.lang.RuntimeException: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:131); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:104); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:86); at org.broadinstitute.hellbender.tools.dataflow.pipelines.BaseRecalibratorDataflowIntegrationTest.testBQSRBucket(BaseRecalibratorDataflowIntegrationTest.java:176); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:128,Testability,test,test,128,"Somewhere between #835 and now, BaseRecalibrator stopped working. When I try to run testBQSRBucket, I get the error below. This test is currently enabled so regression tests should have caught this. ```; java.lang.RuntimeException: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:131); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:104); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:86); at org.broadinstitute.hellbender.tools.dataflow.pipelines.BaseRecalibratorDataflowIntegrationTest.testBQSRBucket(BaseRecalibratorDataflowIntegrationTest.java:176); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:168,Testability,test,tests,168,"Somewhere between #835 and now, BaseRecalibrator stopped working. When I try to run testBQSRBucket, I get the error below. This test is currently enabled so regression tests should have caught this. ```; java.lang.RuntimeException: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:131); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:104); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:86); at org.broadinstitute.hellbender.tools.dataflow.pipelines.BaseRecalibratorDataflowIntegrationTest.testBQSRBucket(BaseRecalibratorDataflowIntegrationTest.java:176); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:776,Testability,test,testBQSRBucket,776,"Somewhere between #835 and now, BaseRecalibrator stopped working. When I try to run testBQSRBucket, I get the error below. This test is currently enabled so regression tests should have caught this. ```; java.lang.RuntimeException: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:131); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:104); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:86); at org.broadinstitute.hellbender.tools.dataflow.pipelines.BaseRecalibratorDataflowIntegrationTest.testBQSRBucket(BaseRecalibratorDataflowIntegrationTest.java:176); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:1138,Testability,test,testng,1138,ntly enabled so regression tests should have caught this. ```; java.lang.RuntimeException: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:131); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:104); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:86); at org.broadinstitute.hellbender.tools.dataflow.pipelines.BaseRecalibratorDataflowIntegrationTest.testBQSRBucket(BaseRecalibratorDataflowIntegrationTest.java:176); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.ru,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:1230,Testability,test,testng,1230,ava.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:131); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:104); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:86); at org.broadinstitute.hellbender.tools.dataflow.pipelines.BaseRecalibratorDataflowIntegrationTest.testBQSRBucket(BaseRecalibratorDataflowIntegrationTest.java:176); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:1293,Testability,test,testng,1293,gle.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:131); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:104); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:86); at org.broadinstitute.hellbender.tools.dataflow.pipelines.BaseRecalibratorDataflowIntegrationTest.testBQSRBucket(BaseRecalibratorDataflowIntegrationTest.java:176); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.r,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:1360,Testability,test,testng,1360,opwatch;; at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:131); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:104); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:86); at org.broadinstitute.hellbender.tools.dataflow.pipelines.BaseRecalibratorDataflowIntegrationTest.testBQSRBucket(BaseRecalibratorDataflowIntegrationTest.java:176); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:1429,Testability,test,testng,1429,executeTest(IntegrationTestSpec.java:131); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:104); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:86); at org.broadinstitute.hellbender.tools.dataflow.pipelines.BaseRecalibratorDataflowIntegrationTest.testBQSRBucket(BaseRecalibratorDataflowIntegrationTest.java:176); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.Remot,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:1445,Testability,Test,TestMethodWorker,1445,onTestSpec.java:131); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:104); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:86); at org.broadinstitute.hellbender.tools.dataflow.pipelines.BaseRecalibratorDataflowIntegrationTest.testBQSRBucket(BaseRecalibratorDataflowIntegrationTest.java:176); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(R,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:1480,Testability,Test,TestMethodWorker,1480,rg.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:104); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:86); at org.broadinstitute.hellbender.tools.dataflow.pipelines.BaseRecalibratorDataflowIntegrationTest.testBQSRBucket(BaseRecalibratorDataflowIntegrationTest.java:176); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:12,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:1515,Testability,test,testng,1515,grationTestSpec.executeTest(IntegrationTestSpec.java:104); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:86); at org.broadinstitute.hellbender.tools.dataflow.pipelines.BaseRecalibratorDataflowIntegrationTest.testBQSRBucket(BaseRecalibratorDataflowIntegrationTest.java:176); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessor,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:1531,Testability,Test,TestMethodWorker,1531,teTest(IntegrationTestSpec.java:104); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:86); at org.broadinstitute.hellbender.tools.dataflow.pipelines.BaseRecalibratorDataflowIntegrationTest.testBQSRBucket(BaseRecalibratorDataflowIntegrationTest.java:176); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native M,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:1552,Testability,Test,TestMethodWorker,1552,estSpec.java:104); at org.broadinstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:86); at org.broadinstitute.hellbender.tools.dataflow.pipelines.BaseRecalibratorDataflowIntegrationTest.testBQSRBucket(BaseRecalibratorDataflowIntegrationTest.java:176); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.refl,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:1587,Testability,test,testng,1587,nstitute.hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:86); at org.broadinstitute.hellbender.tools.dataflow.pipelines.BaseRecalibratorDataflowIntegrationTest.testBQSRBucket(BaseRecalibratorDataflowIntegrationTest.java:176); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.inv,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:1594,Testability,Test,TestRunner,1594,hellbender.tools.IntegrationTestSpec.executeTest(IntegrationTestSpec.java:86); at org.broadinstitute.hellbender.tools.dataflow.pipelines.BaseRecalibratorDataflowIntegrationTest.testBQSRBucket(BaseRecalibratorDataflowIntegrationTest.java:176); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(Nativ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:1616,Testability,Test,TestRunner,1616,IntegrationTestSpec.executeTest(IntegrationTestSpec.java:86); at org.broadinstitute.hellbender.tools.dataflow.pipelines.BaseRecalibratorDataflowIntegrationTest.testBQSRBucket(BaseRecalibratorDataflowIntegrationTest.java:176); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorI,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:1645,Testability,test,testng,1645,IntegrationTestSpec.java:86); at org.broadinstitute.hellbender.tools.dataflow.pipelines.BaseRecalibratorDataflowIntegrationTest.testBQSRBucket(BaseRecalibratorDataflowIntegrationTest.java:176); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.Dele,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:1652,Testability,Test,TestRunner,1652,onTestSpec.java:86); at org.broadinstitute.hellbender.tools.dataflow.pipelines.BaseRecalibratorDataflowIntegrationTest.testBQSRBucket(BaseRecalibratorDataflowIntegrationTest.java:176); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMet,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:1667,Testability,Test,TestRunner,1667,va:86); at org.broadinstitute.hellbender.tools.dataflow.pipelines.BaseRecalibratorDataflowIntegrationTest.testBQSRBucket(BaseRecalibratorDataflowIntegrationTest.java:176); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorIm,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:1696,Testability,test,testng,1696,.hellbender.tools.dataflow.pipelines.BaseRecalibratorDataflowIntegrationTest.testBQSRBucket(BaseRecalibratorDataflowIntegrationTest.java:176); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAcc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:1753,Testability,test,testng,1753,flowIntegrationTest.testBQSRBucket(BaseRecalibratorDataflowIntegrationTest.java:176); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Me,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:1818,Testability,test,testng,1818,ationTest.java:176); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at com.intellij.rt.execution.application.AppMain.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:1878,Testability,test,testng,1878,.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140); Caused by: java.lang.RuntimeExceptio,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:1931,Testability,test,testng,1931,ccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140); Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.bas,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:2000,Testability,test,testng,2000,DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140); Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at com,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:2064,Testability,test,testng,2064,.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140); Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at com.google.cloud.dataflow.sdk.Pipeline.run(Pipeline.java:166); at o,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:2071,Testability,Test,TestNG,2071,3); at java.lang.reflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140); Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at com.google.cloud.dataflow.sdk.Pipeline.run(Pipeline.java:166); at org.broa,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:2100,Testability,Test,TestNG,2100,eflect.Method.invoke(Method.java:483); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140); Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at com.google.cloud.dataflow.sdk.Pipeline.run(Pipeline.java:166); at org.broadinstitute.hellben,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:2126,Testability,test,testng,2126,; at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140); Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at com.google.cloud.dataflow.sdk.Pipeline.run(Pipeline.java:166); at org.broadinstitute.hellbender.engine.dataflow.DataflowCommandLi,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:2133,Testability,Test,TestNG,2133,g.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140); Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at com.google.cloud.dataflow.sdk.Pipeline.run(Pipeline.java:166); at org.broadinstitute.hellbender.engine.dataflow.DataflowCommandLineProgr,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:2157,Testability,Test,TestNG,2157,l.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140); Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at com.google.cloud.dataflow.sdk.Pipeline.run(Pipeline.java:166); at org.broadinstitute.hellbender.engine.dataflow.DataflowCommandLineProgram.runPipeline(,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:2183,Testability,test,testng,2183,hod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140); Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at com.google.cloud.dataflow.sdk.Pipeline.run(Pipeline.java:166); at org.broadinstitute.hellbender.engine.dataflow.DataflowCommandLineProgram.runPipeline(DataflowCommandLineProgram.java:145,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:2190,Testability,Test,TestNG,2190,hodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140); Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at com.google.cloud.dataflow.sdk.Pipeline.run(Pipeline.java:166); at org.broadinstitute.hellbender.engine.dataflow.DataflowCommandLineProgram.runPipeline(DataflowCommandLineProgram.java:145); at o,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:2201,Testability,Test,TestNG,2201,tionHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140); Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at com.google.cloud.dataflow.sdk.Pipeline.run(Pipeline.java:166); at org.broadinstitute.hellbender.engine.dataflow.DataflowCommandLineProgram.runPipeline(DataflowCommandLineProgram.java:145); at org.broadi,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:2227,Testability,test,testng,2227,testng.internal.Invoker.invokeMethod(Invoker.java:639); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140); Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at com.google.cloud.dataflow.sdk.Pipeline.run(Pipeline.java:166); at org.broadinstitute.hellbender.engine.dataflow.DataflowCommandLineProgram.runPipeline(DataflowCommandLineProgram.java:145); at org.broadinstitute.hellbender.engine.d,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:2289,Testability,test,testng,2289,.testng.internal.Invoker.invokeTestMethod(Invoker.java:821); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140); Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at com.google.cloud.dataflow.sdk.Pipeline.run(Pipeline.java:166); at org.broadinstitute.hellbender.engine.dataflow.DataflowCommandLineProgram.runPipeline(DataflowCommandLineProgram.java:145); at org.broadinstitute.hellbender.engine.dataflow.DataflowCommandLineProgram.doWork(DataflowCommandLineP,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:2358,Testability,test,testng,2358,estng.internal.Invoker.invokeTestMethods(Invoker.java:1131); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140); Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at com.google.cloud.dataflow.sdk.Pipeline.run(Pipeline.java:166); at org.broadinstitute.hellbender.engine.dataflow.DataflowCommandLineProgram.runPipeline(DataflowCommandLineProgram.java:145); at org.broadinstitute.hellbender.engine.dataflow.DataflowCommandLineProgram.doWork(DataflowCommandLineProgram.java:107); at org.broadinstitute.hellbender.cmdline.CommandLin,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/issues/866:2421,Testability,test,testng,2421, org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:773); at org.testng.TestRunner.run(TestRunner.java:623); at org.testng.SuiteRunner.runTest(SuiteRunner.java:357); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:352); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:310); at org.testng.SuiteRunner.run(SuiteRunner.java:259); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1185); at org.testng.TestNG.runSuitesLocally(TestNG.java:1110); at org.testng.TestNG.run(TestNG.java:1018); at org.testng.remote.RemoteTestNG.run(RemoteTestNG.java:111); at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:204); at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:175); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:125); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:483); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140); Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodError: com.google.common.base.Stopwatch.createStarted()Lcom/google/common/base/Stopwatch;; at com.google.cloud.dataflow.sdk.Pipeline.run(Pipeline.java:166); at org.broadinstitute.hellbender.engine.dataflow.DataflowCommandLineProgram.runPipeline(DataflowCommandLineProgram.java:145); at org.broadinstitute.hellbender.engine.dataflow.DataflowCommandLineProgram.doWork(DataflowCommandLineProgram.java:107); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:98); at org.broadinsti,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/866
https://github.com/broadinstitute/gatk/pull/870:12,Deployability,integrat,integration,12,Adding CRAM integration tests for CountReads.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/870
https://github.com/broadinstitute/gatk/pull/870:12,Integrability,integrat,integration,12,Adding CRAM integration tests for CountReads.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/870
https://github.com/broadinstitute/gatk/pull/870:24,Testability,test,tests,24,Adding CRAM integration tests for CountReads.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/870
https://github.com/broadinstitute/gatk/pull/871:114,Energy Efficiency,adapt,adapter,114,"Some questions before this is code reviewed in detail:. 1) A number of query methods in GoogleGenomicsReadAdapter adapter; throw if the corresponding field is not present in the underlying read. For some; of these there are guard methods you can call to avoid this (see for example; the changes in ReadUtils.java), but for some of the others I'm not sure how to; usefully query the state without already knowing the answer, ie.:. -isSupplementaryAlignment; -isSecondaryAlignment,; -failsVendorQualityCheck; -isDuplicate; -mateIsReverseStrand. To have fidelity with SAMRecord.getSAMString , we need to be able to query these; (as does ReadUtils.getFlags, which has a similar problem, but I changed that to; use guard methods to prevent throwing). In a couple of cases I had to change; the Read adapter to not throw. We need to figure out if this kind; of change is ok. or what the alternative is. 2) This is incidental to this PR, but there are a few inconsistencies between how; GenomicsConverter.makeSAMRecord and ReadUtils compute derived state values, ie. flags.; I can work around these in the getSAMString tests (I'm using Read->SAMRecord; conversions to validate the tests), but the underlying format conversions; are inconsistent. Should we align them ?. For example, GenomicsConverter sets the firstInPair flag on the SAMRecord if readNumber==0,; even if numberOfReads==1, whereas the ReadUtils/GoogleReadAdapter requires readNumber==0; and numberOfReads==2. Likewise the unmapped flag is determined differently: Genomics converter: (http://google-genomics.readthedocs.org/en/latest/migrating_tips.html):; final boolean unmapped = (read.getAlignment() == null || ; read.getAlignment().getPosition() == null || ; read.getAlignment().getPosition().getPosition() == null);; ReadUtils:; private boolean positionIsUnmapped( final Position position ) {; return position == null ||; position.getReferenceName() == null || position.getReferenceName().equals(SAMRecord.NO_ALIGNMENT_REFERENCE_NAME) ||; ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/871
https://github.com/broadinstitute/gatk/pull/871:793,Energy Efficiency,adapt,adapter,793,"Some questions before this is code reviewed in detail:. 1) A number of query methods in GoogleGenomicsReadAdapter adapter; throw if the corresponding field is not present in the underlying read. For some; of these there are guard methods you can call to avoid this (see for example; the changes in ReadUtils.java), but for some of the others I'm not sure how to; usefully query the state without already knowing the answer, ie.:. -isSupplementaryAlignment; -isSecondaryAlignment,; -failsVendorQualityCheck; -isDuplicate; -mateIsReverseStrand. To have fidelity with SAMRecord.getSAMString , we need to be able to query these; (as does ReadUtils.getFlags, which has a similar problem, but I changed that to; use guard methods to prevent throwing). In a couple of cases I had to change; the Read adapter to not throw. We need to figure out if this kind; of change is ok. or what the alternative is. 2) This is incidental to this PR, but there are a few inconsistencies between how; GenomicsConverter.makeSAMRecord and ReadUtils compute derived state values, ie. flags.; I can work around these in the getSAMString tests (I'm using Read->SAMRecord; conversions to validate the tests), but the underlying format conversions; are inconsistent. Should we align them ?. For example, GenomicsConverter sets the firstInPair flag on the SAMRecord if readNumber==0,; even if numberOfReads==1, whereas the ReadUtils/GoogleReadAdapter requires readNumber==0; and numberOfReads==2. Likewise the unmapped flag is determined differently: Genomics converter: (http://google-genomics.readthedocs.org/en/latest/migrating_tips.html):; final boolean unmapped = (read.getAlignment() == null || ; read.getAlignment().getPosition() == null || ; read.getAlignment().getPosition().getPosition() == null);; ReadUtils:; private boolean positionIsUnmapped( final Position position ) {; return position == null ||; position.getReferenceName() == null || position.getReferenceName().equals(SAMRecord.NO_ALIGNMENT_REFERENCE_NAME) ||; ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/871
https://github.com/broadinstitute/gatk/pull/871:114,Integrability,adapter,adapter,114,"Some questions before this is code reviewed in detail:. 1) A number of query methods in GoogleGenomicsReadAdapter adapter; throw if the corresponding field is not present in the underlying read. For some; of these there are guard methods you can call to avoid this (see for example; the changes in ReadUtils.java), but for some of the others I'm not sure how to; usefully query the state without already knowing the answer, ie.:. -isSupplementaryAlignment; -isSecondaryAlignment,; -failsVendorQualityCheck; -isDuplicate; -mateIsReverseStrand. To have fidelity with SAMRecord.getSAMString , we need to be able to query these; (as does ReadUtils.getFlags, which has a similar problem, but I changed that to; use guard methods to prevent throwing). In a couple of cases I had to change; the Read adapter to not throw. We need to figure out if this kind; of change is ok. or what the alternative is. 2) This is incidental to this PR, but there are a few inconsistencies between how; GenomicsConverter.makeSAMRecord and ReadUtils compute derived state values, ie. flags.; I can work around these in the getSAMString tests (I'm using Read->SAMRecord; conversions to validate the tests), but the underlying format conversions; are inconsistent. Should we align them ?. For example, GenomicsConverter sets the firstInPair flag on the SAMRecord if readNumber==0,; even if numberOfReads==1, whereas the ReadUtils/GoogleReadAdapter requires readNumber==0; and numberOfReads==2. Likewise the unmapped flag is determined differently: Genomics converter: (http://google-genomics.readthedocs.org/en/latest/migrating_tips.html):; final boolean unmapped = (read.getAlignment() == null || ; read.getAlignment().getPosition() == null || ; read.getAlignment().getPosition().getPosition() == null);; ReadUtils:; private boolean positionIsUnmapped( final Position position ) {; return position == null ||; position.getReferenceName() == null || position.getReferenceName().equals(SAMRecord.NO_ALIGNMENT_REFERENCE_NAME) ||; ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/871
https://github.com/broadinstitute/gatk/pull/871:793,Integrability,adapter,adapter,793,"Some questions before this is code reviewed in detail:. 1) A number of query methods in GoogleGenomicsReadAdapter adapter; throw if the corresponding field is not present in the underlying read. For some; of these there are guard methods you can call to avoid this (see for example; the changes in ReadUtils.java), but for some of the others I'm not sure how to; usefully query the state without already knowing the answer, ie.:. -isSupplementaryAlignment; -isSecondaryAlignment,; -failsVendorQualityCheck; -isDuplicate; -mateIsReverseStrand. To have fidelity with SAMRecord.getSAMString , we need to be able to query these; (as does ReadUtils.getFlags, which has a similar problem, but I changed that to; use guard methods to prevent throwing). In a couple of cases I had to change; the Read adapter to not throw. We need to figure out if this kind; of change is ok. or what the alternative is. 2) This is incidental to this PR, but there are a few inconsistencies between how; GenomicsConverter.makeSAMRecord and ReadUtils compute derived state values, ie. flags.; I can work around these in the getSAMString tests (I'm using Read->SAMRecord; conversions to validate the tests), but the underlying format conversions; are inconsistent. Should we align them ?. For example, GenomicsConverter sets the firstInPair flag on the SAMRecord if readNumber==0,; even if numberOfReads==1, whereas the ReadUtils/GoogleReadAdapter requires readNumber==0; and numberOfReads==2. Likewise the unmapped flag is determined differently: Genomics converter: (http://google-genomics.readthedocs.org/en/latest/migrating_tips.html):; final boolean unmapped = (read.getAlignment() == null || ; read.getAlignment().getPosition() == null || ; read.getAlignment().getPosition().getPosition() == null);; ReadUtils:; private boolean positionIsUnmapped( final Position position ) {; return position == null ||; position.getReferenceName() == null || position.getReferenceName().equals(SAMRecord.NO_ALIGNMENT_REFERENCE_NAME) ||; ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/871
https://github.com/broadinstitute/gatk/pull/871:114,Modifiability,adapt,adapter,114,"Some questions before this is code reviewed in detail:. 1) A number of query methods in GoogleGenomicsReadAdapter adapter; throw if the corresponding field is not present in the underlying read. For some; of these there are guard methods you can call to avoid this (see for example; the changes in ReadUtils.java), but for some of the others I'm not sure how to; usefully query the state without already knowing the answer, ie.:. -isSupplementaryAlignment; -isSecondaryAlignment,; -failsVendorQualityCheck; -isDuplicate; -mateIsReverseStrand. To have fidelity with SAMRecord.getSAMString , we need to be able to query these; (as does ReadUtils.getFlags, which has a similar problem, but I changed that to; use guard methods to prevent throwing). In a couple of cases I had to change; the Read adapter to not throw. We need to figure out if this kind; of change is ok. or what the alternative is. 2) This is incidental to this PR, but there are a few inconsistencies between how; GenomicsConverter.makeSAMRecord and ReadUtils compute derived state values, ie. flags.; I can work around these in the getSAMString tests (I'm using Read->SAMRecord; conversions to validate the tests), but the underlying format conversions; are inconsistent. Should we align them ?. For example, GenomicsConverter sets the firstInPair flag on the SAMRecord if readNumber==0,; even if numberOfReads==1, whereas the ReadUtils/GoogleReadAdapter requires readNumber==0; and numberOfReads==2. Likewise the unmapped flag is determined differently: Genomics converter: (http://google-genomics.readthedocs.org/en/latest/migrating_tips.html):; final boolean unmapped = (read.getAlignment() == null || ; read.getAlignment().getPosition() == null || ; read.getAlignment().getPosition().getPosition() == null);; ReadUtils:; private boolean positionIsUnmapped( final Position position ) {; return position == null ||; position.getReferenceName() == null || position.getReferenceName().equals(SAMRecord.NO_ALIGNMENT_REFERENCE_NAME) ||; ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/871
https://github.com/broadinstitute/gatk/pull/871:793,Modifiability,adapt,adapter,793,"Some questions before this is code reviewed in detail:. 1) A number of query methods in GoogleGenomicsReadAdapter adapter; throw if the corresponding field is not present in the underlying read. For some; of these there are guard methods you can call to avoid this (see for example; the changes in ReadUtils.java), but for some of the others I'm not sure how to; usefully query the state without already knowing the answer, ie.:. -isSupplementaryAlignment; -isSecondaryAlignment,; -failsVendorQualityCheck; -isDuplicate; -mateIsReverseStrand. To have fidelity with SAMRecord.getSAMString , we need to be able to query these; (as does ReadUtils.getFlags, which has a similar problem, but I changed that to; use guard methods to prevent throwing). In a couple of cases I had to change; the Read adapter to not throw. We need to figure out if this kind; of change is ok. or what the alternative is. 2) This is incidental to this PR, but there are a few inconsistencies between how; GenomicsConverter.makeSAMRecord and ReadUtils compute derived state values, ie. flags.; I can work around these in the getSAMString tests (I'm using Read->SAMRecord; conversions to validate the tests), but the underlying format conversions; are inconsistent. Should we align them ?. For example, GenomicsConverter sets the firstInPair flag on the SAMRecord if readNumber==0,; even if numberOfReads==1, whereas the ReadUtils/GoogleReadAdapter requires readNumber==0; and numberOfReads==2. Likewise the unmapped flag is determined differently: Genomics converter: (http://google-genomics.readthedocs.org/en/latest/migrating_tips.html):; final boolean unmapped = (read.getAlignment() == null || ; read.getAlignment().getPosition() == null || ; read.getAlignment().getPosition().getPosition() == null);; ReadUtils:; private boolean positionIsUnmapped( final Position position ) {; return position == null ||; position.getReferenceName() == null || position.getReferenceName().equals(SAMRecord.NO_ALIGNMENT_REFERENCE_NAME) ||; ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/871
https://github.com/broadinstitute/gatk/pull/871:254,Safety,avoid,avoid,254,"Some questions before this is code reviewed in detail:. 1) A number of query methods in GoogleGenomicsReadAdapter adapter; throw if the corresponding field is not present in the underlying read. For some; of these there are guard methods you can call to avoid this (see for example; the changes in ReadUtils.java), but for some of the others I'm not sure how to; usefully query the state without already knowing the answer, ie.:. -isSupplementaryAlignment; -isSecondaryAlignment,; -failsVendorQualityCheck; -isDuplicate; -mateIsReverseStrand. To have fidelity with SAMRecord.getSAMString , we need to be able to query these; (as does ReadUtils.getFlags, which has a similar problem, but I changed that to; use guard methods to prevent throwing). In a couple of cases I had to change; the Read adapter to not throw. We need to figure out if this kind; of change is ok. or what the alternative is. 2) This is incidental to this PR, but there are a few inconsistencies between how; GenomicsConverter.makeSAMRecord and ReadUtils compute derived state values, ie. flags.; I can work around these in the getSAMString tests (I'm using Read->SAMRecord; conversions to validate the tests), but the underlying format conversions; are inconsistent. Should we align them ?. For example, GenomicsConverter sets the firstInPair flag on the SAMRecord if readNumber==0,; even if numberOfReads==1, whereas the ReadUtils/GoogleReadAdapter requires readNumber==0; and numberOfReads==2. Likewise the unmapped flag is determined differently: Genomics converter: (http://google-genomics.readthedocs.org/en/latest/migrating_tips.html):; final boolean unmapped = (read.getAlignment() == null || ; read.getAlignment().getPosition() == null || ; read.getAlignment().getPosition().getPosition() == null);; ReadUtils:; private boolean positionIsUnmapped( final Position position ) {; return position == null ||; position.getReferenceName() == null || position.getReferenceName().equals(SAMRecord.NO_ALIGNMENT_REFERENCE_NAME) ||; ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/871
https://github.com/broadinstitute/gatk/pull/871:1160,Security,validat,validate,1160,"er of query methods in GoogleGenomicsReadAdapter adapter; throw if the corresponding field is not present in the underlying read. For some; of these there are guard methods you can call to avoid this (see for example; the changes in ReadUtils.java), but for some of the others I'm not sure how to; usefully query the state without already knowing the answer, ie.:. -isSupplementaryAlignment; -isSecondaryAlignment,; -failsVendorQualityCheck; -isDuplicate; -mateIsReverseStrand. To have fidelity with SAMRecord.getSAMString , we need to be able to query these; (as does ReadUtils.getFlags, which has a similar problem, but I changed that to; use guard methods to prevent throwing). In a couple of cases I had to change; the Read adapter to not throw. We need to figure out if this kind; of change is ok. or what the alternative is. 2) This is incidental to this PR, but there are a few inconsistencies between how; GenomicsConverter.makeSAMRecord and ReadUtils compute derived state values, ie. flags.; I can work around these in the getSAMString tests (I'm using Read->SAMRecord; conversions to validate the tests), but the underlying format conversions; are inconsistent. Should we align them ?. For example, GenomicsConverter sets the firstInPair flag on the SAMRecord if readNumber==0,; even if numberOfReads==1, whereas the ReadUtils/GoogleReadAdapter requires readNumber==0; and numberOfReads==2. Likewise the unmapped flag is determined differently: Genomics converter: (http://google-genomics.readthedocs.org/en/latest/migrating_tips.html):; final boolean unmapped = (read.getAlignment() == null || ; read.getAlignment().getPosition() == null || ; read.getAlignment().getPosition().getPosition() == null);; ReadUtils:; private boolean positionIsUnmapped( final Position position ) {; return position == null ||; position.getReferenceName() == null || position.getReferenceName().equals(SAMRecord.NO_ALIGNMENT_REFERENCE_NAME) ||; position.getPosition() == null || position.getPosition() < 0;; }",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/871
https://github.com/broadinstitute/gatk/pull/871:1111,Testability,test,tests,1111,"er of query methods in GoogleGenomicsReadAdapter adapter; throw if the corresponding field is not present in the underlying read. For some; of these there are guard methods you can call to avoid this (see for example; the changes in ReadUtils.java), but for some of the others I'm not sure how to; usefully query the state without already knowing the answer, ie.:. -isSupplementaryAlignment; -isSecondaryAlignment,; -failsVendorQualityCheck; -isDuplicate; -mateIsReverseStrand. To have fidelity with SAMRecord.getSAMString , we need to be able to query these; (as does ReadUtils.getFlags, which has a similar problem, but I changed that to; use guard methods to prevent throwing). In a couple of cases I had to change; the Read adapter to not throw. We need to figure out if this kind; of change is ok. or what the alternative is. 2) This is incidental to this PR, but there are a few inconsistencies between how; GenomicsConverter.makeSAMRecord and ReadUtils compute derived state values, ie. flags.; I can work around these in the getSAMString tests (I'm using Read->SAMRecord; conversions to validate the tests), but the underlying format conversions; are inconsistent. Should we align them ?. For example, GenomicsConverter sets the firstInPair flag on the SAMRecord if readNumber==0,; even if numberOfReads==1, whereas the ReadUtils/GoogleReadAdapter requires readNumber==0; and numberOfReads==2. Likewise the unmapped flag is determined differently: Genomics converter: (http://google-genomics.readthedocs.org/en/latest/migrating_tips.html):; final boolean unmapped = (read.getAlignment() == null || ; read.getAlignment().getPosition() == null || ; read.getAlignment().getPosition().getPosition() == null);; ReadUtils:; private boolean positionIsUnmapped( final Position position ) {; return position == null ||; position.getReferenceName() == null || position.getReferenceName().equals(SAMRecord.NO_ALIGNMENT_REFERENCE_NAME) ||; position.getPosition() == null || position.getPosition() < 0;; }",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/871
https://github.com/broadinstitute/gatk/pull/871:1173,Testability,test,tests,1173,"er of query methods in GoogleGenomicsReadAdapter adapter; throw if the corresponding field is not present in the underlying read. For some; of these there are guard methods you can call to avoid this (see for example; the changes in ReadUtils.java), but for some of the others I'm not sure how to; usefully query the state without already knowing the answer, ie.:. -isSupplementaryAlignment; -isSecondaryAlignment,; -failsVendorQualityCheck; -isDuplicate; -mateIsReverseStrand. To have fidelity with SAMRecord.getSAMString , we need to be able to query these; (as does ReadUtils.getFlags, which has a similar problem, but I changed that to; use guard methods to prevent throwing). In a couple of cases I had to change; the Read adapter to not throw. We need to figure out if this kind; of change is ok. or what the alternative is. 2) This is incidental to this PR, but there are a few inconsistencies between how; GenomicsConverter.makeSAMRecord and ReadUtils compute derived state values, ie. flags.; I can work around these in the getSAMString tests (I'm using Read->SAMRecord; conversions to validate the tests), but the underlying format conversions; are inconsistent. Should we align them ?. For example, GenomicsConverter sets the firstInPair flag on the SAMRecord if readNumber==0,; even if numberOfReads==1, whereas the ReadUtils/GoogleReadAdapter requires readNumber==0; and numberOfReads==2. Likewise the unmapped flag is determined differently: Genomics converter: (http://google-genomics.readthedocs.org/en/latest/migrating_tips.html):; final boolean unmapped = (read.getAlignment() == null || ; read.getAlignment().getPosition() == null || ; read.getAlignment().getPosition().getPosition() == null);; ReadUtils:; private boolean positionIsUnmapped( final Position position ) {; return position == null ||; position.getReferenceName() == null || position.getReferenceName().equals(SAMRecord.NO_ALIGNMENT_REFERENCE_NAME) ||; position.getPosition() == null || position.getPosition() < 0;; }",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/871
https://github.com/broadinstitute/gatk/issues/873:44,Testability,assert,assertSameReads,44,This should go in AddContextDataToReadSpark.assertSameReads,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/873
https://github.com/broadinstitute/gatk/pull/877:664,Deployability,Update,Updated,664,"-Require that the reference dictionary be a superset of the reads dictionary; only when there is at least one CRAM input. -When determining whether a superset relationship exists, do not take extended; attributes (like the sequence MD5) into account; only consider the contig names; and lengths. -Do not require common contigs to occur at the same absolute indices across; dictionaries (but do require that they occur in the same relative order).; Contig indices were an issue for GATK3, but since hellbender relies on contig; names for queries we can afford to disable this annoying check. If we later find; that we need to turn it back on, we can easily do so. -Updated tests appropriately:; -Added test cases showing that extended attributes are ignored when checking; for a superset. ```; -Added test cases for various combinations of the new boolean options; requireSuperset and checkContigIndices. -The existing integration test CRAMSupportIntegrationTest.testWrongRef(); shows that we throw when a CRAM is provided as input with a reference; that does not contain all of its contigs.; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/877
https://github.com/broadinstitute/gatk/pull/877:918,Deployability,integrat,integration,918,"-Require that the reference dictionary be a superset of the reads dictionary; only when there is at least one CRAM input. -When determining whether a superset relationship exists, do not take extended; attributes (like the sequence MD5) into account; only consider the contig names; and lengths. -Do not require common contigs to occur at the same absolute indices across; dictionaries (but do require that they occur in the same relative order).; Contig indices were an issue for GATK3, but since hellbender relies on contig; names for queries we can afford to disable this annoying check. If we later find; that we need to turn it back on, we can easily do so. -Updated tests appropriately:; -Added test cases showing that extended attributes are ignored when checking; for a superset. ```; -Added test cases for various combinations of the new boolean options; requireSuperset and checkContigIndices. -The existing integration test CRAMSupportIntegrationTest.testWrongRef(); shows that we throw when a CRAM is provided as input with a reference; that does not contain all of its contigs.; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/877
https://github.com/broadinstitute/gatk/pull/877:918,Integrability,integrat,integration,918,"-Require that the reference dictionary be a superset of the reads dictionary; only when there is at least one CRAM input. -When determining whether a superset relationship exists, do not take extended; attributes (like the sequence MD5) into account; only consider the contig names; and lengths. -Do not require common contigs to occur at the same absolute indices across; dictionaries (but do require that they occur in the same relative order).; Contig indices were an issue for GATK3, but since hellbender relies on contig; names for queries we can afford to disable this annoying check. If we later find; that we need to turn it back on, we can easily do so. -Updated tests appropriately:; -Added test cases showing that extended attributes are ignored when checking; for a superset. ```; -Added test cases for various combinations of the new boolean options; requireSuperset and checkContigIndices. -The existing integration test CRAMSupportIntegrationTest.testWrongRef(); shows that we throw when a CRAM is provided as input with a reference; that does not contain all of its contigs.; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/877
https://github.com/broadinstitute/gatk/pull/877:192,Modifiability,extend,extended,192,"-Require that the reference dictionary be a superset of the reads dictionary; only when there is at least one CRAM input. -When determining whether a superset relationship exists, do not take extended; attributes (like the sequence MD5) into account; only consider the contig names; and lengths. -Do not require common contigs to occur at the same absolute indices across; dictionaries (but do require that they occur in the same relative order).; Contig indices were an issue for GATK3, but since hellbender relies on contig; names for queries we can afford to disable this annoying check. If we later find; that we need to turn it back on, we can easily do so. -Updated tests appropriately:; -Added test cases showing that extended attributes are ignored when checking; for a superset. ```; -Added test cases for various combinations of the new boolean options; requireSuperset and checkContigIndices. -The existing integration test CRAMSupportIntegrationTest.testWrongRef(); shows that we throw when a CRAM is provided as input with a reference; that does not contain all of its contigs.; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/877
https://github.com/broadinstitute/gatk/pull/877:725,Modifiability,extend,extended,725,"-Require that the reference dictionary be a superset of the reads dictionary; only when there is at least one CRAM input. -When determining whether a superset relationship exists, do not take extended; attributes (like the sequence MD5) into account; only consider the contig names; and lengths. -Do not require common contigs to occur at the same absolute indices across; dictionaries (but do require that they occur in the same relative order).; Contig indices were an issue for GATK3, but since hellbender relies on contig; names for queries we can afford to disable this annoying check. If we later find; that we need to turn it back on, we can easily do so. -Updated tests appropriately:; -Added test cases showing that extended attributes are ignored when checking; for a superset. ```; -Added test cases for various combinations of the new boolean options; requireSuperset and checkContigIndices. -The existing integration test CRAMSupportIntegrationTest.testWrongRef(); shows that we throw when a CRAM is provided as input with a reference; that does not contain all of its contigs.; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/877
https://github.com/broadinstitute/gatk/pull/877:672,Testability,test,tests,672,"-Require that the reference dictionary be a superset of the reads dictionary; only when there is at least one CRAM input. -When determining whether a superset relationship exists, do not take extended; attributes (like the sequence MD5) into account; only consider the contig names; and lengths. -Do not require common contigs to occur at the same absolute indices across; dictionaries (but do require that they occur in the same relative order).; Contig indices were an issue for GATK3, but since hellbender relies on contig; names for queries we can afford to disable this annoying check. If we later find; that we need to turn it back on, we can easily do so. -Updated tests appropriately:; -Added test cases showing that extended attributes are ignored when checking; for a superset. ```; -Added test cases for various combinations of the new boolean options; requireSuperset and checkContigIndices. -The existing integration test CRAMSupportIntegrationTest.testWrongRef(); shows that we throw when a CRAM is provided as input with a reference; that does not contain all of its contigs.; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/877
https://github.com/broadinstitute/gatk/pull/877:701,Testability,test,test,701,"-Require that the reference dictionary be a superset of the reads dictionary; only when there is at least one CRAM input. -When determining whether a superset relationship exists, do not take extended; attributes (like the sequence MD5) into account; only consider the contig names; and lengths. -Do not require common contigs to occur at the same absolute indices across; dictionaries (but do require that they occur in the same relative order).; Contig indices were an issue for GATK3, but since hellbender relies on contig; names for queries we can afford to disable this annoying check. If we later find; that we need to turn it back on, we can easily do so. -Updated tests appropriately:; -Added test cases showing that extended attributes are ignored when checking; for a superset. ```; -Added test cases for various combinations of the new boolean options; requireSuperset and checkContigIndices. -The existing integration test CRAMSupportIntegrationTest.testWrongRef(); shows that we throw when a CRAM is provided as input with a reference; that does not contain all of its contigs.; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/877
https://github.com/broadinstitute/gatk/pull/877:800,Testability,test,test,800,"-Require that the reference dictionary be a superset of the reads dictionary; only when there is at least one CRAM input. -When determining whether a superset relationship exists, do not take extended; attributes (like the sequence MD5) into account; only consider the contig names; and lengths. -Do not require common contigs to occur at the same absolute indices across; dictionaries (but do require that they occur in the same relative order).; Contig indices were an issue for GATK3, but since hellbender relies on contig; names for queries we can afford to disable this annoying check. If we later find; that we need to turn it back on, we can easily do so. -Updated tests appropriately:; -Added test cases showing that extended attributes are ignored when checking; for a superset. ```; -Added test cases for various combinations of the new boolean options; requireSuperset and checkContigIndices. -The existing integration test CRAMSupportIntegrationTest.testWrongRef(); shows that we throw when a CRAM is provided as input with a reference; that does not contain all of its contigs.; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/877
https://github.com/broadinstitute/gatk/pull/877:930,Testability,test,test,930,"-Require that the reference dictionary be a superset of the reads dictionary; only when there is at least one CRAM input. -When determining whether a superset relationship exists, do not take extended; attributes (like the sequence MD5) into account; only consider the contig names; and lengths. -Do not require common contigs to occur at the same absolute indices across; dictionaries (but do require that they occur in the same relative order).; Contig indices were an issue for GATK3, but since hellbender relies on contig; names for queries we can afford to disable this annoying check. If we later find; that we need to turn it back on, we can easily do so. -Updated tests appropriately:; -Added test cases showing that extended attributes are ignored when checking; for a superset. ```; -Added test cases for various combinations of the new boolean options; requireSuperset and checkContigIndices. -The existing integration test CRAMSupportIntegrationTest.testWrongRef(); shows that we throw when a CRAM is provided as input with a reference; that does not contain all of its contigs.; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/877
https://github.com/broadinstitute/gatk/pull/877:962,Testability,test,testWrongRef,962,"-Require that the reference dictionary be a superset of the reads dictionary; only when there is at least one CRAM input. -When determining whether a superset relationship exists, do not take extended; attributes (like the sequence MD5) into account; only consider the contig names; and lengths. -Do not require common contigs to occur at the same absolute indices across; dictionaries (but do require that they occur in the same relative order).; Contig indices were an issue for GATK3, but since hellbender relies on contig; names for queries we can afford to disable this annoying check. If we later find; that we need to turn it back on, we can easily do so. -Updated tests appropriately:; -Added test cases showing that extended attributes are ignored when checking; for a superset. ```; -Added test cases for various combinations of the new boolean options; requireSuperset and checkContigIndices. -The existing integration test CRAMSupportIntegrationTest.testWrongRef(); shows that we throw when a CRAM is provided as input with a reference; that does not contain all of its contigs.; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/877
https://github.com/broadinstitute/gatk/pull/878:220,Deployability,update,updated,220,- CEUTrio.HiSeq.WGS.b37.ch20.4379150-4379157.bam is a very small input that triggers the bug.; - TestMath is a small demonstration of the underlying problem (order of operations changes the answer); - RecalDatum.java is updated to fix the problem; - BaseRecalibratorDataflowIntegrationTest runs the new code and confirms it's OK.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/878
https://github.com/broadinstitute/gatk/pull/878:97,Testability,Test,TestMath,97,- CEUTrio.HiSeq.WGS.b37.ch20.4379150-4379157.bam is a very small input that triggers the bug.; - TestMath is a small demonstration of the underlying problem (order of operations changes the answer); - RecalDatum.java is updated to fix the problem; - BaseRecalibratorDataflowIntegrationTest runs the new code and confirms it's OK.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/878
https://github.com/broadinstitute/gatk/pull/879:19,Testability,test,tests,19,"The Spark Dataflow tests started failing after the Spark code merge. The problem is that Spark Dataflow uses a shared SparkContext, while the new Spark codes uses a context per test, and there is an odd interaction where calling `stop()` on a context sets its static SparkEnv to null, which then causes the Spark Dataflow shared context to fail. This fix puts all of the new Spark tests into a `spark` group, so they don't run together. A longer term fix is to have a single shared Spark Context for both Spark and Spark Dataflow. (See discussion here: https://issues.apache.org/jira/browse/SPARK-2243) This will require some changes to Spark Dataflow. I also removed the Travis `DATAFLOW_RUNNER=SparkPipelineRunner CLOUD=mandatory` combination, which we talked about removing before since it's not a very meaningful combination.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/879
https://github.com/broadinstitute/gatk/pull/879:177,Testability,test,test,177,"The Spark Dataflow tests started failing after the Spark code merge. The problem is that Spark Dataflow uses a shared SparkContext, while the new Spark codes uses a context per test, and there is an odd interaction where calling `stop()` on a context sets its static SparkEnv to null, which then causes the Spark Dataflow shared context to fail. This fix puts all of the new Spark tests into a `spark` group, so they don't run together. A longer term fix is to have a single shared Spark Context for both Spark and Spark Dataflow. (See discussion here: https://issues.apache.org/jira/browse/SPARK-2243) This will require some changes to Spark Dataflow. I also removed the Travis `DATAFLOW_RUNNER=SparkPipelineRunner CLOUD=mandatory` combination, which we talked about removing before since it's not a very meaningful combination.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/879
https://github.com/broadinstitute/gatk/pull/879:381,Testability,test,tests,381,"The Spark Dataflow tests started failing after the Spark code merge. The problem is that Spark Dataflow uses a shared SparkContext, while the new Spark codes uses a context per test, and there is an odd interaction where calling `stop()` on a context sets its static SparkEnv to null, which then causes the Spark Dataflow shared context to fail. This fix puts all of the new Spark tests into a `spark` group, so they don't run together. A longer term fix is to have a single shared Spark Context for both Spark and Spark Dataflow. (See discussion here: https://issues.apache.org/jira/browse/SPARK-2243) This will require some changes to Spark Dataflow. I also removed the Travis `DATAFLOW_RUNNER=SparkPipelineRunner CLOUD=mandatory` combination, which we talked about removing before since it's not a very meaningful combination.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/879
https://github.com/broadinstitute/gatk/pull/880:671,Availability,failure,failures,671,"DataflowUtils#getReadsFromLocalBams will return unmapped reads if they have a start position that overlaps an interval, but the Hadoop version will filter them out. This change fixes this inconsistency, and makes the MarkDuplicates dataflow tests use the Spark Dataflow runner if it's specified on the command line (it used to ignore the setting). The change to the MarkDuplicates test also uncovered another problem where some tests failed with ""Mate unmapped flag should not be set for unpaired read"". I fixed this by moving from `com.google.cloud.genomics.utils.ReadUtils.makeRead` and `GoogleGenomicsReadToGATKReadAdapter` (which are lossy, and presumably caused the failures) to `SAMRecordToGATKReadAdapter`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/880
https://github.com/broadinstitute/gatk/pull/880:241,Testability,test,tests,241,"DataflowUtils#getReadsFromLocalBams will return unmapped reads if they have a start position that overlaps an interval, but the Hadoop version will filter them out. This change fixes this inconsistency, and makes the MarkDuplicates dataflow tests use the Spark Dataflow runner if it's specified on the command line (it used to ignore the setting). The change to the MarkDuplicates test also uncovered another problem where some tests failed with ""Mate unmapped flag should not be set for unpaired read"". I fixed this by moving from `com.google.cloud.genomics.utils.ReadUtils.makeRead` and `GoogleGenomicsReadToGATKReadAdapter` (which are lossy, and presumably caused the failures) to `SAMRecordToGATKReadAdapter`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/880
https://github.com/broadinstitute/gatk/pull/880:381,Testability,test,test,381,"DataflowUtils#getReadsFromLocalBams will return unmapped reads if they have a start position that overlaps an interval, but the Hadoop version will filter them out. This change fixes this inconsistency, and makes the MarkDuplicates dataflow tests use the Spark Dataflow runner if it's specified on the command line (it used to ignore the setting). The change to the MarkDuplicates test also uncovered another problem where some tests failed with ""Mate unmapped flag should not be set for unpaired read"". I fixed this by moving from `com.google.cloud.genomics.utils.ReadUtils.makeRead` and `GoogleGenomicsReadToGATKReadAdapter` (which are lossy, and presumably caused the failures) to `SAMRecordToGATKReadAdapter`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/880
https://github.com/broadinstitute/gatk/pull/880:428,Testability,test,tests,428,"DataflowUtils#getReadsFromLocalBams will return unmapped reads if they have a start position that overlaps an interval, but the Hadoop version will filter them out. This change fixes this inconsistency, and makes the MarkDuplicates dataflow tests use the Spark Dataflow runner if it's specified on the command line (it used to ignore the setting). The change to the MarkDuplicates test also uncovered another problem where some tests failed with ""Mate unmapped flag should not be set for unpaired read"". I fixed this by moving from `com.google.cloud.genomics.utils.ReadUtils.makeRead` and `GoogleGenomicsReadToGATKReadAdapter` (which are lossy, and presumably caused the failures) to `SAMRecordToGATKReadAdapter`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/880
https://github.com/broadinstitute/gatk/pull/881:36,Testability,test,test,36,@cmnbroad please review. very small test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/881
https://github.com/broadinstitute/gatk/pull/882:255,Availability,error,errors,255,"There were a couple of things I needed to do to get the new Spark code running on a cluster:. i. Go back to using Spark's version of Kryo. Using a different version of Kryo is not actually needed (2.21 used by Spark passes the tests), and actually caused errors on the cluster when run with `--conf spark.driver.userClassPathFirst=true` (which is needed to avoid other library conflicts, like with jopt-simple). ii. Exclude Spark from the JAR file to avoid library conflicts. It's normal to exclude Spark and Hadoop from JAR files since they are supplied by `spark-submit`. Since Gradle doesn't have a 'provided' dependency (see https://github.com/broadinstitute/hellbender/issues/836), I had to do a bit of a workaround with the `shadowJar` target, which is now `sparkJar`. . Here's the command I ran:. ``` bash; NAMENODE=...; SPARK_MASTER=yarn-client; HELLBENDER_HOME=...; spark-submit \; --master $SPARK_MASTER \; --conf spark.driver.userClassPathFirst=true \; --conf spark.executor.userClassPathFirst=true \; --conf spark.io.compression.codec=lzf \; build/libs/hellbender-all-*-spark.jar ReadsPipelineSpark \; --input hdfs://$NAMENODE/user/$USER/bam/NA12878.chr17_69k_70k.dictFix.bam \; --output hdfs://$NAMENODE/user/$USER/out/spark-reads-pipeline \; --reference hdfs://$NAMENODE/user/$USER/fasta/human_g1k_v37.chr17_1Mb.fasta \; --baseRecalibrationKnownVariants $HELLBENDER_HOME/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf \; --sparkMaster $SPARK_MASTER ; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/882
https://github.com/broadinstitute/gatk/pull/882:1244,Deployability,pipeline,pipeline,1244,"There were a couple of things I needed to do to get the new Spark code running on a cluster:. i. Go back to using Spark's version of Kryo. Using a different version of Kryo is not actually needed (2.21 used by Spark passes the tests), and actually caused errors on the cluster when run with `--conf spark.driver.userClassPathFirst=true` (which is needed to avoid other library conflicts, like with jopt-simple). ii. Exclude Spark from the JAR file to avoid library conflicts. It's normal to exclude Spark and Hadoop from JAR files since they are supplied by `spark-submit`. Since Gradle doesn't have a 'provided' dependency (see https://github.com/broadinstitute/hellbender/issues/836), I had to do a bit of a workaround with the `shadowJar` target, which is now `sparkJar`. . Here's the command I ran:. ``` bash; NAMENODE=...; SPARK_MASTER=yarn-client; HELLBENDER_HOME=...; spark-submit \; --master $SPARK_MASTER \; --conf spark.driver.userClassPathFirst=true \; --conf spark.executor.userClassPathFirst=true \; --conf spark.io.compression.codec=lzf \; build/libs/hellbender-all-*-spark.jar ReadsPipelineSpark \; --input hdfs://$NAMENODE/user/$USER/bam/NA12878.chr17_69k_70k.dictFix.bam \; --output hdfs://$NAMENODE/user/$USER/out/spark-reads-pipeline \; --reference hdfs://$NAMENODE/user/$USER/fasta/human_g1k_v37.chr17_1Mb.fasta \; --baseRecalibrationKnownVariants $HELLBENDER_HOME/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf \; --sparkMaster $SPARK_MASTER ; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/882
https://github.com/broadinstitute/gatk/pull/882:613,Integrability,depend,dependency,613,"There were a couple of things I needed to do to get the new Spark code running on a cluster:. i. Go back to using Spark's version of Kryo. Using a different version of Kryo is not actually needed (2.21 used by Spark passes the tests), and actually caused errors on the cluster when run with `--conf spark.driver.userClassPathFirst=true` (which is needed to avoid other library conflicts, like with jopt-simple). ii. Exclude Spark from the JAR file to avoid library conflicts. It's normal to exclude Spark and Hadoop from JAR files since they are supplied by `spark-submit`. Since Gradle doesn't have a 'provided' dependency (see https://github.com/broadinstitute/hellbender/issues/836), I had to do a bit of a workaround with the `shadowJar` target, which is now `sparkJar`. . Here's the command I ran:. ``` bash; NAMENODE=...; SPARK_MASTER=yarn-client; HELLBENDER_HOME=...; spark-submit \; --master $SPARK_MASTER \; --conf spark.driver.userClassPathFirst=true \; --conf spark.executor.userClassPathFirst=true \; --conf spark.io.compression.codec=lzf \; build/libs/hellbender-all-*-spark.jar ReadsPipelineSpark \; --input hdfs://$NAMENODE/user/$USER/bam/NA12878.chr17_69k_70k.dictFix.bam \; --output hdfs://$NAMENODE/user/$USER/out/spark-reads-pipeline \; --reference hdfs://$NAMENODE/user/$USER/fasta/human_g1k_v37.chr17_1Mb.fasta \; --baseRecalibrationKnownVariants $HELLBENDER_HOME/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf \; --sparkMaster $SPARK_MASTER ; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/882
https://github.com/broadinstitute/gatk/pull/882:357,Safety,avoid,avoid,357,"There were a couple of things I needed to do to get the new Spark code running on a cluster:. i. Go back to using Spark's version of Kryo. Using a different version of Kryo is not actually needed (2.21 used by Spark passes the tests), and actually caused errors on the cluster when run with `--conf spark.driver.userClassPathFirst=true` (which is needed to avoid other library conflicts, like with jopt-simple). ii. Exclude Spark from the JAR file to avoid library conflicts. It's normal to exclude Spark and Hadoop from JAR files since they are supplied by `spark-submit`. Since Gradle doesn't have a 'provided' dependency (see https://github.com/broadinstitute/hellbender/issues/836), I had to do a bit of a workaround with the `shadowJar` target, which is now `sparkJar`. . Here's the command I ran:. ``` bash; NAMENODE=...; SPARK_MASTER=yarn-client; HELLBENDER_HOME=...; spark-submit \; --master $SPARK_MASTER \; --conf spark.driver.userClassPathFirst=true \; --conf spark.executor.userClassPathFirst=true \; --conf spark.io.compression.codec=lzf \; build/libs/hellbender-all-*-spark.jar ReadsPipelineSpark \; --input hdfs://$NAMENODE/user/$USER/bam/NA12878.chr17_69k_70k.dictFix.bam \; --output hdfs://$NAMENODE/user/$USER/out/spark-reads-pipeline \; --reference hdfs://$NAMENODE/user/$USER/fasta/human_g1k_v37.chr17_1Mb.fasta \; --baseRecalibrationKnownVariants $HELLBENDER_HOME/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf \; --sparkMaster $SPARK_MASTER ; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/882
https://github.com/broadinstitute/gatk/pull/882:451,Safety,avoid,avoid,451,"There were a couple of things I needed to do to get the new Spark code running on a cluster:. i. Go back to using Spark's version of Kryo. Using a different version of Kryo is not actually needed (2.21 used by Spark passes the tests), and actually caused errors on the cluster when run with `--conf spark.driver.userClassPathFirst=true` (which is needed to avoid other library conflicts, like with jopt-simple). ii. Exclude Spark from the JAR file to avoid library conflicts. It's normal to exclude Spark and Hadoop from JAR files since they are supplied by `spark-submit`. Since Gradle doesn't have a 'provided' dependency (see https://github.com/broadinstitute/hellbender/issues/836), I had to do a bit of a workaround with the `shadowJar` target, which is now `sparkJar`. . Here's the command I ran:. ``` bash; NAMENODE=...; SPARK_MASTER=yarn-client; HELLBENDER_HOME=...; spark-submit \; --master $SPARK_MASTER \; --conf spark.driver.userClassPathFirst=true \; --conf spark.executor.userClassPathFirst=true \; --conf spark.io.compression.codec=lzf \; build/libs/hellbender-all-*-spark.jar ReadsPipelineSpark \; --input hdfs://$NAMENODE/user/$USER/bam/NA12878.chr17_69k_70k.dictFix.bam \; --output hdfs://$NAMENODE/user/$USER/out/spark-reads-pipeline \; --reference hdfs://$NAMENODE/user/$USER/fasta/human_g1k_v37.chr17_1Mb.fasta \; --baseRecalibrationKnownVariants $HELLBENDER_HOME/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf \; --sparkMaster $SPARK_MASTER ; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/882
https://github.com/broadinstitute/gatk/pull/882:227,Testability,test,tests,227,"There were a couple of things I needed to do to get the new Spark code running on a cluster:. i. Go back to using Spark's version of Kryo. Using a different version of Kryo is not actually needed (2.21 used by Spark passes the tests), and actually caused errors on the cluster when run with `--conf spark.driver.userClassPathFirst=true` (which is needed to avoid other library conflicts, like with jopt-simple). ii. Exclude Spark from the JAR file to avoid library conflicts. It's normal to exclude Spark and Hadoop from JAR files since they are supplied by `spark-submit`. Since Gradle doesn't have a 'provided' dependency (see https://github.com/broadinstitute/hellbender/issues/836), I had to do a bit of a workaround with the `shadowJar` target, which is now `sparkJar`. . Here's the command I ran:. ``` bash; NAMENODE=...; SPARK_MASTER=yarn-client; HELLBENDER_HOME=...; spark-submit \; --master $SPARK_MASTER \; --conf spark.driver.userClassPathFirst=true \; --conf spark.executor.userClassPathFirst=true \; --conf spark.io.compression.codec=lzf \; build/libs/hellbender-all-*-spark.jar ReadsPipelineSpark \; --input hdfs://$NAMENODE/user/$USER/bam/NA12878.chr17_69k_70k.dictFix.bam \; --output hdfs://$NAMENODE/user/$USER/out/spark-reads-pipeline \; --reference hdfs://$NAMENODE/user/$USER/fasta/human_g1k_v37.chr17_1Mb.fasta \; --baseRecalibrationKnownVariants $HELLBENDER_HOME/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf \; --sparkMaster $SPARK_MASTER ; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/882
https://github.com/broadinstitute/gatk/pull/882:1389,Testability,test,test,1389,"There were a couple of things I needed to do to get the new Spark code running on a cluster:. i. Go back to using Spark's version of Kryo. Using a different version of Kryo is not actually needed (2.21 used by Spark passes the tests), and actually caused errors on the cluster when run with `--conf spark.driver.userClassPathFirst=true` (which is needed to avoid other library conflicts, like with jopt-simple). ii. Exclude Spark from the JAR file to avoid library conflicts. It's normal to exclude Spark and Hadoop from JAR files since they are supplied by `spark-submit`. Since Gradle doesn't have a 'provided' dependency (see https://github.com/broadinstitute/hellbender/issues/836), I had to do a bit of a workaround with the `shadowJar` target, which is now `sparkJar`. . Here's the command I ran:. ``` bash; NAMENODE=...; SPARK_MASTER=yarn-client; HELLBENDER_HOME=...; spark-submit \; --master $SPARK_MASTER \; --conf spark.driver.userClassPathFirst=true \; --conf spark.executor.userClassPathFirst=true \; --conf spark.io.compression.codec=lzf \; build/libs/hellbender-all-*-spark.jar ReadsPipelineSpark \; --input hdfs://$NAMENODE/user/$USER/bam/NA12878.chr17_69k_70k.dictFix.bam \; --output hdfs://$NAMENODE/user/$USER/out/spark-reads-pipeline \; --reference hdfs://$NAMENODE/user/$USER/fasta/human_g1k_v37.chr17_1Mb.fasta \; --baseRecalibrationKnownVariants $HELLBENDER_HOME/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf \; --sparkMaster $SPARK_MASTER ; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/882
https://github.com/broadinstitute/gatk/pull/882:403,Usability,simpl,simple,403,"There were a couple of things I needed to do to get the new Spark code running on a cluster:. i. Go back to using Spark's version of Kryo. Using a different version of Kryo is not actually needed (2.21 used by Spark passes the tests), and actually caused errors on the cluster when run with `--conf spark.driver.userClassPathFirst=true` (which is needed to avoid other library conflicts, like with jopt-simple). ii. Exclude Spark from the JAR file to avoid library conflicts. It's normal to exclude Spark and Hadoop from JAR files since they are supplied by `spark-submit`. Since Gradle doesn't have a 'provided' dependency (see https://github.com/broadinstitute/hellbender/issues/836), I had to do a bit of a workaround with the `shadowJar` target, which is now `sparkJar`. . Here's the command I ran:. ``` bash; NAMENODE=...; SPARK_MASTER=yarn-client; HELLBENDER_HOME=...; spark-submit \; --master $SPARK_MASTER \; --conf spark.driver.userClassPathFirst=true \; --conf spark.executor.userClassPathFirst=true \; --conf spark.io.compression.codec=lzf \; build/libs/hellbender-all-*-spark.jar ReadsPipelineSpark \; --input hdfs://$NAMENODE/user/$USER/bam/NA12878.chr17_69k_70k.dictFix.bam \; --output hdfs://$NAMENODE/user/$USER/out/spark-reads-pipeline \; --reference hdfs://$NAMENODE/user/$USER/fasta/human_g1k_v37.chr17_1Mb.fasta \; --baseRecalibrationKnownVariants $HELLBENDER_HOME/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf \; --sparkMaster $SPARK_MASTER ; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/882
https://github.com/broadinstitute/gatk/issues/883:36,Testability,test,test,36,"From @tomwhite:. I noticed that the test with ""-knownSites"" from BaseRecalibratorIntegrationTest (i.e. the non-dataflow version) fails with both the Direct and Spark runners. I had a look at the file output and there are a few discrepancies (see diff below). . ```; diff /var/folders/d1/8f5_j4hx04z72w6wgqxkb2l40000gn/T/walktest.tmp_param.02172067147450353519.tmp src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.NA12878.chr17_69k_70k.2inputs.txt; 60c60; < 34 3051 34. ---; > 34 3050 34; 71c71; < 45 46942 45. ---; > 45 46940 45; 124,126c124,126; < 809R9ABXX101220.5 D 45.0000 45.0000 23471 0.00; < 809R9ABXX101220.5 I 45.0000 45.0000 23471 0.00; < 809R9ABXX101220.5 M 27.0000 27.0494 23471 49.13. ---; > 809R9ABXX101220.5 D 45.0000 45.0000 23470 0.00; > 809R9ABXX101220.5 I 45.0000 45.0000 23470 0.00; > 809R9ABXX101220.5 M 27.0000 27.0493 23470 49.13; 155c155; < 809R9ABXX101220.5 34 M 34.0000 3051 2.96. ---; > 809R9ABXX101220.5 34 M 34.0000 3050 2.96; 161,162c161,162; < 809R9ABXX101220.5 45 D 45.0000 23471 0.00; < 809R9ABXX101220.5 45 I 45.0000 23471 0.00. ---; > 809R9ABXX101220.5 45 D 45.0000 23470 0.00; > 809R9ABXX101220.5 45 I 45.0000 23470 0.00; 2714c2714; < 809R9ABXX101220.5 34 29 Cycle M 34.0000 20 0.00. ---; > 809R9ABXX101220.5 34 29 Cycle M 34.0000 19 0.00; 2773c2773; < 809R9ABXX101220.5 34 CA Context M 34.0000 506 0.00. ---; > 809R9ABXX101220.5 34 CA Context M 34.0000 505 0.00; 3464,3465c3464,3465; < 809R9ABXX101220.5 45 29 Cycle D 45.0000 180 0.00; < 809R9ABXX101220.5 45 29 Cycle I 45.0000 180 0.00. ---; > 809R9ABXX101220.5 45 29 Cycle D 45.0000 179 0.00; > 809R9ABXX101220.5 45 29 Cycle I 45.0000 179 0.00; 3634,3635c3634,3635; < 809R9ABXX101220.5 45 GCA Context D 45.0000 278 0.00; < 809R9ABXX101220.5 45 GCA Context I 45.0000 278 0.00. ---; > 809R9ABXX101220.5 45 GCA Context D 45.0000 277 0.00; > 809R9ABXX101220.5 45 GCA Context I 45.0000 277 0.00; ```. The relevant test is this one from `BaseRecalibratorDataflowIntegrationTest`. ```; new BQSRTest(",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/883
https://github.com/broadinstitute/gatk/issues/883:368,Testability,test,test,368,"From @tomwhite:. I noticed that the test with ""-knownSites"" from BaseRecalibratorIntegrationTest (i.e. the non-dataflow version) fails with both the Direct and Spark runners. I had a look at the file output and there are a few discrepancies (see diff below). . ```; diff /var/folders/d1/8f5_j4hx04z72w6wgqxkb2l40000gn/T/walktest.tmp_param.02172067147450353519.tmp src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.NA12878.chr17_69k_70k.2inputs.txt; 60c60; < 34 3051 34. ---; > 34 3050 34; 71c71; < 45 46942 45. ---; > 45 46940 45; 124,126c124,126; < 809R9ABXX101220.5 D 45.0000 45.0000 23471 0.00; < 809R9ABXX101220.5 I 45.0000 45.0000 23471 0.00; < 809R9ABXX101220.5 M 27.0000 27.0494 23471 49.13. ---; > 809R9ABXX101220.5 D 45.0000 45.0000 23470 0.00; > 809R9ABXX101220.5 I 45.0000 45.0000 23470 0.00; > 809R9ABXX101220.5 M 27.0000 27.0493 23470 49.13; 155c155; < 809R9ABXX101220.5 34 M 34.0000 3051 2.96. ---; > 809R9ABXX101220.5 34 M 34.0000 3050 2.96; 161,162c161,162; < 809R9ABXX101220.5 45 D 45.0000 23471 0.00; < 809R9ABXX101220.5 45 I 45.0000 23471 0.00. ---; > 809R9ABXX101220.5 45 D 45.0000 23470 0.00; > 809R9ABXX101220.5 45 I 45.0000 23470 0.00; 2714c2714; < 809R9ABXX101220.5 34 29 Cycle M 34.0000 20 0.00. ---; > 809R9ABXX101220.5 34 29 Cycle M 34.0000 19 0.00; 2773c2773; < 809R9ABXX101220.5 34 CA Context M 34.0000 506 0.00. ---; > 809R9ABXX101220.5 34 CA Context M 34.0000 505 0.00; 3464,3465c3464,3465; < 809R9ABXX101220.5 45 29 Cycle D 45.0000 180 0.00; < 809R9ABXX101220.5 45 29 Cycle I 45.0000 180 0.00. ---; > 809R9ABXX101220.5 45 29 Cycle D 45.0000 179 0.00; > 809R9ABXX101220.5 45 29 Cycle I 45.0000 179 0.00; 3634,3635c3634,3635; < 809R9ABXX101220.5 45 GCA Context D 45.0000 278 0.00; < 809R9ABXX101220.5 45 GCA Context I 45.0000 278 0.00. ---; > 809R9ABXX101220.5 45 GCA Context D 45.0000 277 0.00; > 809R9ABXX101220.5 45 GCA Context I 45.0000 277 0.00; ```. The relevant test is this one from `BaseRecalibratorDataflowIntegrationTest`. ```; new BQSRTest(",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/883
https://github.com/broadinstitute/gatk/issues/883:1918,Testability,test,test,1918,"s with both the Direct and Spark runners. I had a look at the file output and there are a few discrepancies (see diff below). . ```; diff /var/folders/d1/8f5_j4hx04z72w6wgqxkb2l40000gn/T/walktest.tmp_param.02172067147450353519.tmp src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.NA12878.chr17_69k_70k.2inputs.txt; 60c60; < 34 3051 34. ---; > 34 3050 34; 71c71; < 45 46942 45. ---; > 45 46940 45; 124,126c124,126; < 809R9ABXX101220.5 D 45.0000 45.0000 23471 0.00; < 809R9ABXX101220.5 I 45.0000 45.0000 23471 0.00; < 809R9ABXX101220.5 M 27.0000 27.0494 23471 49.13. ---; > 809R9ABXX101220.5 D 45.0000 45.0000 23470 0.00; > 809R9ABXX101220.5 I 45.0000 45.0000 23470 0.00; > 809R9ABXX101220.5 M 27.0000 27.0493 23470 49.13; 155c155; < 809R9ABXX101220.5 34 M 34.0000 3051 2.96. ---; > 809R9ABXX101220.5 34 M 34.0000 3050 2.96; 161,162c161,162; < 809R9ABXX101220.5 45 D 45.0000 23471 0.00; < 809R9ABXX101220.5 45 I 45.0000 23471 0.00. ---; > 809R9ABXX101220.5 45 D 45.0000 23470 0.00; > 809R9ABXX101220.5 45 I 45.0000 23470 0.00; 2714c2714; < 809R9ABXX101220.5 34 29 Cycle M 34.0000 20 0.00. ---; > 809R9ABXX101220.5 34 29 Cycle M 34.0000 19 0.00; 2773c2773; < 809R9ABXX101220.5 34 CA Context M 34.0000 506 0.00. ---; > 809R9ABXX101220.5 34 CA Context M 34.0000 505 0.00; 3464,3465c3464,3465; < 809R9ABXX101220.5 45 29 Cycle D 45.0000 180 0.00; < 809R9ABXX101220.5 45 29 Cycle I 45.0000 180 0.00. ---; > 809R9ABXX101220.5 45 29 Cycle D 45.0000 179 0.00; > 809R9ABXX101220.5 45 29 Cycle I 45.0000 179 0.00; 3634,3635c3634,3635; < 809R9ABXX101220.5 45 GCA Context D 45.0000 278 0.00; < 809R9ABXX101220.5 45 GCA Context I 45.0000 278 0.00. ---; > 809R9ABXX101220.5 45 GCA Context D 45.0000 277 0.00; > 809R9ABXX101220.5 45 GCA Context I 45.0000 277 0.00; ```. The relevant test is this one from `BaseRecalibratorDataflowIntegrationTest`. ```; new BQSRTest(hg18Reference, HiSeqBam, dbSNPb37, ""-knownSites "" + moreSites, getResourceDir() + ""expected.NA12878.chr17_69k_70k.2inputs.txt""); ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/883
https://github.com/broadinstitute/gatk/pull/884:137,Availability,error,error,137,"Completed tests with three options including MINIMUM_MAPPING_QUALITY=39, TAIL_LIMIT=25000, and CHIMERA_KB_MIN=200000. However, throws an error when using ""null"". Needless to say, so does Picard.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/884
https://github.com/broadinstitute/gatk/pull/884:10,Testability,test,tests,10,"Completed tests with three options including MINIMUM_MAPPING_QUALITY=39, TAIL_LIMIT=25000, and CHIMERA_KB_MIN=200000. However, throws an error when using ""null"". Needless to say, so does Picard.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/884
https://github.com/broadinstitute/gatk/issues/885:6,Testability,test,tests,6,"Cloud tests on Travis run against Google dataflow. This could, in principle, be accomplished for Spark using Amazon EMR. There may be version compatibility issues.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/885
https://github.com/broadinstitute/gatk/issues/886:40,Availability,error,errors,40,This will eliminate the transient Spark errors that look like this:. ```; java.io.IOException: org.apache.spark.SparkException: Failed to get broadcast_3_piece0 of broadcast_3; ```. (Reported by @akiezun.),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/886
https://github.com/broadinstitute/gatk/pull/887:117,Testability,test,tests,117,"This is another one for @davidadamsphd. Fixes #886. There could be further work to make the Spark and Spark Dataflow tests share a context, but that's not strictly needed as we don't run the two tests together.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/887
https://github.com/broadinstitute/gatk/pull/887:195,Testability,test,tests,195,"This is another one for @davidadamsphd. Fixes #886. There could be further work to make the Spark and Spark Dataflow tests share a context, but that's not strictly needed as we don't run the two tests together.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/887
https://github.com/broadinstitute/gatk/pull/889:188,Deployability,integrat,integration,188,"This is based on @davidadamsphd's initial work to port mark duplicates to Spark. It's not finished yet, but I wanted to post this for discussion. In particular 7 of the 56 mark duplicates integration tests are failing with ""Cannot get mate information for an unpaired read"" - I'm not sure how to address that. I'd appreciate some help on this one. The code currently has four shuffles: one groupBy in transformFragments (in MarkDuplicatesSparkUtils), two groupBys in transformReads, and one combine (foldByKey) in generateMetrics. The combine is more efficient than the others since it can run on the map side, reducing the amount of data that goes through the shuffle. I think it may be possible to merge the processing of the fragments and the reads to eliminate a shuffle - so there are only two shuffles for the main transform. A fragment would be represented as a pair with an empty second slot, so it can be handed in the processing separately from the true pairs that have both slots filled.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/889
https://github.com/broadinstitute/gatk/pull/889:551,Energy Efficiency,efficient,efficient,551,"This is based on @davidadamsphd's initial work to port mark duplicates to Spark. It's not finished yet, but I wanted to post this for discussion. In particular 7 of the 56 mark duplicates integration tests are failing with ""Cannot get mate information for an unpaired read"" - I'm not sure how to address that. I'd appreciate some help on this one. The code currently has four shuffles: one groupBy in transformFragments (in MarkDuplicatesSparkUtils), two groupBys in transformReads, and one combine (foldByKey) in generateMetrics. The combine is more efficient than the others since it can run on the map side, reducing the amount of data that goes through the shuffle. I think it may be possible to merge the processing of the fragments and the reads to eliminate a shuffle - so there are only two shuffles for the main transform. A fragment would be represented as a pair with an empty second slot, so it can be handed in the processing separately from the true pairs that have both slots filled.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/889
https://github.com/broadinstitute/gatk/pull/889:188,Integrability,integrat,integration,188,"This is based on @davidadamsphd's initial work to port mark duplicates to Spark. It's not finished yet, but I wanted to post this for discussion. In particular 7 of the 56 mark duplicates integration tests are failing with ""Cannot get mate information for an unpaired read"" - I'm not sure how to address that. I'd appreciate some help on this one. The code currently has four shuffles: one groupBy in transformFragments (in MarkDuplicatesSparkUtils), two groupBys in transformReads, and one combine (foldByKey) in generateMetrics. The combine is more efficient than the others since it can run on the map side, reducing the amount of data that goes through the shuffle. I think it may be possible to merge the processing of the fragments and the reads to eliminate a shuffle - so there are only two shuffles for the main transform. A fragment would be represented as a pair with an empty second slot, so it can be handed in the processing separately from the true pairs that have both slots filled.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/889
https://github.com/broadinstitute/gatk/pull/889:200,Testability,test,tests,200,"This is based on @davidadamsphd's initial work to port mark duplicates to Spark. It's not finished yet, but I wanted to post this for discussion. In particular 7 of the 56 mark duplicates integration tests are failing with ""Cannot get mate information for an unpaired read"" - I'm not sure how to address that. I'd appreciate some help on this one. The code currently has four shuffles: one groupBy in transformFragments (in MarkDuplicatesSparkUtils), two groupBys in transformReads, and one combine (foldByKey) in generateMetrics. The combine is more efficient than the others since it can run on the map side, reducing the amount of data that goes through the shuffle. I think it may be possible to merge the processing of the fragments and the reads to eliminate a shuffle - so there are only two shuffles for the main transform. A fragment would be represented as a pair with an empty second slot, so it can be handed in the processing separately from the true pairs that have both slots filled.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/889
https://github.com/broadinstitute/gatk/pull/892:47,Energy Efficiency,efficient,efficient,47,"Holds Locatables (e.g. variants) and offers an efficient ""queryOverlapping"" operation.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/892
https://github.com/broadinstitute/gatk/issues/897:4,Deployability,integrat,integration,4,the integration test (testBasic) must check the contents of the created file,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/897
https://github.com/broadinstitute/gatk/issues/897:4,Integrability,integrat,integration,4,the integration test (testBasic) must check the contents of the created file,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/897
https://github.com/broadinstitute/gatk/issues/897:16,Testability,test,test,16,the integration test (testBasic) must check the contents of the created file,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/897
https://github.com/broadinstitute/gatk/issues/897:22,Testability,test,testBasic,22,the integration test (testBasic) must check the contents of the created file,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/897
https://github.com/broadinstitute/gatk/issues/900:371,Modifiability,extend,extends,371,"This is meant as a group discussion that could happen several places, and here is as good as any. We know that shipping around the header is has a _huge_ cost. So, we need to find a way to effectively strip it from the `SAMRecord` without breaking it. I propose the following.; - Modify `SAMRecord` to use getter methods for the header; - Create a `HeaderSAMRecord` that extends `SAMRecord` and that has a static field for the header. This class would override `getHeader` to return the static; - Use `Broadcast` with `mapPartitions` to set the static on each worker. An alternative would be audit the field usage and do a combination of performing all necessary calls that require the header to when we load the reads and, if possible, making the still offending methods inaccessible. So, @tomwhite , @akiezun , @droazen , @lbergelson , @jean-philippe-martin , what do you all think?. I know @lbergelson previous expressed he didn't like the usage of statics for this purpose.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900
https://github.com/broadinstitute/gatk/issues/900:638,Performance,perform,performing,638,"This is meant as a group discussion that could happen several places, and here is as good as any. We know that shipping around the header is has a _huge_ cost. So, we need to find a way to effectively strip it from the `SAMRecord` without breaking it. I propose the following.; - Modify `SAMRecord` to use getter methods for the header; - Create a `HeaderSAMRecord` that extends `SAMRecord` and that has a static field for the header. This class would override `getHeader` to return the static; - Use `Broadcast` with `mapPartitions` to set the static on each worker. An alternative would be audit the field usage and do a combination of performing all necessary calls that require the header to when we load the reads and, if possible, making the still offending methods inaccessible. So, @tomwhite , @akiezun , @droazen , @lbergelson , @jean-philippe-martin , what do you all think?. I know @lbergelson previous expressed he didn't like the usage of statics for this purpose.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900
https://github.com/broadinstitute/gatk/issues/900:704,Performance,load,load,704,"This is meant as a group discussion that could happen several places, and here is as good as any. We know that shipping around the header is has a _huge_ cost. So, we need to find a way to effectively strip it from the `SAMRecord` without breaking it. I propose the following.; - Modify `SAMRecord` to use getter methods for the header; - Create a `HeaderSAMRecord` that extends `SAMRecord` and that has a static field for the header. This class would override `getHeader` to return the static; - Use `Broadcast` with `mapPartitions` to set the static on each worker. An alternative would be audit the field usage and do a combination of performing all necessary calls that require the header to when we load the reads and, if possible, making the still offending methods inaccessible. So, @tomwhite , @akiezun , @droazen , @lbergelson , @jean-philippe-martin , what do you all think?. I know @lbergelson previous expressed he didn't like the usage of statics for this purpose.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900
https://github.com/broadinstitute/gatk/issues/900:592,Security,audit,audit,592,"This is meant as a group discussion that could happen several places, and here is as good as any. We know that shipping around the header is has a _huge_ cost. So, we need to find a way to effectively strip it from the `SAMRecord` without breaking it. I propose the following.; - Modify `SAMRecord` to use getter methods for the header; - Create a `HeaderSAMRecord` that extends `SAMRecord` and that has a static field for the header. This class would override `getHeader` to return the static; - Use `Broadcast` with `mapPartitions` to set the static on each worker. An alternative would be audit the field usage and do a combination of performing all necessary calls that require the header to when we load the reads and, if possible, making the still offending methods inaccessible. So, @tomwhite , @akiezun , @droazen , @lbergelson , @jean-philippe-martin , what do you all think?. I know @lbergelson previous expressed he didn't like the usage of statics for this purpose.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900
https://github.com/broadinstitute/gatk/issues/903:281,Deployability,patch,patch,281,"The SAMRecord class currently allows the header to be set to null (either at construction time or via `setHeader()`), but may blow up or allow itself to enter an inconsistent state when it lacks a header (eg., the reference name and reference index can get out of sync). We should patch this class (and subclasses such as `BAMRecord`) in https://github.com/samtools/htsjdk/ to behave sensibly in all cases when a header is not present (eg., use a special missing value for reference index when the reference index cannot be looked up), and add unit tests to prove that headerless `SAMRecords` function correctly. This is important for dataflow and spark, where we want to serialize `SAMRecords` without paying the cost of serializing a header for each record.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/903
https://github.com/broadinstitute/gatk/issues/903:549,Testability,test,tests,549,"The SAMRecord class currently allows the header to be set to null (either at construction time or via `setHeader()`), but may blow up or allow itself to enter an inconsistent state when it lacks a header (eg., the reference name and reference index can get out of sync). We should patch this class (and subclasses such as `BAMRecord`) in https://github.com/samtools/htsjdk/ to behave sensibly in all cases when a header is not present (eg., use a special missing value for reference index when the reference index cannot be looked up), and add unit tests to prove that headerless `SAMRecords` function correctly. This is important for dataflow and spark, where we want to serialize `SAMRecords` without paying the cost of serializing a header for each record.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/903
https://github.com/broadinstitute/gatk/pull/904:2,Usability,simpl,simple,2,A simple change with a big impact.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/904
https://github.com/broadinstitute/gatk/pull/905:39,Testability,test,tests,39,"This is not ready to be merged since 4 tests are failing (MarkDuplicatesSparkIntegrationTest#testMarkDuplicatesSparkIntegrationTestLocal). The thing that is different about these tests is that they have paired reads where the read names differ for the two reads in a pair. So handling these as fragments _after_ grouping by read group and name means that the reads are not brought together in the way that they are being in the current version (with the extra shuffle). It's possible there's a fix for this, but I haven't spotted it yet. Extra eyes on this would be welcome.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/905
https://github.com/broadinstitute/gatk/pull/905:93,Testability,test,testMarkDuplicatesSparkIntegrationTestLocal,93,"This is not ready to be merged since 4 tests are failing (MarkDuplicatesSparkIntegrationTest#testMarkDuplicatesSparkIntegrationTestLocal). The thing that is different about these tests is that they have paired reads where the read names differ for the two reads in a pair. So handling these as fragments _after_ grouping by read group and name means that the reads are not brought together in the way that they are being in the current version (with the extra shuffle). It's possible there's a fix for this, but I haven't spotted it yet. Extra eyes on this would be welcome.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/905
https://github.com/broadinstitute/gatk/pull/905:179,Testability,test,tests,179,"This is not ready to be merged since 4 tests are failing (MarkDuplicatesSparkIntegrationTest#testMarkDuplicatesSparkIntegrationTestLocal). The thing that is different about these tests is that they have paired reads where the read names differ for the two reads in a pair. So handling these as fragments _after_ grouping by read group and name means that the reads are not brought together in the way that they are being in the current version (with the extra shuffle). It's possible there's a fix for this, but I haven't spotted it yet. Extra eyes on this would be welcome.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/905
https://github.com/broadinstitute/gatk/pull/907:89,Availability,avail,available,89,"adding a test for large files existance in the ""large"" test group. large files should be available for tests on travis after this pull request",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/907
https://github.com/broadinstitute/gatk/pull/907:9,Testability,test,test,9,"adding a test for large files existance in the ""large"" test group. large files should be available for tests on travis after this pull request",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/907
https://github.com/broadinstitute/gatk/pull/907:55,Testability,test,test,55,"adding a test for large files existance in the ""large"" test group. large files should be available for tests on travis after this pull request",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/907
https://github.com/broadinstitute/gatk/pull/907:103,Testability,test,tests,103,"adding a test for large files existance in the ""large"" test group. large files should be available for tests on travis after this pull request",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/907
https://github.com/broadinstitute/gatk/pull/910:36,Testability,benchmark,benchmarking,36,Fixes #906. This will be useful for benchmarking. Can you have a look when you have time @davidadamsphd?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/910
https://github.com/broadinstitute/gatk/pull/911:38,Modifiability,Refactor,Refactored,38,"-Ported BQSR and ApplyBQSR to spark. -Refactored the BQSR engine so that all versions of BQSR (walker, dataflow,; and spark) call into a common engine, and removed duplicated versions; of the engine from the codebase.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/911
https://github.com/broadinstitute/gatk/pull/912:28,Integrability,depend,dependencies,28,The ADAM jar was pulling in dependencies that should not be in the sparkJar since they stop it working on a cluster.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/912
https://github.com/broadinstitute/gatk/pull/913:88,Energy Efficiency,adapt,adapted,88,"This script will look for a small input that trips BaseRecalibrator. However, it can be adapted for debugging pretty much anything else, so long as you have two versions of the code: a ""known good"" one to compare against, and a ""under test"" one that has the bug you're trying to generate a minimal input for.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/913
https://github.com/broadinstitute/gatk/pull/913:88,Modifiability,adapt,adapted,88,"This script will look for a small input that trips BaseRecalibrator. However, it can be adapted for debugging pretty much anything else, so long as you have two versions of the code: a ""known good"" one to compare against, and a ""under test"" one that has the bug you're trying to generate a minimal input for.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/913
https://github.com/broadinstitute/gatk/pull/913:235,Testability,test,test,235,"This script will look for a small input that trips BaseRecalibrator. However, it can be adapted for debugging pretty much anything else, so long as you have two versions of the code: a ""known good"" one to compare against, and a ""under test"" one that has the bug you're trying to generate a minimal input for.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/913
https://github.com/broadinstitute/gatk/issues/914:53,Performance,concurren,concurrency,53,mutable static state is a source of memory leaks and concurrency bugs on dataflow/spark. we need to get rid of all of it. In particular mutable static collections but mutated static arrays are also bad (can't make java arrays unmodifiable unfortunately),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/914
https://github.com/broadinstitute/gatk/pull/915:0,Integrability,wrap,wrapping,0,wrapping ReadCovariate.keyCache in a ThreadLocal to prevent multithreading issues; changing worker type for dataflow to 4-core,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/915
https://github.com/broadinstitute/gatk/issues/918:11,Deployability,install,install,11,```; build/install/hellbender/bin/hellbender CollectWgsMetrics -I src//test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.bam -R src//test/resources/org/broadinstitute/hellbender/tools/exome/test_reference.fasta -O CollectWGSMetrics.txt; ```. ```; java.lang.ArrayIndexOutOfBoundsException: 1000; at org.broadinstitute.hellbender.tools.picard.analysis.directed.CollectWgsMetrics.doWork(CollectWgsMetrics.java:161); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:98); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:151); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgram.instanceMain(PicardCommandLineProgram.java:51); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:71); at org.broadinstitute.hellbender.Main.main(Main.java:86); ```. note: same bug is present in picard 1.138,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/918
https://github.com/broadinstitute/gatk/issues/918:71,Testability,test,test,71,```; build/install/hellbender/bin/hellbender CollectWgsMetrics -I src//test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.bam -R src//test/resources/org/broadinstitute/hellbender/tools/exome/test_reference.fasta -O CollectWGSMetrics.txt; ```. ```; java.lang.ArrayIndexOutOfBoundsException: 1000; at org.broadinstitute.hellbender.tools.picard.analysis.directed.CollectWgsMetrics.doWork(CollectWgsMetrics.java:161); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:98); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:151); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgram.instanceMain(PicardCommandLineProgram.java:51); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:71); at org.broadinstitute.hellbender.Main.main(Main.java:86); ```. note: same bug is present in picard 1.138,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/918
https://github.com/broadinstitute/gatk/issues/918:166,Testability,test,test,166,```; build/install/hellbender/bin/hellbender CollectWgsMetrics -I src//test/resources/org/broadinstitute/hellbender/tools/exome/exome-read-counts-NA12878.bam -R src//test/resources/org/broadinstitute/hellbender/tools/exome/test_reference.fasta -O CollectWGSMetrics.txt; ```. ```; java.lang.ArrayIndexOutOfBoundsException: 1000; at org.broadinstitute.hellbender.tools.picard.analysis.directed.CollectWgsMetrics.doWork(CollectWgsMetrics.java:161); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:98); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:151); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgram.instanceMain(PicardCommandLineProgram.java:51); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:71); at org.broadinstitute.hellbender.Main.main(Main.java:86); ```. note: same bug is present in picard 1.138,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/918
https://github.com/broadinstitute/gatk/pull/919:277,Availability,Down,Downloads,277,"This branch adds the ability to perform a Broadcast of the reference and also support for 2bit references. I'm submitting this PR against the `dr_lb_spark_bqsr` branch. I can run the following two commands on my local machine, which produce the same output. Broadcast:. ```; ~/Downloads/spark-1.4.1-bin-hadoop2.4/bin/spark-submit \; --master local[2] \; ~/repos/hellbender/build/libs/hellbender-all-GATK.4.*-spark.jar \; BaseRecalibratorSpark \; --input ~/repos/hellbender/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam \; --knownSites ~/repos/hellbender/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf \; --reference ~/repos/hellbender/src/test/resources/large/human_g1k_v37.20.21.2bit \; --joinStrategy BROADCAST \; --output ~/tmp/bqsr.out.2.txt; ```. Shuffle:. ```; ~/Downloads/spark-1.4.1-bin-hadoop2.4/bin/spark-submit \; --master local[2] \; ~/repos/hellbender/build/libs/hellbender-all-GATK.4.*-spark.jar \; BaseRecalibratorSpark \; --input ~/repos/hellbender/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam \; --knownSites ~/repos/hellbender/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf \; --reference ~/repos/hellbender/src/test/resources/large/human_g1k_v37.20.21.fasta \; --joinStrategy SHUFFLE \; --output ~/tmp/bqsr.out.3.txt; ```. Still need to try it on a cluster and on bigger input. cc @tomwhite @davidadamsphd for review.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/919
https://github.com/broadinstitute/gatk/pull/919:901,Availability,Down,Downloads,901,"This branch adds the ability to perform a Broadcast of the reference and also support for 2bit references. I'm submitting this PR against the `dr_lb_spark_bqsr` branch. I can run the following two commands on my local machine, which produce the same output. Broadcast:. ```; ~/Downloads/spark-1.4.1-bin-hadoop2.4/bin/spark-submit \; --master local[2] \; ~/repos/hellbender/build/libs/hellbender-all-GATK.4.*-spark.jar \; BaseRecalibratorSpark \; --input ~/repos/hellbender/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam \; --knownSites ~/repos/hellbender/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf \; --reference ~/repos/hellbender/src/test/resources/large/human_g1k_v37.20.21.2bit \; --joinStrategy BROADCAST \; --output ~/tmp/bqsr.out.2.txt; ```. Shuffle:. ```; ~/Downloads/spark-1.4.1-bin-hadoop2.4/bin/spark-submit \; --master local[2] \; ~/repos/hellbender/build/libs/hellbender-all-GATK.4.*-spark.jar \; BaseRecalibratorSpark \; --input ~/repos/hellbender/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam \; --knownSites ~/repos/hellbender/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf \; --reference ~/repos/hellbender/src/test/resources/large/human_g1k_v37.20.21.fasta \; --joinStrategy SHUFFLE \; --output ~/tmp/bqsr.out.3.txt; ```. Still need to try it on a cluster and on bigger input. cc @tomwhite @davidadamsphd for review.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/919
https://github.com/broadinstitute/gatk/pull/919:32,Performance,perform,perform,32,"This branch adds the ability to perform a Broadcast of the reference and also support for 2bit references. I'm submitting this PR against the `dr_lb_spark_bqsr` branch. I can run the following two commands on my local machine, which produce the same output. Broadcast:. ```; ~/Downloads/spark-1.4.1-bin-hadoop2.4/bin/spark-submit \; --master local[2] \; ~/repos/hellbender/build/libs/hellbender-all-GATK.4.*-spark.jar \; BaseRecalibratorSpark \; --input ~/repos/hellbender/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam \; --knownSites ~/repos/hellbender/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf \; --reference ~/repos/hellbender/src/test/resources/large/human_g1k_v37.20.21.2bit \; --joinStrategy BROADCAST \; --output ~/tmp/bqsr.out.2.txt; ```. Shuffle:. ```; ~/Downloads/spark-1.4.1-bin-hadoop2.4/bin/spark-submit \; --master local[2] \; ~/repos/hellbender/build/libs/hellbender-all-GATK.4.*-spark.jar \; BaseRecalibratorSpark \; --input ~/repos/hellbender/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam \; --knownSites ~/repos/hellbender/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf \; --reference ~/repos/hellbender/src/test/resources/large/human_g1k_v37.20.21.fasta \; --joinStrategy SHUFFLE \; --output ~/tmp/bqsr.out.3.txt; ```. Still need to try it on a cluster and on bigger input. cc @tomwhite @davidadamsphd for review.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/919
https://github.com/broadinstitute/gatk/pull/919:477,Testability,test,test,477,"This branch adds the ability to perform a Broadcast of the reference and also support for 2bit references. I'm submitting this PR against the `dr_lb_spark_bqsr` branch. I can run the following two commands on my local machine, which produce the same output. Broadcast:. ```; ~/Downloads/spark-1.4.1-bin-hadoop2.4/bin/spark-submit \; --master local[2] \; ~/repos/hellbender/build/libs/hellbender-all-GATK.4.*-spark.jar \; BaseRecalibratorSpark \; --input ~/repos/hellbender/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam \; --knownSites ~/repos/hellbender/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf \; --reference ~/repos/hellbender/src/test/resources/large/human_g1k_v37.20.21.2bit \; --joinStrategy BROADCAST \; --output ~/tmp/bqsr.out.2.txt; ```. Shuffle:. ```; ~/Downloads/spark-1.4.1-bin-hadoop2.4/bin/spark-submit \; --master local[2] \; ~/repos/hellbender/build/libs/hellbender-all-GATK.4.*-spark.jar \; BaseRecalibratorSpark \; --input ~/repos/hellbender/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam \; --knownSites ~/repos/hellbender/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf \; --reference ~/repos/hellbender/src/test/resources/large/human_g1k_v37.20.21.fasta \; --joinStrategy SHUFFLE \; --output ~/tmp/bqsr.out.3.txt; ```. Still need to try it on a cluster and on bigger input. cc @tomwhite @davidadamsphd for review.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/919
https://github.com/broadinstitute/gatk/pull/919:619,Testability,test,test,619,"This branch adds the ability to perform a Broadcast of the reference and also support for 2bit references. I'm submitting this PR against the `dr_lb_spark_bqsr` branch. I can run the following two commands on my local machine, which produce the same output. Broadcast:. ```; ~/Downloads/spark-1.4.1-bin-hadoop2.4/bin/spark-submit \; --master local[2] \; ~/repos/hellbender/build/libs/hellbender-all-GATK.4.*-spark.jar \; BaseRecalibratorSpark \; --input ~/repos/hellbender/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam \; --knownSites ~/repos/hellbender/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf \; --reference ~/repos/hellbender/src/test/resources/large/human_g1k_v37.20.21.2bit \; --joinStrategy BROADCAST \; --output ~/tmp/bqsr.out.2.txt; ```. Shuffle:. ```; ~/Downloads/spark-1.4.1-bin-hadoop2.4/bin/spark-submit \; --master local[2] \; ~/repos/hellbender/build/libs/hellbender-all-GATK.4.*-spark.jar \; BaseRecalibratorSpark \; --input ~/repos/hellbender/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam \; --knownSites ~/repos/hellbender/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf \; --reference ~/repos/hellbender/src/test/resources/large/human_g1k_v37.20.21.fasta \; --joinStrategy SHUFFLE \; --output ~/tmp/bqsr.out.3.txt; ```. Still need to try it on a cluster and on bigger input. cc @tomwhite @davidadamsphd for review.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/919
https://github.com/broadinstitute/gatk/pull/919:771,Testability,test,test,771,"This branch adds the ability to perform a Broadcast of the reference and also support for 2bit references. I'm submitting this PR against the `dr_lb_spark_bqsr` branch. I can run the following two commands on my local machine, which produce the same output. Broadcast:. ```; ~/Downloads/spark-1.4.1-bin-hadoop2.4/bin/spark-submit \; --master local[2] \; ~/repos/hellbender/build/libs/hellbender-all-GATK.4.*-spark.jar \; BaseRecalibratorSpark \; --input ~/repos/hellbender/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam \; --knownSites ~/repos/hellbender/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf \; --reference ~/repos/hellbender/src/test/resources/large/human_g1k_v37.20.21.2bit \; --joinStrategy BROADCAST \; --output ~/tmp/bqsr.out.2.txt; ```. Shuffle:. ```; ~/Downloads/spark-1.4.1-bin-hadoop2.4/bin/spark-submit \; --master local[2] \; ~/repos/hellbender/build/libs/hellbender-all-GATK.4.*-spark.jar \; BaseRecalibratorSpark \; --input ~/repos/hellbender/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam \; --knownSites ~/repos/hellbender/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf \; --reference ~/repos/hellbender/src/test/resources/large/human_g1k_v37.20.21.fasta \; --joinStrategy SHUFFLE \; --output ~/tmp/bqsr.out.3.txt; ```. Still need to try it on a cluster and on bigger input. cc @tomwhite @davidadamsphd for review.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/919
https://github.com/broadinstitute/gatk/pull/919:1101,Testability,test,test,1101,"This branch adds the ability to perform a Broadcast of the reference and also support for 2bit references. I'm submitting this PR against the `dr_lb_spark_bqsr` branch. I can run the following two commands on my local machine, which produce the same output. Broadcast:. ```; ~/Downloads/spark-1.4.1-bin-hadoop2.4/bin/spark-submit \; --master local[2] \; ~/repos/hellbender/build/libs/hellbender-all-GATK.4.*-spark.jar \; BaseRecalibratorSpark \; --input ~/repos/hellbender/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam \; --knownSites ~/repos/hellbender/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf \; --reference ~/repos/hellbender/src/test/resources/large/human_g1k_v37.20.21.2bit \; --joinStrategy BROADCAST \; --output ~/tmp/bqsr.out.2.txt; ```. Shuffle:. ```; ~/Downloads/spark-1.4.1-bin-hadoop2.4/bin/spark-submit \; --master local[2] \; ~/repos/hellbender/build/libs/hellbender-all-GATK.4.*-spark.jar \; BaseRecalibratorSpark \; --input ~/repos/hellbender/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam \; --knownSites ~/repos/hellbender/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf \; --reference ~/repos/hellbender/src/test/resources/large/human_g1k_v37.20.21.fasta \; --joinStrategy SHUFFLE \; --output ~/tmp/bqsr.out.3.txt; ```. Still need to try it on a cluster and on bigger input. cc @tomwhite @davidadamsphd for review.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/919
https://github.com/broadinstitute/gatk/pull/919:1243,Testability,test,test,1243,"This branch adds the ability to perform a Broadcast of the reference and also support for 2bit references. I'm submitting this PR against the `dr_lb_spark_bqsr` branch. I can run the following two commands on my local machine, which produce the same output. Broadcast:. ```; ~/Downloads/spark-1.4.1-bin-hadoop2.4/bin/spark-submit \; --master local[2] \; ~/repos/hellbender/build/libs/hellbender-all-GATK.4.*-spark.jar \; BaseRecalibratorSpark \; --input ~/repos/hellbender/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam \; --knownSites ~/repos/hellbender/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf \; --reference ~/repos/hellbender/src/test/resources/large/human_g1k_v37.20.21.2bit \; --joinStrategy BROADCAST \; --output ~/tmp/bqsr.out.2.txt; ```. Shuffle:. ```; ~/Downloads/spark-1.4.1-bin-hadoop2.4/bin/spark-submit \; --master local[2] \; ~/repos/hellbender/build/libs/hellbender-all-GATK.4.*-spark.jar \; BaseRecalibratorSpark \; --input ~/repos/hellbender/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam \; --knownSites ~/repos/hellbender/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf \; --reference ~/repos/hellbender/src/test/resources/large/human_g1k_v37.20.21.fasta \; --joinStrategy SHUFFLE \; --output ~/tmp/bqsr.out.3.txt; ```. Still need to try it on a cluster and on bigger input. cc @tomwhite @davidadamsphd for review.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/919
https://github.com/broadinstitute/gatk/pull/919:1395,Testability,test,test,1395,"This branch adds the ability to perform a Broadcast of the reference and also support for 2bit references. I'm submitting this PR against the `dr_lb_spark_bqsr` branch. I can run the following two commands on my local machine, which produce the same output. Broadcast:. ```; ~/Downloads/spark-1.4.1-bin-hadoop2.4/bin/spark-submit \; --master local[2] \; ~/repos/hellbender/build/libs/hellbender-all-GATK.4.*-spark.jar \; BaseRecalibratorSpark \; --input ~/repos/hellbender/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam \; --knownSites ~/repos/hellbender/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf \; --reference ~/repos/hellbender/src/test/resources/large/human_g1k_v37.20.21.2bit \; --joinStrategy BROADCAST \; --output ~/tmp/bqsr.out.2.txt; ```. Shuffle:. ```; ~/Downloads/spark-1.4.1-bin-hadoop2.4/bin/spark-submit \; --master local[2] \; ~/repos/hellbender/build/libs/hellbender-all-GATK.4.*-spark.jar \; BaseRecalibratorSpark \; --input ~/repos/hellbender/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam \; --knownSites ~/repos/hellbender/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf \; --reference ~/repos/hellbender/src/test/resources/large/human_g1k_v37.20.21.fasta \; --joinStrategy SHUFFLE \; --output ~/tmp/bqsr.out.3.txt; ```. Still need to try it on a cluster and on bigger input. cc @tomwhite @davidadamsphd for review.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/919
https://github.com/broadinstitute/gatk/pull/920:26,Safety,sanity check,sanity checking,26,"the simplest example, for sanity checking of instalations",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/920
https://github.com/broadinstitute/gatk/pull/920:4,Usability,simpl,simplest,4,"the simplest example, for sanity checking of instalations",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/920
https://github.com/broadinstitute/gatk/pull/922:17,Testability,log,logging,17,Making java.util.logging obey our verbosity setting; setting our logging level to WARN in tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/922
https://github.com/broadinstitute/gatk/pull/922:65,Testability,log,logging,65,Making java.util.logging obey our verbosity setting; setting our logging level to WARN in tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/922
https://github.com/broadinstitute/gatk/pull/922:90,Testability,test,tests,90,Making java.util.logging obey our verbosity setting; setting our logging level to WARN in tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/922
https://github.com/broadinstitute/gatk/issues/923:43,Deployability,Pipeline,PipelineOptions,43,methods like BucketUtils.createFile take a PipelineOptions argument. That argument can be null if the path is not on a cloud but the doc does not mention that fact.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/923
https://github.com/broadinstitute/gatk/pull/927:29,Security,access,access,29,"Requires a ""git lfs pull"" to access. File size is ~230 MB.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/927
https://github.com/broadinstitute/gatk/pull/931:44,Performance,scalab,scalability,44,another small program on spark - useful for scalability testing of read/writes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/931
https://github.com/broadinstitute/gatk/pull/931:56,Testability,test,testing,56,another small program on spark - useful for scalability testing of read/writes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/931
https://github.com/broadinstitute/gatk/pull/932:55,Testability,test,tests,55,"Added handling of interval to count reads.; Additional tests are ported from the dataflow side: CountReadsDataflowIntegrationTest; Note that the semantics of no specifying any -L is to count **all** reads, aligned and unaligned.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/932
https://github.com/broadinstitute/gatk/issues/933:96,Energy Efficiency,reduce,reduce,96,FlagStatDataflow and tests should be easy to port and a useful tool that requires a non-trivial reduce,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/933
https://github.com/broadinstitute/gatk/issues/933:21,Testability,test,tests,21,FlagStatDataflow and tests should be easy to port and a useful tool that requires a non-trivial reduce,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/933
https://github.com/broadinstitute/gatk/issues/935:0,Testability,Test,Test,0,Test that sharded files written with `ReadsSparkSink` can be read back with `ReadsSparkSource`.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/935
https://github.com/broadinstitute/gatk/pull/937:121,Energy Efficiency,reduce,reduce,121,change shards `hashCode` to fix bad distribution to partitions. fix NPE. adding uri's change from distinct to aggregate. reduce shard size by half,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/937
https://github.com/broadinstitute/gatk/pull/937:15,Security,hash,hashCode,15,change shards `hashCode` to fix bad distribution to partitions. fix NPE. adding uri's change from distinct to aggregate. reduce shard size by half,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/937
https://github.com/broadinstitute/gatk/pull/939:76,Energy Efficiency,monitor,monitoring,76,I want to be able to specify the name of the app as it appears in the Spark monitoring GUI.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/939
https://github.com/broadinstitute/gatk/issues/940:2,Testability,test,tested,2,"I tested on a 30Gb file, trying to write to HDFS. It wrote more than 1.4 TB to disk and took hours to complete.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/940
https://github.com/broadinstitute/gatk/pull/941:58,Deployability,upgrade,upgrade,58,"we've been recommending a very old version, might as well upgrade",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/941
https://github.com/broadinstitute/gatk/pull/942:98,Performance,cache,cache,98,"FeatureDataSource was not correctly keeping track of the interval covered; by the contents of its cache, and as a result was producing many more; cache misses than it should have.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/942
https://github.com/broadinstitute/gatk/pull/942:146,Performance,cache,cache,146,"FeatureDataSource was not correctly keeping track of the interval covered; by the contents of its cache, and as a result was producing many more; cache misses than it should have.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/942
https://github.com/broadinstitute/gatk/issues/944:254,Energy Efficiency,reduce,reduced,254,"The HaplotypeBAMWriter implementation as ported from GATK is currently spread out over 5 classes, with a base class and two subclasses for the writers and a base class and one subclass to represent the writer destination. All of the functionality can be reduced to one simple HaplotypeBAMWriter class (or possibly two if we want to keep the destination separate).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/944
https://github.com/broadinstitute/gatk/issues/944:269,Usability,simpl,simple,269,"The HaplotypeBAMWriter implementation as ported from GATK is currently spread out over 5 classes, with a base class and two subclasses for the writers and a base class and one subclass to represent the writer destination. All of the functionality can be reduced to one simple HaplotypeBAMWriter class (or possibly two if we want to keep the destination separate).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/944
https://github.com/broadinstitute/gatk/issues/952:542,Availability,Down,Downloading,542,"@vdauwera reported this here #950 :. > Can't seem to do git clone https://github.com/broadinstitute/hellbender/. ```; wmd16-c9e:codespace vdauwera$ git clone http://github.com/broadinstitute/hellbender/; Cloning into 'hellbender'...; remote: Counting objects: 22221, done.; remote: Compressing objects: 100% (142/142), done.; remote: Total 22221 (delta 47), reused 4 (delta 4), pack-reused 22046; Receiving objects: 100% (22221/22221), 36.63 MiB | 3.58 MiB/s, done.; Resolving deltas: 100% (9903/9903), done.; Checking connectivity... done.; Downloading src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam (76.16 MB); Username for 'http://github.com': vdauwera; Password for 'http://vdauwera@github.com': ; Error accessing media: src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam (6b1304800e60c0ac0358df137bdad48b7857a36465b04fef3fbbb09380f04746). Errors logged to /Users/vdauwera/codespace/hellbender/.git/lfs/objects/logs/20151005T220016.510795175.log.; Use `git lfs logs last` to view the log.; Downloading src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam.bai (11.25 KB); Username for 'http://github.com': ; ```. > Looks like I'm failing to download large test files. Do I need to be on VPN for this to work? Or is it expected and I should ignore it?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/952
https://github.com/broadinstitute/gatk/issues/952:720,Availability,Error,Error,720,"@vdauwera reported this here #950 :. > Can't seem to do git clone https://github.com/broadinstitute/hellbender/. ```; wmd16-c9e:codespace vdauwera$ git clone http://github.com/broadinstitute/hellbender/; Cloning into 'hellbender'...; remote: Counting objects: 22221, done.; remote: Compressing objects: 100% (142/142), done.; remote: Total 22221 (delta 47), reused 4 (delta 4), pack-reused 22046; Receiving objects: 100% (22221/22221), 36.63 MiB | 3.58 MiB/s, done.; Resolving deltas: 100% (9903/9903), done.; Checking connectivity... done.; Downloading src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam (76.16 MB); Username for 'http://github.com': vdauwera; Password for 'http://vdauwera@github.com': ; Error accessing media: src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam (6b1304800e60c0ac0358df137bdad48b7857a36465b04fef3fbbb09380f04746). Errors logged to /Users/vdauwera/codespace/hellbender/.git/lfs/objects/logs/20151005T220016.510795175.log.; Use `git lfs logs last` to view the log.; Downloading src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam.bai (11.25 KB); Username for 'http://github.com': ; ```. > Looks like I'm failing to download large test files. Do I need to be on VPN for this to work? Or is it expected and I should ignore it?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/952
https://github.com/broadinstitute/gatk/issues/952:876,Availability,Error,Errors,876,"@vdauwera reported this here #950 :. > Can't seem to do git clone https://github.com/broadinstitute/hellbender/. ```; wmd16-c9e:codespace vdauwera$ git clone http://github.com/broadinstitute/hellbender/; Cloning into 'hellbender'...; remote: Counting objects: 22221, done.; remote: Compressing objects: 100% (142/142), done.; remote: Total 22221 (delta 47), reused 4 (delta 4), pack-reused 22046; Receiving objects: 100% (22221/22221), 36.63 MiB | 3.58 MiB/s, done.; Resolving deltas: 100% (9903/9903), done.; Checking connectivity... done.; Downloading src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam (76.16 MB); Username for 'http://github.com': vdauwera; Password for 'http://vdauwera@github.com': ; Error accessing media: src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam (6b1304800e60c0ac0358df137bdad48b7857a36465b04fef3fbbb09380f04746). Errors logged to /Users/vdauwera/codespace/hellbender/.git/lfs/objects/logs/20151005T220016.510795175.log.; Use `git lfs logs last` to view the log.; Downloading src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam.bai (11.25 KB); Username for 'http://github.com': ; ```. > Looks like I'm failing to download large test files. Do I need to be on VPN for this to work? Or is it expected and I should ignore it?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/952
https://github.com/broadinstitute/gatk/issues/952:1026,Availability,Down,Downloading,1026,"@vdauwera reported this here #950 :. > Can't seem to do git clone https://github.com/broadinstitute/hellbender/. ```; wmd16-c9e:codespace vdauwera$ git clone http://github.com/broadinstitute/hellbender/; Cloning into 'hellbender'...; remote: Counting objects: 22221, done.; remote: Compressing objects: 100% (142/142), done.; remote: Total 22221 (delta 47), reused 4 (delta 4), pack-reused 22046; Receiving objects: 100% (22221/22221), 36.63 MiB | 3.58 MiB/s, done.; Resolving deltas: 100% (9903/9903), done.; Checking connectivity... done.; Downloading src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam (76.16 MB); Username for 'http://github.com': vdauwera; Password for 'http://vdauwera@github.com': ; Error accessing media: src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam (6b1304800e60c0ac0358df137bdad48b7857a36465b04fef3fbbb09380f04746). Errors logged to /Users/vdauwera/codespace/hellbender/.git/lfs/objects/logs/20151005T220016.510795175.log.; Use `git lfs logs last` to view the log.; Downloading src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam.bai (11.25 KB); Username for 'http://github.com': ; ```. > Looks like I'm failing to download large test files. Do I need to be on VPN for this to work? Or is it expected and I should ignore it?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/952
https://github.com/broadinstitute/gatk/issues/952:1188,Availability,down,download,1188,"@vdauwera reported this here #950 :. > Can't seem to do git clone https://github.com/broadinstitute/hellbender/. ```; wmd16-c9e:codespace vdauwera$ git clone http://github.com/broadinstitute/hellbender/; Cloning into 'hellbender'...; remote: Counting objects: 22221, done.; remote: Compressing objects: 100% (142/142), done.; remote: Total 22221 (delta 47), reused 4 (delta 4), pack-reused 22046; Receiving objects: 100% (22221/22221), 36.63 MiB | 3.58 MiB/s, done.; Resolving deltas: 100% (9903/9903), done.; Checking connectivity... done.; Downloading src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam (76.16 MB); Username for 'http://github.com': vdauwera; Password for 'http://vdauwera@github.com': ; Error accessing media: src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam (6b1304800e60c0ac0358df137bdad48b7857a36465b04fef3fbbb09380f04746). Errors logged to /Users/vdauwera/codespace/hellbender/.git/lfs/objects/logs/20151005T220016.510795175.log.; Use `git lfs logs last` to view the log.; Downloading src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam.bai (11.25 KB); Username for 'http://github.com': ; ```. > Looks like I'm failing to download large test files. Do I need to be on VPN for this to work? Or is it expected and I should ignore it?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/952
https://github.com/broadinstitute/gatk/issues/952:675,Security,Password,Password,675,"@vdauwera reported this here #950 :. > Can't seem to do git clone https://github.com/broadinstitute/hellbender/. ```; wmd16-c9e:codespace vdauwera$ git clone http://github.com/broadinstitute/hellbender/; Cloning into 'hellbender'...; remote: Counting objects: 22221, done.; remote: Compressing objects: 100% (142/142), done.; remote: Total 22221 (delta 47), reused 4 (delta 4), pack-reused 22046; Receiving objects: 100% (22221/22221), 36.63 MiB | 3.58 MiB/s, done.; Resolving deltas: 100% (9903/9903), done.; Checking connectivity... done.; Downloading src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam (76.16 MB); Username for 'http://github.com': vdauwera; Password for 'http://vdauwera@github.com': ; Error accessing media: src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam (6b1304800e60c0ac0358df137bdad48b7857a36465b04fef3fbbb09380f04746). Errors logged to /Users/vdauwera/codespace/hellbender/.git/lfs/objects/logs/20151005T220016.510795175.log.; Use `git lfs logs last` to view the log.; Downloading src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam.bai (11.25 KB); Username for 'http://github.com': ; ```. > Looks like I'm failing to download large test files. Do I need to be on VPN for this to work? Or is it expected and I should ignore it?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/952
https://github.com/broadinstitute/gatk/issues/952:726,Security,access,accessing,726,"@vdauwera reported this here #950 :. > Can't seem to do git clone https://github.com/broadinstitute/hellbender/. ```; wmd16-c9e:codespace vdauwera$ git clone http://github.com/broadinstitute/hellbender/; Cloning into 'hellbender'...; remote: Counting objects: 22221, done.; remote: Compressing objects: 100% (142/142), done.; remote: Total 22221 (delta 47), reused 4 (delta 4), pack-reused 22046; Receiving objects: 100% (22221/22221), 36.63 MiB | 3.58 MiB/s, done.; Resolving deltas: 100% (9903/9903), done.; Checking connectivity... done.; Downloading src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam (76.16 MB); Username for 'http://github.com': vdauwera; Password for 'http://vdauwera@github.com': ; Error accessing media: src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam (6b1304800e60c0ac0358df137bdad48b7857a36465b04fef3fbbb09380f04746). Errors logged to /Users/vdauwera/codespace/hellbender/.git/lfs/objects/logs/20151005T220016.510795175.log.; Use `git lfs logs last` to view the log.; Downloading src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam.bai (11.25 KB); Username for 'http://github.com': ; ```. > Looks like I'm failing to download large test files. Do I need to be on VPN for this to work? Or is it expected and I should ignore it?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/952
https://github.com/broadinstitute/gatk/issues/952:558,Testability,test,test,558,"@vdauwera reported this here #950 :. > Can't seem to do git clone https://github.com/broadinstitute/hellbender/. ```; wmd16-c9e:codespace vdauwera$ git clone http://github.com/broadinstitute/hellbender/; Cloning into 'hellbender'...; remote: Counting objects: 22221, done.; remote: Compressing objects: 100% (142/142), done.; remote: Total 22221 (delta 47), reused 4 (delta 4), pack-reused 22046; Receiving objects: 100% (22221/22221), 36.63 MiB | 3.58 MiB/s, done.; Resolving deltas: 100% (9903/9903), done.; Checking connectivity... done.; Downloading src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam (76.16 MB); Username for 'http://github.com': vdauwera; Password for 'http://vdauwera@github.com': ; Error accessing media: src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam (6b1304800e60c0ac0358df137bdad48b7857a36465b04fef3fbbb09380f04746). Errors logged to /Users/vdauwera/codespace/hellbender/.git/lfs/objects/logs/20151005T220016.510795175.log.; Use `git lfs logs last` to view the log.; Downloading src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam.bai (11.25 KB); Username for 'http://github.com': ; ```. > Looks like I'm failing to download large test files. Do I need to be on VPN for this to work? Or is it expected and I should ignore it?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/952
https://github.com/broadinstitute/gatk/issues/952:747,Testability,test,test,747,"@vdauwera reported this here #950 :. > Can't seem to do git clone https://github.com/broadinstitute/hellbender/. ```; wmd16-c9e:codespace vdauwera$ git clone http://github.com/broadinstitute/hellbender/; Cloning into 'hellbender'...; remote: Counting objects: 22221, done.; remote: Compressing objects: 100% (142/142), done.; remote: Total 22221 (delta 47), reused 4 (delta 4), pack-reused 22046; Receiving objects: 100% (22221/22221), 36.63 MiB | 3.58 MiB/s, done.; Resolving deltas: 100% (9903/9903), done.; Checking connectivity... done.; Downloading src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam (76.16 MB); Username for 'http://github.com': vdauwera; Password for 'http://vdauwera@github.com': ; Error accessing media: src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam (6b1304800e60c0ac0358df137bdad48b7857a36465b04fef3fbbb09380f04746). Errors logged to /Users/vdauwera/codespace/hellbender/.git/lfs/objects/logs/20151005T220016.510795175.log.; Use `git lfs logs last` to view the log.; Downloading src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam.bai (11.25 KB); Username for 'http://github.com': ; ```. > Looks like I'm failing to download large test files. Do I need to be on VPN for this to work? Or is it expected and I should ignore it?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/952
https://github.com/broadinstitute/gatk/issues/952:883,Testability,log,logged,883,"@vdauwera reported this here #950 :. > Can't seem to do git clone https://github.com/broadinstitute/hellbender/. ```; wmd16-c9e:codespace vdauwera$ git clone http://github.com/broadinstitute/hellbender/; Cloning into 'hellbender'...; remote: Counting objects: 22221, done.; remote: Compressing objects: 100% (142/142), done.; remote: Total 22221 (delta 47), reused 4 (delta 4), pack-reused 22046; Receiving objects: 100% (22221/22221), 36.63 MiB | 3.58 MiB/s, done.; Resolving deltas: 100% (9903/9903), done.; Checking connectivity... done.; Downloading src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam (76.16 MB); Username for 'http://github.com': vdauwera; Password for 'http://vdauwera@github.com': ; Error accessing media: src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam (6b1304800e60c0ac0358df137bdad48b7857a36465b04fef3fbbb09380f04746). Errors logged to /Users/vdauwera/codespace/hellbender/.git/lfs/objects/logs/20151005T220016.510795175.log.; Use `git lfs logs last` to view the log.; Downloading src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam.bai (11.25 KB); Username for 'http://github.com': ; ```. > Looks like I'm failing to download large test files. Do I need to be on VPN for this to work? Or is it expected and I should ignore it?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/952
https://github.com/broadinstitute/gatk/issues/952:947,Testability,log,logs,947,"@vdauwera reported this here #950 :. > Can't seem to do git clone https://github.com/broadinstitute/hellbender/. ```; wmd16-c9e:codespace vdauwera$ git clone http://github.com/broadinstitute/hellbender/; Cloning into 'hellbender'...; remote: Counting objects: 22221, done.; remote: Compressing objects: 100% (142/142), done.; remote: Total 22221 (delta 47), reused 4 (delta 4), pack-reused 22046; Receiving objects: 100% (22221/22221), 36.63 MiB | 3.58 MiB/s, done.; Resolving deltas: 100% (9903/9903), done.; Checking connectivity... done.; Downloading src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam (76.16 MB); Username for 'http://github.com': vdauwera; Password for 'http://vdauwera@github.com': ; Error accessing media: src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam (6b1304800e60c0ac0358df137bdad48b7857a36465b04fef3fbbb09380f04746). Errors logged to /Users/vdauwera/codespace/hellbender/.git/lfs/objects/logs/20151005T220016.510795175.log.; Use `git lfs logs last` to view the log.; Downloading src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam.bai (11.25 KB); Username for 'http://github.com': ; ```. > Looks like I'm failing to download large test files. Do I need to be on VPN for this to work? Or is it expected and I should ignore it?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/952
https://github.com/broadinstitute/gatk/issues/952:978,Testability,log,log,978,"@vdauwera reported this here #950 :. > Can't seem to do git clone https://github.com/broadinstitute/hellbender/. ```; wmd16-c9e:codespace vdauwera$ git clone http://github.com/broadinstitute/hellbender/; Cloning into 'hellbender'...; remote: Counting objects: 22221, done.; remote: Compressing objects: 100% (142/142), done.; remote: Total 22221 (delta 47), reused 4 (delta 4), pack-reused 22046; Receiving objects: 100% (22221/22221), 36.63 MiB | 3.58 MiB/s, done.; Resolving deltas: 100% (9903/9903), done.; Checking connectivity... done.; Downloading src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam (76.16 MB); Username for 'http://github.com': vdauwera; Password for 'http://vdauwera@github.com': ; Error accessing media: src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam (6b1304800e60c0ac0358df137bdad48b7857a36465b04fef3fbbb09380f04746). Errors logged to /Users/vdauwera/codespace/hellbender/.git/lfs/objects/logs/20151005T220016.510795175.log.; Use `git lfs logs last` to view the log.; Downloading src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam.bai (11.25 KB); Username for 'http://github.com': ; ```. > Looks like I'm failing to download large test files. Do I need to be on VPN for this to work? Or is it expected and I should ignore it?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/952
https://github.com/broadinstitute/gatk/issues/952:997,Testability,log,logs,997,"@vdauwera reported this here #950 :. > Can't seem to do git clone https://github.com/broadinstitute/hellbender/. ```; wmd16-c9e:codespace vdauwera$ git clone http://github.com/broadinstitute/hellbender/; Cloning into 'hellbender'...; remote: Counting objects: 22221, done.; remote: Compressing objects: 100% (142/142), done.; remote: Total 22221 (delta 47), reused 4 (delta 4), pack-reused 22046; Receiving objects: 100% (22221/22221), 36.63 MiB | 3.58 MiB/s, done.; Resolving deltas: 100% (9903/9903), done.; Checking connectivity... done.; Downloading src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam (76.16 MB); Username for 'http://github.com': vdauwera; Password for 'http://vdauwera@github.com': ; Error accessing media: src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam (6b1304800e60c0ac0358df137bdad48b7857a36465b04fef3fbbb09380f04746). Errors logged to /Users/vdauwera/codespace/hellbender/.git/lfs/objects/logs/20151005T220016.510795175.log.; Use `git lfs logs last` to view the log.; Downloading src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam.bai (11.25 KB); Username for 'http://github.com': ; ```. > Looks like I'm failing to download large test files. Do I need to be on VPN for this to work? Or is it expected and I should ignore it?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/952
https://github.com/broadinstitute/gatk/issues/952:1020,Testability,log,log,1020,"@vdauwera reported this here #950 :. > Can't seem to do git clone https://github.com/broadinstitute/hellbender/. ```; wmd16-c9e:codespace vdauwera$ git clone http://github.com/broadinstitute/hellbender/; Cloning into 'hellbender'...; remote: Counting objects: 22221, done.; remote: Compressing objects: 100% (142/142), done.; remote: Total 22221 (delta 47), reused 4 (delta 4), pack-reused 22046; Receiving objects: 100% (22221/22221), 36.63 MiB | 3.58 MiB/s, done.; Resolving deltas: 100% (9903/9903), done.; Checking connectivity... done.; Downloading src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam (76.16 MB); Username for 'http://github.com': vdauwera; Password for 'http://vdauwera@github.com': ; Error accessing media: src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam (6b1304800e60c0ac0358df137bdad48b7857a36465b04fef3fbbb09380f04746). Errors logged to /Users/vdauwera/codespace/hellbender/.git/lfs/objects/logs/20151005T220016.510795175.log.; Use `git lfs logs last` to view the log.; Downloading src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam.bai (11.25 KB); Username for 'http://github.com': ; ```. > Looks like I'm failing to download large test files. Do I need to be on VPN for this to work? Or is it expected and I should ignore it?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/952
https://github.com/broadinstitute/gatk/issues/952:1042,Testability,test,test,1042,"@vdauwera reported this here #950 :. > Can't seem to do git clone https://github.com/broadinstitute/hellbender/. ```; wmd16-c9e:codespace vdauwera$ git clone http://github.com/broadinstitute/hellbender/; Cloning into 'hellbender'...; remote: Counting objects: 22221, done.; remote: Compressing objects: 100% (142/142), done.; remote: Total 22221 (delta 47), reused 4 (delta 4), pack-reused 22046; Receiving objects: 100% (22221/22221), 36.63 MiB | 3.58 MiB/s, done.; Resolving deltas: 100% (9903/9903), done.; Checking connectivity... done.; Downloading src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam (76.16 MB); Username for 'http://github.com': vdauwera; Password for 'http://vdauwera@github.com': ; Error accessing media: src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam (6b1304800e60c0ac0358df137bdad48b7857a36465b04fef3fbbb09380f04746). Errors logged to /Users/vdauwera/codespace/hellbender/.git/lfs/objects/logs/20151005T220016.510795175.log.; Use `git lfs logs last` to view the log.; Downloading src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam.bai (11.25 KB); Username for 'http://github.com': ; ```. > Looks like I'm failing to download large test files. Do I need to be on VPN for this to work? Or is it expected and I should ignore it?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/952
https://github.com/broadinstitute/gatk/issues/952:1203,Testability,test,test,1203,"@vdauwera reported this here #950 :. > Can't seem to do git clone https://github.com/broadinstitute/hellbender/. ```; wmd16-c9e:codespace vdauwera$ git clone http://github.com/broadinstitute/hellbender/; Cloning into 'hellbender'...; remote: Counting objects: 22221, done.; remote: Compressing objects: 100% (142/142), done.; remote: Total 22221 (delta 47), reused 4 (delta 4), pack-reused 22046; Receiving objects: 100% (22221/22221), 36.63 MiB | 3.58 MiB/s, done.; Resolving deltas: 100% (9903/9903), done.; Checking connectivity... done.; Downloading src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam (76.16 MB); Username for 'http://github.com': vdauwera; Password for 'http://vdauwera@github.com': ; Error accessing media: src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam (6b1304800e60c0ac0358df137bdad48b7857a36465b04fef3fbbb09380f04746). Errors logged to /Users/vdauwera/codespace/hellbender/.git/lfs/objects/logs/20151005T220016.510795175.log.; Use `git lfs logs last` to view the log.; Downloading src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam.bai (11.25 KB); Username for 'http://github.com': ; ```. > Looks like I'm failing to download large test files. Do I need to be on VPN for this to work? Or is it expected and I should ignore it?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/952
https://github.com/broadinstitute/gatk/issues/954:84,Integrability,depend,dependencies,84,"This entails moving all dataflow code to hellbender-dataflow and mininimizing other dependencies. Ideally, up to the point of dropping from the buildscript.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/954
https://github.com/broadinstitute/gatk/pull/955:440,Modifiability,extend,extend,440,"-Created a new base class for Spark tools, GATKSparkTool, that centrally manages; and validates standard tool inputs (reads, reference, and intervals). This allows; us to enforce consistency across tools, delete duplicated boilerplate code from tools; to load inputs, and perform standard kinds of validation (eg., sequence dictionary; validation) in one place. -Tools that don't fit into the pattern established by GATKSparkTool can still extend; SparkCommandLineProgram directly. -This is just a first step -- there is still much work to be done to unify our data source; classes and transparently handle inputs from different sources (GCS, hdfs, files), but; having inputs centrally managed should make the remaining tasks much easier.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/955
https://github.com/broadinstitute/gatk/pull/955:255,Performance,load,load,255,"-Created a new base class for Spark tools, GATKSparkTool, that centrally manages; and validates standard tool inputs (reads, reference, and intervals). This allows; us to enforce consistency across tools, delete duplicated boilerplate code from tools; to load inputs, and perform standard kinds of validation (eg., sequence dictionary; validation) in one place. -Tools that don't fit into the pattern established by GATKSparkTool can still extend; SparkCommandLineProgram directly. -This is just a first step -- there is still much work to be done to unify our data source; classes and transparently handle inputs from different sources (GCS, hdfs, files), but; having inputs centrally managed should make the remaining tasks much easier.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/955
https://github.com/broadinstitute/gatk/pull/955:272,Performance,perform,perform,272,"-Created a new base class for Spark tools, GATKSparkTool, that centrally manages; and validates standard tool inputs (reads, reference, and intervals). This allows; us to enforce consistency across tools, delete duplicated boilerplate code from tools; to load inputs, and perform standard kinds of validation (eg., sequence dictionary; validation) in one place. -Tools that don't fit into the pattern established by GATKSparkTool can still extend; SparkCommandLineProgram directly. -This is just a first step -- there is still much work to be done to unify our data source; classes and transparently handle inputs from different sources (GCS, hdfs, files), but; having inputs centrally managed should make the remaining tasks much easier.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/955
https://github.com/broadinstitute/gatk/pull/955:86,Security,validat,validates,86,"-Created a new base class for Spark tools, GATKSparkTool, that centrally manages; and validates standard tool inputs (reads, reference, and intervals). This allows; us to enforce consistency across tools, delete duplicated boilerplate code from tools; to load inputs, and perform standard kinds of validation (eg., sequence dictionary; validation) in one place. -Tools that don't fit into the pattern established by GATKSparkTool can still extend; SparkCommandLineProgram directly. -This is just a first step -- there is still much work to be done to unify our data source; classes and transparently handle inputs from different sources (GCS, hdfs, files), but; having inputs centrally managed should make the remaining tasks much easier.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/955
https://github.com/broadinstitute/gatk/pull/955:298,Security,validat,validation,298,"-Created a new base class for Spark tools, GATKSparkTool, that centrally manages; and validates standard tool inputs (reads, reference, and intervals). This allows; us to enforce consistency across tools, delete duplicated boilerplate code from tools; to load inputs, and perform standard kinds of validation (eg., sequence dictionary; validation) in one place. -Tools that don't fit into the pattern established by GATKSparkTool can still extend; SparkCommandLineProgram directly. -This is just a first step -- there is still much work to be done to unify our data source; classes and transparently handle inputs from different sources (GCS, hdfs, files), but; having inputs centrally managed should make the remaining tasks much easier.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/955
https://github.com/broadinstitute/gatk/pull/955:336,Security,validat,validation,336,"-Created a new base class for Spark tools, GATKSparkTool, that centrally manages; and validates standard tool inputs (reads, reference, and intervals). This allows; us to enforce consistency across tools, delete duplicated boilerplate code from tools; to load inputs, and perform standard kinds of validation (eg., sequence dictionary; validation) in one place. -Tools that don't fit into the pattern established by GATKSparkTool can still extend; SparkCommandLineProgram directly. -This is just a first step -- there is still much work to be done to unify our data source; classes and transparently handle inputs from different sources (GCS, hdfs, files), but; having inputs centrally managed should make the remaining tasks much easier.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/955
https://github.com/broadinstitute/gatk/issues/959:58,Modifiability,refactor,refactor,58,"Our data source classes are an inconsistent mess -- let's refactor so that we have ONE centralized reads source used by all tools (walkers and spark), one reference source, etc. This will have the side benefit of making it easier for new features like CRAM support to propagate transparently to all tools.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/959
https://github.com/broadinstitute/gatk/issues/960:119,Deployability,pipeline,pipelines,119,"We need a mechanism to guarantee that all spark tools are written in a way that allows them to be composed into larger pipelines. Currently, we rely on the tool author to extract the core of their tool into a separate method or class that can be called externally, but there is nothing forcing tool authors to do this.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/960
https://github.com/broadinstitute/gatk/issues/961:178,Testability,log,log,178,"Spark tools should be just as easy to run as walkers. Users shouldn't have to write a shell script to invoke spark-submit or gcloud, build a special jar and upload it somewhere, log in to a particular machine, etc. Ideally we want something as simple as: `./hellbender ToolName [toolOptions] [sparkOptions]`, and the engine should figure out whether to invoke spark-submit or gcloud and invoke it on the user's behalf. Options include:; -Invoke spark-submit/gcloud programmatically within hellbender (possibly using a simple `Runtime.getRuntime().exec()` approach). -Write a shell script that can run any hellbender command and auto-delegate to spark-submit / gcloud as necessary.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/961
https://github.com/broadinstitute/gatk/issues/961:244,Usability,simpl,simple,244,"Spark tools should be just as easy to run as walkers. Users shouldn't have to write a shell script to invoke spark-submit or gcloud, build a special jar and upload it somewhere, log in to a particular machine, etc. Ideally we want something as simple as: `./hellbender ToolName [toolOptions] [sparkOptions]`, and the engine should figure out whether to invoke spark-submit or gcloud and invoke it on the user's behalf. Options include:; -Invoke spark-submit/gcloud programmatically within hellbender (possibly using a simple `Runtime.getRuntime().exec()` approach). -Write a shell script that can run any hellbender command and auto-delegate to spark-submit / gcloud as necessary.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/961
https://github.com/broadinstitute/gatk/issues/961:518,Usability,simpl,simple,518,"Spark tools should be just as easy to run as walkers. Users shouldn't have to write a shell script to invoke spark-submit or gcloud, build a special jar and upload it somewhere, log in to a particular machine, etc. Ideally we want something as simple as: `./hellbender ToolName [toolOptions] [sparkOptions]`, and the engine should figure out whether to invoke spark-submit or gcloud and invoke it on the user's behalf. Options include:; -Invoke spark-submit/gcloud programmatically within hellbender (possibly using a simple `Runtime.getRuntime().exec()` approach). -Write a shell script that can run any hellbender command and auto-delegate to spark-submit / gcloud as necessary.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/961
https://github.com/broadinstitute/gatk/issues/962:175,Energy Efficiency,monitor,monitoring,175,"Currently when running a spark tool we spam the console with lots of useless garbage. Let's suppress this at the default logging level, and instead output a link to the spark monitoring console and/or a progress meter.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/962
https://github.com/broadinstitute/gatk/issues/962:212,Energy Efficiency,meter,meter,212,"Currently when running a spark tool we spam the console with lots of useless garbage. Let's suppress this at the default logging level, and instead output a link to the spark monitoring console and/or a progress meter.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/962
https://github.com/broadinstitute/gatk/issues/962:121,Testability,log,logging,121,"Currently when running a spark tool we spam the console with lots of useless garbage. Let's suppress this at the default logging level, and instead output a link to the spark monitoring console and/or a progress meter.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/962
https://github.com/broadinstitute/gatk/issues/974:17,Usability,progress bar,progress bar,17,We should have a progress bar for local walkers. This can be based on GATK's progress bar,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/974
https://github.com/broadinstitute/gatk/issues/974:77,Usability,progress bar,progress bar,77,We should have a progress bar for local walkers. This can be based on GATK's progress bar,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/974
https://github.com/broadinstitute/gatk/pull/982:18,Integrability,depend,dependencies,18,"Remove all static dependencies of code outside the dataflow packages; on code inside the dataflow packages. With these changes, the codebase compiles when you delete the; engine.dataflow, tools.dataflow, and utils.dataflow packages from; both main and test.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/982
https://github.com/broadinstitute/gatk/pull/982:252,Testability,test,test,252,"Remove all static dependencies of code outside the dataflow packages; on code inside the dataflow packages. With these changes, the codebase compiles when you delete the; engine.dataflow, tools.dataflow, and utils.dataflow packages from; both main and test.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/982
https://github.com/broadinstitute/gatk/pull/985:101,Testability,test,test,101,fixes #235 . Note: we can't read index files created by this tool for block gzippped vcfs. I added a test for it but disabled it,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/985
https://github.com/broadinstitute/gatk/issues/986:51,Performance,optimiz,optimizations,51,"@jean-philippe-martin will be porting his dataflow optimizations to spark as part of https://github.com/broadinstitute/gatk/issues/970, and then going on leave for several weeks. It would be good if @tomwhite and @laserson could advise him over the next week or so as he does this, and then take over the process of optimization after he leaves. I've created this ticket as a place for @jean-philippe-martin, @tomwhite, and @laserson to sync up and spawn additional tickets as necessary.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/986
https://github.com/broadinstitute/gatk/issues/986:316,Performance,optimiz,optimization,316,"@jean-philippe-martin will be porting his dataflow optimizations to spark as part of https://github.com/broadinstitute/gatk/issues/970, and then going on leave for several weeks. It would be good if @tomwhite and @laserson could advise him over the next week or so as he does this, and then take over the process of optimization after he leaves. I've created this ticket as a place for @jean-philippe-martin, @tomwhite, and @laserson to sync up and spawn additional tickets as necessary.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/986
https://github.com/broadinstitute/gatk/pull/987:98,Deployability,Pipeline,PipelineOptions,98,"This code (building off of Louis' fixes) adds the following:; - AuthHolder, a replacement for the PipelineOptions. It stores the authentication info we need for GCS and supports both API_KEY and client-secrets.json. I adapted a few classes to accept an AuthHolder.; - BaseRecalibratorOptimizedSpark, a port of the ""shard"" approach I first did on the Dataflow side. Note that currently this code only performs reasonably for small inputs if you specify -L on the command line (for large inputs it doesn't matter).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/987
https://github.com/broadinstitute/gatk/pull/987:218,Energy Efficiency,adapt,adapted,218,"This code (building off of Louis' fixes) adds the following:; - AuthHolder, a replacement for the PipelineOptions. It stores the authentication info we need for GCS and supports both API_KEY and client-secrets.json. I adapted a few classes to accept an AuthHolder.; - BaseRecalibratorOptimizedSpark, a port of the ""shard"" approach I first did on the Dataflow side. Note that currently this code only performs reasonably for small inputs if you specify -L on the command line (for large inputs it doesn't matter).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/987
https://github.com/broadinstitute/gatk/pull/987:218,Modifiability,adapt,adapted,218,"This code (building off of Louis' fixes) adds the following:; - AuthHolder, a replacement for the PipelineOptions. It stores the authentication info we need for GCS and supports both API_KEY and client-secrets.json. I adapted a few classes to accept an AuthHolder.; - BaseRecalibratorOptimizedSpark, a port of the ""shard"" approach I first did on the Dataflow side. Note that currently this code only performs reasonably for small inputs if you specify -L on the command line (for large inputs it doesn't matter).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/987
https://github.com/broadinstitute/gatk/pull/987:400,Performance,perform,performs,400,"This code (building off of Louis' fixes) adds the following:; - AuthHolder, a replacement for the PipelineOptions. It stores the authentication info we need for GCS and supports both API_KEY and client-secrets.json. I adapted a few classes to accept an AuthHolder.; - BaseRecalibratorOptimizedSpark, a port of the ""shard"" approach I first did on the Dataflow side. Note that currently this code only performs reasonably for small inputs if you specify -L on the command line (for large inputs it doesn't matter).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/987
https://github.com/broadinstitute/gatk/pull/987:129,Security,authenticat,authentication,129,"This code (building off of Louis' fixes) adds the following:; - AuthHolder, a replacement for the PipelineOptions. It stores the authentication info we need for GCS and supports both API_KEY and client-secrets.json. I adapted a few classes to accept an AuthHolder.; - BaseRecalibratorOptimizedSpark, a port of the ""shard"" approach I first did on the Dataflow side. Note that currently this code only performs reasonably for small inputs if you specify -L on the command line (for large inputs it doesn't matter).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/987
https://github.com/broadinstitute/gatk/pull/988:6,Testability,test,tests,6,These tests were enabled by changes in https://github.com/samtools/htsjdk/pull/343. More cram tests will be added for both #777 and #966.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/988
https://github.com/broadinstitute/gatk/pull/988:94,Testability,test,tests,94,These tests were enabled by changes in https://github.com/samtools/htsjdk/pull/343. More cram tests will be added for both #777 and #966.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/988
https://github.com/broadinstitute/gatk/pull/992:76,Availability,avail,available,76,moving some test utilities from src/test to src/main/ in order to make them available to hellbender-dataflow. removed a method that was only used by dataflow,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/992
https://github.com/broadinstitute/gatk/pull/992:12,Testability,test,test,12,moving some test utilities from src/test to src/main/ in order to make them available to hellbender-dataflow. removed a method that was only used by dataflow,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/992
https://github.com/broadinstitute/gatk/pull/992:36,Testability,test,test,36,moving some test utilities from src/test to src/main/ in order to make them available to hellbender-dataflow. removed a method that was only used by dataflow,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/992
https://github.com/broadinstitute/gatk/issues/995:294,Modifiability,flexible,flexible,294,"As mentioned in the discussion for https://github.com/broadinstitute/gatk/pull/987, we want to compare the manual sharding approach taken to optimizing BQSR in that branch against an alternative approach of broadcasting the reference and variants. The latter approach would be simpler and more flexible/idiomatic (allow spark to handle sharding and data localization rather than doing it manually), but might be slower. Let's find out what the performance is like for both approaches before making a decision.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/995
https://github.com/broadinstitute/gatk/issues/995:141,Performance,optimiz,optimizing,141,"As mentioned in the discussion for https://github.com/broadinstitute/gatk/pull/987, we want to compare the manual sharding approach taken to optimizing BQSR in that branch against an alternative approach of broadcasting the reference and variants. The latter approach would be simpler and more flexible/idiomatic (allow spark to handle sharding and data localization rather than doing it manually), but might be slower. Let's find out what the performance is like for both approaches before making a decision.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/995
https://github.com/broadinstitute/gatk/issues/995:444,Performance,perform,performance,444,"As mentioned in the discussion for https://github.com/broadinstitute/gatk/pull/987, we want to compare the manual sharding approach taken to optimizing BQSR in that branch against an alternative approach of broadcasting the reference and variants. The latter approach would be simpler and more flexible/idiomatic (allow spark to handle sharding and data localization rather than doing it manually), but might be slower. Let's find out what the performance is like for both approaches before making a decision.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/995
https://github.com/broadinstitute/gatk/issues/995:277,Usability,simpl,simpler,277,"As mentioned in the discussion for https://github.com/broadinstitute/gatk/pull/987, we want to compare the manual sharding approach taken to optimizing BQSR in that branch against an alternative approach of broadcasting the reference and variants. The latter approach would be simpler and more flexible/idiomatic (allow spark to handle sharding and data localization rather than doing it manually), but might be slower. Let's find out what the performance is like for both approaches before making a decision.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/995
https://github.com/broadinstitute/gatk/pull/996:46,Deployability,Integrat,Integration,46,Created new branch (old one was problematic). Integration test was successful. Let me know if additional parameters should be tested.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/996
https://github.com/broadinstitute/gatk/pull/996:46,Integrability,Integrat,Integration,46,Created new branch (old one was problematic). Integration test was successful. Let me know if additional parameters should be tested.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/996
https://github.com/broadinstitute/gatk/pull/996:58,Testability,test,test,58,Created new branch (old one was problematic). Integration test was successful. Let me know if additional parameters should be tested.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/996
https://github.com/broadinstitute/gatk/pull/996:126,Testability,test,tested,126,Created new branch (old one was problematic). Integration test was successful. Let me know if additional parameters should be tested.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/996
https://github.com/broadinstitute/gatk/issues/1002:63,Modifiability,inherit,inherits,63,"We use the GATKGCSOptions class to hold GCP authentication. It inherits from the Dataflow hierarchy and works well there, but since it doesn't implement Serializable it's cumbersome to work with in Spark. We've created AuthHolder as a replacement. It can do all the things GATKGCSOptions can do, and more (well, except for holding Dataflow debug options but we don't need that anymore). Once #978 is merged in, we need to migrate the code from GATKGCSOptions to AuthHolder. One benefit is that this will allow the Spark code to support client-secrets.json (for access to private GCS files, unlike the API key which only grants access to world-readable GCS files).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1002
https://github.com/broadinstitute/gatk/issues/1002:44,Security,authenticat,authentication,44,"We use the GATKGCSOptions class to hold GCP authentication. It inherits from the Dataflow hierarchy and works well there, but since it doesn't implement Serializable it's cumbersome to work with in Spark. We've created AuthHolder as a replacement. It can do all the things GATKGCSOptions can do, and more (well, except for holding Dataflow debug options but we don't need that anymore). Once #978 is merged in, we need to migrate the code from GATKGCSOptions to AuthHolder. One benefit is that this will allow the Spark code to support client-secrets.json (for access to private GCS files, unlike the API key which only grants access to world-readable GCS files).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1002
https://github.com/broadinstitute/gatk/issues/1002:561,Security,access,access,561,"We use the GATKGCSOptions class to hold GCP authentication. It inherits from the Dataflow hierarchy and works well there, but since it doesn't implement Serializable it's cumbersome to work with in Spark. We've created AuthHolder as a replacement. It can do all the things GATKGCSOptions can do, and more (well, except for holding Dataflow debug options but we don't need that anymore). Once #978 is merged in, we need to migrate the code from GATKGCSOptions to AuthHolder. One benefit is that this will allow the Spark code to support client-secrets.json (for access to private GCS files, unlike the API key which only grants access to world-readable GCS files).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1002
https://github.com/broadinstitute/gatk/issues/1002:627,Security,access,access,627,"We use the GATKGCSOptions class to hold GCP authentication. It inherits from the Dataflow hierarchy and works well there, but since it doesn't implement Serializable it's cumbersome to work with in Spark. We've created AuthHolder as a replacement. It can do all the things GATKGCSOptions can do, and more (well, except for holding Dataflow debug options but we don't need that anymore). Once #978 is merged in, we need to migrate the code from GATKGCSOptions to AuthHolder. One benefit is that this will allow the Spark code to support client-secrets.json (for access to private GCS files, unlike the API key which only grants access to world-readable GCS files).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1002
https://github.com/broadinstitute/gatk/issues/1005:71,Performance,load,loaded,71,"MarkDuplicatesSpark runs successfully, but the (sharded) BAM cannot be loaded using ReadsSparkSource (with your fix to getHeader). I don't think this is a problem with HadoopBam because I'm able to run the same input through SortBamSpark and the output can be read. The input is from JP's bucket; `gs://jpmartin/hellbender-test-inputs/CEUTrio.HiSeq.WGS.b37.ch1.1m-65m.NA12878.bam`; but copied to hdfs. I ran. ```; gcloud beta dataproc jobs submit spark --cluster high-mem-32-4 --properties spark.executor.memory=19g,spark.executor.instances=32,spark.executor.cores=3 --class org.broadinstitute.hellbender.Main --jar build/libs/gatk-all-4.pre-alpha-7-*-SNAPSHOT-spark.jar MarkDuplicatesSpark -I hdfs:///user/davidada/CEUTrio.HiSeq.WGS.b37.ch1.1m-65m.NA12878.bam -O hdfs:///user/davidada/dummy-duped-CEUTrio.HiSeq.WGS.b37.ch1.1m-65m.NA12878.bam --sparkMaster yarn-client. gcloud beta dataproc jobs submit spark --cluster high-mem-32-4 --properties spark.executor.memory=19g,spark.executor.instances=32,spark.executor.cores=3 --class org.broadinstitute.hellbender.Main --jar build/libs/gatk-all-4.pre-alpha-7-*-SNAPSHOT-spark.jar SortBamSpark -I hdfs:///user/davidada/dummy-duped-CEUTrio.HiSeq.WGS.b37.ch1.1m-65m.NA12878.bam --sparkMaster yarn-client -O hdfs:///user/davidada/tmp.bam; ```. But I expect that spark-submit should be the same.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1005
https://github.com/broadinstitute/gatk/issues/1005:323,Testability,test,test-inputs,323,"MarkDuplicatesSpark runs successfully, but the (sharded) BAM cannot be loaded using ReadsSparkSource (with your fix to getHeader). I don't think this is a problem with HadoopBam because I'm able to run the same input through SortBamSpark and the output can be read. The input is from JP's bucket; `gs://jpmartin/hellbender-test-inputs/CEUTrio.HiSeq.WGS.b37.ch1.1m-65m.NA12878.bam`; but copied to hdfs. I ran. ```; gcloud beta dataproc jobs submit spark --cluster high-mem-32-4 --properties spark.executor.memory=19g,spark.executor.instances=32,spark.executor.cores=3 --class org.broadinstitute.hellbender.Main --jar build/libs/gatk-all-4.pre-alpha-7-*-SNAPSHOT-spark.jar MarkDuplicatesSpark -I hdfs:///user/davidada/CEUTrio.HiSeq.WGS.b37.ch1.1m-65m.NA12878.bam -O hdfs:///user/davidada/dummy-duped-CEUTrio.HiSeq.WGS.b37.ch1.1m-65m.NA12878.bam --sparkMaster yarn-client. gcloud beta dataproc jobs submit spark --cluster high-mem-32-4 --properties spark.executor.memory=19g,spark.executor.instances=32,spark.executor.cores=3 --class org.broadinstitute.hellbender.Main --jar build/libs/gatk-all-4.pre-alpha-7-*-SNAPSHOT-spark.jar SortBamSpark -I hdfs:///user/davidada/dummy-duped-CEUTrio.HiSeq.WGS.b37.ch1.1m-65m.NA12878.bam --sparkMaster yarn-client -O hdfs:///user/davidada/tmp.bam; ```. But I expect that spark-submit should be the same.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1005
https://github.com/broadinstitute/gatk/issues/1006:259,Deployability,patch,patch,259,"@jean-philippe-martin noticed that the performance of his optimized version of spark BQSR took a nosedive during one of the rebases of his branch. Since he's on leave, one of us will have to profile it in order to find out what the bottleneck is and submit a patch. This is a prerequisite to being able to do the broadcast vs. manual sharding comparison called for in https://github.com/broadinstitute/gatk/issues/995",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1006
https://github.com/broadinstitute/gatk/issues/1006:39,Performance,perform,performance,39,"@jean-philippe-martin noticed that the performance of his optimized version of spark BQSR took a nosedive during one of the rebases of his branch. Since he's on leave, one of us will have to profile it in order to find out what the bottleneck is and submit a patch. This is a prerequisite to being able to do the broadcast vs. manual sharding comparison called for in https://github.com/broadinstitute/gatk/issues/995",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1006
https://github.com/broadinstitute/gatk/issues/1006:58,Performance,optimiz,optimized,58,"@jean-philippe-martin noticed that the performance of his optimized version of spark BQSR took a nosedive during one of the rebases of his branch. Since he's on leave, one of us will have to profile it in order to find out what the bottleneck is and submit a patch. This is a prerequisite to being able to do the broadcast vs. manual sharding comparison called for in https://github.com/broadinstitute/gatk/issues/995",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1006
https://github.com/broadinstitute/gatk/issues/1006:232,Performance,bottleneck,bottleneck,232,"@jean-philippe-martin noticed that the performance of his optimized version of spark BQSR took a nosedive during one of the rebases of his branch. Since he's on leave, one of us will have to profile it in order to find out what the bottleneck is and submit a patch. This is a prerequisite to being able to do the broadcast vs. manual sharding comparison called for in https://github.com/broadinstitute/gatk/issues/995",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1006
https://github.com/broadinstitute/gatk/issues/1007:47,Safety,avoid,avoids,47,"Currently `AddContextDataToReadSparkOptimized` avoids shuffles by doing its own sharding. This introduces a lot of additional complexity, and doesn't leverage the built-in support for sharding in spark. During a discussion today it came up that this code could potentially be made more idiomatic/spark-friendly by using a custom partitioner. Let's investigate whether this is possible and how easy a change it would be to make (and if it's workable and a simple change, put together a quick implementation). Making `AddContextDataToReadSparkOptimized` more spark-idiomatic would allow it to compare more favorably from a stylistic standpoint against the broadcast-based approach when we do https://github.com/broadinstitute/gatk/issues/995",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1007
https://github.com/broadinstitute/gatk/issues/1007:455,Usability,simpl,simple,455,"Currently `AddContextDataToReadSparkOptimized` avoids shuffles by doing its own sharding. This introduces a lot of additional complexity, and doesn't leverage the built-in support for sharding in spark. During a discussion today it came up that this code could potentially be made more idiomatic/spark-friendly by using a custom partitioner. Let's investigate whether this is possible and how easy a change it would be to make (and if it's workable and a simple change, put together a quick implementation). Making `AddContextDataToReadSparkOptimized` more spark-idiomatic would allow it to compare more favorably from a stylistic standpoint against the broadcast-based approach when we do https://github.com/broadinstitute/gatk/issues/995",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1007
https://github.com/broadinstitute/gatk/issues/1008:25,Performance,optimiz,optimizations,25,"There are some un-ported optimizations to ApplyBQSR from the dataflow codebase that could be ported to spark. First, however, we need to settle the ""broadcast vs. custom sharding"" question raised in https://github.com/broadinstitute/gatk/issues/995 before we can evaluate how these ApplyBQSR optimizations apply to the final spark version of BQSR (and if they are still applicable at all).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1008
https://github.com/broadinstitute/gatk/issues/1008:292,Performance,optimiz,optimizations,292,"There are some un-ported optimizations to ApplyBQSR from the dataflow codebase that could be ported to spark. First, however, we need to settle the ""broadcast vs. custom sharding"" question raised in https://github.com/broadinstitute/gatk/issues/995 before we can evaluate how these ApplyBQSR optimizations apply to the final spark version of BQSR (and if they are still applicable at all).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1008
https://github.com/broadinstitute/gatk/pull/1011:64,Availability,error,error,64,"this used to lead to complaints when building on some machines ""error: unmappable character for encoding ASCII"". for @davidadamsphd",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1011
https://github.com/broadinstitute/gatk/pull/1014:5,Testability,test,test,5,"This test was failing to clean up its output directory, because it; was calling File.deleteOnExit() instead of IOUtils.deleteRecursivelyOnExit(). Also changed the tests to write their output to temp locations instead of; the hellbender root. Resolves #977",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1014
https://github.com/broadinstitute/gatk/pull/1014:163,Testability,test,tests,163,"This test was failing to clean up its output directory, because it; was calling File.deleteOnExit() instead of IOUtils.deleteRecursivelyOnExit(). Also changed the tests to write their output to temp locations instead of; the hellbender root. Resolves #977",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1014
https://github.com/broadinstitute/gatk/issues/1017:5,Testability,test,tests,5,"BQSR tests in spark use a bam file and dbSNP file that are non-corresponding (coming from different chromosomes). . ""CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam"";; ""dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf"";. the same tests in non-spark use properly matched bam and vcf file",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1017
https://github.com/broadinstitute/gatk/issues/1017:238,Testability,test,tests,238,"BQSR tests in spark use a bam file and dbSNP file that are non-corresponding (coming from different chromosomes). . ""CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam"";; ""dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf"";. the same tests in non-spark use properly matched bam and vcf file",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1017
https://github.com/broadinstitute/gatk/pull/1021:91,Testability,log,logic,91,Removing the spark dataflow runner build and the cloud_todo_build from travis. Left in the logic for dealing with the cloud_todo in case we have similar problems in the future. I can strip it out of if th,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1021
https://github.com/broadinstitute/gatk/pull/1023:184,Deployability,update,updated,184,this allows us to also remove the cloudera artifactory repo which will fix #610. removing some traces of gradle 2.2.1 from our build script and rerunning gradle wrapper to generate an updated wrapper,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1023
https://github.com/broadinstitute/gatk/pull/1023:161,Integrability,wrap,wrapper,161,this allows us to also remove the cloudera artifactory repo which will fix #610. removing some traces of gradle 2.2.1 from our build script and rerunning gradle wrapper to generate an updated wrapper,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1023
https://github.com/broadinstitute/gatk/pull/1023:192,Integrability,wrap,wrapper,192,this allows us to also remove the cloudera artifactory repo which will fix #610. removing some traces of gradle 2.2.1 from our build script and rerunning gradle wrapper to generate an updated wrapper,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1023
https://github.com/broadinstitute/gatk/issues/1027:134,Safety,avoid,avoid,134,a few metrics that are spark equivalents of SinglePassSamProgram should perhaps have a common superclass with common functionality to avoid code duplication (or the duplication should be achieved in another way). For example the read filter that gets applied is very similar from tool to tool.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1027
https://github.com/broadinstitute/gatk/pull/1028:177,Testability,test,test,177,We were having trouble serializing this lambda when using the BROADCAST strategy; in BQSR for reasons we still don't understand. This fixes the issue for now and; enables us to test out BROADCAST.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1028
https://github.com/broadinstitute/gatk/issues/1029:139,Availability,ERROR,ERROR,139,"If I run BaseRecalibrator on a reference with contigs [20,21] and knownSites only has only sites from 17, then GATK3 blows up:. ```; ##### ERROR MESSAGE: Input files knownSites and reference have incompatible contigs: No overlapping contigs found.; ##### ERROR knownSites contigs = [17]; ##### ERROR reference contigs = [20, 21]; ```. but gatk4 does not (and it should). This is the cause of the bogus tests in #1017 (they should have never been allowed to exist). The commandline for GATK3 is; (the VCF has no sequence dictionary). ```; -T BaseRecalibrator -R src/test/resources/large/human_g1k_v37.20.21.fasta -I src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam --out gatk3.3.recal.txt --knownSites src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1029
https://github.com/broadinstitute/gatk/issues/1029:255,Availability,ERROR,ERROR,255,"If I run BaseRecalibrator on a reference with contigs [20,21] and knownSites only has only sites from 17, then GATK3 blows up:. ```; ##### ERROR MESSAGE: Input files knownSites and reference have incompatible contigs: No overlapping contigs found.; ##### ERROR knownSites contigs = [17]; ##### ERROR reference contigs = [20, 21]; ```. but gatk4 does not (and it should). This is the cause of the bogus tests in #1017 (they should have never been allowed to exist). The commandline for GATK3 is; (the VCF has no sequence dictionary). ```; -T BaseRecalibrator -R src/test/resources/large/human_g1k_v37.20.21.fasta -I src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam --out gatk3.3.recal.txt --knownSites src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1029
https://github.com/broadinstitute/gatk/issues/1029:294,Availability,ERROR,ERROR,294,"If I run BaseRecalibrator on a reference with contigs [20,21] and knownSites only has only sites from 17, then GATK3 blows up:. ```; ##### ERROR MESSAGE: Input files knownSites and reference have incompatible contigs: No overlapping contigs found.; ##### ERROR knownSites contigs = [17]; ##### ERROR reference contigs = [20, 21]; ```. but gatk4 does not (and it should). This is the cause of the bogus tests in #1017 (they should have never been allowed to exist). The commandline for GATK3 is; (the VCF has no sequence dictionary). ```; -T BaseRecalibrator -R src/test/resources/large/human_g1k_v37.20.21.fasta -I src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam --out gatk3.3.recal.txt --knownSites src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1029
https://github.com/broadinstitute/gatk/issues/1029:145,Integrability,MESSAGE,MESSAGE,145,"If I run BaseRecalibrator on a reference with contigs [20,21] and knownSites only has only sites from 17, then GATK3 blows up:. ```; ##### ERROR MESSAGE: Input files knownSites and reference have incompatible contigs: No overlapping contigs found.; ##### ERROR knownSites contigs = [17]; ##### ERROR reference contigs = [20, 21]; ```. but gatk4 does not (and it should). This is the cause of the bogus tests in #1017 (they should have never been allowed to exist). The commandline for GATK3 is; (the VCF has no sequence dictionary). ```; -T BaseRecalibrator -R src/test/resources/large/human_g1k_v37.20.21.fasta -I src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam --out gatk3.3.recal.txt --knownSites src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1029
https://github.com/broadinstitute/gatk/issues/1029:402,Testability,test,tests,402,"If I run BaseRecalibrator on a reference with contigs [20,21] and knownSites only has only sites from 17, then GATK3 blows up:. ```; ##### ERROR MESSAGE: Input files knownSites and reference have incompatible contigs: No overlapping contigs found.; ##### ERROR knownSites contigs = [17]; ##### ERROR reference contigs = [20, 21]; ```. but gatk4 does not (and it should). This is the cause of the bogus tests in #1017 (they should have never been allowed to exist). The commandline for GATK3 is; (the VCF has no sequence dictionary). ```; -T BaseRecalibrator -R src/test/resources/large/human_g1k_v37.20.21.fasta -I src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam --out gatk3.3.recal.txt --knownSites src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1029
https://github.com/broadinstitute/gatk/issues/1029:565,Testability,test,test,565,"If I run BaseRecalibrator on a reference with contigs [20,21] and knownSites only has only sites from 17, then GATK3 blows up:. ```; ##### ERROR MESSAGE: Input files knownSites and reference have incompatible contigs: No overlapping contigs found.; ##### ERROR knownSites contigs = [17]; ##### ERROR reference contigs = [20, 21]; ```. but gatk4 does not (and it should). This is the cause of the bogus tests in #1017 (they should have never been allowed to exist). The commandline for GATK3 is; (the VCF has no sequence dictionary). ```; -T BaseRecalibrator -R src/test/resources/large/human_g1k_v37.20.21.fasta -I src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam --out gatk3.3.recal.txt --knownSites src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1029
https://github.com/broadinstitute/gatk/issues/1029:619,Testability,test,test,619,"If I run BaseRecalibrator on a reference with contigs [20,21] and knownSites only has only sites from 17, then GATK3 blows up:. ```; ##### ERROR MESSAGE: Input files knownSites and reference have incompatible contigs: No overlapping contigs found.; ##### ERROR knownSites contigs = [17]; ##### ERROR reference contigs = [20, 21]; ```. but gatk4 does not (and it should). This is the cause of the bogus tests in #1017 (they should have never been allowed to exist). The commandline for GATK3 is; (the VCF has no sequence dictionary). ```; -T BaseRecalibrator -R src/test/resources/large/human_g1k_v37.20.21.fasta -I src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam --out gatk3.3.recal.txt --knownSites src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1029
https://github.com/broadinstitute/gatk/issues/1029:763,Testability,test,test,763,"If I run BaseRecalibrator on a reference with contigs [20,21] and knownSites only has only sites from 17, then GATK3 blows up:. ```; ##### ERROR MESSAGE: Input files knownSites and reference have incompatible contigs: No overlapping contigs found.; ##### ERROR knownSites contigs = [17]; ##### ERROR reference contigs = [20, 21]; ```. but gatk4 does not (and it should). This is the cause of the bogus tests in #1017 (they should have never been allowed to exist). The commandline for GATK3 is; (the VCF has no sequence dictionary). ```; -T BaseRecalibrator -R src/test/resources/large/human_g1k_v37.20.21.fasta -I src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam --out gatk3.3.recal.txt --knownSites src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1029
https://github.com/broadinstitute/gatk/issues/1030:345,Deployability,install,install,345,this commandline . ```; java -jar ~/bin/GenomeAnalysisTK-3.4-46/GenomeAnalysisTK.jar -T BaseRecalibrator -R src/test/resources/large/human_g1k_v37.20.21.fasta -I CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam --out gatk3.4-46.recal.txt --knownSites src/test/resources/large/dbsnp_138.b37.20.21.vcf; ```. makes a different table than. ```; build/install/gatk/bin/gatk BaseRecalibrator -R src/test/resources/large/human_g1k_v37.20.21.fasta -I CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam --out gatk4.recal.txt --knownSites src/test/resources/large/dbsnp_138.b37.20.21.vcf; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1030
https://github.com/broadinstitute/gatk/issues/1030:112,Testability,test,test,112,this commandline . ```; java -jar ~/bin/GenomeAnalysisTK-3.4-46/GenomeAnalysisTK.jar -T BaseRecalibrator -R src/test/resources/large/human_g1k_v37.20.21.fasta -I CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam --out gatk3.4-46.recal.txt --knownSites src/test/resources/large/dbsnp_138.b37.20.21.vcf; ```. makes a different table than. ```; build/install/gatk/bin/gatk BaseRecalibrator -R src/test/resources/large/human_g1k_v37.20.21.fasta -I CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam --out gatk4.recal.txt --knownSites src/test/resources/large/dbsnp_138.b37.20.21.vcf; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1030
https://github.com/broadinstitute/gatk/issues/1030:253,Testability,test,test,253,this commandline . ```; java -jar ~/bin/GenomeAnalysisTK-3.4-46/GenomeAnalysisTK.jar -T BaseRecalibrator -R src/test/resources/large/human_g1k_v37.20.21.fasta -I CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam --out gatk3.4-46.recal.txt --knownSites src/test/resources/large/dbsnp_138.b37.20.21.vcf; ```. makes a different table than. ```; build/install/gatk/bin/gatk BaseRecalibrator -R src/test/resources/large/human_g1k_v37.20.21.fasta -I CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam --out gatk4.recal.txt --knownSites src/test/resources/large/dbsnp_138.b37.20.21.vcf; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1030
https://github.com/broadinstitute/gatk/issues/1030:391,Testability,test,test,391,this commandline . ```; java -jar ~/bin/GenomeAnalysisTK-3.4-46/GenomeAnalysisTK.jar -T BaseRecalibrator -R src/test/resources/large/human_g1k_v37.20.21.fasta -I CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam --out gatk3.4-46.recal.txt --knownSites src/test/resources/large/dbsnp_138.b37.20.21.vcf; ```. makes a different table than. ```; build/install/gatk/bin/gatk BaseRecalibrator -R src/test/resources/large/human_g1k_v37.20.21.fasta -I CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam --out gatk4.recal.txt --knownSites src/test/resources/large/dbsnp_138.b37.20.21.vcf; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1030
https://github.com/broadinstitute/gatk/issues/1030:527,Testability,test,test,527,this commandline . ```; java -jar ~/bin/GenomeAnalysisTK-3.4-46/GenomeAnalysisTK.jar -T BaseRecalibrator -R src/test/resources/large/human_g1k_v37.20.21.fasta -I CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam --out gatk3.4-46.recal.txt --knownSites src/test/resources/large/dbsnp_138.b37.20.21.vcf; ```. makes a different table than. ```; build/install/gatk/bin/gatk BaseRecalibrator -R src/test/resources/large/human_g1k_v37.20.21.fasta -I CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam --out gatk4.recal.txt --knownSites src/test/resources/large/dbsnp_138.b37.20.21.vcf; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1030
https://github.com/broadinstitute/gatk/issues/1032:153,Performance,optimiz,optimize,153,the goal is to be at least same as gatk3.4 on single thread. This is for the walker version of the tool.; The ticket can be split into a) profile and b) optimize if needed,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1032
https://github.com/broadinstitute/gatk/issues/1033:153,Performance,optimiz,optimize,153,the goal is to be at least same as gatk3.4 on single thread. This is for the walker version of the tool.; The ticket can be split into a) profile and b) optimize if needed,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1033
https://github.com/broadinstitute/gatk/issues/1034:154,Performance,optimiz,optimize,154,the goal is to be at least same as gatk3.4 on single thread. This is for the walker version of the tools.; The ticket can be split into a) profile and b) optimize if needed. The reason to do this is to see if the engine itself adds any overhead. Need to tests on NFS as well as on local drive,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1034
https://github.com/broadinstitute/gatk/issues/1034:254,Testability,test,tests,254,the goal is to be at least same as gatk3.4 on single thread. This is for the walker version of the tools.; The ticket can be split into a) profile and b) optimize if needed. The reason to do this is to see if the engine itself adds any overhead. Need to tests on NFS as well as on local drive,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1034
https://github.com/broadinstitute/gatk/issues/1035:154,Performance,optimiz,optimize,154,the goal is to be at least same as gatk3.4 on single thread. This is for the walker version of the tools.; The ticket can be split into a) profile and b) optimize if needed,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1035
https://github.com/broadinstitute/gatk/issues/1036:153,Performance,optimiz,optimize,153,the goal is to be at least same as gatk3.4 on single thread. This is for the walker version of the tool.; The ticket can be split into a) profile and b) optimize if needed. Note: the GATK3.4 version is called CountRODs. The reason to do this is to see if the engine itself adds any overhead.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1036
https://github.com/broadinstitute/gatk/pull/1037:280,Deployability,update,updates,280,"-Prints the current locus, the elapsed time, number of records processed,; and the rate at which records are being processed. -Hooked up for ReadWalkers, VariantWalkers, and IntervalWalkers. -A new command-line arg in GATKTool allows control over the frequency of; progress meter updates. -Tweaked the log4j output format to create more screen space for logger output. Resolves #974 (for alpha purposes)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1037
https://github.com/broadinstitute/gatk/pull/1037:274,Energy Efficiency,meter,meter,274,"-Prints the current locus, the elapsed time, number of records processed,; and the rate at which records are being processed. -Hooked up for ReadWalkers, VariantWalkers, and IntervalWalkers. -A new command-line arg in GATKTool allows control over the frequency of; progress meter updates. -Tweaked the log4j output format to create more screen space for logger output. Resolves #974 (for alpha purposes)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1037
https://github.com/broadinstitute/gatk/pull/1037:354,Testability,log,logger,354,"-Prints the current locus, the elapsed time, number of records processed,; and the rate at which records are being processed. -Hooked up for ReadWalkers, VariantWalkers, and IntervalWalkers. -A new command-line arg in GATKTool allows control over the frequency of; progress meter updates. -Tweaked the log4j output format to create more screen space for logger output. Resolves #974 (for alpha purposes)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1037
https://github.com/broadinstitute/gatk/issues/1040:108,Testability,test,tests,108,"The requirements are:; - we need full source code in the repository and buildable from gradle and with unit tests; - all versions of the code, native or not, must produce exactly the same results every time and we much have tests that check that.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1040
https://github.com/broadinstitute/gatk/issues/1040:224,Testability,test,tests,224,"The requirements are:; - we need full source code in the repository and buildable from gradle and with unit tests; - all versions of the code, native or not, must produce exactly the same results every time and we much have tests that check that.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1040
https://github.com/broadinstitute/gatk/issues/1042:4,Testability,test,tests,4,The tests are:; - [x] `testOpticalDuplicateClusterSamePositionNoOpticalDuplicates`; - [x] `testOpticalDuplicateClusterSamePositionNoOpticalDuplicatesWithinPixelDistance`; - [x] `testStackOverFlowPairSetSwap`; in `MarkDuplicatesSparkIntegrationTest`,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1042
https://github.com/broadinstitute/gatk/issues/1042:23,Testability,test,testOpticalDuplicateClusterSamePositionNoOpticalDuplicates,23,The tests are:; - [x] `testOpticalDuplicateClusterSamePositionNoOpticalDuplicates`; - [x] `testOpticalDuplicateClusterSamePositionNoOpticalDuplicatesWithinPixelDistance`; - [x] `testStackOverFlowPairSetSwap`; in `MarkDuplicatesSparkIntegrationTest`,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1042
https://github.com/broadinstitute/gatk/issues/1042:91,Testability,test,testOpticalDuplicateClusterSamePositionNoOpticalDuplicatesWithinPixelDistance,91,The tests are:; - [x] `testOpticalDuplicateClusterSamePositionNoOpticalDuplicates`; - [x] `testOpticalDuplicateClusterSamePositionNoOpticalDuplicatesWithinPixelDistance`; - [x] `testStackOverFlowPairSetSwap`; in `MarkDuplicatesSparkIntegrationTest`,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1042
https://github.com/broadinstitute/gatk/issues/1042:178,Testability,test,testStackOverFlowPairSetSwap,178,The tests are:; - [x] `testOpticalDuplicateClusterSamePositionNoOpticalDuplicates`; - [x] `testOpticalDuplicateClusterSamePositionNoOpticalDuplicatesWithinPixelDistance`; - [x] `testStackOverFlowPairSetSwap`; in `MarkDuplicatesSparkIntegrationTest`,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1042
https://github.com/broadinstitute/gatk/issues/1045:147,Testability,test,test,147,"Currently they leave out values that have all 0's. The formatting is different, and the sorting is different. ```; picard MarkDuplicates INPUT=src/test/resources/org/broadinstitute/hellbender/tools/picard/sam/MarkDuplicates/example.chr1.1-1K.unmarkedDups.bam METRICS_FILE=expected_duplicate_metrics.txt.picard OUTPUT=out.bam.picard; ```. produces. ```; ## htsjdk.samtools.metrics.StringHeader; # picard.sam.markduplicates.MarkDuplicates INPUT=[src/test/resources/org/broadinstitute/hellbender/tools/picard/sam/MarkDuplicates/example.chr1.1-1K.unmarkedDups.bam] OUTPUT=out.bam.picard METRICS_FILE=expected_duplicate_metrics.txt.picard MAX_SEQUENCES_FOR_DISK_READ_ENDS_MAP=50000 MAX_FILE_HANDLES_FOR_READ_ENDS_MAP=8000 SORTING_COLLECTION_SIZE_RATIO=0.25 PROGRAM_RECORD_ID=MarkDuplicates PROGRAM_GROUP_NAME=MarkDuplicates REMOVE_DUPLICATES=false ASSUME_SORTED=false DUPLICATE_SCORING_STRATEGY=SUM_OF_BASE_QUALITIES READ_NAME_REGEX=[a-zA-Z0-9]+:[0-9]:([0-9]+):([0-9]+):([0-9]+).* OPTICAL_DUPLICATE_PIXEL_DISTANCE=100 VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_INDEX=false CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json; ## htsjdk.samtools.metrics.StringHeader; # Started on: Thu Oct 22 16:45:11 EDT 2015. ## METRICS CLASS picard.sam.DuplicationMetrics; LIBRARY UNPAIRED_READS_EXAMINED READ_PAIRS_EXAMINED UNMAPPED_READS UNPAIRED_READ_DUPLICATES READ_PAIR_DUPLICATES READ_PAIR_OPTICAL_DUPLICATES PERCENT_DUPLICATION ESTIMATED_LIBRARY_SIZE; Solexa-16399 0 0 0 0 0 0 ?; Solexa-16421 0 0 0 0 0 0 ?; Solexa-16410 0 0 0 0 0 0 ?; Solexa-16398 0 0 0 0 0 0 ?; Solexa-16420 0 0 0 0 0 0 ?; Solexa-16419 4 4 4 0 0 0 0; Solexa-16408 0 0 0 0 0 0 ?; Solexa-16416 2 2 2 0 0 0 0; Solexa-16426 0 0 0 0 0 0 ?; Solexa-16415 0 0 0 0 0 0 ?; Solexa-16404 3 9 3 0 2 0 0.190476 17; Solexa-16418 0 0 0 0 0 0 ?; Solexa-16407 0 0 0 0 0 0 ?; Solexa-16406 1 10 1 0 0 0 0; Solexa-16412 3 6 3 0 1 0 0.133333 15; Solexa-16423 0 0 0 0 0 0 ?; Solexa-16411 0 ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1045
https://github.com/broadinstitute/gatk/issues/1045:448,Testability,test,test,448,"Currently they leave out values that have all 0's. The formatting is different, and the sorting is different. ```; picard MarkDuplicates INPUT=src/test/resources/org/broadinstitute/hellbender/tools/picard/sam/MarkDuplicates/example.chr1.1-1K.unmarkedDups.bam METRICS_FILE=expected_duplicate_metrics.txt.picard OUTPUT=out.bam.picard; ```. produces. ```; ## htsjdk.samtools.metrics.StringHeader; # picard.sam.markduplicates.MarkDuplicates INPUT=[src/test/resources/org/broadinstitute/hellbender/tools/picard/sam/MarkDuplicates/example.chr1.1-1K.unmarkedDups.bam] OUTPUT=out.bam.picard METRICS_FILE=expected_duplicate_metrics.txt.picard MAX_SEQUENCES_FOR_DISK_READ_ENDS_MAP=50000 MAX_FILE_HANDLES_FOR_READ_ENDS_MAP=8000 SORTING_COLLECTION_SIZE_RATIO=0.25 PROGRAM_RECORD_ID=MarkDuplicates PROGRAM_GROUP_NAME=MarkDuplicates REMOVE_DUPLICATES=false ASSUME_SORTED=false DUPLICATE_SCORING_STRATEGY=SUM_OF_BASE_QUALITIES READ_NAME_REGEX=[a-zA-Z0-9]+:[0-9]:([0-9]+):([0-9]+):([0-9]+).* OPTICAL_DUPLICATE_PIXEL_DISTANCE=100 VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_INDEX=false CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json; ## htsjdk.samtools.metrics.StringHeader; # Started on: Thu Oct 22 16:45:11 EDT 2015. ## METRICS CLASS picard.sam.DuplicationMetrics; LIBRARY UNPAIRED_READS_EXAMINED READ_PAIRS_EXAMINED UNMAPPED_READS UNPAIRED_READ_DUPLICATES READ_PAIR_DUPLICATES READ_PAIR_OPTICAL_DUPLICATES PERCENT_DUPLICATION ESTIMATED_LIBRARY_SIZE; Solexa-16399 0 0 0 0 0 0 ?; Solexa-16421 0 0 0 0 0 0 ?; Solexa-16410 0 0 0 0 0 0 ?; Solexa-16398 0 0 0 0 0 0 ?; Solexa-16420 0 0 0 0 0 0 ?; Solexa-16419 4 4 4 0 0 0 0; Solexa-16408 0 0 0 0 0 0 ?; Solexa-16416 2 2 2 0 0 0 0; Solexa-16426 0 0 0 0 0 0 ?; Solexa-16415 0 0 0 0 0 0 ?; Solexa-16404 3 9 3 0 2 0 0.190476 17; Solexa-16418 0 0 0 0 0 0 ?; Solexa-16407 0 0 0 0 0 0 ?; Solexa-16406 1 10 1 0 0 0 0; Solexa-16412 3 6 3 0 1 0 0.133333 15; Solexa-16423 0 0 0 0 0 0 ?; Solexa-16411 0 ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1045
https://github.com/broadinstitute/gatk/issues/1045:2299,Testability,test,test,2299,([0-9]+):([0-9]+).* OPTICAL_DUPLICATE_PIXEL_DISTANCE=100 VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_INDEX=false CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json; ## htsjdk.samtools.metrics.StringHeader; # Started on: Thu Oct 22 16:45:11 EDT 2015. ## METRICS CLASS picard.sam.DuplicationMetrics; LIBRARY UNPAIRED_READS_EXAMINED READ_PAIRS_EXAMINED UNMAPPED_READS UNPAIRED_READ_DUPLICATES READ_PAIR_DUPLICATES READ_PAIR_OPTICAL_DUPLICATES PERCENT_DUPLICATION ESTIMATED_LIBRARY_SIZE; Solexa-16399 0 0 0 0 0 0 ?; Solexa-16421 0 0 0 0 0 0 ?; Solexa-16410 0 0 0 0 0 0 ?; Solexa-16398 0 0 0 0 0 0 ?; Solexa-16420 0 0 0 0 0 0 ?; Solexa-16419 4 4 4 0 0 0 0; Solexa-16408 0 0 0 0 0 0 ?; Solexa-16416 2 2 2 0 0 0 0; Solexa-16426 0 0 0 0 0 0 ?; Solexa-16415 0 0 0 0 0 0 ?; Solexa-16404 3 9 3 0 2 0 0.190476 17; Solexa-16418 0 0 0 0 0 0 ?; Solexa-16407 0 0 0 0 0 0 ?; Solexa-16406 1 10 1 0 0 0 0; Solexa-16412 3 6 3 0 1 0 0.133333 15; Solexa-16423 0 0 0 0 0 0 ?; Solexa-16411 0 0 0 0 0 0 ?; Solexa-16422 0 0 0 0 0 0 ?; Solexa-16400 0 0 0 0 0 0 ?; Solexa-16425 0 0 0 0 0 0 ?; Solexa-16403 0 0 0 0 0 0 ?; Solexa-16414 0 0 0 0 0 0 ?; Solexa-16424 0 0 0 0 0 0 ?; Solexa-16402 0 0 0 0 0 0 ?; ```. The equivalent hellbender command . ```; hellbender MarkDuplicatesSpark --input src/test/resources/org/broadinstitute/hellbender/tools/picard/sam/MarkDuplicates/example.chr1.1-1K.unmarkedDups.bam --METRICS_FILE expected_duplicate_metrics.txt.spark --output out.bam.spark; ```. produces. ```; ## METRICS CLASS org.broadinstitute.hellbender.utils.read.markduplicates.DuplicationMetrics; LIBRARY UNPAIRED_READS_EXAMINED READ_PAIRS_EXAMINED UNMAPPED_READS UNPAIRED_READ_DUPLICATES READ_PAIR_DUPLICATES READ_PAIR_OPTICAL_DUPLICATES PERCENT_DUPLICATION ESTIMATED_LIBRARY_SIZE; Solexa-16416 2 2 2 0 0 0 0 0; Solexa-16404 3 9 3 0 2 0 0.190476 17; Solexa-16419 4 4 4 0 0 0 0 0; Solexa-16412 3 6 3 0 1 0 0.133333 15; Solexa-16406 1 10 1 0 0 0 0 0; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1045
https://github.com/broadinstitute/gatk/issues/1047:13,Performance,perform,performance,13,"What kind of performance do we get when we run Spark tools locally compared to both the walker versions and the GATK3 versions? We should test apples-to-apples first (1 core for Spark), then test multithreaded Spark vs. single-threaded walkers. Should also use fairly large inputs. @lbergelson 's initial tests on the Spark BQSR show that with 1 or 2 threads the Spark version is unusably slow locally, and with 8 threads (on a 4 core machine) it still loses by ~6x or ~7x to the walker version. This is regardless of joinStrategy = SHUFFLE or BROADCAST. If the slowness above is confirmed, and we can identify ways to speed up Spark locally, we should create additional tickets to make those changes and assess whether they are realistic for the alpha milestone.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1047
https://github.com/broadinstitute/gatk/issues/1047:138,Testability,test,test,138,"What kind of performance do we get when we run Spark tools locally compared to both the walker versions and the GATK3 versions? We should test apples-to-apples first (1 core for Spark), then test multithreaded Spark vs. single-threaded walkers. Should also use fairly large inputs. @lbergelson 's initial tests on the Spark BQSR show that with 1 or 2 threads the Spark version is unusably slow locally, and with 8 threads (on a 4 core machine) it still loses by ~6x or ~7x to the walker version. This is regardless of joinStrategy = SHUFFLE or BROADCAST. If the slowness above is confirmed, and we can identify ways to speed up Spark locally, we should create additional tickets to make those changes and assess whether they are realistic for the alpha milestone.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1047
https://github.com/broadinstitute/gatk/issues/1047:191,Testability,test,test,191,"What kind of performance do we get when we run Spark tools locally compared to both the walker versions and the GATK3 versions? We should test apples-to-apples first (1 core for Spark), then test multithreaded Spark vs. single-threaded walkers. Should also use fairly large inputs. @lbergelson 's initial tests on the Spark BQSR show that with 1 or 2 threads the Spark version is unusably slow locally, and with 8 threads (on a 4 core machine) it still loses by ~6x or ~7x to the walker version. This is regardless of joinStrategy = SHUFFLE or BROADCAST. If the slowness above is confirmed, and we can identify ways to speed up Spark locally, we should create additional tickets to make those changes and assess whether they are realistic for the alpha milestone.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1047
https://github.com/broadinstitute/gatk/issues/1047:305,Testability,test,tests,305,"What kind of performance do we get when we run Spark tools locally compared to both the walker versions and the GATK3 versions? We should test apples-to-apples first (1 core for Spark), then test multithreaded Spark vs. single-threaded walkers. Should also use fairly large inputs. @lbergelson 's initial tests on the Spark BQSR show that with 1 or 2 threads the Spark version is unusably slow locally, and with 8 threads (on a 4 core machine) it still loses by ~6x or ~7x to the walker version. This is regardless of joinStrategy = SHUFFLE or BROADCAST. If the slowness above is confirmed, and we can identify ways to speed up Spark locally, we should create additional tickets to make those changes and assess whether they are realistic for the alpha milestone.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1047
https://github.com/broadinstitute/gatk/pull/1048:177,Modifiability,refactor,refactoring,177,"Please feel free to close this out. Just noticing small typos as I read through the docs for #1027; Not sure whether y'all prefer to avoid making trivial changes until a larger refactoring occurs, or would want them fixed on their own when they are noticed..",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1048
https://github.com/broadinstitute/gatk/pull/1048:133,Safety,avoid,avoid,133,"Please feel free to close this out. Just noticing small typos as I read through the docs for #1027; Not sure whether y'all prefer to avoid making trivial changes until a larger refactoring occurs, or would want them fixed on their own when they are noticed..",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1048
https://github.com/broadinstitute/gatk/issues/1049:146,Deployability,install,install,146,"the dev-oriented material such as coding conventions etc should be moved to a separate wiki page.; The main readme should have examples of how to install it, how to validate the installation and how run it locally, on spark cluster and on the cloud. Candidate for alpha",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1049
https://github.com/broadinstitute/gatk/issues/1049:178,Deployability,install,installation,178,"the dev-oriented material such as coding conventions etc should be moved to a separate wiki page.; The main readme should have examples of how to install it, how to validate the installation and how run it locally, on spark cluster and on the cloud. Candidate for alpha",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1049
https://github.com/broadinstitute/gatk/issues/1049:165,Security,validat,validate,165,"the dev-oriented material such as coding conventions etc should be moved to a separate wiki page.; The main readme should have examples of how to install it, how to validate the installation and how run it locally, on spark cluster and on the cloud. Candidate for alpha",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1049
https://github.com/broadinstitute/gatk/pull/1050:0,Testability,test,testing,0,testing to see if external pull request testing is fixed,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1050
https://github.com/broadinstitute/gatk/pull/1050:40,Testability,test,testing,40,testing to see if external pull request testing is fixed,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1050
https://github.com/broadinstitute/gatk/issues/1051:59,Deployability,install,installed,59,"Currently we have a dependency on having gcloud and gsutil installed and configured in a certain way, but we don't have any documentation about it. . We're getting authentication partially from gcloud auth login, which is being propagated in a way I don't fully understand through the dataflow pipeline options. . We need to understand exactly what's happening and then write an explanation of what a user needs to do to have it work.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1051
https://github.com/broadinstitute/gatk/issues/1051:294,Deployability,pipeline,pipeline,294,"Currently we have a dependency on having gcloud and gsutil installed and configured in a certain way, but we don't have any documentation about it. . We're getting authentication partially from gcloud auth login, which is being propagated in a way I don't fully understand through the dataflow pipeline options. . We need to understand exactly what's happening and then write an explanation of what a user needs to do to have it work.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1051
https://github.com/broadinstitute/gatk/issues/1051:20,Integrability,depend,dependency,20,"Currently we have a dependency on having gcloud and gsutil installed and configured in a certain way, but we don't have any documentation about it. . We're getting authentication partially from gcloud auth login, which is being propagated in a way I don't fully understand through the dataflow pipeline options. . We need to understand exactly what's happening and then write an explanation of what a user needs to do to have it work.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1051
https://github.com/broadinstitute/gatk/issues/1051:73,Modifiability,config,configured,73,"Currently we have a dependency on having gcloud and gsutil installed and configured in a certain way, but we don't have any documentation about it. . We're getting authentication partially from gcloud auth login, which is being propagated in a way I don't fully understand through the dataflow pipeline options. . We need to understand exactly what's happening and then write an explanation of what a user needs to do to have it work.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1051
https://github.com/broadinstitute/gatk/issues/1051:164,Security,authenticat,authentication,164,"Currently we have a dependency on having gcloud and gsutil installed and configured in a certain way, but we don't have any documentation about it. . We're getting authentication partially from gcloud auth login, which is being propagated in a way I don't fully understand through the dataflow pipeline options. . We need to understand exactly what's happening and then write an explanation of what a user needs to do to have it work.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1051
https://github.com/broadinstitute/gatk/issues/1051:206,Testability,log,login,206,"Currently we have a dependency on having gcloud and gsutil installed and configured in a certain way, but we don't have any documentation about it. . We're getting authentication partially from gcloud auth login, which is being propagated in a way I don't fully understand through the dataflow pipeline options. . We need to understand exactly what's happening and then write an explanation of what a user needs to do to have it work.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1051
https://github.com/broadinstitute/gatk/pull/1053:262,Deployability,pipeline,pipelines,262,"Fixes #1027 . This follows google java style guide. Not sure why `pf_read_only` and `aligned_reads_only` are not; camel-cased, but I'm all for that style of casing. ---. The following test passes:. > gradle test --tests org.broadinstitute.hellbender.tools.spark.pipelines.metrics.MeanQualityByCycleSparkIntegrationTest. It seems that there is no need for a unit test here, but please let me; know if you would prefer one. I have a skeleton test class to verify; that GatkReadFilter blocks secondary alignment reads,; blocks supplementary alignment reads, can restrict to passing filter; reads only, and can restrict to aligned reads only.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1053
https://github.com/broadinstitute/gatk/pull/1053:184,Testability,test,test,184,"Fixes #1027 . This follows google java style guide. Not sure why `pf_read_only` and `aligned_reads_only` are not; camel-cased, but I'm all for that style of casing. ---. The following test passes:. > gradle test --tests org.broadinstitute.hellbender.tools.spark.pipelines.metrics.MeanQualityByCycleSparkIntegrationTest. It seems that there is no need for a unit test here, but please let me; know if you would prefer one. I have a skeleton test class to verify; that GatkReadFilter blocks secondary alignment reads,; blocks supplementary alignment reads, can restrict to passing filter; reads only, and can restrict to aligned reads only.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1053
https://github.com/broadinstitute/gatk/pull/1053:207,Testability,test,test,207,"Fixes #1027 . This follows google java style guide. Not sure why `pf_read_only` and `aligned_reads_only` are not; camel-cased, but I'm all for that style of casing. ---. The following test passes:. > gradle test --tests org.broadinstitute.hellbender.tools.spark.pipelines.metrics.MeanQualityByCycleSparkIntegrationTest. It seems that there is no need for a unit test here, but please let me; know if you would prefer one. I have a skeleton test class to verify; that GatkReadFilter blocks secondary alignment reads,; blocks supplementary alignment reads, can restrict to passing filter; reads only, and can restrict to aligned reads only.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1053
https://github.com/broadinstitute/gatk/pull/1053:214,Testability,test,tests,214,"Fixes #1027 . This follows google java style guide. Not sure why `pf_read_only` and `aligned_reads_only` are not; camel-cased, but I'm all for that style of casing. ---. The following test passes:. > gradle test --tests org.broadinstitute.hellbender.tools.spark.pipelines.metrics.MeanQualityByCycleSparkIntegrationTest. It seems that there is no need for a unit test here, but please let me; know if you would prefer one. I have a skeleton test class to verify; that GatkReadFilter blocks secondary alignment reads,; blocks supplementary alignment reads, can restrict to passing filter; reads only, and can restrict to aligned reads only.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1053
https://github.com/broadinstitute/gatk/pull/1053:362,Testability,test,test,362,"Fixes #1027 . This follows google java style guide. Not sure why `pf_read_only` and `aligned_reads_only` are not; camel-cased, but I'm all for that style of casing. ---. The following test passes:. > gradle test --tests org.broadinstitute.hellbender.tools.spark.pipelines.metrics.MeanQualityByCycleSparkIntegrationTest. It seems that there is no need for a unit test here, but please let me; know if you would prefer one. I have a skeleton test class to verify; that GatkReadFilter blocks secondary alignment reads,; blocks supplementary alignment reads, can restrict to passing filter; reads only, and can restrict to aligned reads only.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1053
https://github.com/broadinstitute/gatk/pull/1053:440,Testability,test,test,440,"Fixes #1027 . This follows google java style guide. Not sure why `pf_read_only` and `aligned_reads_only` are not; camel-cased, but I'm all for that style of casing. ---. The following test passes:. > gradle test --tests org.broadinstitute.hellbender.tools.spark.pipelines.metrics.MeanQualityByCycleSparkIntegrationTest. It seems that there is no need for a unit test here, but please let me; know if you would prefer one. I have a skeleton test class to verify; that GatkReadFilter blocks secondary alignment reads,; blocks supplementary alignment reads, can restrict to passing filter; reads only, and can restrict to aligned reads only.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1053
https://github.com/broadinstitute/gatk/pull/1053:45,Usability,guid,guide,45,"Fixes #1027 . This follows google java style guide. Not sure why `pf_read_only` and `aligned_reads_only` are not; camel-cased, but I'm all for that style of casing. ---. The following test passes:. > gradle test --tests org.broadinstitute.hellbender.tools.spark.pipelines.metrics.MeanQualityByCycleSparkIntegrationTest. It seems that there is no need for a unit test here, but please let me; know if you would prefer one. I have a skeleton test class to verify; that GatkReadFilter blocks secondary alignment reads,; blocks supplementary alignment reads, can restrict to passing filter; reads only, and can restrict to aligned reads only.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1053
https://github.com/broadinstitute/gatk/issues/1056:123,Performance,perform,performance,123,"After doing this, do another comparison run against GATK3 BQSR to see how much eliminating this code bought us in terms of performance.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1056
https://github.com/broadinstitute/gatk/pull/1059:28,Deployability,release,released,28,Now that ADAM 0.18 has been released. Fixes #957.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1059
https://github.com/broadinstitute/gatk/issues/1060:147,Testability,log,log,147,"It seems that using -L pulls in unmapped reads which is not what we want I think. The reason I think unmapped reads are pulled in is this progress log from a Spark job. Note the 'Current locus' on the last line. ```; org.broadinstitute.hellbender.tools.CountReads --intervals 1:1-20000000 --input /humgen/gsa-hpprojects/NA12878Collection/bams/CEUTrio.HiSeq.WGS.b37.NA12878.bam --disable_all_read_filters false --interval_set_rule UNION --interval_padding 0 --secondsBetweenProgressUpdates 10.0 --help false --version false --VERBOSITY INFO --QUIET false; [October 24, 2015 2:16:18 AM EDT] Executing as akiezun@dataflow01.broadinstitute.org on Linux 2.6.32-573.3.1.el6.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0-b132; Version: Version:4.pre-alpha-45-g168cd60-SNAPSHOT JdkDeflater; 02:16:18.972 INFO CountReads - Initializing engine; 02:16:19.296 INFO IntervalArgumentCollection - Processing 20000000 bp from intervals; 02:16:19.300 INFO ReadsDataSource - Preparing intervals for traversal; 02:16:19.301 INFO CountReads - Done initializing engine; 02:16:19.301 INFO ProgressMeter - Starting traversal; 02:16:19.302 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 02:16:29.306 INFO ProgressMeter - 1:3034965 0.2 2219000 13310007.0; 02:16:39.306 INFO ProgressMeter - unmapped 0.3 4542000 13623275.3; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1060
https://github.com/broadinstitute/gatk/issues/1063:254,Performance,cache,caches,254,Currently we get this warning every time we run a spark program. We should exclude the older version of slf4j so we don't get this warning. ```; SLF4J: Class path contains multiple SLF4J bindings.; SLF4J: Found binding in [jar:file:/Users/louisb/.gradle/caches/modules-2/files-2.1/org.slf4j/slf4j-log4j12/1.7.10/b3eeae7d1765f988a1f45ea81517191315c69c9e/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: Found binding in [jar:file:/Users/louisb/.gradle/caches/modules-2/files-2.1/org.slf4j/slf4j-jdk14/1.7.7/25d160723ea37a6cb84e87cd70773ff02997e857/slf4j-jdk14-1.7.7.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.; SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1063
https://github.com/broadinstitute/gatk/issues/1063:477,Performance,cache,caches,477,Currently we get this warning every time we run a spark program. We should exclude the older version of slf4j so we don't get this warning. ```; SLF4J: Class path contains multiple SLF4J bindings.; SLF4J: Found binding in [jar:file:/Users/louisb/.gradle/caches/modules-2/files-2.1/org.slf4j/slf4j-log4j12/1.7.10/b3eeae7d1765f988a1f45ea81517191315c69c9e/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: Found binding in [jar:file:/Users/louisb/.gradle/caches/modules-2/files-2.1/org.slf4j/slf4j-jdk14/1.7.7/25d160723ea37a6cb84e87cd70773ff02997e857/slf4j-jdk14-1.7.7.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.; SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1063
https://github.com/broadinstitute/gatk/issues/1064:93,Security,expose,exposed,93,"`mapred.max.split.size` is currently hardcoded to 10485760 in ReadsSparkSource. It should be exposed as a parameter that can be set at the command line since different values are better for different tools. It's a deprecated property, so it should probably be replaced with the new `mapreduce.input.fileinputformat.split.maxsize` instead.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1064
https://github.com/broadinstitute/gatk/pull/1067:42,Integrability,message,message,42,File generation is included in the commit message.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1067
https://github.com/broadinstitute/gatk/pull/1068:216,Integrability,depend,depending,216,"We needed UUIDs for Dataflow, but they are just a hinderance in Spark.; In this PR, I removed every reference to UUID that was related to the original Dataflow code. I also fixed some unit tests that were implicitly depending on the UUIDs to have test reads not equal. The fix was to give the test reads different names.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1068
https://github.com/broadinstitute/gatk/pull/1068:189,Testability,test,tests,189,"We needed UUIDs for Dataflow, but they are just a hinderance in Spark.; In this PR, I removed every reference to UUID that was related to the original Dataflow code. I also fixed some unit tests that were implicitly depending on the UUIDs to have test reads not equal. The fix was to give the test reads different names.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1068
https://github.com/broadinstitute/gatk/pull/1068:247,Testability,test,test,247,"We needed UUIDs for Dataflow, but they are just a hinderance in Spark.; In this PR, I removed every reference to UUID that was related to the original Dataflow code. I also fixed some unit tests that were implicitly depending on the UUIDs to have test reads not equal. The fix was to give the test reads different names.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1068
https://github.com/broadinstitute/gatk/pull/1068:293,Testability,test,test,293,"We needed UUIDs for Dataflow, but they are just a hinderance in Spark.; In this PR, I removed every reference to UUID that was related to the original Dataflow code. I also fixed some unit tests that were implicitly depending on the UUIDs to have test reads not equal. The fix was to give the test reads different names.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1068
https://github.com/broadinstitute/gatk/issues/1070:135,Availability,mask,mask,135,"And `SparkCommandLineProgram` should not set a default master. This should be left to `spark-submit`. Otherwise, the settings actually mask my requested spark master that I set with `spark-submit --master ...`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1070
https://github.com/broadinstitute/gatk/issues/1072:107,Security,audit,audit,107,"Once https://github.com/samtools/htsjdk/pull/327 is merged into htsjdk and propagates to hellbender, let's audit our Spark tools to ensure that we are always serializing headerless SAMRecords",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1072
https://github.com/broadinstitute/gatk/issues/1073:131,Testability,test,tests,131,"CompareSam ignores actual content of the reads (bases, qualities, attributes etc). We need this functionality to use CompareSam in tests. . This issue may be fixed by creating a new facility to compare bam/sam files that takes those into account.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1073
https://github.com/broadinstitute/gatk/pull/1079:286,Testability,test,tests,286,"Fixes https://github.com/broadinstitute/gatk/issues/1073. note expected.HiSeq.1mb.1RG.2k_lines.bqsr.DIQ.alternate.bam is modified because the previous version was bogus and did not remove indel quals (ie included BD and BI tags, incorrectly). Note: as discovered by these new stringent tests, cram writing is broken (https://github.com/samtools/htsjdk/issues/364) so we make that comparison lenient for now. Note: Spark tools lose order of reads from the input and so comparison is done after sorting the output files (an alternative would have been to write the stringent sam comparison in a way that can ignore order or equivalent reads, but sorting is easier to do).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1079
https://github.com/broadinstitute/gatk/issues/1081:42,Testability,test,tests,42,"Intellij pointed out to me that these two tests were identical, but they sound like they're testing different things. Are we missing an important test case? . We should either fix whichever one isn't testing the thing it says it is, or delete one of them. ```; @Test; public void testStartInMiddleWithBubble() {; final TestAssembler assembler = new TestAssembler(3);; final String ref = ""CAAAATGGGG"";; final String read = ""AAATCGGG"";; assembler.addSequence(ref.getBytes(), true);; assembler.addSequence(read.getBytes(), false);; assertSingleBubble(assembler, ref, ""CAAAATCGGG"");; }. @Test; public void testNoGoodStarts() {; final TestAssembler assembler = new TestAssembler(3);; final String ref = ""CAAAATGGGG"";; final String read = ""AAATCGGG"";; assembler.addSequence(ref.getBytes(), true);; assembler.addSequence(read.getBytes(), false);; assertSingleBubble(assembler, ref, ""CAAAATCGGG"");; }; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1081
https://github.com/broadinstitute/gatk/issues/1081:92,Testability,test,testing,92,"Intellij pointed out to me that these two tests were identical, but they sound like they're testing different things. Are we missing an important test case? . We should either fix whichever one isn't testing the thing it says it is, or delete one of them. ```; @Test; public void testStartInMiddleWithBubble() {; final TestAssembler assembler = new TestAssembler(3);; final String ref = ""CAAAATGGGG"";; final String read = ""AAATCGGG"";; assembler.addSequence(ref.getBytes(), true);; assembler.addSequence(read.getBytes(), false);; assertSingleBubble(assembler, ref, ""CAAAATCGGG"");; }. @Test; public void testNoGoodStarts() {; final TestAssembler assembler = new TestAssembler(3);; final String ref = ""CAAAATGGGG"";; final String read = ""AAATCGGG"";; assembler.addSequence(ref.getBytes(), true);; assembler.addSequence(read.getBytes(), false);; assertSingleBubble(assembler, ref, ""CAAAATCGGG"");; }; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1081
https://github.com/broadinstitute/gatk/issues/1081:146,Testability,test,test,146,"Intellij pointed out to me that these two tests were identical, but they sound like they're testing different things. Are we missing an important test case? . We should either fix whichever one isn't testing the thing it says it is, or delete one of them. ```; @Test; public void testStartInMiddleWithBubble() {; final TestAssembler assembler = new TestAssembler(3);; final String ref = ""CAAAATGGGG"";; final String read = ""AAATCGGG"";; assembler.addSequence(ref.getBytes(), true);; assembler.addSequence(read.getBytes(), false);; assertSingleBubble(assembler, ref, ""CAAAATCGGG"");; }. @Test; public void testNoGoodStarts() {; final TestAssembler assembler = new TestAssembler(3);; final String ref = ""CAAAATGGGG"";; final String read = ""AAATCGGG"";; assembler.addSequence(ref.getBytes(), true);; assembler.addSequence(read.getBytes(), false);; assertSingleBubble(assembler, ref, ""CAAAATCGGG"");; }; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1081
https://github.com/broadinstitute/gatk/issues/1081:200,Testability,test,testing,200,"Intellij pointed out to me that these two tests were identical, but they sound like they're testing different things. Are we missing an important test case? . We should either fix whichever one isn't testing the thing it says it is, or delete one of them. ```; @Test; public void testStartInMiddleWithBubble() {; final TestAssembler assembler = new TestAssembler(3);; final String ref = ""CAAAATGGGG"";; final String read = ""AAATCGGG"";; assembler.addSequence(ref.getBytes(), true);; assembler.addSequence(read.getBytes(), false);; assertSingleBubble(assembler, ref, ""CAAAATCGGG"");; }. @Test; public void testNoGoodStarts() {; final TestAssembler assembler = new TestAssembler(3);; final String ref = ""CAAAATGGGG"";; final String read = ""AAATCGGG"";; assembler.addSequence(ref.getBytes(), true);; assembler.addSequence(read.getBytes(), false);; assertSingleBubble(assembler, ref, ""CAAAATCGGG"");; }; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1081
https://github.com/broadinstitute/gatk/issues/1081:262,Testability,Test,Test,262,"Intellij pointed out to me that these two tests were identical, but they sound like they're testing different things. Are we missing an important test case? . We should either fix whichever one isn't testing the thing it says it is, or delete one of them. ```; @Test; public void testStartInMiddleWithBubble() {; final TestAssembler assembler = new TestAssembler(3);; final String ref = ""CAAAATGGGG"";; final String read = ""AAATCGGG"";; assembler.addSequence(ref.getBytes(), true);; assembler.addSequence(read.getBytes(), false);; assertSingleBubble(assembler, ref, ""CAAAATCGGG"");; }. @Test; public void testNoGoodStarts() {; final TestAssembler assembler = new TestAssembler(3);; final String ref = ""CAAAATGGGG"";; final String read = ""AAATCGGG"";; assembler.addSequence(ref.getBytes(), true);; assembler.addSequence(read.getBytes(), false);; assertSingleBubble(assembler, ref, ""CAAAATCGGG"");; }; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1081
https://github.com/broadinstitute/gatk/issues/1081:280,Testability,test,testStartInMiddleWithBubble,280,"Intellij pointed out to me that these two tests were identical, but they sound like they're testing different things. Are we missing an important test case? . We should either fix whichever one isn't testing the thing it says it is, or delete one of them. ```; @Test; public void testStartInMiddleWithBubble() {; final TestAssembler assembler = new TestAssembler(3);; final String ref = ""CAAAATGGGG"";; final String read = ""AAATCGGG"";; assembler.addSequence(ref.getBytes(), true);; assembler.addSequence(read.getBytes(), false);; assertSingleBubble(assembler, ref, ""CAAAATCGGG"");; }. @Test; public void testNoGoodStarts() {; final TestAssembler assembler = new TestAssembler(3);; final String ref = ""CAAAATGGGG"";; final String read = ""AAATCGGG"";; assembler.addSequence(ref.getBytes(), true);; assembler.addSequence(read.getBytes(), false);; assertSingleBubble(assembler, ref, ""CAAAATCGGG"");; }; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1081
https://github.com/broadinstitute/gatk/issues/1081:319,Testability,Test,TestAssembler,319,"Intellij pointed out to me that these two tests were identical, but they sound like they're testing different things. Are we missing an important test case? . We should either fix whichever one isn't testing the thing it says it is, or delete one of them. ```; @Test; public void testStartInMiddleWithBubble() {; final TestAssembler assembler = new TestAssembler(3);; final String ref = ""CAAAATGGGG"";; final String read = ""AAATCGGG"";; assembler.addSequence(ref.getBytes(), true);; assembler.addSequence(read.getBytes(), false);; assertSingleBubble(assembler, ref, ""CAAAATCGGG"");; }. @Test; public void testNoGoodStarts() {; final TestAssembler assembler = new TestAssembler(3);; final String ref = ""CAAAATGGGG"";; final String read = ""AAATCGGG"";; assembler.addSequence(ref.getBytes(), true);; assembler.addSequence(read.getBytes(), false);; assertSingleBubble(assembler, ref, ""CAAAATCGGG"");; }; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1081
https://github.com/broadinstitute/gatk/issues/1081:349,Testability,Test,TestAssembler,349,"Intellij pointed out to me that these two tests were identical, but they sound like they're testing different things. Are we missing an important test case? . We should either fix whichever one isn't testing the thing it says it is, or delete one of them. ```; @Test; public void testStartInMiddleWithBubble() {; final TestAssembler assembler = new TestAssembler(3);; final String ref = ""CAAAATGGGG"";; final String read = ""AAATCGGG"";; assembler.addSequence(ref.getBytes(), true);; assembler.addSequence(read.getBytes(), false);; assertSingleBubble(assembler, ref, ""CAAAATCGGG"");; }. @Test; public void testNoGoodStarts() {; final TestAssembler assembler = new TestAssembler(3);; final String ref = ""CAAAATGGGG"";; final String read = ""AAATCGGG"";; assembler.addSequence(ref.getBytes(), true);; assembler.addSequence(read.getBytes(), false);; assertSingleBubble(assembler, ref, ""CAAAATCGGG"");; }; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1081
https://github.com/broadinstitute/gatk/issues/1081:529,Testability,assert,assertSingleBubble,529,"Intellij pointed out to me that these two tests were identical, but they sound like they're testing different things. Are we missing an important test case? . We should either fix whichever one isn't testing the thing it says it is, or delete one of them. ```; @Test; public void testStartInMiddleWithBubble() {; final TestAssembler assembler = new TestAssembler(3);; final String ref = ""CAAAATGGGG"";; final String read = ""AAATCGGG"";; assembler.addSequence(ref.getBytes(), true);; assembler.addSequence(read.getBytes(), false);; assertSingleBubble(assembler, ref, ""CAAAATCGGG"");; }. @Test; public void testNoGoodStarts() {; final TestAssembler assembler = new TestAssembler(3);; final String ref = ""CAAAATGGGG"";; final String read = ""AAATCGGG"";; assembler.addSequence(ref.getBytes(), true);; assembler.addSequence(read.getBytes(), false);; assertSingleBubble(assembler, ref, ""CAAAATCGGG"");; }; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1081
https://github.com/broadinstitute/gatk/issues/1081:584,Testability,Test,Test,584,"Intellij pointed out to me that these two tests were identical, but they sound like they're testing different things. Are we missing an important test case? . We should either fix whichever one isn't testing the thing it says it is, or delete one of them. ```; @Test; public void testStartInMiddleWithBubble() {; final TestAssembler assembler = new TestAssembler(3);; final String ref = ""CAAAATGGGG"";; final String read = ""AAATCGGG"";; assembler.addSequence(ref.getBytes(), true);; assembler.addSequence(read.getBytes(), false);; assertSingleBubble(assembler, ref, ""CAAAATCGGG"");; }. @Test; public void testNoGoodStarts() {; final TestAssembler assembler = new TestAssembler(3);; final String ref = ""CAAAATGGGG"";; final String read = ""AAATCGGG"";; assembler.addSequence(ref.getBytes(), true);; assembler.addSequence(read.getBytes(), false);; assertSingleBubble(assembler, ref, ""CAAAATCGGG"");; }; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1081
https://github.com/broadinstitute/gatk/issues/1081:602,Testability,test,testNoGoodStarts,602,"Intellij pointed out to me that these two tests were identical, but they sound like they're testing different things. Are we missing an important test case? . We should either fix whichever one isn't testing the thing it says it is, or delete one of them. ```; @Test; public void testStartInMiddleWithBubble() {; final TestAssembler assembler = new TestAssembler(3);; final String ref = ""CAAAATGGGG"";; final String read = ""AAATCGGG"";; assembler.addSequence(ref.getBytes(), true);; assembler.addSequence(read.getBytes(), false);; assertSingleBubble(assembler, ref, ""CAAAATCGGG"");; }. @Test; public void testNoGoodStarts() {; final TestAssembler assembler = new TestAssembler(3);; final String ref = ""CAAAATGGGG"";; final String read = ""AAATCGGG"";; assembler.addSequence(ref.getBytes(), true);; assembler.addSequence(read.getBytes(), false);; assertSingleBubble(assembler, ref, ""CAAAATCGGG"");; }; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1081
https://github.com/broadinstitute/gatk/issues/1081:630,Testability,Test,TestAssembler,630,"Intellij pointed out to me that these two tests were identical, but they sound like they're testing different things. Are we missing an important test case? . We should either fix whichever one isn't testing the thing it says it is, or delete one of them. ```; @Test; public void testStartInMiddleWithBubble() {; final TestAssembler assembler = new TestAssembler(3);; final String ref = ""CAAAATGGGG"";; final String read = ""AAATCGGG"";; assembler.addSequence(ref.getBytes(), true);; assembler.addSequence(read.getBytes(), false);; assertSingleBubble(assembler, ref, ""CAAAATCGGG"");; }. @Test; public void testNoGoodStarts() {; final TestAssembler assembler = new TestAssembler(3);; final String ref = ""CAAAATGGGG"";; final String read = ""AAATCGGG"";; assembler.addSequence(ref.getBytes(), true);; assembler.addSequence(read.getBytes(), false);; assertSingleBubble(assembler, ref, ""CAAAATCGGG"");; }; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1081
https://github.com/broadinstitute/gatk/issues/1081:660,Testability,Test,TestAssembler,660,"Intellij pointed out to me that these two tests were identical, but they sound like they're testing different things. Are we missing an important test case? . We should either fix whichever one isn't testing the thing it says it is, or delete one of them. ```; @Test; public void testStartInMiddleWithBubble() {; final TestAssembler assembler = new TestAssembler(3);; final String ref = ""CAAAATGGGG"";; final String read = ""AAATCGGG"";; assembler.addSequence(ref.getBytes(), true);; assembler.addSequence(read.getBytes(), false);; assertSingleBubble(assembler, ref, ""CAAAATCGGG"");; }. @Test; public void testNoGoodStarts() {; final TestAssembler assembler = new TestAssembler(3);; final String ref = ""CAAAATGGGG"";; final String read = ""AAATCGGG"";; assembler.addSequence(ref.getBytes(), true);; assembler.addSequence(read.getBytes(), false);; assertSingleBubble(assembler, ref, ""CAAAATCGGG"");; }; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1081
https://github.com/broadinstitute/gatk/issues/1081:840,Testability,assert,assertSingleBubble,840,"Intellij pointed out to me that these two tests were identical, but they sound like they're testing different things. Are we missing an important test case? . We should either fix whichever one isn't testing the thing it says it is, or delete one of them. ```; @Test; public void testStartInMiddleWithBubble() {; final TestAssembler assembler = new TestAssembler(3);; final String ref = ""CAAAATGGGG"";; final String read = ""AAATCGGG"";; assembler.addSequence(ref.getBytes(), true);; assembler.addSequence(read.getBytes(), false);; assertSingleBubble(assembler, ref, ""CAAAATCGGG"");; }. @Test; public void testNoGoodStarts() {; final TestAssembler assembler = new TestAssembler(3);; final String ref = ""CAAAATGGGG"";; final String read = ""AAATCGGG"";; assembler.addSequence(ref.getBytes(), true);; assembler.addSequence(read.getBytes(), false);; assertSingleBubble(assembler, ref, ""CAAAATCGGG"");; }; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1081
https://github.com/broadinstitute/gatk/pull/1084:83,Integrability,depend,depends,83,There is one test in ValidateSamFileIntegrationTest that is commented out since it depends on a change to htsjdk.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1084
https://github.com/broadinstitute/gatk/pull/1084:21,Security,Validat,ValidateSamFileIntegrationTest,21,There is one test in ValidateSamFileIntegrationTest that is commented out since it depends on a change to htsjdk.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1084
https://github.com/broadinstitute/gatk/pull/1084:13,Testability,test,test,13,There is one test in ValidateSamFileIntegrationTest that is commented out since it depends on a change to htsjdk.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1084
https://github.com/broadinstitute/gatk/issues/1085:215,Testability,test,tests,215,"BaseRecalibrator can take multiple feature files as known sites (the --knownSites argument). But BaseRecalibratorSpark can't and so BQSRPipelineSpark can't and ReadsPipelineSpark can't. Once this is fixed, relevant tests should be reenabled",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1085
https://github.com/broadinstitute/gatk/issues/1087:86,Testability,test,tests,86,due to a CRAM bug https://github.com/samtools/htsjdk/issues/364 we have to make a few tests lenient. make them stringent when the cram bug is resolved,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1087
https://github.com/broadinstitute/gatk/pull/1089:26,Security,validat,validation,26,This is required for some validation work we're currently doing.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1089
https://github.com/broadinstitute/gatk/pull/1097:176,Deployability,configurat,configuration,176,"moving settings from SparkCommandLineProgram to SparkContextFactory; the settings that were being applied to SparkContext.getConf were pointless since getConf is a copy of the configuration; instead they're applied to the SparkConfig in SparkContextFactory.getSparkContext. fixes #1096. <!-- Reviewable:start -->. [<img src=""https://reviewable.io/review_button.png"" height=40 alt=""Review on Reviewable""/>](https://reviewable.io/reviews/broadinstitute/gatk/1097). <!-- Reviewable:end -->",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1097
https://github.com/broadinstitute/gatk/pull/1097:176,Modifiability,config,configuration,176,"moving settings from SparkCommandLineProgram to SparkContextFactory; the settings that were being applied to SparkContext.getConf were pointless since getConf is a copy of the configuration; instead they're applied to the SparkConfig in SparkContextFactory.getSparkContext. fixes #1096. <!-- Reviewable:start -->. [<img src=""https://reviewable.io/review_button.png"" height=40 alt=""Review on Reviewable""/>](https://reviewable.io/reviews/broadinstitute/gatk/1097). <!-- Reviewable:end -->",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1097
https://github.com/broadinstitute/gatk/issues/1098:1179,Availability,down,down,1179,"The symptom is that I'm getting an invalid record when using the Hadoop-BAM probabilistic splitter. I wrote a small program to verify the bug and the record it's happening on. To run this, check out da_key_bug and run something similar to my command. ```; gcloud beta dataproc jobs submit spark \; --cluster high-mem-16-8-sd \; --properties spark.executor.memory=38g,spark.executor.instances=15,spark.executor.cores=7 \; --class org.broadinstitute.hellbender.Main \; --jar build/libs/gatk-all-4.pre-alpha-*-spark.jar \; KeyReadsSpark \; -I hdfs:///user/davidada/CEUTrio.HiSeq.WGS.b37.NA12878.bam \; --bps 4194304 \; --sparkMaster yarn-clien; ```. The important bits are the BAM (`gsutil cp gs://jpmartin/hellbender-test-inputs/CEUTrio.HiSeq.WGS.b37.NA12878.bam .` should work to grab it) and the bps being set to `4194304`. It doesn't happen with a different split. (Yet more evidence pointing to Hadoop-BAM). The bad record is on chromosome 1 and starts at 801305857. I imagine that making a small input would work to find this issue (instead of needing to use the 300 GB BAM). Assigning to Uri (I'd assign it to Tom, but I don't know when he's back).; If you need help cutting down that BAM @droazen and @lbergelson can give some advice.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1098
https://github.com/broadinstitute/gatk/issues/1098:715,Testability,test,test-inputs,715,"The symptom is that I'm getting an invalid record when using the Hadoop-BAM probabilistic splitter. I wrote a small program to verify the bug and the record it's happening on. To run this, check out da_key_bug and run something similar to my command. ```; gcloud beta dataproc jobs submit spark \; --cluster high-mem-16-8-sd \; --properties spark.executor.memory=38g,spark.executor.instances=15,spark.executor.cores=7 \; --class org.broadinstitute.hellbender.Main \; --jar build/libs/gatk-all-4.pre-alpha-*-spark.jar \; KeyReadsSpark \; -I hdfs:///user/davidada/CEUTrio.HiSeq.WGS.b37.NA12878.bam \; --bps 4194304 \; --sparkMaster yarn-clien; ```. The important bits are the BAM (`gsutil cp gs://jpmartin/hellbender-test-inputs/CEUTrio.HiSeq.WGS.b37.NA12878.bam .` should work to grab it) and the bps being set to `4194304`. It doesn't happen with a different split. (Yet more evidence pointing to Hadoop-BAM). The bad record is on chromosome 1 and starts at 801305857. I imagine that making a small input would work to find this issue (instead of needing to use the 300 GB BAM). Assigning to Uri (I'd assign it to Tom, but I don't know when he's back).; If you need help cutting down that BAM @droazen and @lbergelson can give some advice.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1098
https://github.com/broadinstitute/gatk/pull/1099:0,Usability,Simpl,Simplifies,0,Simplifies code and speeds up ApplyBQSR by ~50%. See https://github.com/broadinstitute/gatk/issues/1056 for some numbers,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1099
https://github.com/broadinstitute/gatk/issues/1100:124,Performance,optimiz,optimizations,124,"In the process of designing correctness tests for `MarkDuplicatesSpark`, @davidadamsphd has come up with a potential set of optimizations to `MarkDuplicatesSpark` that have the potential to improve performance by an order of magnitude. The task here is to meet with @davidadamsphd, get access to and understand his optimizations, and port them to the main `MarkDuplicatesSpark` tool (along with any other optimizations you feel are appropriate).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1100
https://github.com/broadinstitute/gatk/issues/1100:198,Performance,perform,performance,198,"In the process of designing correctness tests for `MarkDuplicatesSpark`, @davidadamsphd has come up with a potential set of optimizations to `MarkDuplicatesSpark` that have the potential to improve performance by an order of magnitude. The task here is to meet with @davidadamsphd, get access to and understand his optimizations, and port them to the main `MarkDuplicatesSpark` tool (along with any other optimizations you feel are appropriate).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1100
https://github.com/broadinstitute/gatk/issues/1100:315,Performance,optimiz,optimizations,315,"In the process of designing correctness tests for `MarkDuplicatesSpark`, @davidadamsphd has come up with a potential set of optimizations to `MarkDuplicatesSpark` that have the potential to improve performance by an order of magnitude. The task here is to meet with @davidadamsphd, get access to and understand his optimizations, and port them to the main `MarkDuplicatesSpark` tool (along with any other optimizations you feel are appropriate).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1100
https://github.com/broadinstitute/gatk/issues/1100:405,Performance,optimiz,optimizations,405,"In the process of designing correctness tests for `MarkDuplicatesSpark`, @davidadamsphd has come up with a potential set of optimizations to `MarkDuplicatesSpark` that have the potential to improve performance by an order of magnitude. The task here is to meet with @davidadamsphd, get access to and understand his optimizations, and port them to the main `MarkDuplicatesSpark` tool (along with any other optimizations you feel are appropriate).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1100
https://github.com/broadinstitute/gatk/issues/1100:286,Security,access,access,286,"In the process of designing correctness tests for `MarkDuplicatesSpark`, @davidadamsphd has come up with a potential set of optimizations to `MarkDuplicatesSpark` that have the potential to improve performance by an order of magnitude. The task here is to meet with @davidadamsphd, get access to and understand his optimizations, and port them to the main `MarkDuplicatesSpark` tool (along with any other optimizations you feel are appropriate).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1100
https://github.com/broadinstitute/gatk/issues/1100:40,Testability,test,tests,40,"In the process of designing correctness tests for `MarkDuplicatesSpark`, @davidadamsphd has come up with a potential set of optimizations to `MarkDuplicatesSpark` that have the potential to improve performance by an order of magnitude. The task here is to meet with @davidadamsphd, get access to and understand his optimizations, and port them to the main `MarkDuplicatesSpark` tool (along with any other optimizations you feel are appropriate).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1100
https://github.com/broadinstitute/gatk/issues/1104:6,Usability,simpl,simply,6,"First simply gather reads and their mates for evaluation, then we can evaluate whether to put them into a more compact data structure.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1104
https://github.com/broadinstitute/gatk/issues/1107:0,Security,Expose,Expose,0,Expose the attributes we set automatically in `SparkContextFactory` so they can be overridden by the user if necessary.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1107
https://github.com/broadinstitute/gatk/pull/1108:58,Safety,avoid,avoid,58,"updating our git lfs recommendation to a newer version to avoid the problems Geraldine had. fixes #952. <!-- Reviewable:start -->. [<img src=""https://reviewable.io/review_button.png"" height=40 alt=""Review on Reviewable""/>](https://reviewable.io/reviews/broadinstitute/gatk/1108). <!-- Reviewable:end -->",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1108
https://github.com/broadinstitute/gatk/pull/1109:45,Performance,cache,cache,45,"Modified FeatureCache to track the number of cache hits/misses over the; lifetime of each FeatureDataSource. Upon close, output these statistics; to logger.debug(). Tracking this information introduces almost zero overhead, but should be; useful on an ongoing basis as we add new tools to GATK4 and profile them.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1109
https://github.com/broadinstitute/gatk/pull/1109:149,Testability,log,logger,149,"Modified FeatureCache to track the number of cache hits/misses over the; lifetime of each FeatureDataSource. Upon close, output these statistics; to logger.debug(). Tracking this information introduces almost zero overhead, but should be; useful on an ongoing basis as we add new tools to GATK4 and profile them.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1109
https://github.com/broadinstitute/gatk/pull/1110:170,Testability,test,test,170,"PR #1068 had the unintended side effect of removing the method responsible for; stripping out SAMFileHeaders on Spark. This commit restores that method, and adds; a unit test to verify that all reads emitted by ReadSparkSource are headerless.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1110
https://github.com/broadinstitute/gatk/pull/1111:35,Performance,perform,performance,35,as seen in #1092 this improves the performance of variant walkers (at least SelectVariants). fixes #1092 ; quick one for @droazen,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1111
https://github.com/broadinstitute/gatk/issues/1112:29,Performance,perform,performance,29,We need to keep track of our performance so we can notice if a PR breaks performance. This issue is to remember to do this.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1112
https://github.com/broadinstitute/gatk/issues/1112:73,Performance,perform,performance,73,We need to keep track of our performance so we can notice if a PR breaks performance. This issue is to remember to do this.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1112
https://github.com/broadinstitute/gatk/issues/1113:71,Availability,error,errors,71,Our travis builds are getting killed intermittently with out-of-memory errors -- it's unclear whether it's the test suite JVM or the JVM with gradle that is getting killed. This is happening more and more often...,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1113
https://github.com/broadinstitute/gatk/issues/1113:111,Testability,test,test,111,Our travis builds are getting killed intermittently with out-of-memory errors -- it's unclear whether it's the test suite JVM or the JVM with gradle that is getting killed. This is happening more and more often...,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1113
https://github.com/broadinstitute/gatk/pull/1114:33,Performance,perform,performance,33,"Simple code changes that improve performance of BaseRecalibrator by ~20%. . NOTE: this is not related to removing indels. That will come later and is expected to improve performance further. According to my tests, we now beat GATK3 on the infamous first 10Mb of chr1 in CEUTrio.HiSeq.WGS.b37.NA12878.bam. @droazen can you review? some of those changes are similar to those in #1099",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1114
https://github.com/broadinstitute/gatk/pull/1114:170,Performance,perform,performance,170,"Simple code changes that improve performance of BaseRecalibrator by ~20%. . NOTE: this is not related to removing indels. That will come later and is expected to improve performance further. According to my tests, we now beat GATK3 on the infamous first 10Mb of chr1 in CEUTrio.HiSeq.WGS.b37.NA12878.bam. @droazen can you review? some of those changes are similar to those in #1099",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1114
https://github.com/broadinstitute/gatk/pull/1114:207,Testability,test,tests,207,"Simple code changes that improve performance of BaseRecalibrator by ~20%. . NOTE: this is not related to removing indels. That will come later and is expected to improve performance further. According to my tests, we now beat GATK3 on the infamous first 10Mb of chr1 in CEUTrio.HiSeq.WGS.b37.NA12878.bam. @droazen can you review? some of those changes are similar to those in #1099",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1114
https://github.com/broadinstitute/gatk/pull/1114:0,Usability,Simpl,Simple,0,"Simple code changes that improve performance of BaseRecalibrator by ~20%. . NOTE: this is not related to removing indels. That will come later and is expected to improve performance further. According to my tests, we now beat GATK3 on the infamous first 10Mb of chr1 in CEUTrio.HiSeq.WGS.b37.NA12878.bam. @droazen can you review? some of those changes are similar to those in #1099",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1114
https://github.com/broadinstitute/gatk/issues/1118:4,Testability,test,testPlottingWorkflow,4,the testPlottingWorkflow in BaseRecalibratorSparkIntegrationTest is disabled because it uses a bogus expected file. Needs to be fixed and reenabled,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1118
https://github.com/broadinstitute/gatk/issues/1119:172,Availability,mask,masking,172,BaseRecalibratorSparkOptimizedIntegrationTest.testBQSRLocal fails once we started doing stringent checks of results. It needs to be fixed. It may have something to do with masking of variants,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1119
https://github.com/broadinstitute/gatk/issues/1119:46,Testability,test,testBQSRLocal,46,BaseRecalibratorSparkOptimizedIntegrationTest.testBQSRLocal fails once we started doing stringent checks of results. It needs to be fixed. It may have something to do with masking of variants,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1119
https://github.com/broadinstitute/gatk/pull/1120:60,Integrability,depend,dependency,60,fixes #1117; note though that removing fastutil as a direct dependency does not remove it as a indirect one and so the code still compiles and runs. Removing the indirect dependency would be a much more heroic task,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1120
https://github.com/broadinstitute/gatk/pull/1120:171,Integrability,depend,dependency,171,fixes #1117; note though that removing fastutil as a direct dependency does not remove it as a indirect one and so the code still compiles and runs. Removing the indirect dependency would be a much more heroic task,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1120
https://github.com/broadinstitute/gatk/issues/1121:192,Usability,simpl,simply,192,Currently there is a FeatureWalker in hellbender-protected that could be moved to GATK4. In fact it would be a great parent (generalization) of the current VariantWalker as VariantContext are simply a feature.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1121
https://github.com/broadinstitute/gatk/issues/1123:67,Testability,log,log,67,"`ReadSparkSinkUnitTest.readsSinkADAMTest()` always writes an `adam.log` file to the hellbender root. We should figure out how to prevent this, or at least clean it up after tests run.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1123
https://github.com/broadinstitute/gatk/issues/1123:173,Testability,test,tests,173,"`ReadSparkSinkUnitTest.readsSinkADAMTest()` always writes an `adam.log` file to the hellbender root. We should figure out how to prevent this, or at least clean it up after tests run.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1123
https://github.com/broadinstitute/gatk/pull/1124:35,Testability,test,test,35,"set the maximum memory used by the test jvm to 2g. should prevent at least 1 cause of travis from falling over at random (fixes #1113), but since it's intermittent it's hard to tell if it's really fixed or not. <!-- Reviewable:start -->. [<img src=""https://reviewable.io/review_button.png"" height=40 alt=""Review on Reviewable""/>](https://reviewable.io/reviews/broadinstitute/gatk/1124). <!-- Reviewable:end -->",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1124
https://github.com/broadinstitute/gatk/pull/1126:79,Testability,test,test,79,"fixes #1078, note though that we ignore `useOriginalQualities` ( #1125) so the test changes slightly",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1126
https://github.com/broadinstitute/gatk/pull/1127:528,Integrability,interface,interface,528,"This change enables SAMRecordToGATKReadAdapterSerializer, which has been in the codebase for a while now, just not explicitly enabled. We've been using it for manual testing and haven't seen any problems with it. All unit tests pass. The performance improvement is striking: running mark duplicates locally went from ~120s to ~36s (https://github.com/broadinstitute/gatk/issues/1047). In terms of the change this makes, it means that the header is not present on SAMRecord, but since operations on reads go through the GATKRead interface (which does not need the header), the change is safe. Note also that SAMRecordToGATKReadAdapterSerializer explicitly serializes the reference name (and the mate reference name) so that the round trip serialization/deserialization works.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1127
https://github.com/broadinstitute/gatk/pull/1127:238,Performance,perform,performance,238,"This change enables SAMRecordToGATKReadAdapterSerializer, which has been in the codebase for a while now, just not explicitly enabled. We've been using it for manual testing and haven't seen any problems with it. All unit tests pass. The performance improvement is striking: running mark duplicates locally went from ~120s to ~36s (https://github.com/broadinstitute/gatk/issues/1047). In terms of the change this makes, it means that the header is not present on SAMRecord, but since operations on reads go through the GATKRead interface (which does not need the header), the change is safe. Note also that SAMRecordToGATKReadAdapterSerializer explicitly serializes the reference name (and the mate reference name) so that the round trip serialization/deserialization works.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1127
https://github.com/broadinstitute/gatk/pull/1127:586,Safety,safe,safe,586,"This change enables SAMRecordToGATKReadAdapterSerializer, which has been in the codebase for a while now, just not explicitly enabled. We've been using it for manual testing and haven't seen any problems with it. All unit tests pass. The performance improvement is striking: running mark duplicates locally went from ~120s to ~36s (https://github.com/broadinstitute/gatk/issues/1047). In terms of the change this makes, it means that the header is not present on SAMRecord, but since operations on reads go through the GATKRead interface (which does not need the header), the change is safe. Note also that SAMRecordToGATKReadAdapterSerializer explicitly serializes the reference name (and the mate reference name) so that the round trip serialization/deserialization works.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1127
https://github.com/broadinstitute/gatk/pull/1127:166,Testability,test,testing,166,"This change enables SAMRecordToGATKReadAdapterSerializer, which has been in the codebase for a while now, just not explicitly enabled. We've been using it for manual testing and haven't seen any problems with it. All unit tests pass. The performance improvement is striking: running mark duplicates locally went from ~120s to ~36s (https://github.com/broadinstitute/gatk/issues/1047). In terms of the change this makes, it means that the header is not present on SAMRecord, but since operations on reads go through the GATKRead interface (which does not need the header), the change is safe. Note also that SAMRecordToGATKReadAdapterSerializer explicitly serializes the reference name (and the mate reference name) so that the round trip serialization/deserialization works.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1127
https://github.com/broadinstitute/gatk/pull/1127:222,Testability,test,tests,222,"This change enables SAMRecordToGATKReadAdapterSerializer, which has been in the codebase for a while now, just not explicitly enabled. We've been using it for manual testing and haven't seen any problems with it. All unit tests pass. The performance improvement is striking: running mark duplicates locally went from ~120s to ~36s (https://github.com/broadinstitute/gatk/issues/1047). In terms of the change this makes, it means that the header is not present on SAMRecord, but since operations on reads go through the GATKRead interface (which does not need the header), the change is safe. Note also that SAMRecordToGATKReadAdapterSerializer explicitly serializes the reference name (and the mate reference name) so that the round trip serialization/deserialization works.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1127
https://github.com/broadinstitute/gatk/issues/1129:524,Performance,perform,performs,524,"`VariantFiltration` in GATK4 with clustered SNP filtering on is likely to underperform GATK3, as this results in queries against the driving source of variants both before and after the current variant, and we have caching turned off for the copy of the driving datasource added to the `FeatureManager` for querying (as our caching strategy for features is currently only able to look ahead). Task is to run `VariantFiltration` on both GATK3 and 4 with `--clusterSize` and `--clusterWindowSize`, record how much worse GATK4 performs for this use case, and (assuming it does lose to GATK3) create a **beta** ticket to fix it (not urgent enough for alpha).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1129
https://github.com/broadinstitute/gatk/issues/1130:205,Availability,error,error,205,"Only 2bit references load the reference data into memory and can be effectively broadcast -- need to add a check that we have a 2bit reference when using BROADCAST in `BaseRecalibratorSpark`, and throw an error with instructions on how to create one when we don't.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1130
https://github.com/broadinstitute/gatk/issues/1130:21,Performance,load,load,21,"Only 2bit references load the reference data into memory and can be effectively broadcast -- need to add a check that we have a 2bit reference when using BROADCAST in `BaseRecalibratorSpark`, and throw an error with instructions on how to create one when we don't.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1130
https://github.com/broadinstitute/gatk/issues/1133:27,Testability,test,test,27,Should include a CRAM file test.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1133
https://github.com/broadinstitute/gatk/issues/1135:15,Deployability,integrat,integrated,15,"It needs to be integrated with CRAMIndexer, and tests should be added for both BAM and CRAM.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1135
https://github.com/broadinstitute/gatk/issues/1135:15,Integrability,integrat,integrated,15,"It needs to be integrated with CRAMIndexer, and tests should be added for both BAM and CRAM.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1135
https://github.com/broadinstitute/gatk/issues/1135:48,Testability,test,tests,48,"It needs to be integrated with CRAMIndexer, and tests should be added for both BAM and CRAM.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1135
https://github.com/broadinstitute/gatk/issues/1138:273,Availability,avail,available,273,"there is one bug commented out in ValidateSamFileIntegrationTest. The issue is https://github.com/samtools/htsjdk/issues/369, the fix is in https://github.com/samtools/htsjdk/pull/368. SamFileValidator throws NPE on a CRAM file with an invalid sort order. Once that fix is available we can uncomment the test.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1138
https://github.com/broadinstitute/gatk/issues/1138:34,Security,Validat,ValidateSamFileIntegrationTest,34,"there is one bug commented out in ValidateSamFileIntegrationTest. The issue is https://github.com/samtools/htsjdk/issues/369, the fix is in https://github.com/samtools/htsjdk/pull/368. SamFileValidator throws NPE on a CRAM file with an invalid sort order. Once that fix is available we can uncomment the test.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1138
https://github.com/broadinstitute/gatk/issues/1138:304,Testability,test,test,304,"there is one bug commented out in ValidateSamFileIntegrationTest. The issue is https://github.com/samtools/htsjdk/issues/369, the fix is in https://github.com/samtools/htsjdk/pull/368. SamFileValidator throws NPE on a CRAM file with an invalid sort order. Once that fix is available we can uncomment the test.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1138
https://github.com/broadinstitute/gatk/issues/1141:9,Testability,test,tests,9,The CRAM tests in GatherBamFilesIntegrationTest are commented out because they fail without a fix to https://github.com/samtools/htsjdk/issues/365 (the presorted false flag is being ignored so htsjdk expects the reads to already be sorted). The fix is in https://github.com/samtools/htsjdk/pull/368. The GatherBamFilesIntegrationTest tests are not yet merged into master; they currently live in PR #1084.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1141
https://github.com/broadinstitute/gatk/issues/1141:334,Testability,test,tests,334,The CRAM tests in GatherBamFilesIntegrationTest are commented out because they fail without a fix to https://github.com/samtools/htsjdk/issues/365 (the presorted false flag is being ignored so htsjdk expects the reads to already be sorted). The fix is in https://github.com/samtools/htsjdk/pull/368. The GatherBamFilesIntegrationTest tests are not yet merged into master; they currently live in PR #1084.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1141
https://github.com/broadinstitute/gatk/issues/1143:194,Usability,clear,clearOptions,194,createVCFWriter currently has a workaround for a bug in htsjdk that is now fixed. The call to vcWriterBuilder.unsetOption(Options.INDEX_ON_THE_FLY) should be removed and replaced with a call to clearOptions (which used to break but was fixed in https://github.com/samtools/htsjdk/pull/354).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1143
https://github.com/broadinstitute/gatk/pull/1144:2,Availability,error,error,2,"- error messages will now include all the missing arguments when applicable; - error messages should be more readable; old style:. ```; $ hellbender PrintReads; ***********************************************************************. A USER ERROR has occurred: Invalid command line: Argument output was missing: Argument 'output' is required. ***********************************************************************; ```. new style:. ```; $ hellbender PrintReads; ***********************************************************************. A USER ERROR has occurred:. Invalid command line:; required argument --input was not specified; required argument --output was not specified. Rerun with --help to see more information on available options. ***********************************************************************; ```; - fixed a bug in CommandLineParser; - collection arguments that had a mutual exclusion field would be reported as missing even if one of the mutex arguments was present; - adding tests for this case; - some refactoring on CommandLineParser. fixes #418. <!-- Reviewable:start -->. [<img src=""https://reviewable.io/review_button.png"" height=40 alt=""Review on Reviewable""/>](https://reviewable.io/reviews/broadinstitute/gatk/1144). <!-- Reviewable:end -->",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1144
https://github.com/broadinstitute/gatk/pull/1144:79,Availability,error,error,79,"- error messages will now include all the missing arguments when applicable; - error messages should be more readable; old style:. ```; $ hellbender PrintReads; ***********************************************************************. A USER ERROR has occurred: Invalid command line: Argument output was missing: Argument 'output' is required. ***********************************************************************; ```. new style:. ```; $ hellbender PrintReads; ***********************************************************************. A USER ERROR has occurred:. Invalid command line:; required argument --input was not specified; required argument --output was not specified. Rerun with --help to see more information on available options. ***********************************************************************; ```; - fixed a bug in CommandLineParser; - collection arguments that had a mutual exclusion field would be reported as missing even if one of the mutex arguments was present; - adding tests for this case; - some refactoring on CommandLineParser. fixes #418. <!-- Reviewable:start -->. [<img src=""https://reviewable.io/review_button.png"" height=40 alt=""Review on Reviewable""/>](https://reviewable.io/reviews/broadinstitute/gatk/1144). <!-- Reviewable:end -->",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1144
https://github.com/broadinstitute/gatk/pull/1144:241,Availability,ERROR,ERROR,241,"- error messages will now include all the missing arguments when applicable; - error messages should be more readable; old style:. ```; $ hellbender PrintReads; ***********************************************************************. A USER ERROR has occurred: Invalid command line: Argument output was missing: Argument 'output' is required. ***********************************************************************; ```. new style:. ```; $ hellbender PrintReads; ***********************************************************************. A USER ERROR has occurred:. Invalid command line:; required argument --input was not specified; required argument --output was not specified. Rerun with --help to see more information on available options. ***********************************************************************; ```; - fixed a bug in CommandLineParser; - collection arguments that had a mutual exclusion field would be reported as missing even if one of the mutex arguments was present; - adding tests for this case; - some refactoring on CommandLineParser. fixes #418. <!-- Reviewable:start -->. [<img src=""https://reviewable.io/review_button.png"" height=40 alt=""Review on Reviewable""/>](https://reviewable.io/reviews/broadinstitute/gatk/1144). <!-- Reviewable:end -->",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1144
https://github.com/broadinstitute/gatk/pull/1144:543,Availability,ERROR,ERROR,543,"- error messages will now include all the missing arguments when applicable; - error messages should be more readable; old style:. ```; $ hellbender PrintReads; ***********************************************************************. A USER ERROR has occurred: Invalid command line: Argument output was missing: Argument 'output' is required. ***********************************************************************; ```. new style:. ```; $ hellbender PrintReads; ***********************************************************************. A USER ERROR has occurred:. Invalid command line:; required argument --input was not specified; required argument --output was not specified. Rerun with --help to see more information on available options. ***********************************************************************; ```; - fixed a bug in CommandLineParser; - collection arguments that had a mutual exclusion field would be reported as missing even if one of the mutex arguments was present; - adding tests for this case; - some refactoring on CommandLineParser. fixes #418. <!-- Reviewable:start -->. [<img src=""https://reviewable.io/review_button.png"" height=40 alt=""Review on Reviewable""/>](https://reviewable.io/reviews/broadinstitute/gatk/1144). <!-- Reviewable:end -->",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1144
https://github.com/broadinstitute/gatk/pull/1144:723,Availability,avail,available,723,"- error messages will now include all the missing arguments when applicable; - error messages should be more readable; old style:. ```; $ hellbender PrintReads; ***********************************************************************. A USER ERROR has occurred: Invalid command line: Argument output was missing: Argument 'output' is required. ***********************************************************************; ```. new style:. ```; $ hellbender PrintReads; ***********************************************************************. A USER ERROR has occurred:. Invalid command line:; required argument --input was not specified; required argument --output was not specified. Rerun with --help to see more information on available options. ***********************************************************************; ```; - fixed a bug in CommandLineParser; - collection arguments that had a mutual exclusion field would be reported as missing even if one of the mutex arguments was present; - adding tests for this case; - some refactoring on CommandLineParser. fixes #418. <!-- Reviewable:start -->. [<img src=""https://reviewable.io/review_button.png"" height=40 alt=""Review on Reviewable""/>](https://reviewable.io/reviews/broadinstitute/gatk/1144). <!-- Reviewable:end -->",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1144
https://github.com/broadinstitute/gatk/pull/1144:8,Integrability,message,messages,8,"- error messages will now include all the missing arguments when applicable; - error messages should be more readable; old style:. ```; $ hellbender PrintReads; ***********************************************************************. A USER ERROR has occurred: Invalid command line: Argument output was missing: Argument 'output' is required. ***********************************************************************; ```. new style:. ```; $ hellbender PrintReads; ***********************************************************************. A USER ERROR has occurred:. Invalid command line:; required argument --input was not specified; required argument --output was not specified. Rerun with --help to see more information on available options. ***********************************************************************; ```; - fixed a bug in CommandLineParser; - collection arguments that had a mutual exclusion field would be reported as missing even if one of the mutex arguments was present; - adding tests for this case; - some refactoring on CommandLineParser. fixes #418. <!-- Reviewable:start -->. [<img src=""https://reviewable.io/review_button.png"" height=40 alt=""Review on Reviewable""/>](https://reviewable.io/reviews/broadinstitute/gatk/1144). <!-- Reviewable:end -->",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1144
https://github.com/broadinstitute/gatk/pull/1144:85,Integrability,message,messages,85,"- error messages will now include all the missing arguments when applicable; - error messages should be more readable; old style:. ```; $ hellbender PrintReads; ***********************************************************************. A USER ERROR has occurred: Invalid command line: Argument output was missing: Argument 'output' is required. ***********************************************************************; ```. new style:. ```; $ hellbender PrintReads; ***********************************************************************. A USER ERROR has occurred:. Invalid command line:; required argument --input was not specified; required argument --output was not specified. Rerun with --help to see more information on available options. ***********************************************************************; ```; - fixed a bug in CommandLineParser; - collection arguments that had a mutual exclusion field would be reported as missing even if one of the mutex arguments was present; - adding tests for this case; - some refactoring on CommandLineParser. fixes #418. <!-- Reviewable:start -->. [<img src=""https://reviewable.io/review_button.png"" height=40 alt=""Review on Reviewable""/>](https://reviewable.io/reviews/broadinstitute/gatk/1144). <!-- Reviewable:end -->",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1144
https://github.com/broadinstitute/gatk/pull/1144:1027,Modifiability,refactor,refactoring,1027,"- error messages will now include all the missing arguments when applicable; - error messages should be more readable; old style:. ```; $ hellbender PrintReads; ***********************************************************************. A USER ERROR has occurred: Invalid command line: Argument output was missing: Argument 'output' is required. ***********************************************************************; ```. new style:. ```; $ hellbender PrintReads; ***********************************************************************. A USER ERROR has occurred:. Invalid command line:; required argument --input was not specified; required argument --output was not specified. Rerun with --help to see more information on available options. ***********************************************************************; ```; - fixed a bug in CommandLineParser; - collection arguments that had a mutual exclusion field would be reported as missing even if one of the mutex arguments was present; - adding tests for this case; - some refactoring on CommandLineParser. fixes #418. <!-- Reviewable:start -->. [<img src=""https://reviewable.io/review_button.png"" height=40 alt=""Review on Reviewable""/>](https://reviewable.io/reviews/broadinstitute/gatk/1144). <!-- Reviewable:end -->",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1144
https://github.com/broadinstitute/gatk/pull/1144:999,Testability,test,tests,999,"- error messages will now include all the missing arguments when applicable; - error messages should be more readable; old style:. ```; $ hellbender PrintReads; ***********************************************************************. A USER ERROR has occurred: Invalid command line: Argument output was missing: Argument 'output' is required. ***********************************************************************; ```. new style:. ```; $ hellbender PrintReads; ***********************************************************************. A USER ERROR has occurred:. Invalid command line:; required argument --input was not specified; required argument --output was not specified. Rerun with --help to see more information on available options. ***********************************************************************; ```; - fixed a bug in CommandLineParser; - collection arguments that had a mutual exclusion field would be reported as missing even if one of the mutex arguments was present; - adding tests for this case; - some refactoring on CommandLineParser. fixes #418. <!-- Reviewable:start -->. [<img src=""https://reviewable.io/review_button.png"" height=40 alt=""Review on Reviewable""/>](https://reviewable.io/reviews/broadinstitute/gatk/1144). <!-- Reviewable:end -->",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1144
https://github.com/broadinstitute/gatk/issues/1150:1664,Testability,test,tests,1664,"r BAM` should be changed to SAM/BAM/CRAM; - [x] all metrics that have names matching `Collect*Metrics` should have the same form of a doc. Now it's all messy, eg `Produces from a SAM or BAM a file containing summary alignment metrics` vs `Writes insert size distribution metrics for a SAM or BAM file` vs `Produces jumping library metrics for the provided SAM/BAMs`; - [x] note, normally, we'd rename all metrics to have the same form of name but let's wait until picard is sync'd up; - [x] note, normally we'd rename all commands that mention 'Sam` to something more accurate but we're waiting for picard sync up; - [x] ApplyBQSR can also work on SAM and CRAM but doc says `Applies the BQSR table to the input BAM`; - [x] some entries has periods at the end, some don't. Make them the same (no periods); - [x] add works BQSR to doc of `BaseRecalibrator` and `AnalyzeCovariates`; - [x] CountBases should say more than `Count bases`; - [x] CountReads should say more than `Count reads`; - [x] PrintReads should say more than `Print reads`; - [x] LeftAlignIndels should capitalize `bam` in doc; - [x] `Spark tests: Programs to test out Apache Spark` should be less about tests and more about 'spark-enabled implementation of tools'. Somethng like that; - [x] `ApplyBQSRSpark apply BQSR on spark` -> `ApplyBQSR on Spark`; - [x] `BQSRPipelineSpark Both steps of BQSR` - what steps?; - [x] both BaseRecalibratorSpark and BaseRecalibratorSparkOptimized say `Generates recalibration table`; - [x] I think all Spark tools can just have doc saying `TOOLNAMe on Spark` if it's all they are; - [x] `CountVariants Count variants` - counts them where?; - [x] ExampleReadWalkerWithVariants should be in the BAM/CRAM/SAM group'; - [x] ExampleVariantWalker add 'example' to its doc; - [x] IndexFeatureFile `Creates indices for Feature-containing files` is too cryptic; - [x] LiftoverVcf - all tools for liftover should use the same language. Now each one describes it differently; - [x] i think we should remove all m",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1150
https://github.com/broadinstitute/gatk/issues/1150:1683,Testability,test,test,1683,"r BAM` should be changed to SAM/BAM/CRAM; - [x] all metrics that have names matching `Collect*Metrics` should have the same form of a doc. Now it's all messy, eg `Produces from a SAM or BAM a file containing summary alignment metrics` vs `Writes insert size distribution metrics for a SAM or BAM file` vs `Produces jumping library metrics for the provided SAM/BAMs`; - [x] note, normally, we'd rename all metrics to have the same form of name but let's wait until picard is sync'd up; - [x] note, normally we'd rename all commands that mention 'Sam` to something more accurate but we're waiting for picard sync up; - [x] ApplyBQSR can also work on SAM and CRAM but doc says `Applies the BQSR table to the input BAM`; - [x] some entries has periods at the end, some don't. Make them the same (no periods); - [x] add works BQSR to doc of `BaseRecalibrator` and `AnalyzeCovariates`; - [x] CountBases should say more than `Count bases`; - [x] CountReads should say more than `Count reads`; - [x] PrintReads should say more than `Print reads`; - [x] LeftAlignIndels should capitalize `bam` in doc; - [x] `Spark tests: Programs to test out Apache Spark` should be less about tests and more about 'spark-enabled implementation of tools'. Somethng like that; - [x] `ApplyBQSRSpark apply BQSR on spark` -> `ApplyBQSR on Spark`; - [x] `BQSRPipelineSpark Both steps of BQSR` - what steps?; - [x] both BaseRecalibratorSpark and BaseRecalibratorSparkOptimized say `Generates recalibration table`; - [x] I think all Spark tools can just have doc saying `TOOLNAMe on Spark` if it's all they are; - [x] `CountVariants Count variants` - counts them where?; - [x] ExampleReadWalkerWithVariants should be in the BAM/CRAM/SAM group'; - [x] ExampleVariantWalker add 'example' to its doc; - [x] IndexFeatureFile `Creates indices for Feature-containing files` is too cryptic; - [x] LiftoverVcf - all tools for liftover should use the same language. Now each one describes it differently; - [x] i think we should remove all m",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1150
https://github.com/broadinstitute/gatk/issues/1150:1727,Testability,test,tests,1727,"r BAM` should be changed to SAM/BAM/CRAM; - [x] all metrics that have names matching `Collect*Metrics` should have the same form of a doc. Now it's all messy, eg `Produces from a SAM or BAM a file containing summary alignment metrics` vs `Writes insert size distribution metrics for a SAM or BAM file` vs `Produces jumping library metrics for the provided SAM/BAMs`; - [x] note, normally, we'd rename all metrics to have the same form of name but let's wait until picard is sync'd up; - [x] note, normally we'd rename all commands that mention 'Sam` to something more accurate but we're waiting for picard sync up; - [x] ApplyBQSR can also work on SAM and CRAM but doc says `Applies the BQSR table to the input BAM`; - [x] some entries has periods at the end, some don't. Make them the same (no periods); - [x] add works BQSR to doc of `BaseRecalibrator` and `AnalyzeCovariates`; - [x] CountBases should say more than `Count bases`; - [x] CountReads should say more than `Count reads`; - [x] PrintReads should say more than `Print reads`; - [x] LeftAlignIndels should capitalize `bam` in doc; - [x] `Spark tests: Programs to test out Apache Spark` should be less about tests and more about 'spark-enabled implementation of tools'. Somethng like that; - [x] `ApplyBQSRSpark apply BQSR on spark` -> `ApplyBQSR on Spark`; - [x] `BQSRPipelineSpark Both steps of BQSR` - what steps?; - [x] both BaseRecalibratorSpark and BaseRecalibratorSparkOptimized say `Generates recalibration table`; - [x] I think all Spark tools can just have doc saying `TOOLNAMe on Spark` if it's all they are; - [x] `CountVariants Count variants` - counts them where?; - [x] ExampleReadWalkerWithVariants should be in the BAM/CRAM/SAM group'; - [x] ExampleVariantWalker add 'example' to its doc; - [x] IndexFeatureFile `Creates indices for Feature-containing files` is too cryptic; - [x] LiftoverVcf - all tools for liftover should use the same language. Now each one describes it differently; - [x] i think we should remove all m",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1150
https://github.com/broadinstitute/gatk/issues/1151:104,Performance,cache,cached,104,see #1129 - we're slower on VariantFiltration with cluster options because the driving variants are not cached,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1151
https://github.com/broadinstitute/gatk/pull/1152:60,Availability,error,errors,60,fixes #1140 (extracts file names to name constants to avoid errors and indicate where same outputs are expected). for @droazen,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1152
https://github.com/broadinstitute/gatk/pull/1152:54,Safety,avoid,avoid,54,fixes #1140 (extracts file names to name constants to avoid errors and indicate where same outputs are expected). for @droazen,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1152
https://github.com/broadinstitute/gatk/pull/1153:260,Deployability,update,updates,260,This brings in recently-merged changes related to headerless SAMRecords; that are needed in order to enable the faster SAMRecord serializer; (SAMRecordToGATKReadAdapterSerializer). Temporarily disabled the SAMRecordToGATKReadAdapterSerializerUnitTest; pending updates in PR #1127.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1153
https://github.com/broadinstitute/gatk/issues/1154:18,Deployability,release,release,18,once a new htsjdk release comes out we should switch off relying on since #1153,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1154
https://github.com/broadinstitute/gatk/issues/1155:145,Modifiability,variab,variables,145,"In `PicardCommandLineProgram` there is an `instanceMain` that gets called when a subclass program is called. This ""main"" sets a number of static variables to values parsed from the arguments, then calls `super.instanceMain`. The problem is that the values haven't been parsed before they are referenced in this function, so the default values are _always_ used. The ignored flags are:; - `VALIDATION_STRINGENCY`; - `COMPRESSION_LEVEL`; - `MAX_RECORDS_IN_RAM`; - `CREATE_INDEX`; - `CREATE_MD5_FILE`. These flags are ignored for _all_ Picard tools, of which we have dozens. A rough sketch of the solution is here:; https://github.com/broadinstitute/gatk/compare/da_fix_picard; If this seems like a reasonable approach, I'll retake the bug and fix this.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1155
https://github.com/broadinstitute/gatk/pull/1156:77,Availability,failure,failure,77,… test. partial fix for #1042 - reenabled testStackOverFlowPairSetSwap - the failure was due to scoring strategy using by picard (total ref bases) vs spark (sum of quals). Spark did not even have a pluggable scoring strategy. Now it does and the test passes. For @davidadamsphd,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1156
https://github.com/broadinstitute/gatk/pull/1156:2,Testability,test,test,2,… test. partial fix for #1042 - reenabled testStackOverFlowPairSetSwap - the failure was due to scoring strategy using by picard (total ref bases) vs spark (sum of quals). Spark did not even have a pluggable scoring strategy. Now it does and the test passes. For @davidadamsphd,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1156
https://github.com/broadinstitute/gatk/pull/1156:42,Testability,test,testStackOverFlowPairSetSwap,42,… test. partial fix for #1042 - reenabled testStackOverFlowPairSetSwap - the failure was due to scoring strategy using by picard (total ref bases) vs spark (sum of quals). Spark did not even have a pluggable scoring strategy. Now it does and the test passes. For @davidadamsphd,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1156
https://github.com/broadinstitute/gatk/pull/1156:246,Testability,test,test,246,… test. partial fix for #1042 - reenabled testStackOverFlowPairSetSwap - the failure was due to scoring strategy using by picard (total ref bases) vs spark (sum of quals). Spark did not even have a pluggable scoring strategy. Now it does and the test passes. For @davidadamsphd,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1156
https://github.com/broadinstitute/gatk/pull/1159:113,Modifiability,inherit,inherited,113,"Most ReadWalkers apply the WellformedReadFilter, but their spark equivalents; were not doing so. This creates an inherited method GATKSparkTool.makeReadFilter(); that defaults to the WellformedReadFilter and gets automatically applied to the; RDD of reads returned from GATKSparkTool.getReads(). Only BaseRecalibratorSpark needed to override this method to apply a custom; read filter in order to match the walker filtering settings. Resolves #1158",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1159
https://github.com/broadinstitute/gatk/pull/1161:20,Testability,test,tests,20,fix for 2 remaining tests in https://github.com/broadinstitute/gatk/issues/1042. It introduces (from picard) the RF/FR orientation for pairs for marking optical dups.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1161
https://github.com/broadinstitute/gatk/issues/1163:253,Deployability,integrat,integrated,253,"GatherBAMFiles and some other tools use BamFileIoUtils.gatherWithBlockCopying to do block transfer of BAM file blocks, but degenerate to decoding individual records for CRAM. A similar optimization should be able to be done for CRAM containers and then integrated with those tools.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1163
https://github.com/broadinstitute/gatk/issues/1163:253,Integrability,integrat,integrated,253,"GatherBAMFiles and some other tools use BamFileIoUtils.gatherWithBlockCopying to do block transfer of BAM file blocks, but degenerate to decoding individual records for CRAM. A similar optimization should be able to be done for CRAM containers and then integrated with those tools.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1163
https://github.com/broadinstitute/gatk/issues/1163:185,Performance,optimiz,optimization,185,"GatherBAMFiles and some other tools use BamFileIoUtils.gatherWithBlockCopying to do block transfer of BAM file blocks, but degenerate to decoding individual records for CRAM. A similar optimization should be able to be done for CRAM containers and then integrated with those tools.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1163
https://github.com/broadinstitute/gatk/issues/1164:822,Deployability,Integrat,IntegrationTestSpec,822,"I discovered some strange behavior in our test suite. This test in `PrintReadsSparkIntegrationTest` passes:. ```; @Test; public void testReadFiltering() throws IOException {; final File samWithOneMalformedRead = new File(getTestDataDir(), ""print_reads_one_malformed_read.sam"");; final File outBam = createTempFile(""print_reads_testReadFiltering"", "".bam"");. ArgumentsBuilder args = new ArgumentsBuilder();; args.add(""--"" + StandardArgumentDefinitions.INPUT_LONG_NAME);; args.add(samWithOneMalformedRead.getCanonicalPath());; args.add(""--"" + StandardArgumentDefinitions.OUTPUT_LONG_NAME);; args.add(outBam.getCanonicalPath());. runCommandLine(args.getArgsArray());; SamAssertionUtils.assertSamsEqual(outBam, new File(getTestDataDir(), ""expected.print_reads_one_malformed_read.bam""));; }; ```. But if you re-write it to use `IntegrationTestSpec` with the same input, output, and expected file, it fails with `Sort order differs. File 1: nullFile 2: coordinate`:. ```; @Test; public void testReadFiltering() throws IOException {; final File samWithOneMalformedRead = new File(getTestDataDir(), ""print_reads_one_malformed_read.sam"");; final File outBam = createTempFile(""print_reads_testReadFiltering"", "".bam"");. final IntegrationTestSpec spec = new IntegrationTestSpec(; "" --"" + StandardArgumentDefinitions.INPUT_LONG_NAME + "" "" + samWithOneMalformedRead.getCanonicalPath() +; "" --"" + StandardArgumentDefinitions.OUTPUT_LONG_NAME + "" "" + outBam.getCanonicalPath(),; Arrays.asList(new File(getTestDataDir(), ""expected.print_reads_one_malformed_read.bam"").getCanonicalPath()); );. spec.executeTest(""PrintReadsSpark_testReadFiltering"", this);; }; ```. Possibly this is indicative of a bug in `IntegrationTestSpec`?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1164
https://github.com/broadinstitute/gatk/issues/1164:1214,Deployability,Integrat,IntegrationTestSpec,1214,"I discovered some strange behavior in our test suite. This test in `PrintReadsSparkIntegrationTest` passes:. ```; @Test; public void testReadFiltering() throws IOException {; final File samWithOneMalformedRead = new File(getTestDataDir(), ""print_reads_one_malformed_read.sam"");; final File outBam = createTempFile(""print_reads_testReadFiltering"", "".bam"");. ArgumentsBuilder args = new ArgumentsBuilder();; args.add(""--"" + StandardArgumentDefinitions.INPUT_LONG_NAME);; args.add(samWithOneMalformedRead.getCanonicalPath());; args.add(""--"" + StandardArgumentDefinitions.OUTPUT_LONG_NAME);; args.add(outBam.getCanonicalPath());. runCommandLine(args.getArgsArray());; SamAssertionUtils.assertSamsEqual(outBam, new File(getTestDataDir(), ""expected.print_reads_one_malformed_read.bam""));; }; ```. But if you re-write it to use `IntegrationTestSpec` with the same input, output, and expected file, it fails with `Sort order differs. File 1: nullFile 2: coordinate`:. ```; @Test; public void testReadFiltering() throws IOException {; final File samWithOneMalformedRead = new File(getTestDataDir(), ""print_reads_one_malformed_read.sam"");; final File outBam = createTempFile(""print_reads_testReadFiltering"", "".bam"");. final IntegrationTestSpec spec = new IntegrationTestSpec(; "" --"" + StandardArgumentDefinitions.INPUT_LONG_NAME + "" "" + samWithOneMalformedRead.getCanonicalPath() +; "" --"" + StandardArgumentDefinitions.OUTPUT_LONG_NAME + "" "" + outBam.getCanonicalPath(),; Arrays.asList(new File(getTestDataDir(), ""expected.print_reads_one_malformed_read.bam"").getCanonicalPath()); );. spec.executeTest(""PrintReadsSpark_testReadFiltering"", this);; }; ```. Possibly this is indicative of a bug in `IntegrationTestSpec`?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1164
https://github.com/broadinstitute/gatk/issues/1164:1245,Deployability,Integrat,IntegrationTestSpec,1245,"I discovered some strange behavior in our test suite. This test in `PrintReadsSparkIntegrationTest` passes:. ```; @Test; public void testReadFiltering() throws IOException {; final File samWithOneMalformedRead = new File(getTestDataDir(), ""print_reads_one_malformed_read.sam"");; final File outBam = createTempFile(""print_reads_testReadFiltering"", "".bam"");. ArgumentsBuilder args = new ArgumentsBuilder();; args.add(""--"" + StandardArgumentDefinitions.INPUT_LONG_NAME);; args.add(samWithOneMalformedRead.getCanonicalPath());; args.add(""--"" + StandardArgumentDefinitions.OUTPUT_LONG_NAME);; args.add(outBam.getCanonicalPath());. runCommandLine(args.getArgsArray());; SamAssertionUtils.assertSamsEqual(outBam, new File(getTestDataDir(), ""expected.print_reads_one_malformed_read.bam""));; }; ```. But if you re-write it to use `IntegrationTestSpec` with the same input, output, and expected file, it fails with `Sort order differs. File 1: nullFile 2: coordinate`:. ```; @Test; public void testReadFiltering() throws IOException {; final File samWithOneMalformedRead = new File(getTestDataDir(), ""print_reads_one_malformed_read.sam"");; final File outBam = createTempFile(""print_reads_testReadFiltering"", "".bam"");. final IntegrationTestSpec spec = new IntegrationTestSpec(; "" --"" + StandardArgumentDefinitions.INPUT_LONG_NAME + "" "" + samWithOneMalformedRead.getCanonicalPath() +; "" --"" + StandardArgumentDefinitions.OUTPUT_LONG_NAME + "" "" + outBam.getCanonicalPath(),; Arrays.asList(new File(getTestDataDir(), ""expected.print_reads_one_malformed_read.bam"").getCanonicalPath()); );. spec.executeTest(""PrintReadsSpark_testReadFiltering"", this);; }; ```. Possibly this is indicative of a bug in `IntegrationTestSpec`?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1164
https://github.com/broadinstitute/gatk/issues/1164:1686,Deployability,Integrat,IntegrationTestSpec,1686,"I discovered some strange behavior in our test suite. This test in `PrintReadsSparkIntegrationTest` passes:. ```; @Test; public void testReadFiltering() throws IOException {; final File samWithOneMalformedRead = new File(getTestDataDir(), ""print_reads_one_malformed_read.sam"");; final File outBam = createTempFile(""print_reads_testReadFiltering"", "".bam"");. ArgumentsBuilder args = new ArgumentsBuilder();; args.add(""--"" + StandardArgumentDefinitions.INPUT_LONG_NAME);; args.add(samWithOneMalformedRead.getCanonicalPath());; args.add(""--"" + StandardArgumentDefinitions.OUTPUT_LONG_NAME);; args.add(outBam.getCanonicalPath());. runCommandLine(args.getArgsArray());; SamAssertionUtils.assertSamsEqual(outBam, new File(getTestDataDir(), ""expected.print_reads_one_malformed_read.bam""));; }; ```. But if you re-write it to use `IntegrationTestSpec` with the same input, output, and expected file, it fails with `Sort order differs. File 1: nullFile 2: coordinate`:. ```; @Test; public void testReadFiltering() throws IOException {; final File samWithOneMalformedRead = new File(getTestDataDir(), ""print_reads_one_malformed_read.sam"");; final File outBam = createTempFile(""print_reads_testReadFiltering"", "".bam"");. final IntegrationTestSpec spec = new IntegrationTestSpec(; "" --"" + StandardArgumentDefinitions.INPUT_LONG_NAME + "" "" + samWithOneMalformedRead.getCanonicalPath() +; "" --"" + StandardArgumentDefinitions.OUTPUT_LONG_NAME + "" "" + outBam.getCanonicalPath(),; Arrays.asList(new File(getTestDataDir(), ""expected.print_reads_one_malformed_read.bam"").getCanonicalPath()); );. spec.executeTest(""PrintReadsSpark_testReadFiltering"", this);; }; ```. Possibly this is indicative of a bug in `IntegrationTestSpec`?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1164
https://github.com/broadinstitute/gatk/issues/1164:822,Integrability,Integrat,IntegrationTestSpec,822,"I discovered some strange behavior in our test suite. This test in `PrintReadsSparkIntegrationTest` passes:. ```; @Test; public void testReadFiltering() throws IOException {; final File samWithOneMalformedRead = new File(getTestDataDir(), ""print_reads_one_malformed_read.sam"");; final File outBam = createTempFile(""print_reads_testReadFiltering"", "".bam"");. ArgumentsBuilder args = new ArgumentsBuilder();; args.add(""--"" + StandardArgumentDefinitions.INPUT_LONG_NAME);; args.add(samWithOneMalformedRead.getCanonicalPath());; args.add(""--"" + StandardArgumentDefinitions.OUTPUT_LONG_NAME);; args.add(outBam.getCanonicalPath());. runCommandLine(args.getArgsArray());; SamAssertionUtils.assertSamsEqual(outBam, new File(getTestDataDir(), ""expected.print_reads_one_malformed_read.bam""));; }; ```. But if you re-write it to use `IntegrationTestSpec` with the same input, output, and expected file, it fails with `Sort order differs. File 1: nullFile 2: coordinate`:. ```; @Test; public void testReadFiltering() throws IOException {; final File samWithOneMalformedRead = new File(getTestDataDir(), ""print_reads_one_malformed_read.sam"");; final File outBam = createTempFile(""print_reads_testReadFiltering"", "".bam"");. final IntegrationTestSpec spec = new IntegrationTestSpec(; "" --"" + StandardArgumentDefinitions.INPUT_LONG_NAME + "" "" + samWithOneMalformedRead.getCanonicalPath() +; "" --"" + StandardArgumentDefinitions.OUTPUT_LONG_NAME + "" "" + outBam.getCanonicalPath(),; Arrays.asList(new File(getTestDataDir(), ""expected.print_reads_one_malformed_read.bam"").getCanonicalPath()); );. spec.executeTest(""PrintReadsSpark_testReadFiltering"", this);; }; ```. Possibly this is indicative of a bug in `IntegrationTestSpec`?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1164
https://github.com/broadinstitute/gatk/issues/1164:1214,Integrability,Integrat,IntegrationTestSpec,1214,"I discovered some strange behavior in our test suite. This test in `PrintReadsSparkIntegrationTest` passes:. ```; @Test; public void testReadFiltering() throws IOException {; final File samWithOneMalformedRead = new File(getTestDataDir(), ""print_reads_one_malformed_read.sam"");; final File outBam = createTempFile(""print_reads_testReadFiltering"", "".bam"");. ArgumentsBuilder args = new ArgumentsBuilder();; args.add(""--"" + StandardArgumentDefinitions.INPUT_LONG_NAME);; args.add(samWithOneMalformedRead.getCanonicalPath());; args.add(""--"" + StandardArgumentDefinitions.OUTPUT_LONG_NAME);; args.add(outBam.getCanonicalPath());. runCommandLine(args.getArgsArray());; SamAssertionUtils.assertSamsEqual(outBam, new File(getTestDataDir(), ""expected.print_reads_one_malformed_read.bam""));; }; ```. But if you re-write it to use `IntegrationTestSpec` with the same input, output, and expected file, it fails with `Sort order differs. File 1: nullFile 2: coordinate`:. ```; @Test; public void testReadFiltering() throws IOException {; final File samWithOneMalformedRead = new File(getTestDataDir(), ""print_reads_one_malformed_read.sam"");; final File outBam = createTempFile(""print_reads_testReadFiltering"", "".bam"");. final IntegrationTestSpec spec = new IntegrationTestSpec(; "" --"" + StandardArgumentDefinitions.INPUT_LONG_NAME + "" "" + samWithOneMalformedRead.getCanonicalPath() +; "" --"" + StandardArgumentDefinitions.OUTPUT_LONG_NAME + "" "" + outBam.getCanonicalPath(),; Arrays.asList(new File(getTestDataDir(), ""expected.print_reads_one_malformed_read.bam"").getCanonicalPath()); );. spec.executeTest(""PrintReadsSpark_testReadFiltering"", this);; }; ```. Possibly this is indicative of a bug in `IntegrationTestSpec`?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1164
https://github.com/broadinstitute/gatk/issues/1164:1245,Integrability,Integrat,IntegrationTestSpec,1245,"I discovered some strange behavior in our test suite. This test in `PrintReadsSparkIntegrationTest` passes:. ```; @Test; public void testReadFiltering() throws IOException {; final File samWithOneMalformedRead = new File(getTestDataDir(), ""print_reads_one_malformed_read.sam"");; final File outBam = createTempFile(""print_reads_testReadFiltering"", "".bam"");. ArgumentsBuilder args = new ArgumentsBuilder();; args.add(""--"" + StandardArgumentDefinitions.INPUT_LONG_NAME);; args.add(samWithOneMalformedRead.getCanonicalPath());; args.add(""--"" + StandardArgumentDefinitions.OUTPUT_LONG_NAME);; args.add(outBam.getCanonicalPath());. runCommandLine(args.getArgsArray());; SamAssertionUtils.assertSamsEqual(outBam, new File(getTestDataDir(), ""expected.print_reads_one_malformed_read.bam""));; }; ```. But if you re-write it to use `IntegrationTestSpec` with the same input, output, and expected file, it fails with `Sort order differs. File 1: nullFile 2: coordinate`:. ```; @Test; public void testReadFiltering() throws IOException {; final File samWithOneMalformedRead = new File(getTestDataDir(), ""print_reads_one_malformed_read.sam"");; final File outBam = createTempFile(""print_reads_testReadFiltering"", "".bam"");. final IntegrationTestSpec spec = new IntegrationTestSpec(; "" --"" + StandardArgumentDefinitions.INPUT_LONG_NAME + "" "" + samWithOneMalformedRead.getCanonicalPath() +; "" --"" + StandardArgumentDefinitions.OUTPUT_LONG_NAME + "" "" + outBam.getCanonicalPath(),; Arrays.asList(new File(getTestDataDir(), ""expected.print_reads_one_malformed_read.bam"").getCanonicalPath()); );. spec.executeTest(""PrintReadsSpark_testReadFiltering"", this);; }; ```. Possibly this is indicative of a bug in `IntegrationTestSpec`?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1164
https://github.com/broadinstitute/gatk/issues/1164:1686,Integrability,Integrat,IntegrationTestSpec,1686,"I discovered some strange behavior in our test suite. This test in `PrintReadsSparkIntegrationTest` passes:. ```; @Test; public void testReadFiltering() throws IOException {; final File samWithOneMalformedRead = new File(getTestDataDir(), ""print_reads_one_malformed_read.sam"");; final File outBam = createTempFile(""print_reads_testReadFiltering"", "".bam"");. ArgumentsBuilder args = new ArgumentsBuilder();; args.add(""--"" + StandardArgumentDefinitions.INPUT_LONG_NAME);; args.add(samWithOneMalformedRead.getCanonicalPath());; args.add(""--"" + StandardArgumentDefinitions.OUTPUT_LONG_NAME);; args.add(outBam.getCanonicalPath());. runCommandLine(args.getArgsArray());; SamAssertionUtils.assertSamsEqual(outBam, new File(getTestDataDir(), ""expected.print_reads_one_malformed_read.bam""));; }; ```. But if you re-write it to use `IntegrationTestSpec` with the same input, output, and expected file, it fails with `Sort order differs. File 1: nullFile 2: coordinate`:. ```; @Test; public void testReadFiltering() throws IOException {; final File samWithOneMalformedRead = new File(getTestDataDir(), ""print_reads_one_malformed_read.sam"");; final File outBam = createTempFile(""print_reads_testReadFiltering"", "".bam"");. final IntegrationTestSpec spec = new IntegrationTestSpec(; "" --"" + StandardArgumentDefinitions.INPUT_LONG_NAME + "" "" + samWithOneMalformedRead.getCanonicalPath() +; "" --"" + StandardArgumentDefinitions.OUTPUT_LONG_NAME + "" "" + outBam.getCanonicalPath(),; Arrays.asList(new File(getTestDataDir(), ""expected.print_reads_one_malformed_read.bam"").getCanonicalPath()); );. spec.executeTest(""PrintReadsSpark_testReadFiltering"", this);; }; ```. Possibly this is indicative of a bug in `IntegrationTestSpec`?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1164
https://github.com/broadinstitute/gatk/issues/1164:42,Testability,test,test,42,"I discovered some strange behavior in our test suite. This test in `PrintReadsSparkIntegrationTest` passes:. ```; @Test; public void testReadFiltering() throws IOException {; final File samWithOneMalformedRead = new File(getTestDataDir(), ""print_reads_one_malformed_read.sam"");; final File outBam = createTempFile(""print_reads_testReadFiltering"", "".bam"");. ArgumentsBuilder args = new ArgumentsBuilder();; args.add(""--"" + StandardArgumentDefinitions.INPUT_LONG_NAME);; args.add(samWithOneMalformedRead.getCanonicalPath());; args.add(""--"" + StandardArgumentDefinitions.OUTPUT_LONG_NAME);; args.add(outBam.getCanonicalPath());. runCommandLine(args.getArgsArray());; SamAssertionUtils.assertSamsEqual(outBam, new File(getTestDataDir(), ""expected.print_reads_one_malformed_read.bam""));; }; ```. But if you re-write it to use `IntegrationTestSpec` with the same input, output, and expected file, it fails with `Sort order differs. File 1: nullFile 2: coordinate`:. ```; @Test; public void testReadFiltering() throws IOException {; final File samWithOneMalformedRead = new File(getTestDataDir(), ""print_reads_one_malformed_read.sam"");; final File outBam = createTempFile(""print_reads_testReadFiltering"", "".bam"");. final IntegrationTestSpec spec = new IntegrationTestSpec(; "" --"" + StandardArgumentDefinitions.INPUT_LONG_NAME + "" "" + samWithOneMalformedRead.getCanonicalPath() +; "" --"" + StandardArgumentDefinitions.OUTPUT_LONG_NAME + "" "" + outBam.getCanonicalPath(),; Arrays.asList(new File(getTestDataDir(), ""expected.print_reads_one_malformed_read.bam"").getCanonicalPath()); );. spec.executeTest(""PrintReadsSpark_testReadFiltering"", this);; }; ```. Possibly this is indicative of a bug in `IntegrationTestSpec`?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1164
https://github.com/broadinstitute/gatk/issues/1164:59,Testability,test,test,59,"I discovered some strange behavior in our test suite. This test in `PrintReadsSparkIntegrationTest` passes:. ```; @Test; public void testReadFiltering() throws IOException {; final File samWithOneMalformedRead = new File(getTestDataDir(), ""print_reads_one_malformed_read.sam"");; final File outBam = createTempFile(""print_reads_testReadFiltering"", "".bam"");. ArgumentsBuilder args = new ArgumentsBuilder();; args.add(""--"" + StandardArgumentDefinitions.INPUT_LONG_NAME);; args.add(samWithOneMalformedRead.getCanonicalPath());; args.add(""--"" + StandardArgumentDefinitions.OUTPUT_LONG_NAME);; args.add(outBam.getCanonicalPath());. runCommandLine(args.getArgsArray());; SamAssertionUtils.assertSamsEqual(outBam, new File(getTestDataDir(), ""expected.print_reads_one_malformed_read.bam""));; }; ```. But if you re-write it to use `IntegrationTestSpec` with the same input, output, and expected file, it fails with `Sort order differs. File 1: nullFile 2: coordinate`:. ```; @Test; public void testReadFiltering() throws IOException {; final File samWithOneMalformedRead = new File(getTestDataDir(), ""print_reads_one_malformed_read.sam"");; final File outBam = createTempFile(""print_reads_testReadFiltering"", "".bam"");. final IntegrationTestSpec spec = new IntegrationTestSpec(; "" --"" + StandardArgumentDefinitions.INPUT_LONG_NAME + "" "" + samWithOneMalformedRead.getCanonicalPath() +; "" --"" + StandardArgumentDefinitions.OUTPUT_LONG_NAME + "" "" + outBam.getCanonicalPath(),; Arrays.asList(new File(getTestDataDir(), ""expected.print_reads_one_malformed_read.bam"").getCanonicalPath()); );. spec.executeTest(""PrintReadsSpark_testReadFiltering"", this);; }; ```. Possibly this is indicative of a bug in `IntegrationTestSpec`?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1164
https://github.com/broadinstitute/gatk/issues/1164:115,Testability,Test,Test,115,"I discovered some strange behavior in our test suite. This test in `PrintReadsSparkIntegrationTest` passes:. ```; @Test; public void testReadFiltering() throws IOException {; final File samWithOneMalformedRead = new File(getTestDataDir(), ""print_reads_one_malformed_read.sam"");; final File outBam = createTempFile(""print_reads_testReadFiltering"", "".bam"");. ArgumentsBuilder args = new ArgumentsBuilder();; args.add(""--"" + StandardArgumentDefinitions.INPUT_LONG_NAME);; args.add(samWithOneMalformedRead.getCanonicalPath());; args.add(""--"" + StandardArgumentDefinitions.OUTPUT_LONG_NAME);; args.add(outBam.getCanonicalPath());. runCommandLine(args.getArgsArray());; SamAssertionUtils.assertSamsEqual(outBam, new File(getTestDataDir(), ""expected.print_reads_one_malformed_read.bam""));; }; ```. But if you re-write it to use `IntegrationTestSpec` with the same input, output, and expected file, it fails with `Sort order differs. File 1: nullFile 2: coordinate`:. ```; @Test; public void testReadFiltering() throws IOException {; final File samWithOneMalformedRead = new File(getTestDataDir(), ""print_reads_one_malformed_read.sam"");; final File outBam = createTempFile(""print_reads_testReadFiltering"", "".bam"");. final IntegrationTestSpec spec = new IntegrationTestSpec(; "" --"" + StandardArgumentDefinitions.INPUT_LONG_NAME + "" "" + samWithOneMalformedRead.getCanonicalPath() +; "" --"" + StandardArgumentDefinitions.OUTPUT_LONG_NAME + "" "" + outBam.getCanonicalPath(),; Arrays.asList(new File(getTestDataDir(), ""expected.print_reads_one_malformed_read.bam"").getCanonicalPath()); );. spec.executeTest(""PrintReadsSpark_testReadFiltering"", this);; }; ```. Possibly this is indicative of a bug in `IntegrationTestSpec`?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1164
https://github.com/broadinstitute/gatk/issues/1164:133,Testability,test,testReadFiltering,133,"I discovered some strange behavior in our test suite. This test in `PrintReadsSparkIntegrationTest` passes:. ```; @Test; public void testReadFiltering() throws IOException {; final File samWithOneMalformedRead = new File(getTestDataDir(), ""print_reads_one_malformed_read.sam"");; final File outBam = createTempFile(""print_reads_testReadFiltering"", "".bam"");. ArgumentsBuilder args = new ArgumentsBuilder();; args.add(""--"" + StandardArgumentDefinitions.INPUT_LONG_NAME);; args.add(samWithOneMalformedRead.getCanonicalPath());; args.add(""--"" + StandardArgumentDefinitions.OUTPUT_LONG_NAME);; args.add(outBam.getCanonicalPath());. runCommandLine(args.getArgsArray());; SamAssertionUtils.assertSamsEqual(outBam, new File(getTestDataDir(), ""expected.print_reads_one_malformed_read.bam""));; }; ```. But if you re-write it to use `IntegrationTestSpec` with the same input, output, and expected file, it fails with `Sort order differs. File 1: nullFile 2: coordinate`:. ```; @Test; public void testReadFiltering() throws IOException {; final File samWithOneMalformedRead = new File(getTestDataDir(), ""print_reads_one_malformed_read.sam"");; final File outBam = createTempFile(""print_reads_testReadFiltering"", "".bam"");. final IntegrationTestSpec spec = new IntegrationTestSpec(; "" --"" + StandardArgumentDefinitions.INPUT_LONG_NAME + "" "" + samWithOneMalformedRead.getCanonicalPath() +; "" --"" + StandardArgumentDefinitions.OUTPUT_LONG_NAME + "" "" + outBam.getCanonicalPath(),; Arrays.asList(new File(getTestDataDir(), ""expected.print_reads_one_malformed_read.bam"").getCanonicalPath()); );. spec.executeTest(""PrintReadsSpark_testReadFiltering"", this);; }; ```. Possibly this is indicative of a bug in `IntegrationTestSpec`?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1164
https://github.com/broadinstitute/gatk/issues/1164:682,Testability,assert,assertSamsEqual,682,"I discovered some strange behavior in our test suite. This test in `PrintReadsSparkIntegrationTest` passes:. ```; @Test; public void testReadFiltering() throws IOException {; final File samWithOneMalformedRead = new File(getTestDataDir(), ""print_reads_one_malformed_read.sam"");; final File outBam = createTempFile(""print_reads_testReadFiltering"", "".bam"");. ArgumentsBuilder args = new ArgumentsBuilder();; args.add(""--"" + StandardArgumentDefinitions.INPUT_LONG_NAME);; args.add(samWithOneMalformedRead.getCanonicalPath());; args.add(""--"" + StandardArgumentDefinitions.OUTPUT_LONG_NAME);; args.add(outBam.getCanonicalPath());. runCommandLine(args.getArgsArray());; SamAssertionUtils.assertSamsEqual(outBam, new File(getTestDataDir(), ""expected.print_reads_one_malformed_read.bam""));; }; ```. But if you re-write it to use `IntegrationTestSpec` with the same input, output, and expected file, it fails with `Sort order differs. File 1: nullFile 2: coordinate`:. ```; @Test; public void testReadFiltering() throws IOException {; final File samWithOneMalformedRead = new File(getTestDataDir(), ""print_reads_one_malformed_read.sam"");; final File outBam = createTempFile(""print_reads_testReadFiltering"", "".bam"");. final IntegrationTestSpec spec = new IntegrationTestSpec(; "" --"" + StandardArgumentDefinitions.INPUT_LONG_NAME + "" "" + samWithOneMalformedRead.getCanonicalPath() +; "" --"" + StandardArgumentDefinitions.OUTPUT_LONG_NAME + "" "" + outBam.getCanonicalPath(),; Arrays.asList(new File(getTestDataDir(), ""expected.print_reads_one_malformed_read.bam"").getCanonicalPath()); );. spec.executeTest(""PrintReadsSpark_testReadFiltering"", this);; }; ```. Possibly this is indicative of a bug in `IntegrationTestSpec`?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1164
https://github.com/broadinstitute/gatk/issues/1164:966,Testability,Test,Test,966,"I discovered some strange behavior in our test suite. This test in `PrintReadsSparkIntegrationTest` passes:. ```; @Test; public void testReadFiltering() throws IOException {; final File samWithOneMalformedRead = new File(getTestDataDir(), ""print_reads_one_malformed_read.sam"");; final File outBam = createTempFile(""print_reads_testReadFiltering"", "".bam"");. ArgumentsBuilder args = new ArgumentsBuilder();; args.add(""--"" + StandardArgumentDefinitions.INPUT_LONG_NAME);; args.add(samWithOneMalformedRead.getCanonicalPath());; args.add(""--"" + StandardArgumentDefinitions.OUTPUT_LONG_NAME);; args.add(outBam.getCanonicalPath());. runCommandLine(args.getArgsArray());; SamAssertionUtils.assertSamsEqual(outBam, new File(getTestDataDir(), ""expected.print_reads_one_malformed_read.bam""));; }; ```. But if you re-write it to use `IntegrationTestSpec` with the same input, output, and expected file, it fails with `Sort order differs. File 1: nullFile 2: coordinate`:. ```; @Test; public void testReadFiltering() throws IOException {; final File samWithOneMalformedRead = new File(getTestDataDir(), ""print_reads_one_malformed_read.sam"");; final File outBam = createTempFile(""print_reads_testReadFiltering"", "".bam"");. final IntegrationTestSpec spec = new IntegrationTestSpec(; "" --"" + StandardArgumentDefinitions.INPUT_LONG_NAME + "" "" + samWithOneMalformedRead.getCanonicalPath() +; "" --"" + StandardArgumentDefinitions.OUTPUT_LONG_NAME + "" "" + outBam.getCanonicalPath(),; Arrays.asList(new File(getTestDataDir(), ""expected.print_reads_one_malformed_read.bam"").getCanonicalPath()); );. spec.executeTest(""PrintReadsSpark_testReadFiltering"", this);; }; ```. Possibly this is indicative of a bug in `IntegrationTestSpec`?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1164
https://github.com/broadinstitute/gatk/issues/1164:984,Testability,test,testReadFiltering,984,"I discovered some strange behavior in our test suite. This test in `PrintReadsSparkIntegrationTest` passes:. ```; @Test; public void testReadFiltering() throws IOException {; final File samWithOneMalformedRead = new File(getTestDataDir(), ""print_reads_one_malformed_read.sam"");; final File outBam = createTempFile(""print_reads_testReadFiltering"", "".bam"");. ArgumentsBuilder args = new ArgumentsBuilder();; args.add(""--"" + StandardArgumentDefinitions.INPUT_LONG_NAME);; args.add(samWithOneMalformedRead.getCanonicalPath());; args.add(""--"" + StandardArgumentDefinitions.OUTPUT_LONG_NAME);; args.add(outBam.getCanonicalPath());. runCommandLine(args.getArgsArray());; SamAssertionUtils.assertSamsEqual(outBam, new File(getTestDataDir(), ""expected.print_reads_one_malformed_read.bam""));; }; ```. But if you re-write it to use `IntegrationTestSpec` with the same input, output, and expected file, it fails with `Sort order differs. File 1: nullFile 2: coordinate`:. ```; @Test; public void testReadFiltering() throws IOException {; final File samWithOneMalformedRead = new File(getTestDataDir(), ""print_reads_one_malformed_read.sam"");; final File outBam = createTempFile(""print_reads_testReadFiltering"", "".bam"");. final IntegrationTestSpec spec = new IntegrationTestSpec(; "" --"" + StandardArgumentDefinitions.INPUT_LONG_NAME + "" "" + samWithOneMalformedRead.getCanonicalPath() +; "" --"" + StandardArgumentDefinitions.OUTPUT_LONG_NAME + "" "" + outBam.getCanonicalPath(),; Arrays.asList(new File(getTestDataDir(), ""expected.print_reads_one_malformed_read.bam"").getCanonicalPath()); );. spec.executeTest(""PrintReadsSpark_testReadFiltering"", this);; }; ```. Possibly this is indicative of a bug in `IntegrationTestSpec`?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1164
https://github.com/broadinstitute/gatk/issues/1165:210,Deployability,pipeline,pipelines,210,"Currently spark read filters are applied to the initial reads returned from `GATKSparkTool.getReads()` via an overridable `GATKSparkTool.makeReadFilter()`. This is fine for standalone tools, but for multi-tool pipelines it creates a problem, since they must call the underlying transform for each tool instead of invoking the actual `GATKSparkTool`, and so have to handle read filtering manually for each step in the pipeline. We need a Transform abstraction that stores and applies the read filters for each tool, instead of doing this at the `GATKSparkTool` level. . Related to the tool composability ticket https://github.com/broadinstitute/gatk/issues/960",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1165
https://github.com/broadinstitute/gatk/issues/1165:417,Deployability,pipeline,pipeline,417,"Currently spark read filters are applied to the initial reads returned from `GATKSparkTool.getReads()` via an overridable `GATKSparkTool.makeReadFilter()`. This is fine for standalone tools, but for multi-tool pipelines it creates a problem, since they must call the underlying transform for each tool instead of invoking the actual `GATKSparkTool`, and so have to handle read filtering manually for each step in the pipeline. We need a Transform abstraction that stores and applies the read filters for each tool, instead of doing this at the `GATKSparkTool` level. . Related to the tool composability ticket https://github.com/broadinstitute/gatk/issues/960",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1165
https://github.com/broadinstitute/gatk/issues/1170:63,Testability,test,test,63,`PicardCommandLineProgramTest` doesn't yet exist. The relevant test are currently in `MarkDuplicatesIntegrationTest`.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1170
https://github.com/broadinstitute/gatk/pull/1173:8,Safety,avoid,avoid,8,To help avoid user confusion. Resolves #1172,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1173
https://github.com/broadinstitute/gatk/pull/1174:155,Energy Efficiency,reduce,reducer,155,"This addresses https://github.com/broadinstitute/gatk/issues/1015 and https://github.com/broadinstitute/gatk/issues/1094. The idea is to remove the single reducer sort (which doesn't scale), by performing a totally ordered parallel sort on the reads, then writing each partition as a (headerless) BAM file. Finally, the BAM files are concatenated together after writing an initial header. This is very similar to the approach that Hadoop-BAM takes, but adapted to work on Spark. I haven't done extensive benchmarking, but when I ran MD on a ~75MB BAM the runtime dropped from >30 mins to around 8 mins. This is still worse than the walker equivalent for small files, but it's an improvement that means many jobs that didn't finish before now do. Note that this includes the changes from https://github.com/broadinstitute/gatk/pull/1127. I'll rebase once that is committed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1174
https://github.com/broadinstitute/gatk/pull/1174:453,Energy Efficiency,adapt,adapted,453,"This addresses https://github.com/broadinstitute/gatk/issues/1015 and https://github.com/broadinstitute/gatk/issues/1094. The idea is to remove the single reducer sort (which doesn't scale), by performing a totally ordered parallel sort on the reads, then writing each partition as a (headerless) BAM file. Finally, the BAM files are concatenated together after writing an initial header. This is very similar to the approach that Hadoop-BAM takes, but adapted to work on Spark. I haven't done extensive benchmarking, but when I ran MD on a ~75MB BAM the runtime dropped from >30 mins to around 8 mins. This is still worse than the walker equivalent for small files, but it's an improvement that means many jobs that didn't finish before now do. Note that this includes the changes from https://github.com/broadinstitute/gatk/pull/1127. I'll rebase once that is committed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1174
https://github.com/broadinstitute/gatk/pull/1174:453,Modifiability,adapt,adapted,453,"This addresses https://github.com/broadinstitute/gatk/issues/1015 and https://github.com/broadinstitute/gatk/issues/1094. The idea is to remove the single reducer sort (which doesn't scale), by performing a totally ordered parallel sort on the reads, then writing each partition as a (headerless) BAM file. Finally, the BAM files are concatenated together after writing an initial header. This is very similar to the approach that Hadoop-BAM takes, but adapted to work on Spark. I haven't done extensive benchmarking, but when I ran MD on a ~75MB BAM the runtime dropped from >30 mins to around 8 mins. This is still worse than the walker equivalent for small files, but it's an improvement that means many jobs that didn't finish before now do. Note that this includes the changes from https://github.com/broadinstitute/gatk/pull/1127. I'll rebase once that is committed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1174
https://github.com/broadinstitute/gatk/pull/1174:194,Performance,perform,performing,194,"This addresses https://github.com/broadinstitute/gatk/issues/1015 and https://github.com/broadinstitute/gatk/issues/1094. The idea is to remove the single reducer sort (which doesn't scale), by performing a totally ordered parallel sort on the reads, then writing each partition as a (headerless) BAM file. Finally, the BAM files are concatenated together after writing an initial header. This is very similar to the approach that Hadoop-BAM takes, but adapted to work on Spark. I haven't done extensive benchmarking, but when I ran MD on a ~75MB BAM the runtime dropped from >30 mins to around 8 mins. This is still worse than the walker equivalent for small files, but it's an improvement that means many jobs that didn't finish before now do. Note that this includes the changes from https://github.com/broadinstitute/gatk/pull/1127. I'll rebase once that is committed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1174
https://github.com/broadinstitute/gatk/pull/1174:504,Testability,benchmark,benchmarking,504,"This addresses https://github.com/broadinstitute/gatk/issues/1015 and https://github.com/broadinstitute/gatk/issues/1094. The idea is to remove the single reducer sort (which doesn't scale), by performing a totally ordered parallel sort on the reads, then writing each partition as a (headerless) BAM file. Finally, the BAM files are concatenated together after writing an initial header. This is very similar to the approach that Hadoop-BAM takes, but adapted to work on Spark. I haven't done extensive benchmarking, but when I ran MD on a ~75MB BAM the runtime dropped from >30 mins to around 8 mins. This is still worse than the walker equivalent for small files, but it's an improvement that means many jobs that didn't finish before now do. Note that this includes the changes from https://github.com/broadinstitute/gatk/pull/1127. I'll rebase once that is committed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1174
https://github.com/broadinstitute/gatk/pull/1178:273,Usability,usab,usability,273,"GATK4 uses contig names, rather than contig indices, and so does not; need to be as strict as GATK3 and require contigs to occur in the same; relative order in two sequence dictionaries, or check for lexicographic; ordering in human dictionaries. This solves several major usability issues:. -2bit references (used by the spark BQSR) typically contain dictionaries; with very non-standard contig ordering. Since we query contigs by name,; we are actually compatible with these references and shouldn't blow up. -Many VCF dictionaries use lexicographic ordering, and GATK4 would blow; up on these. With this change, we also no longer require variant dictionaries to share; a common subset of contigs with each other (just with the reference and/or; reads). Resolves #1176; Resolves #1024",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1178
https://github.com/broadinstitute/gatk/issues/1179:525,Deployability,patch,patched,525,"`GATKTool` uses stricter sequence dictionary validation settings for CRAM vs. reference than for non-CRAM vs. reference:. ```; if ( hasCramInput() ) {; // Use stricter validation for CRAM vs. the reference; SequenceDictionaryUtils.validateCRAMDictionaryAgainstReference(refDict, readDict);; }; else {; // Use standard validation settings for non-CRAM reads input vs. the reference; SequenceDictionaryUtils.validateDictionaries(""reference"", refDict, ""reads"", readDict);; }; ```. `GATKSparkTool.validateToolInputs()` should be patched to do the same, AFTER https://github.com/broadinstitute/gatk/issues/966 is done and cram support is in a usable state.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1179
https://github.com/broadinstitute/gatk/issues/1179:45,Security,validat,validation,45,"`GATKTool` uses stricter sequence dictionary validation settings for CRAM vs. reference than for non-CRAM vs. reference:. ```; if ( hasCramInput() ) {; // Use stricter validation for CRAM vs. the reference; SequenceDictionaryUtils.validateCRAMDictionaryAgainstReference(refDict, readDict);; }; else {; // Use standard validation settings for non-CRAM reads input vs. the reference; SequenceDictionaryUtils.validateDictionaries(""reference"", refDict, ""reads"", readDict);; }; ```. `GATKSparkTool.validateToolInputs()` should be patched to do the same, AFTER https://github.com/broadinstitute/gatk/issues/966 is done and cram support is in a usable state.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1179
https://github.com/broadinstitute/gatk/issues/1179:168,Security,validat,validation,168,"`GATKTool` uses stricter sequence dictionary validation settings for CRAM vs. reference than for non-CRAM vs. reference:. ```; if ( hasCramInput() ) {; // Use stricter validation for CRAM vs. the reference; SequenceDictionaryUtils.validateCRAMDictionaryAgainstReference(refDict, readDict);; }; else {; // Use standard validation settings for non-CRAM reads input vs. the reference; SequenceDictionaryUtils.validateDictionaries(""reference"", refDict, ""reads"", readDict);; }; ```. `GATKSparkTool.validateToolInputs()` should be patched to do the same, AFTER https://github.com/broadinstitute/gatk/issues/966 is done and cram support is in a usable state.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1179
https://github.com/broadinstitute/gatk/issues/1179:231,Security,validat,validateCRAMDictionaryAgainstReference,231,"`GATKTool` uses stricter sequence dictionary validation settings for CRAM vs. reference than for non-CRAM vs. reference:. ```; if ( hasCramInput() ) {; // Use stricter validation for CRAM vs. the reference; SequenceDictionaryUtils.validateCRAMDictionaryAgainstReference(refDict, readDict);; }; else {; // Use standard validation settings for non-CRAM reads input vs. the reference; SequenceDictionaryUtils.validateDictionaries(""reference"", refDict, ""reads"", readDict);; }; ```. `GATKSparkTool.validateToolInputs()` should be patched to do the same, AFTER https://github.com/broadinstitute/gatk/issues/966 is done and cram support is in a usable state.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1179
https://github.com/broadinstitute/gatk/issues/1179:318,Security,validat,validation,318,"`GATKTool` uses stricter sequence dictionary validation settings for CRAM vs. reference than for non-CRAM vs. reference:. ```; if ( hasCramInput() ) {; // Use stricter validation for CRAM vs. the reference; SequenceDictionaryUtils.validateCRAMDictionaryAgainstReference(refDict, readDict);; }; else {; // Use standard validation settings for non-CRAM reads input vs. the reference; SequenceDictionaryUtils.validateDictionaries(""reference"", refDict, ""reads"", readDict);; }; ```. `GATKSparkTool.validateToolInputs()` should be patched to do the same, AFTER https://github.com/broadinstitute/gatk/issues/966 is done and cram support is in a usable state.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1179
https://github.com/broadinstitute/gatk/issues/1179:406,Security,validat,validateDictionaries,406,"`GATKTool` uses stricter sequence dictionary validation settings for CRAM vs. reference than for non-CRAM vs. reference:. ```; if ( hasCramInput() ) {; // Use stricter validation for CRAM vs. the reference; SequenceDictionaryUtils.validateCRAMDictionaryAgainstReference(refDict, readDict);; }; else {; // Use standard validation settings for non-CRAM reads input vs. the reference; SequenceDictionaryUtils.validateDictionaries(""reference"", refDict, ""reads"", readDict);; }; ```. `GATKSparkTool.validateToolInputs()` should be patched to do the same, AFTER https://github.com/broadinstitute/gatk/issues/966 is done and cram support is in a usable state.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1179
https://github.com/broadinstitute/gatk/issues/1179:493,Security,validat,validateToolInputs,493,"`GATKTool` uses stricter sequence dictionary validation settings for CRAM vs. reference than for non-CRAM vs. reference:. ```; if ( hasCramInput() ) {; // Use stricter validation for CRAM vs. the reference; SequenceDictionaryUtils.validateCRAMDictionaryAgainstReference(refDict, readDict);; }; else {; // Use standard validation settings for non-CRAM reads input vs. the reference; SequenceDictionaryUtils.validateDictionaries(""reference"", refDict, ""reads"", readDict);; }; ```. `GATKSparkTool.validateToolInputs()` should be patched to do the same, AFTER https://github.com/broadinstitute/gatk/issues/966 is done and cram support is in a usable state.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1179
https://github.com/broadinstitute/gatk/issues/1179:638,Usability,usab,usable,638,"`GATKTool` uses stricter sequence dictionary validation settings for CRAM vs. reference than for non-CRAM vs. reference:. ```; if ( hasCramInput() ) {; // Use stricter validation for CRAM vs. the reference; SequenceDictionaryUtils.validateCRAMDictionaryAgainstReference(refDict, readDict);; }; else {; // Use standard validation settings for non-CRAM reads input vs. the reference; SequenceDictionaryUtils.validateDictionaries(""reference"", refDict, ""reads"", readDict);; }; ```. `GATKSparkTool.validateToolInputs()` should be patched to do the same, AFTER https://github.com/broadinstitute/gatk/issues/966 is done and cram support is in a usable state.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1179
https://github.com/broadinstitute/gatk/issues/1181:214,Security,validat,validateToolInputs,214,"Similar to how `GATKTool` requires a reference when there's at least one cram input, we need to do the same thing in spark. Right place to do this is probably in `GATKSparkTool.initializeReads()` or `GATKSparkTool.validateToolInputs()`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1181
https://github.com/broadinstitute/gatk/issues/1183:82,Testability,test,tests,82,Its currently set to false since defaulting to true breaks a couple of PrintReads tests which will need to be fixed. Also add fullName doc attribute.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1183
https://github.com/broadinstitute/gatk/issues/1184:323,Availability,avail,available,323,"I would be useful to be able to explicitly indicate the Codec class for a FeatureInputs perhaps using an annotation. . Currently the feature manager tries every possible codec hoping to find one and only one that answers yes to the canDecode(FileName) method call. If none does execution fails saying that there is no code available to deal with the input file; if more than one codec returns true then is supposed to throw another error indicating the ambiguity. The former is likely an user cased error whereas the later is rather a bug as Codec developers seems to be responsible to make sure that such a collision never happens... This has a few draw backs:; - Seems to quasi-force to establish a 1-to-1 assignation of Codecs and file extension names; canDecode documentation encourages use the file name as the way to determine whether the codec can decode or not the file. What if the file is a simple tab separated value file (with some column count and format constrains) and general extensions such as .tab or .tsv seem acceptable names in practice?; - The error message when there is no supporting code does not tell what the problem is; whether the extension of the file (due to the the 1-to-1 name to type quasi-restriction above) or a more complex formatting issue in the file (e.g. required header missing, version not supported ... blah blah). ; - All codecs are tried out even when most won't ever apply. Even if the performance impact should in practice be minimal still may cause several file IO open operations as several Codec do actually peek into the file (e.g. BCF and VCF codecs). ; - Codec developers have to make sure their new codec does not collides with others; it would be better if codec development can be totally independent.; - General file extensions such as .tab , .tsv cannot be used by codecs due to possible collisions constraining users to name their files the way GATK needs them to; ""I don't like people telling what file names a have to use... I'm already pl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1184
https://github.com/broadinstitute/gatk/issues/1184:432,Availability,error,error,432,"I would be useful to be able to explicitly indicate the Codec class for a FeatureInputs perhaps using an annotation. . Currently the feature manager tries every possible codec hoping to find one and only one that answers yes to the canDecode(FileName) method call. If none does execution fails saying that there is no code available to deal with the input file; if more than one codec returns true then is supposed to throw another error indicating the ambiguity. The former is likely an user cased error whereas the later is rather a bug as Codec developers seems to be responsible to make sure that such a collision never happens... This has a few draw backs:; - Seems to quasi-force to establish a 1-to-1 assignation of Codecs and file extension names; canDecode documentation encourages use the file name as the way to determine whether the codec can decode or not the file. What if the file is a simple tab separated value file (with some column count and format constrains) and general extensions such as .tab or .tsv seem acceptable names in practice?; - The error message when there is no supporting code does not tell what the problem is; whether the extension of the file (due to the the 1-to-1 name to type quasi-restriction above) or a more complex formatting issue in the file (e.g. required header missing, version not supported ... blah blah). ; - All codecs are tried out even when most won't ever apply. Even if the performance impact should in practice be minimal still may cause several file IO open operations as several Codec do actually peek into the file (e.g. BCF and VCF codecs). ; - Codec developers have to make sure their new codec does not collides with others; it would be better if codec development can be totally independent.; - General file extensions such as .tab , .tsv cannot be used by codecs due to possible collisions constraining users to name their files the way GATK needs them to; ""I don't like people telling what file names a have to use... I'm already pl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1184
https://github.com/broadinstitute/gatk/issues/1184:499,Availability,error,error,499,"I would be useful to be able to explicitly indicate the Codec class for a FeatureInputs perhaps using an annotation. . Currently the feature manager tries every possible codec hoping to find one and only one that answers yes to the canDecode(FileName) method call. If none does execution fails saying that there is no code available to deal with the input file; if more than one codec returns true then is supposed to throw another error indicating the ambiguity. The former is likely an user cased error whereas the later is rather a bug as Codec developers seems to be responsible to make sure that such a collision never happens... This has a few draw backs:; - Seems to quasi-force to establish a 1-to-1 assignation of Codecs and file extension names; canDecode documentation encourages use the file name as the way to determine whether the codec can decode or not the file. What if the file is a simple tab separated value file (with some column count and format constrains) and general extensions such as .tab or .tsv seem acceptable names in practice?; - The error message when there is no supporting code does not tell what the problem is; whether the extension of the file (due to the the 1-to-1 name to type quasi-restriction above) or a more complex formatting issue in the file (e.g. required header missing, version not supported ... blah blah). ; - All codecs are tried out even when most won't ever apply. Even if the performance impact should in practice be minimal still may cause several file IO open operations as several Codec do actually peek into the file (e.g. BCF and VCF codecs). ; - Codec developers have to make sure their new codec does not collides with others; it would be better if codec development can be totally independent.; - General file extensions such as .tab , .tsv cannot be used by codecs due to possible collisions constraining users to name their files the way GATK needs them to; ""I don't like people telling what file names a have to use... I'm already pl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1184
https://github.com/broadinstitute/gatk/issues/1184:1066,Availability,error,error,1066,"very possible codec hoping to find one and only one that answers yes to the canDecode(FileName) method call. If none does execution fails saying that there is no code available to deal with the input file; if more than one codec returns true then is supposed to throw another error indicating the ambiguity. The former is likely an user cased error whereas the later is rather a bug as Codec developers seems to be responsible to make sure that such a collision never happens... This has a few draw backs:; - Seems to quasi-force to establish a 1-to-1 assignation of Codecs and file extension names; canDecode documentation encourages use the file name as the way to determine whether the codec can decode or not the file. What if the file is a simple tab separated value file (with some column count and format constrains) and general extensions such as .tab or .tsv seem acceptable names in practice?; - The error message when there is no supporting code does not tell what the problem is; whether the extension of the file (due to the the 1-to-1 name to type quasi-restriction above) or a more complex formatting issue in the file (e.g. required header missing, version not supported ... blah blah). ; - All codecs are tried out even when most won't ever apply. Even if the performance impact should in practice be minimal still may cause several file IO open operations as several Codec do actually peek into the file (e.g. BCF and VCF codecs). ; - Codec developers have to make sure their new codec does not collides with others; it would be better if codec development can be totally independent.; - General file extensions such as .tab , .tsv cannot be used by codecs due to possible collisions constraining users to name their files the way GATK needs them to; ""I don't like people telling what file names a have to use... I'm already placing the correct argument name before the file name. What else you need!"". Proposal:. An annotation to tell what codes to try out, the first one that canDe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1184
https://github.com/broadinstitute/gatk/issues/1184:2208,Availability,error,error,2208,"practice?; - The error message when there is no supporting code does not tell what the problem is; whether the extension of the file (due to the the 1-to-1 name to type quasi-restriction above) or a more complex formatting issue in the file (e.g. required header missing, version not supported ... blah blah). ; - All codecs are tried out even when most won't ever apply. Even if the performance impact should in practice be minimal still may cause several file IO open operations as several Codec do actually peek into the file (e.g. BCF and VCF codecs). ; - Codec developers have to make sure their new codec does not collides with others; it would be better if codec development can be totally independent.; - General file extensions such as .tab , .tsv cannot be used by codecs due to possible collisions constraining users to name their files the way GATK needs them to; ""I don't like people telling what file names a have to use... I'm already placing the correct argument name before the file name. What else you need!"". Proposal:. An annotation to tell what codes to try out, the first one that canDecode returns true is used otherwise a configurable error message saying what the problem could be:. <pre>; @Codecs(BEDCodec.class); FeatureInput&lt;BEDFeature&gt; features;; </pre>. <pre>; @Codecs(value = BEDCodec.class, failureMessage = ""The file provided must be a BED formatted file with extension .bed""); FeatureInput&lt;BEDFeature&gt; features;; </pre> . <pre>; @Codecs(BCFCodec.class, VCFCodec.class); FeatureInput&lt;VariantContext&gt; variants;; </pre>. <pre>; // force = true, means that canDecode won't be called and instead we try to read the content directly,; // the codec's code is responsible to throw an appropriate UserException.BadInput indicating formatting issues; this should be the case already anyway.; @Codecs(value = TargetCodec.class, force = true); FeatureInput&lt;Target&gt; target;; </pre>. If the annotation is not present it can default to the current behavior.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1184
https://github.com/broadinstitute/gatk/issues/1184:2378,Availability,failure,failureMessage,2378,"practice?; - The error message when there is no supporting code does not tell what the problem is; whether the extension of the file (due to the the 1-to-1 name to type quasi-restriction above) or a more complex formatting issue in the file (e.g. required header missing, version not supported ... blah blah). ; - All codecs are tried out even when most won't ever apply. Even if the performance impact should in practice be minimal still may cause several file IO open operations as several Codec do actually peek into the file (e.g. BCF and VCF codecs). ; - Codec developers have to make sure their new codec does not collides with others; it would be better if codec development can be totally independent.; - General file extensions such as .tab , .tsv cannot be used by codecs due to possible collisions constraining users to name their files the way GATK needs them to; ""I don't like people telling what file names a have to use... I'm already placing the correct argument name before the file name. What else you need!"". Proposal:. An annotation to tell what codes to try out, the first one that canDecode returns true is used otherwise a configurable error message saying what the problem could be:. <pre>; @Codecs(BEDCodec.class); FeatureInput&lt;BEDFeature&gt; features;; </pre>. <pre>; @Codecs(value = BEDCodec.class, failureMessage = ""The file provided must be a BED formatted file with extension .bed""); FeatureInput&lt;BEDFeature&gt; features;; </pre> . <pre>; @Codecs(BCFCodec.class, VCFCodec.class); FeatureInput&lt;VariantContext&gt; variants;; </pre>. <pre>; // force = true, means that canDecode won't be called and instead we try to read the content directly,; // the codec's code is responsible to throw an appropriate UserException.BadInput indicating formatting issues; this should be the case already anyway.; @Codecs(value = TargetCodec.class, force = true); FeatureInput&lt;Target&gt; target;; </pre>. If the annotation is not present it can default to the current behavior.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1184
https://github.com/broadinstitute/gatk/issues/1184:1072,Integrability,message,message,1072,"very possible codec hoping to find one and only one that answers yes to the canDecode(FileName) method call. If none does execution fails saying that there is no code available to deal with the input file; if more than one codec returns true then is supposed to throw another error indicating the ambiguity. The former is likely an user cased error whereas the later is rather a bug as Codec developers seems to be responsible to make sure that such a collision never happens... This has a few draw backs:; - Seems to quasi-force to establish a 1-to-1 assignation of Codecs and file extension names; canDecode documentation encourages use the file name as the way to determine whether the codec can decode or not the file. What if the file is a simple tab separated value file (with some column count and format constrains) and general extensions such as .tab or .tsv seem acceptable names in practice?; - The error message when there is no supporting code does not tell what the problem is; whether the extension of the file (due to the the 1-to-1 name to type quasi-restriction above) or a more complex formatting issue in the file (e.g. required header missing, version not supported ... blah blah). ; - All codecs are tried out even when most won't ever apply. Even if the performance impact should in practice be minimal still may cause several file IO open operations as several Codec do actually peek into the file (e.g. BCF and VCF codecs). ; - Codec developers have to make sure their new codec does not collides with others; it would be better if codec development can be totally independent.; - General file extensions such as .tab , .tsv cannot be used by codecs due to possible collisions constraining users to name their files the way GATK needs them to; ""I don't like people telling what file names a have to use... I'm already placing the correct argument name before the file name. What else you need!"". Proposal:. An annotation to tell what codes to try out, the first one that canDe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1184
https://github.com/broadinstitute/gatk/issues/1184:2214,Integrability,message,message,2214,"practice?; - The error message when there is no supporting code does not tell what the problem is; whether the extension of the file (due to the the 1-to-1 name to type quasi-restriction above) or a more complex formatting issue in the file (e.g. required header missing, version not supported ... blah blah). ; - All codecs are tried out even when most won't ever apply. Even if the performance impact should in practice be minimal still may cause several file IO open operations as several Codec do actually peek into the file (e.g. BCF and VCF codecs). ; - Codec developers have to make sure their new codec does not collides with others; it would be better if codec development can be totally independent.; - General file extensions such as .tab , .tsv cannot be used by codecs due to possible collisions constraining users to name their files the way GATK needs them to; ""I don't like people telling what file names a have to use... I'm already placing the correct argument name before the file name. What else you need!"". Proposal:. An annotation to tell what codes to try out, the first one that canDecode returns true is used otherwise a configurable error message saying what the problem could be:. <pre>; @Codecs(BEDCodec.class); FeatureInput&lt;BEDFeature&gt; features;; </pre>. <pre>; @Codecs(value = BEDCodec.class, failureMessage = ""The file provided must be a BED formatted file with extension .bed""); FeatureInput&lt;BEDFeature&gt; features;; </pre> . <pre>; @Codecs(BCFCodec.class, VCFCodec.class); FeatureInput&lt;VariantContext&gt; variants;; </pre>. <pre>; // force = true, means that canDecode won't be called and instead we try to read the content directly,; // the codec's code is responsible to throw an appropriate UserException.BadInput indicating formatting issues; this should be the case already anyway.; @Codecs(value = TargetCodec.class, force = true); FeatureInput&lt;Target&gt; target;; </pre>. If the annotation is not present it can default to the current behavior.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1184
https://github.com/broadinstitute/gatk/issues/1184:2195,Modifiability,config,configurable,2195,"practice?; - The error message when there is no supporting code does not tell what the problem is; whether the extension of the file (due to the the 1-to-1 name to type quasi-restriction above) or a more complex formatting issue in the file (e.g. required header missing, version not supported ... blah blah). ; - All codecs are tried out even when most won't ever apply. Even if the performance impact should in practice be minimal still may cause several file IO open operations as several Codec do actually peek into the file (e.g. BCF and VCF codecs). ; - Codec developers have to make sure their new codec does not collides with others; it would be better if codec development can be totally independent.; - General file extensions such as .tab , .tsv cannot be used by codecs due to possible collisions constraining users to name their files the way GATK needs them to; ""I don't like people telling what file names a have to use... I'm already placing the correct argument name before the file name. What else you need!"". Proposal:. An annotation to tell what codes to try out, the first one that canDecode returns true is used otherwise a configurable error message saying what the problem could be:. <pre>; @Codecs(BEDCodec.class); FeatureInput&lt;BEDFeature&gt; features;; </pre>. <pre>; @Codecs(value = BEDCodec.class, failureMessage = ""The file provided must be a BED formatted file with extension .bed""); FeatureInput&lt;BEDFeature&gt; features;; </pre> . <pre>; @Codecs(BCFCodec.class, VCFCodec.class); FeatureInput&lt;VariantContext&gt; variants;; </pre>. <pre>; // force = true, means that canDecode won't be called and instead we try to read the content directly,; // the codec's code is responsible to throw an appropriate UserException.BadInput indicating formatting issues; this should be the case already anyway.; @Codecs(value = TargetCodec.class, force = true); FeatureInput&lt;Target&gt; target;; </pre>. If the annotation is not present it can default to the current behavior.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1184
https://github.com/broadinstitute/gatk/issues/1184:1433,Performance,perform,performance,1433,"rror whereas the later is rather a bug as Codec developers seems to be responsible to make sure that such a collision never happens... This has a few draw backs:; - Seems to quasi-force to establish a 1-to-1 assignation of Codecs and file extension names; canDecode documentation encourages use the file name as the way to determine whether the codec can decode or not the file. What if the file is a simple tab separated value file (with some column count and format constrains) and general extensions such as .tab or .tsv seem acceptable names in practice?; - The error message when there is no supporting code does not tell what the problem is; whether the extension of the file (due to the the 1-to-1 name to type quasi-restriction above) or a more complex formatting issue in the file (e.g. required header missing, version not supported ... blah blah). ; - All codecs are tried out even when most won't ever apply. Even if the performance impact should in practice be minimal still may cause several file IO open operations as several Codec do actually peek into the file (e.g. BCF and VCF codecs). ; - Codec developers have to make sure their new codec does not collides with others; it would be better if codec development can be totally independent.; - General file extensions such as .tab , .tsv cannot be used by codecs due to possible collisions constraining users to name their files the way GATK needs them to; ""I don't like people telling what file names a have to use... I'm already placing the correct argument name before the file name. What else you need!"". Proposal:. An annotation to tell what codes to try out, the first one that canDecode returns true is used otherwise a configurable error message saying what the problem could be:. <pre>; @Codecs(BEDCodec.class); FeatureInput&lt;BEDFeature&gt; features;; </pre>. <pre>; @Codecs(value = BEDCodec.class, failureMessage = ""The file provided must be a BED formatted file with extension .bed""); FeatureInput&lt;BEDFeature&gt; feat",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1184
https://github.com/broadinstitute/gatk/issues/1184:901,Usability,simpl,simple,901,"I would be useful to be able to explicitly indicate the Codec class for a FeatureInputs perhaps using an annotation. . Currently the feature manager tries every possible codec hoping to find one and only one that answers yes to the canDecode(FileName) method call. If none does execution fails saying that there is no code available to deal with the input file; if more than one codec returns true then is supposed to throw another error indicating the ambiguity. The former is likely an user cased error whereas the later is rather a bug as Codec developers seems to be responsible to make sure that such a collision never happens... This has a few draw backs:; - Seems to quasi-force to establish a 1-to-1 assignation of Codecs and file extension names; canDecode documentation encourages use the file name as the way to determine whether the codec can decode or not the file. What if the file is a simple tab separated value file (with some column count and format constrains) and general extensions such as .tab or .tsv seem acceptable names in practice?; - The error message when there is no supporting code does not tell what the problem is; whether the extension of the file (due to the the 1-to-1 name to type quasi-restriction above) or a more complex formatting issue in the file (e.g. required header missing, version not supported ... blah blah). ; - All codecs are tried out even when most won't ever apply. Even if the performance impact should in practice be minimal still may cause several file IO open operations as several Codec do actually peek into the file (e.g. BCF and VCF codecs). ; - Codec developers have to make sure their new codec does not collides with others; it would be better if codec development can be totally independent.; - General file extensions such as .tab , .tsv cannot be used by codecs due to possible collisions constraining users to name their files the way GATK needs them to; ""I don't like people telling what file names a have to use... I'm already pl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1184
https://github.com/broadinstitute/gatk/pull/1185:56,Availability,avail,available,56,"The build is failing since 1.21.0-SNAPSHOT is no longer available in any Maven repositories. It looks like 1.21.0 was released last week: https://repo1.maven.org/maven2/com/google/http-client/google-http-client/, and changing the build to use that version seems to fix the problem. Related to #650.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1185
https://github.com/broadinstitute/gatk/pull/1185:118,Deployability,release,released,118,"The build is failing since 1.21.0-SNAPSHOT is no longer available in any Maven repositories. It looks like 1.21.0 was released last week: https://repo1.maven.org/maven2/com/google/http-client/google-http-client/, and changing the build to use that version seems to fix the problem. Related to #650.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1185
https://github.com/broadinstitute/gatk/issues/1187:202,Testability,test,test,202,Cannot read indices on BGZF files created by IndexFeatureFile when they are written using the default .tbi extension. see discussion in https://github.com/broadinstitute/gatk/pull/985; See the disabled test `IndexFeatureFileIntegrationTest.testVCFGZIndex_inferredName`,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1187
https://github.com/broadinstitute/gatk/issues/1188:157,Security,password,passwords,157,During alpha we should work out the process of releasing builds to maven central. This may require coordinating with ops in order to handle signing keys and passwords.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1188
https://github.com/broadinstitute/gatk/issues/1191:68,Integrability,interface,interface,68,now that htsjdk is java 8 we can push a bunch of functions into the interface itself.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1191
https://github.com/broadinstitute/gatk/issues/1192:14,Testability,test,tests,14,both of those tests are disabled because the cloud does not have a hg18 reference and so the non-spark tests (which do use hg18) can't be just ported. the task here is to create a new set of expected data and re-enable the test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1192
https://github.com/broadinstitute/gatk/issues/1192:103,Testability,test,tests,103,both of those tests are disabled because the cloud does not have a hg18 reference and so the non-spark tests (which do use hg18) can't be just ported. the task here is to create a new set of expected data and re-enable the test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1192
https://github.com/broadinstitute/gatk/issues/1192:223,Testability,test,test,223,both of those tests are disabled because the cloud does not have a hg18 reference and so the non-spark tests (which do use hg18) can't be just ported. the task here is to create a new set of expected data and re-enable the test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1192
https://github.com/broadinstitute/gatk/pull/1193:126,Testability,test,test,126,This it for https://github.com/broadinstitute/gatk/issues/972. By adding `-Dgatk.spark.debug=true` you can run a single Spark test and look at the Spark UI (on http://localhost:4040/) as it runs.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1193
https://github.com/broadinstitute/gatk/issues/1196:110,Deployability,pipeline,pipeline,110,"the main advantage of spark for processing is that we can do stuff in memory and so throughout **of the whole pipeline** should be higher than that of the string of Picard+GATK tools. The thing to do here compare is:; 1) take a bam file, run ReadsPipelineSpark on it, measure time (as function of # nodes, start with 1); 2) take same bam file, run MarkDuplicates, BaseRecalibrator, PrintReads in order, measure time. The bam file should be non-trivial, at least 30GB. The goal for beta should be to beat non-spark on 1 node. It may already be true for alpha.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1196
https://github.com/broadinstitute/gatk/issues/1198:532,Modifiability,extend,extendable,532,"Hello, I would like to ask for the implementation of a SlidingWindowWalker (both for reads and variants), that could be very interesting for other tools. I was thinking that it could be similar to IntervalWalker, but generating the intervals internally using a window size and step size as parameters (provided by the user and without merging overlapping intervals, like suggested on #302). I think that this issue is different from issue #10 and the pull request #890 because it is a more general Walker that could be abstract and extendable by other tools.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1198
https://github.com/broadinstitute/gatk/issues/1201:74,Usability,simpl,simple,74,"Gatk-protected needs to be able to write bed files. They've implemented a simple writer, but it only writes the required fields and doesn't include optional ones. . This will be considered completed when a complex bed file can be read in as a FeatureInput and then written back to disk identically.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1201
https://github.com/broadinstitute/gatk/issues/1206:108,Testability,test,tests,108,We need to have the ability to read from a ga4gh compliant readstore. The task to is implement this and add tests for it (using reference reads store or google genomics - ideally both),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1206
https://github.com/broadinstitute/gatk/issues/1209:118,Deployability,integrat,integration,118,SplitNCigarReadsIntegrationTest and SplitNCigarReadsUnitTest are bizzarely similar. something weird is going on. the 'integration test' is not really an intergration test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1209
https://github.com/broadinstitute/gatk/issues/1209:118,Integrability,integrat,integration,118,SplitNCigarReadsIntegrationTest and SplitNCigarReadsUnitTest are bizzarely similar. something weird is going on. the 'integration test' is not really an intergration test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1209
https://github.com/broadinstitute/gatk/issues/1209:130,Testability,test,test,130,SplitNCigarReadsIntegrationTest and SplitNCigarReadsUnitTest are bizzarely similar. something weird is going on. the 'integration test' is not really an intergration test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1209
https://github.com/broadinstitute/gatk/issues/1209:166,Testability,test,test,166,SplitNCigarReadsIntegrationTest and SplitNCigarReadsUnitTest are bizzarely similar. something weird is going on. the 'integration test' is not really an intergration test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1209
https://github.com/broadinstitute/gatk/pull/1211:56,Deployability,install,installDist,56,"this is a script which can be used after running gradle installDist to run spark jobs; it can be used identically to ths build/install/bin/gatk script, but has extra features for dealing with spark. running a spark tool and supplying the option --sparkTarget with LOCAL, CLUSTER, or GCS has special behavior; LOCAL will run the tool in the in memory spark runner; CLUSTER along with an appropriate --sparkMaster will run on an accessible spark cluster using spark-submit; arguments to spark-submit may be specified before the arguments to GATK by separating them with a --; GCS will submit jobs to google dataproc using gcloud; common arguments for spark submit will be adapted to match the gcloud formating; this will fail if gcloud isn't installed. if GATK_GCS_STAGING is specified, the jar will be uploaded and cached in the specified bucket for rapid re-use. input files will not be autouploaded to the cloud. --dry-run may be specified before the --, this will only print the commands that will be run instead of actually running them. Adding DataProcArgumentReplace simple tool to convert spark-submit args into gcloud args.; This conversion is not guarenteed to translate all spark command line options to matching gcloud ones.; If you find options that are not translated or are miss-translated please file an issue.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1211
https://github.com/broadinstitute/gatk/pull/1211:127,Deployability,install,install,127,"this is a script which can be used after running gradle installDist to run spark jobs; it can be used identically to ths build/install/bin/gatk script, but has extra features for dealing with spark. running a spark tool and supplying the option --sparkTarget with LOCAL, CLUSTER, or GCS has special behavior; LOCAL will run the tool in the in memory spark runner; CLUSTER along with an appropriate --sparkMaster will run on an accessible spark cluster using spark-submit; arguments to spark-submit may be specified before the arguments to GATK by separating them with a --; GCS will submit jobs to google dataproc using gcloud; common arguments for spark submit will be adapted to match the gcloud formating; this will fail if gcloud isn't installed. if GATK_GCS_STAGING is specified, the jar will be uploaded and cached in the specified bucket for rapid re-use. input files will not be autouploaded to the cloud. --dry-run may be specified before the --, this will only print the commands that will be run instead of actually running them. Adding DataProcArgumentReplace simple tool to convert spark-submit args into gcloud args.; This conversion is not guarenteed to translate all spark command line options to matching gcloud ones.; If you find options that are not translated or are miss-translated please file an issue.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1211
