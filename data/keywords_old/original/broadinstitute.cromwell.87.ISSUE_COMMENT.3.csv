id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/broadinstitute/cromwell/issues/2535#issuecomment-321847390:77,Performance,concurren,concurrent,77,"```; Caused by: java.io.IOException: insufficient data written; #011at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); #011at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); #011at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); #011at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); #011at akka.dispatch.Mailbox.exec(Mailbox.scala:234); #011at akka.dispatch.Mailbox.run(Mailbox.scala:224); #011at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); #011at akka.actor.ActorCell.invoke(ActorCell.scala:494); #011at akka.actor.ActorCell.autoReceiveMessage(ActorCell.scala:511); #011at akka.actor.ActorCell.receivedTerminated(ActorCell.scala:374); #011at akka.actor.dungeon.DeathWatch$class.receivedTerminated(DeathWatch.scala:46); #011at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager.aroundReceive(JesApiQueryManager.scala:26); #011at akka.actor.Actor$class.aroundReceive(Actor.scala:496); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager$$anonfun$receive$1.applyOrElse(JesApiQueryManager.scala:51); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager.cromwell$backend$impl$jes$statuspolling$JesApiQueryManager$$handleTerminated(JesApiQueryManager.scala:101); #011at scala.collection.immutable.List.foreach(List.scala:381); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager$$anonfun$cromwell$backend$impl$jes$statuspolling$JesApiQueryManager$$handleTerminated$1.apply(JesApiQueryManager.scala:101); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager$$anonfun$cromwell$backend$impl$jes$statuspolling$JesApiQueryManager$$handleTerminated$1.apply(JesApiQueryManager.scala:103); cromwell.backend.impl.jes.statuspolling.JesApiQueryManager$JesApiException: Unable to complete JES Api Request; 2017-08-10 08:29:38,408 cromwell-system-akka.dispatche",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2535#issuecomment-321847390
https://github.com/broadinstitute/cromwell/issues/2535#issuecomment-321847390:167,Performance,concurren,concurrent,167,"```; Caused by: java.io.IOException: insufficient data written; #011at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); #011at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); #011at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); #011at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); #011at akka.dispatch.Mailbox.exec(Mailbox.scala:234); #011at akka.dispatch.Mailbox.run(Mailbox.scala:224); #011at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); #011at akka.actor.ActorCell.invoke(ActorCell.scala:494); #011at akka.actor.ActorCell.autoReceiveMessage(ActorCell.scala:511); #011at akka.actor.ActorCell.receivedTerminated(ActorCell.scala:374); #011at akka.actor.dungeon.DeathWatch$class.receivedTerminated(DeathWatch.scala:46); #011at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager.aroundReceive(JesApiQueryManager.scala:26); #011at akka.actor.Actor$class.aroundReceive(Actor.scala:496); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager$$anonfun$receive$1.applyOrElse(JesApiQueryManager.scala:51); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager.cromwell$backend$impl$jes$statuspolling$JesApiQueryManager$$handleTerminated(JesApiQueryManager.scala:101); #011at scala.collection.immutable.List.foreach(List.scala:381); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager$$anonfun$cromwell$backend$impl$jes$statuspolling$JesApiQueryManager$$handleTerminated$1.apply(JesApiQueryManager.scala:101); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager$$anonfun$cromwell$backend$impl$jes$statuspolling$JesApiQueryManager$$handleTerminated$1.apply(JesApiQueryManager.scala:103); cromwell.backend.impl.jes.statuspolling.JesApiQueryManager$JesApiException: Unable to complete JES Api Request; 2017-08-10 08:29:38,408 cromwell-system-akka.dispatche",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2535#issuecomment-321847390
https://github.com/broadinstitute/cromwell/issues/2535#issuecomment-321847390:248,Performance,concurren,concurrent,248,"```; Caused by: java.io.IOException: insufficient data written; #011at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); #011at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); #011at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); #011at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); #011at akka.dispatch.Mailbox.exec(Mailbox.scala:234); #011at akka.dispatch.Mailbox.run(Mailbox.scala:224); #011at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); #011at akka.actor.ActorCell.invoke(ActorCell.scala:494); #011at akka.actor.ActorCell.autoReceiveMessage(ActorCell.scala:511); #011at akka.actor.ActorCell.receivedTerminated(ActorCell.scala:374); #011at akka.actor.dungeon.DeathWatch$class.receivedTerminated(DeathWatch.scala:46); #011at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager.aroundReceive(JesApiQueryManager.scala:26); #011at akka.actor.Actor$class.aroundReceive(Actor.scala:496); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager$$anonfun$receive$1.applyOrElse(JesApiQueryManager.scala:51); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager.cromwell$backend$impl$jes$statuspolling$JesApiQueryManager$$handleTerminated(JesApiQueryManager.scala:101); #011at scala.collection.immutable.List.foreach(List.scala:381); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager$$anonfun$cromwell$backend$impl$jes$statuspolling$JesApiQueryManager$$handleTerminated$1.apply(JesApiQueryManager.scala:101); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager$$anonfun$cromwell$backend$impl$jes$statuspolling$JesApiQueryManager$$handleTerminated$1.apply(JesApiQueryManager.scala:103); cromwell.backend.impl.jes.statuspolling.JesApiQueryManager$JesApiException: Unable to complete JES Api Request; 2017-08-10 08:29:38,408 cromwell-system-akka.dispatche",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2535#issuecomment-321847390
https://github.com/broadinstitute/cromwell/issues/2535#issuecomment-321847390:337,Performance,concurren,concurrent,337,"```; Caused by: java.io.IOException: insufficient data written; #011at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); #011at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); #011at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); #011at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); #011at akka.dispatch.Mailbox.exec(Mailbox.scala:234); #011at akka.dispatch.Mailbox.run(Mailbox.scala:224); #011at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); #011at akka.actor.ActorCell.invoke(ActorCell.scala:494); #011at akka.actor.ActorCell.autoReceiveMessage(ActorCell.scala:511); #011at akka.actor.ActorCell.receivedTerminated(ActorCell.scala:374); #011at akka.actor.dungeon.DeathWatch$class.receivedTerminated(DeathWatch.scala:46); #011at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager.aroundReceive(JesApiQueryManager.scala:26); #011at akka.actor.Actor$class.aroundReceive(Actor.scala:496); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager$$anonfun$receive$1.applyOrElse(JesApiQueryManager.scala:51); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager.cromwell$backend$impl$jes$statuspolling$JesApiQueryManager$$handleTerminated(JesApiQueryManager.scala:101); #011at scala.collection.immutable.List.foreach(List.scala:381); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager$$anonfun$cromwell$backend$impl$jes$statuspolling$JesApiQueryManager$$handleTerminated$1.apply(JesApiQueryManager.scala:101); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager$$anonfun$cromwell$backend$impl$jes$statuspolling$JesApiQueryManager$$handleTerminated$1.apply(JesApiQueryManager.scala:103); cromwell.backend.impl.jes.statuspolling.JesApiQueryManager$JesApiException: Unable to complete JES Api Request; 2017-08-10 08:29:38,408 cromwell-system-akka.dispatche",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2535#issuecomment-321847390
https://github.com/broadinstitute/cromwell/issues/2535#issuecomment-321847390:2295,Testability,log,logs,2295,"vedTerminated(ActorCell.scala:374); #011at akka.actor.dungeon.DeathWatch$class.receivedTerminated(DeathWatch.scala:46); #011at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager.aroundReceive(JesApiQueryManager.scala:26); #011at akka.actor.Actor$class.aroundReceive(Actor.scala:496); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager$$anonfun$receive$1.applyOrElse(JesApiQueryManager.scala:51); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager.cromwell$backend$impl$jes$statuspolling$JesApiQueryManager$$handleTerminated(JesApiQueryManager.scala:101); #011at scala.collection.immutable.List.foreach(List.scala:381); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager$$anonfun$cromwell$backend$impl$jes$statuspolling$JesApiQueryManager$$handleTerminated$1.apply(JesApiQueryManager.scala:101); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager$$anonfun$cromwell$backend$impl$jes$statuspolling$JesApiQueryManager$$handleTerminated$1.apply(JesApiQueryManager.scala:103); cromwell.backend.impl.jes.statuspolling.JesApiQueryManager$JesApiException: Unable to complete JES Api Request; 2017-08-10 08:29:38,408 cromwell-system-akka.dispatchers.engine-dispatcher-64 ERROR - WorkflowManagerActor Workflow e3f4d391-a0bc-480f-9203-d0ef4ee5b876 failed (during ExecutingWorkflowState): Unable to complete JES Api Request; 2017-08-10 08:29:37,713 cromwell-system-akka.dispatchers.io-dispatcher-38 INFO - $e [UUID(fb9254a8)]: Copying workflow logs from /cromwell-workflow-logs/workflow.fb9254a8-00ec-48bc-b8c8-2f0e5e74fa81.log to gs://fc-35446f22-ea37-483a-bd6c-5e9fc56851ff/9ef84046-7047-423b-88e8-bb138181f5a8/workflow.logs/workflow.fb9254a8-00ec-48bc-b8c8-2f0e5e74fa81.log; 2017-08-10 08:29:37,713 cromwell-system-akka.dispatchers.engine-dispatcher-6 INFO - WorkflowManagerActor WorkflowActor-fb9254a8-00ec-48bc-b8c8-2f0e5e74fa81 is in a terminal state: WorkflowFailedState```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2535#issuecomment-321847390
https://github.com/broadinstitute/cromwell/issues/2535#issuecomment-321847390:2324,Testability,log,logs,2324,"vedTerminated(ActorCell.scala:374); #011at akka.actor.dungeon.DeathWatch$class.receivedTerminated(DeathWatch.scala:46); #011at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager.aroundReceive(JesApiQueryManager.scala:26); #011at akka.actor.Actor$class.aroundReceive(Actor.scala:496); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager$$anonfun$receive$1.applyOrElse(JesApiQueryManager.scala:51); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager.cromwell$backend$impl$jes$statuspolling$JesApiQueryManager$$handleTerminated(JesApiQueryManager.scala:101); #011at scala.collection.immutable.List.foreach(List.scala:381); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager$$anonfun$cromwell$backend$impl$jes$statuspolling$JesApiQueryManager$$handleTerminated$1.apply(JesApiQueryManager.scala:101); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager$$anonfun$cromwell$backend$impl$jes$statuspolling$JesApiQueryManager$$handleTerminated$1.apply(JesApiQueryManager.scala:103); cromwell.backend.impl.jes.statuspolling.JesApiQueryManager$JesApiException: Unable to complete JES Api Request; 2017-08-10 08:29:38,408 cromwell-system-akka.dispatchers.engine-dispatcher-64 ERROR - WorkflowManagerActor Workflow e3f4d391-a0bc-480f-9203-d0ef4ee5b876 failed (during ExecutingWorkflowState): Unable to complete JES Api Request; 2017-08-10 08:29:37,713 cromwell-system-akka.dispatchers.io-dispatcher-38 INFO - $e [UUID(fb9254a8)]: Copying workflow logs from /cromwell-workflow-logs/workflow.fb9254a8-00ec-48bc-b8c8-2f0e5e74fa81.log to gs://fc-35446f22-ea37-483a-bd6c-5e9fc56851ff/9ef84046-7047-423b-88e8-bb138181f5a8/workflow.logs/workflow.fb9254a8-00ec-48bc-b8c8-2f0e5e74fa81.log; 2017-08-10 08:29:37,713 cromwell-system-akka.dispatchers.engine-dispatcher-6 INFO - WorkflowManagerActor WorkflowActor-fb9254a8-00ec-48bc-b8c8-2f0e5e74fa81 is in a terminal state: WorkflowFailedState```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2535#issuecomment-321847390
https://github.com/broadinstitute/cromwell/issues/2535#issuecomment-321847390:2375,Testability,log,log,2375,"vedTerminated(ActorCell.scala:374); #011at akka.actor.dungeon.DeathWatch$class.receivedTerminated(DeathWatch.scala:46); #011at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager.aroundReceive(JesApiQueryManager.scala:26); #011at akka.actor.Actor$class.aroundReceive(Actor.scala:496); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager$$anonfun$receive$1.applyOrElse(JesApiQueryManager.scala:51); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager.cromwell$backend$impl$jes$statuspolling$JesApiQueryManager$$handleTerminated(JesApiQueryManager.scala:101); #011at scala.collection.immutable.List.foreach(List.scala:381); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager$$anonfun$cromwell$backend$impl$jes$statuspolling$JesApiQueryManager$$handleTerminated$1.apply(JesApiQueryManager.scala:101); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager$$anonfun$cromwell$backend$impl$jes$statuspolling$JesApiQueryManager$$handleTerminated$1.apply(JesApiQueryManager.scala:103); cromwell.backend.impl.jes.statuspolling.JesApiQueryManager$JesApiException: Unable to complete JES Api Request; 2017-08-10 08:29:38,408 cromwell-system-akka.dispatchers.engine-dispatcher-64 ERROR - WorkflowManagerActor Workflow e3f4d391-a0bc-480f-9203-d0ef4ee5b876 failed (during ExecutingWorkflowState): Unable to complete JES Api Request; 2017-08-10 08:29:37,713 cromwell-system-akka.dispatchers.io-dispatcher-38 INFO - $e [UUID(fb9254a8)]: Copying workflow logs from /cromwell-workflow-logs/workflow.fb9254a8-00ec-48bc-b8c8-2f0e5e74fa81.log to gs://fc-35446f22-ea37-483a-bd6c-5e9fc56851ff/9ef84046-7047-423b-88e8-bb138181f5a8/workflow.logs/workflow.fb9254a8-00ec-48bc-b8c8-2f0e5e74fa81.log; 2017-08-10 08:29:37,713 cromwell-system-akka.dispatchers.engine-dispatcher-6 INFO - WorkflowManagerActor WorkflowActor-fb9254a8-00ec-48bc-b8c8-2f0e5e74fa81 is in a terminal state: WorkflowFailedState```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2535#issuecomment-321847390
https://github.com/broadinstitute/cromwell/issues/2535#issuecomment-321847390:2473,Testability,log,logs,2473,"vedTerminated(ActorCell.scala:374); #011at akka.actor.dungeon.DeathWatch$class.receivedTerminated(DeathWatch.scala:46); #011at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager.aroundReceive(JesApiQueryManager.scala:26); #011at akka.actor.Actor$class.aroundReceive(Actor.scala:496); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager$$anonfun$receive$1.applyOrElse(JesApiQueryManager.scala:51); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager.cromwell$backend$impl$jes$statuspolling$JesApiQueryManager$$handleTerminated(JesApiQueryManager.scala:101); #011at scala.collection.immutable.List.foreach(List.scala:381); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager$$anonfun$cromwell$backend$impl$jes$statuspolling$JesApiQueryManager$$handleTerminated$1.apply(JesApiQueryManager.scala:101); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager$$anonfun$cromwell$backend$impl$jes$statuspolling$JesApiQueryManager$$handleTerminated$1.apply(JesApiQueryManager.scala:103); cromwell.backend.impl.jes.statuspolling.JesApiQueryManager$JesApiException: Unable to complete JES Api Request; 2017-08-10 08:29:38,408 cromwell-system-akka.dispatchers.engine-dispatcher-64 ERROR - WorkflowManagerActor Workflow e3f4d391-a0bc-480f-9203-d0ef4ee5b876 failed (during ExecutingWorkflowState): Unable to complete JES Api Request; 2017-08-10 08:29:37,713 cromwell-system-akka.dispatchers.io-dispatcher-38 INFO - $e [UUID(fb9254a8)]: Copying workflow logs from /cromwell-workflow-logs/workflow.fb9254a8-00ec-48bc-b8c8-2f0e5e74fa81.log to gs://fc-35446f22-ea37-483a-bd6c-5e9fc56851ff/9ef84046-7047-423b-88e8-bb138181f5a8/workflow.logs/workflow.fb9254a8-00ec-48bc-b8c8-2f0e5e74fa81.log; 2017-08-10 08:29:37,713 cromwell-system-akka.dispatchers.engine-dispatcher-6 INFO - WorkflowManagerActor WorkflowActor-fb9254a8-00ec-48bc-b8c8-2f0e5e74fa81 is in a terminal state: WorkflowFailedState```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2535#issuecomment-321847390
https://github.com/broadinstitute/cromwell/issues/2535#issuecomment-321847390:2524,Testability,log,log,2524,"vedTerminated(ActorCell.scala:374); #011at akka.actor.dungeon.DeathWatch$class.receivedTerminated(DeathWatch.scala:46); #011at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager.aroundReceive(JesApiQueryManager.scala:26); #011at akka.actor.Actor$class.aroundReceive(Actor.scala:496); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager$$anonfun$receive$1.applyOrElse(JesApiQueryManager.scala:51); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager.cromwell$backend$impl$jes$statuspolling$JesApiQueryManager$$handleTerminated(JesApiQueryManager.scala:101); #011at scala.collection.immutable.List.foreach(List.scala:381); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager$$anonfun$cromwell$backend$impl$jes$statuspolling$JesApiQueryManager$$handleTerminated$1.apply(JesApiQueryManager.scala:101); #011at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager$$anonfun$cromwell$backend$impl$jes$statuspolling$JesApiQueryManager$$handleTerminated$1.apply(JesApiQueryManager.scala:103); cromwell.backend.impl.jes.statuspolling.JesApiQueryManager$JesApiException: Unable to complete JES Api Request; 2017-08-10 08:29:38,408 cromwell-system-akka.dispatchers.engine-dispatcher-64 ERROR - WorkflowManagerActor Workflow e3f4d391-a0bc-480f-9203-d0ef4ee5b876 failed (during ExecutingWorkflowState): Unable to complete JES Api Request; 2017-08-10 08:29:37,713 cromwell-system-akka.dispatchers.io-dispatcher-38 INFO - $e [UUID(fb9254a8)]: Copying workflow logs from /cromwell-workflow-logs/workflow.fb9254a8-00ec-48bc-b8c8-2f0e5e74fa81.log to gs://fc-35446f22-ea37-483a-bd6c-5e9fc56851ff/9ef84046-7047-423b-88e8-bb138181f5a8/workflow.logs/workflow.fb9254a8-00ec-48bc-b8c8-2f0e5e74fa81.log; 2017-08-10 08:29:37,713 cromwell-system-akka.dispatchers.engine-dispatcher-6 INFO - WorkflowManagerActor WorkflowActor-fb9254a8-00ec-48bc-b8c8-2f0e5e74fa81 is in a terminal state: WorkflowFailedState```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2535#issuecomment-321847390
https://github.com/broadinstitute/cromwell/issues/2535#issuecomment-322288854:122,Integrability,protocol,protocol,122,Different stack trace but same exception:. ```; Caused by: java.io.IOException: insufficient data written; at sun.net.www.protocol.http.HttpURLConnection$StreamingOutputStream.close(HttpURLConnection.java:3540); at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:81); at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); at com.google.api.client.googleapis.batch.BatchRequest.execute(BatchRequest.java:241); at cromwell.backend.impl.jes.statuspolling.JesPollingActor.runBatch(JesPollingActor.scala:63); at cromwell.backend.impl.jes.statuspolling.JesPollingActor.cromwell$backend$impl$jes$statuspolling$JesPollingActor$$handleBatch(JesPollingActor.scala:57); at cromwell.backend.impl.jes.statuspolling.JesPollingActor$$anonfun$receive$1.applyOrElse(JesPollingActor.scala:36); at akka.actor.Actor$class.aroundReceive(Actor.scala:496); at cromwell.backend.impl.jes.statuspolling.JesPollingActor.aroundReceive(JesPollingActor.scala:22); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); at akka.actor.ActorCell.invoke(ActorCell.scala:495); ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2535#issuecomment-322288854
https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321823273:33,Security,hash,hash-lookup,33,"@LeeTL1220 are you using `docker.hash-lookup.method = ""local""` ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321823273
https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321823882:32,Integrability,message,message,32,I'm pretty sure if you see this message it means that it wasn't able to get the hash at all,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321823882
https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321823882:80,Security,hash,hash,80,I'm pretty sure if you see this message it means that it wasn't able to get the hash at all,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321823882
https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321825726:180,Integrability,message,message,180,"It ran the task and I don't see how it could have done that otherwise.. On Fri, Aug 11, 2017 at 10:13 AM, Thib <notifications@github.com> wrote:. > I'm pretty sure if you see this message it means that it wasn't able to; > get the hash at all; >; > ‚Äî; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321823882>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk3eHGDQKVm_OJyuRuQ8i9BrfJ1bqks5sXGGJgaJpZM4O0GvF>; > .; >. -- ; Lee Lichtenstein; Broad Institute; 75 Ames Street, Room 8011A; Cambridge, MA 02142; 617 714 8632",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321825726
https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321825726:231,Security,hash,hash,231,"It ran the task and I don't see how it could have done that otherwise.. On Fri, Aug 11, 2017 at 10:13 AM, Thib <notifications@github.com> wrote:. > I'm pretty sure if you see this message it means that it wasn't able to; > get the hash at all; >; > ‚Äî; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321823882>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk3eHGDQKVm_OJyuRuQ8i9BrfJ1bqks5sXGGJgaJpZM4O0GvF>; > .; >. -- ; Lee Lichtenstein; Broad Institute; 75 Ames Street, Room 8011A; Cambridge, MA 02142; 617 714 8632",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321825726
https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321842808:71,Performance,cache,cache,71,"It can run the task without having its hash, it just won't try to call cache it nor write it to the cache",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321842808
https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321842808:100,Performance,cache,cache,100,"It can run the task without having its hash, it just won't try to call cache it nor write it to the cache",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321842808
https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321842808:39,Security,hash,hash,39,"It can run the task without having its hash, it just won't try to call cache it nor write it to the cache",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321842808
https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321869435:271,Performance,cache,cache,271,"IT should be able to get the hash. Anyway, in this case, it's not a big; deal, since this is part of our github testing. On Fri, Aug 11, 2017 at 11:22 AM, Thib <notifications@github.com> wrote:. > It can run the task without having its hash, it just won't try to call; > cache it nor write it to the cache; >; > ‚Äî; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321842808>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk4g7uP1uJPFhouOoyfne9aGXQrA8ks5sXHHBgaJpZM4O0GvF>; > .; >. -- ; Lee Lichtenstein; Broad Institute; 75 Ames Street, Room 8011A; Cambridge, MA 02142; 617 714 8632",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321869435
https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321869435:300,Performance,cache,cache,300,"IT should be able to get the hash. Anyway, in this case, it's not a big; deal, since this is part of our github testing. On Fri, Aug 11, 2017 at 11:22 AM, Thib <notifications@github.com> wrote:. > It can run the task without having its hash, it just won't try to call; > cache it nor write it to the cache; >; > ‚Äî; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321842808>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk4g7uP1uJPFhouOoyfne9aGXQrA8ks5sXHHBgaJpZM4O0GvF>; > .; >. -- ; Lee Lichtenstein; Broad Institute; 75 Ames Street, Room 8011A; Cambridge, MA 02142; 617 714 8632",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321869435
https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321869435:29,Security,hash,hash,29,"IT should be able to get the hash. Anyway, in this case, it's not a big; deal, since this is part of our github testing. On Fri, Aug 11, 2017 at 11:22 AM, Thib <notifications@github.com> wrote:. > It can run the task without having its hash, it just won't try to call; > cache it nor write it to the cache; >; > ‚Äî; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321842808>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk4g7uP1uJPFhouOoyfne9aGXQrA8ks5sXHHBgaJpZM4O0GvF>; > .; >. -- ; Lee Lichtenstein; Broad Institute; 75 Ames Street, Room 8011A; Cambridge, MA 02142; 617 714 8632",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321869435
https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321869435:236,Security,hash,hash,236,"IT should be able to get the hash. Anyway, in this case, it's not a big; deal, since this is part of our github testing. On Fri, Aug 11, 2017 at 11:22 AM, Thib <notifications@github.com> wrote:. > It can run the task without having its hash, it just won't try to call; > cache it nor write it to the cache; >; > ‚Äî; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321842808>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk4g7uP1uJPFhouOoyfne9aGXQrA8ks5sXHHBgaJpZM4O0GvF>; > .; >. -- ; Lee Lichtenstein; Broad Institute; 75 Ames Street, Room 8011A; Cambridge, MA 02142; 617 714 8632",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321869435
https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321869435:112,Testability,test,testing,112,"IT should be able to get the hash. Anyway, in this case, it's not a big; deal, since this is part of our github testing. On Fri, Aug 11, 2017 at 11:22 AM, Thib <notifications@github.com> wrote:. > It can run the task without having its hash, it just won't try to call; > cache it nor write it to the cache; >; > ‚Äî; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321842808>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk4g7uP1uJPFhouOoyfne9aGXQrA8ks5sXHHBgaJpZM4O0GvF>; > .; >. -- ; Lee Lichtenstein; Broad Institute; 75 Ames Street, Room 8011A; Cambridge, MA 02142; 617 714 8632",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321869435
https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321872886:129,Security,hash,hash,129,"If the image is not on dockerhub but exists locally where the Cromwell application is running then it should be able to find the hash if `docker.hash-lookup.method = ""local""`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321872886
https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321872886:145,Security,hash,hash-lookup,145,"If the image is not on dockerhub but exists locally where the Cromwell application is running then it should be able to find the hash if `docker.hash-lookup.method = ""local""`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321872886
https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321874576:44,Integrability,message,messages,44,"Excellent. So if I fix that in my conf, the messages should go away,; right? Can I specify docker.hash-lookup.method in the workflow_options?. On Fri, Aug 11, 2017 at 1:31 PM, Thib <notifications@github.com> wrote:. > If the image is not on dockerhub but exists locally to where the Cromwell; > application is running then it should be able to find the hash if docker.hash-lookup.method; > = ""local""; >; > ‚Äî; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321872886>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXkxZ61CdCMTLR5po4xUtPAM1MnJ0sks5sXI_2gaJpZM4O0GvF>; > .; >. -- ; Lee Lichtenstein; Broad Institute; 75 Ames Street, Room 8011A; Cambridge, MA 02142; 617 714 8632",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321874576
https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321874576:98,Security,hash,hash-lookup,98,"Excellent. So if I fix that in my conf, the messages should go away,; right? Can I specify docker.hash-lookup.method in the workflow_options?. On Fri, Aug 11, 2017 at 1:31 PM, Thib <notifications@github.com> wrote:. > If the image is not on dockerhub but exists locally to where the Cromwell; > application is running then it should be able to find the hash if docker.hash-lookup.method; > = ""local""; >; > ‚Äî; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321872886>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXkxZ61CdCMTLR5po4xUtPAM1MnJ0sks5sXI_2gaJpZM4O0GvF>; > .; >. -- ; Lee Lichtenstein; Broad Institute; 75 Ames Street, Room 8011A; Cambridge, MA 02142; 617 714 8632",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321874576
https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321874576:353,Security,hash,hash,353,"Excellent. So if I fix that in my conf, the messages should go away,; right? Can I specify docker.hash-lookup.method in the workflow_options?. On Fri, Aug 11, 2017 at 1:31 PM, Thib <notifications@github.com> wrote:. > If the image is not on dockerhub but exists locally to where the Cromwell; > application is running then it should be able to find the hash if docker.hash-lookup.method; > = ""local""; >; > ‚Äî; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321872886>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXkxZ61CdCMTLR5po4xUtPAM1MnJ0sks5sXI_2gaJpZM4O0GvF>; > .; >. -- ; Lee Lichtenstein; Broad Institute; 75 Ames Street, Room 8011A; Cambridge, MA 02142; 617 714 8632",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321874576
https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321874576:368,Security,hash,hash-lookup,368,"Excellent. So if I fix that in my conf, the messages should go away,; right? Can I specify docker.hash-lookup.method in the workflow_options?. On Fri, Aug 11, 2017 at 1:31 PM, Thib <notifications@github.com> wrote:. > If the image is not on dockerhub but exists locally to where the Cromwell; > application is running then it should be able to find the hash if docker.hash-lookup.method; > = ""local""; >; > ‚Äî; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321872886>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXkxZ61CdCMTLR5po4xUtPAM1MnJ0sks5sXI_2gaJpZM4O0GvF>; > .; >. -- ; Lee Lichtenstein; Broad Institute; 75 Ames Street, Room 8011A; Cambridge, MA 02142; 617 714 8632",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321874576
https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321876895:35,Integrability,message,messages,35,"> So if I fix that in my conf, the messages should go away,; right?. Yes. > Can I specify docker.hash-lookup.method in the workflow_options?. No, if that's something you'd like feel free to create a github issue :)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321876895
https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321876895:97,Security,hash,hash-lookup,97,"> So if I fix that in my conf, the messages should go away,; right?. Yes. > Can I specify docker.hash-lookup.method in the workflow_options?. No, if that's something you'd like feel free to create a github issue :)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321876895
https://github.com/broadinstitute/cromwell/pull/2541#issuecomment-321910634:61,Deployability,deploy,deployments,61,"@cjllanwarne we could, but it's really just for our internal deployments with devops so imo it's not necessary and would just add to the visual noise of our docs. It'd only take a couple of minutes to create said visual noise if you really think it'd be helpful",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2541#issuecomment-321910634
https://github.com/broadinstitute/cromwell/pull/2542#issuecomment-322078309:199,Deployability,install,installations,199,"@Horneth Out of curiosity, do you have any real world numbers on the impact memory-wise? Is this only really going to be a big impact for huge WFs like in the JG case or should this also help out w/ installations like FC?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2542#issuecomment-322078309
https://github.com/broadinstitute/cromwell/pull/2543#issuecomment-321990621:24,Modifiability,extend,extend,24,üëç . ToL: Since they all extend the `BatchingDbWriterActor` trait we could even put this logging there instead. [![Approved with PullApprove](https://img.shields.io/badge/reviewers-approved-brightgreen.svg)](https://pullapprove.com/broadinstitute/cromwell/pull-request/2543/?utm_source=github-pr&utm_medium=comment-badge&utm_campaign=broadinstitute/cromwell),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2543#issuecomment-321990621
https://github.com/broadinstitute/cromwell/pull/2543#issuecomment-321990621:88,Testability,log,logging,88,üëç . ToL: Since they all extend the `BatchingDbWriterActor` trait we could even put this logging there instead. [![Approved with PullApprove](https://img.shields.io/badge/reviewers-approved-brightgreen.svg)](https://pullapprove.com/broadinstitute/cromwell/pull-request/2543/?utm_source=github-pr&utm_medium=comment-badge&utm_campaign=broadinstitute/cromwell),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2543#issuecomment-321990621
https://github.com/broadinstitute/cromwell/pull/2546#issuecomment-322291846:197,Testability,test,tests,197,"@cjllanwarne about the migration that's a good point. I think we're going to want to add that and warn firecloud of the change.; Also looks like we're already using `""null""` in centaur in multiple tests so I'll have to change that",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2546#issuecomment-322291846
https://github.com/broadinstitute/cromwell/pull/2546#issuecomment-322329894:168,Availability,downtime,downtime,168,"@cjllanwarne Initially the concern was that I've heard, well, concern from firecloud folks here and there about frivolous metadata migrations on our part as they cause downtime they don't always want to incur. It also ties in to my rapidly increasing sentiment that we should not be migrating a supposedly immutable data store for what are merely cosmetic changes - if we have to in order to fix something we know is causing issues w/ programatic clients you gotta do what you gotta do. When we talked with @abaumann he indicated that a) they wouldn't really care if the old data stayed as-is and b) made a similar point as I did about the event store. @Horneth with all of these taken together I don't think we should be migrating. The key constituency has said that it would be at best superfluous and IMO it's part of a habit we should be getting out of anyways.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2546#issuecomment-322329894
https://github.com/broadinstitute/cromwell/issues/2548#issuecomment-332626911:98,Modifiability,config,configured,98,"As a **user running workflows**, I want **Cromwell to use a default job count limit if I have not configured a `concurrent-job-limit`**, so that **the backend defaults to a sensible job limit**.; * Effort: Small; * Risk: Small; * Business Value: Small to Medium",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2548#issuecomment-332626911
https://github.com/broadinstitute/cromwell/issues/2548#issuecomment-332626911:112,Performance,concurren,concurrent-job-limit,112,"As a **user running workflows**, I want **Cromwell to use a default job count limit if I have not configured a `concurrent-job-limit`**, so that **the backend defaults to a sensible job limit**.; * Effort: Small; * Risk: Small; * Business Value: Small to Medium",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2548#issuecomment-332626911
https://github.com/broadinstitute/cromwell/issues/2548#issuecomment-332626911:215,Safety,Risk,Risk,215,"As a **user running workflows**, I want **Cromwell to use a default job count limit if I have not configured a `concurrent-job-limit`**, so that **the backend defaults to a sensible job limit**.; * Effort: Small; * Risk: Small; * Business Value: Small to Medium",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2548#issuecomment-332626911
https://github.com/broadinstitute/cromwell/issues/2562#issuecomment-323794220:135,Safety,timeout,timeout,135,"Looks like it issues a SIGTERM by default: https://www.ctl.io/developers/blog/post/gracefully-stopping-docker-containers/. However the timeout for docker will be shorter than cromwell's, so we should still document how to change *that* (`docker stop ----time=30 foo`) and thus I'm not closing this like I just said I would.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2562#issuecomment-323794220
https://github.com/broadinstitute/cromwell/issues/2562#issuecomment-325717424:71,Availability,down,down,71,@katevoss This issue expects that there is some way to gracefully shut down Cromwell and that stopping the docker process does not do it by default. . #1495 looks to me like an edge case and is not related to this issue.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2562#issuecomment-325717424
https://github.com/broadinstitute/cromwell/issues/2564#issuecomment-324371179:382,Security,validat,validation,382,"It seems Cromwell is converting the undefined optional string as ""null"" since the inputs for the call are:; ```; ""inputs"": {; ""dockerStr"": ""null""; }; ```. Currently, when one uses optional's for other runtime attributes (such as disks or cpu), the job refuses to run as the JES backend requires values for both, the same way it requires a value for docker. It seems like due to the validation being run on non-docker attributes, when they have missing optional values, the job won't run. Since there is no validation for the docker string, Cromwell is trying to force the optional value as the docker value. It might be best if there was light layer of validation for the docker key which differentiated between a user given value vs an undefined optional. In the case of the optional, it would be good if it failed to run the job so that it would be consistent with the behavior of the other runtime attributes when they fail validation.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2564#issuecomment-324371179
https://github.com/broadinstitute/cromwell/issues/2564#issuecomment-324371179:506,Security,validat,validation,506,"It seems Cromwell is converting the undefined optional string as ""null"" since the inputs for the call are:; ```; ""inputs"": {; ""dockerStr"": ""null""; }; ```. Currently, when one uses optional's for other runtime attributes (such as disks or cpu), the job refuses to run as the JES backend requires values for both, the same way it requires a value for docker. It seems like due to the validation being run on non-docker attributes, when they have missing optional values, the job won't run. Since there is no validation for the docker string, Cromwell is trying to force the optional value as the docker value. It might be best if there was light layer of validation for the docker key which differentiated between a user given value vs an undefined optional. In the case of the optional, it would be good if it failed to run the job so that it would be consistent with the behavior of the other runtime attributes when they fail validation.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2564#issuecomment-324371179
https://github.com/broadinstitute/cromwell/issues/2564#issuecomment-324371179:653,Security,validat,validation,653,"It seems Cromwell is converting the undefined optional string as ""null"" since the inputs for the call are:; ```; ""inputs"": {; ""dockerStr"": ""null""; }; ```. Currently, when one uses optional's for other runtime attributes (such as disks or cpu), the job refuses to run as the JES backend requires values for both, the same way it requires a value for docker. It seems like due to the validation being run on non-docker attributes, when they have missing optional values, the job won't run. Since there is no validation for the docker string, Cromwell is trying to force the optional value as the docker value. It might be best if there was light layer of validation for the docker key which differentiated between a user given value vs an undefined optional. In the case of the optional, it would be good if it failed to run the job so that it would be consistent with the behavior of the other runtime attributes when they fail validation.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2564#issuecomment-324371179
https://github.com/broadinstitute/cromwell/issues/2564#issuecomment-324371179:927,Security,validat,validation,927,"It seems Cromwell is converting the undefined optional string as ""null"" since the inputs for the call are:; ```; ""inputs"": {; ""dockerStr"": ""null""; }; ```. Currently, when one uses optional's for other runtime attributes (such as disks or cpu), the job refuses to run as the JES backend requires values for both, the same way it requires a value for docker. It seems like due to the validation being run on non-docker attributes, when they have missing optional values, the job won't run. Since there is no validation for the docker string, Cromwell is trying to force the optional value as the docker value. It might be best if there was light layer of validation for the docker key which differentiated between a user given value vs an undefined optional. In the case of the optional, it would be good if it failed to run the job so that it would be consistent with the behavior of the other runtime attributes when they fail validation.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2564#issuecomment-324371179
https://github.com/broadinstitute/cromwell/issues/2565#issuecomment-323820125:163,Integrability,depend,depend,163,"Actually now that I think about it more I don't understand why the two with intermediate values can't be overridden. Is it bad to provide a default value that may depend on something else? I can think of cases where that would be useful. . The middle change is very helpful -- I'm willing to put up with a bit of potential confusion in order to have it. . One other question: will this affect what gets listed as ""requested"" by `wdltool inputs`? I'd like for everything that *can* be supplied to be in there even if I provided a default value.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2565#issuecomment-323820125
https://github.com/broadinstitute/cromwell/issues/2565#issuecomment-323822585:252,Deployability,release,released,252,@vdauwera My thought was that if you're wiring up something like that that there's probably a good reason to have done so. I could easily see people wanting to munge those values when debugging and such but then would it be an attractive nuisance once released into the wild?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2565#issuecomment-323822585
https://github.com/broadinstitute/cromwell/issues/2565#issuecomment-323826098:139,Integrability,depend,depending,139,"Well, here's a use case. I want to run the same workflow on exomes and on whole genomes, and some of my parameters take different defaults depending on the data type. It would be swell to be able to say e.g. `my_param = param_values[data_type]` assuming I've set up my defaults as maps with e.g. 'wgs' and 'exome' as keys, and I can somewhere set `data_type = 'wgs'` (because presumably several values would need to be switched) (by the way, does wdl have enums?). So I'd have defaults that are variable references -- but I might decide to use something else entirely and just input my_workflow.my_param = 5 in my json for whatever reason. . Is that crazy/wrong?. I guess I could instead do the override by injecting the value I want into `param_values`...? But then I'm constrained to work with whatever `data_types` have been planned for and can't add something different on the fly. . Does any of this make sense?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2565#issuecomment-323826098
https://github.com/broadinstitute/cromwell/issues/2565#issuecomment-323826098:707,Integrability,inject,injecting,707,"Well, here's a use case. I want to run the same workflow on exomes and on whole genomes, and some of my parameters take different defaults depending on the data type. It would be swell to be able to say e.g. `my_param = param_values[data_type]` assuming I've set up my defaults as maps with e.g. 'wgs' and 'exome' as keys, and I can somewhere set `data_type = 'wgs'` (because presumably several values would need to be switched) (by the way, does wdl have enums?). So I'd have defaults that are variable references -- but I might decide to use something else entirely and just input my_workflow.my_param = 5 in my json for whatever reason. . Is that crazy/wrong?. I guess I could instead do the override by injecting the value I want into `param_values`...? But then I'm constrained to work with whatever `data_types` have been planned for and can't add something different on the fly. . Does any of this make sense?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2565#issuecomment-323826098
https://github.com/broadinstitute/cromwell/issues/2565#issuecomment-323826098:495,Modifiability,variab,variable,495,"Well, here's a use case. I want to run the same workflow on exomes and on whole genomes, and some of my parameters take different defaults depending on the data type. It would be swell to be able to say e.g. `my_param = param_values[data_type]` assuming I've set up my defaults as maps with e.g. 'wgs' and 'exome' as keys, and I can somewhere set `data_type = 'wgs'` (because presumably several values would need to be switched) (by the way, does wdl have enums?). So I'd have defaults that are variable references -- but I might decide to use something else entirely and just input my_workflow.my_param = 5 in my json for whatever reason. . Is that crazy/wrong?. I guess I could instead do the override by injecting the value I want into `param_values`...? But then I'm constrained to work with whatever `data_types` have been planned for and can't add something different on the fly. . Does any of this make sense?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2565#issuecomment-323826098
https://github.com/broadinstitute/cromwell/issues/2565#issuecomment-323826098:707,Security,inject,injecting,707,"Well, here's a use case. I want to run the same workflow on exomes and on whole genomes, and some of my parameters take different defaults depending on the data type. It would be swell to be able to say e.g. `my_param = param_values[data_type]` assuming I've set up my defaults as maps with e.g. 'wgs' and 'exome' as keys, and I can somewhere set `data_type = 'wgs'` (because presumably several values would need to be switched) (by the way, does wdl have enums?). So I'd have defaults that are variable references -- but I might decide to use something else entirely and just input my_workflow.my_param = 5 in my json for whatever reason. . Is that crazy/wrong?. I guess I could instead do the override by injecting the value I want into `param_values`...? But then I'm constrained to work with whatever `data_types` have been planned for and can't add something different on the fly. . Does any of this make sense?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2565#issuecomment-323826098
https://github.com/broadinstitute/cromwell/issues/2565#issuecomment-323832181:104,Modifiability,variab,variable,104,"I think that defaults should be allowed to be overridden, even if the default value is based on another variable. Not sure I agree with the logic to prevent that.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2565#issuecomment-323832181
https://github.com/broadinstitute/cromwell/issues/2565#issuecomment-323832181:140,Testability,log,logic,140,"I think that defaults should be allowed to be overridden, even if the default value is based on another variable. Not sure I agree with the logic to prevent that.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2565#issuecomment-323832181
https://github.com/broadinstitute/cromwell/issues/2565#issuecomment-323832814:278,Availability,down,downstream,278,"@yfarjoun Yeah, I agree. @vdauwera quickly provided a totally valid use case beyond ""I'm screwing around"". Specifically what I was concerned about here is providing a case where we allow corners to be cuttable for the implementer which then leave loaded guns sitting around for downstream users to shoot themselves with.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2565#issuecomment-323832814
https://github.com/broadinstitute/cromwell/issues/2565#issuecomment-323832814:247,Performance,load,loaded,247,"@yfarjoun Yeah, I agree. @vdauwera quickly provided a totally valid use case beyond ""I'm screwing around"". Specifically what I was concerned about here is providing a case where we allow corners to be cuttable for the implementer which then leave loaded guns sitting around for downstream users to shoot themselves with.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2565#issuecomment-323832814
https://github.com/broadinstitute/cromwell/pull/2566#issuecomment-324109617:47,Testability,test,tests,47,üëç for this PR. Are there any remaining ignored tests that we still need to be looked at?. [![Approved with PullApprove](https://img.shields.io/badge/reviewers-approved-brightgreen.svg)](https://pullapprove.com/broadinstitute/cromwell/pull-request/2566/?utm_source=github-pr&utm_medium=comment-badge&utm_campaign=broadinstitute/cromwell),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2566#issuecomment-324109617
https://github.com/broadinstitute/cromwell/pull/2566#issuecomment-324120498:180,Safety,abort,abort,180,"@cjllanwarne there was one `ignore`d test about default runtime attributes that pretty clearly seemed to be covered by newer tests, so I've deleted that as well. There's one other abort test we should definitely continue to feel bad about, and another test for a ""taskless workflow"" for which I couldn't readily find an equivalent.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2566#issuecomment-324120498
https://github.com/broadinstitute/cromwell/pull/2566#issuecomment-324120498:37,Testability,test,test,37,"@cjllanwarne there was one `ignore`d test about default runtime attributes that pretty clearly seemed to be covered by newer tests, so I've deleted that as well. There's one other abort test we should definitely continue to feel bad about, and another test for a ""taskless workflow"" for which I couldn't readily find an equivalent.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2566#issuecomment-324120498
https://github.com/broadinstitute/cromwell/pull/2566#issuecomment-324120498:125,Testability,test,tests,125,"@cjllanwarne there was one `ignore`d test about default runtime attributes that pretty clearly seemed to be covered by newer tests, so I've deleted that as well. There's one other abort test we should definitely continue to feel bad about, and another test for a ""taskless workflow"" for which I couldn't readily find an equivalent.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2566#issuecomment-324120498
https://github.com/broadinstitute/cromwell/pull/2566#issuecomment-324120498:186,Testability,test,test,186,"@cjllanwarne there was one `ignore`d test about default runtime attributes that pretty clearly seemed to be covered by newer tests, so I've deleted that as well. There's one other abort test we should definitely continue to feel bad about, and another test for a ""taskless workflow"" for which I couldn't readily find an equivalent.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2566#issuecomment-324120498
https://github.com/broadinstitute/cromwell/pull/2566#issuecomment-324120498:252,Testability,test,test,252,"@cjllanwarne there was one `ignore`d test about default runtime attributes that pretty clearly seemed to be covered by newer tests, so I've deleted that as well. There's one other abort test we should definitely continue to feel bad about, and another test for a ""taskless workflow"" for which I couldn't readily find an equivalent.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2566#issuecomment-324120498
https://github.com/broadinstitute/cromwell/pull/2566#issuecomment-324120498:87,Usability,clear,clearly,87,"@cjllanwarne there was one `ignore`d test about default runtime attributes that pretty clearly seemed to be covered by newer tests, so I've deleted that as well. There's one other abort test we should definitely continue to feel bad about, and another test for a ""taskless workflow"" for which I couldn't readily find an equivalent.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2566#issuecomment-324120498
https://github.com/broadinstitute/cromwell/issues/2567#issuecomment-324099137:48,Security,validat,validate,48,"I should have checked first, this actually does validate...",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2567#issuecomment-324099137
https://github.com/broadinstitute/cromwell/issues/2569#issuecomment-331458725:11,Availability,redundant,redundant,11,Closing as redundant. See #2638.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2569#issuecomment-331458725
https://github.com/broadinstitute/cromwell/issues/2569#issuecomment-331458725:11,Safety,redund,redundant,11,Closing as redundant. See #2638.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2569#issuecomment-331458725
https://github.com/broadinstitute/cromwell/pull/2572#issuecomment-324401972:0,Availability,Ping,Pinging,0,Pinging @cjllanwarne as he was the prometheus of `operations`,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2572#issuecomment-324401972
https://github.com/broadinstitute/cromwell/pull/2572#issuecomment-324406500:102,Deployability,install,installations,102,"@kshakir Beyond unit tests, how was this tested? It'd be good to try to throw this at some live mysql installations of various configurations to make sure it doesn't blow up",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2572#issuecomment-324406500
https://github.com/broadinstitute/cromwell/pull/2572#issuecomment-324406500:127,Deployability,configurat,configurations,127,"@kshakir Beyond unit tests, how was this tested? It'd be good to try to throw this at some live mysql installations of various configurations to make sure it doesn't blow up",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2572#issuecomment-324406500
https://github.com/broadinstitute/cromwell/pull/2572#issuecomment-324406500:127,Modifiability,config,configurations,127,"@kshakir Beyond unit tests, how was this tested? It'd be good to try to throw this at some live mysql installations of various configurations to make sure it doesn't blow up",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2572#issuecomment-324406500
https://github.com/broadinstitute/cromwell/pull/2572#issuecomment-324406500:21,Testability,test,tests,21,"@kshakir Beyond unit tests, how was this tested? It'd be good to try to throw this at some live mysql installations of various configurations to make sure it doesn't blow up",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2572#issuecomment-324406500
https://github.com/broadinstitute/cromwell/pull/2572#issuecomment-324406500:41,Testability,test,tested,41,"@kshakir Beyond unit tests, how was this tested? It'd be good to try to throw this at some live mysql installations of various configurations to make sure it doesn't blow up",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2572#issuecomment-324406500
https://github.com/broadinstitute/cromwell/pull/2572#issuecomment-324791741:19,Testability,test,tests,19,"Re:. > Beyond unit tests, how was this tested?. The DBMS CI tests are testing fresh MySQL databases for both engine and metadata. I manually started running a workflow on develop with MySql. Stopped Cromwell, switched to this branch, and restarted. Liquibase ran successfully, marking the change_logs as ""MARK_RAN"" vs. ""EXECUTED"". The jobs/workflow resumed and succeeded.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2572#issuecomment-324791741
https://github.com/broadinstitute/cromwell/pull/2572#issuecomment-324791741:39,Testability,test,tested,39,"Re:. > Beyond unit tests, how was this tested?. The DBMS CI tests are testing fresh MySQL databases for both engine and metadata. I manually started running a workflow on develop with MySql. Stopped Cromwell, switched to this branch, and restarted. Liquibase ran successfully, marking the change_logs as ""MARK_RAN"" vs. ""EXECUTED"". The jobs/workflow resumed and succeeded.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2572#issuecomment-324791741
https://github.com/broadinstitute/cromwell/pull/2572#issuecomment-324791741:60,Testability,test,tests,60,"Re:. > Beyond unit tests, how was this tested?. The DBMS CI tests are testing fresh MySQL databases for both engine and metadata. I manually started running a workflow on develop with MySql. Stopped Cromwell, switched to this branch, and restarted. Liquibase ran successfully, marking the change_logs as ""MARK_RAN"" vs. ""EXECUTED"". The jobs/workflow resumed and succeeded.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2572#issuecomment-324791741
https://github.com/broadinstitute/cromwell/pull/2572#issuecomment-324791741:70,Testability,test,testing,70,"Re:. > Beyond unit tests, how was this tested?. The DBMS CI tests are testing fresh MySQL databases for both engine and metadata. I manually started running a workflow on develop with MySql. Stopped Cromwell, switched to this branch, and restarted. Liquibase ran successfully, marking the change_logs as ""MARK_RAN"" vs. ""EXECUTED"". The jobs/workflow resumed and succeeded.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2572#issuecomment-324791741
https://github.com/broadinstitute/cromwell/pull/2572#issuecomment-324791741:349,Usability,resume,resumed,349,"Re:. > Beyond unit tests, how was this tested?. The DBMS CI tests are testing fresh MySQL databases for both engine and metadata. I manually started running a workflow on develop with MySql. Stopped Cromwell, switched to this branch, and restarted. Liquibase ran successfully, marking the change_logs as ""MARK_RAN"" vs. ""EXECUTED"". The jobs/workflow resumed and succeeded.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2572#issuecomment-324791741
https://github.com/broadinstitute/cromwell/issues/2574#issuecomment-424937576:66,Deployability,release,release,66,Completed https://github.com/broadinstitute/cromwell/blob/develop/release/release_workflow.wdl#L182-L291,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2574#issuecomment-424937576
https://github.com/broadinstitute/cromwell/issues/2576#issuecomment-348286795:101,Availability,error,errors,101,@Horneth Out of curiosity has this been addressed. We are using v28.2 and seem to get a lot of these errors when doing `size` lookups,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2576#issuecomment-348286795
https://github.com/broadinstitute/cromwell/issues/2576#issuecomment-348720128:148,Availability,error,errors,148,"@Horneth Thanks for letting me know. It would be great if this was prioritized, we are unable to fully do call caching at the moment, so having 503 errors can get quite expensive for us. Are there any config properties which you know of that might help with this?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2576#issuecomment-348720128
https://github.com/broadinstitute/cromwell/issues/2576#issuecomment-348720128:201,Modifiability,config,config,201,"@Horneth Thanks for letting me know. It would be great if this was prioritized, we are unable to fully do call caching at the moment, so having 503 errors can get quite expensive for us. Are there any config properties which you know of that might help with this?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2576#issuecomment-348720128
https://github.com/broadinstitute/cromwell/issues/2576#issuecomment-349031774:317,Availability,reliab,reliable,317,"> Are there any config properties which you know of that might help with this?. Not that I can think of unfortunately :/ One quick thing we could maybe do before the fixing it ""the right way"" would be to enable retries at the GCS library level. We've disabled it because we have our own retry mechanism which is more reliable and asynchronous (but WDL functions couldn't use it so far, which is why they're not retried). We're about to release Cromwell 30 imminently so I don't think this can make it before then but we could consider hotfixing it if this is really becoming urgent. Edit: actually looking at it more closely, even though we don't supply an ""retry settings"" to the GCS library they have default ones allowing for 6 attempts. However like I said we've found their retries to not always be reliable so it might be that for some particular errors it's not retried at all.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2576#issuecomment-349031774
https://github.com/broadinstitute/cromwell/issues/2576#issuecomment-349031774:804,Availability,reliab,reliable,804,"> Are there any config properties which you know of that might help with this?. Not that I can think of unfortunately :/ One quick thing we could maybe do before the fixing it ""the right way"" would be to enable retries at the GCS library level. We've disabled it because we have our own retry mechanism which is more reliable and asynchronous (but WDL functions couldn't use it so far, which is why they're not retried). We're about to release Cromwell 30 imminently so I don't think this can make it before then but we could consider hotfixing it if this is really becoming urgent. Edit: actually looking at it more closely, even though we don't supply an ""retry settings"" to the GCS library they have default ones allowing for 6 attempts. However like I said we've found their retries to not always be reliable so it might be that for some particular errors it's not retried at all.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2576#issuecomment-349031774
https://github.com/broadinstitute/cromwell/issues/2576#issuecomment-349031774:853,Availability,error,errors,853,"> Are there any config properties which you know of that might help with this?. Not that I can think of unfortunately :/ One quick thing we could maybe do before the fixing it ""the right way"" would be to enable retries at the GCS library level. We've disabled it because we have our own retry mechanism which is more reliable and asynchronous (but WDL functions couldn't use it so far, which is why they're not retried). We're about to release Cromwell 30 imminently so I don't think this can make it before then but we could consider hotfixing it if this is really becoming urgent. Edit: actually looking at it more closely, even though we don't supply an ""retry settings"" to the GCS library they have default ones allowing for 6 attempts. However like I said we've found their retries to not always be reliable so it might be that for some particular errors it's not retried at all.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2576#issuecomment-349031774
https://github.com/broadinstitute/cromwell/issues/2576#issuecomment-349031774:436,Deployability,release,release,436,"> Are there any config properties which you know of that might help with this?. Not that I can think of unfortunately :/ One quick thing we could maybe do before the fixing it ""the right way"" would be to enable retries at the GCS library level. We've disabled it because we have our own retry mechanism which is more reliable and asynchronous (but WDL functions couldn't use it so far, which is why they're not retried). We're about to release Cromwell 30 imminently so I don't think this can make it before then but we could consider hotfixing it if this is really becoming urgent. Edit: actually looking at it more closely, even though we don't supply an ""retry settings"" to the GCS library they have default ones allowing for 6 attempts. However like I said we've found their retries to not always be reliable so it might be that for some particular errors it's not retried at all.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2576#issuecomment-349031774
https://github.com/broadinstitute/cromwell/issues/2576#issuecomment-349031774:535,Deployability,hotfix,hotfixing,535,"> Are there any config properties which you know of that might help with this?. Not that I can think of unfortunately :/ One quick thing we could maybe do before the fixing it ""the right way"" would be to enable retries at the GCS library level. We've disabled it because we have our own retry mechanism which is more reliable and asynchronous (but WDL functions couldn't use it so far, which is why they're not retried). We're about to release Cromwell 30 imminently so I don't think this can make it before then but we could consider hotfixing it if this is really becoming urgent. Edit: actually looking at it more closely, even though we don't supply an ""retry settings"" to the GCS library they have default ones allowing for 6 attempts. However like I said we've found their retries to not always be reliable so it might be that for some particular errors it's not retried at all.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2576#issuecomment-349031774
https://github.com/broadinstitute/cromwell/issues/2576#issuecomment-349031774:16,Modifiability,config,config,16,"> Are there any config properties which you know of that might help with this?. Not that I can think of unfortunately :/ One quick thing we could maybe do before the fixing it ""the right way"" would be to enable retries at the GCS library level. We've disabled it because we have our own retry mechanism which is more reliable and asynchronous (but WDL functions couldn't use it so far, which is why they're not retried). We're about to release Cromwell 30 imminently so I don't think this can make it before then but we could consider hotfixing it if this is really becoming urgent. Edit: actually looking at it more closely, even though we don't supply an ""retry settings"" to the GCS library they have default ones allowing for 6 attempts. However like I said we've found their retries to not always be reliable so it might be that for some particular errors it's not retried at all.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2576#issuecomment-349031774
https://github.com/broadinstitute/cromwell/pull/2577#issuecomment-324989698:16,Availability,down,downstream,16,I realized that downstream libs won't automagically get the updated cats library so no need to relax this,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2577#issuecomment-324989698
https://github.com/broadinstitute/cromwell/pull/2577#issuecomment-324989698:60,Deployability,update,updated,60,I realized that downstream libs won't automagically get the updated cats library so no need to relax this,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2577#issuecomment-324989698
https://github.com/broadinstitute/cromwell/pull/2578#issuecomment-325698953:114,Deployability,update,update,114,"FYI for reviewers: need to retrofit `/v1` to still fill in `Some(""WDL"")` instead of `None` to fix tests, and will update docs to suggest ""draft-2"" as a workflow type version.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2578#issuecomment-325698953
https://github.com/broadinstitute/cromwell/pull/2578#issuecomment-325698953:98,Testability,test,tests,98,"FYI for reviewers: need to retrofit `/v1` to still fill in `Some(""WDL"")` instead of `None` to fix tests, and will update docs to suggest ""draft-2"" as a workflow type version.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2578#issuecomment-325698953
https://github.com/broadinstitute/cromwell/pull/2583#issuecomment-325881488:48,Security,authenticat,authenticating,48,"As background, we run cromwell server behind an authenticating proxy.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2583#issuecomment-325881488
https://github.com/broadinstitute/cromwell/issues/2590#issuecomment-328219372:70,Integrability,interface,interface,70,"tl;dr we want a CLI that allows SWR Cromwell to be invoked through an interface that greatly resembles `cwltool`. Per `cwltest`, it might even be a good idea to call it that:. ```; # Add prefixes if running on MacOSX so that boot2docker writes to /Users; with templock:; if 'darwin' in sys.platform and args.tool == 'cwltool':; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2590#issuecomment-328219372
https://github.com/broadinstitute/cromwell/issues/2590#issuecomment-328223594:40,Testability,test,test,40,"@mcovarr DoD is to have the conformance test exercising Cromwell in their CI. I know that that requires a command line program in a well known location, but they're not picky about the implementation of that program other than it's transforming that API they provide to the CWL implementation. I'm also not picky, was just throwing out a few other possibilities which might have been overlooked. . If you're afraid of proceeding without some Bird-X, I'd suggest maybe writing up something (or via faces) describing how other systems handle this and seeing if anyone else has strong opinions.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2590#issuecomment-328223594
https://github.com/broadinstitute/cromwell/issues/2590#issuecomment-333315542:47,Availability,failure,failure,47,"Useful tidbit to note, [this is how you signal failure due to unimplemented functionality](https://github.com/common-workflow-language/common-workflow-language/pull/278/files#diff-ee814a9c027fc9750beb075c283a973cR49) - which I believe means that one can still be ""green"" on CI",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2590#issuecomment-333315542
https://github.com/broadinstitute/cromwell/issues/2590#issuecomment-333315542:264,Energy Efficiency,green,green,264,"Useful tidbit to note, [this is how you signal failure due to unimplemented functionality](https://github.com/common-workflow-language/common-workflow-language/pull/278/files#diff-ee814a9c027fc9750beb075c283a973cR49) - which I believe means that one can still be ""green"" on CI",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2590#issuecomment-333315542
https://github.com/broadinstitute/cromwell/pull/2591#issuecomment-326653496:25,Availability,error,error,25,Thanks very much for the error report and fix! üòÑ :+1: . [![Approved with PullApprove](https://img.shields.io/badge/reviewers-approved-brightgreen.svg)](https://pullapprove.com/broadinstitute/cromwell/pull-request/2591/?utm_source=github-pr&utm_medium=comment-badge&utm_campaign=broadinstitute/cromwell),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2591#issuecomment-326653496
https://github.com/broadinstitute/cromwell/pull/2591#issuecomment-326665158:182,Security,validat,validate,182,"Yes I think the `-` needs to be escaped.; If you could also make the same change on line 52, and add a new line with your docker image in the table in `DockerImageIdentifierSpec` to validate that it works it would be great :). Thanks !",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2591#issuecomment-326665158
https://github.com/broadinstitute/cromwell/issues/2593#issuecomment-327320882:86,Deployability,pipeline,pipelines,86,"@raylim At the moment, no. Also note that if you're using the google backend that the pipelines API currently has the same limitation.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2593#issuecomment-327320882
https://github.com/broadinstitute/cromwell/issues/2593#issuecomment-364071889:79,Availability,avail,available,79,"I am facing the same problem, because I am using alpine images and bash is not available. Could it be possible that this is fix in the near future?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2593#issuecomment-364071889
https://github.com/broadinstitute/cromwell/issues/2593#issuecomment-562507565:18,Modifiability,config,configure,18,Is it possible to configure shell path? e.g. to `/bin/sh`,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2593#issuecomment-562507565
https://github.com/broadinstitute/cromwell/issues/2598#issuecomment-331165701:6,Performance,Perform,Perform,6,"- [x] Perform OAuth authentication (via clicky buttons in swagger, gcloud on CLI); - [x] Register user in Sam; - [x] Submit workflow to Cromwell; - [x] Get final results from Cromwell for that workflow",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2598#issuecomment-331165701
https://github.com/broadinstitute/cromwell/issues/2598#issuecomment-331165701:20,Security,authenticat,authentication,20,"- [x] Perform OAuth authentication (via clicky buttons in swagger, gcloud on CLI); - [x] Register user in Sam; - [x] Submit workflow to Cromwell; - [x] Get final results from Cromwell for that workflow",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2598#issuecomment-331165701
https://github.com/broadinstitute/cromwell/issues/2604#issuecomment-328198717:571,Performance,cache,cache,571,"I can't think of any runtime parameters (with the exception of `docker`); that should change the hashing. Also, are the inputs to the task hashed or; is it the fully rendered command block or what? Because if I have a; parameter to the task (such as ""preemptible_attempts"") that is only used in; the runtime block, (ideally) I'd like it to be ignored for call caching; purposes. On Fri, Sep 8, 2017 at 3:12 PM, Kate Voss <notifications@github.com> wrote:. > As a *workflow runner*, I want *certain parameters to be ignored in the; > hashing process*, so that I can *call cache on more workflows when the; > result is exactly the same*.; >; > - Effort: *?*; > - Risk: *Medium*; > - We should err on the side of hashing a workflow differently if we; > are not absolutely confident that the parameter does not impact the result.; > - Which parameters are ignored is NOT user-editable. This is to; > prevent users from accidentally ignoring parameters that do impact the; > result.; > - Business value: *Medium*; >; > Some parameters, such as preemptible_attempts and CPU, don't affect the; > outcome of the workflow but workflows with different CPU values will not; > call cache.; >; > @LeeTL1220 <https://github.com/leetl1220> and @geoffjentry; > <https://github.com/geoffjentry> to provide additional thoughts and; > context if helpful.; > Related issue #1210; > <https://github.com/broadinstitute/cromwell/issues/1210>; >; > ‚Äî; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/2604>, or mute the; > thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk24fM_SrXs0gx-Ry1aw1opHFZAb5ks5sgZG5gaJpZM4PRlLU>; > .; >. -- ; Lee Lichtenstein; Broad Institute; 75 Ames Street, Room 8011A; Cambridge, MA 02142; 617 714 8632",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2604#issuecomment-328198717
https://github.com/broadinstitute/cromwell/issues/2604#issuecomment-328198717:1170,Performance,cache,cache,1170,"I can't think of any runtime parameters (with the exception of `docker`); that should change the hashing. Also, are the inputs to the task hashed or; is it the fully rendered command block or what? Because if I have a; parameter to the task (such as ""preemptible_attempts"") that is only used in; the runtime block, (ideally) I'd like it to be ignored for call caching; purposes. On Fri, Sep 8, 2017 at 3:12 PM, Kate Voss <notifications@github.com> wrote:. > As a *workflow runner*, I want *certain parameters to be ignored in the; > hashing process*, so that I can *call cache on more workflows when the; > result is exactly the same*.; >; > - Effort: *?*; > - Risk: *Medium*; > - We should err on the side of hashing a workflow differently if we; > are not absolutely confident that the parameter does not impact the result.; > - Which parameters are ignored is NOT user-editable. This is to; > prevent users from accidentally ignoring parameters that do impact the; > result.; > - Business value: *Medium*; >; > Some parameters, such as preemptible_attempts and CPU, don't affect the; > outcome of the workflow but workflows with different CPU values will not; > call cache.; >; > @LeeTL1220 <https://github.com/leetl1220> and @geoffjentry; > <https://github.com/geoffjentry> to provide additional thoughts and; > context if helpful.; > Related issue #1210; > <https://github.com/broadinstitute/cromwell/issues/1210>; >; > ‚Äî; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/2604>, or mute the; > thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk24fM_SrXs0gx-Ry1aw1opHFZAb5ks5sgZG5gaJpZM4PRlLU>; > .; >. -- ; Lee Lichtenstein; Broad Institute; 75 Ames Street, Room 8011A; Cambridge, MA 02142; 617 714 8632",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2604#issuecomment-328198717
https://github.com/broadinstitute/cromwell/issues/2604#issuecomment-328198717:661,Safety,Risk,Risk,661,"I can't think of any runtime parameters (with the exception of `docker`); that should change the hashing. Also, are the inputs to the task hashed or; is it the fully rendered command block or what? Because if I have a; parameter to the task (such as ""preemptible_attempts"") that is only used in; the runtime block, (ideally) I'd like it to be ignored for call caching; purposes. On Fri, Sep 8, 2017 at 3:12 PM, Kate Voss <notifications@github.com> wrote:. > As a *workflow runner*, I want *certain parameters to be ignored in the; > hashing process*, so that I can *call cache on more workflows when the; > result is exactly the same*.; >; > - Effort: *?*; > - Risk: *Medium*; > - We should err on the side of hashing a workflow differently if we; > are not absolutely confident that the parameter does not impact the result.; > - Which parameters are ignored is NOT user-editable. This is to; > prevent users from accidentally ignoring parameters that do impact the; > result.; > - Business value: *Medium*; >; > Some parameters, such as preemptible_attempts and CPU, don't affect the; > outcome of the workflow but workflows with different CPU values will not; > call cache.; >; > @LeeTL1220 <https://github.com/leetl1220> and @geoffjentry; > <https://github.com/geoffjentry> to provide additional thoughts and; > context if helpful.; > Related issue #1210; > <https://github.com/broadinstitute/cromwell/issues/1210>; >; > ‚Äî; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/2604>, or mute the; > thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk24fM_SrXs0gx-Ry1aw1opHFZAb5ks5sgZG5gaJpZM4PRlLU>; > .; >. -- ; Lee Lichtenstein; Broad Institute; 75 Ames Street, Room 8011A; Cambridge, MA 02142; 617 714 8632",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2604#issuecomment-328198717
https://github.com/broadinstitute/cromwell/issues/2604#issuecomment-328198717:97,Security,hash,hashing,97,"I can't think of any runtime parameters (with the exception of `docker`); that should change the hashing. Also, are the inputs to the task hashed or; is it the fully rendered command block or what? Because if I have a; parameter to the task (such as ""preemptible_attempts"") that is only used in; the runtime block, (ideally) I'd like it to be ignored for call caching; purposes. On Fri, Sep 8, 2017 at 3:12 PM, Kate Voss <notifications@github.com> wrote:. > As a *workflow runner*, I want *certain parameters to be ignored in the; > hashing process*, so that I can *call cache on more workflows when the; > result is exactly the same*.; >; > - Effort: *?*; > - Risk: *Medium*; > - We should err on the side of hashing a workflow differently if we; > are not absolutely confident that the parameter does not impact the result.; > - Which parameters are ignored is NOT user-editable. This is to; > prevent users from accidentally ignoring parameters that do impact the; > result.; > - Business value: *Medium*; >; > Some parameters, such as preemptible_attempts and CPU, don't affect the; > outcome of the workflow but workflows with different CPU values will not; > call cache.; >; > @LeeTL1220 <https://github.com/leetl1220> and @geoffjentry; > <https://github.com/geoffjentry> to provide additional thoughts and; > context if helpful.; > Related issue #1210; > <https://github.com/broadinstitute/cromwell/issues/1210>; >; > ‚Äî; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/2604>, or mute the; > thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk24fM_SrXs0gx-Ry1aw1opHFZAb5ks5sgZG5gaJpZM4PRlLU>; > .; >. -- ; Lee Lichtenstein; Broad Institute; 75 Ames Street, Room 8011A; Cambridge, MA 02142; 617 714 8632",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2604#issuecomment-328198717
https://github.com/broadinstitute/cromwell/issues/2604#issuecomment-328198717:139,Security,hash,hashed,139,"I can't think of any runtime parameters (with the exception of `docker`); that should change the hashing. Also, are the inputs to the task hashed or; is it the fully rendered command block or what? Because if I have a; parameter to the task (such as ""preemptible_attempts"") that is only used in; the runtime block, (ideally) I'd like it to be ignored for call caching; purposes. On Fri, Sep 8, 2017 at 3:12 PM, Kate Voss <notifications@github.com> wrote:. > As a *workflow runner*, I want *certain parameters to be ignored in the; > hashing process*, so that I can *call cache on more workflows when the; > result is exactly the same*.; >; > - Effort: *?*; > - Risk: *Medium*; > - We should err on the side of hashing a workflow differently if we; > are not absolutely confident that the parameter does not impact the result.; > - Which parameters are ignored is NOT user-editable. This is to; > prevent users from accidentally ignoring parameters that do impact the; > result.; > - Business value: *Medium*; >; > Some parameters, such as preemptible_attempts and CPU, don't affect the; > outcome of the workflow but workflows with different CPU values will not; > call cache.; >; > @LeeTL1220 <https://github.com/leetl1220> and @geoffjentry; > <https://github.com/geoffjentry> to provide additional thoughts and; > context if helpful.; > Related issue #1210; > <https://github.com/broadinstitute/cromwell/issues/1210>; >; > ‚Äî; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/2604>, or mute the; > thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk24fM_SrXs0gx-Ry1aw1opHFZAb5ks5sgZG5gaJpZM4PRlLU>; > .; >. -- ; Lee Lichtenstein; Broad Institute; 75 Ames Street, Room 8011A; Cambridge, MA 02142; 617 714 8632",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2604#issuecomment-328198717
https://github.com/broadinstitute/cromwell/issues/2604#issuecomment-328198717:533,Security,hash,hashing,533,"I can't think of any runtime parameters (with the exception of `docker`); that should change the hashing. Also, are the inputs to the task hashed or; is it the fully rendered command block or what? Because if I have a; parameter to the task (such as ""preemptible_attempts"") that is only used in; the runtime block, (ideally) I'd like it to be ignored for call caching; purposes. On Fri, Sep 8, 2017 at 3:12 PM, Kate Voss <notifications@github.com> wrote:. > As a *workflow runner*, I want *certain parameters to be ignored in the; > hashing process*, so that I can *call cache on more workflows when the; > result is exactly the same*.; >; > - Effort: *?*; > - Risk: *Medium*; > - We should err on the side of hashing a workflow differently if we; > are not absolutely confident that the parameter does not impact the result.; > - Which parameters are ignored is NOT user-editable. This is to; > prevent users from accidentally ignoring parameters that do impact the; > result.; > - Business value: *Medium*; >; > Some parameters, such as preemptible_attempts and CPU, don't affect the; > outcome of the workflow but workflows with different CPU values will not; > call cache.; >; > @LeeTL1220 <https://github.com/leetl1220> and @geoffjentry; > <https://github.com/geoffjentry> to provide additional thoughts and; > context if helpful.; > Related issue #1210; > <https://github.com/broadinstitute/cromwell/issues/1210>; >; > ‚Äî; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/2604>, or mute the; > thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk24fM_SrXs0gx-Ry1aw1opHFZAb5ks5sgZG5gaJpZM4PRlLU>; > .; >. -- ; Lee Lichtenstein; Broad Institute; 75 Ames Street, Room 8011A; Cambridge, MA 02142; 617 714 8632",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2604#issuecomment-328198717
https://github.com/broadinstitute/cromwell/issues/2604#issuecomment-328198717:710,Security,hash,hashing,710,"I can't think of any runtime parameters (with the exception of `docker`); that should change the hashing. Also, are the inputs to the task hashed or; is it the fully rendered command block or what? Because if I have a; parameter to the task (such as ""preemptible_attempts"") that is only used in; the runtime block, (ideally) I'd like it to be ignored for call caching; purposes. On Fri, Sep 8, 2017 at 3:12 PM, Kate Voss <notifications@github.com> wrote:. > As a *workflow runner*, I want *certain parameters to be ignored in the; > hashing process*, so that I can *call cache on more workflows when the; > result is exactly the same*.; >; > - Effort: *?*; > - Risk: *Medium*; > - We should err on the side of hashing a workflow differently if we; > are not absolutely confident that the parameter does not impact the result.; > - Which parameters are ignored is NOT user-editable. This is to; > prevent users from accidentally ignoring parameters that do impact the; > result.; > - Business value: *Medium*; >; > Some parameters, such as preemptible_attempts and CPU, don't affect the; > outcome of the workflow but workflows with different CPU values will not; > call cache.; >; > @LeeTL1220 <https://github.com/leetl1220> and @geoffjentry; > <https://github.com/geoffjentry> to provide additional thoughts and; > context if helpful.; > Related issue #1210; > <https://github.com/broadinstitute/cromwell/issues/1210>; >; > ‚Äî; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/2604>, or mute the; > thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk24fM_SrXs0gx-Ry1aw1opHFZAb5ks5sgZG5gaJpZM4PRlLU>; > .; >. -- ; Lee Lichtenstein; Broad Institute; 75 Ames Street, Room 8011A; Cambridge, MA 02142; 617 714 8632",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2604#issuecomment-328198717
https://github.com/broadinstitute/cromwell/issues/2604#issuecomment-331260390:48,Security,hash,hash,48,"Good news! @geoffjentry is wrong, and we do not hash the cpu or memory runtime attributes. So call caching works as you want it to. These runtime attributes are hashed (and count for call caching):; * `ContinueOnReturnCode`; * `Docker`; * `FailOnStderr`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2604#issuecomment-331260390
https://github.com/broadinstitute/cromwell/issues/2604#issuecomment-331260390:161,Security,hash,hashed,161,"Good news! @geoffjentry is wrong, and we do not hash the cpu or memory runtime attributes. So call caching works as you want it to. These runtime attributes are hashed (and count for call caching):; * `ContinueOnReturnCode`; * `Docker`; * `FailOnStderr`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2604#issuecomment-331260390
https://github.com/broadinstitute/cromwell/issues/2604#issuecomment-331262988:90,Performance,Cache,Cache,90,"@LeeTL1220 if you ran this in a server mode Cromwell, I suggest having a look at the Call Cache Diff endpoint to work out what really caused this call cache miss and in the mean time close this issue.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2604#issuecomment-331262988
https://github.com/broadinstitute/cromwell/issues/2604#issuecomment-331262988:151,Performance,cache,cache,151,"@LeeTL1220 if you ran this in a server mode Cromwell, I suggest having a look at the Call Cache Diff endpoint to work out what really caused this call cache miss and in the mean time close this issue.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2604#issuecomment-331262988
https://github.com/broadinstitute/cromwell/issues/2606#issuecomment-347902943:30,Integrability,wrap,wrapper,30,"Luckily, we now have a simple wrapper that can turn `WomValue`s into `WomExpression`s (which simply return the value given to them), so runtime attributes can be WomExpression, and the values given in the default runtime attributes can be easily converted into expressions",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2606#issuecomment-347902943
https://github.com/broadinstitute/cromwell/issues/2606#issuecomment-347902943:23,Usability,simpl,simple,23,"Luckily, we now have a simple wrapper that can turn `WomValue`s into `WomExpression`s (which simply return the value given to them), so runtime attributes can be WomExpression, and the values given in the default runtime attributes can be easily converted into expressions",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2606#issuecomment-347902943
https://github.com/broadinstitute/cromwell/issues/2606#issuecomment-347902943:93,Usability,simpl,simply,93,"Luckily, we now have a simple wrapper that can turn `WomValue`s into `WomExpression`s (which simply return the value given to them), so runtime attributes can be WomExpression, and the values given in the default runtime attributes can be easily converted into expressions",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2606#issuecomment-347902943
https://github.com/broadinstitute/cromwell/issues/2612#issuecomment-349130801:150,Availability,error,error-for-engine-functions,150,@katevoss heads up that this was reported and requested in the forums here: https://gatkforums.broadinstitute.org/wdl/discussion/10853/consistent-503-error-for-engine-functions#latest,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2612#issuecomment-349130801
https://github.com/broadinstitute/cromwell/issues/2612#issuecomment-349133282:173,Availability,reliab,reliable,173,"@katevoss seems to be, yeah. This is a specific fix to the problem in #2576 which also comes with extra benefits like throttling and batching to make it generally much more reliable and scalable.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2612#issuecomment-349133282
https://github.com/broadinstitute/cromwell/issues/2612#issuecomment-349133282:186,Performance,scalab,scalable,186,"@katevoss seems to be, yeah. This is a specific fix to the problem in #2576 which also comes with extra benefits like throttling and batching to make it generally much more reliable and scalable.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2612#issuecomment-349133282
https://github.com/broadinstitute/cromwell/pull/2613#issuecomment-328900320:132,Deployability,hotfix,hotfix,132,"As per TechTalk this morning we're a bit on the fence about whether break develop (so that we're forced to fix it and don't have to hotfix 3 branches) or keep a separate branch and leave develop as is (so that people using it can keep doing that and we have a non-hotfix working branch).; I personally don't have a very strong opinion either way, I may slightly lean towards keeping a separate branch as long as we don't make significant changes to develop. If we do merge to develop I think we should change the default github branch to point to master though so that someone cloning Cromwell doesn't accidentally ends up with the broken version.; @geoffjentry ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2613#issuecomment-328900320
https://github.com/broadinstitute/cromwell/pull/2613#issuecomment-328900320:264,Deployability,hotfix,hotfix,264,"As per TechTalk this morning we're a bit on the fence about whether break develop (so that we're forced to fix it and don't have to hotfix 3 branches) or keep a separate branch and leave develop as is (so that people using it can keep doing that and we have a non-hotfix working branch).; I personally don't have a very strong opinion either way, I may slightly lean towards keeping a separate branch as long as we don't make significant changes to develop. If we do merge to develop I think we should change the default github branch to point to master though so that someone cloning Cromwell doesn't accidentally ends up with the broken version.; @geoffjentry ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2613#issuecomment-328900320
https://github.com/broadinstitute/cromwell/pull/2613#issuecomment-328934905:116,Testability,test,tests,116,"@geoffjentry sounds good.; I'm going to close this as I'm rebasing, cleaning up a little, fixing or tagging failing tests, creating a centaur branch with disabled failing tests etc... I'll reopen a new PR on a separate branch when ready",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2613#issuecomment-328934905
https://github.com/broadinstitute/cromwell/pull/2613#issuecomment-328934905:171,Testability,test,tests,171,"@geoffjentry sounds good.; I'm going to close this as I'm rebasing, cleaning up a little, fixing or tagging failing tests, creating a centaur branch with disabled failing tests etc... I'll reopen a new PR on a separate branch when ready",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2613#issuecomment-328934905
https://github.com/broadinstitute/cromwell/pull/2619#issuecomment-329019729:65,Availability,failure,failures,65,"@jainh I think you need to rebase, my suspicion is that the test failures are due to not being quite up to date on develop. Also, not for this PR but I'd suggest looking into porting this backend to the standard backend trait, it might help wiht these divergences in the future",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2619#issuecomment-329019729
https://github.com/broadinstitute/cromwell/pull/2619#issuecomment-329019729:60,Testability,test,test,60,"@jainh I think you need to rebase, my suspicion is that the test failures are due to not being quite up to date on develop. Also, not for this PR but I'd suggest looking into porting this backend to the standard backend trait, it might help wiht these divergences in the future",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2619#issuecomment-329019729
https://github.com/broadinstitute/cromwell/issues/2620#issuecomment-482549494:245,Modifiability,config,config,245,With the new caching heuristic for generating File input hashes (`path+modtime`) relies on soft-linking for it to work correctly. Having soft-links disabled by design when containerizing a task makes this option mood. I consider it weird that a config option has a hard-override within cromwell... leave it up to users to configure their backend.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2620#issuecomment-482549494
https://github.com/broadinstitute/cromwell/issues/2620#issuecomment-482549494:322,Modifiability,config,configure,322,With the new caching heuristic for generating File input hashes (`path+modtime`) relies on soft-linking for it to work correctly. Having soft-links disabled by design when containerizing a task makes this option mood. I consider it weird that a config option has a hard-override within cromwell... leave it up to users to configure their backend.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2620#issuecomment-482549494
https://github.com/broadinstitute/cromwell/issues/2620#issuecomment-482549494:57,Security,hash,hashes,57,With the new caching heuristic for generating File input hashes (`path+modtime`) relies on soft-linking for it to work correctly. Having soft-links disabled by design when containerizing a task makes this option mood. I consider it weird that a config option has a hard-override within cromwell... leave it up to users to configure their backend.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2620#issuecomment-482549494
https://github.com/broadinstitute/cromwell/issues/2620#issuecomment-482565332:59,Security,hash,hashes,59,> With the new caching heuristic for generating File input hashes (path+modtime) relies on soft-linking for it to work correctly. Having soft-links disabled by design when containerizing a task makes this option mood. The hash is calculated based on the original path. Not on the relocalized path. So this should not be an issue.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2620#issuecomment-482565332
https://github.com/broadinstitute/cromwell/issues/2620#issuecomment-482565332:222,Security,hash,hash,222,> With the new caching heuristic for generating File input hashes (path+modtime) relies on soft-linking for it to work correctly. Having soft-links disabled by design when containerizing a task makes this option mood. The hash is calculated based on the original path. Not on the relocalized path. So this should not be an issue.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2620#issuecomment-482565332
https://github.com/broadinstitute/cromwell/issues/2621#issuecomment-329262812:21,Safety,safe,safe,21,I think for now it's safe to believe the user that it's an MD5 file,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2621#issuecomment-329262812
https://github.com/broadinstitute/cromwell/issues/2627#issuecomment-414084761:37,Usability,clear,clearly,37,Closing this as it's been a year and clearly no one is going to bother to do this,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2627#issuecomment-414084761
https://github.com/broadinstitute/cromwell/issues/2632#issuecomment-330359991:45,Availability,error,errors,45,"@LeeTL1220 when you get the ""file not found"" errors, does it fail the workflow? Or does it still continue?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2632#issuecomment-330359991
https://github.com/broadinstitute/cromwell/issues/2632#issuecomment-330401409:179,Availability,error,errors,179,"Fails the workflow. On Mon, Sep 18, 2017 at 5:21 PM, Kate Voss <notifications@github.com> wrote:. > @LeeTL1220 <https://github.com/leetl1220> when you get the ""file not; > found"" errors, does it fail the workflow? Or does it still continue?; >; > ‚Äî; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/2632#issuecomment-330359991>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXkxMH5YiFxEFZPeULlAAXomDFkWi2ks5sjt7PgaJpZM4PZZvF>; > .; >. -- ; Lee Lichtenstein; Broad Institute; 75 Ames Street, Room 8011A; Cambridge, MA 02142; 617 714 8632",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2632#issuecomment-330401409
https://github.com/broadinstitute/cromwell/pull/2633#issuecomment-330316320:0,Testability,Test,Tested,0,Tested manually via. ```bash; docker run -it --rm -v $PWD:$PWD -w $PWD \; -e 'JAVA_OPTS=-Dconfig.file=cromwell.examples.conf' \; broadinstitute/cromwell:develop server; ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2633#issuecomment-330316320
https://github.com/broadinstitute/cromwell/issues/2638#issuecomment-333626764:61,Testability,test,test,61,https://github.com/broadinstitute/wdl4s/blob/develop/cwl/src/test/resources/three_step.cwl#L59. üòÆ,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2638#issuecomment-333626764
https://github.com/broadinstitute/cromwell/issues/2640#issuecomment-330666862:419,Availability,error,error,419,"@jainh Yes, there are multiple `--conf` attributes.; If there is no space in the value of `--conf` attribute, single quote is not needed; otherwise, I think it's needed. However the [gatk-launch](https://github.com/broadinstitute/gatk/blob/70edbb6e4caa2b7cf1b8678450443c0c590a2b76/gatk-launch) in GATK beta 4 does not produce the single quote for such case; but if I run the following without single quote, it leads to error:; >Error: Unrecognized option: -Dsamjdk.use_async_io_read_samtools=false. command:; ```; /opt/spark-latest/bin/spark-submit --master spark://localhost:6066 --deploy-mode cluster \; --driver-cores 4 --driver-memory 8g --executor-memory 4g --total-executor-cores 10 \; --conf 'spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false' \; --conf 'spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true' \; ...; ```; Here is a related [post](https://stackoverflow.com/questions/28166667/how-to-pass-d-parameter-or-environment-variable-to-spark-job) on stackoverflow.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2640#issuecomment-330666862
https://github.com/broadinstitute/cromwell/issues/2640#issuecomment-330666862:428,Availability,Error,Error,428,"@jainh Yes, there are multiple `--conf` attributes.; If there is no space in the value of `--conf` attribute, single quote is not needed; otherwise, I think it's needed. However the [gatk-launch](https://github.com/broadinstitute/gatk/blob/70edbb6e4caa2b7cf1b8678450443c0c590a2b76/gatk-launch) in GATK beta 4 does not produce the single quote for such case; but if I run the following without single quote, it leads to error:; >Error: Unrecognized option: -Dsamjdk.use_async_io_read_samtools=false. command:; ```; /opt/spark-latest/bin/spark-submit --master spark://localhost:6066 --deploy-mode cluster \; --driver-cores 4 --driver-memory 8g --executor-memory 4g --total-executor-cores 10 \; --conf 'spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false' \; --conf 'spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true' \; ...; ```; Here is a related [post](https://stackoverflow.com/questions/28166667/how-to-pass-d-parameter-or-environment-variable-to-spark-job) on stackoverflow.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2640#issuecomment-330666862
https://github.com/broadinstitute/cromwell/issues/2640#issuecomment-330666862:583,Deployability,deploy,deploy-mode,583,"@jainh Yes, there are multiple `--conf` attributes.; If there is no space in the value of `--conf` attribute, single quote is not needed; otherwise, I think it's needed. However the [gatk-launch](https://github.com/broadinstitute/gatk/blob/70edbb6e4caa2b7cf1b8678450443c0c590a2b76/gatk-launch) in GATK beta 4 does not produce the single quote for such case; but if I run the following without single quote, it leads to error:; >Error: Unrecognized option: -Dsamjdk.use_async_io_read_samtools=false. command:; ```; /opt/spark-latest/bin/spark-submit --master spark://localhost:6066 --deploy-mode cluster \; --driver-cores 4 --driver-memory 8g --executor-memory 4g --total-executor-cores 10 \; --conf 'spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false' \; --conf 'spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true' \; ...; ```; Here is a related [post](https://stackoverflow.com/questions/28166667/how-to-pass-d-parameter-or-environment-variable-to-spark-job) on stackoverflow.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2640#issuecomment-330666862
https://github.com/broadinstitute/cromwell/issues/2640#issuecomment-330666862:1199,Modifiability,variab,variable-to-spark-job,1199,"@jainh Yes, there are multiple `--conf` attributes.; If there is no space in the value of `--conf` attribute, single quote is not needed; otherwise, I think it's needed. However the [gatk-launch](https://github.com/broadinstitute/gatk/blob/70edbb6e4caa2b7cf1b8678450443c0c590a2b76/gatk-launch) in GATK beta 4 does not produce the single quote for such case; but if I run the following without single quote, it leads to error:; >Error: Unrecognized option: -Dsamjdk.use_async_io_read_samtools=false. command:; ```; /opt/spark-latest/bin/spark-submit --master spark://localhost:6066 --deploy-mode cluster \; --driver-cores 4 --driver-memory 8g --executor-memory 4g --total-executor-cores 10 \; --conf 'spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false' \; --conf 'spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true' \; ...; ```; Here is a related [post](https://stackoverflow.com/questions/28166667/how-to-pass-d-parameter-or-environment-variable-to-spark-job) on stackoverflow.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2640#issuecomment-330666862
https://github.com/broadinstitute/cromwell/issues/2640#issuecomment-331604537:532,Deployability,update,updated,532,"Just wonder why the runtime block has to be key-value pairs? `spark-submit` has tons of attributes and new attributes may be added in the future. Can the runtime block just be wrapped as string and passed to `spark-submit`?. If it has to be key-value pair, can the key be something like ""additionalArgs"" and the value be a string of containing attributes the user wants to add? for example:; `""additionalArgs"": ""--conf 'xx -Dxx' --name xx""`; In this way, if `spark-submit` has new attributes in the future, cromwell doesn't need to updated.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2640#issuecomment-331604537
https://github.com/broadinstitute/cromwell/issues/2640#issuecomment-331604537:176,Integrability,wrap,wrapped,176,"Just wonder why the runtime block has to be key-value pairs? `spark-submit` has tons of attributes and new attributes may be added in the future. Can the runtime block just be wrapped as string and passed to `spark-submit`?. If it has to be key-value pair, can the key be something like ""additionalArgs"" and the value be a string of containing attributes the user wants to add? for example:; `""additionalArgs"": ""--conf 'xx -Dxx' --name xx""`; In this way, if `spark-submit` has new attributes in the future, cromwell doesn't need to updated.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2640#issuecomment-331604537
https://github.com/broadinstitute/cromwell/issues/2640#issuecomment-332307343:1039,Deployability,update,update,1039,"Hi @jainh,. The runtime section is very backend-implementation specific, but to answer your question in the abstract:. The wdl spec [says](https://github.com/broadinstitute/wdl/blob/develop/SPEC.md#runtime-section) that ""Values can be any expression ‚Ä¶"". For example:. Valid wdl string:; ```; runtime {; my_key: ""a 'b c' d""; }; ```. Valid wdl array:; ```; runtime {; my_key: [""a"", ""b c"", ""d""]; }; ```. The following however is **invalid** according to the spec as the keys are duplicated:; ```; runtime {; my_key: ""a""; my_key: ""b c""; my_key: ""d""; }; ```. It is then up to the backend to decide and implement what keys and values it will accept. The config backend is currently implemented to [only](https://github.com/broadinstitute/cromwell/blob/839ea1e456b929d6149430f4d7d3805f8c235d3f/supportedBackends/sfs/src/main/scala/cromwell/backend/impl/sfs/config/DeclarationValidation.scala#L43-L50) support primitive wdl types (WdlInteger, WdlString, WdlFloat, WdlBoolean) and their optional wrappers. While it does not support them, one could update that code to support arrays of values too. Meanwhile, the JES backend already does support arrays for some attributes, e.g. for [`zones`](https://github.com/broadinstitute/cromwell/blob/839ea1e456b929d6149430f4d7d3805f8c235d3f/supportedBackends/jes/src/main/scala/cromwell/backend/impl/jes/JesRuntimeAttributes.scala#L127) and [`disks`](https://github.com/broadinstitute/cromwell/blob/839ea1e456b929d6149430f4d7d3805f8c235d3f/supportedBackends/jes/src/main/scala/cromwell/backend/impl/jes/JesRuntimeAttributes.scala#L142).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2640#issuecomment-332307343
https://github.com/broadinstitute/cromwell/issues/2640#issuecomment-332307343:987,Integrability,wrap,wrappers,987,"Hi @jainh,. The runtime section is very backend-implementation specific, but to answer your question in the abstract:. The wdl spec [says](https://github.com/broadinstitute/wdl/blob/develop/SPEC.md#runtime-section) that ""Values can be any expression ‚Ä¶"". For example:. Valid wdl string:; ```; runtime {; my_key: ""a 'b c' d""; }; ```. Valid wdl array:; ```; runtime {; my_key: [""a"", ""b c"", ""d""]; }; ```. The following however is **invalid** according to the spec as the keys are duplicated:; ```; runtime {; my_key: ""a""; my_key: ""b c""; my_key: ""d""; }; ```. It is then up to the backend to decide and implement what keys and values it will accept. The config backend is currently implemented to [only](https://github.com/broadinstitute/cromwell/blob/839ea1e456b929d6149430f4d7d3805f8c235d3f/supportedBackends/sfs/src/main/scala/cromwell/backend/impl/sfs/config/DeclarationValidation.scala#L43-L50) support primitive wdl types (WdlInteger, WdlString, WdlFloat, WdlBoolean) and their optional wrappers. While it does not support them, one could update that code to support arrays of values too. Meanwhile, the JES backend already does support arrays for some attributes, e.g. for [`zones`](https://github.com/broadinstitute/cromwell/blob/839ea1e456b929d6149430f4d7d3805f8c235d3f/supportedBackends/jes/src/main/scala/cromwell/backend/impl/jes/JesRuntimeAttributes.scala#L127) and [`disks`](https://github.com/broadinstitute/cromwell/blob/839ea1e456b929d6149430f4d7d3805f8c235d3f/supportedBackends/jes/src/main/scala/cromwell/backend/impl/jes/JesRuntimeAttributes.scala#L142).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2640#issuecomment-332307343
https://github.com/broadinstitute/cromwell/issues/2640#issuecomment-332307343:648,Modifiability,config,config,648,"Hi @jainh,. The runtime section is very backend-implementation specific, but to answer your question in the abstract:. The wdl spec [says](https://github.com/broadinstitute/wdl/blob/develop/SPEC.md#runtime-section) that ""Values can be any expression ‚Ä¶"". For example:. Valid wdl string:; ```; runtime {; my_key: ""a 'b c' d""; }; ```. Valid wdl array:; ```; runtime {; my_key: [""a"", ""b c"", ""d""]; }; ```. The following however is **invalid** according to the spec as the keys are duplicated:; ```; runtime {; my_key: ""a""; my_key: ""b c""; my_key: ""d""; }; ```. It is then up to the backend to decide and implement what keys and values it will accept. The config backend is currently implemented to [only](https://github.com/broadinstitute/cromwell/blob/839ea1e456b929d6149430f4d7d3805f8c235d3f/supportedBackends/sfs/src/main/scala/cromwell/backend/impl/sfs/config/DeclarationValidation.scala#L43-L50) support primitive wdl types (WdlInteger, WdlString, WdlFloat, WdlBoolean) and their optional wrappers. While it does not support them, one could update that code to support arrays of values too. Meanwhile, the JES backend already does support arrays for some attributes, e.g. for [`zones`](https://github.com/broadinstitute/cromwell/blob/839ea1e456b929d6149430f4d7d3805f8c235d3f/supportedBackends/jes/src/main/scala/cromwell/backend/impl/jes/JesRuntimeAttributes.scala#L127) and [`disks`](https://github.com/broadinstitute/cromwell/blob/839ea1e456b929d6149430f4d7d3805f8c235d3f/supportedBackends/jes/src/main/scala/cromwell/backend/impl/jes/JesRuntimeAttributes.scala#L142).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2640#issuecomment-332307343
https://github.com/broadinstitute/cromwell/issues/2640#issuecomment-332307343:850,Modifiability,config,config,850,"Hi @jainh,. The runtime section is very backend-implementation specific, but to answer your question in the abstract:. The wdl spec [says](https://github.com/broadinstitute/wdl/blob/develop/SPEC.md#runtime-section) that ""Values can be any expression ‚Ä¶"". For example:. Valid wdl string:; ```; runtime {; my_key: ""a 'b c' d""; }; ```. Valid wdl array:; ```; runtime {; my_key: [""a"", ""b c"", ""d""]; }; ```. The following however is **invalid** according to the spec as the keys are duplicated:; ```; runtime {; my_key: ""a""; my_key: ""b c""; my_key: ""d""; }; ```. It is then up to the backend to decide and implement what keys and values it will accept. The config backend is currently implemented to [only](https://github.com/broadinstitute/cromwell/blob/839ea1e456b929d6149430f4d7d3805f8c235d3f/supportedBackends/sfs/src/main/scala/cromwell/backend/impl/sfs/config/DeclarationValidation.scala#L43-L50) support primitive wdl types (WdlInteger, WdlString, WdlFloat, WdlBoolean) and their optional wrappers. While it does not support them, one could update that code to support arrays of values too. Meanwhile, the JES backend already does support arrays for some attributes, e.g. for [`zones`](https://github.com/broadinstitute/cromwell/blob/839ea1e456b929d6149430f4d7d3805f8c235d3f/supportedBackends/jes/src/main/scala/cromwell/backend/impl/jes/JesRuntimeAttributes.scala#L127) and [`disks`](https://github.com/broadinstitute/cromwell/blob/839ea1e456b929d6149430f4d7d3805f8c235d3f/supportedBackends/jes/src/main/scala/cromwell/backend/impl/jes/JesRuntimeAttributes.scala#L142).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2640#issuecomment-332307343
https://github.com/broadinstitute/cromwell/issues/2643#issuecomment-330975479:211,Availability,echo,echo,211,"@LeeTL1220 I just ran the following WDL against `PAPI` and `Local` it worked for both, could you confirm that it fails against SGE?. ```; task foo {; Int? mem; Int final_mem = select_first([mem, 3]). command {; echo hello world; }. runtime {; memory: final_mem + "" GB""; docker: ""ubuntu:latest""; }. output {; Int five = 5; }; }. workflow bar {; call foo; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2643#issuecomment-330975479
https://github.com/broadinstitute/cromwell/issues/2645#issuecomment-394727569:31,Availability,down,down,31,"It looks like it does now shut down, but the exit code is 0, which is potentially deceiving to people or programs that interact with it",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2645#issuecomment-394727569
https://github.com/broadinstitute/cromwell/pull/2646#issuecomment-331251916:8,Integrability,depend,dependencies,8,All the dependencies I removed are pulled in transitively from wdl4s. T,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2646#issuecomment-331251916
https://github.com/broadinstitute/cromwell/pull/2648#issuecomment-331915147:33,Energy Efficiency,charge,charge,33,Compilation included at no extra charge in #2649,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2648#issuecomment-331915147
https://github.com/broadinstitute/cromwell/issues/2652#issuecomment-331680557:194,Security,validat,validation,194,":+1: these were removed for non-technical reasons which are no longer an issue. Note to implementer (here and #2651) - keep in mind that we very intentionally don't process workflows (including validation) synchronously for submission so we should be careful here as well. One thought would be to put this (and the inputs functionality in #2651) in something behind the service registry. The default impl could process the request the way one would expect, but in something like CaaS the requests could be farmed out to another microservice or something like that. . Either way, we're also doing validation in MWDA, we should make sure it's being done the same as here",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2652#issuecomment-331680557
https://github.com/broadinstitute/cromwell/issues/2652#issuecomment-331680557:596,Security,validat,validation,596,":+1: these were removed for non-technical reasons which are no longer an issue. Note to implementer (here and #2651) - keep in mind that we very intentionally don't process workflows (including validation) synchronously for submission so we should be careful here as well. One thought would be to put this (and the inputs functionality in #2651) in something behind the service registry. The default impl could process the request the way one would expect, but in something like CaaS the requests could be farmed out to another microservice or something like that. . Either way, we're also doing validation in MWDA, we should make sure it's being done the same as here",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2652#issuecomment-331680557
https://github.com/broadinstitute/cromwell/pull/2654#issuecomment-332953049:3089,Security,authenticat,authentication,3089,tree#diff-c3VwcG9ydGVkQmFja2VuZHMvc2ZzL3NyYy9tYWluL3NjYWxhL2Nyb213ZWxsL2JhY2tlbmQvc2ZzL1NoYXJlZEZpbGVTeXN0ZW1Jbml0aWFsaXphdGlvbkFjdG9yLnNjYWxh) | `100% <√∏> (√∏)` | :arrow_up: |; | [...romwell/cloudSupport/gcp/auth/GoogleAuthMode.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/2654?src=pr&el=tree#diff-Y2xvdWRTdXBwb3J0L3NyYy9tYWluL3NjYWxhL2Nyb213ZWxsL2Nsb3VkU3VwcG9ydC9nY3AvYXV0aC9Hb29nbGVBdXRoTW9kZS5zY2FsYQ==) | `0% <√∏> (√∏)` | |; | [...cala/cromwell/backend/impl/jes/JesAttributes.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/2654?src=pr&el=tree#diff-c3VwcG9ydGVkQmFja2VuZHMvamVzL3NyYy9tYWluL3NjYWxhL2Nyb213ZWxsL2JhY2tlbmQvaW1wbC9qZXMvSmVzQXR0cmlidXRlcy5zY2FsYQ==) | `90.9% <√∏> (√∏)` | :arrow_up: |; | [...well/backend/impl/jes/JesInitializationActor.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/2654?src=pr&el=tree#diff-c3VwcG9ydGVkQmFja2VuZHMvamVzL3NyYy9tYWluL3NjYWxhL2Nyb213ZWxsL2JhY2tlbmQvaW1wbC9qZXMvSmVzSW5pdGlhbGl6YXRpb25BY3Rvci5zY2FsYQ==) | `39.39% <√∏> (√∏)` | :arrow_up: |; | [...a/cromwell/backend/impl/jes/JesConfiguration.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/2654?src=pr&el=tree#diff-c3VwcG9ydGVkQmFja2VuZHMvamVzL3NyYy9tYWluL3NjYWxhL2Nyb213ZWxsL2JhY2tlbmQvaW1wbC9qZXMvSmVzQ29uZmlndXJhdGlvbi5zY2FsYQ==) | `100% <√∏> (√∏)` | :arrow_up: |; | [.../impl/jes/authentication/JesVMAuthentication.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/2654?src=pr&el=tree#diff-c3VwcG9ydGVkQmFja2VuZHMvamVzL3NyYy9tYWluL3NjYWxhL2Nyb213ZWxsL2JhY2tlbmQvaW1wbC9qZXMvYXV0aGVudGljYXRpb24vSmVzVk1BdXRoZW50aWNhdGlvbi5zY2FsYQ==) | `100% <√∏> (√∏)` | :arrow_up: |; | [...omwell/filesystems/gcs/GcsPathBuilderFactory.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/2654?src=pr&el=tree#diff-ZmlsZXN5c3RlbXMvZ2NzL3NyYy9tYWluL3NjYWxhL2Nyb213ZWxsL2ZpbGVzeXN0ZW1zL2djcy9HY3NQYXRoQnVpbGRlckZhY3Rvcnkuc2NhbGE=) | `50% <√∏> (-16.67%)` | :arrow_down: |; | ... and [28 more](https://codecov.io/gh/broadinstitute/cromwell/pull/2654?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2654#issuecomment-332953049
https://github.com/broadinstitute/cromwell/pull/2657#issuecomment-332631165:237,Availability,error,error-reference,237,# [Codecov](https://codecov.io/gh/broadinstitute/cromwell/pull/2657?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`develop@370f3e3`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## develop #2657 +/- ##; ==========================================; Coverage ? 64.03% ; ==========================================; Files ? 381 ; Lines ? 8893 ; Branches ? 193 ; ==========================================; Hits ? 5695 ; Misses ? 3198 ; Partials ? 0; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/cromwell/pull/2657?src=pr&el=tree) | Coverage Œî | |; |---|---|---|; | [...backend/standard/StandardAsyncExecutionActor.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/2657?src=pr&el=tree#diff-YmFja2VuZC9zcmMvbWFpbi9zY2FsYS9jcm9td2VsbC9iYWNrZW5kL3N0YW5kYXJkL1N0YW5kYXJkQXN5bmNFeGVjdXRpb25BY3Rvci5zY2FsYQ==) | `67.44% <100%> (√∏)` | |,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2657#issuecomment-332631165
https://github.com/broadinstitute/cromwell/pull/2657#issuecomment-332631165:185,Usability,learn,learn,185,# [Codecov](https://codecov.io/gh/broadinstitute/cromwell/pull/2657?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`develop@370f3e3`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## develop #2657 +/- ##; ==========================================; Coverage ? 64.03% ; ==========================================; Files ? 381 ; Lines ? 8893 ; Branches ? 193 ; ==========================================; Hits ? 5695 ; Misses ? 3198 ; Partials ? 0; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/cromwell/pull/2657?src=pr&el=tree) | Coverage Œî | |; |---|---|---|; | [...backend/standard/StandardAsyncExecutionActor.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/2657?src=pr&el=tree#diff-YmFja2VuZC9zcmMvbWFpbi9zY2FsYS9jcm9td2VsbC9iYWNrZW5kL3N0YW5kYXJkL1N0YW5kYXJkQXN5bmNFeGVjdXRpb25BY3Rvci5zY2FsYQ==) | `67.44% <100%> (√∏)` | |,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2657#issuecomment-332631165
https://github.com/broadinstitute/cromwell/issues/2658#issuecomment-332269515:582,Modifiability,config,config,582,"At this time, changing the-user-id-running-_inside_-the-docker-container from `root`/`0` to the-user-id-running-_outside_-the-container would be a breaking change. There are probably hundreds of docker images running on Cromwell, and some unknown fraction of them may be expecting to run as docker's default root. Without more discussion with our wider user base we cannot make this change to the default user id just yet. However, as a workaround for those that would like to harden their environments, one can change the default docker user from root to `$EUID` by changing their config:. ```hocon; backend.providers.Local.config {; runtime-attributes = """"""; String? docker; String docker_user = ""$EUID""; """"""; }; ```; (tested on 29-242b111)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2658#issuecomment-332269515
https://github.com/broadinstitute/cromwell/issues/2658#issuecomment-332269515:625,Modifiability,config,config,625,"At this time, changing the-user-id-running-_inside_-the-docker-container from `root`/`0` to the-user-id-running-_outside_-the-container would be a breaking change. There are probably hundreds of docker images running on Cromwell, and some unknown fraction of them may be expecting to run as docker's default root. Without more discussion with our wider user base we cannot make this change to the default user id just yet. However, as a workaround for those that would like to harden their environments, one can change the default docker user from root to `$EUID` by changing their config:. ```hocon; backend.providers.Local.config {; runtime-attributes = """"""; String? docker; String docker_user = ""$EUID""; """"""; }; ```; (tested on 29-242b111)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2658#issuecomment-332269515
https://github.com/broadinstitute/cromwell/issues/2658#issuecomment-332269515:721,Testability,test,tested,721,"At this time, changing the-user-id-running-_inside_-the-docker-container from `root`/`0` to the-user-id-running-_outside_-the-container would be a breaking change. There are probably hundreds of docker images running on Cromwell, and some unknown fraction of them may be expecting to run as docker's default root. Without more discussion with our wider user base we cannot make this change to the default user id just yet. However, as a workaround for those that would like to harden their environments, one can change the default docker user from root to `$EUID` by changing their config:. ```hocon; backend.providers.Local.config {; runtime-attributes = """"""; String? docker; String docker_user = ""$EUID""; """"""; }; ```; (tested on 29-242b111)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2658#issuecomment-332269515
https://github.com/broadinstitute/cromwell/issues/2658#issuecomment-333065528:30,Modifiability,config,config,30,"I have changed it in my local config, thanks. I should add that this appears to work even for images that do not have user $EUID configured inside the docker, but there could be images that expect the user to be root to function.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2658#issuecomment-333065528
https://github.com/broadinstitute/cromwell/issues/2658#issuecomment-333065528:129,Modifiability,config,configured,129,"I have changed it in my local config, thanks. I should add that this appears to work even for images that do not have user $EUID configured inside the docker, but there could be images that expect the user to be root to function.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2658#issuecomment-333065528
https://github.com/broadinstitute/cromwell/issues/2658#issuecomment-490503768:279,Modifiability,config,config,279,"For people who also spent some time with this there is also an option to do this on a per workflow basis:; 1. Put it in a options.json:; ```json; {; ""default_runtime_attributes"": {; ""docker_user"": ""$EUID""; }; }; ```; 2. Do it on the command line: `java -Dbackend.providers.Local.config.runtime-attributes='String? docker String? docker_user=""$EUID""' -jar <cromwell_jar> run mypipeline.wdl`. @geoffjentry Do you have some preference where we should put this in the documentation? Or not, of course. I posted it here so people searching for a solution would find it.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2658#issuecomment-490503768
https://github.com/broadinstitute/cromwell/issues/2660#issuecomment-332220784:23,Integrability,depend,depend,23,These types should not depend on anything WDL.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2660#issuecomment-332220784
https://github.com/broadinstitute/cromwell/issues/2661#issuecomment-332222843:0,Integrability,Depend,Depends,0,Depends on #2660,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2661#issuecomment-332222843
https://github.com/broadinstitute/cromwell/pull/2663#issuecomment-332620801:237,Availability,error,error-reference,237,# [Codecov](https://codecov.io/gh/broadinstitute/cromwell/pull/2663?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`develop@839ea1e`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## develop #2663 +/- ##; ==========================================; Coverage ? 64.32% ; ==========================================; Files ? 381 ; Lines ? 8892 ; Branches ? 195 ; ==========================================; Hits ? 5720 ; Misses ? 3172 ; Partials ? 0; ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2663#issuecomment-332620801
https://github.com/broadinstitute/cromwell/pull/2663#issuecomment-332620801:185,Usability,learn,learn,185,# [Codecov](https://codecov.io/gh/broadinstitute/cromwell/pull/2663?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`develop@839ea1e`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## develop #2663 +/- ##; ==========================================; Coverage ? 64.32% ; ==========================================; Files ? 381 ; Lines ? 8892 ; Branches ? 195 ; ==========================================; Hits ? 5720 ; Misses ? 3172 ; Partials ? 0; ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2663#issuecomment-332620801
https://github.com/broadinstitute/cromwell/issues/2671#issuecomment-333909114:242,Modifiability,config,config,242,"Hi @dstreett - what you're seeing is an artifact of the fact that where the read API is reading from is separate from the internal database and it takes a moment for that propagation to happen. . You can improve the situation by tweaking the config setting `services.MetadataService.config.metadata-summary-refresh-interval`, the default is 2 seconds. However there'll always be a non-zero time differential there.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2671#issuecomment-333909114
https://github.com/broadinstitute/cromwell/issues/2671#issuecomment-333909114:283,Modifiability,config,config,283,"Hi @dstreett - what you're seeing is an artifact of the fact that where the read API is reading from is separate from the internal database and it takes a moment for that propagation to happen. . You can improve the situation by tweaking the config setting `services.MetadataService.config.metadata-summary-refresh-interval`, the default is 2 seconds. However there'll always be a non-zero time differential there.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2671#issuecomment-333909114
https://github.com/broadinstitute/cromwell/issues/2671#issuecomment-476351327:125,Availability,error,error,125,"I wonder if we could peek at the workflow store in the GET case and if the workflow is just-submitted, return a more helpful error than ‚Äúnot found‚Äù",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2671#issuecomment-476351327
https://github.com/broadinstitute/cromwell/issues/2677#issuecomment-334755171:90,Testability,test,tests,90,This isn't done -- there's a Cromwell PR required as well (and probably a centaur one for tests),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2677#issuecomment-334755171
https://github.com/broadinstitute/cromwell/issues/2679#issuecomment-338281475:8,Deployability,release,release,8,Yup the release WDL has most definitely been broken. ü§ï,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2679#issuecomment-338281475
https://github.com/broadinstitute/cromwell/issues/2679#issuecomment-338283948:30,Usability,simpl,simpler,30,Good news is it should become simpler no ?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2679#issuecomment-338283948
https://github.com/broadinstitute/cromwell/pull/2680#issuecomment-334792061:40,Testability,test,tests,40,@danbills because I want to fix the JES tests too and I know they're still broken for now,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2680#issuecomment-334792061
https://github.com/broadinstitute/cromwell/pull/2680#issuecomment-334931335:13,Availability,failure,failure,13,"The only JES failure is `sizeenginefunction` which seems to be suffering from some file path chimerism. In my selfish desire to move forward with Cromwell unification, I'd be more than OK with disabling that temporarily and merging what's here. üòÑ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2680#issuecomment-334931335
https://github.com/broadinstitute/cromwell/issues/2681#issuecomment-335536210:241,Availability,avail,available,241,@geoffjentry is it possible to call cache when the original input no longer exists? ; @dheiman have you looked at the [call cache diff endpoint](https://github.com/broadinstitute/cromwell#get-apiworkflowsversioncallcachingdiff)? This is not available in FireCloud but it may have more information about why a workflow cached (or did not).,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2681#issuecomment-335536210
https://github.com/broadinstitute/cromwell/issues/2681#issuecomment-335536210:36,Performance,cache,cache,36,@geoffjentry is it possible to call cache when the original input no longer exists? ; @dheiman have you looked at the [call cache diff endpoint](https://github.com/broadinstitute/cromwell#get-apiworkflowsversioncallcachingdiff)? This is not available in FireCloud but it may have more information about why a workflow cached (or did not).,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2681#issuecomment-335536210
https://github.com/broadinstitute/cromwell/issues/2681#issuecomment-335536210:124,Performance,cache,cache,124,@geoffjentry is it possible to call cache when the original input no longer exists? ; @dheiman have you looked at the [call cache diff endpoint](https://github.com/broadinstitute/cromwell#get-apiworkflowsversioncallcachingdiff)? This is not available in FireCloud but it may have more information about why a workflow cached (or did not).,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2681#issuecomment-335536210
https://github.com/broadinstitute/cromwell/issues/2681#issuecomment-335536210:318,Performance,cache,cached,318,@geoffjentry is it possible to call cache when the original input no longer exists? ; @dheiman have you looked at the [call cache diff endpoint](https://github.com/broadinstitute/cromwell#get-apiworkflowsversioncallcachingdiff)? This is not available in FireCloud but it may have more information about why a workflow cached (or did not).,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2681#issuecomment-335536210
https://github.com/broadinstitute/cromwell/issues/2681#issuecomment-335540147:24,Availability,avail,available,24,"@katevoss, it not being available in FireCloud is my high-level issue - it turns out that since FireCloud currently implements Cromwell 28, [call_caching_placeholder.txt gets placed, even though it is actually cache-by-copy rather than reference](https://gatkforums.broadinstitute.org/firecloud/discussion/10282/confusing-file-left-in-call-cached-execution-directory). . This makes me believe that it should be trivial to leave a file or log entry with details of _why_ a call was cached, which would be quite useful to me, or anyone else trying to troubleshoot an unexpected occurrence like this.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2681#issuecomment-335540147
https://github.com/broadinstitute/cromwell/issues/2681#issuecomment-335540147:210,Performance,cache,cache-by-copy,210,"@katevoss, it not being available in FireCloud is my high-level issue - it turns out that since FireCloud currently implements Cromwell 28, [call_caching_placeholder.txt gets placed, even though it is actually cache-by-copy rather than reference](https://gatkforums.broadinstitute.org/firecloud/discussion/10282/confusing-file-left-in-call-cached-execution-directory). . This makes me believe that it should be trivial to leave a file or log entry with details of _why_ a call was cached, which would be quite useful to me, or anyone else trying to troubleshoot an unexpected occurrence like this.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2681#issuecomment-335540147
https://github.com/broadinstitute/cromwell/issues/2681#issuecomment-335540147:340,Performance,cache,cached-execution-directory,340,"@katevoss, it not being available in FireCloud is my high-level issue - it turns out that since FireCloud currently implements Cromwell 28, [call_caching_placeholder.txt gets placed, even though it is actually cache-by-copy rather than reference](https://gatkforums.broadinstitute.org/firecloud/discussion/10282/confusing-file-left-in-call-cached-execution-directory). . This makes me believe that it should be trivial to leave a file or log entry with details of _why_ a call was cached, which would be quite useful to me, or anyone else trying to troubleshoot an unexpected occurrence like this.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2681#issuecomment-335540147
https://github.com/broadinstitute/cromwell/issues/2681#issuecomment-335540147:481,Performance,cache,cached,481,"@katevoss, it not being available in FireCloud is my high-level issue - it turns out that since FireCloud currently implements Cromwell 28, [call_caching_placeholder.txt gets placed, even though it is actually cache-by-copy rather than reference](https://gatkforums.broadinstitute.org/firecloud/discussion/10282/confusing-file-left-in-call-cached-execution-directory). . This makes me believe that it should be trivial to leave a file or log entry with details of _why_ a call was cached, which would be quite useful to me, or anyone else trying to troubleshoot an unexpected occurrence like this.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2681#issuecomment-335540147
https://github.com/broadinstitute/cromwell/issues/2681#issuecomment-335540147:438,Testability,log,log,438,"@katevoss, it not being available in FireCloud is my high-level issue - it turns out that since FireCloud currently implements Cromwell 28, [call_caching_placeholder.txt gets placed, even though it is actually cache-by-copy rather than reference](https://gatkforums.broadinstitute.org/firecloud/discussion/10282/confusing-file-left-in-call-cached-execution-directory). . This makes me believe that it should be trivial to leave a file or log entry with details of _why_ a call was cached, which would be quite useful to me, or anyone else trying to troubleshoot an unexpected occurrence like this.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2681#issuecomment-335540147
https://github.com/broadinstitute/cromwell/issues/2681#issuecomment-335560210:46,Performance,cache,cached,46,"@dheiman for what it's worth, ""why a call was cached"" is very conservative, so you can be assured that yes, your file's hash exactly matched the old input. As indeed did every other input value, the command string, the relevant workflow and runtime options, and the docker image specified. If anything wasn't the same, Cromwell wouldn't have used the cached result.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2681#issuecomment-335560210
https://github.com/broadinstitute/cromwell/issues/2681#issuecomment-335560210:351,Performance,cache,cached,351,"@dheiman for what it's worth, ""why a call was cached"" is very conservative, so you can be assured that yes, your file's hash exactly matched the old input. As indeed did every other input value, the command string, the relevant workflow and runtime options, and the docker image specified. If anything wasn't the same, Cromwell wouldn't have used the cached result.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2681#issuecomment-335560210
https://github.com/broadinstitute/cromwell/issues/2681#issuecomment-335560210:120,Security,hash,hash,120,"@dheiman for what it's worth, ""why a call was cached"" is very conservative, so you can be assured that yes, your file's hash exactly matched the old input. As indeed did every other input value, the command string, the relevant workflow and runtime options, and the docker image specified. If anything wasn't the same, Cromwell wouldn't have used the cached result.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2681#issuecomment-335560210
https://github.com/broadinstitute/cromwell/issues/2681#issuecomment-335560563:197,Performance,cache,cache,197,"@katevoss we can reuse the result even if the original input file is gone, because we record the hash of the file at execution time. That way, even if the old input file is modified, we won't call-cache unless the new input file matches what was used to generate the original result.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2681#issuecomment-335560563
https://github.com/broadinstitute/cromwell/issues/2681#issuecomment-335560563:97,Security,hash,hash,97,"@katevoss we can reuse the result even if the original input file is gone, because we record the hash of the file at execution time. That way, even if the old input file is modified, we won't call-cache unless the new input file matches what was used to generate the original result.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2681#issuecomment-335560563
https://github.com/broadinstitute/cromwell/issues/2685#issuecomment-335946538:97,Safety,avoid,avoid,97,"Thanks very much! In this case I had set one of my parameters to a very large number in order to avoid triggering file chunking (the Int represented maximum number of lines to read from a file before chunking). . I don't want this to take away from the fact that on genome-scale computing, there are lots of reasons for people to want to use a double. One example would be to indicate the length of the genome in bases (~3b for humans, more for some other organisms).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2685#issuecomment-335946538
https://github.com/broadinstitute/cromwell/pull/2689#issuecomment-335849487:17,Testability,test,test,17,"@mcovarr see new test. Before this change they fail because they were inserting extra `""`s:; ```; Expected :WdlString(someStr); Actual :WdlString(""someStr""); ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2689#issuecomment-335849487
https://github.com/broadinstitute/cromwell/issues/2691#issuecomment-335849494:566,Availability,avail,available,566,"From Gitter:; > we're submitting jobs via API to remote cromwell server, and want to submit workflows with all the imports resolved already (client-side) so that querying cromwell metadata submittedFiles.workflow value shows verbatim what's being executed. Is there a way in wdl4s for example to do something effectively like: `val ns = NamespaceWithWorkflow.load(myWorkflow, myResolver); val wfAsString = ns.toWdlSource` i.e. get the string representation of the workflow back again, but with the imports resolved (""expanded"")?. @cjllanwarne your gist is no longer available, do you remember what you wrote?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2691#issuecomment-335849494
https://github.com/broadinstitute/cromwell/issues/2691#issuecomment-335849494:359,Performance,load,load,359,"From Gitter:; > we're submitting jobs via API to remote cromwell server, and want to submit workflows with all the imports resolved already (client-side) so that querying cromwell metadata submittedFiles.workflow value shows verbatim what's being executed. Is there a way in wdl4s for example to do something effectively like: `val ns = NamespaceWithWorkflow.load(myWorkflow, myResolver); val wfAsString = ns.toWdlSource` i.e. get the string representation of the workflow back again, but with the imports resolved (""expanded"")?. @cjllanwarne your gist is no longer available, do you remember what you wrote?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2691#issuecomment-335849494
https://github.com/broadinstitute/cromwell/issues/2698#issuecomment-345410829:677,Availability,echo,echo,677,"There are multiple related issues in this ticket. The common thread is: a WDL author expects to be able to write compound WDL statements in a task `output` section. However, there are certain WDL statements that fail parsing when strung together, but _will_ work if the statement is broken into multiple variables. The original issue identifies problems in `output` using `glob()` or `Map[,]`. In terms of a fix, I'm guessing for the right dev this is a medium<sup>1</sup> sized task, but would probably be lower on the list of TODOs as there exists a workaround. This ""workaround"" works, where all three `output` variables are relatively simple:; ```wdl; task x {; command {; echo 0 > intFile.txt; echo hello > outFile.txt; }; runtime { docker: ""ubuntu"" }; output {; Int intermediateInt = read_int(""intFile.txt""); Array[File] intermediateOuts = glob(""outFile.txt""); File out = intermediateOuts[intermediateInt]; }; }. workflow glob_indexing { call x }; ```. Starting to compress the output block into two statements, where the latter is a compound expression, this still parses and runs:; ```wdl; output {; Int intermediateInt = read_int(""intFile.txt""); File out = glob(""outFile.txt"")[intermediateInt]; }; ```. Regarding the problems with `Map[,]` this _does_ work:; ```wdl; output {; Map[String, File] intermediateMap = {""a"": ""outFile.txt""}; File out = intermediateMap[""a""]; }; ```. HOWEVER, this doesn't work, currently failing with the error `Workflow input processing failed: <string:8:20 lbrace ""ew==""> (of class wdl4s.parser.WdlParser$Terminal)`:. ```wdl; output {; File out = {""a"": ""outFile.txt""}[""a""]; }; ```. And going back to globbing, the error with globs is _slightly_ better. This doesn't work, either:; ```wdl; output {; File out = glob(""outFile.txt"")[read_int(""intFile.txt"")]; }; ```. And fails with the ""prettier"" message at the moment:. ```; ERROR: Unexpected symbol (line 8, col 48) when parsing 'e'. Expected rsquare, got (. File out = glob(""outFile.txt"")[read_int(""intFile.txt"")];",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2698#issuecomment-345410829
https://github.com/broadinstitute/cromwell/issues/2698#issuecomment-345410829:699,Availability,echo,echo,699,"There are multiple related issues in this ticket. The common thread is: a WDL author expects to be able to write compound WDL statements in a task `output` section. However, there are certain WDL statements that fail parsing when strung together, but _will_ work if the statement is broken into multiple variables. The original issue identifies problems in `output` using `glob()` or `Map[,]`. In terms of a fix, I'm guessing for the right dev this is a medium<sup>1</sup> sized task, but would probably be lower on the list of TODOs as there exists a workaround. This ""workaround"" works, where all three `output` variables are relatively simple:; ```wdl; task x {; command {; echo 0 > intFile.txt; echo hello > outFile.txt; }; runtime { docker: ""ubuntu"" }; output {; Int intermediateInt = read_int(""intFile.txt""); Array[File] intermediateOuts = glob(""outFile.txt""); File out = intermediateOuts[intermediateInt]; }; }. workflow glob_indexing { call x }; ```. Starting to compress the output block into two statements, where the latter is a compound expression, this still parses and runs:; ```wdl; output {; Int intermediateInt = read_int(""intFile.txt""); File out = glob(""outFile.txt"")[intermediateInt]; }; ```. Regarding the problems with `Map[,]` this _does_ work:; ```wdl; output {; Map[String, File] intermediateMap = {""a"": ""outFile.txt""}; File out = intermediateMap[""a""]; }; ```. HOWEVER, this doesn't work, currently failing with the error `Workflow input processing failed: <string:8:20 lbrace ""ew==""> (of class wdl4s.parser.WdlParser$Terminal)`:. ```wdl; output {; File out = {""a"": ""outFile.txt""}[""a""]; }; ```. And going back to globbing, the error with globs is _slightly_ better. This doesn't work, either:; ```wdl; output {; File out = glob(""outFile.txt"")[read_int(""intFile.txt"")]; }; ```. And fails with the ""prettier"" message at the moment:. ```; ERROR: Unexpected symbol (line 8, col 48) when parsing 'e'. Expected rsquare, got (. File out = glob(""outFile.txt"")[read_int(""intFile.txt"")];",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2698#issuecomment-345410829
https://github.com/broadinstitute/cromwell/issues/2698#issuecomment-345410829:1440,Availability,error,error,1440,"medium<sup>1</sup> sized task, but would probably be lower on the list of TODOs as there exists a workaround. This ""workaround"" works, where all three `output` variables are relatively simple:; ```wdl; task x {; command {; echo 0 > intFile.txt; echo hello > outFile.txt; }; runtime { docker: ""ubuntu"" }; output {; Int intermediateInt = read_int(""intFile.txt""); Array[File] intermediateOuts = glob(""outFile.txt""); File out = intermediateOuts[intermediateInt]; }; }. workflow glob_indexing { call x }; ```. Starting to compress the output block into two statements, where the latter is a compound expression, this still parses and runs:; ```wdl; output {; Int intermediateInt = read_int(""intFile.txt""); File out = glob(""outFile.txt"")[intermediateInt]; }; ```. Regarding the problems with `Map[,]` this _does_ work:; ```wdl; output {; Map[String, File] intermediateMap = {""a"": ""outFile.txt""}; File out = intermediateMap[""a""]; }; ```. HOWEVER, this doesn't work, currently failing with the error `Workflow input processing failed: <string:8:20 lbrace ""ew==""> (of class wdl4s.parser.WdlParser$Terminal)`:. ```wdl; output {; File out = {""a"": ""outFile.txt""}[""a""]; }; ```. And going back to globbing, the error with globs is _slightly_ better. This doesn't work, either:; ```wdl; output {; File out = glob(""outFile.txt"")[read_int(""intFile.txt"")]; }; ```. And fails with the ""prettier"" message at the moment:. ```; ERROR: Unexpected symbol (line 8, col 48) when parsing 'e'. Expected rsquare, got (. File out = glob(""outFile.txt"")[read_int(""intFile.txt"")]; ^. $e = :identifier <=> :lparen $_gen18 :rparen -> FunctionCall( name=$0, params=$2 ); ; ```. ---. <sup>1</sup> The ""medium"" estimate is assuming this only needs to be fixed in the ~wdl4s~ cromwell-wdl project. If this is a problem lower down in the parser/grammar, then it might be harder for a developer to do. My note here is because Winstanley is also highlighting these ""bad"" examples as problematic with red-underlines, hinting that this may be a ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2698#issuecomment-345410829
https://github.com/broadinstitute/cromwell/issues/2698#issuecomment-345410829:1651,Availability,error,error,1651," would probably be lower on the list of TODOs as there exists a workaround. This ""workaround"" works, where all three `output` variables are relatively simple:; ```wdl; task x {; command {; echo 0 > intFile.txt; echo hello > outFile.txt; }; runtime { docker: ""ubuntu"" }; output {; Int intermediateInt = read_int(""intFile.txt""); Array[File] intermediateOuts = glob(""outFile.txt""); File out = intermediateOuts[intermediateInt]; }; }. workflow glob_indexing { call x }; ```. Starting to compress the output block into two statements, where the latter is a compound expression, this still parses and runs:; ```wdl; output {; Int intermediateInt = read_int(""intFile.txt""); File out = glob(""outFile.txt"")[intermediateInt]; }; ```. Regarding the problems with `Map[,]` this _does_ work:; ```wdl; output {; Map[String, File] intermediateMap = {""a"": ""outFile.txt""}; File out = intermediateMap[""a""]; }; ```. HOWEVER, this doesn't work, currently failing with the error `Workflow input processing failed: <string:8:20 lbrace ""ew==""> (of class wdl4s.parser.WdlParser$Terminal)`:. ```wdl; output {; File out = {""a"": ""outFile.txt""}[""a""]; }; ```. And going back to globbing, the error with globs is _slightly_ better. This doesn't work, either:; ```wdl; output {; File out = glob(""outFile.txt"")[read_int(""intFile.txt"")]; }; ```. And fails with the ""prettier"" message at the moment:. ```; ERROR: Unexpected symbol (line 8, col 48) when parsing 'e'. Expected rsquare, got (. File out = glob(""outFile.txt"")[read_int(""intFile.txt"")]; ^. $e = :identifier <=> :lparen $_gen18 :rparen -> FunctionCall( name=$0, params=$2 ); ; ```. ---. <sup>1</sup> The ""medium"" estimate is assuming this only needs to be fixed in the ~wdl4s~ cromwell-wdl project. If this is a problem lower down in the parser/grammar, then it might be harder for a developer to do. My note here is because Winstanley is also highlighting these ""bad"" examples as problematic with red-underlines, hinting that this may be a lower level problem than I think.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2698#issuecomment-345410829
https://github.com/broadinstitute/cromwell/issues/2698#issuecomment-345410829:1860,Availability,ERROR,ERROR,1860," would probably be lower on the list of TODOs as there exists a workaround. This ""workaround"" works, where all three `output` variables are relatively simple:; ```wdl; task x {; command {; echo 0 > intFile.txt; echo hello > outFile.txt; }; runtime { docker: ""ubuntu"" }; output {; Int intermediateInt = read_int(""intFile.txt""); Array[File] intermediateOuts = glob(""outFile.txt""); File out = intermediateOuts[intermediateInt]; }; }. workflow glob_indexing { call x }; ```. Starting to compress the output block into two statements, where the latter is a compound expression, this still parses and runs:; ```wdl; output {; Int intermediateInt = read_int(""intFile.txt""); File out = glob(""outFile.txt"")[intermediateInt]; }; ```. Regarding the problems with `Map[,]` this _does_ work:; ```wdl; output {; Map[String, File] intermediateMap = {""a"": ""outFile.txt""}; File out = intermediateMap[""a""]; }; ```. HOWEVER, this doesn't work, currently failing with the error `Workflow input processing failed: <string:8:20 lbrace ""ew==""> (of class wdl4s.parser.WdlParser$Terminal)`:. ```wdl; output {; File out = {""a"": ""outFile.txt""}[""a""]; }; ```. And going back to globbing, the error with globs is _slightly_ better. This doesn't work, either:; ```wdl; output {; File out = glob(""outFile.txt"")[read_int(""intFile.txt"")]; }; ```. And fails with the ""prettier"" message at the moment:. ```; ERROR: Unexpected symbol (line 8, col 48) when parsing 'e'. Expected rsquare, got (. File out = glob(""outFile.txt"")[read_int(""intFile.txt"")]; ^. $e = :identifier <=> :lparen $_gen18 :rparen -> FunctionCall( name=$0, params=$2 ); ; ```. ---. <sup>1</sup> The ""medium"" estimate is assuming this only needs to be fixed in the ~wdl4s~ cromwell-wdl project. If this is a problem lower down in the parser/grammar, then it might be harder for a developer to do. My note here is because Winstanley is also highlighting these ""bad"" examples as problematic with red-underlines, hinting that this may be a lower level problem than I think.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2698#issuecomment-345410829
https://github.com/broadinstitute/cromwell/issues/2698#issuecomment-345410829:2240,Availability,down,down,2240," would probably be lower on the list of TODOs as there exists a workaround. This ""workaround"" works, where all three `output` variables are relatively simple:; ```wdl; task x {; command {; echo 0 > intFile.txt; echo hello > outFile.txt; }; runtime { docker: ""ubuntu"" }; output {; Int intermediateInt = read_int(""intFile.txt""); Array[File] intermediateOuts = glob(""outFile.txt""); File out = intermediateOuts[intermediateInt]; }; }. workflow glob_indexing { call x }; ```. Starting to compress the output block into two statements, where the latter is a compound expression, this still parses and runs:; ```wdl; output {; Int intermediateInt = read_int(""intFile.txt""); File out = glob(""outFile.txt"")[intermediateInt]; }; ```. Regarding the problems with `Map[,]` this _does_ work:; ```wdl; output {; Map[String, File] intermediateMap = {""a"": ""outFile.txt""}; File out = intermediateMap[""a""]; }; ```. HOWEVER, this doesn't work, currently failing with the error `Workflow input processing failed: <string:8:20 lbrace ""ew==""> (of class wdl4s.parser.WdlParser$Terminal)`:. ```wdl; output {; File out = {""a"": ""outFile.txt""}[""a""]; }; ```. And going back to globbing, the error with globs is _slightly_ better. This doesn't work, either:; ```wdl; output {; File out = glob(""outFile.txt"")[read_int(""intFile.txt"")]; }; ```. And fails with the ""prettier"" message at the moment:. ```; ERROR: Unexpected symbol (line 8, col 48) when parsing 'e'. Expected rsquare, got (. File out = glob(""outFile.txt"")[read_int(""intFile.txt"")]; ^. $e = :identifier <=> :lparen $_gen18 :rparen -> FunctionCall( name=$0, params=$2 ); ; ```. ---. <sup>1</sup> The ""medium"" estimate is assuming this only needs to be fixed in the ~wdl4s~ cromwell-wdl project. If this is a problem lower down in the parser/grammar, then it might be harder for a developer to do. My note here is because Winstanley is also highlighting these ""bad"" examples as problematic with red-underlines, hinting that this may be a lower level problem than I think.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2698#issuecomment-345410829
https://github.com/broadinstitute/cromwell/issues/2698#issuecomment-345410829:1831,Integrability,message,message,1831," would probably be lower on the list of TODOs as there exists a workaround. This ""workaround"" works, where all three `output` variables are relatively simple:; ```wdl; task x {; command {; echo 0 > intFile.txt; echo hello > outFile.txt; }; runtime { docker: ""ubuntu"" }; output {; Int intermediateInt = read_int(""intFile.txt""); Array[File] intermediateOuts = glob(""outFile.txt""); File out = intermediateOuts[intermediateInt]; }; }. workflow glob_indexing { call x }; ```. Starting to compress the output block into two statements, where the latter is a compound expression, this still parses and runs:; ```wdl; output {; Int intermediateInt = read_int(""intFile.txt""); File out = glob(""outFile.txt"")[intermediateInt]; }; ```. Regarding the problems with `Map[,]` this _does_ work:; ```wdl; output {; Map[String, File] intermediateMap = {""a"": ""outFile.txt""}; File out = intermediateMap[""a""]; }; ```. HOWEVER, this doesn't work, currently failing with the error `Workflow input processing failed: <string:8:20 lbrace ""ew==""> (of class wdl4s.parser.WdlParser$Terminal)`:. ```wdl; output {; File out = {""a"": ""outFile.txt""}[""a""]; }; ```. And going back to globbing, the error with globs is _slightly_ better. This doesn't work, either:; ```wdl; output {; File out = glob(""outFile.txt"")[read_int(""intFile.txt"")]; }; ```. And fails with the ""prettier"" message at the moment:. ```; ERROR: Unexpected symbol (line 8, col 48) when parsing 'e'. Expected rsquare, got (. File out = glob(""outFile.txt"")[read_int(""intFile.txt"")]; ^. $e = :identifier <=> :lparen $_gen18 :rparen -> FunctionCall( name=$0, params=$2 ); ; ```. ---. <sup>1</sup> The ""medium"" estimate is assuming this only needs to be fixed in the ~wdl4s~ cromwell-wdl project. If this is a problem lower down in the parser/grammar, then it might be harder for a developer to do. My note here is because Winstanley is also highlighting these ""bad"" examples as problematic with red-underlines, hinting that this may be a lower level problem than I think.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2698#issuecomment-345410829
https://github.com/broadinstitute/cromwell/issues/2698#issuecomment-345410829:304,Modifiability,variab,variables,304,"There are multiple related issues in this ticket. The common thread is: a WDL author expects to be able to write compound WDL statements in a task `output` section. However, there are certain WDL statements that fail parsing when strung together, but _will_ work if the statement is broken into multiple variables. The original issue identifies problems in `output` using `glob()` or `Map[,]`. In terms of a fix, I'm guessing for the right dev this is a medium<sup>1</sup> sized task, but would probably be lower on the list of TODOs as there exists a workaround. This ""workaround"" works, where all three `output` variables are relatively simple:; ```wdl; task x {; command {; echo 0 > intFile.txt; echo hello > outFile.txt; }; runtime { docker: ""ubuntu"" }; output {; Int intermediateInt = read_int(""intFile.txt""); Array[File] intermediateOuts = glob(""outFile.txt""); File out = intermediateOuts[intermediateInt]; }; }. workflow glob_indexing { call x }; ```. Starting to compress the output block into two statements, where the latter is a compound expression, this still parses and runs:; ```wdl; output {; Int intermediateInt = read_int(""intFile.txt""); File out = glob(""outFile.txt"")[intermediateInt]; }; ```. Regarding the problems with `Map[,]` this _does_ work:; ```wdl; output {; Map[String, File] intermediateMap = {""a"": ""outFile.txt""}; File out = intermediateMap[""a""]; }; ```. HOWEVER, this doesn't work, currently failing with the error `Workflow input processing failed: <string:8:20 lbrace ""ew==""> (of class wdl4s.parser.WdlParser$Terminal)`:. ```wdl; output {; File out = {""a"": ""outFile.txt""}[""a""]; }; ```. And going back to globbing, the error with globs is _slightly_ better. This doesn't work, either:; ```wdl; output {; File out = glob(""outFile.txt"")[read_int(""intFile.txt"")]; }; ```. And fails with the ""prettier"" message at the moment:. ```; ERROR: Unexpected symbol (line 8, col 48) when parsing 'e'. Expected rsquare, got (. File out = glob(""outFile.txt"")[read_int(""intFile.txt"")];",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2698#issuecomment-345410829
https://github.com/broadinstitute/cromwell/issues/2698#issuecomment-345410829:614,Modifiability,variab,variables,614,"There are multiple related issues in this ticket. The common thread is: a WDL author expects to be able to write compound WDL statements in a task `output` section. However, there are certain WDL statements that fail parsing when strung together, but _will_ work if the statement is broken into multiple variables. The original issue identifies problems in `output` using `glob()` or `Map[,]`. In terms of a fix, I'm guessing for the right dev this is a medium<sup>1</sup> sized task, but would probably be lower on the list of TODOs as there exists a workaround. This ""workaround"" works, where all three `output` variables are relatively simple:; ```wdl; task x {; command {; echo 0 > intFile.txt; echo hello > outFile.txt; }; runtime { docker: ""ubuntu"" }; output {; Int intermediateInt = read_int(""intFile.txt""); Array[File] intermediateOuts = glob(""outFile.txt""); File out = intermediateOuts[intermediateInt]; }; }. workflow glob_indexing { call x }; ```. Starting to compress the output block into two statements, where the latter is a compound expression, this still parses and runs:; ```wdl; output {; Int intermediateInt = read_int(""intFile.txt""); File out = glob(""outFile.txt"")[intermediateInt]; }; ```. Regarding the problems with `Map[,]` this _does_ work:; ```wdl; output {; Map[String, File] intermediateMap = {""a"": ""outFile.txt""}; File out = intermediateMap[""a""]; }; ```. HOWEVER, this doesn't work, currently failing with the error `Workflow input processing failed: <string:8:20 lbrace ""ew==""> (of class wdl4s.parser.WdlParser$Terminal)`:. ```wdl; output {; File out = {""a"": ""outFile.txt""}[""a""]; }; ```. And going back to globbing, the error with globs is _slightly_ better. This doesn't work, either:; ```wdl; output {; File out = glob(""outFile.txt"")[read_int(""intFile.txt"")]; }; ```. And fails with the ""prettier"" message at the moment:. ```; ERROR: Unexpected symbol (line 8, col 48) when parsing 'e'. Expected rsquare, got (. File out = glob(""outFile.txt"")[read_int(""intFile.txt"")];",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2698#issuecomment-345410829
https://github.com/broadinstitute/cromwell/issues/2698#issuecomment-345410829:639,Usability,simpl,simple,639,"There are multiple related issues in this ticket. The common thread is: a WDL author expects to be able to write compound WDL statements in a task `output` section. However, there are certain WDL statements that fail parsing when strung together, but _will_ work if the statement is broken into multiple variables. The original issue identifies problems in `output` using `glob()` or `Map[,]`. In terms of a fix, I'm guessing for the right dev this is a medium<sup>1</sup> sized task, but would probably be lower on the list of TODOs as there exists a workaround. This ""workaround"" works, where all three `output` variables are relatively simple:; ```wdl; task x {; command {; echo 0 > intFile.txt; echo hello > outFile.txt; }; runtime { docker: ""ubuntu"" }; output {; Int intermediateInt = read_int(""intFile.txt""); Array[File] intermediateOuts = glob(""outFile.txt""); File out = intermediateOuts[intermediateInt]; }; }. workflow glob_indexing { call x }; ```. Starting to compress the output block into two statements, where the latter is a compound expression, this still parses and runs:; ```wdl; output {; Int intermediateInt = read_int(""intFile.txt""); File out = glob(""outFile.txt"")[intermediateInt]; }; ```. Regarding the problems with `Map[,]` this _does_ work:; ```wdl; output {; Map[String, File] intermediateMap = {""a"": ""outFile.txt""}; File out = intermediateMap[""a""]; }; ```. HOWEVER, this doesn't work, currently failing with the error `Workflow input processing failed: <string:8:20 lbrace ""ew==""> (of class wdl4s.parser.WdlParser$Terminal)`:. ```wdl; output {; File out = {""a"": ""outFile.txt""}[""a""]; }; ```. And going back to globbing, the error with globs is _slightly_ better. This doesn't work, either:; ```wdl; output {; File out = glob(""outFile.txt"")[read_int(""intFile.txt"")]; }; ```. And fails with the ""prettier"" message at the moment:. ```; ERROR: Unexpected symbol (line 8, col 48) when parsing 'e'. Expected rsquare, got (. File out = glob(""outFile.txt"")[read_int(""intFile.txt"")];",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2698#issuecomment-345410829
https://github.com/broadinstitute/cromwell/issues/2700#issuecomment-345403662:363,Integrability,Depend,Dependencies,363,"Closing this, as the above now fails fast during Materialization in cromwell/develop. Previously this would try to run several jobs and then fail (possibly) hours later. For the curious, from going through the git history, I believe https://github.com/broadinstitute/cromwell/pull/2647 is the first time this started failing fast in cromwell. From that commit's [Dependencies.scala](https://github.com/broadinstitute/cromwell/pull/2647/files#diff-0ecdbc5a001d52fb34f5eafb7cd1aaa6), here are the four commits on the wdl4s side around that time too: https://github.com/broadinstitute/wdl4s/compare/ba89da9...f63dc02",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2700#issuecomment-345403662
https://github.com/broadinstitute/cromwell/issues/2701#issuecomment-335873358:38,Modifiability,enhance,enhancement,38,@helgridly is this still a non-urgent enhancement request?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2701#issuecomment-335873358
https://github.com/broadinstitute/cromwell/issues/2701#issuecomment-335903681:92,Security,hash,hash,92,"Yeah, this was from way back when we on FC thought we'd be parsing the WDL and doing docker-hash switcheroos ourselves. But you ended up doing it! So my use case for needing this has gone away.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2701#issuecomment-335903681
https://github.com/broadinstitute/cromwell/issues/2702#issuecomment-369630808:433,Safety,avoid,avoid,433,"@katevoss I would love to have this functionality. I'm effectively nesting two scatters (by scatter over calls to a subworkflow with a scatter), which returns an Array[Array[File]]. Nothing happens to those Files at the top level, they just get passed up the callstack, so it doesn't matter to me which scatter generated which subset of Files. It would be nice to be able to operate on a flattened Array of Files at the top level to avoid gathering and moving extra data or making the WDL unnecessarily complicated.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2702#issuecomment-369630808
https://github.com/broadinstitute/cromwell/issues/2708#issuecomment-345252091:226,Modifiability,config,configurable,226,"Pretty easy: https://doc.akka.io/docs/akka-http/current/scala/http/common/json-support.html#pretty-printing. I'm picking up a discussion on what the workbench-wide policy for such things should be (e.g. always-on, always-off, configurable). Once that's decided the path for this ticket will be clear.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2708#issuecomment-345252091
https://github.com/broadinstitute/cromwell/issues/2708#issuecomment-345252091:294,Usability,clear,clear,294,"Pretty easy: https://doc.akka.io/docs/akka-http/current/scala/http/common/json-support.html#pretty-printing. I'm picking up a discussion on what the workbench-wide policy for such things should be (e.g. always-on, always-off, configurable). Once that's decided the path for this ticket will be clear.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2708#issuecomment-345252091
https://github.com/broadinstitute/cromwell/issues/2712#issuecomment-345032450:249,Safety,Risk,Risk,249,"As a **Cromwell dev**, I want **the wdl4s-CWL subproject to compile quickly**, so that **I don't waste my time waiting and waiting**.; - Effort: small? ; - As @danbills mentioned, maybe putting Circe encoding into another project will save time.; - Risk: small; - Business value: Small",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2712#issuecomment-345032450
https://github.com/broadinstitute/cromwell/issues/2718#issuecomment-335918217:11,Deployability,install,install,11,* one must install `cwltool` to test the code and/or use CWL functionality; * show people how to use CWL parsing ; * give some pointers as to how to use coproducts,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2718#issuecomment-335918217
https://github.com/broadinstitute/cromwell/issues/2718#issuecomment-335918217:32,Testability,test,test,32,* one must install `cwltool` to test the code and/or use CWL functionality; * show people how to use CWL parsing ; * give some pointers as to how to use coproducts,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2718#issuecomment-335918217
https://github.com/broadinstitute/cromwell/issues/2718#issuecomment-394008620:61,Integrability,depend,dependencies,61,- what version of cwltool is used and versions of transitive dependencies if known,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2718#issuecomment-394008620
https://github.com/broadinstitute/cromwell/issues/2719#issuecomment-335898405:14,Deployability,update,update,14,@danbills any update on this ticket?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2719#issuecomment-335898405
https://github.com/broadinstitute/cromwell/issues/2736#issuecomment-336137269:58,Energy Efficiency,schedul,scheduling,58,"In theory it shouldn't make a difference.* Cromwell isn't scheduling anything, it's merely seeing what is runnable and launching it. Thus the time delta should be miniscule. However, in the real world there are things such as quotas on the backend and that could make a difference, yes. But keep in mind that backends will themselves process job requests differently and aren't necessarily going to honor the order we send them in anyways. Thus, in my opinion this sort of general optimization is going to be folly as we can never guarantee the underlying behavior anyways. To your primary point, I get what you're saying although my experience has been that every time someone has stated that a behavior should be X as it matches the real world I find someone telling me that the opposite behavior matches the real world. :) This is one of those cases. This one is more complex in that we also hear differing opinions on the whole workflow level (ie should workflows be processed as many at once as possible or optimizing for throughput for any individual workflow). At the end of the day the limiting factor is going to be the backend set up and whatever quotas are in place. * Yes, there is a global job limit but this can be tweaked as high as one would like, so effectively not an issue.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2736#issuecomment-336137269
https://github.com/broadinstitute/cromwell/issues/2736#issuecomment-336137269:481,Performance,optimiz,optimization,481,"In theory it shouldn't make a difference.* Cromwell isn't scheduling anything, it's merely seeing what is runnable and launching it. Thus the time delta should be miniscule. However, in the real world there are things such as quotas on the backend and that could make a difference, yes. But keep in mind that backends will themselves process job requests differently and aren't necessarily going to honor the order we send them in anyways. Thus, in my opinion this sort of general optimization is going to be folly as we can never guarantee the underlying behavior anyways. To your primary point, I get what you're saying although my experience has been that every time someone has stated that a behavior should be X as it matches the real world I find someone telling me that the opposite behavior matches the real world. :) This is one of those cases. This one is more complex in that we also hear differing opinions on the whole workflow level (ie should workflows be processed as many at once as possible or optimizing for throughput for any individual workflow). At the end of the day the limiting factor is going to be the backend set up and whatever quotas are in place. * Yes, there is a global job limit but this can be tweaked as high as one would like, so effectively not an issue.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2736#issuecomment-336137269
https://github.com/broadinstitute/cromwell/issues/2736#issuecomment-336137269:1012,Performance,optimiz,optimizing,1012,"In theory it shouldn't make a difference.* Cromwell isn't scheduling anything, it's merely seeing what is runnable and launching it. Thus the time delta should be miniscule. However, in the real world there are things such as quotas on the backend and that could make a difference, yes. But keep in mind that backends will themselves process job requests differently and aren't necessarily going to honor the order we send them in anyways. Thus, in my opinion this sort of general optimization is going to be folly as we can never guarantee the underlying behavior anyways. To your primary point, I get what you're saying although my experience has been that every time someone has stated that a behavior should be X as it matches the real world I find someone telling me that the opposite behavior matches the real world. :) This is one of those cases. This one is more complex in that we also hear differing opinions on the whole workflow level (ie should workflows be processed as many at once as possible or optimizing for throughput for any individual workflow). At the end of the day the limiting factor is going to be the backend set up and whatever quotas are in place. * Yes, there is a global job limit but this can be tweaked as high as one would like, so effectively not an issue.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2736#issuecomment-336137269
https://github.com/broadinstitute/cromwell/issues/2736#issuecomment-336137269:1027,Performance,throughput,throughput,1027,"In theory it shouldn't make a difference.* Cromwell isn't scheduling anything, it's merely seeing what is runnable and launching it. Thus the time delta should be miniscule. However, in the real world there are things such as quotas on the backend and that could make a difference, yes. But keep in mind that backends will themselves process job requests differently and aren't necessarily going to honor the order we send them in anyways. Thus, in my opinion this sort of general optimization is going to be folly as we can never guarantee the underlying behavior anyways. To your primary point, I get what you're saying although my experience has been that every time someone has stated that a behavior should be X as it matches the real world I find someone telling me that the opposite behavior matches the real world. :) This is one of those cases. This one is more complex in that we also hear differing opinions on the whole workflow level (ie should workflows be processed as many at once as possible or optimizing for throughput for any individual workflow). At the end of the day the limiting factor is going to be the backend set up and whatever quotas are in place. * Yes, there is a global job limit but this can be tweaked as high as one would like, so effectively not an issue.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2736#issuecomment-336137269
https://github.com/broadinstitute/cromwell/issues/2736#issuecomment-336140019:498,Availability,avail,available,498,"Out of curiosity, did you observe a behavior that makes you think that tasks are not being run as early as they could be ?; Cromwell periodically traverses the ""unstarted"" nodes to determine if all their dependencies are satisfied, and if so starts the task, which should effectively run all tasks as soon as possible. *There is an exception to this for sub-workflows, tasks depending on a sub workflow output will only be run once the whole sub-workflow completes, even if this specific output is available before that.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2736#issuecomment-336140019
https://github.com/broadinstitute/cromwell/issues/2736#issuecomment-336140019:204,Integrability,depend,dependencies,204,"Out of curiosity, did you observe a behavior that makes you think that tasks are not being run as early as they could be ?; Cromwell periodically traverses the ""unstarted"" nodes to determine if all their dependencies are satisfied, and if so starts the task, which should effectively run all tasks as soon as possible. *There is an exception to this for sub-workflows, tasks depending on a sub workflow output will only be run once the whole sub-workflow completes, even if this specific output is available before that.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2736#issuecomment-336140019
https://github.com/broadinstitute/cromwell/issues/2736#issuecomment-336140019:375,Integrability,depend,depending,375,"Out of curiosity, did you observe a behavior that makes you think that tasks are not being run as early as they could be ?; Cromwell periodically traverses the ""unstarted"" nodes to determine if all their dependencies are satisfied, and if so starts the task, which should effectively run all tasks as soon as possible. *There is an exception to this for sub-workflows, tasks depending on a sub workflow output will only be run once the whole sub-workflow completes, even if this specific output is available before that.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2736#issuecomment-336140019
https://github.com/broadinstitute/cromwell/issues/2743#issuecomment-342169064:2011,Modifiability,config,configurable,2011,"imported and/or stored a number of places, including ~JES~ PAPI, MySQL, etc. I've frequently seen millisecond format differences when the formatter truncates the zero milliseconds. In the example above there appears to be a difference between [`start`](https://github.com/broadinstitute/cromwell/blob/2caec7d3fb24cef6e9e1fd1d3f89f6504f48dda8/engine/src/main/scala/cromwell/engine/workflow/lifecycle/execution/WorkflowMetadataHelper.scala#L15) vs. [`end`](https://github.com/broadinstitute/cromwell/blob/2caec7d3fb24cef6e9e1fd1d3f89f6504f48dda8/engine/src/main/scala/cromwell/engine/workflow/lifecycle/execution/WorkflowMetadataHelper.scala#L20)/[`submission`](https://github.com/broadinstitute/cromwell/blob/2caec7d3fb24cef6e9e1fd1d3f89f6504f48dda8/engine/src/main/scala/cromwell/engine/workflow/workflowstore/WorkflowStoreSubmitActor.scala#L111), ex: `""2017-09-15T01:50:58Z""` vs `""2017-09-15T01:50:58.000Z""`. Each is actually generated the same way using `OffsetDateTime.now.toString`. For timezone differences, I'm a little less sure without more context. I believe most (all?) google dates come back as UTC. But it's possible one may run cromwell on a JVM using a [default offset](https://docs.oracle.com/javase/8/docs/api/java/util/TimeZone.html#getDefault--), producing some `OffsetDateTime.now` with `-07:00`. This is especially the case for dates stored in database `TIMESTAMP` columns, as we use the zone of _cromwell_ before [stripping the zone](https://github.com/broadinstitute/cromwell/blob/2caec7d3fb24cef6e9e1fd1d3f89f6504f48dda8/database/sql/src/main/scala/cromwell/database/sql/SqlConverters.scala#L9-L19) and sending the datetime over to the db. A possible fix to this whole issue would be to feed all `OffsetDateTime`s through a function that, for example, does `.withNano(0).atZoneSameInstant(ZoneOffset.UTC)`, if that's what we want to do. Perhaps the ZoneOffset could be configurable, as I've heard cromwell users mentioning trouble doing the date math when staring at UTC times.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2743#issuecomment-342169064
https://github.com/broadinstitute/cromwell/issues/2743#issuecomment-459418808:397,Deployability,pipeline,pipeline,397,"Hello! We are still seeing this issue on version `36-fde91e6` using Cromwell-as-a-Service. For example, in the workflow ""d182afeb-33ae-45ac-8e78-ba9e0a7da7ab"", the ""SmartSeq2ZarrConversion"" task has an end time with no seconds or milliseconds but the start time is the full date-time stamp:; ```; ""start"": ""2019-01-28T10:24:40.084Z"" ; ""end"": ""2019-01-28T10:47Z""; ```. We noticed this issue in our pipeline that submits analysis results to the HCA, since the JSON schema that we follow to format the results requires that the timestamps are all in the full datetime format. . We could handle this inconsistency in our pipeline, but having Cromwell return timestamps in a consistent format would be ideal because then the tools that consume this information would not have to implement individual work-arounds to standardize the dates.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2743#issuecomment-459418808
https://github.com/broadinstitute/cromwell/issues/2743#issuecomment-459418808:617,Deployability,pipeline,pipeline,617,"Hello! We are still seeing this issue on version `36-fde91e6` using Cromwell-as-a-Service. For example, in the workflow ""d182afeb-33ae-45ac-8e78-ba9e0a7da7ab"", the ""SmartSeq2ZarrConversion"" task has an end time with no seconds or milliseconds but the start time is the full date-time stamp:; ```; ""start"": ""2019-01-28T10:24:40.084Z"" ; ""end"": ""2019-01-28T10:47Z""; ```. We noticed this issue in our pipeline that submits analysis results to the HCA, since the JSON schema that we follow to format the results requires that the timestamps are all in the full datetime format. . We could handle this inconsistency in our pipeline, but having Cromwell return timestamps in a consistent format would be ideal because then the tools that consume this information would not have to implement individual work-arounds to standardize the dates.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2743#issuecomment-459418808
https://github.com/broadinstitute/cromwell/issues/2744#issuecomment-336553801:73,Safety,avoid,avoid,73,Maybe you should use Long as internal cromwell wdl-Int representation to avoid such type of bugs?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2744#issuecomment-336553801
https://github.com/broadinstitute/cromwell/issues/2750#issuecomment-336873648:236,Performance,queue,queued,236,"More people are using the JG server to launch multiple workflows w/ jobs on the order of 10k and it's being slow to start those jobs. There's definitely something going on w/ memory still but one explanation is also that jobs are being queued and throttled in Cromwell to respect quota for submission which is good, but if we have tens of thousands it might take some time to start them. Jose submitted a 40k jobs workflow and aborted it almost immediately and it got me thinking that *if* they were in that queue they would still be submitted.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2750#issuecomment-336873648
https://github.com/broadinstitute/cromwell/issues/2750#issuecomment-336873648:247,Performance,throttle,throttled,247,"More people are using the JG server to launch multiple workflows w/ jobs on the order of 10k and it's being slow to start those jobs. There's definitely something going on w/ memory still but one explanation is also that jobs are being queued and throttled in Cromwell to respect quota for submission which is good, but if we have tens of thousands it might take some time to start them. Jose submitted a 40k jobs workflow and aborted it almost immediately and it got me thinking that *if* they were in that queue they would still be submitted.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2750#issuecomment-336873648
https://github.com/broadinstitute/cromwell/issues/2750#issuecomment-336873648:508,Performance,queue,queue,508,"More people are using the JG server to launch multiple workflows w/ jobs on the order of 10k and it's being slow to start those jobs. There's definitely something going on w/ memory still but one explanation is also that jobs are being queued and throttled in Cromwell to respect quota for submission which is good, but if we have tens of thousands it might take some time to start them. Jose submitted a 40k jobs workflow and aborted it almost immediately and it got me thinking that *if* they were in that queue they would still be submitted.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2750#issuecomment-336873648
https://github.com/broadinstitute/cromwell/issues/2750#issuecomment-336873648:427,Safety,abort,aborted,427,"More people are using the JG server to launch multiple workflows w/ jobs on the order of 10k and it's being slow to start those jobs. There's definitely something going on w/ memory still but one explanation is also that jobs are being queued and throttled in Cromwell to respect quota for submission which is good, but if we have tens of thousands it might take some time to start them. Jose submitted a 40k jobs workflow and aborted it almost immediately and it got me thinking that *if* they were in that queue they would still be submitted.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2750#issuecomment-336873648
https://github.com/broadinstitute/cromwell/issues/2753#issuecomment-337605187:63,Deployability,patch,patch,63,"Thanks for the issue @meganshand, we probably won't be able to patch a fix for this in 29_hotfix but we'll definitely try to make sure it's fixed in 30 :)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2753#issuecomment-337605187
https://github.com/broadinstitute/cromwell/pull/2755#issuecomment-337259904:13,Deployability,patch,patch,13,Can you also patch this in `wdltool` and any other dependencies that are as yet un-cromwell-repo-ified?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2755#issuecomment-337259904
https://github.com/broadinstitute/cromwell/pull/2755#issuecomment-337259904:51,Integrability,depend,dependencies,51,Can you also patch this in `wdltool` and any other dependencies that are as yet un-cromwell-repo-ified?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2755#issuecomment-337259904
https://github.com/broadinstitute/cromwell/issues/2756#issuecomment-337605367:61,Deployability,patch,patch,61,"Thanks for the issue @kottmast, we probably won't be able to patch a fix for this in 29_hotfix but we'll definitely try to make sure it's fixed in 30 :)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2756#issuecomment-337605367
https://github.com/broadinstitute/cromwell/issues/2756#issuecomment-337729403:45,Deployability,release,release,45,"Thanks @Horneth - any estimate on v30 target release date? Or, any other way you can think of to work around the issue?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2756#issuecomment-337729403
https://github.com/broadinstitute/cromwell/issues/2756#issuecomment-337931672:93,Deployability,pipeline,pipeline,93,"this is a critical issue of cromwell/wdltool, how did Broad avoid this issue in its internal pipeline using cromwell/wdl? this feature of WDL seems to be so commonly used in pipeline development.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2756#issuecomment-337931672
https://github.com/broadinstitute/cromwell/issues/2756#issuecomment-337931672:174,Deployability,pipeline,pipeline,174,"this is a critical issue of cromwell/wdltool, how did Broad avoid this issue in its internal pipeline using cromwell/wdl? this feature of WDL seems to be so commonly used in pipeline development.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2756#issuecomment-337931672
https://github.com/broadinstitute/cromwell/issues/2756#issuecomment-337931672:60,Safety,avoid,avoid,60,"this is a critical issue of cromwell/wdltool, how did Broad avoid this issue in its internal pipeline using cromwell/wdl? this feature of WDL seems to be so commonly used in pipeline development.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2756#issuecomment-337931672
https://github.com/broadinstitute/cromwell/issues/2756#issuecomment-435006736:743,Availability,error,error,743,"I am also having this issue. . I don't understand what I am going wrong because it seems to be I am following the basic use case explained in the cromwell manual. I have basicaly took the published paired-fastq-to-unmapped-bam.wdl. can have added inputs and parsing to that each umapped bam file created get processed first by ; processing-for-variant-discovery-local-gatk4.wdl; and then the processed bam file gets processed by ; haplotypecaller-gvcf-gatk4.wdl. So I import the 2 workflows on the top. ```; import ""processing-for-variant-discovery-local-gatk4.wdl"" as process_bam; import ""haplotypecaller-gvcf-gatk4_no_docker.wdl"" as haplotype_caller; ```. and then use them on the ubam outputs. When I run it through validate I get the same error. ```; java -jar ~/src/cromwell-36/womtool-36.jar validate my_pipeline.wdl. ERROR: Missing value or call: Couldn't find value or call with name 'haplotype_caller' in workflow (line 131):. Array[File] HaplotypeCalls_output_vcfs = haplotype_caller.HaplotypeCallerGvcf_GATK4.output_vcf; ^. java -jar ~/src/cromwell-36/womtool-36.jar validate my_pipeline.wdl. ERROR: Missing value or call: Couldn't find value or call with name 'haplotype_caller' in workflow (line 131):. Array[File] HaplotypeCalls_output_vcfs = haplotype_caller.output_vcf; ^; ```. I thought it might be that 2 subworkflows was not supported so I took out the last one and the error become about the first:. ```; java -jar ~/src/cromwell-36/womtool-36.jar validate my_pipeline_no_variant_calling.wdl. ERROR: Missing value or call: Couldn't find value or call with name 'sub' in workflow (line 110):. Array[File] ProcessedBams_duplication_metrics = sub.duplication_metrics; ^; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2756#issuecomment-435006736
https://github.com/broadinstitute/cromwell/issues/2756#issuecomment-435006736:824,Availability,ERROR,ERROR,824,"I am also having this issue. . I don't understand what I am going wrong because it seems to be I am following the basic use case explained in the cromwell manual. I have basicaly took the published paired-fastq-to-unmapped-bam.wdl. can have added inputs and parsing to that each umapped bam file created get processed first by ; processing-for-variant-discovery-local-gatk4.wdl; and then the processed bam file gets processed by ; haplotypecaller-gvcf-gatk4.wdl. So I import the 2 workflows on the top. ```; import ""processing-for-variant-discovery-local-gatk4.wdl"" as process_bam; import ""haplotypecaller-gvcf-gatk4_no_docker.wdl"" as haplotype_caller; ```. and then use them on the ubam outputs. When I run it through validate I get the same error. ```; java -jar ~/src/cromwell-36/womtool-36.jar validate my_pipeline.wdl. ERROR: Missing value or call: Couldn't find value or call with name 'haplotype_caller' in workflow (line 131):. Array[File] HaplotypeCalls_output_vcfs = haplotype_caller.HaplotypeCallerGvcf_GATK4.output_vcf; ^. java -jar ~/src/cromwell-36/womtool-36.jar validate my_pipeline.wdl. ERROR: Missing value or call: Couldn't find value or call with name 'haplotype_caller' in workflow (line 131):. Array[File] HaplotypeCalls_output_vcfs = haplotype_caller.output_vcf; ^; ```. I thought it might be that 2 subworkflows was not supported so I took out the last one and the error become about the first:. ```; java -jar ~/src/cromwell-36/womtool-36.jar validate my_pipeline_no_variant_calling.wdl. ERROR: Missing value or call: Couldn't find value or call with name 'sub' in workflow (line 110):. Array[File] ProcessedBams_duplication_metrics = sub.duplication_metrics; ^; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2756#issuecomment-435006736
https://github.com/broadinstitute/cromwell/issues/2756#issuecomment-435006736:1104,Availability,ERROR,ERROR,1104,"I am also having this issue. . I don't understand what I am going wrong because it seems to be I am following the basic use case explained in the cromwell manual. I have basicaly took the published paired-fastq-to-unmapped-bam.wdl. can have added inputs and parsing to that each umapped bam file created get processed first by ; processing-for-variant-discovery-local-gatk4.wdl; and then the processed bam file gets processed by ; haplotypecaller-gvcf-gatk4.wdl. So I import the 2 workflows on the top. ```; import ""processing-for-variant-discovery-local-gatk4.wdl"" as process_bam; import ""haplotypecaller-gvcf-gatk4_no_docker.wdl"" as haplotype_caller; ```. and then use them on the ubam outputs. When I run it through validate I get the same error. ```; java -jar ~/src/cromwell-36/womtool-36.jar validate my_pipeline.wdl. ERROR: Missing value or call: Couldn't find value or call with name 'haplotype_caller' in workflow (line 131):. Array[File] HaplotypeCalls_output_vcfs = haplotype_caller.HaplotypeCallerGvcf_GATK4.output_vcf; ^. java -jar ~/src/cromwell-36/womtool-36.jar validate my_pipeline.wdl. ERROR: Missing value or call: Couldn't find value or call with name 'haplotype_caller' in workflow (line 131):. Array[File] HaplotypeCalls_output_vcfs = haplotype_caller.output_vcf; ^; ```. I thought it might be that 2 subworkflows was not supported so I took out the last one and the error become about the first:. ```; java -jar ~/src/cromwell-36/womtool-36.jar validate my_pipeline_no_variant_calling.wdl. ERROR: Missing value or call: Couldn't find value or call with name 'sub' in workflow (line 110):. Array[File] ProcessedBams_duplication_metrics = sub.duplication_metrics; ^; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2756#issuecomment-435006736
https://github.com/broadinstitute/cromwell/issues/2756#issuecomment-435006736:1389,Availability,error,error,1389,"I am also having this issue. . I don't understand what I am going wrong because it seems to be I am following the basic use case explained in the cromwell manual. I have basicaly took the published paired-fastq-to-unmapped-bam.wdl. can have added inputs and parsing to that each umapped bam file created get processed first by ; processing-for-variant-discovery-local-gatk4.wdl; and then the processed bam file gets processed by ; haplotypecaller-gvcf-gatk4.wdl. So I import the 2 workflows on the top. ```; import ""processing-for-variant-discovery-local-gatk4.wdl"" as process_bam; import ""haplotypecaller-gvcf-gatk4_no_docker.wdl"" as haplotype_caller; ```. and then use them on the ubam outputs. When I run it through validate I get the same error. ```; java -jar ~/src/cromwell-36/womtool-36.jar validate my_pipeline.wdl. ERROR: Missing value or call: Couldn't find value or call with name 'haplotype_caller' in workflow (line 131):. Array[File] HaplotypeCalls_output_vcfs = haplotype_caller.HaplotypeCallerGvcf_GATK4.output_vcf; ^. java -jar ~/src/cromwell-36/womtool-36.jar validate my_pipeline.wdl. ERROR: Missing value or call: Couldn't find value or call with name 'haplotype_caller' in workflow (line 131):. Array[File] HaplotypeCalls_output_vcfs = haplotype_caller.output_vcf; ^; ```. I thought it might be that 2 subworkflows was not supported so I took out the last one and the error become about the first:. ```; java -jar ~/src/cromwell-36/womtool-36.jar validate my_pipeline_no_variant_calling.wdl. ERROR: Missing value or call: Couldn't find value or call with name 'sub' in workflow (line 110):. Array[File] ProcessedBams_duplication_metrics = sub.duplication_metrics; ^; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2756#issuecomment-435006736
https://github.com/broadinstitute/cromwell/issues/2756#issuecomment-435006736:1513,Availability,ERROR,ERROR,1513,"I am also having this issue. . I don't understand what I am going wrong because it seems to be I am following the basic use case explained in the cromwell manual. I have basicaly took the published paired-fastq-to-unmapped-bam.wdl. can have added inputs and parsing to that each umapped bam file created get processed first by ; processing-for-variant-discovery-local-gatk4.wdl; and then the processed bam file gets processed by ; haplotypecaller-gvcf-gatk4.wdl. So I import the 2 workflows on the top. ```; import ""processing-for-variant-discovery-local-gatk4.wdl"" as process_bam; import ""haplotypecaller-gvcf-gatk4_no_docker.wdl"" as haplotype_caller; ```. and then use them on the ubam outputs. When I run it through validate I get the same error. ```; java -jar ~/src/cromwell-36/womtool-36.jar validate my_pipeline.wdl. ERROR: Missing value or call: Couldn't find value or call with name 'haplotype_caller' in workflow (line 131):. Array[File] HaplotypeCalls_output_vcfs = haplotype_caller.HaplotypeCallerGvcf_GATK4.output_vcf; ^. java -jar ~/src/cromwell-36/womtool-36.jar validate my_pipeline.wdl. ERROR: Missing value or call: Couldn't find value or call with name 'haplotype_caller' in workflow (line 131):. Array[File] HaplotypeCalls_output_vcfs = haplotype_caller.output_vcf; ^; ```. I thought it might be that 2 subworkflows was not supported so I took out the last one and the error become about the first:. ```; java -jar ~/src/cromwell-36/womtool-36.jar validate my_pipeline_no_variant_calling.wdl. ERROR: Missing value or call: Couldn't find value or call with name 'sub' in workflow (line 110):. Array[File] ProcessedBams_duplication_metrics = sub.duplication_metrics; ^; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2756#issuecomment-435006736
https://github.com/broadinstitute/cromwell/issues/2756#issuecomment-435006736:719,Security,validat,validate,719,"I am also having this issue. . I don't understand what I am going wrong because it seems to be I am following the basic use case explained in the cromwell manual. I have basicaly took the published paired-fastq-to-unmapped-bam.wdl. can have added inputs and parsing to that each umapped bam file created get processed first by ; processing-for-variant-discovery-local-gatk4.wdl; and then the processed bam file gets processed by ; haplotypecaller-gvcf-gatk4.wdl. So I import the 2 workflows on the top. ```; import ""processing-for-variant-discovery-local-gatk4.wdl"" as process_bam; import ""haplotypecaller-gvcf-gatk4_no_docker.wdl"" as haplotype_caller; ```. and then use them on the ubam outputs. When I run it through validate I get the same error. ```; java -jar ~/src/cromwell-36/womtool-36.jar validate my_pipeline.wdl. ERROR: Missing value or call: Couldn't find value or call with name 'haplotype_caller' in workflow (line 131):. Array[File] HaplotypeCalls_output_vcfs = haplotype_caller.HaplotypeCallerGvcf_GATK4.output_vcf; ^. java -jar ~/src/cromwell-36/womtool-36.jar validate my_pipeline.wdl. ERROR: Missing value or call: Couldn't find value or call with name 'haplotype_caller' in workflow (line 131):. Array[File] HaplotypeCalls_output_vcfs = haplotype_caller.output_vcf; ^; ```. I thought it might be that 2 subworkflows was not supported so I took out the last one and the error become about the first:. ```; java -jar ~/src/cromwell-36/womtool-36.jar validate my_pipeline_no_variant_calling.wdl. ERROR: Missing value or call: Couldn't find value or call with name 'sub' in workflow (line 110):. Array[File] ProcessedBams_duplication_metrics = sub.duplication_metrics; ^; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2756#issuecomment-435006736
https://github.com/broadinstitute/cromwell/issues/2756#issuecomment-435006736:798,Security,validat,validate,798,"I am also having this issue. . I don't understand what I am going wrong because it seems to be I am following the basic use case explained in the cromwell manual. I have basicaly took the published paired-fastq-to-unmapped-bam.wdl. can have added inputs and parsing to that each umapped bam file created get processed first by ; processing-for-variant-discovery-local-gatk4.wdl; and then the processed bam file gets processed by ; haplotypecaller-gvcf-gatk4.wdl. So I import the 2 workflows on the top. ```; import ""processing-for-variant-discovery-local-gatk4.wdl"" as process_bam; import ""haplotypecaller-gvcf-gatk4_no_docker.wdl"" as haplotype_caller; ```. and then use them on the ubam outputs. When I run it through validate I get the same error. ```; java -jar ~/src/cromwell-36/womtool-36.jar validate my_pipeline.wdl. ERROR: Missing value or call: Couldn't find value or call with name 'haplotype_caller' in workflow (line 131):. Array[File] HaplotypeCalls_output_vcfs = haplotype_caller.HaplotypeCallerGvcf_GATK4.output_vcf; ^. java -jar ~/src/cromwell-36/womtool-36.jar validate my_pipeline.wdl. ERROR: Missing value or call: Couldn't find value or call with name 'haplotype_caller' in workflow (line 131):. Array[File] HaplotypeCalls_output_vcfs = haplotype_caller.output_vcf; ^; ```. I thought it might be that 2 subworkflows was not supported so I took out the last one and the error become about the first:. ```; java -jar ~/src/cromwell-36/womtool-36.jar validate my_pipeline_no_variant_calling.wdl. ERROR: Missing value or call: Couldn't find value or call with name 'sub' in workflow (line 110):. Array[File] ProcessedBams_duplication_metrics = sub.duplication_metrics; ^; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2756#issuecomment-435006736
https://github.com/broadinstitute/cromwell/issues/2756#issuecomment-435006736:1078,Security,validat,validate,1078,"I am also having this issue. . I don't understand what I am going wrong because it seems to be I am following the basic use case explained in the cromwell manual. I have basicaly took the published paired-fastq-to-unmapped-bam.wdl. can have added inputs and parsing to that each umapped bam file created get processed first by ; processing-for-variant-discovery-local-gatk4.wdl; and then the processed bam file gets processed by ; haplotypecaller-gvcf-gatk4.wdl. So I import the 2 workflows on the top. ```; import ""processing-for-variant-discovery-local-gatk4.wdl"" as process_bam; import ""haplotypecaller-gvcf-gatk4_no_docker.wdl"" as haplotype_caller; ```. and then use them on the ubam outputs. When I run it through validate I get the same error. ```; java -jar ~/src/cromwell-36/womtool-36.jar validate my_pipeline.wdl. ERROR: Missing value or call: Couldn't find value or call with name 'haplotype_caller' in workflow (line 131):. Array[File] HaplotypeCalls_output_vcfs = haplotype_caller.HaplotypeCallerGvcf_GATK4.output_vcf; ^. java -jar ~/src/cromwell-36/womtool-36.jar validate my_pipeline.wdl. ERROR: Missing value or call: Couldn't find value or call with name 'haplotype_caller' in workflow (line 131):. Array[File] HaplotypeCalls_output_vcfs = haplotype_caller.output_vcf; ^; ```. I thought it might be that 2 subworkflows was not supported so I took out the last one and the error become about the first:. ```; java -jar ~/src/cromwell-36/womtool-36.jar validate my_pipeline_no_variant_calling.wdl. ERROR: Missing value or call: Couldn't find value or call with name 'sub' in workflow (line 110):. Array[File] ProcessedBams_duplication_metrics = sub.duplication_metrics; ^; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2756#issuecomment-435006736
https://github.com/broadinstitute/cromwell/issues/2756#issuecomment-435006736:1468,Security,validat,validate,1468,"I am also having this issue. . I don't understand what I am going wrong because it seems to be I am following the basic use case explained in the cromwell manual. I have basicaly took the published paired-fastq-to-unmapped-bam.wdl. can have added inputs and parsing to that each umapped bam file created get processed first by ; processing-for-variant-discovery-local-gatk4.wdl; and then the processed bam file gets processed by ; haplotypecaller-gvcf-gatk4.wdl. So I import the 2 workflows on the top. ```; import ""processing-for-variant-discovery-local-gatk4.wdl"" as process_bam; import ""haplotypecaller-gvcf-gatk4_no_docker.wdl"" as haplotype_caller; ```. and then use them on the ubam outputs. When I run it through validate I get the same error. ```; java -jar ~/src/cromwell-36/womtool-36.jar validate my_pipeline.wdl. ERROR: Missing value or call: Couldn't find value or call with name 'haplotype_caller' in workflow (line 131):. Array[File] HaplotypeCalls_output_vcfs = haplotype_caller.HaplotypeCallerGvcf_GATK4.output_vcf; ^. java -jar ~/src/cromwell-36/womtool-36.jar validate my_pipeline.wdl. ERROR: Missing value or call: Couldn't find value or call with name 'haplotype_caller' in workflow (line 131):. Array[File] HaplotypeCalls_output_vcfs = haplotype_caller.output_vcf; ^; ```. I thought it might be that 2 subworkflows was not supported so I took out the last one and the error become about the first:. ```; java -jar ~/src/cromwell-36/womtool-36.jar validate my_pipeline_no_variant_calling.wdl. ERROR: Missing value or call: Couldn't find value or call with name 'sub' in workflow (line 110):. Array[File] ProcessedBams_duplication_metrics = sub.duplication_metrics; ^; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2756#issuecomment-435006736
https://github.com/broadinstitute/cromwell/pull/2762#issuecomment-337983823:234,Testability,test,test,234,@mcovarr I thought we said that the move to unicromwell wouldn't require `cromwell-` in front of jar names? I noticed that this morning in the convo about where the `wdl4s` artifacts went. If this is a program designed to generically test wdl & cwl (which IMO it **is**) it shouldn't have `cromwell-` in front of the name.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2762#issuecomment-337983823
https://github.com/broadinstitute/cromwell/issues/2768#issuecomment-338301969:70,Performance,load,load,70,> We'll need 5GB (no joke!) . Hmm it doesn't seem like a good idea to load a 5GB file over network in Cromwell's memory üòÑ,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2768#issuecomment-338301969
https://github.com/broadinstitute/cromwell/issues/2768#issuecomment-338348644:51,Deployability,upgrade,upgraded,51,"@ldgauthier has the actual use case. We've already upgraded the methods cromwell. Is there a way to scatter over an iterator, so the whole list does not have to be read into RAM?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2768#issuecomment-338348644
https://github.com/broadinstitute/cromwell/issues/2768#issuecomment-338350853:300,Energy Efficiency,charge,charge,300,"Deleting some comments due to being interspersed with untrue things. @LeeTL1220 . As per #1762 the intention was to have spec mandated minimums and implementation level maximums. The former never happened so technically it's not part of the spec at all. And as I noted, Cromwell team is no longer in charge of the WDL spec, so ... That said, it's tunable. You can increase it if you want. I wouldn't recommend going all that high unless you're willing to really jam a lot of memory in there. As per your iterator comment, I go back to the Cromwell team doesn't control WDL anymore and there's no WDL construct which would allow that. There's been chatter about things which might help but they're unlikely to arrive until after WDL 1.0",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2768#issuecomment-338350853
https://github.com/broadinstitute/cromwell/issues/2768#issuecomment-338398224:586,Energy Efficiency,charge,charge,586,"If it can be specified by a workflow option, then everyone is happy. And; we don't have to wait for 1.0. On Oct 20, 2017 20:30, ""Jeff Gentry"" <notifications@github.com> wrote:. > Deleting some comments due to being interspersed with untrue things.; >; > @LeeTL1220 <https://github.com/leetl1220>; >; > As per #1762 <https://github.com/broadinstitute/cromwell/issues/1762> the; > intention was to have spec mandated minimums and implementation level; > maximums. The former never happened so technically it's not part of the; > spec at all. And as I noted, Cromwell team is no longer in charge of the; > WDL spec, so ...; >; > That said, it's tunable. You can increase it if you want. I wouldn't; > recommend going all that high unless you're willing to really jam a lot of; > memory in there.; >; > As per your iterator comment, I go back to the Cromwell team doesn't; > control WDL anymore and there's no WDL construct which would allow that.; > There's been chatter about things which might help but they're unlikely to; > arrive until after WDL 1.0; >; > ‚Äî; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/2768#issuecomment-338350853>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXkyBD9ZS-tfUwjFaEVS_i9Gro7EOUks5suTs2gaJpZM4QBFpH>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2768#issuecomment-338398224
https://github.com/broadinstitute/cromwell/issues/2768#issuecomment-338406950:74,Energy Efficiency,power,power,74,The point of the setting is to protect the server from users. Putting the power directly in the hands of the users seems unwise,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2768#issuecomment-338406950
https://github.com/broadinstitute/cromwell/issues/2768#issuecomment-413173960:116,Availability,error,error,116,"I am using exactly the wdl and json offered by gatk GitHub page for gatk4-germline-snps-indels, locally, I got this error, intervals-hg38.even.handcurated.20k.intervals is larger than 128000 Bytes. Maximum read limits can be adjusted in the configuration under system.input-read-limits.; I tried to change it via type this in command line: java -Dsystem.input-read-limits=500000 -jar /cromwell-34.jar ; Didn't work.; Who can tell me how to fix it?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2768#issuecomment-413173960
https://github.com/broadinstitute/cromwell/issues/2768#issuecomment-413173960:241,Deployability,configurat,configuration,241,"I am using exactly the wdl and json offered by gatk GitHub page for gatk4-germline-snps-indels, locally, I got this error, intervals-hg38.even.handcurated.20k.intervals is larger than 128000 Bytes. Maximum read limits can be adjusted in the configuration under system.input-read-limits.; I tried to change it via type this in command line: java -Dsystem.input-read-limits=500000 -jar /cromwell-34.jar ; Didn't work.; Who can tell me how to fix it?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2768#issuecomment-413173960
https://github.com/broadinstitute/cromwell/issues/2768#issuecomment-413173960:241,Modifiability,config,configuration,241,"I am using exactly the wdl and json offered by gatk GitHub page for gatk4-germline-snps-indels, locally, I got this error, intervals-hg38.even.handcurated.20k.intervals is larger than 128000 Bytes. Maximum read limits can be adjusted in the configuration under system.input-read-limits.; I tried to change it via type this in command line: java -Dsystem.input-read-limits=500000 -jar /cromwell-34.jar ; Didn't work.; Who can tell me how to fix it?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2768#issuecomment-413173960
https://github.com/broadinstitute/cromwell/issues/2768#issuecomment-417328909:33,Modifiability,config,configure,33,"@LeeTL1220 since its possible to configure this limit as needed, I'm hoping you've got what you needed. Feel free to reopen if I missed something.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2768#issuecomment-417328909
https://github.com/broadinstitute/cromwell/pull/2770#issuecomment-338699689:59,Usability,clear,clear,59,"üëç I don't particularly like ""common"" since it's not at all clear what now goes in ""common"" vs ""core"" but ü§∑‚Äç‚ôÇÔ∏è I can't think of anything better. [![Approved with PullApprove](https://img.shields.io/badge/reviewers-approved-brightgreen.svg)](https://pullapprove.com/broadinstitute/cromwell/pull-request/2770/?utm_source=github-pr&utm_medium=comment-badge&utm_campaign=broadinstitute/cromwell)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2770#issuecomment-338699689
https://github.com/broadinstitute/cromwell/issues/2771#issuecomment-338325747:59,Modifiability,portab,portable,59,"It could, I sort-of don't like the idea of encouraging non-portable workflows by allowing users to make the read-length higher in config files without making that explicit in the CWL",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2771#issuecomment-338325747
https://github.com/broadinstitute/cromwell/issues/2771#issuecomment-338325747:130,Modifiability,config,config,130,"It could, I sort-of don't like the idea of encouraging non-portable workflows by allowing users to make the read-length higher in config files without making that explicit in the CWL",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2771#issuecomment-338325747
https://github.com/broadinstitute/cromwell/issues/2771#issuecomment-338328135:82,Modifiability,portab,portable,82,"THIs wouldn‚Äôt be us contributing to nonportability, the feature is inherently non portable",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2771#issuecomment-338328135
https://github.com/broadinstitute/cromwell/issues/2771#issuecomment-338328584:56,Usability,simpl,simpler,56,"Note that I don‚Äôt really care but it seems like it‚Äôd be simpler for us and it‚Äôs not being skeezy or anything, that was literally how they intended it to work",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2771#issuecomment-338328584
https://github.com/broadinstitute/cromwell/issues/2773#issuecomment-338747591:64,Modifiability,config,configurability,64,"I would love to see this folded into a general ""import resolver configurability"" feature. Right now the code is a bit of spaghetti for different conditions (e.g. local imports, zip imports, http). Would be great to have that all config driven. Also -- I wrote the http importer in such a way that we should be able to ""configure"" an http importer that provides headers/credentials for certain URLs. That could also be the driver to implement this. Happy to discuss more with faces",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2773#issuecomment-338747591
https://github.com/broadinstitute/cromwell/issues/2773#issuecomment-338747591:229,Modifiability,config,config,229,"I would love to see this folded into a general ""import resolver configurability"" feature. Right now the code is a bit of spaghetti for different conditions (e.g. local imports, zip imports, http). Would be great to have that all config driven. Also -- I wrote the http importer in such a way that we should be able to ""configure"" an http importer that provides headers/credentials for certain URLs. That could also be the driver to implement this. Happy to discuss more with faces",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2773#issuecomment-338747591
https://github.com/broadinstitute/cromwell/issues/2773#issuecomment-338747591:319,Modifiability,config,configure,319,"I would love to see this folded into a general ""import resolver configurability"" feature. Right now the code is a bit of spaghetti for different conditions (e.g. local imports, zip imports, http). Would be great to have that all config driven. Also -- I wrote the http importer in such a way that we should be able to ""configure"" an http importer that provides headers/credentials for certain URLs. That could also be the driver to implement this. Happy to discuss more with faces",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2773#issuecomment-338747591
https://github.com/broadinstitute/cromwell/issues/2774#issuecomment-342886864:35,Availability,error,error,35,"We get 'fail to delocalize' as the error message over a bunch of failure types. In particular, when the task failed with return code 0. This makes failures hard to debug in FireCloud, as users have to dig down into logs.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2774#issuecomment-342886864
https://github.com/broadinstitute/cromwell/issues/2774#issuecomment-342886864:65,Availability,failure,failure,65,"We get 'fail to delocalize' as the error message over a bunch of failure types. In particular, when the task failed with return code 0. This makes failures hard to debug in FireCloud, as users have to dig down into logs.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2774#issuecomment-342886864
https://github.com/broadinstitute/cromwell/issues/2774#issuecomment-342886864:147,Availability,failure,failures,147,"We get 'fail to delocalize' as the error message over a bunch of failure types. In particular, when the task failed with return code 0. This makes failures hard to debug in FireCloud, as users have to dig down into logs.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2774#issuecomment-342886864
https://github.com/broadinstitute/cromwell/issues/2774#issuecomment-342886864:205,Availability,down,down,205,"We get 'fail to delocalize' as the error message over a bunch of failure types. In particular, when the task failed with return code 0. This makes failures hard to debug in FireCloud, as users have to dig down into logs.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2774#issuecomment-342886864
https://github.com/broadinstitute/cromwell/issues/2774#issuecomment-342886864:41,Integrability,message,message,41,"We get 'fail to delocalize' as the error message over a bunch of failure types. In particular, when the task failed with return code 0. This makes failures hard to debug in FireCloud, as users have to dig down into logs.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2774#issuecomment-342886864
https://github.com/broadinstitute/cromwell/issues/2774#issuecomment-342886864:215,Testability,log,logs,215,"We get 'fail to delocalize' as the error message over a bunch of failure types. In particular, when the task failed with return code 0. This makes failures hard to debug in FireCloud, as users have to dig down into logs.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2774#issuecomment-342886864
https://github.com/broadinstitute/cromwell/pull/2775#issuecomment-338986251:20,Energy Efficiency,green,green,20,LGTM when travis is green üëç . [![Approved with PullApprove](https://img.shields.io/badge/reviewers-approved-brightgreen.svg)](https://pullapprove.com/broadinstitute/cromwell/pull-request/2775/?utm_source=github-pr&utm_medium=comment-badge&utm_campaign=broadinstitute/cromwell),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2775#issuecomment-338986251
https://github.com/broadinstitute/cromwell/pull/2777#issuecomment-339033675:173,Availability,mainten,maintenance,173,"Er, what I meant to write was, can you please create this branch in the main Cromwell repo and PR that instead? Having branches in private repos has been causing review and maintenance pain.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2777#issuecomment-339033675
https://github.com/broadinstitute/cromwell/pull/2778#issuecomment-339041352:20,Testability,test,tested,20,For the record I've tested this manually.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2778#issuecomment-339041352
https://github.com/broadinstitute/cromwell/pull/2779#issuecomment-339091206:409,Deployability,Patch,Patch,409,"For those that come across this PR in the future, a subset of the [docs](https://docs.codecov.io/v4.3.6/docs) referred to in this PR:; - Commit Status; - Project Status; - [Target](https://docs.codecov.io/v4.3.6/docs/commit-status#section-target); - [Threshold](https://docs.codecov.io/v4.3.6/docs/commit-status#section-threshold); - [Base](https://docs.codecov.io/v4.3.6/docs/commit-status#section-base); - [Patch Status](https://docs.codecov.io/v4.3.6/docs/commit-status#section-patch-status); - Coverage Configuration; - [Range](https://docs.codecov.io/v4.3.6/docs/coverage-configuration#section-range); - [Rounding](https://docs.codecov.io/v4.3.6/docs/coverage-configuration#section-rounding); - Notifications; - [Slack](https://docs.codecov.io/v4.3.6/docs/notifications#section-slack); - Pull Request Comments; - [Disable comment](https://docs.codecov.io/v4.3.6/docs/pull-request-comments#section-disable-comment) (aka Github emails); - CodeCov YAML; - [Default Branch](https://docs.codecov.io/v4.3.6/docs/codecov-yaml#section-default-branch); - [Validate your repository yaml](https://docs.codecov.io/v4.3.6/docs/codecov-yaml#section-validate-your-repository-yaml)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2779#issuecomment-339091206
https://github.com/broadinstitute/cromwell/pull/2779#issuecomment-339091206:481,Deployability,patch,patch-status,481,"For those that come across this PR in the future, a subset of the [docs](https://docs.codecov.io/v4.3.6/docs) referred to in this PR:; - Commit Status; - Project Status; - [Target](https://docs.codecov.io/v4.3.6/docs/commit-status#section-target); - [Threshold](https://docs.codecov.io/v4.3.6/docs/commit-status#section-threshold); - [Base](https://docs.codecov.io/v4.3.6/docs/commit-status#section-base); - [Patch Status](https://docs.codecov.io/v4.3.6/docs/commit-status#section-patch-status); - Coverage Configuration; - [Range](https://docs.codecov.io/v4.3.6/docs/coverage-configuration#section-range); - [Rounding](https://docs.codecov.io/v4.3.6/docs/coverage-configuration#section-rounding); - Notifications; - [Slack](https://docs.codecov.io/v4.3.6/docs/notifications#section-slack); - Pull Request Comments; - [Disable comment](https://docs.codecov.io/v4.3.6/docs/pull-request-comments#section-disable-comment) (aka Github emails); - CodeCov YAML; - [Default Branch](https://docs.codecov.io/v4.3.6/docs/codecov-yaml#section-default-branch); - [Validate your repository yaml](https://docs.codecov.io/v4.3.6/docs/codecov-yaml#section-validate-your-repository-yaml)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2779#issuecomment-339091206
https://github.com/broadinstitute/cromwell/pull/2779#issuecomment-339091206:507,Deployability,Configurat,Configuration,507,"For those that come across this PR in the future, a subset of the [docs](https://docs.codecov.io/v4.3.6/docs) referred to in this PR:; - Commit Status; - Project Status; - [Target](https://docs.codecov.io/v4.3.6/docs/commit-status#section-target); - [Threshold](https://docs.codecov.io/v4.3.6/docs/commit-status#section-threshold); - [Base](https://docs.codecov.io/v4.3.6/docs/commit-status#section-base); - [Patch Status](https://docs.codecov.io/v4.3.6/docs/commit-status#section-patch-status); - Coverage Configuration; - [Range](https://docs.codecov.io/v4.3.6/docs/coverage-configuration#section-range); - [Rounding](https://docs.codecov.io/v4.3.6/docs/coverage-configuration#section-rounding); - Notifications; - [Slack](https://docs.codecov.io/v4.3.6/docs/notifications#section-slack); - Pull Request Comments; - [Disable comment](https://docs.codecov.io/v4.3.6/docs/pull-request-comments#section-disable-comment) (aka Github emails); - CodeCov YAML; - [Default Branch](https://docs.codecov.io/v4.3.6/docs/codecov-yaml#section-default-branch); - [Validate your repository yaml](https://docs.codecov.io/v4.3.6/docs/codecov-yaml#section-validate-your-repository-yaml)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2779#issuecomment-339091206
https://github.com/broadinstitute/cromwell/pull/2779#issuecomment-339091206:577,Deployability,configurat,configuration,577,"For those that come across this PR in the future, a subset of the [docs](https://docs.codecov.io/v4.3.6/docs) referred to in this PR:; - Commit Status; - Project Status; - [Target](https://docs.codecov.io/v4.3.6/docs/commit-status#section-target); - [Threshold](https://docs.codecov.io/v4.3.6/docs/commit-status#section-threshold); - [Base](https://docs.codecov.io/v4.3.6/docs/commit-status#section-base); - [Patch Status](https://docs.codecov.io/v4.3.6/docs/commit-status#section-patch-status); - Coverage Configuration; - [Range](https://docs.codecov.io/v4.3.6/docs/coverage-configuration#section-range); - [Rounding](https://docs.codecov.io/v4.3.6/docs/coverage-configuration#section-rounding); - Notifications; - [Slack](https://docs.codecov.io/v4.3.6/docs/notifications#section-slack); - Pull Request Comments; - [Disable comment](https://docs.codecov.io/v4.3.6/docs/pull-request-comments#section-disable-comment) (aka Github emails); - CodeCov YAML; - [Default Branch](https://docs.codecov.io/v4.3.6/docs/codecov-yaml#section-default-branch); - [Validate your repository yaml](https://docs.codecov.io/v4.3.6/docs/codecov-yaml#section-validate-your-repository-yaml)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2779#issuecomment-339091206
https://github.com/broadinstitute/cromwell/pull/2779#issuecomment-339091206:665,Deployability,configurat,configuration,665,"For those that come across this PR in the future, a subset of the [docs](https://docs.codecov.io/v4.3.6/docs) referred to in this PR:; - Commit Status; - Project Status; - [Target](https://docs.codecov.io/v4.3.6/docs/commit-status#section-target); - [Threshold](https://docs.codecov.io/v4.3.6/docs/commit-status#section-threshold); - [Base](https://docs.codecov.io/v4.3.6/docs/commit-status#section-base); - [Patch Status](https://docs.codecov.io/v4.3.6/docs/commit-status#section-patch-status); - Coverage Configuration; - [Range](https://docs.codecov.io/v4.3.6/docs/coverage-configuration#section-range); - [Rounding](https://docs.codecov.io/v4.3.6/docs/coverage-configuration#section-rounding); - Notifications; - [Slack](https://docs.codecov.io/v4.3.6/docs/notifications#section-slack); - Pull Request Comments; - [Disable comment](https://docs.codecov.io/v4.3.6/docs/pull-request-comments#section-disable-comment) (aka Github emails); - CodeCov YAML; - [Default Branch](https://docs.codecov.io/v4.3.6/docs/codecov-yaml#section-default-branch); - [Validate your repository yaml](https://docs.codecov.io/v4.3.6/docs/codecov-yaml#section-validate-your-repository-yaml)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2779#issuecomment-339091206
https://github.com/broadinstitute/cromwell/pull/2779#issuecomment-339091206:507,Modifiability,Config,Configuration,507,"For those that come across this PR in the future, a subset of the [docs](https://docs.codecov.io/v4.3.6/docs) referred to in this PR:; - Commit Status; - Project Status; - [Target](https://docs.codecov.io/v4.3.6/docs/commit-status#section-target); - [Threshold](https://docs.codecov.io/v4.3.6/docs/commit-status#section-threshold); - [Base](https://docs.codecov.io/v4.3.6/docs/commit-status#section-base); - [Patch Status](https://docs.codecov.io/v4.3.6/docs/commit-status#section-patch-status); - Coverage Configuration; - [Range](https://docs.codecov.io/v4.3.6/docs/coverage-configuration#section-range); - [Rounding](https://docs.codecov.io/v4.3.6/docs/coverage-configuration#section-rounding); - Notifications; - [Slack](https://docs.codecov.io/v4.3.6/docs/notifications#section-slack); - Pull Request Comments; - [Disable comment](https://docs.codecov.io/v4.3.6/docs/pull-request-comments#section-disable-comment) (aka Github emails); - CodeCov YAML; - [Default Branch](https://docs.codecov.io/v4.3.6/docs/codecov-yaml#section-default-branch); - [Validate your repository yaml](https://docs.codecov.io/v4.3.6/docs/codecov-yaml#section-validate-your-repository-yaml)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2779#issuecomment-339091206
https://github.com/broadinstitute/cromwell/pull/2779#issuecomment-339091206:577,Modifiability,config,configuration,577,"For those that come across this PR in the future, a subset of the [docs](https://docs.codecov.io/v4.3.6/docs) referred to in this PR:; - Commit Status; - Project Status; - [Target](https://docs.codecov.io/v4.3.6/docs/commit-status#section-target); - [Threshold](https://docs.codecov.io/v4.3.6/docs/commit-status#section-threshold); - [Base](https://docs.codecov.io/v4.3.6/docs/commit-status#section-base); - [Patch Status](https://docs.codecov.io/v4.3.6/docs/commit-status#section-patch-status); - Coverage Configuration; - [Range](https://docs.codecov.io/v4.3.6/docs/coverage-configuration#section-range); - [Rounding](https://docs.codecov.io/v4.3.6/docs/coverage-configuration#section-rounding); - Notifications; - [Slack](https://docs.codecov.io/v4.3.6/docs/notifications#section-slack); - Pull Request Comments; - [Disable comment](https://docs.codecov.io/v4.3.6/docs/pull-request-comments#section-disable-comment) (aka Github emails); - CodeCov YAML; - [Default Branch](https://docs.codecov.io/v4.3.6/docs/codecov-yaml#section-default-branch); - [Validate your repository yaml](https://docs.codecov.io/v4.3.6/docs/codecov-yaml#section-validate-your-repository-yaml)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2779#issuecomment-339091206
https://github.com/broadinstitute/cromwell/pull/2779#issuecomment-339091206:665,Modifiability,config,configuration,665,"For those that come across this PR in the future, a subset of the [docs](https://docs.codecov.io/v4.3.6/docs) referred to in this PR:; - Commit Status; - Project Status; - [Target](https://docs.codecov.io/v4.3.6/docs/commit-status#section-target); - [Threshold](https://docs.codecov.io/v4.3.6/docs/commit-status#section-threshold); - [Base](https://docs.codecov.io/v4.3.6/docs/commit-status#section-base); - [Patch Status](https://docs.codecov.io/v4.3.6/docs/commit-status#section-patch-status); - Coverage Configuration; - [Range](https://docs.codecov.io/v4.3.6/docs/coverage-configuration#section-range); - [Rounding](https://docs.codecov.io/v4.3.6/docs/coverage-configuration#section-rounding); - Notifications; - [Slack](https://docs.codecov.io/v4.3.6/docs/notifications#section-slack); - Pull Request Comments; - [Disable comment](https://docs.codecov.io/v4.3.6/docs/pull-request-comments#section-disable-comment) (aka Github emails); - CodeCov YAML; - [Default Branch](https://docs.codecov.io/v4.3.6/docs/codecov-yaml#section-default-branch); - [Validate your repository yaml](https://docs.codecov.io/v4.3.6/docs/codecov-yaml#section-validate-your-repository-yaml)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2779#issuecomment-339091206
https://github.com/broadinstitute/cromwell/pull/2779#issuecomment-339091206:1052,Security,Validat,Validate,1052,"For those that come across this PR in the future, a subset of the [docs](https://docs.codecov.io/v4.3.6/docs) referred to in this PR:; - Commit Status; - Project Status; - [Target](https://docs.codecov.io/v4.3.6/docs/commit-status#section-target); - [Threshold](https://docs.codecov.io/v4.3.6/docs/commit-status#section-threshold); - [Base](https://docs.codecov.io/v4.3.6/docs/commit-status#section-base); - [Patch Status](https://docs.codecov.io/v4.3.6/docs/commit-status#section-patch-status); - Coverage Configuration; - [Range](https://docs.codecov.io/v4.3.6/docs/coverage-configuration#section-range); - [Rounding](https://docs.codecov.io/v4.3.6/docs/coverage-configuration#section-rounding); - Notifications; - [Slack](https://docs.codecov.io/v4.3.6/docs/notifications#section-slack); - Pull Request Comments; - [Disable comment](https://docs.codecov.io/v4.3.6/docs/pull-request-comments#section-disable-comment) (aka Github emails); - CodeCov YAML; - [Default Branch](https://docs.codecov.io/v4.3.6/docs/codecov-yaml#section-default-branch); - [Validate your repository yaml](https://docs.codecov.io/v4.3.6/docs/codecov-yaml#section-validate-your-repository-yaml)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2779#issuecomment-339091206
https://github.com/broadinstitute/cromwell/pull/2779#issuecomment-339091206:1140,Security,validat,validate-your-repository-yaml,1140,"For those that come across this PR in the future, a subset of the [docs](https://docs.codecov.io/v4.3.6/docs) referred to in this PR:; - Commit Status; - Project Status; - [Target](https://docs.codecov.io/v4.3.6/docs/commit-status#section-target); - [Threshold](https://docs.codecov.io/v4.3.6/docs/commit-status#section-threshold); - [Base](https://docs.codecov.io/v4.3.6/docs/commit-status#section-base); - [Patch Status](https://docs.codecov.io/v4.3.6/docs/commit-status#section-patch-status); - Coverage Configuration; - [Range](https://docs.codecov.io/v4.3.6/docs/coverage-configuration#section-range); - [Rounding](https://docs.codecov.io/v4.3.6/docs/coverage-configuration#section-rounding); - Notifications; - [Slack](https://docs.codecov.io/v4.3.6/docs/notifications#section-slack); - Pull Request Comments; - [Disable comment](https://docs.codecov.io/v4.3.6/docs/pull-request-comments#section-disable-comment) (aka Github emails); - CodeCov YAML; - [Default Branch](https://docs.codecov.io/v4.3.6/docs/codecov-yaml#section-default-branch); - [Validate your repository yaml](https://docs.codecov.io/v4.3.6/docs/codecov-yaml#section-validate-your-repository-yaml)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2779#issuecomment-339091206
https://github.com/broadinstitute/cromwell/pull/2785#issuecomment-339382680:177,Availability,error,error,177,Note: This PR breaks the cromwell-as-a-git-submodle functionality. But I've got verbal confirmation from @hjfbynara that Green is no longer using cromwell this way. This is the error that one sees with the `sbt-git` used in this PR plus a git submodule:. ```java; fatal: Invalid gitfile format: /Users/kshakir/src/cromwell/.git; [error] java.util.NoSuchElementException: head of empty stream; [error] 	at scala.collection.immutable.Stream$Empty$.head(Stream.scala:1104); [error] 	at scala.collection.immutable.Stream$Empty$.head(Stream.scala:1102); [error] 	at com.typesafe.sbt.SbtGit$.$anonfun$buildSettings$21(SbtGit.scala:138); [error] 	at sbt.internal.util.Init$Value.$anonfun$apply$3(Settings.scala:804); [error] 	at sbt.internal.util.EvaluateSettings.$anonfun$constant$1(INode.scala:197); [error] 	at sbt.internal.util.EvaluateSettings$MixedNode.evaluate0(INode.scala:214); [error] 	at sbt.internal.util.EvaluateSettings$INode.evaluate(INode.scala:159); [error] 	at sbt.internal.util.EvaluateSettings.$anonfun$submitEvaluate$1(INode.scala:82); [error] 	at sbt.internal.util.EvaluateSettings.sbt$internal$util$EvaluateSettings$$run0(INode.scala:93); [error] 	at sbt.internal.util.EvaluateSettings$$anon$3.run(INode.scala:89); [error] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); [error] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); [error] 	at java.lang.Thread.run(Thread.java:745); [error] java.util.NoSuchElementException: head of empty stream; ```. cc https://github.com/broadinstitute/cromwell/issues/644,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2785#issuecomment-339382680
https://github.com/broadinstitute/cromwell/pull/2785#issuecomment-339382680:330,Availability,error,error,330,Note: This PR breaks the cromwell-as-a-git-submodle functionality. But I've got verbal confirmation from @hjfbynara that Green is no longer using cromwell this way. This is the error that one sees with the `sbt-git` used in this PR plus a git submodule:. ```java; fatal: Invalid gitfile format: /Users/kshakir/src/cromwell/.git; [error] java.util.NoSuchElementException: head of empty stream; [error] 	at scala.collection.immutable.Stream$Empty$.head(Stream.scala:1104); [error] 	at scala.collection.immutable.Stream$Empty$.head(Stream.scala:1102); [error] 	at com.typesafe.sbt.SbtGit$.$anonfun$buildSettings$21(SbtGit.scala:138); [error] 	at sbt.internal.util.Init$Value.$anonfun$apply$3(Settings.scala:804); [error] 	at sbt.internal.util.EvaluateSettings.$anonfun$constant$1(INode.scala:197); [error] 	at sbt.internal.util.EvaluateSettings$MixedNode.evaluate0(INode.scala:214); [error] 	at sbt.internal.util.EvaluateSettings$INode.evaluate(INode.scala:159); [error] 	at sbt.internal.util.EvaluateSettings.$anonfun$submitEvaluate$1(INode.scala:82); [error] 	at sbt.internal.util.EvaluateSettings.sbt$internal$util$EvaluateSettings$$run0(INode.scala:93); [error] 	at sbt.internal.util.EvaluateSettings$$anon$3.run(INode.scala:89); [error] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); [error] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); [error] 	at java.lang.Thread.run(Thread.java:745); [error] java.util.NoSuchElementException: head of empty stream; ```. cc https://github.com/broadinstitute/cromwell/issues/644,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2785#issuecomment-339382680
https://github.com/broadinstitute/cromwell/pull/2785#issuecomment-339382680:394,Availability,error,error,394,Note: This PR breaks the cromwell-as-a-git-submodle functionality. But I've got verbal confirmation from @hjfbynara that Green is no longer using cromwell this way. This is the error that one sees with the `sbt-git` used in this PR plus a git submodule:. ```java; fatal: Invalid gitfile format: /Users/kshakir/src/cromwell/.git; [error] java.util.NoSuchElementException: head of empty stream; [error] 	at scala.collection.immutable.Stream$Empty$.head(Stream.scala:1104); [error] 	at scala.collection.immutable.Stream$Empty$.head(Stream.scala:1102); [error] 	at com.typesafe.sbt.SbtGit$.$anonfun$buildSettings$21(SbtGit.scala:138); [error] 	at sbt.internal.util.Init$Value.$anonfun$apply$3(Settings.scala:804); [error] 	at sbt.internal.util.EvaluateSettings.$anonfun$constant$1(INode.scala:197); [error] 	at sbt.internal.util.EvaluateSettings$MixedNode.evaluate0(INode.scala:214); [error] 	at sbt.internal.util.EvaluateSettings$INode.evaluate(INode.scala:159); [error] 	at sbt.internal.util.EvaluateSettings.$anonfun$submitEvaluate$1(INode.scala:82); [error] 	at sbt.internal.util.EvaluateSettings.sbt$internal$util$EvaluateSettings$$run0(INode.scala:93); [error] 	at sbt.internal.util.EvaluateSettings$$anon$3.run(INode.scala:89); [error] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); [error] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); [error] 	at java.lang.Thread.run(Thread.java:745); [error] java.util.NoSuchElementException: head of empty stream; ```. cc https://github.com/broadinstitute/cromwell/issues/644,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2785#issuecomment-339382680
https://github.com/broadinstitute/cromwell/pull/2785#issuecomment-339382680:472,Availability,error,error,472,Note: This PR breaks the cromwell-as-a-git-submodle functionality. But I've got verbal confirmation from @hjfbynara that Green is no longer using cromwell this way. This is the error that one sees with the `sbt-git` used in this PR plus a git submodule:. ```java; fatal: Invalid gitfile format: /Users/kshakir/src/cromwell/.git; [error] java.util.NoSuchElementException: head of empty stream; [error] 	at scala.collection.immutable.Stream$Empty$.head(Stream.scala:1104); [error] 	at scala.collection.immutable.Stream$Empty$.head(Stream.scala:1102); [error] 	at com.typesafe.sbt.SbtGit$.$anonfun$buildSettings$21(SbtGit.scala:138); [error] 	at sbt.internal.util.Init$Value.$anonfun$apply$3(Settings.scala:804); [error] 	at sbt.internal.util.EvaluateSettings.$anonfun$constant$1(INode.scala:197); [error] 	at sbt.internal.util.EvaluateSettings$MixedNode.evaluate0(INode.scala:214); [error] 	at sbt.internal.util.EvaluateSettings$INode.evaluate(INode.scala:159); [error] 	at sbt.internal.util.EvaluateSettings.$anonfun$submitEvaluate$1(INode.scala:82); [error] 	at sbt.internal.util.EvaluateSettings.sbt$internal$util$EvaluateSettings$$run0(INode.scala:93); [error] 	at sbt.internal.util.EvaluateSettings$$anon$3.run(INode.scala:89); [error] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); [error] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); [error] 	at java.lang.Thread.run(Thread.java:745); [error] java.util.NoSuchElementException: head of empty stream; ```. cc https://github.com/broadinstitute/cromwell/issues/644,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2785#issuecomment-339382680
https://github.com/broadinstitute/cromwell/pull/2785#issuecomment-339382680:550,Availability,error,error,550,Note: This PR breaks the cromwell-as-a-git-submodle functionality. But I've got verbal confirmation from @hjfbynara that Green is no longer using cromwell this way. This is the error that one sees with the `sbt-git` used in this PR plus a git submodule:. ```java; fatal: Invalid gitfile format: /Users/kshakir/src/cromwell/.git; [error] java.util.NoSuchElementException: head of empty stream; [error] 	at scala.collection.immutable.Stream$Empty$.head(Stream.scala:1104); [error] 	at scala.collection.immutable.Stream$Empty$.head(Stream.scala:1102); [error] 	at com.typesafe.sbt.SbtGit$.$anonfun$buildSettings$21(SbtGit.scala:138); [error] 	at sbt.internal.util.Init$Value.$anonfun$apply$3(Settings.scala:804); [error] 	at sbt.internal.util.EvaluateSettings.$anonfun$constant$1(INode.scala:197); [error] 	at sbt.internal.util.EvaluateSettings$MixedNode.evaluate0(INode.scala:214); [error] 	at sbt.internal.util.EvaluateSettings$INode.evaluate(INode.scala:159); [error] 	at sbt.internal.util.EvaluateSettings.$anonfun$submitEvaluate$1(INode.scala:82); [error] 	at sbt.internal.util.EvaluateSettings.sbt$internal$util$EvaluateSettings$$run0(INode.scala:93); [error] 	at sbt.internal.util.EvaluateSettings$$anon$3.run(INode.scala:89); [error] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); [error] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); [error] 	at java.lang.Thread.run(Thread.java:745); [error] java.util.NoSuchElementException: head of empty stream; ```. cc https://github.com/broadinstitute/cromwell/issues/644,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2785#issuecomment-339382680
https://github.com/broadinstitute/cromwell/pull/2785#issuecomment-339382680:632,Availability,error,error,632,Note: This PR breaks the cromwell-as-a-git-submodle functionality. But I've got verbal confirmation from @hjfbynara that Green is no longer using cromwell this way. This is the error that one sees with the `sbt-git` used in this PR plus a git submodule:. ```java; fatal: Invalid gitfile format: /Users/kshakir/src/cromwell/.git; [error] java.util.NoSuchElementException: head of empty stream; [error] 	at scala.collection.immutable.Stream$Empty$.head(Stream.scala:1104); [error] 	at scala.collection.immutable.Stream$Empty$.head(Stream.scala:1102); [error] 	at com.typesafe.sbt.SbtGit$.$anonfun$buildSettings$21(SbtGit.scala:138); [error] 	at sbt.internal.util.Init$Value.$anonfun$apply$3(Settings.scala:804); [error] 	at sbt.internal.util.EvaluateSettings.$anonfun$constant$1(INode.scala:197); [error] 	at sbt.internal.util.EvaluateSettings$MixedNode.evaluate0(INode.scala:214); [error] 	at sbt.internal.util.EvaluateSettings$INode.evaluate(INode.scala:159); [error] 	at sbt.internal.util.EvaluateSettings.$anonfun$submitEvaluate$1(INode.scala:82); [error] 	at sbt.internal.util.EvaluateSettings.sbt$internal$util$EvaluateSettings$$run0(INode.scala:93); [error] 	at sbt.internal.util.EvaluateSettings$$anon$3.run(INode.scala:89); [error] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); [error] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); [error] 	at java.lang.Thread.run(Thread.java:745); [error] java.util.NoSuchElementException: head of empty stream; ```. cc https://github.com/broadinstitute/cromwell/issues/644,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2785#issuecomment-339382680
https://github.com/broadinstitute/cromwell/pull/2785#issuecomment-339382680:711,Availability,error,error,711,Note: This PR breaks the cromwell-as-a-git-submodle functionality. But I've got verbal confirmation from @hjfbynara that Green is no longer using cromwell this way. This is the error that one sees with the `sbt-git` used in this PR plus a git submodule:. ```java; fatal: Invalid gitfile format: /Users/kshakir/src/cromwell/.git; [error] java.util.NoSuchElementException: head of empty stream; [error] 	at scala.collection.immutable.Stream$Empty$.head(Stream.scala:1104); [error] 	at scala.collection.immutable.Stream$Empty$.head(Stream.scala:1102); [error] 	at com.typesafe.sbt.SbtGit$.$anonfun$buildSettings$21(SbtGit.scala:138); [error] 	at sbt.internal.util.Init$Value.$anonfun$apply$3(Settings.scala:804); [error] 	at sbt.internal.util.EvaluateSettings.$anonfun$constant$1(INode.scala:197); [error] 	at sbt.internal.util.EvaluateSettings$MixedNode.evaluate0(INode.scala:214); [error] 	at sbt.internal.util.EvaluateSettings$INode.evaluate(INode.scala:159); [error] 	at sbt.internal.util.EvaluateSettings.$anonfun$submitEvaluate$1(INode.scala:82); [error] 	at sbt.internal.util.EvaluateSettings.sbt$internal$util$EvaluateSettings$$run0(INode.scala:93); [error] 	at sbt.internal.util.EvaluateSettings$$anon$3.run(INode.scala:89); [error] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); [error] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); [error] 	at java.lang.Thread.run(Thread.java:745); [error] java.util.NoSuchElementException: head of empty stream; ```. cc https://github.com/broadinstitute/cromwell/issues/644,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2785#issuecomment-339382680
https://github.com/broadinstitute/cromwell/pull/2785#issuecomment-339382680:796,Availability,error,error,796,Note: This PR breaks the cromwell-as-a-git-submodle functionality. But I've got verbal confirmation from @hjfbynara that Green is no longer using cromwell this way. This is the error that one sees with the `sbt-git` used in this PR plus a git submodule:. ```java; fatal: Invalid gitfile format: /Users/kshakir/src/cromwell/.git; [error] java.util.NoSuchElementException: head of empty stream; [error] 	at scala.collection.immutable.Stream$Empty$.head(Stream.scala:1104); [error] 	at scala.collection.immutable.Stream$Empty$.head(Stream.scala:1102); [error] 	at com.typesafe.sbt.SbtGit$.$anonfun$buildSettings$21(SbtGit.scala:138); [error] 	at sbt.internal.util.Init$Value.$anonfun$apply$3(Settings.scala:804); [error] 	at sbt.internal.util.EvaluateSettings.$anonfun$constant$1(INode.scala:197); [error] 	at sbt.internal.util.EvaluateSettings$MixedNode.evaluate0(INode.scala:214); [error] 	at sbt.internal.util.EvaluateSettings$INode.evaluate(INode.scala:159); [error] 	at sbt.internal.util.EvaluateSettings.$anonfun$submitEvaluate$1(INode.scala:82); [error] 	at sbt.internal.util.EvaluateSettings.sbt$internal$util$EvaluateSettings$$run0(INode.scala:93); [error] 	at sbt.internal.util.EvaluateSettings$$anon$3.run(INode.scala:89); [error] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); [error] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); [error] 	at java.lang.Thread.run(Thread.java:745); [error] java.util.NoSuchElementException: head of empty stream; ```. cc https://github.com/broadinstitute/cromwell/issues/644,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2785#issuecomment-339382680
https://github.com/broadinstitute/cromwell/pull/2785#issuecomment-339382680:881,Availability,error,error,881,Note: This PR breaks the cromwell-as-a-git-submodle functionality. But I've got verbal confirmation from @hjfbynara that Green is no longer using cromwell this way. This is the error that one sees with the `sbt-git` used in this PR plus a git submodule:. ```java; fatal: Invalid gitfile format: /Users/kshakir/src/cromwell/.git; [error] java.util.NoSuchElementException: head of empty stream; [error] 	at scala.collection.immutable.Stream$Empty$.head(Stream.scala:1104); [error] 	at scala.collection.immutable.Stream$Empty$.head(Stream.scala:1102); [error] 	at com.typesafe.sbt.SbtGit$.$anonfun$buildSettings$21(SbtGit.scala:138); [error] 	at sbt.internal.util.Init$Value.$anonfun$apply$3(Settings.scala:804); [error] 	at sbt.internal.util.EvaluateSettings.$anonfun$constant$1(INode.scala:197); [error] 	at sbt.internal.util.EvaluateSettings$MixedNode.evaluate0(INode.scala:214); [error] 	at sbt.internal.util.EvaluateSettings$INode.evaluate(INode.scala:159); [error] 	at sbt.internal.util.EvaluateSettings.$anonfun$submitEvaluate$1(INode.scala:82); [error] 	at sbt.internal.util.EvaluateSettings.sbt$internal$util$EvaluateSettings$$run0(INode.scala:93); [error] 	at sbt.internal.util.EvaluateSettings$$anon$3.run(INode.scala:89); [error] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); [error] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); [error] 	at java.lang.Thread.run(Thread.java:745); [error] java.util.NoSuchElementException: head of empty stream; ```. cc https://github.com/broadinstitute/cromwell/issues/644,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2785#issuecomment-339382680
https://github.com/broadinstitute/cromwell/pull/2785#issuecomment-339382680:961,Availability,error,error,961,Note: This PR breaks the cromwell-as-a-git-submodle functionality. But I've got verbal confirmation from @hjfbynara that Green is no longer using cromwell this way. This is the error that one sees with the `sbt-git` used in this PR plus a git submodule:. ```java; fatal: Invalid gitfile format: /Users/kshakir/src/cromwell/.git; [error] java.util.NoSuchElementException: head of empty stream; [error] 	at scala.collection.immutable.Stream$Empty$.head(Stream.scala:1104); [error] 	at scala.collection.immutable.Stream$Empty$.head(Stream.scala:1102); [error] 	at com.typesafe.sbt.SbtGit$.$anonfun$buildSettings$21(SbtGit.scala:138); [error] 	at sbt.internal.util.Init$Value.$anonfun$apply$3(Settings.scala:804); [error] 	at sbt.internal.util.EvaluateSettings.$anonfun$constant$1(INode.scala:197); [error] 	at sbt.internal.util.EvaluateSettings$MixedNode.evaluate0(INode.scala:214); [error] 	at sbt.internal.util.EvaluateSettings$INode.evaluate(INode.scala:159); [error] 	at sbt.internal.util.EvaluateSettings.$anonfun$submitEvaluate$1(INode.scala:82); [error] 	at sbt.internal.util.EvaluateSettings.sbt$internal$util$EvaluateSettings$$run0(INode.scala:93); [error] 	at sbt.internal.util.EvaluateSettings$$anon$3.run(INode.scala:89); [error] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); [error] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); [error] 	at java.lang.Thread.run(Thread.java:745); [error] java.util.NoSuchElementException: head of empty stream; ```. cc https://github.com/broadinstitute/cromwell/issues/644,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2785#issuecomment-339382680
https://github.com/broadinstitute/cromwell/pull/2785#issuecomment-339382680:1051,Availability,error,error,1051,Note: This PR breaks the cromwell-as-a-git-submodle functionality. But I've got verbal confirmation from @hjfbynara that Green is no longer using cromwell this way. This is the error that one sees with the `sbt-git` used in this PR plus a git submodule:. ```java; fatal: Invalid gitfile format: /Users/kshakir/src/cromwell/.git; [error] java.util.NoSuchElementException: head of empty stream; [error] 	at scala.collection.immutable.Stream$Empty$.head(Stream.scala:1104); [error] 	at scala.collection.immutable.Stream$Empty$.head(Stream.scala:1102); [error] 	at com.typesafe.sbt.SbtGit$.$anonfun$buildSettings$21(SbtGit.scala:138); [error] 	at sbt.internal.util.Init$Value.$anonfun$apply$3(Settings.scala:804); [error] 	at sbt.internal.util.EvaluateSettings.$anonfun$constant$1(INode.scala:197); [error] 	at sbt.internal.util.EvaluateSettings$MixedNode.evaluate0(INode.scala:214); [error] 	at sbt.internal.util.EvaluateSettings$INode.evaluate(INode.scala:159); [error] 	at sbt.internal.util.EvaluateSettings.$anonfun$submitEvaluate$1(INode.scala:82); [error] 	at sbt.internal.util.EvaluateSettings.sbt$internal$util$EvaluateSettings$$run0(INode.scala:93); [error] 	at sbt.internal.util.EvaluateSettings$$anon$3.run(INode.scala:89); [error] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); [error] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); [error] 	at java.lang.Thread.run(Thread.java:745); [error] java.util.NoSuchElementException: head of empty stream; ```. cc https://github.com/broadinstitute/cromwell/issues/644,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2785#issuecomment-339382680
https://github.com/broadinstitute/cromwell/pull/2785#issuecomment-339382680:1156,Availability,error,error,1156,Note: This PR breaks the cromwell-as-a-git-submodle functionality. But I've got verbal confirmation from @hjfbynara that Green is no longer using cromwell this way. This is the error that one sees with the `sbt-git` used in this PR plus a git submodule:. ```java; fatal: Invalid gitfile format: /Users/kshakir/src/cromwell/.git; [error] java.util.NoSuchElementException: head of empty stream; [error] 	at scala.collection.immutable.Stream$Empty$.head(Stream.scala:1104); [error] 	at scala.collection.immutable.Stream$Empty$.head(Stream.scala:1102); [error] 	at com.typesafe.sbt.SbtGit$.$anonfun$buildSettings$21(SbtGit.scala:138); [error] 	at sbt.internal.util.Init$Value.$anonfun$apply$3(Settings.scala:804); [error] 	at sbt.internal.util.EvaluateSettings.$anonfun$constant$1(INode.scala:197); [error] 	at sbt.internal.util.EvaluateSettings$MixedNode.evaluate0(INode.scala:214); [error] 	at sbt.internal.util.EvaluateSettings$INode.evaluate(INode.scala:159); [error] 	at sbt.internal.util.EvaluateSettings.$anonfun$submitEvaluate$1(INode.scala:82); [error] 	at sbt.internal.util.EvaluateSettings.sbt$internal$util$EvaluateSettings$$run0(INode.scala:93); [error] 	at sbt.internal.util.EvaluateSettings$$anon$3.run(INode.scala:89); [error] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); [error] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); [error] 	at java.lang.Thread.run(Thread.java:745); [error] java.util.NoSuchElementException: head of empty stream; ```. cc https://github.com/broadinstitute/cromwell/issues/644,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2785#issuecomment-339382680
https://github.com/broadinstitute/cromwell/pull/2785#issuecomment-339382680:1232,Availability,error,error,1232,Note: This PR breaks the cromwell-as-a-git-submodle functionality. But I've got verbal confirmation from @hjfbynara that Green is no longer using cromwell this way. This is the error that one sees with the `sbt-git` used in this PR plus a git submodule:. ```java; fatal: Invalid gitfile format: /Users/kshakir/src/cromwell/.git; [error] java.util.NoSuchElementException: head of empty stream; [error] 	at scala.collection.immutable.Stream$Empty$.head(Stream.scala:1104); [error] 	at scala.collection.immutable.Stream$Empty$.head(Stream.scala:1102); [error] 	at com.typesafe.sbt.SbtGit$.$anonfun$buildSettings$21(SbtGit.scala:138); [error] 	at sbt.internal.util.Init$Value.$anonfun$apply$3(Settings.scala:804); [error] 	at sbt.internal.util.EvaluateSettings.$anonfun$constant$1(INode.scala:197); [error] 	at sbt.internal.util.EvaluateSettings$MixedNode.evaluate0(INode.scala:214); [error] 	at sbt.internal.util.EvaluateSettings$INode.evaluate(INode.scala:159); [error] 	at sbt.internal.util.EvaluateSettings.$anonfun$submitEvaluate$1(INode.scala:82); [error] 	at sbt.internal.util.EvaluateSettings.sbt$internal$util$EvaluateSettings$$run0(INode.scala:93); [error] 	at sbt.internal.util.EvaluateSettings$$anon$3.run(INode.scala:89); [error] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); [error] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); [error] 	at java.lang.Thread.run(Thread.java:745); [error] java.util.NoSuchElementException: head of empty stream; ```. cc https://github.com/broadinstitute/cromwell/issues/644,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2785#issuecomment-339382680
https://github.com/broadinstitute/cromwell/pull/2785#issuecomment-339382680:1325,Availability,error,error,1325,Note: This PR breaks the cromwell-as-a-git-submodle functionality. But I've got verbal confirmation from @hjfbynara that Green is no longer using cromwell this way. This is the error that one sees with the `sbt-git` used in this PR plus a git submodule:. ```java; fatal: Invalid gitfile format: /Users/kshakir/src/cromwell/.git; [error] java.util.NoSuchElementException: head of empty stream; [error] 	at scala.collection.immutable.Stream$Empty$.head(Stream.scala:1104); [error] 	at scala.collection.immutable.Stream$Empty$.head(Stream.scala:1102); [error] 	at com.typesafe.sbt.SbtGit$.$anonfun$buildSettings$21(SbtGit.scala:138); [error] 	at sbt.internal.util.Init$Value.$anonfun$apply$3(Settings.scala:804); [error] 	at sbt.internal.util.EvaluateSettings.$anonfun$constant$1(INode.scala:197); [error] 	at sbt.internal.util.EvaluateSettings$MixedNode.evaluate0(INode.scala:214); [error] 	at sbt.internal.util.EvaluateSettings$INode.evaluate(INode.scala:159); [error] 	at sbt.internal.util.EvaluateSettings.$anonfun$submitEvaluate$1(INode.scala:82); [error] 	at sbt.internal.util.EvaluateSettings.sbt$internal$util$EvaluateSettings$$run0(INode.scala:93); [error] 	at sbt.internal.util.EvaluateSettings$$anon$3.run(INode.scala:89); [error] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); [error] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); [error] 	at java.lang.Thread.run(Thread.java:745); [error] java.util.NoSuchElementException: head of empty stream; ```. cc https://github.com/broadinstitute/cromwell/issues/644,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2785#issuecomment-339382680
https://github.com/broadinstitute/cromwell/pull/2785#issuecomment-339382680:1418,Availability,error,error,1418,Note: This PR breaks the cromwell-as-a-git-submodle functionality. But I've got verbal confirmation from @hjfbynara that Green is no longer using cromwell this way. This is the error that one sees with the `sbt-git` used in this PR plus a git submodule:. ```java; fatal: Invalid gitfile format: /Users/kshakir/src/cromwell/.git; [error] java.util.NoSuchElementException: head of empty stream; [error] 	at scala.collection.immutable.Stream$Empty$.head(Stream.scala:1104); [error] 	at scala.collection.immutable.Stream$Empty$.head(Stream.scala:1102); [error] 	at com.typesafe.sbt.SbtGit$.$anonfun$buildSettings$21(SbtGit.scala:138); [error] 	at sbt.internal.util.Init$Value.$anonfun$apply$3(Settings.scala:804); [error] 	at sbt.internal.util.EvaluateSettings.$anonfun$constant$1(INode.scala:197); [error] 	at sbt.internal.util.EvaluateSettings$MixedNode.evaluate0(INode.scala:214); [error] 	at sbt.internal.util.EvaluateSettings$INode.evaluate(INode.scala:159); [error] 	at sbt.internal.util.EvaluateSettings.$anonfun$submitEvaluate$1(INode.scala:82); [error] 	at sbt.internal.util.EvaluateSettings.sbt$internal$util$EvaluateSettings$$run0(INode.scala:93); [error] 	at sbt.internal.util.EvaluateSettings$$anon$3.run(INode.scala:89); [error] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); [error] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); [error] 	at java.lang.Thread.run(Thread.java:745); [error] java.util.NoSuchElementException: head of empty stream; ```. cc https://github.com/broadinstitute/cromwell/issues/644,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2785#issuecomment-339382680
https://github.com/broadinstitute/cromwell/pull/2785#issuecomment-339382680:1469,Availability,error,error,1469,Note: This PR breaks the cromwell-as-a-git-submodle functionality. But I've got verbal confirmation from @hjfbynara that Green is no longer using cromwell this way. This is the error that one sees with the `sbt-git` used in this PR plus a git submodule:. ```java; fatal: Invalid gitfile format: /Users/kshakir/src/cromwell/.git; [error] java.util.NoSuchElementException: head of empty stream; [error] 	at scala.collection.immutable.Stream$Empty$.head(Stream.scala:1104); [error] 	at scala.collection.immutable.Stream$Empty$.head(Stream.scala:1102); [error] 	at com.typesafe.sbt.SbtGit$.$anonfun$buildSettings$21(SbtGit.scala:138); [error] 	at sbt.internal.util.Init$Value.$anonfun$apply$3(Settings.scala:804); [error] 	at sbt.internal.util.EvaluateSettings.$anonfun$constant$1(INode.scala:197); [error] 	at sbt.internal.util.EvaluateSettings$MixedNode.evaluate0(INode.scala:214); [error] 	at sbt.internal.util.EvaluateSettings$INode.evaluate(INode.scala:159); [error] 	at sbt.internal.util.EvaluateSettings.$anonfun$submitEvaluate$1(INode.scala:82); [error] 	at sbt.internal.util.EvaluateSettings.sbt$internal$util$EvaluateSettings$$run0(INode.scala:93); [error] 	at sbt.internal.util.EvaluateSettings$$anon$3.run(INode.scala:89); [error] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); [error] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); [error] 	at java.lang.Thread.run(Thread.java:745); [error] java.util.NoSuchElementException: head of empty stream; ```. cc https://github.com/broadinstitute/cromwell/issues/644,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2785#issuecomment-339382680
https://github.com/broadinstitute/cromwell/pull/2785#issuecomment-339382680:121,Energy Efficiency,Green,Green,121,Note: This PR breaks the cromwell-as-a-git-submodle functionality. But I've got verbal confirmation from @hjfbynara that Green is no longer using cromwell this way. This is the error that one sees with the `sbt-git` used in this PR plus a git submodule:. ```java; fatal: Invalid gitfile format: /Users/kshakir/src/cromwell/.git; [error] java.util.NoSuchElementException: head of empty stream; [error] 	at scala.collection.immutable.Stream$Empty$.head(Stream.scala:1104); [error] 	at scala.collection.immutable.Stream$Empty$.head(Stream.scala:1102); [error] 	at com.typesafe.sbt.SbtGit$.$anonfun$buildSettings$21(SbtGit.scala:138); [error] 	at sbt.internal.util.Init$Value.$anonfun$apply$3(Settings.scala:804); [error] 	at sbt.internal.util.EvaluateSettings.$anonfun$constant$1(INode.scala:197); [error] 	at sbt.internal.util.EvaluateSettings$MixedNode.evaluate0(INode.scala:214); [error] 	at sbt.internal.util.EvaluateSettings$INode.evaluate(INode.scala:159); [error] 	at sbt.internal.util.EvaluateSettings.$anonfun$submitEvaluate$1(INode.scala:82); [error] 	at sbt.internal.util.EvaluateSettings.sbt$internal$util$EvaluateSettings$$run0(INode.scala:93); [error] 	at sbt.internal.util.EvaluateSettings$$anon$3.run(INode.scala:89); [error] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); [error] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); [error] 	at java.lang.Thread.run(Thread.java:745); [error] java.util.NoSuchElementException: head of empty stream; ```. cc https://github.com/broadinstitute/cromwell/issues/644,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2785#issuecomment-339382680
https://github.com/broadinstitute/cromwell/pull/2785#issuecomment-339382680:1253,Performance,concurren,concurrent,1253,Note: This PR breaks the cromwell-as-a-git-submodle functionality. But I've got verbal confirmation from @hjfbynara that Green is no longer using cromwell this way. This is the error that one sees with the `sbt-git` used in this PR plus a git submodule:. ```java; fatal: Invalid gitfile format: /Users/kshakir/src/cromwell/.git; [error] java.util.NoSuchElementException: head of empty stream; [error] 	at scala.collection.immutable.Stream$Empty$.head(Stream.scala:1104); [error] 	at scala.collection.immutable.Stream$Empty$.head(Stream.scala:1102); [error] 	at com.typesafe.sbt.SbtGit$.$anonfun$buildSettings$21(SbtGit.scala:138); [error] 	at sbt.internal.util.Init$Value.$anonfun$apply$3(Settings.scala:804); [error] 	at sbt.internal.util.EvaluateSettings.$anonfun$constant$1(INode.scala:197); [error] 	at sbt.internal.util.EvaluateSettings$MixedNode.evaluate0(INode.scala:214); [error] 	at sbt.internal.util.EvaluateSettings$INode.evaluate(INode.scala:159); [error] 	at sbt.internal.util.EvaluateSettings.$anonfun$submitEvaluate$1(INode.scala:82); [error] 	at sbt.internal.util.EvaluateSettings.sbt$internal$util$EvaluateSettings$$run0(INode.scala:93); [error] 	at sbt.internal.util.EvaluateSettings$$anon$3.run(INode.scala:89); [error] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); [error] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); [error] 	at java.lang.Thread.run(Thread.java:745); [error] java.util.NoSuchElementException: head of empty stream; ```. cc https://github.com/broadinstitute/cromwell/issues/644,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2785#issuecomment-339382680
https://github.com/broadinstitute/cromwell/pull/2785#issuecomment-339382680:1346,Performance,concurren,concurrent,1346,Note: This PR breaks the cromwell-as-a-git-submodle functionality. But I've got verbal confirmation from @hjfbynara that Green is no longer using cromwell this way. This is the error that one sees with the `sbt-git` used in this PR plus a git submodule:. ```java; fatal: Invalid gitfile format: /Users/kshakir/src/cromwell/.git; [error] java.util.NoSuchElementException: head of empty stream; [error] 	at scala.collection.immutable.Stream$Empty$.head(Stream.scala:1104); [error] 	at scala.collection.immutable.Stream$Empty$.head(Stream.scala:1102); [error] 	at com.typesafe.sbt.SbtGit$.$anonfun$buildSettings$21(SbtGit.scala:138); [error] 	at sbt.internal.util.Init$Value.$anonfun$apply$3(Settings.scala:804); [error] 	at sbt.internal.util.EvaluateSettings.$anonfun$constant$1(INode.scala:197); [error] 	at sbt.internal.util.EvaluateSettings$MixedNode.evaluate0(INode.scala:214); [error] 	at sbt.internal.util.EvaluateSettings$INode.evaluate(INode.scala:159); [error] 	at sbt.internal.util.EvaluateSettings.$anonfun$submitEvaluate$1(INode.scala:82); [error] 	at sbt.internal.util.EvaluateSettings.sbt$internal$util$EvaluateSettings$$run0(INode.scala:93); [error] 	at sbt.internal.util.EvaluateSettings$$anon$3.run(INode.scala:89); [error] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); [error] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); [error] 	at java.lang.Thread.run(Thread.java:745); [error] java.util.NoSuchElementException: head of empty stream; ```. cc https://github.com/broadinstitute/cromwell/issues/644,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2785#issuecomment-339382680
https://github.com/broadinstitute/cromwell/issues/2788#issuecomment-339510928:54,Testability,test,testSbt,54,I thought this was going to be a lack of `set -e` in `testSbt.sh` but that doesn't appear to be the case. ü§î,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2788#issuecomment-339510928
https://github.com/broadinstitute/cromwell/issues/2788#issuecomment-339511828:0,Security,Access,AccessDenied,0,AccessDenied for the raw log. I can't see anything attempting to compile CWL in the cooked log. `src/bin/travis/test.sh` is shown as running for 0.01 seconds. üòï,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2788#issuecomment-339511828
https://github.com/broadinstitute/cromwell/issues/2788#issuecomment-339511828:25,Testability,log,log,25,AccessDenied for the raw log. I can't see anything attempting to compile CWL in the cooked log. `src/bin/travis/test.sh` is shown as running for 0.01 seconds. üòï,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2788#issuecomment-339511828
https://github.com/broadinstitute/cromwell/issues/2788#issuecomment-339511828:91,Testability,log,log,91,AccessDenied for the raw log. I can't see anything attempting to compile CWL in the cooked log. `src/bin/travis/test.sh` is shown as running for 0.01 seconds. üòï,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2788#issuecomment-339511828
https://github.com/broadinstitute/cromwell/issues/2788#issuecomment-339511828:112,Testability,test,test,112,AccessDenied for the raw log. I can't see anything attempting to compile CWL in the cooked log. `src/bin/travis/test.sh` is shown as running for 0.01 seconds. üòï,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2788#issuecomment-339511828
https://github.com/broadinstitute/cromwell/issues/2791#issuecomment-342953538:158,Availability,error,error-the-local-copy-message-must-have-path-set,158,"Apologies, that metadata appears to have disappeared, but the same issue is referenced here: https://gatkforums.broadinstitute.org/firecloud/discussion/10740/error-the-local-copy-message-must-have-path-set/p1?new=1",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2791#issuecomment-342953538
https://github.com/broadinstitute/cromwell/issues/2791#issuecomment-342953538:179,Integrability,message,message-must-have-path-set,179,"Apologies, that metadata appears to have disappeared, but the same issue is referenced here: https://gatkforums.broadinstitute.org/firecloud/discussion/10740/error-the-local-copy-message-must-have-path-set/p1?new=1",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2791#issuecomment-342953538
https://github.com/broadinstitute/cromwell/issues/2791#issuecomment-342955580:1791,Availability,echo,echo,1791,And only exec.sh is present in the bucket (no log etc)....; ```#!/bin/bash; tmpDir=$(mktemp -d /cromwell_root/tmp.XXXXXX); chmod 777 $tmpDir; export _JAVA_OPTIONS=-Djava.io.tmpdir=$tmpDir; export TMPDIR=$tmpDir. (; cd /cromwell_root; java -Xmx4g -jar /cromwell_root/broad-dsde-methods/lichtens/test_cnv_validation/gatk.jar ModelSegments \; --denoisedCopyRatios /cromwell_root/broad-dsde-methods/lichtens/cromwell-executions-test-dl-oxoq-full/CNVValidation/6246d2fa-a8e5-49c0-ac38-8ae33867f394/call-cnvPair/CNVSomaticPairWorkflow/c8a063ce-0309-45a1-a6cf-25fdcfe4245c/call-DenoiseReadCountsNormal/G25783.TCGA-55-6986-11A-01D-1945-08.2.denoisedCR.tsv \; --allelicCounts /cromwell_root/broad-dsde-methods/lichtens/cromwell-executions-test-dl-oxoq-full/CNVValidation/6246d2fa-a8e5-49c0-ac38-8ae33867f394/call-cnvPair/CNVSomaticPairWorkflow/c8a063ce-0309-45a1-a6cf-25fdcfe4245c/call-CollectAllelicCountsNormal/attempt-3/G25783.TCGA-55-6986-11A-01D-1945-08.2.allelicCounts.tsv \; \; --maxNumSegmentsPerChromosome 500 \; --minTotalAlleleCount 30 \; --genotypingHomozygousLogRatioThreshold -10.0 \; --genotypingBaseErrorRate 0.05 \; --kernelVarianceCopyRatio 0.0 \; --kernelVarianceAlleleFraction 0.01 \; --kernelScalingAlleleFraction 1.0 \; --kernelApproximationDimension 100 \; --windowSize 8 --windowSize 16 --windowSize 32 --windowSize 64 --windowSize 128 --windowSize 256 \; --numChangepointsPenaltyFactor 1.0 \; --minorAlleleFractionPriorAlpha 25.0 \; --numSamplesCopyRatio 100 \; --numBurnInCopyRatio 50 \; --numSamplesAlleleFraction 100 \; --numBurnInAlleleFraction 50 \; --smoothingThresholdCopyRatio 2.0 \; --smoothingThresholdAlleleFraction 2.0 \; --maxNumSmoothingIterations 10 \; --numSmoothingIterationsPerFit 0 \; --output . \; --outputPrefix G25783.TCGA-55-6986-11A-01D-1945-08.2; ); echo $? > /cromwell_root/ModelSegmentsNormal-rc.txt.tmp; (; cd /cromwell_root. ); sync; mv /cromwell_root/ModelSegmentsNormal-rc.txt.tmp /cromwell_root/ModelSegmentsNormal-rc.txt```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2791#issuecomment-342955580
https://github.com/broadinstitute/cromwell/issues/2791#issuecomment-342955580:46,Testability,log,log,46,And only exec.sh is present in the bucket (no log etc)....; ```#!/bin/bash; tmpDir=$(mktemp -d /cromwell_root/tmp.XXXXXX); chmod 777 $tmpDir; export _JAVA_OPTIONS=-Djava.io.tmpdir=$tmpDir; export TMPDIR=$tmpDir. (; cd /cromwell_root; java -Xmx4g -jar /cromwell_root/broad-dsde-methods/lichtens/test_cnv_validation/gatk.jar ModelSegments \; --denoisedCopyRatios /cromwell_root/broad-dsde-methods/lichtens/cromwell-executions-test-dl-oxoq-full/CNVValidation/6246d2fa-a8e5-49c0-ac38-8ae33867f394/call-cnvPair/CNVSomaticPairWorkflow/c8a063ce-0309-45a1-a6cf-25fdcfe4245c/call-DenoiseReadCountsNormal/G25783.TCGA-55-6986-11A-01D-1945-08.2.denoisedCR.tsv \; --allelicCounts /cromwell_root/broad-dsde-methods/lichtens/cromwell-executions-test-dl-oxoq-full/CNVValidation/6246d2fa-a8e5-49c0-ac38-8ae33867f394/call-cnvPair/CNVSomaticPairWorkflow/c8a063ce-0309-45a1-a6cf-25fdcfe4245c/call-CollectAllelicCountsNormal/attempt-3/G25783.TCGA-55-6986-11A-01D-1945-08.2.allelicCounts.tsv \; \; --maxNumSegmentsPerChromosome 500 \; --minTotalAlleleCount 30 \; --genotypingHomozygousLogRatioThreshold -10.0 \; --genotypingBaseErrorRate 0.05 \; --kernelVarianceCopyRatio 0.0 \; --kernelVarianceAlleleFraction 0.01 \; --kernelScalingAlleleFraction 1.0 \; --kernelApproximationDimension 100 \; --windowSize 8 --windowSize 16 --windowSize 32 --windowSize 64 --windowSize 128 --windowSize 256 \; --numChangepointsPenaltyFactor 1.0 \; --minorAlleleFractionPriorAlpha 25.0 \; --numSamplesCopyRatio 100 \; --numBurnInCopyRatio 50 \; --numSamplesAlleleFraction 100 \; --numBurnInAlleleFraction 50 \; --smoothingThresholdCopyRatio 2.0 \; --smoothingThresholdAlleleFraction 2.0 \; --maxNumSmoothingIterations 10 \; --numSmoothingIterationsPerFit 0 \; --output . \; --outputPrefix G25783.TCGA-55-6986-11A-01D-1945-08.2; ); echo $? > /cromwell_root/ModelSegmentsNormal-rc.txt.tmp; (; cd /cromwell_root. ); sync; mv /cromwell_root/ModelSegmentsNormal-rc.txt.tmp /cromwell_root/ModelSegmentsNormal-rc.txt```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2791#issuecomment-342955580
https://github.com/broadinstitute/cromwell/issues/2791#issuecomment-342955580:424,Testability,test,test-dl-oxoq-full,424,And only exec.sh is present in the bucket (no log etc)....; ```#!/bin/bash; tmpDir=$(mktemp -d /cromwell_root/tmp.XXXXXX); chmod 777 $tmpDir; export _JAVA_OPTIONS=-Djava.io.tmpdir=$tmpDir; export TMPDIR=$tmpDir. (; cd /cromwell_root; java -Xmx4g -jar /cromwell_root/broad-dsde-methods/lichtens/test_cnv_validation/gatk.jar ModelSegments \; --denoisedCopyRatios /cromwell_root/broad-dsde-methods/lichtens/cromwell-executions-test-dl-oxoq-full/CNVValidation/6246d2fa-a8e5-49c0-ac38-8ae33867f394/call-cnvPair/CNVSomaticPairWorkflow/c8a063ce-0309-45a1-a6cf-25fdcfe4245c/call-DenoiseReadCountsNormal/G25783.TCGA-55-6986-11A-01D-1945-08.2.denoisedCR.tsv \; --allelicCounts /cromwell_root/broad-dsde-methods/lichtens/cromwell-executions-test-dl-oxoq-full/CNVValidation/6246d2fa-a8e5-49c0-ac38-8ae33867f394/call-cnvPair/CNVSomaticPairWorkflow/c8a063ce-0309-45a1-a6cf-25fdcfe4245c/call-CollectAllelicCountsNormal/attempt-3/G25783.TCGA-55-6986-11A-01D-1945-08.2.allelicCounts.tsv \; \; --maxNumSegmentsPerChromosome 500 \; --minTotalAlleleCount 30 \; --genotypingHomozygousLogRatioThreshold -10.0 \; --genotypingBaseErrorRate 0.05 \; --kernelVarianceCopyRatio 0.0 \; --kernelVarianceAlleleFraction 0.01 \; --kernelScalingAlleleFraction 1.0 \; --kernelApproximationDimension 100 \; --windowSize 8 --windowSize 16 --windowSize 32 --windowSize 64 --windowSize 128 --windowSize 256 \; --numChangepointsPenaltyFactor 1.0 \; --minorAlleleFractionPriorAlpha 25.0 \; --numSamplesCopyRatio 100 \; --numBurnInCopyRatio 50 \; --numSamplesAlleleFraction 100 \; --numBurnInAlleleFraction 50 \; --smoothingThresholdCopyRatio 2.0 \; --smoothingThresholdAlleleFraction 2.0 \; --maxNumSmoothingIterations 10 \; --numSmoothingIterationsPerFit 0 \; --output . \; --outputPrefix G25783.TCGA-55-6986-11A-01D-1945-08.2; ); echo $? > /cromwell_root/ModelSegmentsNormal-rc.txt.tmp; (; cd /cromwell_root. ); sync; mv /cromwell_root/ModelSegmentsNormal-rc.txt.tmp /cromwell_root/ModelSegmentsNormal-rc.txt```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2791#issuecomment-342955580
https://github.com/broadinstitute/cromwell/issues/2791#issuecomment-342955580:730,Testability,test,test-dl-oxoq-full,730,And only exec.sh is present in the bucket (no log etc)....; ```#!/bin/bash; tmpDir=$(mktemp -d /cromwell_root/tmp.XXXXXX); chmod 777 $tmpDir; export _JAVA_OPTIONS=-Djava.io.tmpdir=$tmpDir; export TMPDIR=$tmpDir. (; cd /cromwell_root; java -Xmx4g -jar /cromwell_root/broad-dsde-methods/lichtens/test_cnv_validation/gatk.jar ModelSegments \; --denoisedCopyRatios /cromwell_root/broad-dsde-methods/lichtens/cromwell-executions-test-dl-oxoq-full/CNVValidation/6246d2fa-a8e5-49c0-ac38-8ae33867f394/call-cnvPair/CNVSomaticPairWorkflow/c8a063ce-0309-45a1-a6cf-25fdcfe4245c/call-DenoiseReadCountsNormal/G25783.TCGA-55-6986-11A-01D-1945-08.2.denoisedCR.tsv \; --allelicCounts /cromwell_root/broad-dsde-methods/lichtens/cromwell-executions-test-dl-oxoq-full/CNVValidation/6246d2fa-a8e5-49c0-ac38-8ae33867f394/call-cnvPair/CNVSomaticPairWorkflow/c8a063ce-0309-45a1-a6cf-25fdcfe4245c/call-CollectAllelicCountsNormal/attempt-3/G25783.TCGA-55-6986-11A-01D-1945-08.2.allelicCounts.tsv \; \; --maxNumSegmentsPerChromosome 500 \; --minTotalAlleleCount 30 \; --genotypingHomozygousLogRatioThreshold -10.0 \; --genotypingBaseErrorRate 0.05 \; --kernelVarianceCopyRatio 0.0 \; --kernelVarianceAlleleFraction 0.01 \; --kernelScalingAlleleFraction 1.0 \; --kernelApproximationDimension 100 \; --windowSize 8 --windowSize 16 --windowSize 32 --windowSize 64 --windowSize 128 --windowSize 256 \; --numChangepointsPenaltyFactor 1.0 \; --minorAlleleFractionPriorAlpha 25.0 \; --numSamplesCopyRatio 100 \; --numBurnInCopyRatio 50 \; --numSamplesAlleleFraction 100 \; --numBurnInAlleleFraction 50 \; --smoothingThresholdCopyRatio 2.0 \; --smoothingThresholdAlleleFraction 2.0 \; --maxNumSmoothingIterations 10 \; --numSmoothingIterationsPerFit 0 \; --output . \; --outputPrefix G25783.TCGA-55-6986-11A-01D-1945-08.2; ); echo $? > /cromwell_root/ModelSegmentsNormal-rc.txt.tmp; (; cd /cromwell_root. ); sync; mv /cromwell_root/ModelSegmentsNormal-rc.txt.tmp /cromwell_root/ModelSegmentsNormal-rc.txt```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2791#issuecomment-342955580
https://github.com/broadinstitute/cromwell/issues/2791#issuecomment-343304266:195,Integrability,message,message,195,"True. This workflow works fine with local backends and FC without normal_allelic_counts. I guess cromwell read null as a file based on line 141 in file ""ModelSegments.java "". Then, it return the message ""the local copy message must have path set."". Not sure... ModelSegments.java ; 141 private File inputNormalAllelicCountsFile = null;",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2791#issuecomment-343304266
https://github.com/broadinstitute/cromwell/issues/2791#issuecomment-343304266:219,Integrability,message,message,219,"True. This workflow works fine with local backends and FC without normal_allelic_counts. I guess cromwell read null as a file based on line 141 in file ""ModelSegments.java "". Then, it return the message ""the local copy message must have path set."". Not sure... ModelSegments.java ; 141 private File inputNormalAllelicCountsFile = null;",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2791#issuecomment-343304266
https://github.com/broadinstitute/cromwell/issues/2791#issuecomment-506470150:92,Deployability,update,updates,92,@cy-bao is this still the case on the latest version of Cromwell in FireCloud? . All future updates to this issue will be made in JIRA: ; https://broadworkbench.atlassian.net/browse/BA-2791; Sorry for the inconvenience.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2791#issuecomment-506470150
https://github.com/broadinstitute/cromwell/issues/2797#issuecomment-340481018:85,Security,validat,validate,85,We talked about this with Ruchi and I guess we could be very forgiving in the way we validate those docker strings. If it ends up being an invalid docker image the job won't run anyway when we get to that point so..,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2797#issuecomment-340481018
https://github.com/broadinstitute/cromwell/issues/2797#issuecomment-360599386:315,Testability,test,tests,315,"Hey, I've encountered this issue when tried to use local registry. [This exception](https://github.com/broadinstitute/cromwell/blob/1b1a56372659b9cb7a168bb1fa2a2296103e1256/dockerHashing/src/main/scala/cromwell/docker/DockerImageIdentifier.scala#L60) is raised when trying to use image named ""localhost:5000/alpine-tests:0.0.2"" which IMHO is a correct image name.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2797#issuecomment-360599386
https://github.com/broadinstitute/cromwell/pull/2803#issuecomment-341213876:30,Usability,simpl,simple,30,This PR will return when less simple `if`s are added too,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2803#issuecomment-341213876
https://github.com/broadinstitute/cromwell/pull/2807#issuecomment-341493941:10,Availability,failure,failures,10,"The build failures are in unrelated Swagger tests, rebasing on develop should get this green.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2807#issuecomment-341493941
https://github.com/broadinstitute/cromwell/pull/2807#issuecomment-341493941:87,Energy Efficiency,green,green,87,"The build failures are in unrelated Swagger tests, rebasing on develop should get this green.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2807#issuecomment-341493941
https://github.com/broadinstitute/cromwell/pull/2807#issuecomment-341493941:44,Testability,test,tests,44,"The build failures are in unrelated Swagger tests, rebasing on develop should get this green.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2807#issuecomment-341493941
https://github.com/broadinstitute/cromwell/pull/2807#issuecomment-341513736:109,Security,authoriz,authorized,109,"Thank @mcovarr and @cjllanwarne, I believe I am done. Please let me know if there is anything else. I am not authorized to merge this PR, so I am leaving this up to your team.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2807#issuecomment-341513736
https://github.com/broadinstitute/cromwell/pull/2807#issuecomment-342278838:69,Availability,failure,failure,69,"@orodeh in case you're not able to read the Travis output, the build failure is currently being caused by:; ```; [0m[[0minfo[0m] [0m[31m*** 1 TEST FAILED ***[0m[0m; [0m[[0minfo[0m] [0m[31mWdlSubworkflowWomSpec:[0m[0m; [0m[[0minfo[0m] [0m[31mWdlNamespaces with subworkflows [0m[0m; [0m[[0minfo[0m] [0m[31m- should support WDL to WOM conversion of subworkflow calls *** FAILED *** (51 milliseconds)[0m[0m; [0m[[0minfo[0m] [0m[31m wdl4s.parser.WdlParser$SyntaxError: ERROR: out is declared as a Array[String] but the expression evaluates to a String:[0m[0m; [0m[[0minfo[0m] [0m[31m[0m[0m; [0m[[0minfo[0m] [0m[31m Array[String] out = inner.out[0m[0m; [0m[[0minfo[0m] [0m[31m ^[0m[0m; [0m[[0minfo[0m] [0m[31m at wdl.WdlNamespace$.$anonfun$typeCheckDeclaration$1(WdlNamespace.scala:493)[0m[0m; [0m[[0minfo[0m] [0m[31m at scala.Option.flatMap(Option.scala:171)[0m[0m; [0m[[0minfo[0m] [0m[31m at wdl.WdlNamespace$.typeCheckDeclaration(WdlNamespace.scala:488)[0m[0m; [0m[[0minfo[0m] [0m[31m at wdl.WdlNamespace$.validateDeclaration(WdlNamespace.scala:466)[0m[0m; [0m[[0minfo[0m] [0m[31m at wdl.WdlNamespace$.$anonfun$apply$35(WdlNamespace.scala:381)[0m[0m; [0m[[0minfo[0m] [0m[31m at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:241)[0m[0m; [0m[[0minfo[0m] [0m[31m at scala.collection.Iterator.foreach(Iterator.scala:929)[0m[0m; [0m[[0minfo[0m] [0m[31m at scala.collection.Iterator.foreach$(Iterator.scala:929)[0m[0m; [0m[[0minfo[0m] [0m[31m at scala.collection.AbstractIterator.foreach(Iterator.scala:1417)[0m[0m; [0m[[0minfo[0m] [0m[31m at scala.collection.IterableLike.foreach(IterableLike.scala:71)[0m[0m; ```. I'm not sure whether you intended to roll back that change at the same time as rolling back the test case? I think we can argue to make the set of coercions explicit in draft 3 (and not include `X => Array[X]`), but IMO we shouldn't ""unsupp",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2807#issuecomment-342278838
https://github.com/broadinstitute/cromwell/pull/2807#issuecomment-342278838:497,Availability,ERROR,ERROR,497,"@orodeh in case you're not able to read the Travis output, the build failure is currently being caused by:; ```; [0m[[0minfo[0m] [0m[31m*** 1 TEST FAILED ***[0m[0m; [0m[[0minfo[0m] [0m[31mWdlSubworkflowWomSpec:[0m[0m; [0m[[0minfo[0m] [0m[31mWdlNamespaces with subworkflows [0m[0m; [0m[[0minfo[0m] [0m[31m- should support WDL to WOM conversion of subworkflow calls *** FAILED *** (51 milliseconds)[0m[0m; [0m[[0minfo[0m] [0m[31m wdl4s.parser.WdlParser$SyntaxError: ERROR: out is declared as a Array[String] but the expression evaluates to a String:[0m[0m; [0m[[0minfo[0m] [0m[31m[0m[0m; [0m[[0minfo[0m] [0m[31m Array[String] out = inner.out[0m[0m; [0m[[0minfo[0m] [0m[31m ^[0m[0m; [0m[[0minfo[0m] [0m[31m at wdl.WdlNamespace$.$anonfun$typeCheckDeclaration$1(WdlNamespace.scala:493)[0m[0m; [0m[[0minfo[0m] [0m[31m at scala.Option.flatMap(Option.scala:171)[0m[0m; [0m[[0minfo[0m] [0m[31m at wdl.WdlNamespace$.typeCheckDeclaration(WdlNamespace.scala:488)[0m[0m; [0m[[0minfo[0m] [0m[31m at wdl.WdlNamespace$.validateDeclaration(WdlNamespace.scala:466)[0m[0m; [0m[[0minfo[0m] [0m[31m at wdl.WdlNamespace$.$anonfun$apply$35(WdlNamespace.scala:381)[0m[0m; [0m[[0minfo[0m] [0m[31m at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:241)[0m[0m; [0m[[0minfo[0m] [0m[31m at scala.collection.Iterator.foreach(Iterator.scala:929)[0m[0m; [0m[[0minfo[0m] [0m[31m at scala.collection.Iterator.foreach$(Iterator.scala:929)[0m[0m; [0m[[0minfo[0m] [0m[31m at scala.collection.AbstractIterator.foreach(Iterator.scala:1417)[0m[0m; [0m[[0minfo[0m] [0m[31m at scala.collection.IterableLike.foreach(IterableLike.scala:71)[0m[0m; ```. I'm not sure whether you intended to roll back that change at the same time as rolling back the test case? I think we can argue to make the set of coercions explicit in draft 3 (and not include `X => Array[X]`), but IMO we shouldn't ""unsupp",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2807#issuecomment-342278838
https://github.com/broadinstitute/cromwell/pull/2807#issuecomment-342278838:1840,Deployability,rolling,rolling,1840,"he Travis output, the build failure is currently being caused by:; ```; [0m[[0minfo[0m] [0m[31m*** 1 TEST FAILED ***[0m[0m; [0m[[0minfo[0m] [0m[31mWdlSubworkflowWomSpec:[0m[0m; [0m[[0minfo[0m] [0m[31mWdlNamespaces with subworkflows [0m[0m; [0m[[0minfo[0m] [0m[31m- should support WDL to WOM conversion of subworkflow calls *** FAILED *** (51 milliseconds)[0m[0m; [0m[[0minfo[0m] [0m[31m wdl4s.parser.WdlParser$SyntaxError: ERROR: out is declared as a Array[String] but the expression evaluates to a String:[0m[0m; [0m[[0minfo[0m] [0m[31m[0m[0m; [0m[[0minfo[0m] [0m[31m Array[String] out = inner.out[0m[0m; [0m[[0minfo[0m] [0m[31m ^[0m[0m; [0m[[0minfo[0m] [0m[31m at wdl.WdlNamespace$.$anonfun$typeCheckDeclaration$1(WdlNamespace.scala:493)[0m[0m; [0m[[0minfo[0m] [0m[31m at scala.Option.flatMap(Option.scala:171)[0m[0m; [0m[[0minfo[0m] [0m[31m at wdl.WdlNamespace$.typeCheckDeclaration(WdlNamespace.scala:488)[0m[0m; [0m[[0minfo[0m] [0m[31m at wdl.WdlNamespace$.validateDeclaration(WdlNamespace.scala:466)[0m[0m; [0m[[0minfo[0m] [0m[31m at wdl.WdlNamespace$.$anonfun$apply$35(WdlNamespace.scala:381)[0m[0m; [0m[[0minfo[0m] [0m[31m at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:241)[0m[0m; [0m[[0minfo[0m] [0m[31m at scala.collection.Iterator.foreach(Iterator.scala:929)[0m[0m; [0m[[0minfo[0m] [0m[31m at scala.collection.Iterator.foreach$(Iterator.scala:929)[0m[0m; [0m[[0minfo[0m] [0m[31m at scala.collection.AbstractIterator.foreach(Iterator.scala:1417)[0m[0m; [0m[[0minfo[0m] [0m[31m at scala.collection.IterableLike.foreach(IterableLike.scala:71)[0m[0m; ```. I'm not sure whether you intended to roll back that change at the same time as rolling back the test case? I think we can argue to make the set of coercions explicit in draft 3 (and not include `X => Array[X]`), but IMO we shouldn't ""unsupport"" that Cromwell feature with this PR.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2807#issuecomment-342278838
https://github.com/broadinstitute/cromwell/pull/2807#issuecomment-342278838:1085,Security,validat,validateDeclaration,1085,"he Travis output, the build failure is currently being caused by:; ```; [0m[[0minfo[0m] [0m[31m*** 1 TEST FAILED ***[0m[0m; [0m[[0minfo[0m] [0m[31mWdlSubworkflowWomSpec:[0m[0m; [0m[[0minfo[0m] [0m[31mWdlNamespaces with subworkflows [0m[0m; [0m[[0minfo[0m] [0m[31m- should support WDL to WOM conversion of subworkflow calls *** FAILED *** (51 milliseconds)[0m[0m; [0m[[0minfo[0m] [0m[31m wdl4s.parser.WdlParser$SyntaxError: ERROR: out is declared as a Array[String] but the expression evaluates to a String:[0m[0m; [0m[[0minfo[0m] [0m[31m[0m[0m; [0m[[0minfo[0m] [0m[31m Array[String] out = inner.out[0m[0m; [0m[[0minfo[0m] [0m[31m ^[0m[0m; [0m[[0minfo[0m] [0m[31m at wdl.WdlNamespace$.$anonfun$typeCheckDeclaration$1(WdlNamespace.scala:493)[0m[0m; [0m[[0minfo[0m] [0m[31m at scala.Option.flatMap(Option.scala:171)[0m[0m; [0m[[0minfo[0m] [0m[31m at wdl.WdlNamespace$.typeCheckDeclaration(WdlNamespace.scala:488)[0m[0m; [0m[[0minfo[0m] [0m[31m at wdl.WdlNamespace$.validateDeclaration(WdlNamespace.scala:466)[0m[0m; [0m[[0minfo[0m] [0m[31m at wdl.WdlNamespace$.$anonfun$apply$35(WdlNamespace.scala:381)[0m[0m; [0m[[0minfo[0m] [0m[31m at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:241)[0m[0m; [0m[[0minfo[0m] [0m[31m at scala.collection.Iterator.foreach(Iterator.scala:929)[0m[0m; [0m[[0minfo[0m] [0m[31m at scala.collection.Iterator.foreach$(Iterator.scala:929)[0m[0m; [0m[[0minfo[0m] [0m[31m at scala.collection.AbstractIterator.foreach(Iterator.scala:1417)[0m[0m; [0m[[0minfo[0m] [0m[31m at scala.collection.IterableLike.foreach(IterableLike.scala:71)[0m[0m; ```. I'm not sure whether you intended to roll back that change at the same time as rolling back the test case? I think we can argue to make the set of coercions explicit in draft 3 (and not include `X => Array[X]`), but IMO we shouldn't ""unsupport"" that Cromwell feature with this PR.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2807#issuecomment-342278838
https://github.com/broadinstitute/cromwell/pull/2807#issuecomment-342278838:147,Testability,TEST,TEST,147,"@orodeh in case you're not able to read the Travis output, the build failure is currently being caused by:; ```; [0m[[0minfo[0m] [0m[31m*** 1 TEST FAILED ***[0m[0m; [0m[[0minfo[0m] [0m[31mWdlSubworkflowWomSpec:[0m[0m; [0m[[0minfo[0m] [0m[31mWdlNamespaces with subworkflows [0m[0m; [0m[[0minfo[0m] [0m[31m- should support WDL to WOM conversion of subworkflow calls *** FAILED *** (51 milliseconds)[0m[0m; [0m[[0minfo[0m] [0m[31m wdl4s.parser.WdlParser$SyntaxError: ERROR: out is declared as a Array[String] but the expression evaluates to a String:[0m[0m; [0m[[0minfo[0m] [0m[31m[0m[0m; [0m[[0minfo[0m] [0m[31m Array[String] out = inner.out[0m[0m; [0m[[0minfo[0m] [0m[31m ^[0m[0m; [0m[[0minfo[0m] [0m[31m at wdl.WdlNamespace$.$anonfun$typeCheckDeclaration$1(WdlNamespace.scala:493)[0m[0m; [0m[[0minfo[0m] [0m[31m at scala.Option.flatMap(Option.scala:171)[0m[0m; [0m[[0minfo[0m] [0m[31m at wdl.WdlNamespace$.typeCheckDeclaration(WdlNamespace.scala:488)[0m[0m; [0m[[0minfo[0m] [0m[31m at wdl.WdlNamespace$.validateDeclaration(WdlNamespace.scala:466)[0m[0m; [0m[[0minfo[0m] [0m[31m at wdl.WdlNamespace$.$anonfun$apply$35(WdlNamespace.scala:381)[0m[0m; [0m[[0minfo[0m] [0m[31m at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:241)[0m[0m; [0m[[0minfo[0m] [0m[31m at scala.collection.Iterator.foreach(Iterator.scala:929)[0m[0m; [0m[[0minfo[0m] [0m[31m at scala.collection.Iterator.foreach$(Iterator.scala:929)[0m[0m; [0m[[0minfo[0m] [0m[31m at scala.collection.AbstractIterator.foreach(Iterator.scala:1417)[0m[0m; [0m[[0minfo[0m] [0m[31m at scala.collection.IterableLike.foreach(IterableLike.scala:71)[0m[0m; ```. I'm not sure whether you intended to roll back that change at the same time as rolling back the test case? I think we can argue to make the set of coercions explicit in draft 3 (and not include `X => Array[X]`), but IMO we shouldn't ""unsupp",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2807#issuecomment-342278838
https://github.com/broadinstitute/cromwell/pull/2807#issuecomment-342278838:1857,Testability,test,test,1857,"he Travis output, the build failure is currently being caused by:; ```; [0m[[0minfo[0m] [0m[31m*** 1 TEST FAILED ***[0m[0m; [0m[[0minfo[0m] [0m[31mWdlSubworkflowWomSpec:[0m[0m; [0m[[0minfo[0m] [0m[31mWdlNamespaces with subworkflows [0m[0m; [0m[[0minfo[0m] [0m[31m- should support WDL to WOM conversion of subworkflow calls *** FAILED *** (51 milliseconds)[0m[0m; [0m[[0minfo[0m] [0m[31m wdl4s.parser.WdlParser$SyntaxError: ERROR: out is declared as a Array[String] but the expression evaluates to a String:[0m[0m; [0m[[0minfo[0m] [0m[31m[0m[0m; [0m[[0minfo[0m] [0m[31m Array[String] out = inner.out[0m[0m; [0m[[0minfo[0m] [0m[31m ^[0m[0m; [0m[[0minfo[0m] [0m[31m at wdl.WdlNamespace$.$anonfun$typeCheckDeclaration$1(WdlNamespace.scala:493)[0m[0m; [0m[[0minfo[0m] [0m[31m at scala.Option.flatMap(Option.scala:171)[0m[0m; [0m[[0minfo[0m] [0m[31m at wdl.WdlNamespace$.typeCheckDeclaration(WdlNamespace.scala:488)[0m[0m; [0m[[0minfo[0m] [0m[31m at wdl.WdlNamespace$.validateDeclaration(WdlNamespace.scala:466)[0m[0m; [0m[[0minfo[0m] [0m[31m at wdl.WdlNamespace$.$anonfun$apply$35(WdlNamespace.scala:381)[0m[0m; [0m[[0minfo[0m] [0m[31m at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:241)[0m[0m; [0m[[0minfo[0m] [0m[31m at scala.collection.Iterator.foreach(Iterator.scala:929)[0m[0m; [0m[[0minfo[0m] [0m[31m at scala.collection.Iterator.foreach$(Iterator.scala:929)[0m[0m; [0m[[0minfo[0m] [0m[31m at scala.collection.AbstractIterator.foreach(Iterator.scala:1417)[0m[0m; [0m[[0minfo[0m] [0m[31m at scala.collection.IterableLike.foreach(IterableLike.scala:71)[0m[0m; ```. I'm not sure whether you intended to roll back that change at the same time as rolling back the test case? I think we can argue to make the set of coercions explicit in draft 3 (and not include `X => Array[X]`), but IMO we shouldn't ""unsupport"" that Cromwell feature with this PR.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2807#issuecomment-342278838
https://github.com/broadinstitute/cromwell/pull/2807#issuecomment-342542308:337,Testability,test,test,337,"@orodeh @geoffjentry this is probably a case where the WDL spec has failed to keep up with developments in Cromwell. What's awkward in this case is I think Cromwell could be argued to be overreaching and adding things that **should not** be in the WDL spec!. I'd be fine to remove this as a ""bug fix"", but you'll still need to ""fix"" the test case before I can merge it.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2807#issuecomment-342542308
https://github.com/broadinstitute/cromwell/issues/2813#issuecomment-342201627:67,Testability,test,tester,67,FYI- Saw some infinite retries while wiring in the cwl conformance tester. One minor modification to `isFatal` made in [PR #2821](https://github.com/broadinstitute/cromwell/pull/2821/files) to keep the tester from running forever.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2813#issuecomment-342201627
https://github.com/broadinstitute/cromwell/issues/2813#issuecomment-342201627:202,Testability,test,tester,202,FYI- Saw some infinite retries while wiring in the cwl conformance tester. One minor modification to `isFatal` made in [PR #2821](https://github.com/broadinstitute/cromwell/pull/2821/files) to keep the tester from running forever.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2813#issuecomment-342201627
https://github.com/broadinstitute/cromwell/issues/2820#issuecomment-341607290:69,Safety,abort,aborts,69,"@Horneth Does this mean we should hold off before claiming we ""fixed aborts""? :)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2820#issuecomment-341607290
https://github.com/broadinstitute/cromwell/issues/2824#issuecomment-342845454:197,Security,Access,Access-Control-Allow-Origin,197,- I don't think Cromwell had any opinions on where it gets called from (it's all stateless REST queries over HTTP) - could you give an example of what you're trying to do? ; - I've only ever seen `Access-Control-Allow-Origin` in reference to web browser behavior ; - Maybe you have something in front of Cromwell that's blocking you?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2824#issuecomment-342845454
https://github.com/broadinstitute/cromwell/issues/2824#issuecomment-342872932:87,Security,Access,Access-Control-Allow-Origin,87,"The document that contains the cross-site AJAX calls would need to be; served with the Access-Control-Allow-Origin * HTTP header. Does Cromwell; ever serve documents that contain AJAX calls?. On Wed, Nov 8, 2017 at 10:06 AM, Chris Llanwarne <notifications@github.com>; wrote:. >; > - I don't think Cromwell had any opinions on where it gets called from; > (it's all stateless REST queries over HTTP) - could you give an example of; > what you're trying to do?; > - I've only ever seen Access-Control-Allow-Origin in reference to web; > browser behavior; > - Maybe you have something in front of Cromwell that's blocking you?; >; > ‚Äî; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/2824#issuecomment-342845454>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AG_4aDbsUjYVfFiIoOCTyoVz92Oc3UUvks5s0cOFgaJpZM4QRuA->; > .; >. -- ; Oliver Ruebenacker; Senior Software Engineer, Diabetes Portal; <http://www.type2diabetesgenetics.org/>, Broad Institute; <http://www.broadinstitute.org/>",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2824#issuecomment-342872932
https://github.com/broadinstitute/cromwell/issues/2824#issuecomment-342872932:485,Security,Access,Access-Control-Allow-Origin,485,"The document that contains the cross-site AJAX calls would need to be; served with the Access-Control-Allow-Origin * HTTP header. Does Cromwell; ever serve documents that contain AJAX calls?. On Wed, Nov 8, 2017 at 10:06 AM, Chris Llanwarne <notifications@github.com>; wrote:. >; > - I don't think Cromwell had any opinions on where it gets called from; > (it's all stateless REST queries over HTTP) - could you give an example of; > what you're trying to do?; > - I've only ever seen Access-Control-Allow-Origin in reference to web; > browser behavior; > - Maybe you have something in front of Cromwell that's blocking you?; >; > ‚Äî; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/2824#issuecomment-342845454>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AG_4aDbsUjYVfFiIoOCTyoVz92Oc3UUvks5s0cOFgaJpZM4QRuA->; > .; >. -- ; Oliver Ruebenacker; Senior Software Engineer, Diabetes Portal; <http://www.type2diabetesgenetics.org/>, Broad Institute; <http://www.broadinstitute.org/>",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2824#issuecomment-342872932
https://github.com/broadinstitute/cromwell/issues/2824#issuecomment-344307228:382,Deployability,configurat,configurations,382,"@cjllanwarne , @curoli ; I am writing a UI to deal with cromwell. There I just make Ajax calls to cromwell from ScalaJS without bothering about redirecting everything to the server. I had to configure nginx to provide allow-origin, however,it will be way better if there will be allow-origin option in cromwell config, so people will be able to use my UI without messing with nginx configurations.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2824#issuecomment-344307228
https://github.com/broadinstitute/cromwell/issues/2824#issuecomment-344307228:191,Modifiability,config,configure,191,"@cjllanwarne , @curoli ; I am writing a UI to deal with cromwell. There I just make Ajax calls to cromwell from ScalaJS without bothering about redirecting everything to the server. I had to configure nginx to provide allow-origin, however,it will be way better if there will be allow-origin option in cromwell config, so people will be able to use my UI without messing with nginx configurations.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2824#issuecomment-344307228
https://github.com/broadinstitute/cromwell/issues/2824#issuecomment-344307228:311,Modifiability,config,config,311,"@cjllanwarne , @curoli ; I am writing a UI to deal with cromwell. There I just make Ajax calls to cromwell from ScalaJS without bothering about redirecting everything to the server. I had to configure nginx to provide allow-origin, however,it will be way better if there will be allow-origin option in cromwell config, so people will be able to use my UI without messing with nginx configurations.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2824#issuecomment-344307228
https://github.com/broadinstitute/cromwell/issues/2824#issuecomment-344307228:382,Modifiability,config,configurations,382,"@cjllanwarne , @curoli ; I am writing a UI to deal with cromwell. There I just make Ajax calls to cromwell from ScalaJS without bothering about redirecting everything to the server. I had to configure nginx to provide allow-origin, however,it will be way better if there will be allow-origin option in cromwell config, so people will be able to use my UI without messing with nginx configurations.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2824#issuecomment-344307228
https://github.com/broadinstitute/cromwell/issues/2824#issuecomment-392741040:4,Deployability,update,updates,4,Any updates on this?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2824#issuecomment-392741040
https://github.com/broadinstitute/cromwell/pull/2829#issuecomment-342570056:247,Safety,Abort,Aborting,247,"@mcovarr On top of addressing your comments I added a small migration as I realized it's technically possible for some workflows to be in `RestartableRunning` or `RestartableAborting` when Cromwell starts, which are now replaced by `Running` and `Aborting` with the restarted flag to `true`. If you don't mind re-taking a look at the liquibase :)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2829#issuecomment-342570056
https://github.com/broadinstitute/cromwell/pull/2829#issuecomment-342651363:125,Safety,abort,aborts,125,"@cjllanwarne example scenario:. - Workflow starts; - a few jobs start; - cromwell is restarted; - immediately after, someone aborts this workflow. the workflow can be anywhere from still in the workflow store (waiting to be picked up and restarted) to executing. If it's anywhere but executing (could be materialization, workflow initialization...), the behavior right now is ""we're not executing this workflow yet, which means we haven't started any jobs, so it's fine to just mark it aborted and stop"". This doesn't work because this workflow does have running jobs that will 1) never be aborted 2) stay ""running"" forever in the metadata",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2829#issuecomment-342651363
https://github.com/broadinstitute/cromwell/pull/2829#issuecomment-342651363:486,Safety,abort,aborted,486,"@cjllanwarne example scenario:. - Workflow starts; - a few jobs start; - cromwell is restarted; - immediately after, someone aborts this workflow. the workflow can be anywhere from still in the workflow store (waiting to be picked up and restarted) to executing. If it's anywhere but executing (could be materialization, workflow initialization...), the behavior right now is ""we're not executing this workflow yet, which means we haven't started any jobs, so it's fine to just mark it aborted and stop"". This doesn't work because this workflow does have running jobs that will 1) never be aborted 2) stay ""running"" forever in the metadata",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2829#issuecomment-342651363
https://github.com/broadinstitute/cromwell/pull/2829#issuecomment-342651363:590,Safety,abort,aborted,590,"@cjllanwarne example scenario:. - Workflow starts; - a few jobs start; - cromwell is restarted; - immediately after, someone aborts this workflow. the workflow can be anywhere from still in the workflow store (waiting to be picked up and restarted) to executing. If it's anywhere but executing (could be materialization, workflow initialization...), the behavior right now is ""we're not executing this workflow yet, which means we haven't started any jobs, so it's fine to just mark it aborted and stop"". This doesn't work because this workflow does have running jobs that will 1) never be aborted 2) stay ""running"" forever in the metadata",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2829#issuecomment-342651363
https://github.com/broadinstitute/cromwell/pull/2832#issuecomment-342612911:49,Deployability,update,update,49,Heads up that updating the cromwell.yaml doesn't update the docs. We can mostly autogenerate docs but @katevoss did some hand editing.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2832#issuecomment-342612911
https://github.com/broadinstitute/cromwell/pull/2832#issuecomment-342872053:40,Availability,error,error,40,üëç modulo the ultimate resolution of the error thing. [![Approved with PullApprove](https://img.shields.io/badge/reviewers-approved-brightgreen.svg)](https://pullapprove.com/broadinstitute/cromwell/pull-request/2832/?utm_source=github-pr&utm_medium=comment-badge&utm_campaign=broadinstitute/cromwell),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2832#issuecomment-342872053
https://github.com/broadinstitute/cromwell/pull/2832#issuecomment-343156709:11,Deployability,update,updated,11,"@kshakir I updated the swagger description of the input files in the submit endpoint to say ""JSON or YAML"". It doesn't get automatically updated in the docs but @geoffjentry said we'll figure that out when @katevoss is back.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2832#issuecomment-343156709
https://github.com/broadinstitute/cromwell/pull/2832#issuecomment-343156709:137,Deployability,update,updated,137,"@kshakir I updated the swagger description of the input files in the submit endpoint to say ""JSON or YAML"". It doesn't get automatically updated in the docs but @geoffjentry said we'll figure that out when @katevoss is back.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2832#issuecomment-343156709
https://github.com/broadinstitute/cromwell/pull/2834#issuecomment-342886123:40,Availability,down,down,40,... but it's still broken. Closing this down,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2834#issuecomment-342886123
https://github.com/broadinstitute/cromwell/pull/2843#issuecomment-344407187:34,Testability,test,test,34,@danbills there's another centaur test `workflow_type_and_version_cwl` - is that related to- or maybe an older version of - this one?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2843#issuecomment-344407187
https://github.com/broadinstitute/cromwell/pull/2843#issuecomment-345267188:55,Testability,test,test,55,@cjllanwarne I see the `workflow_type_and_version_cwl` test but so far as I can tell it is testing that such parameters are accepted by cromwell. . It is curious that it passes though because it is actually passing in a WDL file! We should likely disallow this.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2843#issuecomment-345267188
https://github.com/broadinstitute/cromwell/pull/2843#issuecomment-345267188:91,Testability,test,testing,91,@cjllanwarne I see the `workflow_type_and_version_cwl` test but so far as I can tell it is testing that such parameters are accepted by cromwell. . It is curious that it passes though because it is actually passing in a WDL file! We should likely disallow this.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2843#issuecomment-345267188
https://github.com/broadinstitute/cromwell/pull/2843#issuecomment-345749322:103,Testability,test,test,103,"I merged this as it fixes a regression in the code. However, there is an issue w/ centaur in running a test on _only_ centaurLocal. I tried:; * `backends: [Local] which runs on both TES and JES and fails on those.; * `backends: [Local] and `tags: [localdockertest]` which runs on both TES and JES and fails on those.; * `backends: [Local]`, `tags: [localdockertest]` and `backendsMode: ""only""` which ignores the test in all environments. I merged in this final state as it at least does not fail the build overall.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2843#issuecomment-345749322
https://github.com/broadinstitute/cromwell/pull/2843#issuecomment-345749322:412,Testability,test,test,412,"I merged this as it fixes a regression in the code. However, there is an issue w/ centaur in running a test on _only_ centaurLocal. I tried:; * `backends: [Local] which runs on both TES and JES and fails on those.; * `backends: [Local] and `tags: [localdockertest]` which runs on both TES and JES and fails on those.; * `backends: [Local]`, `tags: [localdockertest]` and `backendsMode: ""only""` which ignores the test in all environments. I merged in this final state as it at least does not fail the build overall.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2843#issuecomment-345749322
https://github.com/broadinstitute/cromwell/issues/2844#issuecomment-343271052:40,Availability,error,error,40,And (for obvious reasons) this does not error out on SGE and local backends.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2844#issuecomment-343271052
https://github.com/broadinstitute/cromwell/issues/2844#issuecomment-492821751:91,Testability,test,test,91,"Appears fixed in https://github.com/broadinstitute/cromwell/pull/2512 and has a regression test, closing.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2844#issuecomment-492821751
https://github.com/broadinstitute/cromwell/issues/2845#issuecomment-343273348:20,Safety,abort,abort,20,And I can't seem to abort the workflow.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2845#issuecomment-343273348
https://github.com/broadinstitute/cromwell/issues/2845#issuecomment-344392351:128,Availability,reliab,reliable,128,"Regarding aborts, @Horneth made significant changes to aborts in Cromwell 30 (coming soon!) that should make it easier and more reliable to abort jobs.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2845#issuecomment-344392351
https://github.com/broadinstitute/cromwell/issues/2845#issuecomment-344392351:10,Safety,abort,aborts,10,"Regarding aborts, @Horneth made significant changes to aborts in Cromwell 30 (coming soon!) that should make it easier and more reliable to abort jobs.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2845#issuecomment-344392351
https://github.com/broadinstitute/cromwell/issues/2845#issuecomment-344392351:55,Safety,abort,aborts,55,"Regarding aborts, @Horneth made significant changes to aborts in Cromwell 30 (coming soon!) that should make it easier and more reliable to abort jobs.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2845#issuecomment-344392351
https://github.com/broadinstitute/cromwell/issues/2845#issuecomment-344392351:140,Safety,abort,abort,140,"Regarding aborts, @Horneth made significant changes to aborts in Cromwell 30 (coming soon!) that should make it easier and more reliable to abort jobs.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2845#issuecomment-344392351
https://github.com/broadinstitute/cromwell/issues/2845#issuecomment-344393380:33,Safety,abort,abort,33,"@katevoss Sounds good. Recently, abort has generally worked for me. Just not in this case.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2845#issuecomment-344393380
https://github.com/broadinstitute/cromwell/issues/2845#issuecomment-490179854:18,Testability,test,test,18,AC: Add a centaur test for this.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2845#issuecomment-490179854
https://github.com/broadinstitute/cromwell/issues/2845#issuecomment-492821443:35,Testability,test,test,35,"Based on the presence of a centaur test named `dot_dir_stuck_running` associated with a [PR that fixed this issue](https://github.com/broadinstitute/cromwell/pull/2512), closing.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2845#issuecomment-492821443
https://github.com/broadinstitute/cromwell/pull/2848#issuecomment-343969150:87,Deployability,hotfix,hotfix,87,"I don't think this needs reviews, instead direct comments to the centaur PR for the 29 hotfix",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2848#issuecomment-343969150
https://github.com/broadinstitute/cromwell/issues/2870#issuecomment-344348677:121,Usability,clear,clearly,121,"Having been recently bitten by this, I agree with Eddie's suggestion to document the (somewhat surprising) behavior more clearly rather than making assumptions about how the command block will treat octothorpes and the content that trails them.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2870#issuecomment-344348677
https://github.com/broadinstitute/cromwell/issues/2870#issuecomment-344351988:47,Modifiability,plugin,plugin,47,"For what it's worth, I'm going to plug the WDL plugin for intellij as the way forwards here. If you put this file in you get this:; <img width=""501"" alt=""screen shot 2017-11-14 at 1 23 45 pm"" src=""https://user-images.githubusercontent.com/13006282/32797253-2615f550-c93f-11e7-9bda-deb830959ef5.png"">. I think highlights the points given in the explanation above that:; - The `#` is being interpreted as part of the WDL command; - The `}` is now closing the command block; - The lines below that are now not being parsed properly. And in addition, it does all this as you type!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2870#issuecomment-344351988
https://github.com/broadinstitute/cromwell/issues/2871#issuecomment-348291490:58,Availability,error,error,58,"After #2952, `missing_input_failure` has a somewhat nicer error: `""Evaluating read_string(wf_hello_input) failed: gs://nonexistingbucket/path/doesnt/exist""`. So, I've ticked that box. Just `missing_optional_output` still to go!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2871#issuecomment-348291490
https://github.com/broadinstitute/cromwell/issues/2872#issuecomment-344358518:44,Deployability,release,release,44,"We have a dazzling new ""monorepo"" setup and release process which builds and publishes a version of womtool matched to the currently released version of Cromwell. Though we may have some more work to do here since:. * womtool won't actually report [its version](https://github.com/broadinstitute/cromwell/issues/2868); * We publish jfrog ""executable"" artifacts for cromwell, womtool, and centaur-cwl-runner, but only the cromwell artifact is published to Github.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2872#issuecomment-344358518
https://github.com/broadinstitute/cromwell/issues/2872#issuecomment-344358518:133,Deployability,release,released,133,"We have a dazzling new ""monorepo"" setup and release process which builds and publishes a version of womtool matched to the currently released version of Cromwell. Though we may have some more work to do here since:. * womtool won't actually report [its version](https://github.com/broadinstitute/cromwell/issues/2868); * We publish jfrog ""executable"" artifacts for cromwell, womtool, and centaur-cwl-runner, but only the cromwell artifact is published to Github.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2872#issuecomment-344358518
https://github.com/broadinstitute/cromwell/issues/2872#issuecomment-388163007:20,Deployability,release,released,20,"Closing this, we've released at least once since Nov '17",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2872#issuecomment-388163007
https://github.com/broadinstitute/cromwell/issues/2873#issuecomment-344359170:91,Testability,test,test,91,Sync problems are a thing of the past in the monorepo world so it should be easy enough to test Jeff's hypothesis.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2873#issuecomment-344359170
https://github.com/broadinstitute/cromwell/issues/2873#issuecomment-439426356:180,Integrability,message,messages,180,"A current version of Womtool still validates these tasks as OK, so the problem continues to exist in draft-2. Upgrading the tasks to WDL 1.0 causes Womtool validation to fail with messages of varying helpfulness:. ```; version 1.0. task myTask {. input {; File f; }. command {; touch ${f.bam.bai}; }; }; ```; ```; Failed to process task definition 'myTask' (reason 1 of 1):; Failed to process expression 'f.bam.bai' (reason 1 of 1):; No such field 'bam' on type File; ```; ---; ```; version 1.0. task myTask {. input {; File f; }. command {; touch ${f%%.bam.bai}; }; }; ```; ```; Failed to read task definition at line 3 column 6 (reason 1 of 2):; Failed to convert AST node to ExpressionElement (reason 1 of 2):; No attribute 'rhs' found on Ast 'Remainder'. Did you mean: lhs; Failed to read task definition at line 3 column 6 (reason 2 of 2):; Failed to convert AST node to ExpressionElement (reason 2 of 2):; No attribute 'value' found on Ast 'MemberAccess'. Did you mean: member; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2873#issuecomment-439426356
https://github.com/broadinstitute/cromwell/issues/2873#issuecomment-439426356:35,Security,validat,validates,35,"A current version of Womtool still validates these tasks as OK, so the problem continues to exist in draft-2. Upgrading the tasks to WDL 1.0 causes Womtool validation to fail with messages of varying helpfulness:. ```; version 1.0. task myTask {. input {; File f; }. command {; touch ${f.bam.bai}; }; }; ```; ```; Failed to process task definition 'myTask' (reason 1 of 1):; Failed to process expression 'f.bam.bai' (reason 1 of 1):; No such field 'bam' on type File; ```; ---; ```; version 1.0. task myTask {. input {; File f; }. command {; touch ${f%%.bam.bai}; }; }; ```; ```; Failed to read task definition at line 3 column 6 (reason 1 of 2):; Failed to convert AST node to ExpressionElement (reason 1 of 2):; No attribute 'rhs' found on Ast 'Remainder'. Did you mean: lhs; Failed to read task definition at line 3 column 6 (reason 2 of 2):; Failed to convert AST node to ExpressionElement (reason 2 of 2):; No attribute 'value' found on Ast 'MemberAccess'. Did you mean: member; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2873#issuecomment-439426356
https://github.com/broadinstitute/cromwell/issues/2873#issuecomment-439426356:156,Security,validat,validation,156,"A current version of Womtool still validates these tasks as OK, so the problem continues to exist in draft-2. Upgrading the tasks to WDL 1.0 causes Womtool validation to fail with messages of varying helpfulness:. ```; version 1.0. task myTask {. input {; File f; }. command {; touch ${f.bam.bai}; }; }; ```; ```; Failed to process task definition 'myTask' (reason 1 of 1):; Failed to process expression 'f.bam.bai' (reason 1 of 1):; No such field 'bam' on type File; ```; ---; ```; version 1.0. task myTask {. input {; File f; }. command {; touch ${f%%.bam.bai}; }; }; ```; ```; Failed to read task definition at line 3 column 6 (reason 1 of 2):; Failed to convert AST node to ExpressionElement (reason 1 of 2):; No attribute 'rhs' found on Ast 'Remainder'. Did you mean: lhs; Failed to read task definition at line 3 column 6 (reason 2 of 2):; Failed to convert AST node to ExpressionElement (reason 2 of 2):; No attribute 'value' found on Ast 'MemberAccess'. Did you mean: member; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2873#issuecomment-439426356
https://github.com/broadinstitute/cromwell/issues/2889#issuecomment-344375352:41,Testability,test,test,41,"The code may or may not be okay, but the test is still failing.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2889#issuecomment-344375352
https://github.com/broadinstitute/cromwell/issues/2905#issuecomment-348194063:27,Testability,test,test,27,Close this ticket once the test has been turned back on and verified. PR #2952 should fix this test as well.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2905#issuecomment-348194063
https://github.com/broadinstitute/cromwell/issues/2905#issuecomment-348194063:95,Testability,test,test,95,Close this ticket once the test has been turned back on and verified. PR #2952 should fix this test as well.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2905#issuecomment-348194063
https://github.com/broadinstitute/cromwell/pull/2906#issuecomment-344821296:108,Energy Efficiency,green,green,108,"OK I think the TDD world is fucking wit me as code cov gave me a red mark with a 0% diff. Everyhing else is green, merging.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2906#issuecomment-344821296
https://github.com/broadinstitute/cromwell/pull/2908#issuecomment-344984174:55,Availability,reliab,reliable,55,"@katevoss nope, this is just making a single test more reliable",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2908#issuecomment-344984174
https://github.com/broadinstitute/cromwell/pull/2908#issuecomment-344984174:45,Testability,test,test,45,"@katevoss nope, this is just making a single test more reliable",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2908#issuecomment-344984174
https://github.com/broadinstitute/cromwell/issues/2912#issuecomment-363466390:329,Deployability,release,release,329,"@katevoss This one is important. Although I am open to alternatives, I believe that we need a way to set any parameter from the json file -- no matter how deeply buried the parameter is within subworkflows, etc. Having to explicitly expose parameters has become too big a hardship on developers and has now led to a bugfix GATK4 release with another one forthcoming.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2912#issuecomment-363466390
https://github.com/broadinstitute/cromwell/issues/2912#issuecomment-363466390:233,Security,expose,expose,233,"@katevoss This one is important. Although I am open to alternatives, I believe that we need a way to set any parameter from the json file -- no matter how deeply buried the parameter is within subworkflows, etc. Having to explicitly expose parameters has become too big a hardship on developers and has now led to a bugfix GATK4 release with another one forthcoming.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2912#issuecomment-363466390
https://github.com/broadinstitute/cromwell/issues/2912#issuecomment-490940850:801,Usability,guid,guidance,801,"I ran in this issue this week and it requires some quite nasty and ugly workarounds. So it would be great if this could be fixed. What I can grok from the code in Cromwell is that the node structure only considers tasks as `ExternalInputNode`. These have inputs that can be overwritten. Other nodes may be considered `OuterGraphInputNode`. Basically everything that is not an ExternalInputNode can not be considered for options that can be overridden. I feel there is a lot of technical decisions being made in this piece of code. Without knowing all the reasons why decisions are made it will be very hard to solve this in a PR for an outside contributor. It is hard to find the place in which to edit code in this case. I would love to take some work of cromwell's developers hands, but I need more guidance to do so. @ruchim can I help out in any way in the effort to solve this issue?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2912#issuecomment-490940850
https://github.com/broadinstitute/cromwell/issues/2916#issuecomment-345524845:208,Deployability,Pipeline,Pipelines,208,"Hi @leepc12 - This is a really good question. Internally our interest in requester pays has been fully under the umbrella of a separate team so we haven't run into this. I suspect that this would require the Pipelines API (i.e. JES) to support it and isn't something we can change directly. We can dig into this a bit. Note that Pipelines API has a new version coming out soon which will open up all kinds of functionality, I suspect this is already on the list. Again, we can dig into it.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2916#issuecomment-345524845
https://github.com/broadinstitute/cromwell/issues/2916#issuecomment-345524845:329,Deployability,Pipeline,Pipelines,329,"Hi @leepc12 - This is a really good question. Internally our interest in requester pays has been fully under the umbrella of a separate team so we haven't run into this. I suspect that this would require the Pipelines API (i.e. JES) to support it and isn't something we can change directly. We can dig into this a bit. Note that Pipelines API has a new version coming out soon which will open up all kinds of functionality, I suspect this is already on the list. Again, we can dig into it.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2916#issuecomment-345524845
https://github.com/broadinstitute/cromwell/issues/2916#issuecomment-390666394:84,Deployability,release,released,84,@nrockweiler requester pays buckets can be used in Cromwell when the Cromwell 32 is released. It is scheduled for this month,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2916#issuecomment-390666394
https://github.com/broadinstitute/cromwell/issues/2916#issuecomment-390666394:100,Energy Efficiency,schedul,scheduled,100,@nrockweiler requester pays buckets can be used in Cromwell when the Cromwell 32 is released. It is scheduled for this month,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2916#issuecomment-390666394
https://github.com/broadinstitute/cromwell/issues/2917#issuecomment-475726926:49,Testability,log,logs,49,"@antonkulaga We don't get a lot of usage of the /logs endpoint and considering removing it, so feel free to re-open with use cases for this endpoint.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2917#issuecomment-475726926
https://github.com/broadinstitute/cromwell/issues/2919#issuecomment-506468209:64,Deployability,update,updates,64,"https://broadworkbench.atlassian.net/browse/BA-2919; All future updates to this issue will be posted in JIRA. Sorry for the inconvenience, but you will need to create a free account to access it.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2919#issuecomment-506468209
https://github.com/broadinstitute/cromwell/issues/2919#issuecomment-506468209:185,Security,access,access,185,"https://broadworkbench.atlassian.net/browse/BA-2919; All future updates to this issue will be posted in JIRA. Sorry for the inconvenience, but you will need to create a free account to access it.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2919#issuecomment-506468209
https://github.com/broadinstitute/cromwell/issues/2927#issuecomment-348292881:207,Performance,cache,cached,207,"To clarify the current situation... Most of these ""don't affect the results"" attributes are indeed ignored for call caching. But workflow inputs are all used. So, if it's a hard-coded value it won't be call cached, but if the attribute is set by an expression based on an input, the input value will be hashed even if the runtime attribute value isn't. Hope that made sense...",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2927#issuecomment-348292881
https://github.com/broadinstitute/cromwell/issues/2927#issuecomment-348292881:303,Security,hash,hashed,303,"To clarify the current situation... Most of these ""don't affect the results"" attributes are indeed ignored for call caching. But workflow inputs are all used. So, if it's a hard-coded value it won't be call cached, but if the attribute is set by an expression based on an input, the input value will be hashed even if the runtime attribute value isn't. Hope that made sense...",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2927#issuecomment-348292881
https://github.com/broadinstitute/cromwell/issues/2927#issuecomment-348295352:175,Security,hash,hashed,175,"Maybe an example would also help:; ```wdl; workflow foo {; ...; runtime {; memory: ""2GB"" # ignored for call caching; }; }; ```. ```wdl; workflow foo {; String memory_string # hashed for call caching; runtime {; memory: memory_string # still ignored for call caching; }; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2927#issuecomment-348295352
https://github.com/broadinstitute/cromwell/issues/2928#issuecomment-1066837800:208,Testability,log,logs,208,"Any chance this has been worked on? I would also like to +1 this. I'm working on a setup in which it's not always possible to SSH into the VM where Cromwell is running, so the only option would be to get the logs over REST API.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2928#issuecomment-1066837800
https://github.com/broadinstitute/cromwell/pull/2929#issuecomment-346940945:50,Modifiability,Config,Config,50,"Temporarily closing, I need to try to DRY out the Config vs Standard stuff before review.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2929#issuecomment-346940945
https://github.com/broadinstitute/cromwell/issues/2930#issuecomment-347984022:131,Deployability,patch,patch,131,"It's low effort, low reward. If someone does it in their ""spare"" time, awesome. Otherwise, imho, the cromwell.yaml can be manually patch in a commit post 30, and someone can also fix the migration script at that time.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2930#issuecomment-347984022
https://github.com/broadinstitute/cromwell/issues/2932#issuecomment-346460834:14,Security,validat,validation,14,"How would the validation know what backend the task is going to be run on and if that backend requires docker?. Which is not to say that it can't happen sooner, but I don't think it can work like you're picturing.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2932#issuecomment-346460834
https://github.com/broadinstitute/cromwell/pull/2933#issuecomment-346468873:34,Testability,test,test,34,"Side note: we probably do want to test outputs from this test case, but since it found a bug, an empty `output {}` block in a subworkflow is definitely worth having a test for too",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2933#issuecomment-346468873
https://github.com/broadinstitute/cromwell/pull/2933#issuecomment-346468873:57,Testability,test,test,57,"Side note: we probably do want to test outputs from this test case, but since it found a bug, an empty `output {}` block in a subworkflow is definitely worth having a test for too",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2933#issuecomment-346468873
https://github.com/broadinstitute/cromwell/pull/2933#issuecomment-346468873:167,Testability,test,test,167,"Side note: we probably do want to test outputs from this test case, but since it found a bug, an empty `output {}` block in a subworkflow is definitely worth having a test for too",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2933#issuecomment-346468873
https://github.com/broadinstitute/cromwell/issues/2934#issuecomment-346841079:165,Deployability,release,release,165,"> which will never leave the Running state? If so this was recently resolved in develop. Yes, it is great that it is fixed now. BTW, when do you plan to make a next release?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2934#issuecomment-346841079
https://github.com/broadinstitute/cromwell/pull/2935#issuecomment-347207357:68,Availability,down,down,68,Esprit d'escalier: Does FC know this is coming? Is it going to slow down their adoption of Cromwell 30?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2935#issuecomment-347207357
https://github.com/broadinstitute/cromwell/pull/2935#issuecomment-347208372:37,Usability,simpl,simple,37,"@cjllanwarne in this case it'll be a simple find/replace text change, the underlying API in terms of data structures remains the same.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2935#issuecomment-347208372
https://github.com/broadinstitute/cromwell/pull/2936#issuecomment-347185690:98,Availability,avail,available,98,> I wasn't sure how the sbt magic you put in for the API docs worked. Pass the word on. Currently available both in the updated [wiki](https://github.com/broadinstitute/cromwell/wiki/DevZone#generating-a-markdown-document-of-the-swagger-yaml) and the more comprehensive mega doc-on-docs in our [team drive](https://drive.google.com/drive/u/1/folders/0By3wA7o30lk3VmF3aldBNkEzaDg). EDIT: Maybe we can leave a link at the top of the cromwell.yaml?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2936#issuecomment-347185690
https://github.com/broadinstitute/cromwell/pull/2936#issuecomment-347185690:120,Deployability,update,updated,120,> I wasn't sure how the sbt magic you put in for the API docs worked. Pass the word on. Currently available both in the updated [wiki](https://github.com/broadinstitute/cromwell/wiki/DevZone#generating-a-markdown-document-of-the-swagger-yaml) and the more comprehensive mega doc-on-docs in our [team drive](https://drive.google.com/drive/u/1/folders/0By3wA7o30lk3VmF3aldBNkEzaDg). EDIT: Maybe we can leave a link at the top of the cromwell.yaml?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2936#issuecomment-347185690
https://github.com/broadinstitute/cromwell/pull/2936#issuecomment-347252970:41,Testability,test,tested,41,"@kshakir The pieces I put in are as well tested as their siblings and they'll remain that way as this PR, so Codecov can remain unhappy.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2936#issuecomment-347252970
https://github.com/broadinstitute/cromwell/pull/2936#issuecomment-347276597:7,Availability,failure,failures,7,on the failures - the extra commit at the tail end (cromwell api) i threw in quickly last night after i submitted the PR w/ the intention of finishing it this morning. apparently it didn't even compile. Busted!,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2936#issuecomment-347276597
https://github.com/broadinstitute/cromwell/pull/2941#issuecomment-347637020:7,Availability,failure,failures,7,"NB the failures in `travis/pr` `centaurJes` were caused by the `customLabels` change merging into develop before I rebased. . I didn't want to wait 30 minutes to rerun the tests, since they were already passing on the other backends, and in `travis/push`...",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2941#issuecomment-347637020
https://github.com/broadinstitute/cromwell/pull/2941#issuecomment-347637020:172,Testability,test,tests,172,"NB the failures in `travis/pr` `centaurJes` were caused by the `customLabels` change merging into develop before I rebased. . I didn't want to wait 30 minutes to rerun the tests, since they were already passing on the other backends, and in `travis/push`...",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2941#issuecomment-347637020
https://github.com/broadinstitute/cromwell/issues/2946#issuecomment-348516114:108,Testability,test,test,108,As of current develop (74edee4c5338d25283c0fcf72ddd016b8bf5c4e1) this is not fixed. We should create a unit test to check this somewhere.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2946#issuecomment-348516114
https://github.com/broadinstitute/cromwell/pull/2948#issuecomment-347748418:148,Availability,down,down,148,Ooooh none of us could remember the exact reason but I think you‚Äôre right. And iirc there was some performance problem which was eventually tracked down to be something silly we hadn‚Äôt accounted for. This makes sense,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2948#issuecomment-347748418
https://github.com/broadinstitute/cromwell/pull/2948#issuecomment-347748418:99,Performance,perform,performance,99,Ooooh none of us could remember the exact reason but I think you‚Äôre right. And iirc there was some performance problem which was eventually tracked down to be something silly we hadn‚Äôt accounted for. This makes sense,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2948#issuecomment-347748418
https://github.com/broadinstitute/cromwell/pull/2948#issuecomment-347844423:171,Energy Efficiency,efficient,efficient,171,Yeah I recall Jeff tried a simpler setup like this first and then had to resort to nesting Cromwells when that didn't work. But clearly Cromwell has become that much more efficient so now it does work hooray!,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2948#issuecomment-347844423
https://github.com/broadinstitute/cromwell/pull/2948#issuecomment-347844423:27,Usability,simpl,simpler,27,Yeah I recall Jeff tried a simpler setup like this first and then had to resort to nesting Cromwells when that didn't work. But clearly Cromwell has become that much more efficient so now it does work hooray!,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2948#issuecomment-347844423
https://github.com/broadinstitute/cromwell/pull/2948#issuecomment-347844423:128,Usability,clear,clearly,128,Yeah I recall Jeff tried a simpler setup like this first and then had to resort to nesting Cromwells when that didn't work. But clearly Cromwell has become that much more efficient so now it does work hooray!,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2948#issuecomment-347844423
https://github.com/broadinstitute/cromwell/pull/2951#issuecomment-348033487:50,Testability,Test,Tested,50,Usually only runs via cron and not in pushes/PRs. Tested with some manual intervention here: https://travis-ci.org/broadinstitute/cromwell/jobs/309168581,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2951#issuecomment-348033487
https://github.com/broadinstitute/cromwell/pull/2951#issuecomment-348069333:84,Availability,failure,failures,84,That certainly looks reasonable despite all the Travis redness. I restarted all the failures and assuming everything clears up :+1:. [![Approved with PullApprove](https://img.shields.io/badge/reviewers-approved-brightgreen.svg)](https://pullapprove.com/broadinstitute/cromwell/pull-request/2951/?utm_source=github-pr&utm_medium=comment-badge&utm_campaign=broadinstitute/cromwell),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2951#issuecomment-348069333
https://github.com/broadinstitute/cromwell/pull/2951#issuecomment-348069333:117,Usability,clear,clears,117,That certainly looks reasonable despite all the Travis redness. I restarted all the failures and assuming everything clears up :+1:. [![Approved with PullApprove](https://img.shields.io/badge/reviewers-approved-brightgreen.svg)](https://pullapprove.com/broadinstitute/cromwell/pull-request/2951/?utm_source=github-pr&utm_medium=comment-badge&utm_campaign=broadinstitute/cromwell),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2951#issuecomment-348069333
https://github.com/broadinstitute/cromwell/pull/2959#issuecomment-348353620:92,Testability,test,test,92,"I see, so the function to calculate the type was missing. Sorry about that, I didn't have a test to check it. . üëç",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2959#issuecomment-348353620
https://github.com/broadinstitute/cromwell/issues/2963#issuecomment-348553915:62,Deployability,upgrade,upgraded,62,"False alarm, this was because I was because I was running the upgraded jar in a different directory!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2963#issuecomment-348553915
https://github.com/broadinstitute/cromwell/issues/2966#issuecomment-349111326:12,Deployability,release,released,12,30 has been released.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2966#issuecomment-349111326
https://github.com/broadinstitute/cromwell/issues/2970#issuecomment-348623050:177,Availability,error,error,177,@dianekaplan could you run `gcloud alpha genomics operations describe operations/EKmIx96ALBjh373VhLH0ui8gkYad9-AKKg9wcm9kdWN0aW9uUXVldWU` and add in anything that looks like an error message or error code?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2970#issuecomment-348623050
https://github.com/broadinstitute/cromwell/issues/2970#issuecomment-348623050:194,Availability,error,error,194,@dianekaplan could you run `gcloud alpha genomics operations describe operations/EKmIx96ALBjh373VhLH0ui8gkYad9-AKKg9wcm9kdWN0aW9uUXVldWU` and add in anything that looks like an error message or error code?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2970#issuecomment-348623050
https://github.com/broadinstitute/cromwell/issues/2970#issuecomment-348623050:183,Integrability,message,message,183,@dianekaplan could you run `gcloud alpha genomics operations describe operations/EKmIx96ALBjh373VhLH0ui8gkYad9-AKKg9wcm9kdWN0aW9uUXVldWU` and add in anything that looks like an error message or error code?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2970#issuecomment-348623050
https://github.com/broadinstitute/cromwell/pull/2971#issuecomment-348701623:385,Security,expose,expose,385,"Thanks Saman!. Quick Question: What is ‚Äúparent workflow ID‚Äù here?. I thought that QUERY should only be returning top level workflow result? Otherwise you‚Äôre going to get lots of workflow entries in QUERY for the same SUBMIT request which seems odd to me. Maybe it‚Äôd be useful to make getting subworkflows opt in/out? But that‚Äôs me thinking out loud and not for this PR!. Since we *do* expose subworkflows, we probably should give the ‚Äútop level‚Äù ID (the one returned by SUBMIT) rather than direct ‚Äúparent‚Äù ID.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2971#issuecomment-348701623
https://github.com/broadinstitute/cromwell/pull/2971#issuecomment-349068493:23,Usability,feedback,feedback,23,Thanks for the helpful feedback! I've addressed all of the comments if you want to take another look! @cjllanwarne @mcovarr,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2971#issuecomment-349068493
https://github.com/broadinstitute/cromwell/issues/2972#issuecomment-349014226:119,Deployability,release,release,119,I can reproduce this problem on Cromwell 29 but happily this runs fine on the forthcoming Cromwell 30. We're hoping to release this **very** soon. üôÇ,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2972#issuecomment-349014226
https://github.com/broadinstitute/cromwell/issues/2972#issuecomment-349111259:12,Deployability,release,released,12,30 has been released.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2972#issuecomment-349111259
https://github.com/broadinstitute/cromwell/issues/2973#issuecomment-348778521:145,Availability,echo,echo,145,"Fantastic instincts. This fails in the same develop and passes in the same 29:. ```wdl; task two_input_task {; String inA; String inB; command { echo ${inA} and ${inB} }; runtime { docker: ""ubuntu"" }; }. workflow duplicate_scatter_input {; String my_input = ""input""; scatter (i in range(0)) {; call two_input_task { input: inA = my_input, inB = my_input }; }; }; ```. Produces in this error on develop:; ```java; [2017-12-03 14:48:08,10] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2017-12-03 14:48:09,17] [error] WorkflowManagerActor Workflow 986bbc71-2b80-4cf1-aade-e93dd77062b0 failed (during MaterializingWorkflowDescriptorState): Workflow input processing failed:; Unable to build WOM node for Scatter '$scatter_0': Two or more nodes have the same FullyQualifiedName: ^.my_input; cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; Unable to build WOM node for Scatter '$scatter_0': Two or more nodes have the same FullyQualifiedName: ^.my_input; 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$workflowInitializationFailed(MaterializeWorkflowDescriptorActor.scala:211); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:181); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:176); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); 	at akka.actor.FSM.processEvent(FSM.scala:665); 	at akka.actor.FSM.processEvent$(FSM.scala:662); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:136); 	at akka.actor.LoggingFS",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2973#issuecomment-348778521
https://github.com/broadinstitute/cromwell/issues/2973#issuecomment-348778521:385,Availability,error,error,385,"Fantastic instincts. This fails in the same develop and passes in the same 29:. ```wdl; task two_input_task {; String inA; String inB; command { echo ${inA} and ${inB} }; runtime { docker: ""ubuntu"" }; }. workflow duplicate_scatter_input {; String my_input = ""input""; scatter (i in range(0)) {; call two_input_task { input: inA = my_input, inB = my_input }; }; }; ```. Produces in this error on develop:; ```java; [2017-12-03 14:48:08,10] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2017-12-03 14:48:09,17] [error] WorkflowManagerActor Workflow 986bbc71-2b80-4cf1-aade-e93dd77062b0 failed (during MaterializingWorkflowDescriptorState): Workflow input processing failed:; Unable to build WOM node for Scatter '$scatter_0': Two or more nodes have the same FullyQualifiedName: ^.my_input; cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; Unable to build WOM node for Scatter '$scatter_0': Two or more nodes have the same FullyQualifiedName: ^.my_input; 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$workflowInitializationFailed(MaterializeWorkflowDescriptorActor.scala:211); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:181); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:176); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); 	at akka.actor.FSM.processEvent(FSM.scala:665); 	at akka.actor.FSM.processEvent$(FSM.scala:662); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:136); 	at akka.actor.LoggingFS",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2973#issuecomment-348778521
https://github.com/broadinstitute/cromwell/issues/2973#issuecomment-348778521:522,Availability,error,error,522,"Fantastic instincts. This fails in the same develop and passes in the same 29:. ```wdl; task two_input_task {; String inA; String inB; command { echo ${inA} and ${inB} }; runtime { docker: ""ubuntu"" }; }. workflow duplicate_scatter_input {; String my_input = ""input""; scatter (i in range(0)) {; call two_input_task { input: inA = my_input, inB = my_input }; }; }; ```. Produces in this error on develop:; ```java; [2017-12-03 14:48:08,10] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2017-12-03 14:48:09,17] [error] WorkflowManagerActor Workflow 986bbc71-2b80-4cf1-aade-e93dd77062b0 failed (during MaterializingWorkflowDescriptorState): Workflow input processing failed:; Unable to build WOM node for Scatter '$scatter_0': Two or more nodes have the same FullyQualifiedName: ^.my_input; cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; Unable to build WOM node for Scatter '$scatter_0': Two or more nodes have the same FullyQualifiedName: ^.my_input; 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$workflowInitializationFailed(MaterializeWorkflowDescriptorActor.scala:211); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:181); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:176); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); 	at akka.actor.FSM.processEvent(FSM.scala:665); 	at akka.actor.FSM.processEvent$(FSM.scala:662); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:136); 	at akka.actor.LoggingFS",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2973#issuecomment-348778521
https://github.com/broadinstitute/cromwell/issues/2973#issuecomment-348778521:1899,Testability,Log,LoggingFSM,1899,d:; Unable to build WOM node for Scatter '$scatter_0': Two or more nodes have the same FullyQualifiedName: ^.my_input; 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$workflowInitializationFailed(MaterializeWorkflowDescriptorActor.scala:211); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:181); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:176); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); 	at akka.actor.FSM.processEvent(FSM.scala:665); 	at akka.actor.FSM.processEvent$(FSM.scala:662); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:136); 	at akka.actor.LoggingFSM.processEvent(FSM.scala:801); 	at akka.actor.LoggingFSM.processEvent$(FSM.scala:783); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.processEvent(MaterializeWorkflowDescriptorActor.scala:136); 	at akka.actor.FSM.akka$actor$FSM$$processMsg(FSM.scala:659); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:653); 	at akka.actor.Actor.aroundReceive(Actor.scala:514); 	at akka.actor.Actor.aroundReceive$(Actor.scala:512); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:136); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); 	at akka.actor.ActorCell.invoke(ActorCell.scala:496); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at akka.dispatch.forkjoi,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2973#issuecomment-348778521
https://github.com/broadinstitute/cromwell/issues/2973#issuecomment-348778521:1992,Testability,Log,LoggingFSM,1992,s have the same FullyQualifiedName: ^.my_input; 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$workflowInitializationFailed(MaterializeWorkflowDescriptorActor.scala:211); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:181); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:176); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); 	at akka.actor.FSM.processEvent(FSM.scala:665); 	at akka.actor.FSM.processEvent$(FSM.scala:662); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:136); 	at akka.actor.LoggingFSM.processEvent(FSM.scala:801); 	at akka.actor.LoggingFSM.processEvent$(FSM.scala:783); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.processEvent(MaterializeWorkflowDescriptorActor.scala:136); 	at akka.actor.FSM.akka$actor$FSM$$processMsg(FSM.scala:659); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:653); 	at akka.actor.Actor.aroundReceive(Actor.scala:514); 	at akka.actor.Actor.aroundReceive$(Actor.scala:512); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:136); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); 	at akka.actor.ActorCell.invoke(ActorCell.scala:496); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoi,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2973#issuecomment-348778521
https://github.com/broadinstitute/cromwell/issues/2973#issuecomment-348778521:2047,Testability,Log,LoggingFSM,2047,mwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$workflowInitializationFailed(MaterializeWorkflowDescriptorActor.scala:211); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:181); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:176); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); 	at akka.actor.FSM.processEvent(FSM.scala:665); 	at akka.actor.FSM.processEvent$(FSM.scala:662); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:136); 	at akka.actor.LoggingFSM.processEvent(FSM.scala:801); 	at akka.actor.LoggingFSM.processEvent$(FSM.scala:783); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.processEvent(MaterializeWorkflowDescriptorActor.scala:136); 	at akka.actor.FSM.akka$actor$FSM$$processMsg(FSM.scala:659); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:653); 	at akka.actor.Actor.aroundReceive(Actor.scala:514); 	at akka.actor.Actor.aroundReceive$(Actor.scala:512); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:136); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); 	at akka.actor.ActorCell.invoke(ActorCell.scala:496); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2973#issuecomment-348778521
https://github.com/broadinstitute/cromwell/pull/2975#issuecomment-349000690:63,Deployability,patch,patching,63,"Timing-based fix is suboptimal, but discussed w/ the group and patching this for now.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2975#issuecomment-349000690
https://github.com/broadinstitute/cromwell/pull/2976#issuecomment-348790256:52,Testability,test,test,52,New WomGraph for the `scatter` example in #2973:. ![test](https://user-images.githubusercontent.com/13006282/33527245-4ee874d6-d81b-11e7-9c52-9eac540e5a58.png),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2976#issuecomment-348790256
https://github.com/broadinstitute/cromwell/pull/2988#issuecomment-349344402:286,Integrability,inject,injected,286,"> TOL: To me this feels like it‚Äôd be way neater if the EGIN had a field or def called inputFileName nameInInputSet, to encapsulate all this into the egin itself rather than having to add it later externally?. Good point, I was just reticent to the idea of jamming yet another attribute injected by the language that will only ever be used once during the lifetime of the workflow but I agree it's still neater. > FWIW in my ideal world we‚Äôd have pluggable languages which should only need to define one function like ‚ÄúreadWorkflowIntoWom(content: String, l: Set[ImportResolver]): WomExecutable‚Äù and everything else would be included/encapsulated in that result. Yes but there would be some non-DRYness by having each language implement entirely how they ingest inputs (most of the logic is the same), plus having it in WOM guarantees that all EGIN are handled the same way w.r.t coercion, validation etc.. It could use some refactoring though I agree",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2988#issuecomment-349344402
https://github.com/broadinstitute/cromwell/pull/2988#issuecomment-349344402:924,Modifiability,refactor,refactoring,924,"> TOL: To me this feels like it‚Äôd be way neater if the EGIN had a field or def called inputFileName nameInInputSet, to encapsulate all this into the egin itself rather than having to add it later externally?. Good point, I was just reticent to the idea of jamming yet another attribute injected by the language that will only ever be used once during the lifetime of the workflow but I agree it's still neater. > FWIW in my ideal world we‚Äôd have pluggable languages which should only need to define one function like ‚ÄúreadWorkflowIntoWom(content: String, l: Set[ImportResolver]): WomExecutable‚Äù and everything else would be included/encapsulated in that result. Yes but there would be some non-DRYness by having each language implement entirely how they ingest inputs (most of the logic is the same), plus having it in WOM guarantees that all EGIN are handled the same way w.r.t coercion, validation etc.. It could use some refactoring though I agree",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2988#issuecomment-349344402
https://github.com/broadinstitute/cromwell/pull/2988#issuecomment-349344402:286,Security,inject,injected,286,"> TOL: To me this feels like it‚Äôd be way neater if the EGIN had a field or def called inputFileName nameInInputSet, to encapsulate all this into the egin itself rather than having to add it later externally?. Good point, I was just reticent to the idea of jamming yet another attribute injected by the language that will only ever be used once during the lifetime of the workflow but I agree it's still neater. > FWIW in my ideal world we‚Äôd have pluggable languages which should only need to define one function like ‚ÄúreadWorkflowIntoWom(content: String, l: Set[ImportResolver]): WomExecutable‚Äù and everything else would be included/encapsulated in that result. Yes but there would be some non-DRYness by having each language implement entirely how they ingest inputs (most of the logic is the same), plus having it in WOM guarantees that all EGIN are handled the same way w.r.t coercion, validation etc.. It could use some refactoring though I agree",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2988#issuecomment-349344402
https://github.com/broadinstitute/cromwell/pull/2988#issuecomment-349344402:889,Security,validat,validation,889,"> TOL: To me this feels like it‚Äôd be way neater if the EGIN had a field or def called inputFileName nameInInputSet, to encapsulate all this into the egin itself rather than having to add it later externally?. Good point, I was just reticent to the idea of jamming yet another attribute injected by the language that will only ever be used once during the lifetime of the workflow but I agree it's still neater. > FWIW in my ideal world we‚Äôd have pluggable languages which should only need to define one function like ‚ÄúreadWorkflowIntoWom(content: String, l: Set[ImportResolver]): WomExecutable‚Äù and everything else would be included/encapsulated in that result. Yes but there would be some non-DRYness by having each language implement entirely how they ingest inputs (most of the logic is the same), plus having it in WOM guarantees that all EGIN are handled the same way w.r.t coercion, validation etc.. It could use some refactoring though I agree",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2988#issuecomment-349344402
https://github.com/broadinstitute/cromwell/pull/2988#issuecomment-349344402:781,Testability,log,logic,781,"> TOL: To me this feels like it‚Äôd be way neater if the EGIN had a field or def called inputFileName nameInInputSet, to encapsulate all this into the egin itself rather than having to add it later externally?. Good point, I was just reticent to the idea of jamming yet another attribute injected by the language that will only ever be used once during the lifetime of the workflow but I agree it's still neater. > FWIW in my ideal world we‚Äôd have pluggable languages which should only need to define one function like ‚ÄúreadWorkflowIntoWom(content: String, l: Set[ImportResolver]): WomExecutable‚Äù and everything else would be included/encapsulated in that result. Yes but there would be some non-DRYness by having each language implement entirely how they ingest inputs (most of the logic is the same), plus having it in WOM guarantees that all EGIN are handled the same way w.r.t coercion, validation etc.. It could use some refactoring though I agree",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2988#issuecomment-349344402
https://github.com/broadinstitute/cromwell/pull/2988#issuecomment-349346941:187,Safety,avoid,avoid,187,"@mcovarr I agree (although that day might be sooner than you think, re WDLd3)... read my pluggable comment only as ""this is background info on why I don't want another function if we can avoid it""",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2988#issuecomment-349346941
https://github.com/broadinstitute/cromwell/pull/2988#issuecomment-349403403:280,Testability,test,test,280,@mcovarr @kshakir a quick second pass would be appreciated :) I followed (one of :p) @cjllanwarne suggestions and added an attribute to EGIN instead of passing a function pointer.; I also fixed the FQNs for CWL EGINs which makes the pre-existing `CwlInputValidationSpec` actually test that this works now.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2988#issuecomment-349403403
https://github.com/broadinstitute/cromwell/pull/2988#issuecomment-349447078:23,Testability,test,tests,23,Rebase to unredden TES tests,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2988#issuecomment-349447078
https://github.com/broadinstitute/cromwell/issues/2990#issuecomment-349335796:580,Modifiability,config,configs,580,"Isn't the `runtime` section supposed to be backend/engine specific? Maybe this discussion belongs more in the openWDL board, but having a section that is simply defined as key-value pairs that allows expressions, the implementation of which is at least partially engine specific (as an engine may implement for multiple backends) makes a lot of sense to me. While there are plenty of key-values that are easily generalized, and can be fixed for such a section, backends almost invariably have specialized specific options that are best controlled on the fly rather than via fixed configs. As an analogy, The DRMAA API allowed for this with SGE and similar run-execution engines, by generalizing common functions, and allowing pass-through of specific ones (e.g. soft memory limits, if my vague memory serves).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2990#issuecomment-349335796
https://github.com/broadinstitute/cromwell/issues/2990#issuecomment-349335796:154,Usability,simpl,simply,154,"Isn't the `runtime` section supposed to be backend/engine specific? Maybe this discussion belongs more in the openWDL board, but having a section that is simply defined as key-value pairs that allows expressions, the implementation of which is at least partially engine specific (as an engine may implement for multiple backends) makes a lot of sense to me. While there are plenty of key-values that are easily generalized, and can be fixed for such a section, backends almost invariably have specialized specific options that are best controlled on the fly rather than via fixed configs. As an analogy, The DRMAA API allowed for this with SGE and similar run-execution engines, by generalizing common functions, and allowing pass-through of specific ones (e.g. soft memory limits, if my vague memory serves).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2990#issuecomment-349335796
https://github.com/broadinstitute/cromwell/issues/2990#issuecomment-349459099:263,Availability,down,down,263,"I'd argue that the arbitrary KV thing was one of the largest mistakes from Original WDL (i.e. what came out of the 2 weeks of us locking ourselves in a room and figuring it all out) as it destroys portability unless one adds *some* structure to it. We've doubled down on it over the years by adding what IMO should be Cromwell workflow options into the runtime block which means that a WDL can now have important control information on it which might ruin the portability of that workflow. The worst example I can think of is `backend` which is a purely Cromwell concept - what happens when that workflow goes to run on DNAnexus? What happens when `backend` is *also* a concept in another engine but it means something else? What happens when one engine interprets `cpu` to mean ""at least this much"" and another ""exactly this much""? What happens when in the former case the user gets charged more money than they thought because more memory than they needed was allocated? What happens when one engine assumes `mem` is just a number representing GB and can't parse a string w/ units?. (admittedly `mem` is a bad example as it's one of the very few things in `runtime` the spec is actually opinionated about, but you get the point). If the goal is to decouple Cromwell from WDL, the most obvious target is the `runtime` section. If people need more control over their Cromwell experience the answer is to a) provide that information in a way which doesn't destroy workflow portability of the WDL and b) expose that via Firecloud if those users need Firecloud. FWIW one of my primary goals for WDL 1.0 is a massive redo of `runtime` including removing the arbitrariness of it. If things are implementation specific they can be passed in to that engine separately, which would also help maintain the portability of the workflow itself.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2990#issuecomment-349459099
https://github.com/broadinstitute/cromwell/issues/2990#issuecomment-349459099:884,Energy Efficiency,charge,charged,884,"I'd argue that the arbitrary KV thing was one of the largest mistakes from Original WDL (i.e. what came out of the 2 weeks of us locking ourselves in a room and figuring it all out) as it destroys portability unless one adds *some* structure to it. We've doubled down on it over the years by adding what IMO should be Cromwell workflow options into the runtime block which means that a WDL can now have important control information on it which might ruin the portability of that workflow. The worst example I can think of is `backend` which is a purely Cromwell concept - what happens when that workflow goes to run on DNAnexus? What happens when `backend` is *also* a concept in another engine but it means something else? What happens when one engine interprets `cpu` to mean ""at least this much"" and another ""exactly this much""? What happens when in the former case the user gets charged more money than they thought because more memory than they needed was allocated? What happens when one engine assumes `mem` is just a number representing GB and can't parse a string w/ units?. (admittedly `mem` is a bad example as it's one of the very few things in `runtime` the spec is actually opinionated about, but you get the point). If the goal is to decouple Cromwell from WDL, the most obvious target is the `runtime` section. If people need more control over their Cromwell experience the answer is to a) provide that information in a way which doesn't destroy workflow portability of the WDL and b) expose that via Firecloud if those users need Firecloud. FWIW one of my primary goals for WDL 1.0 is a massive redo of `runtime` including removing the arbitrariness of it. If things are implementation specific they can be passed in to that engine separately, which would also help maintain the portability of the workflow itself.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2990#issuecomment-349459099
https://github.com/broadinstitute/cromwell/issues/2990#issuecomment-349459099:962,Energy Efficiency,allocate,allocated,962,"I'd argue that the arbitrary KV thing was one of the largest mistakes from Original WDL (i.e. what came out of the 2 weeks of us locking ourselves in a room and figuring it all out) as it destroys portability unless one adds *some* structure to it. We've doubled down on it over the years by adding what IMO should be Cromwell workflow options into the runtime block which means that a WDL can now have important control information on it which might ruin the portability of that workflow. The worst example I can think of is `backend` which is a purely Cromwell concept - what happens when that workflow goes to run on DNAnexus? What happens when `backend` is *also* a concept in another engine but it means something else? What happens when one engine interprets `cpu` to mean ""at least this much"" and another ""exactly this much""? What happens when in the former case the user gets charged more money than they thought because more memory than they needed was allocated? What happens when one engine assumes `mem` is just a number representing GB and can't parse a string w/ units?. (admittedly `mem` is a bad example as it's one of the very few things in `runtime` the spec is actually opinionated about, but you get the point). If the goal is to decouple Cromwell from WDL, the most obvious target is the `runtime` section. If people need more control over their Cromwell experience the answer is to a) provide that information in a way which doesn't destroy workflow portability of the WDL and b) expose that via Firecloud if those users need Firecloud. FWIW one of my primary goals for WDL 1.0 is a massive redo of `runtime` including removing the arbitrariness of it. If things are implementation specific they can be passed in to that engine separately, which would also help maintain the portability of the workflow itself.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2990#issuecomment-349459099
https://github.com/broadinstitute/cromwell/issues/2990#issuecomment-349459099:197,Modifiability,portab,portability,197,"I'd argue that the arbitrary KV thing was one of the largest mistakes from Original WDL (i.e. what came out of the 2 weeks of us locking ourselves in a room and figuring it all out) as it destroys portability unless one adds *some* structure to it. We've doubled down on it over the years by adding what IMO should be Cromwell workflow options into the runtime block which means that a WDL can now have important control information on it which might ruin the portability of that workflow. The worst example I can think of is `backend` which is a purely Cromwell concept - what happens when that workflow goes to run on DNAnexus? What happens when `backend` is *also* a concept in another engine but it means something else? What happens when one engine interprets `cpu` to mean ""at least this much"" and another ""exactly this much""? What happens when in the former case the user gets charged more money than they thought because more memory than they needed was allocated? What happens when one engine assumes `mem` is just a number representing GB and can't parse a string w/ units?. (admittedly `mem` is a bad example as it's one of the very few things in `runtime` the spec is actually opinionated about, but you get the point). If the goal is to decouple Cromwell from WDL, the most obvious target is the `runtime` section. If people need more control over their Cromwell experience the answer is to a) provide that information in a way which doesn't destroy workflow portability of the WDL and b) expose that via Firecloud if those users need Firecloud. FWIW one of my primary goals for WDL 1.0 is a massive redo of `runtime` including removing the arbitrariness of it. If things are implementation specific they can be passed in to that engine separately, which would also help maintain the portability of the workflow itself.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2990#issuecomment-349459099
https://github.com/broadinstitute/cromwell/issues/2990#issuecomment-349459099:460,Modifiability,portab,portability,460,"I'd argue that the arbitrary KV thing was one of the largest mistakes from Original WDL (i.e. what came out of the 2 weeks of us locking ourselves in a room and figuring it all out) as it destroys portability unless one adds *some* structure to it. We've doubled down on it over the years by adding what IMO should be Cromwell workflow options into the runtime block which means that a WDL can now have important control information on it which might ruin the portability of that workflow. The worst example I can think of is `backend` which is a purely Cromwell concept - what happens when that workflow goes to run on DNAnexus? What happens when `backend` is *also* a concept in another engine but it means something else? What happens when one engine interprets `cpu` to mean ""at least this much"" and another ""exactly this much""? What happens when in the former case the user gets charged more money than they thought because more memory than they needed was allocated? What happens when one engine assumes `mem` is just a number representing GB and can't parse a string w/ units?. (admittedly `mem` is a bad example as it's one of the very few things in `runtime` the spec is actually opinionated about, but you get the point). If the goal is to decouple Cromwell from WDL, the most obvious target is the `runtime` section. If people need more control over their Cromwell experience the answer is to a) provide that information in a way which doesn't destroy workflow portability of the WDL and b) expose that via Firecloud if those users need Firecloud. FWIW one of my primary goals for WDL 1.0 is a massive redo of `runtime` including removing the arbitrariness of it. If things are implementation specific they can be passed in to that engine separately, which would also help maintain the portability of the workflow itself.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2990#issuecomment-349459099
https://github.com/broadinstitute/cromwell/issues/2990#issuecomment-349459099:1472,Modifiability,portab,portability,1472,"I'd argue that the arbitrary KV thing was one of the largest mistakes from Original WDL (i.e. what came out of the 2 weeks of us locking ourselves in a room and figuring it all out) as it destroys portability unless one adds *some* structure to it. We've doubled down on it over the years by adding what IMO should be Cromwell workflow options into the runtime block which means that a WDL can now have important control information on it which might ruin the portability of that workflow. The worst example I can think of is `backend` which is a purely Cromwell concept - what happens when that workflow goes to run on DNAnexus? What happens when `backend` is *also* a concept in another engine but it means something else? What happens when one engine interprets `cpu` to mean ""at least this much"" and another ""exactly this much""? What happens when in the former case the user gets charged more money than they thought because more memory than they needed was allocated? What happens when one engine assumes `mem` is just a number representing GB and can't parse a string w/ units?. (admittedly `mem` is a bad example as it's one of the very few things in `runtime` the spec is actually opinionated about, but you get the point). If the goal is to decouple Cromwell from WDL, the most obvious target is the `runtime` section. If people need more control over their Cromwell experience the answer is to a) provide that information in a way which doesn't destroy workflow portability of the WDL and b) expose that via Firecloud if those users need Firecloud. FWIW one of my primary goals for WDL 1.0 is a massive redo of `runtime` including removing the arbitrariness of it. If things are implementation specific they can be passed in to that engine separately, which would also help maintain the portability of the workflow itself.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2990#issuecomment-349459099
https://github.com/broadinstitute/cromwell/issues/2990#issuecomment-349459099:1797,Modifiability,portab,portability,1797,"I'd argue that the arbitrary KV thing was one of the largest mistakes from Original WDL (i.e. what came out of the 2 weeks of us locking ourselves in a room and figuring it all out) as it destroys portability unless one adds *some* structure to it. We've doubled down on it over the years by adding what IMO should be Cromwell workflow options into the runtime block which means that a WDL can now have important control information on it which might ruin the portability of that workflow. The worst example I can think of is `backend` which is a purely Cromwell concept - what happens when that workflow goes to run on DNAnexus? What happens when `backend` is *also* a concept in another engine but it means something else? What happens when one engine interprets `cpu` to mean ""at least this much"" and another ""exactly this much""? What happens when in the former case the user gets charged more money than they thought because more memory than they needed was allocated? What happens when one engine assumes `mem` is just a number representing GB and can't parse a string w/ units?. (admittedly `mem` is a bad example as it's one of the very few things in `runtime` the spec is actually opinionated about, but you get the point). If the goal is to decouple Cromwell from WDL, the most obvious target is the `runtime` section. If people need more control over their Cromwell experience the answer is to a) provide that information in a way which doesn't destroy workflow portability of the WDL and b) expose that via Firecloud if those users need Firecloud. FWIW one of my primary goals for WDL 1.0 is a massive redo of `runtime` including removing the arbitrariness of it. If things are implementation specific they can be passed in to that engine separately, which would also help maintain the portability of the workflow itself.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2990#issuecomment-349459099
https://github.com/broadinstitute/cromwell/issues/2990#issuecomment-349459099:1502,Security,expose,expose,1502,"I'd argue that the arbitrary KV thing was one of the largest mistakes from Original WDL (i.e. what came out of the 2 weeks of us locking ourselves in a room and figuring it all out) as it destroys portability unless one adds *some* structure to it. We've doubled down on it over the years by adding what IMO should be Cromwell workflow options into the runtime block which means that a WDL can now have important control information on it which might ruin the portability of that workflow. The worst example I can think of is `backend` which is a purely Cromwell concept - what happens when that workflow goes to run on DNAnexus? What happens when `backend` is *also* a concept in another engine but it means something else? What happens when one engine interprets `cpu` to mean ""at least this much"" and another ""exactly this much""? What happens when in the former case the user gets charged more money than they thought because more memory than they needed was allocated? What happens when one engine assumes `mem` is just a number representing GB and can't parse a string w/ units?. (admittedly `mem` is a bad example as it's one of the very few things in `runtime` the spec is actually opinionated about, but you get the point). If the goal is to decouple Cromwell from WDL, the most obvious target is the `runtime` section. If people need more control over their Cromwell experience the answer is to a) provide that information in a way which doesn't destroy workflow portability of the WDL and b) expose that via Firecloud if those users need Firecloud. FWIW one of my primary goals for WDL 1.0 is a massive redo of `runtime` including removing the arbitrariness of it. If things are implementation specific they can be passed in to that engine separately, which would also help maintain the portability of the workflow itself.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2990#issuecomment-349459099
https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349472979:63,Deployability,hotfix,hotfix,63,"Fixed in develop. Question for @katevoss - is this worthy of a hotfix (and if so, should we wait to see if any more WOM issues bubble up in the next few days and patch them all in one go)?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349472979
https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349472979:162,Deployability,patch,patch,162,"Fixed in develop. Question for @katevoss - is this worthy of a hotfix (and if so, should we wait to see if any more WOM issues bubble up in the next few days and patch them all in one go)?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349472979
https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406:498,Availability,echo,echo,498,"Another if-scatter bug.; i built a new `cromwell-31-d716fd2-SNAP.jar` from your `develop` branch.; ```; workflow test {; 	Boolean b0 = true; 	Boolean b1 = true; 	Boolean b2 = true; 	scatter( i in range(3) ) {; 		if ( b0 ) {; 			call t0 as t1 { input: i=i }; 		}; 	}; 	if ( b1 ) {; 		scatter( i in range(3) ) {; 			call t0 as t2 { input: i=t1.out[i] }; 		}; 	}; 	if ( b1 && b2 ) {; 		scatter( i in range(3) ) {; 			call t0 as t3 { input: i=t2.out[i] }; 		}; 	}; }. task t0 {; 	Int? i; 	command {; 		echo ${i}; 	}; 	output {; 		Int out = read_int(stdout()); 	}; }; ```; error log; ```; $ java -jar /users/leepc12/code/cromwell/./target/scala-2.12/cromwell-31-d716fd2-SNAP.jar run test_conditionals_in_cromwell-30.wdl; Picked up _JAVA_OPTIONS: -Xms256M -Xmx1024M -XX:ParallelGCThreads=1; [2017-12-05 20:11:15,13] [info] Running with database db.url = jdbc:hsqldb:mem:7e58cfd2-b9b6-47f9-bda1-6fe045e7a665;shutdown=false;hsqldb.tx=mvcc; [2017-12-05 20:11:21,83] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2017-12-05 20:11:21,84] [info] [RenameWorkflowOptionsInMetadata] 100%; [2017-12-05 20:11:22,02] [info] Running with database db.url = jdbc:hsqldb:mem:e02f9206-cb15-468a-929a-82676a83a9b8;shutdown=false;hsqldb.tx=mvcc; [2017-12-05 20:11:22,47] [info] Slf4jLogger started; [2017-12-05 20:11:22,67] [info] Metadata summary refreshing every 2 seconds.; [2017-12-05 20:11:22,68] [info] Starting health monitor with the following checks: DockerHub, Engine Database; [2017-12-05 20:11:22,69] [info] WriteMetadataActor configured to write to the database with batch size 200 and flush rate 5 seconds.; [2017-12-05 20:11:22,71] [info] CallCacheWriteActor configured to write to the database with batch size 100 and flush rate 3 seconds.; [2017-12-05 20:11:23,78] [info] SingleWorkflowRunnerActor: Submitting workflow; [2017-12-05 20:11:23,82] [info] Workflow 159210e6-fa6a-4a99-b386-5931ae245324 submitted.; [2017-12-05 20:11:23",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406
https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406:568,Availability,error,error,568,"Another if-scatter bug.; i built a new `cromwell-31-d716fd2-SNAP.jar` from your `develop` branch.; ```; workflow test {; 	Boolean b0 = true; 	Boolean b1 = true; 	Boolean b2 = true; 	scatter( i in range(3) ) {; 		if ( b0 ) {; 			call t0 as t1 { input: i=i }; 		}; 	}; 	if ( b1 ) {; 		scatter( i in range(3) ) {; 			call t0 as t2 { input: i=t1.out[i] }; 		}; 	}; 	if ( b1 && b2 ) {; 		scatter( i in range(3) ) {; 			call t0 as t3 { input: i=t2.out[i] }; 		}; 	}; }. task t0 {; 	Int? i; 	command {; 		echo ${i}; 	}; 	output {; 		Int out = read_int(stdout()); 	}; }; ```; error log; ```; $ java -jar /users/leepc12/code/cromwell/./target/scala-2.12/cromwell-31-d716fd2-SNAP.jar run test_conditionals_in_cromwell-30.wdl; Picked up _JAVA_OPTIONS: -Xms256M -Xmx1024M -XX:ParallelGCThreads=1; [2017-12-05 20:11:15,13] [info] Running with database db.url = jdbc:hsqldb:mem:7e58cfd2-b9b6-47f9-bda1-6fe045e7a665;shutdown=false;hsqldb.tx=mvcc; [2017-12-05 20:11:21,83] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2017-12-05 20:11:21,84] [info] [RenameWorkflowOptionsInMetadata] 100%; [2017-12-05 20:11:22,02] [info] Running with database db.url = jdbc:hsqldb:mem:e02f9206-cb15-468a-929a-82676a83a9b8;shutdown=false;hsqldb.tx=mvcc; [2017-12-05 20:11:22,47] [info] Slf4jLogger started; [2017-12-05 20:11:22,67] [info] Metadata summary refreshing every 2 seconds.; [2017-12-05 20:11:22,68] [info] Starting health monitor with the following checks: DockerHub, Engine Database; [2017-12-05 20:11:22,69] [info] WriteMetadataActor configured to write to the database with batch size 200 and flush rate 5 seconds.; [2017-12-05 20:11:22,71] [info] CallCacheWriteActor configured to write to the database with batch size 100 and flush rate 3 seconds.; [2017-12-05 20:11:23,78] [info] SingleWorkflowRunnerActor: Submitting workflow; [2017-12-05 20:11:23,82] [info] Workflow 159210e6-fa6a-4a99-b386-5931ae245324 submitted.; [2017-12-05 20:11:23",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406
https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406:2498,Availability,error,error,2498,"nitor with the following checks: DockerHub, Engine Database; [2017-12-05 20:11:22,69] [info] WriteMetadataActor configured to write to the database with batch size 200 and flush rate 5 seconds.; [2017-12-05 20:11:22,71] [info] CallCacheWriteActor configured to write to the database with batch size 100 and flush rate 3 seconds.; [2017-12-05 20:11:23,78] [info] SingleWorkflowRunnerActor: Submitting workflow; [2017-12-05 20:11:23,82] [info] Workflow 159210e6-fa6a-4a99-b386-5931ae245324 submitted.; [2017-12-05 20:11:23,82] [info] SingleWorkflowRunnerActor: Workflow submitted 159210e6-fa6a-4a99-b386-5931ae245324; [2017-12-05 20:11:23,82] [info] 1 new workflows fetched; [2017-12-05 20:11:23,82] [info] WorkflowManagerActor Starting workflow 159210e6-fa6a-4a99-b386-5931ae245324; [2017-12-05 20:11:23,83] [info] WorkflowManagerActor Successfully started WorkflowActor-159210e6-fa6a-4a99-b386-5931ae245324; [2017-12-05 20:11:23,83] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2017-12-05 20:11:24,82] [error] WorkflowManagerActor Workflow 159210e6-fa6a-4a99-b386-5931ae245324 failed (during MaterializingWorkflowDescriptorState): Workflow input processing failed:; Unable to build WOM node for If '$if_2': Unable to build WOM node for Scatter '$scatter_2': Unable to build WOM node for WdlTaskCall 't3': Can't index (ArrayOrMapLookup:; lhs=(MemberAccess:; lhs=<string:19:29 identifier ""dDI="">,; rhs=<string:19:32 identifier ""b3V0"">; ),; rhs=<string:19:36 identifier ""aQ=="">; ); cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; Unable to build WOM node for If '$if_2': Unable to build WOM node for Scatter '$scatter_2': Unable to build WOM node for WdlTaskCall 't3': Can't index (ArrayOrMapLookup:; lhs=(MemberAccess:; lhs=<string:19:29 identifier ""dDI="">,; rhs=<string:19:32 identifier ""b3V0"">; ),; rhs=<string:19:36 identifier ""aQ=="">; ); at cromwell.engine.workflow.lifecycle.materialization.Materializ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406
https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406:6210,Deployability,configurat,configuration,6210,"ctor.scala:136); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); at akka.actor.ActorCell.invoke(ActorCell.scala:496); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2017-12-05 20:11:24,83] [warn] Couldn't find a suitable DSN, defaulting to a Noop one.; [2017-12-05 20:11:24,84] [info] Using noop to send events.; [2017-12-05 20:11:24,85] [info] WorkflowManagerActor WorkflowActor-159210e6-fa6a-4a99-b386-5931ae245324 is in a terminal state: WorkflowFailedState; [2017-12-05 20:11:32,22] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2017-12-05 20:11:32,25] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2017-12-05 20:11:32,26] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; Workflow 159210e6-fa6a-4a99-b386-5931ae245324 transitioned to state Failed; [2017-12-05 20:11:32,30] [info] Automatic shutdown of the async connection; [2017-12-05 20:11:32,30] [info] Gracefully shutdown sentry threads.; [2017-12-05 20:11:32,30] [info] Shutdown finished.; ```; This code worked with `cromwell-29.jar`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406
https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406:6553,Deployability,configurat,configuration,6553,"ctor.scala:136); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); at akka.actor.ActorCell.invoke(ActorCell.scala:496); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2017-12-05 20:11:24,83] [warn] Couldn't find a suitable DSN, defaulting to a Noop one.; [2017-12-05 20:11:24,84] [info] Using noop to send events.; [2017-12-05 20:11:24,85] [info] WorkflowManagerActor WorkflowActor-159210e6-fa6a-4a99-b386-5931ae245324 is in a terminal state: WorkflowFailedState; [2017-12-05 20:11:32,22] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2017-12-05 20:11:32,25] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2017-12-05 20:11:32,26] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; Workflow 159210e6-fa6a-4a99-b386-5931ae245324 transitioned to state Failed; [2017-12-05 20:11:32,30] [info] Automatic shutdown of the async connection; [2017-12-05 20:11:32,30] [info] Gracefully shutdown sentry threads.; [2017-12-05 20:11:32,30] [info] Shutdown finished.; ```; This code worked with `cromwell-29.jar`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406
https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406:1479,Energy Efficiency,monitor,monitor,1479,"()); 	}; }; ```; error log; ```; $ java -jar /users/leepc12/code/cromwell/./target/scala-2.12/cromwell-31-d716fd2-SNAP.jar run test_conditionals_in_cromwell-30.wdl; Picked up _JAVA_OPTIONS: -Xms256M -Xmx1024M -XX:ParallelGCThreads=1; [2017-12-05 20:11:15,13] [info] Running with database db.url = jdbc:hsqldb:mem:7e58cfd2-b9b6-47f9-bda1-6fe045e7a665;shutdown=false;hsqldb.tx=mvcc; [2017-12-05 20:11:21,83] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2017-12-05 20:11:21,84] [info] [RenameWorkflowOptionsInMetadata] 100%; [2017-12-05 20:11:22,02] [info] Running with database db.url = jdbc:hsqldb:mem:e02f9206-cb15-468a-929a-82676a83a9b8;shutdown=false;hsqldb.tx=mvcc; [2017-12-05 20:11:22,47] [info] Slf4jLogger started; [2017-12-05 20:11:22,67] [info] Metadata summary refreshing every 2 seconds.; [2017-12-05 20:11:22,68] [info] Starting health monitor with the following checks: DockerHub, Engine Database; [2017-12-05 20:11:22,69] [info] WriteMetadataActor configured to write to the database with batch size 200 and flush rate 5 seconds.; [2017-12-05 20:11:22,71] [info] CallCacheWriteActor configured to write to the database with batch size 100 and flush rate 3 seconds.; [2017-12-05 20:11:23,78] [info] SingleWorkflowRunnerActor: Submitting workflow; [2017-12-05 20:11:23,82] [info] Workflow 159210e6-fa6a-4a99-b386-5931ae245324 submitted.; [2017-12-05 20:11:23,82] [info] SingleWorkflowRunnerActor: Workflow submitted 159210e6-fa6a-4a99-b386-5931ae245324; [2017-12-05 20:11:23,82] [info] 1 new workflows fetched; [2017-12-05 20:11:23,82] [info] WorkflowManagerActor Starting workflow 159210e6-fa6a-4a99-b386-5931ae245324; [2017-12-05 20:11:23,83] [info] WorkflowManagerActor Successfully started WorkflowActor-159210e6-fa6a-4a99-b386-5931ae245324; [2017-12-05 20:11:23,83] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2017-12-05 20:11:24,82] [error] WorkflowManagerActor Workflow 159210e6-fa6a-4a9",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406
https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406:5992,Integrability,Message,Message,5992,"ctor.scala:136); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); at akka.actor.ActorCell.invoke(ActorCell.scala:496); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2017-12-05 20:11:24,83] [warn] Couldn't find a suitable DSN, defaulting to a Noop one.; [2017-12-05 20:11:24,84] [info] Using noop to send events.; [2017-12-05 20:11:24,85] [info] WorkflowManagerActor WorkflowActor-159210e6-fa6a-4a99-b386-5931ae245324 is in a terminal state: WorkflowFailedState; [2017-12-05 20:11:32,22] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2017-12-05 20:11:32,25] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2017-12-05 20:11:32,26] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; Workflow 159210e6-fa6a-4a99-b386-5931ae245324 transitioned to state Failed; [2017-12-05 20:11:32,30] [info] Automatic shutdown of the async connection; [2017-12-05 20:11:32,30] [info] Gracefully shutdown sentry threads.; [2017-12-05 20:11:32,30] [info] Shutdown finished.; ```; This code worked with `cromwell-29.jar`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406
https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406:6335,Integrability,Message,Message,6335,"ctor.scala:136); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); at akka.actor.ActorCell.invoke(ActorCell.scala:496); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2017-12-05 20:11:24,83] [warn] Couldn't find a suitable DSN, defaulting to a Noop one.; [2017-12-05 20:11:24,84] [info] Using noop to send events.; [2017-12-05 20:11:24,85] [info] WorkflowManagerActor WorkflowActor-159210e6-fa6a-4a99-b386-5931ae245324 is in a terminal state: WorkflowFailedState; [2017-12-05 20:11:32,22] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2017-12-05 20:11:32,25] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2017-12-05 20:11:32,26] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; Workflow 159210e6-fa6a-4a99-b386-5931ae245324 transitioned to state Failed; [2017-12-05 20:11:32,30] [info] Automatic shutdown of the async connection; [2017-12-05 20:11:32,30] [info] Gracefully shutdown sentry threads.; [2017-12-05 20:11:32,30] [info] Shutdown finished.; ```; This code worked with `cromwell-29.jar`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406
https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406:1593,Modifiability,config,configured,1593,"()); 	}; }; ```; error log; ```; $ java -jar /users/leepc12/code/cromwell/./target/scala-2.12/cromwell-31-d716fd2-SNAP.jar run test_conditionals_in_cromwell-30.wdl; Picked up _JAVA_OPTIONS: -Xms256M -Xmx1024M -XX:ParallelGCThreads=1; [2017-12-05 20:11:15,13] [info] Running with database db.url = jdbc:hsqldb:mem:7e58cfd2-b9b6-47f9-bda1-6fe045e7a665;shutdown=false;hsqldb.tx=mvcc; [2017-12-05 20:11:21,83] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2017-12-05 20:11:21,84] [info] [RenameWorkflowOptionsInMetadata] 100%; [2017-12-05 20:11:22,02] [info] Running with database db.url = jdbc:hsqldb:mem:e02f9206-cb15-468a-929a-82676a83a9b8;shutdown=false;hsqldb.tx=mvcc; [2017-12-05 20:11:22,47] [info] Slf4jLogger started; [2017-12-05 20:11:22,67] [info] Metadata summary refreshing every 2 seconds.; [2017-12-05 20:11:22,68] [info] Starting health monitor with the following checks: DockerHub, Engine Database; [2017-12-05 20:11:22,69] [info] WriteMetadataActor configured to write to the database with batch size 200 and flush rate 5 seconds.; [2017-12-05 20:11:22,71] [info] CallCacheWriteActor configured to write to the database with batch size 100 and flush rate 3 seconds.; [2017-12-05 20:11:23,78] [info] SingleWorkflowRunnerActor: Submitting workflow; [2017-12-05 20:11:23,82] [info] Workflow 159210e6-fa6a-4a99-b386-5931ae245324 submitted.; [2017-12-05 20:11:23,82] [info] SingleWorkflowRunnerActor: Workflow submitted 159210e6-fa6a-4a99-b386-5931ae245324; [2017-12-05 20:11:23,82] [info] 1 new workflows fetched; [2017-12-05 20:11:23,82] [info] WorkflowManagerActor Starting workflow 159210e6-fa6a-4a99-b386-5931ae245324; [2017-12-05 20:11:23,83] [info] WorkflowManagerActor Successfully started WorkflowActor-159210e6-fa6a-4a99-b386-5931ae245324; [2017-12-05 20:11:23,83] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2017-12-05 20:11:24,82] [error] WorkflowManagerActor Workflow 159210e6-fa6a-4a9",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406
https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406:1728,Modifiability,config,configured,1728,"-Xms256M -Xmx1024M -XX:ParallelGCThreads=1; [2017-12-05 20:11:15,13] [info] Running with database db.url = jdbc:hsqldb:mem:7e58cfd2-b9b6-47f9-bda1-6fe045e7a665;shutdown=false;hsqldb.tx=mvcc; [2017-12-05 20:11:21,83] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2017-12-05 20:11:21,84] [info] [RenameWorkflowOptionsInMetadata] 100%; [2017-12-05 20:11:22,02] [info] Running with database db.url = jdbc:hsqldb:mem:e02f9206-cb15-468a-929a-82676a83a9b8;shutdown=false;hsqldb.tx=mvcc; [2017-12-05 20:11:22,47] [info] Slf4jLogger started; [2017-12-05 20:11:22,67] [info] Metadata summary refreshing every 2 seconds.; [2017-12-05 20:11:22,68] [info] Starting health monitor with the following checks: DockerHub, Engine Database; [2017-12-05 20:11:22,69] [info] WriteMetadataActor configured to write to the database with batch size 200 and flush rate 5 seconds.; [2017-12-05 20:11:22,71] [info] CallCacheWriteActor configured to write to the database with batch size 100 and flush rate 3 seconds.; [2017-12-05 20:11:23,78] [info] SingleWorkflowRunnerActor: Submitting workflow; [2017-12-05 20:11:23,82] [info] Workflow 159210e6-fa6a-4a99-b386-5931ae245324 submitted.; [2017-12-05 20:11:23,82] [info] SingleWorkflowRunnerActor: Workflow submitted 159210e6-fa6a-4a99-b386-5931ae245324; [2017-12-05 20:11:23,82] [info] 1 new workflows fetched; [2017-12-05 20:11:23,82] [info] WorkflowManagerActor Starting workflow 159210e6-fa6a-4a99-b386-5931ae245324; [2017-12-05 20:11:23,83] [info] WorkflowManagerActor Successfully started WorkflowActor-159210e6-fa6a-4a99-b386-5931ae245324; [2017-12-05 20:11:23,83] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2017-12-05 20:11:24,82] [error] WorkflowManagerActor Workflow 159210e6-fa6a-4a99-b386-5931ae245324 failed (during MaterializingWorkflowDescriptorState): Workflow input processing failed:; Unable to build WOM node for If '$if_2': Unable to build WOM node for Scatter '$s",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406
https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406:6210,Modifiability,config,configuration,6210,"ctor.scala:136); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); at akka.actor.ActorCell.invoke(ActorCell.scala:496); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2017-12-05 20:11:24,83] [warn] Couldn't find a suitable DSN, defaulting to a Noop one.; [2017-12-05 20:11:24,84] [info] Using noop to send events.; [2017-12-05 20:11:24,85] [info] WorkflowManagerActor WorkflowActor-159210e6-fa6a-4a99-b386-5931ae245324 is in a terminal state: WorkflowFailedState; [2017-12-05 20:11:32,22] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2017-12-05 20:11:32,25] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2017-12-05 20:11:32,26] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; Workflow 159210e6-fa6a-4a99-b386-5931ae245324 transitioned to state Failed; [2017-12-05 20:11:32,30] [info] Automatic shutdown of the async connection; [2017-12-05 20:11:32,30] [info] Gracefully shutdown sentry threads.; [2017-12-05 20:11:32,30] [info] Shutdown finished.; ```; This code worked with `cromwell-29.jar`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406
https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406:6553,Modifiability,config,configuration,6553,"ctor.scala:136); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); at akka.actor.ActorCell.invoke(ActorCell.scala:496); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2017-12-05 20:11:24,83] [warn] Couldn't find a suitable DSN, defaulting to a Noop one.; [2017-12-05 20:11:24,84] [info] Using noop to send events.; [2017-12-05 20:11:24,85] [info] WorkflowManagerActor WorkflowActor-159210e6-fa6a-4a99-b386-5931ae245324 is in a terminal state: WorkflowFailedState; [2017-12-05 20:11:32,22] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2017-12-05 20:11:32,25] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2017-12-05 20:11:32,26] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; Workflow 159210e6-fa6a-4a99-b386-5931ae245324 transitioned to state Failed; [2017-12-05 20:11:32,30] [info] Automatic shutdown of the async connection; [2017-12-05 20:11:32,30] [info] Gracefully shutdown sentry threads.; [2017-12-05 20:11:32,30] [info] Shutdown finished.; ```; This code worked with `cromwell-29.jar`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406
https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406:113,Testability,test,test,113,"Another if-scatter bug.; i built a new `cromwell-31-d716fd2-SNAP.jar` from your `develop` branch.; ```; workflow test {; 	Boolean b0 = true; 	Boolean b1 = true; 	Boolean b2 = true; 	scatter( i in range(3) ) {; 		if ( b0 ) {; 			call t0 as t1 { input: i=i }; 		}; 	}; 	if ( b1 ) {; 		scatter( i in range(3) ) {; 			call t0 as t2 { input: i=t1.out[i] }; 		}; 	}; 	if ( b1 && b2 ) {; 		scatter( i in range(3) ) {; 			call t0 as t3 { input: i=t2.out[i] }; 		}; 	}; }. task t0 {; 	Int? i; 	command {; 		echo ${i}; 	}; 	output {; 		Int out = read_int(stdout()); 	}; }; ```; error log; ```; $ java -jar /users/leepc12/code/cromwell/./target/scala-2.12/cromwell-31-d716fd2-SNAP.jar run test_conditionals_in_cromwell-30.wdl; Picked up _JAVA_OPTIONS: -Xms256M -Xmx1024M -XX:ParallelGCThreads=1; [2017-12-05 20:11:15,13] [info] Running with database db.url = jdbc:hsqldb:mem:7e58cfd2-b9b6-47f9-bda1-6fe045e7a665;shutdown=false;hsqldb.tx=mvcc; [2017-12-05 20:11:21,83] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2017-12-05 20:11:21,84] [info] [RenameWorkflowOptionsInMetadata] 100%; [2017-12-05 20:11:22,02] [info] Running with database db.url = jdbc:hsqldb:mem:e02f9206-cb15-468a-929a-82676a83a9b8;shutdown=false;hsqldb.tx=mvcc; [2017-12-05 20:11:22,47] [info] Slf4jLogger started; [2017-12-05 20:11:22,67] [info] Metadata summary refreshing every 2 seconds.; [2017-12-05 20:11:22,68] [info] Starting health monitor with the following checks: DockerHub, Engine Database; [2017-12-05 20:11:22,69] [info] WriteMetadataActor configured to write to the database with batch size 200 and flush rate 5 seconds.; [2017-12-05 20:11:22,71] [info] CallCacheWriteActor configured to write to the database with batch size 100 and flush rate 3 seconds.; [2017-12-05 20:11:23,78] [info] SingleWorkflowRunnerActor: Submitting workflow; [2017-12-05 20:11:23,82] [info] Workflow 159210e6-fa6a-4a99-b386-5931ae245324 submitted.; [2017-12-05 20:11:23",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406
https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406:574,Testability,log,log,574,"Another if-scatter bug.; i built a new `cromwell-31-d716fd2-SNAP.jar` from your `develop` branch.; ```; workflow test {; 	Boolean b0 = true; 	Boolean b1 = true; 	Boolean b2 = true; 	scatter( i in range(3) ) {; 		if ( b0 ) {; 			call t0 as t1 { input: i=i }; 		}; 	}; 	if ( b1 ) {; 		scatter( i in range(3) ) {; 			call t0 as t2 { input: i=t1.out[i] }; 		}; 	}; 	if ( b1 && b2 ) {; 		scatter( i in range(3) ) {; 			call t0 as t3 { input: i=t2.out[i] }; 		}; 	}; }. task t0 {; 	Int? i; 	command {; 		echo ${i}; 	}; 	output {; 		Int out = read_int(stdout()); 	}; }; ```; error log; ```; $ java -jar /users/leepc12/code/cromwell/./target/scala-2.12/cromwell-31-d716fd2-SNAP.jar run test_conditionals_in_cromwell-30.wdl; Picked up _JAVA_OPTIONS: -Xms256M -Xmx1024M -XX:ParallelGCThreads=1; [2017-12-05 20:11:15,13] [info] Running with database db.url = jdbc:hsqldb:mem:7e58cfd2-b9b6-47f9-bda1-6fe045e7a665;shutdown=false;hsqldb.tx=mvcc; [2017-12-05 20:11:21,83] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2017-12-05 20:11:21,84] [info] [RenameWorkflowOptionsInMetadata] 100%; [2017-12-05 20:11:22,02] [info] Running with database db.url = jdbc:hsqldb:mem:e02f9206-cb15-468a-929a-82676a83a9b8;shutdown=false;hsqldb.tx=mvcc; [2017-12-05 20:11:22,47] [info] Slf4jLogger started; [2017-12-05 20:11:22,67] [info] Metadata summary refreshing every 2 seconds.; [2017-12-05 20:11:22,68] [info] Starting health monitor with the following checks: DockerHub, Engine Database; [2017-12-05 20:11:22,69] [info] WriteMetadataActor configured to write to the database with batch size 200 and flush rate 5 seconds.; [2017-12-05 20:11:22,71] [info] CallCacheWriteActor configured to write to the database with batch size 100 and flush rate 3 seconds.; [2017-12-05 20:11:23,78] [info] SingleWorkflowRunnerActor: Submitting workflow; [2017-12-05 20:11:23,82] [info] Workflow 159210e6-fa6a-4a99-b386-5931ae245324 submitted.; [2017-12-05 20:11:23",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406
https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406:4264,Testability,Log,LoggingFSM,4264,"s:; lhs=<string:19:29 identifier ""dDI="">,; rhs=<string:19:32 identifier ""b3V0"">; ),; rhs=<string:19:36 identifier ""aQ=="">; ); at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$workflowInitializationFailed(MaterializeWorkflowDescriptorActor.scala:211); at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:181); at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:176); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); at akka.actor.FSM.processEvent(FSM.scala:665); at akka.actor.FSM.processEvent$(FSM.scala:662); at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:136); at akka.actor.LoggingFSM.processEvent(FSM.scala:801); at akka.actor.LoggingFSM.processEvent$(FSM.scala:783); at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.processEvent(MaterializeWorkflowDescriptorActor.scala:136); at akka.actor.FSM.akka$actor$FSM$$processMsg(FSM.scala:659); at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:653); at akka.actor.Actor.aroundReceive(Actor.scala:514); at akka.actor.Actor.aroundReceive$(Actor.scala:512); at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:136); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); at akka.actor.ActorCell.invoke(ActorCell.scala:496); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at akka.dispatch.forkjoin.ForkJoinTask",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406
https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406:4356,Testability,Log,LoggingFSM,4356,"r ""b3V0"">; ),; rhs=<string:19:36 identifier ""aQ=="">; ); at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$workflowInitializationFailed(MaterializeWorkflowDescriptorActor.scala:211); at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:181); at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:176); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); at akka.actor.FSM.processEvent(FSM.scala:665); at akka.actor.FSM.processEvent$(FSM.scala:662); at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:136); at akka.actor.LoggingFSM.processEvent(FSM.scala:801); at akka.actor.LoggingFSM.processEvent$(FSM.scala:783); at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.processEvent(MaterializeWorkflowDescriptorActor.scala:136); at akka.actor.FSM.akka$actor$FSM$$processMsg(FSM.scala:659); at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:653); at akka.actor.Actor.aroundReceive(Actor.scala:514); at akka.actor.Actor.aroundReceive$(Actor.scala:512); at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:136); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); at akka.actor.ActorCell.invoke(ActorCell.scala:496); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406
https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406:4410,Testability,Log,LoggingFSM,4410,; at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$workflowInitializationFailed(MaterializeWorkflowDescriptorActor.scala:211); at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:181); at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:176); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); at akka.actor.FSM.processEvent(FSM.scala:665); at akka.actor.FSM.processEvent$(FSM.scala:662); at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:136); at akka.actor.LoggingFSM.processEvent(FSM.scala:801); at akka.actor.LoggingFSM.processEvent$(FSM.scala:783); at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.processEvent(MaterializeWorkflowDescriptorActor.scala:136); at akka.actor.FSM.akka$actor$FSM$$processMsg(FSM.scala:659); at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:653); at akka.actor.Actor.aroundReceive(Actor.scala:514); at akka.actor.Actor.aroundReceive$(Actor.scala:512); at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:136); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); at akka.actor.ActorCell.invoke(ActorCell.scala:496); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.di,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406
https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406:6167,Testability,log,logging,6167,"ctor.scala:136); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); at akka.actor.ActorCell.invoke(ActorCell.scala:496); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2017-12-05 20:11:24,83] [warn] Couldn't find a suitable DSN, defaulting to a Noop one.; [2017-12-05 20:11:24,84] [info] Using noop to send events.; [2017-12-05 20:11:24,85] [info] WorkflowManagerActor WorkflowActor-159210e6-fa6a-4a99-b386-5931ae245324 is in a terminal state: WorkflowFailedState; [2017-12-05 20:11:32,22] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2017-12-05 20:11:32,25] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2017-12-05 20:11:32,26] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; Workflow 159210e6-fa6a-4a99-b386-5931ae245324 transitioned to state Failed; [2017-12-05 20:11:32,30] [info] Automatic shutdown of the async connection; [2017-12-05 20:11:32,30] [info] Gracefully shutdown sentry threads.; [2017-12-05 20:11:32,30] [info] Shutdown finished.; ```; This code worked with `cromwell-29.jar`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406
https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406:6239,Testability,log,log-dead-letters,6239,"ctor.scala:136); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); at akka.actor.ActorCell.invoke(ActorCell.scala:496); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2017-12-05 20:11:24,83] [warn] Couldn't find a suitable DSN, defaulting to a Noop one.; [2017-12-05 20:11:24,84] [info] Using noop to send events.; [2017-12-05 20:11:24,85] [info] WorkflowManagerActor WorkflowActor-159210e6-fa6a-4a99-b386-5931ae245324 is in a terminal state: WorkflowFailedState; [2017-12-05 20:11:32,22] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2017-12-05 20:11:32,25] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2017-12-05 20:11:32,26] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; Workflow 159210e6-fa6a-4a99-b386-5931ae245324 transitioned to state Failed; [2017-12-05 20:11:32,30] [info] Automatic shutdown of the async connection; [2017-12-05 20:11:32,30] [info] Gracefully shutdown sentry threads.; [2017-12-05 20:11:32,30] [info] Shutdown finished.; ```; This code worked with `cromwell-29.jar`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406
https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406:6267,Testability,log,log-dead-letters-during-shutdown,6267,"ctor.scala:136); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); at akka.actor.ActorCell.invoke(ActorCell.scala:496); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2017-12-05 20:11:24,83] [warn] Couldn't find a suitable DSN, defaulting to a Noop one.; [2017-12-05 20:11:24,84] [info] Using noop to send events.; [2017-12-05 20:11:24,85] [info] WorkflowManagerActor WorkflowActor-159210e6-fa6a-4a99-b386-5931ae245324 is in a terminal state: WorkflowFailedState; [2017-12-05 20:11:32,22] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2017-12-05 20:11:32,25] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2017-12-05 20:11:32,26] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; Workflow 159210e6-fa6a-4a99-b386-5931ae245324 transitioned to state Failed; [2017-12-05 20:11:32,30] [info] Automatic shutdown of the async connection; [2017-12-05 20:11:32,30] [info] Gracefully shutdown sentry threads.; [2017-12-05 20:11:32,30] [info] Shutdown finished.; ```; This code worked with `cromwell-29.jar`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406
https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406:6510,Testability,log,logging,6510,"ctor.scala:136); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); at akka.actor.ActorCell.invoke(ActorCell.scala:496); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2017-12-05 20:11:24,83] [warn] Couldn't find a suitable DSN, defaulting to a Noop one.; [2017-12-05 20:11:24,84] [info] Using noop to send events.; [2017-12-05 20:11:24,85] [info] WorkflowManagerActor WorkflowActor-159210e6-fa6a-4a99-b386-5931ae245324 is in a terminal state: WorkflowFailedState; [2017-12-05 20:11:32,22] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2017-12-05 20:11:32,25] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2017-12-05 20:11:32,26] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; Workflow 159210e6-fa6a-4a99-b386-5931ae245324 transitioned to state Failed; [2017-12-05 20:11:32,30] [info] Automatic shutdown of the async connection; [2017-12-05 20:11:32,30] [info] Gracefully shutdown sentry threads.; [2017-12-05 20:11:32,30] [info] Shutdown finished.; ```; This code worked with `cromwell-29.jar`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406
https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406:6582,Testability,log,log-dead-letters,6582,"ctor.scala:136); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); at akka.actor.ActorCell.invoke(ActorCell.scala:496); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2017-12-05 20:11:24,83] [warn] Couldn't find a suitable DSN, defaulting to a Noop one.; [2017-12-05 20:11:24,84] [info] Using noop to send events.; [2017-12-05 20:11:24,85] [info] WorkflowManagerActor WorkflowActor-159210e6-fa6a-4a99-b386-5931ae245324 is in a terminal state: WorkflowFailedState; [2017-12-05 20:11:32,22] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2017-12-05 20:11:32,25] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2017-12-05 20:11:32,26] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; Workflow 159210e6-fa6a-4a99-b386-5931ae245324 transitioned to state Failed; [2017-12-05 20:11:32,30] [info] Automatic shutdown of the async connection; [2017-12-05 20:11:32,30] [info] Gracefully shutdown sentry threads.; [2017-12-05 20:11:32,30] [info] Shutdown finished.; ```; This code worked with `cromwell-29.jar`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406
https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406:6610,Testability,log,log-dead-letters-during-shutdown,6610,"ctor.scala:136); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); at akka.actor.ActorCell.invoke(ActorCell.scala:496); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2017-12-05 20:11:24,83] [warn] Couldn't find a suitable DSN, defaulting to a Noop one.; [2017-12-05 20:11:24,84] [info] Using noop to send events.; [2017-12-05 20:11:24,85] [info] WorkflowManagerActor WorkflowActor-159210e6-fa6a-4a99-b386-5931ae245324 is in a terminal state: WorkflowFailedState; [2017-12-05 20:11:32,22] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2017-12-05 20:11:32,25] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2017-12-05 20:11:32,26] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; Workflow 159210e6-fa6a-4a99-b386-5931ae245324 transitioned to state Failed; [2017-12-05 20:11:32,30] [info] Automatic shutdown of the async connection; [2017-12-05 20:11:32,30] [info] Gracefully shutdown sentry threads.; [2017-12-05 20:11:32,30] [info] Shutdown finished.; ```; This code worked with `cromwell-29.jar`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992#issuecomment-349527406
https://github.com/broadinstitute/cromwell/pull/2994#issuecomment-349443629:92,Testability,test,tests,92,"I was going to say ""rebase on `develop` to unredden TES"". Unfortunately the CWL conformance tests are also red (and since we ignore the results right now, that means they are failing to run at all, I believe)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2994#issuecomment-349443629
https://github.com/broadinstitute/cromwell/pull/2994#issuecomment-349461963:144,Testability,test,tests,144,"Aha, [a week ago](https://github.com/common-workflow-language/common-workflow-language/commit/915d49f8fb912774cbf5cbe6ba910a430ef69941) 100% of tests were moved under the `v1.0` directory. So this ""fix"" should now work!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2994#issuecomment-349461963
https://github.com/broadinstitute/cromwell/issues/3007#issuecomment-349689182:89,Availability,fault,fault,89,"Hey @leepc12 it turns out that you do have a bug in your WDL and that Cromwell 29 was at fault for not highlighting it too. I'll submit a PR to include a better error message, which will be along the lines of:; ```; Unable to build WOM node for If '$if_2': Unable to build WOM node for Scatter '$scatter_2': Unable to build WOM node for WdlTaskCall 't3': Invalid indexing target. You cannot index a value of type'Array[Int]?'; ```. Notice that in order to access `t2.out` you're looking up inside another `if` block, which means that the output has to be treated as optional. . - Given the structure of *this* workflow you could move the `if ( b1 && b2 )` inside the `if (b1)` (and simplify the conditional expression). ; - If that's not possible in your real workflow you can use `select_first` to get the value out, eg `call t0 as t3 { input: i=select_first([t2.out])[i] }` (NB this is only valid because `if (b1 && b2)` implies `if (b1)` must have been run, so the `select_first` is known to succeed)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3007#issuecomment-349689182
https://github.com/broadinstitute/cromwell/issues/3007#issuecomment-349689182:161,Availability,error,error,161,"Hey @leepc12 it turns out that you do have a bug in your WDL and that Cromwell 29 was at fault for not highlighting it too. I'll submit a PR to include a better error message, which will be along the lines of:; ```; Unable to build WOM node for If '$if_2': Unable to build WOM node for Scatter '$scatter_2': Unable to build WOM node for WdlTaskCall 't3': Invalid indexing target. You cannot index a value of type'Array[Int]?'; ```. Notice that in order to access `t2.out` you're looking up inside another `if` block, which means that the output has to be treated as optional. . - Given the structure of *this* workflow you could move the `if ( b1 && b2 )` inside the `if (b1)` (and simplify the conditional expression). ; - If that's not possible in your real workflow you can use `select_first` to get the value out, eg `call t0 as t3 { input: i=select_first([t2.out])[i] }` (NB this is only valid because `if (b1 && b2)` implies `if (b1)` must have been run, so the `select_first` is known to succeed)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3007#issuecomment-349689182
https://github.com/broadinstitute/cromwell/issues/3007#issuecomment-349689182:167,Integrability,message,message,167,"Hey @leepc12 it turns out that you do have a bug in your WDL and that Cromwell 29 was at fault for not highlighting it too. I'll submit a PR to include a better error message, which will be along the lines of:; ```; Unable to build WOM node for If '$if_2': Unable to build WOM node for Scatter '$scatter_2': Unable to build WOM node for WdlTaskCall 't3': Invalid indexing target. You cannot index a value of type'Array[Int]?'; ```. Notice that in order to access `t2.out` you're looking up inside another `if` block, which means that the output has to be treated as optional. . - Given the structure of *this* workflow you could move the `if ( b1 && b2 )` inside the `if (b1)` (and simplify the conditional expression). ; - If that's not possible in your real workflow you can use `select_first` to get the value out, eg `call t0 as t3 { input: i=select_first([t2.out])[i] }` (NB this is only valid because `if (b1 && b2)` implies `if (b1)` must have been run, so the `select_first` is known to succeed)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3007#issuecomment-349689182
https://github.com/broadinstitute/cromwell/issues/3007#issuecomment-349689182:456,Security,access,access,456,"Hey @leepc12 it turns out that you do have a bug in your WDL and that Cromwell 29 was at fault for not highlighting it too. I'll submit a PR to include a better error message, which will be along the lines of:; ```; Unable to build WOM node for If '$if_2': Unable to build WOM node for Scatter '$scatter_2': Unable to build WOM node for WdlTaskCall 't3': Invalid indexing target. You cannot index a value of type'Array[Int]?'; ```. Notice that in order to access `t2.out` you're looking up inside another `if` block, which means that the output has to be treated as optional. . - Given the structure of *this* workflow you could move the `if ( b1 && b2 )` inside the `if (b1)` (and simplify the conditional expression). ; - If that's not possible in your real workflow you can use `select_first` to get the value out, eg `call t0 as t3 { input: i=select_first([t2.out])[i] }` (NB this is only valid because `if (b1 && b2)` implies `if (b1)` must have been run, so the `select_first` is known to succeed)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3007#issuecomment-349689182
https://github.com/broadinstitute/cromwell/issues/3007#issuecomment-349689182:682,Usability,simpl,simplify,682,"Hey @leepc12 it turns out that you do have a bug in your WDL and that Cromwell 29 was at fault for not highlighting it too. I'll submit a PR to include a better error message, which will be along the lines of:; ```; Unable to build WOM node for If '$if_2': Unable to build WOM node for Scatter '$scatter_2': Unable to build WOM node for WdlTaskCall 't3': Invalid indexing target. You cannot index a value of type'Array[Int]?'; ```. Notice that in order to access `t2.out` you're looking up inside another `if` block, which means that the output has to be treated as optional. . - Given the structure of *this* workflow you could move the `if ( b1 && b2 )` inside the `if (b1)` (and simplify the conditional expression). ; - If that's not possible in your real workflow you can use `select_first` to get the value out, eg `call t0 as t3 { input: i=select_first([t2.out])[i] }` (NB this is only valid because `if (b1 && b2)` implies `if (b1)` must have been run, so the `select_first` is known to succeed)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3007#issuecomment-349689182
https://github.com/broadinstitute/cromwell/issues/3012#issuecomment-377570787:4,Availability,error,error,4,"The error is different nowadays and apparently downstream of the fail. The underlying issue appears to be with not hydrating a `WomMaybePopulatedFile` output from a dependent job on restart: . ```; java.lang.UnsupportedOperationException: value is not available: WomMaybePopulatedFile(None,None,None,None,None,List()); 	at wom.values.WomMaybePopulatedFile.$anonfun$value$2(WomFile.scala:244); 	at scala.Option.getOrElse(Option.scala:121); 	at wom.values.WomMaybePopulatedFile.value(WomFile.scala:244); 	at cwl.internal.EcmaScriptEncoder.encodeFile(EcmaScriptEncoder.scala:102); 	at cwl.internal.EcmaScriptEncoder.encodeFileOrDirectory(EcmaScriptEncoder.scala:90); 	at cwl.internal.EcmaScriptEncoder.encode(EcmaScriptEncoder.scala:39); 	at cwl.internal.EcmaScriptUtil$.$anonfun$evalStructish$3(EcmaScriptUtil.scala:105); 	at scala.collection.MapLike$MappedValues.$anonfun$foreach$3(MapLike.scala:253); 	at scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:789); 	at scala.collection.immutable.Map$Map2.foreach(Map.scala:146); 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:788); 	at scala.collection.MapLike$MappedValues.foreach(MapLike.scala:253); 	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:59); 	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:50); 	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:186); 	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:44); 	at scala.collection.TraversableLike.to(TraversableLike.scala:590); 	at scala.collection.TraversableLike.to$(TraversableLike.scala:587); 	at scala.collection.AbstractTraversable.to(Traversable.scala:104); 	at scala.collection.TraversableOnce.toList(TraversableOnce.scala:294); 	at scala.collection.TraversableOnce.toList$(TraversableOnce.scala:294); 	at scala.collection.AbstractTraversable.toList(Traversable.scala:104); 	at cwl.internal.EcmaScriptUtil$.$anonfun$evalStructish$4(EcmaScrip",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3012#issuecomment-377570787
https://github.com/broadinstitute/cromwell/issues/3012#issuecomment-377570787:47,Availability,down,downstream,47,"The error is different nowadays and apparently downstream of the fail. The underlying issue appears to be with not hydrating a `WomMaybePopulatedFile` output from a dependent job on restart: . ```; java.lang.UnsupportedOperationException: value is not available: WomMaybePopulatedFile(None,None,None,None,None,List()); 	at wom.values.WomMaybePopulatedFile.$anonfun$value$2(WomFile.scala:244); 	at scala.Option.getOrElse(Option.scala:121); 	at wom.values.WomMaybePopulatedFile.value(WomFile.scala:244); 	at cwl.internal.EcmaScriptEncoder.encodeFile(EcmaScriptEncoder.scala:102); 	at cwl.internal.EcmaScriptEncoder.encodeFileOrDirectory(EcmaScriptEncoder.scala:90); 	at cwl.internal.EcmaScriptEncoder.encode(EcmaScriptEncoder.scala:39); 	at cwl.internal.EcmaScriptUtil$.$anonfun$evalStructish$3(EcmaScriptUtil.scala:105); 	at scala.collection.MapLike$MappedValues.$anonfun$foreach$3(MapLike.scala:253); 	at scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:789); 	at scala.collection.immutable.Map$Map2.foreach(Map.scala:146); 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:788); 	at scala.collection.MapLike$MappedValues.foreach(MapLike.scala:253); 	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:59); 	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:50); 	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:186); 	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:44); 	at scala.collection.TraversableLike.to(TraversableLike.scala:590); 	at scala.collection.TraversableLike.to$(TraversableLike.scala:587); 	at scala.collection.AbstractTraversable.to(Traversable.scala:104); 	at scala.collection.TraversableOnce.toList(TraversableOnce.scala:294); 	at scala.collection.TraversableOnce.toList$(TraversableOnce.scala:294); 	at scala.collection.AbstractTraversable.toList(Traversable.scala:104); 	at cwl.internal.EcmaScriptUtil$.$anonfun$evalStructish$4(EcmaScrip",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3012#issuecomment-377570787
https://github.com/broadinstitute/cromwell/issues/3012#issuecomment-377570787:252,Availability,avail,available,252,"The error is different nowadays and apparently downstream of the fail. The underlying issue appears to be with not hydrating a `WomMaybePopulatedFile` output from a dependent job on restart: . ```; java.lang.UnsupportedOperationException: value is not available: WomMaybePopulatedFile(None,None,None,None,None,List()); 	at wom.values.WomMaybePopulatedFile.$anonfun$value$2(WomFile.scala:244); 	at scala.Option.getOrElse(Option.scala:121); 	at wom.values.WomMaybePopulatedFile.value(WomFile.scala:244); 	at cwl.internal.EcmaScriptEncoder.encodeFile(EcmaScriptEncoder.scala:102); 	at cwl.internal.EcmaScriptEncoder.encodeFileOrDirectory(EcmaScriptEncoder.scala:90); 	at cwl.internal.EcmaScriptEncoder.encode(EcmaScriptEncoder.scala:39); 	at cwl.internal.EcmaScriptUtil$.$anonfun$evalStructish$3(EcmaScriptUtil.scala:105); 	at scala.collection.MapLike$MappedValues.$anonfun$foreach$3(MapLike.scala:253); 	at scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:789); 	at scala.collection.immutable.Map$Map2.foreach(Map.scala:146); 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:788); 	at scala.collection.MapLike$MappedValues.foreach(MapLike.scala:253); 	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:59); 	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:50); 	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:186); 	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:44); 	at scala.collection.TraversableLike.to(TraversableLike.scala:590); 	at scala.collection.TraversableLike.to$(TraversableLike.scala:587); 	at scala.collection.AbstractTraversable.to(Traversable.scala:104); 	at scala.collection.TraversableOnce.toList(TraversableOnce.scala:294); 	at scala.collection.TraversableOnce.toList$(TraversableOnce.scala:294); 	at scala.collection.AbstractTraversable.toList(Traversable.scala:104); 	at cwl.internal.EcmaScriptUtil$.$anonfun$evalStructish$4(EcmaScrip",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3012#issuecomment-377570787
https://github.com/broadinstitute/cromwell/issues/3012#issuecomment-377570787:4182,Availability,Error,ErrorOr,4182,at scala.collection.MapLike$MappedValues.foreach(MapLike.scala:253); 	at cwl.internal.EcmaScriptUtil$.$anonfun$evalStructish$1(EcmaScriptUtil.scala:107); 	at cwl.internal.EcmaScriptUtil$.$anonfun$evalStructish$1$adapted(EcmaScriptUtil.scala:97); 	at cwl.internal.EnhancedRhinoSandbox.eval(EnhancedRhinoSandbox.scala:61); 	at cwl.internal.EcmaScriptUtil$.evalRaw(EcmaScriptUtil.scala:69); 	at cwl.internal.EcmaScriptUtil$.evalStructish(EcmaScriptUtil.scala:97); 	at cwl.ExpressionEvaluator$.eval(ExpressionEvaluator.scala:76); 	at cwl.ExpressionEvaluator$.evaluator$1(ExpressionEvaluator.scala:40); 	at cwl.ExpressionEvaluator$.$anonfun$evalExpression$1(ExpressionEvaluator.scala:43); 	at cwl.ExpressionInterpolator$.interpolate(ExpressionInterpolator.scala:140); 	at cwl.ExpressionEvaluator$.evalExpression(ExpressionEvaluator.scala:43); 	at cwl.EvaluateExpression$.$anonfun$script$2(EvaluateExpression.scala:11); 	at cwl.ExpressionEvaluator$.eval(ExpressionEvaluator.scala:35); 	at cwl.CommandLineBindingCommandPart.$anonfun$instantiate$5(CwlExpressionCommandPart.scala:79); 	at scala.Option.flatMap(Option.scala:171); 	at cwl.CommandLineBindingCommandPart.instantiate(CwlExpressionCommandPart.scala:78); 	at wom.callable.CommandTaskDefinition.$anonfun$instantiateCommand$3(CommandTaskDefinition.scala:109); 	at scala.collection.immutable.List.flatMap(List.scala:335); 	at wom.callable.CommandTaskDefinition.instantiateCommand(CommandTaskDefinition.scala:108); 	at wom.callable.CommandTaskDefinition.instantiateCommand$(CommandTaskDefinition.scala:97); 	at wom.callable.CallableTaskDefinition.instantiateCommand(CommandTaskDefinition.scala:136); 	at cromwell.backend.wdl.Command$.$anonfun$instantiate$1(Command.scala:32); 	at common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:20); 	at cromwell.backend.wdl.Command$.instantiate(Command.scala:31); 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:349); ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3012#issuecomment-377570787
https://github.com/broadinstitute/cromwell/issues/3012#issuecomment-377570787:4232,Availability,Error,ErrorOr,4232,at scala.collection.MapLike$MappedValues.foreach(MapLike.scala:253); 	at cwl.internal.EcmaScriptUtil$.$anonfun$evalStructish$1(EcmaScriptUtil.scala:107); 	at cwl.internal.EcmaScriptUtil$.$anonfun$evalStructish$1$adapted(EcmaScriptUtil.scala:97); 	at cwl.internal.EnhancedRhinoSandbox.eval(EnhancedRhinoSandbox.scala:61); 	at cwl.internal.EcmaScriptUtil$.evalRaw(EcmaScriptUtil.scala:69); 	at cwl.internal.EcmaScriptUtil$.evalStructish(EcmaScriptUtil.scala:97); 	at cwl.ExpressionEvaluator$.eval(ExpressionEvaluator.scala:76); 	at cwl.ExpressionEvaluator$.evaluator$1(ExpressionEvaluator.scala:40); 	at cwl.ExpressionEvaluator$.$anonfun$evalExpression$1(ExpressionEvaluator.scala:43); 	at cwl.ExpressionInterpolator$.interpolate(ExpressionInterpolator.scala:140); 	at cwl.ExpressionEvaluator$.evalExpression(ExpressionEvaluator.scala:43); 	at cwl.EvaluateExpression$.$anonfun$script$2(EvaluateExpression.scala:11); 	at cwl.ExpressionEvaluator$.eval(ExpressionEvaluator.scala:35); 	at cwl.CommandLineBindingCommandPart.$anonfun$instantiate$5(CwlExpressionCommandPart.scala:79); 	at scala.Option.flatMap(Option.scala:171); 	at cwl.CommandLineBindingCommandPart.instantiate(CwlExpressionCommandPart.scala:78); 	at wom.callable.CommandTaskDefinition.$anonfun$instantiateCommand$3(CommandTaskDefinition.scala:109); 	at scala.collection.immutable.List.flatMap(List.scala:335); 	at wom.callable.CommandTaskDefinition.instantiateCommand(CommandTaskDefinition.scala:108); 	at wom.callable.CommandTaskDefinition.instantiateCommand$(CommandTaskDefinition.scala:97); 	at wom.callable.CallableTaskDefinition.instantiateCommand(CommandTaskDefinition.scala:136); 	at cromwell.backend.wdl.Command$.$anonfun$instantiate$1(Command.scala:32); 	at common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:20); 	at cromwell.backend.wdl.Command$.instantiate(Command.scala:31); 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:349); ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3012#issuecomment-377570787
https://github.com/broadinstitute/cromwell/issues/3012#issuecomment-377570787:2077,Energy Efficiency,adapt,adapted,2077,tion.TraversableLike$WithFilter.foreach(TraversableLike.scala:788); 	at scala.collection.MapLike$MappedValues.foreach(MapLike.scala:253); 	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:59); 	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:50); 	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:186); 	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:44); 	at scala.collection.TraversableLike.to(TraversableLike.scala:590); 	at scala.collection.TraversableLike.to$(TraversableLike.scala:587); 	at scala.collection.AbstractTraversable.to(Traversable.scala:104); 	at scala.collection.TraversableOnce.toList(TraversableOnce.scala:294); 	at scala.collection.TraversableOnce.toList$(TraversableOnce.scala:294); 	at scala.collection.AbstractTraversable.toList(Traversable.scala:104); 	at cwl.internal.EcmaScriptUtil$.$anonfun$evalStructish$4(EcmaScriptUtil.scala:111); 	at cwl.internal.EcmaScriptUtil$.$anonfun$evalStructish$4$adapted(EcmaScriptUtil.scala:107); 	at scala.collection.MapLike$MappedValues.$anonfun$foreach$3(MapLike.scala:253); 	at scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:789); 	at scala.collection.immutable.Map$Map2.foreach(Map.scala:146); 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:788); 	at scala.collection.MapLike$MappedValues.foreach(MapLike.scala:253); 	at cwl.internal.EcmaScriptUtil$.$anonfun$evalStructish$1(EcmaScriptUtil.scala:107); 	at cwl.internal.EcmaScriptUtil$.$anonfun$evalStructish$1$adapted(EcmaScriptUtil.scala:97); 	at cwl.internal.EnhancedRhinoSandbox.eval(EnhancedRhinoSandbox.scala:61); 	at cwl.internal.EcmaScriptUtil$.evalRaw(EcmaScriptUtil.scala:69); 	at cwl.internal.EcmaScriptUtil$.evalStructish(EcmaScriptUtil.scala:97); 	at cwl.ExpressionEvaluator$.eval(ExpressionEvaluator.scala:76); 	at cwl.ExpressionEvaluator$.evaluator$1(ExpressionEvaluator.scala:40); 	at cwl.ExpressionEvaluator$.$anonfun$eva,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3012#issuecomment-377570787
https://github.com/broadinstitute/cromwell/issues/3012#issuecomment-377570787:2649,Energy Efficiency,adapt,adapted,2649, 	at scala.collection.AbstractTraversable.to(Traversable.scala:104); 	at scala.collection.TraversableOnce.toList(TraversableOnce.scala:294); 	at scala.collection.TraversableOnce.toList$(TraversableOnce.scala:294); 	at scala.collection.AbstractTraversable.toList(Traversable.scala:104); 	at cwl.internal.EcmaScriptUtil$.$anonfun$evalStructish$4(EcmaScriptUtil.scala:111); 	at cwl.internal.EcmaScriptUtil$.$anonfun$evalStructish$4$adapted(EcmaScriptUtil.scala:107); 	at scala.collection.MapLike$MappedValues.$anonfun$foreach$3(MapLike.scala:253); 	at scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:789); 	at scala.collection.immutable.Map$Map2.foreach(Map.scala:146); 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:788); 	at scala.collection.MapLike$MappedValues.foreach(MapLike.scala:253); 	at cwl.internal.EcmaScriptUtil$.$anonfun$evalStructish$1(EcmaScriptUtil.scala:107); 	at cwl.internal.EcmaScriptUtil$.$anonfun$evalStructish$1$adapted(EcmaScriptUtil.scala:97); 	at cwl.internal.EnhancedRhinoSandbox.eval(EnhancedRhinoSandbox.scala:61); 	at cwl.internal.EcmaScriptUtil$.evalRaw(EcmaScriptUtil.scala:69); 	at cwl.internal.EcmaScriptUtil$.evalStructish(EcmaScriptUtil.scala:97); 	at cwl.ExpressionEvaluator$.eval(ExpressionEvaluator.scala:76); 	at cwl.ExpressionEvaluator$.evaluator$1(ExpressionEvaluator.scala:40); 	at cwl.ExpressionEvaluator$.$anonfun$evalExpression$1(ExpressionEvaluator.scala:43); 	at cwl.ExpressionInterpolator$.interpolate(ExpressionInterpolator.scala:140); 	at cwl.ExpressionEvaluator$.evalExpression(ExpressionEvaluator.scala:43); 	at cwl.EvaluateExpression$.$anonfun$script$2(EvaluateExpression.scala:11); 	at cwl.ExpressionEvaluator$.eval(ExpressionEvaluator.scala:35); 	at cwl.CommandLineBindingCommandPart.$anonfun$instantiate$5(CwlExpressionCommandPart.scala:79); 	at scala.Option.flatMap(Option.scala:171); 	at cwl.CommandLineBindingCommandPart.instantiate(CwlExpressionCommandPart.scala:78); 	at w,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3012#issuecomment-377570787
https://github.com/broadinstitute/cromwell/issues/3012#issuecomment-377570787:165,Integrability,depend,dependent,165,"The error is different nowadays and apparently downstream of the fail. The underlying issue appears to be with not hydrating a `WomMaybePopulatedFile` output from a dependent job on restart: . ```; java.lang.UnsupportedOperationException: value is not available: WomMaybePopulatedFile(None,None,None,None,None,List()); 	at wom.values.WomMaybePopulatedFile.$anonfun$value$2(WomFile.scala:244); 	at scala.Option.getOrElse(Option.scala:121); 	at wom.values.WomMaybePopulatedFile.value(WomFile.scala:244); 	at cwl.internal.EcmaScriptEncoder.encodeFile(EcmaScriptEncoder.scala:102); 	at cwl.internal.EcmaScriptEncoder.encodeFileOrDirectory(EcmaScriptEncoder.scala:90); 	at cwl.internal.EcmaScriptEncoder.encode(EcmaScriptEncoder.scala:39); 	at cwl.internal.EcmaScriptUtil$.$anonfun$evalStructish$3(EcmaScriptUtil.scala:105); 	at scala.collection.MapLike$MappedValues.$anonfun$foreach$3(MapLike.scala:253); 	at scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:789); 	at scala.collection.immutable.Map$Map2.foreach(Map.scala:146); 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:788); 	at scala.collection.MapLike$MappedValues.foreach(MapLike.scala:253); 	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:59); 	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:50); 	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:186); 	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:44); 	at scala.collection.TraversableLike.to(TraversableLike.scala:590); 	at scala.collection.TraversableLike.to$(TraversableLike.scala:587); 	at scala.collection.AbstractTraversable.to(Traversable.scala:104); 	at scala.collection.TraversableOnce.toList(TraversableOnce.scala:294); 	at scala.collection.TraversableOnce.toList$(TraversableOnce.scala:294); 	at scala.collection.AbstractTraversable.toList(Traversable.scala:104); 	at cwl.internal.EcmaScriptUtil$.$anonfun$evalStructish$4(EcmaScrip",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3012#issuecomment-377570787
https://github.com/broadinstitute/cromwell/issues/3012#issuecomment-377570787:2077,Modifiability,adapt,adapted,2077,tion.TraversableLike$WithFilter.foreach(TraversableLike.scala:788); 	at scala.collection.MapLike$MappedValues.foreach(MapLike.scala:253); 	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:59); 	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:50); 	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:186); 	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:44); 	at scala.collection.TraversableLike.to(TraversableLike.scala:590); 	at scala.collection.TraversableLike.to$(TraversableLike.scala:587); 	at scala.collection.AbstractTraversable.to(Traversable.scala:104); 	at scala.collection.TraversableOnce.toList(TraversableOnce.scala:294); 	at scala.collection.TraversableOnce.toList$(TraversableOnce.scala:294); 	at scala.collection.AbstractTraversable.toList(Traversable.scala:104); 	at cwl.internal.EcmaScriptUtil$.$anonfun$evalStructish$4(EcmaScriptUtil.scala:111); 	at cwl.internal.EcmaScriptUtil$.$anonfun$evalStructish$4$adapted(EcmaScriptUtil.scala:107); 	at scala.collection.MapLike$MappedValues.$anonfun$foreach$3(MapLike.scala:253); 	at scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:789); 	at scala.collection.immutable.Map$Map2.foreach(Map.scala:146); 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:788); 	at scala.collection.MapLike$MappedValues.foreach(MapLike.scala:253); 	at cwl.internal.EcmaScriptUtil$.$anonfun$evalStructish$1(EcmaScriptUtil.scala:107); 	at cwl.internal.EcmaScriptUtil$.$anonfun$evalStructish$1$adapted(EcmaScriptUtil.scala:97); 	at cwl.internal.EnhancedRhinoSandbox.eval(EnhancedRhinoSandbox.scala:61); 	at cwl.internal.EcmaScriptUtil$.evalRaw(EcmaScriptUtil.scala:69); 	at cwl.internal.EcmaScriptUtil$.evalStructish(EcmaScriptUtil.scala:97); 	at cwl.ExpressionEvaluator$.eval(ExpressionEvaluator.scala:76); 	at cwl.ExpressionEvaluator$.evaluator$1(ExpressionEvaluator.scala:40); 	at cwl.ExpressionEvaluator$.$anonfun$eva,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3012#issuecomment-377570787
https://github.com/broadinstitute/cromwell/issues/3012#issuecomment-377570787:2649,Modifiability,adapt,adapted,2649, 	at scala.collection.AbstractTraversable.to(Traversable.scala:104); 	at scala.collection.TraversableOnce.toList(TraversableOnce.scala:294); 	at scala.collection.TraversableOnce.toList$(TraversableOnce.scala:294); 	at scala.collection.AbstractTraversable.toList(Traversable.scala:104); 	at cwl.internal.EcmaScriptUtil$.$anonfun$evalStructish$4(EcmaScriptUtil.scala:111); 	at cwl.internal.EcmaScriptUtil$.$anonfun$evalStructish$4$adapted(EcmaScriptUtil.scala:107); 	at scala.collection.MapLike$MappedValues.$anonfun$foreach$3(MapLike.scala:253); 	at scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:789); 	at scala.collection.immutable.Map$Map2.foreach(Map.scala:146); 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:788); 	at scala.collection.MapLike$MappedValues.foreach(MapLike.scala:253); 	at cwl.internal.EcmaScriptUtil$.$anonfun$evalStructish$1(EcmaScriptUtil.scala:107); 	at cwl.internal.EcmaScriptUtil$.$anonfun$evalStructish$1$adapted(EcmaScriptUtil.scala:97); 	at cwl.internal.EnhancedRhinoSandbox.eval(EnhancedRhinoSandbox.scala:61); 	at cwl.internal.EcmaScriptUtil$.evalRaw(EcmaScriptUtil.scala:69); 	at cwl.internal.EcmaScriptUtil$.evalStructish(EcmaScriptUtil.scala:97); 	at cwl.ExpressionEvaluator$.eval(ExpressionEvaluator.scala:76); 	at cwl.ExpressionEvaluator$.evaluator$1(ExpressionEvaluator.scala:40); 	at cwl.ExpressionEvaluator$.$anonfun$evalExpression$1(ExpressionEvaluator.scala:43); 	at cwl.ExpressionInterpolator$.interpolate(ExpressionInterpolator.scala:140); 	at cwl.ExpressionEvaluator$.evalExpression(ExpressionEvaluator.scala:43); 	at cwl.EvaluateExpression$.$anonfun$script$2(EvaluateExpression.scala:11); 	at cwl.ExpressionEvaluator$.eval(ExpressionEvaluator.scala:35); 	at cwl.CommandLineBindingCommandPart.$anonfun$instantiate$5(CwlExpressionCommandPart.scala:79); 	at scala.Option.flatMap(Option.scala:171); 	at cwl.CommandLineBindingCommandPart.instantiate(CwlExpressionCommandPart.scala:78); 	at w,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3012#issuecomment-377570787
https://github.com/broadinstitute/cromwell/issues/3012#issuecomment-377570787:2700,Modifiability,Enhance,EnhancedRhinoSandbox,2700,:104); 	at scala.collection.TraversableOnce.toList(TraversableOnce.scala:294); 	at scala.collection.TraversableOnce.toList$(TraversableOnce.scala:294); 	at scala.collection.AbstractTraversable.toList(Traversable.scala:104); 	at cwl.internal.EcmaScriptUtil$.$anonfun$evalStructish$4(EcmaScriptUtil.scala:111); 	at cwl.internal.EcmaScriptUtil$.$anonfun$evalStructish$4$adapted(EcmaScriptUtil.scala:107); 	at scala.collection.MapLike$MappedValues.$anonfun$foreach$3(MapLike.scala:253); 	at scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:789); 	at scala.collection.immutable.Map$Map2.foreach(Map.scala:146); 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:788); 	at scala.collection.MapLike$MappedValues.foreach(MapLike.scala:253); 	at cwl.internal.EcmaScriptUtil$.$anonfun$evalStructish$1(EcmaScriptUtil.scala:107); 	at cwl.internal.EcmaScriptUtil$.$anonfun$evalStructish$1$adapted(EcmaScriptUtil.scala:97); 	at cwl.internal.EnhancedRhinoSandbox.eval(EnhancedRhinoSandbox.scala:61); 	at cwl.internal.EcmaScriptUtil$.evalRaw(EcmaScriptUtil.scala:69); 	at cwl.internal.EcmaScriptUtil$.evalStructish(EcmaScriptUtil.scala:97); 	at cwl.ExpressionEvaluator$.eval(ExpressionEvaluator.scala:76); 	at cwl.ExpressionEvaluator$.evaluator$1(ExpressionEvaluator.scala:40); 	at cwl.ExpressionEvaluator$.$anonfun$evalExpression$1(ExpressionEvaluator.scala:43); 	at cwl.ExpressionInterpolator$.interpolate(ExpressionInterpolator.scala:140); 	at cwl.ExpressionEvaluator$.evalExpression(ExpressionEvaluator.scala:43); 	at cwl.EvaluateExpression$.$anonfun$script$2(EvaluateExpression.scala:11); 	at cwl.ExpressionEvaluator$.eval(ExpressionEvaluator.scala:35); 	at cwl.CommandLineBindingCommandPart.$anonfun$instantiate$5(CwlExpressionCommandPart.scala:79); 	at scala.Option.flatMap(Option.scala:171); 	at cwl.CommandLineBindingCommandPart.instantiate(CwlExpressionCommandPart.scala:78); 	at wom.callable.CommandTaskDefinition.$anonfun$instantiateCommand$3,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3012#issuecomment-377570787
https://github.com/broadinstitute/cromwell/issues/3012#issuecomment-377570787:2726,Modifiability,Enhance,EnhancedRhinoSandbox,2726,ion.TraversableOnce.toList(TraversableOnce.scala:294); 	at scala.collection.TraversableOnce.toList$(TraversableOnce.scala:294); 	at scala.collection.AbstractTraversable.toList(Traversable.scala:104); 	at cwl.internal.EcmaScriptUtil$.$anonfun$evalStructish$4(EcmaScriptUtil.scala:111); 	at cwl.internal.EcmaScriptUtil$.$anonfun$evalStructish$4$adapted(EcmaScriptUtil.scala:107); 	at scala.collection.MapLike$MappedValues.$anonfun$foreach$3(MapLike.scala:253); 	at scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:789); 	at scala.collection.immutable.Map$Map2.foreach(Map.scala:146); 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:788); 	at scala.collection.MapLike$MappedValues.foreach(MapLike.scala:253); 	at cwl.internal.EcmaScriptUtil$.$anonfun$evalStructish$1(EcmaScriptUtil.scala:107); 	at cwl.internal.EcmaScriptUtil$.$anonfun$evalStructish$1$adapted(EcmaScriptUtil.scala:97); 	at cwl.internal.EnhancedRhinoSandbox.eval(EnhancedRhinoSandbox.scala:61); 	at cwl.internal.EcmaScriptUtil$.evalRaw(EcmaScriptUtil.scala:69); 	at cwl.internal.EcmaScriptUtil$.evalStructish(EcmaScriptUtil.scala:97); 	at cwl.ExpressionEvaluator$.eval(ExpressionEvaluator.scala:76); 	at cwl.ExpressionEvaluator$.evaluator$1(ExpressionEvaluator.scala:40); 	at cwl.ExpressionEvaluator$.$anonfun$evalExpression$1(ExpressionEvaluator.scala:43); 	at cwl.ExpressionInterpolator$.interpolate(ExpressionInterpolator.scala:140); 	at cwl.ExpressionEvaluator$.evalExpression(ExpressionEvaluator.scala:43); 	at cwl.EvaluateExpression$.$anonfun$script$2(EvaluateExpression.scala:11); 	at cwl.ExpressionEvaluator$.eval(ExpressionEvaluator.scala:35); 	at cwl.CommandLineBindingCommandPart.$anonfun$instantiate$5(CwlExpressionCommandPart.scala:79); 	at scala.Option.flatMap(Option.scala:171); 	at cwl.CommandLineBindingCommandPart.instantiate(CwlExpressionCommandPart.scala:78); 	at wom.callable.CommandTaskDefinition.$anonfun$instantiateCommand$3(CommandTaskDefinition.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3012#issuecomment-377570787
https://github.com/broadinstitute/cromwell/issues/3012#issuecomment-377570787:4171,Security,validat,validation,4171,at scala.collection.MapLike$MappedValues.foreach(MapLike.scala:253); 	at cwl.internal.EcmaScriptUtil$.$anonfun$evalStructish$1(EcmaScriptUtil.scala:107); 	at cwl.internal.EcmaScriptUtil$.$anonfun$evalStructish$1$adapted(EcmaScriptUtil.scala:97); 	at cwl.internal.EnhancedRhinoSandbox.eval(EnhancedRhinoSandbox.scala:61); 	at cwl.internal.EcmaScriptUtil$.evalRaw(EcmaScriptUtil.scala:69); 	at cwl.internal.EcmaScriptUtil$.evalStructish(EcmaScriptUtil.scala:97); 	at cwl.ExpressionEvaluator$.eval(ExpressionEvaluator.scala:76); 	at cwl.ExpressionEvaluator$.evaluator$1(ExpressionEvaluator.scala:40); 	at cwl.ExpressionEvaluator$.$anonfun$evalExpression$1(ExpressionEvaluator.scala:43); 	at cwl.ExpressionInterpolator$.interpolate(ExpressionInterpolator.scala:140); 	at cwl.ExpressionEvaluator$.evalExpression(ExpressionEvaluator.scala:43); 	at cwl.EvaluateExpression$.$anonfun$script$2(EvaluateExpression.scala:11); 	at cwl.ExpressionEvaluator$.eval(ExpressionEvaluator.scala:35); 	at cwl.CommandLineBindingCommandPart.$anonfun$instantiate$5(CwlExpressionCommandPart.scala:79); 	at scala.Option.flatMap(Option.scala:171); 	at cwl.CommandLineBindingCommandPart.instantiate(CwlExpressionCommandPart.scala:78); 	at wom.callable.CommandTaskDefinition.$anonfun$instantiateCommand$3(CommandTaskDefinition.scala:109); 	at scala.collection.immutable.List.flatMap(List.scala:335); 	at wom.callable.CommandTaskDefinition.instantiateCommand(CommandTaskDefinition.scala:108); 	at wom.callable.CommandTaskDefinition.instantiateCommand$(CommandTaskDefinition.scala:97); 	at wom.callable.CallableTaskDefinition.instantiateCommand(CommandTaskDefinition.scala:136); 	at cromwell.backend.wdl.Command$.$anonfun$instantiate$1(Command.scala:32); 	at common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:20); 	at cromwell.backend.wdl.Command$.instantiate(Command.scala:31); 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:349); ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3012#issuecomment-377570787
https://github.com/broadinstitute/cromwell/pull/3016#issuecomment-349747269:78,Testability,test,tests,78,"Lovely, this parses and runs when actually submitted to Cromwell but the unit tests won't even parse it üò°",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3016#issuecomment-349747269
https://github.com/broadinstitute/cromwell/pull/3016#issuecomment-349759985:316,Modifiability,flexible,flexible,316,"Ok talked with Dan and there are a couple of problems here: ; We have two copies of three_step.cwl, one of which is used by unit tests and the other is used by Centaur. The unit tests currently don't SALAD input CWL so their input needs to be formatted just so. Real Cromwell does SALAD input CWL so it's a lot more flexible. Dan is working on a separate PR so the unit tests run SALAD.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3016#issuecomment-349759985
https://github.com/broadinstitute/cromwell/pull/3016#issuecomment-349759985:129,Testability,test,tests,129,"Ok talked with Dan and there are a couple of problems here: ; We have two copies of three_step.cwl, one of which is used by unit tests and the other is used by Centaur. The unit tests currently don't SALAD input CWL so their input needs to be formatted just so. Real Cromwell does SALAD input CWL so it's a lot more flexible. Dan is working on a separate PR so the unit tests run SALAD.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3016#issuecomment-349759985
https://github.com/broadinstitute/cromwell/pull/3016#issuecomment-349759985:178,Testability,test,tests,178,"Ok talked with Dan and there are a couple of problems here: ; We have two copies of three_step.cwl, one of which is used by unit tests and the other is used by Centaur. The unit tests currently don't SALAD input CWL so their input needs to be formatted just so. Real Cromwell does SALAD input CWL so it's a lot more flexible. Dan is working on a separate PR so the unit tests run SALAD.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3016#issuecomment-349759985
https://github.com/broadinstitute/cromwell/pull/3016#issuecomment-349759985:370,Testability,test,tests,370,"Ok talked with Dan and there are a couple of problems here: ; We have two copies of three_step.cwl, one of which is used by unit tests and the other is used by Centaur. The unit tests currently don't SALAD input CWL so their input needs to be formatted just so. Real Cromwell does SALAD input CWL so it's a lot more flexible. Dan is working on a separate PR so the unit tests run SALAD.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3016#issuecomment-349759985
https://github.com/broadinstitute/cromwell/issues/3023#issuecomment-349955857:49,Integrability,rout,route,49,And if one chooses to go the delete-the-examples route please also look at deleting any wdl code that is no longer needed.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3023#issuecomment-349955857
https://github.com/broadinstitute/cromwell/pull/3030#issuecomment-350478429:14,Energy Efficiency,green,green,14,Tests are now green! Had to double the amount of changes from of the original commit to fix some logging issues.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3030#issuecomment-350478429
https://github.com/broadinstitute/cromwell/pull/3030#issuecomment-350478429:0,Testability,Test,Tests,0,Tests are now green! Had to double the amount of changes from of the original commit to fix some logging issues.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3030#issuecomment-350478429
https://github.com/broadinstitute/cromwell/pull/3030#issuecomment-350478429:97,Testability,log,logging,97,Tests are now green! Had to double the amount of changes from of the original commit to fix some logging issues.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3030#issuecomment-350478429
https://github.com/broadinstitute/cromwell/issues/3031#issuecomment-350516520:113,Availability,avail,available,113,"While this ticket is being resolved for the womtool-on-the-releases-page, for docker users the latest WOMTool is available @ https://hub.docker.com/r/broadinstitute/womtool/tags/",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3031#issuecomment-350516520
https://github.com/broadinstitute/cromwell/issues/3031#issuecomment-350516520:59,Deployability,release,releases-page,59,"While this ticket is being resolved for the womtool-on-the-releases-page, for docker users the latest WOMTool is available @ https://hub.docker.com/r/broadinstitute/womtool/tags/",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3031#issuecomment-350516520
https://github.com/broadinstitute/cromwell/issues/3032#issuecomment-350283048:195,Energy Efficiency,adapt,adapters,195,"While this is investigated, you should be able to work around this by moving the constant string outside the `${}`s, eg ; ```; python $(which encode_trim_adapter.py) \; ${write_tsv(fastqs)} \; --adapters ${write_tsv(adapters)} \; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3032#issuecomment-350283048
https://github.com/broadinstitute/cromwell/issues/3032#issuecomment-350283048:216,Energy Efficiency,adapt,adapters,216,"While this is investigated, you should be able to work around this by moving the constant string outside the `${}`s, eg ; ```; python $(which encode_trim_adapter.py) \; ${write_tsv(fastqs)} \; --adapters ${write_tsv(adapters)} \; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3032#issuecomment-350283048
https://github.com/broadinstitute/cromwell/issues/3032#issuecomment-350283048:195,Integrability,adapter,adapters,195,"While this is investigated, you should be able to work around this by moving the constant string outside the `${}`s, eg ; ```; python $(which encode_trim_adapter.py) \; ${write_tsv(fastqs)} \; --adapters ${write_tsv(adapters)} \; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3032#issuecomment-350283048
https://github.com/broadinstitute/cromwell/issues/3032#issuecomment-350283048:216,Integrability,adapter,adapters,216,"While this is investigated, you should be able to work around this by moving the constant string outside the `${}`s, eg ; ```; python $(which encode_trim_adapter.py) \; ${write_tsv(fastqs)} \; --adapters ${write_tsv(adapters)} \; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3032#issuecomment-350283048
https://github.com/broadinstitute/cromwell/issues/3032#issuecomment-350283048:195,Modifiability,adapt,adapters,195,"While this is investigated, you should be able to work around this by moving the constant string outside the `${}`s, eg ; ```; python $(which encode_trim_adapter.py) \; ${write_tsv(fastqs)} \; --adapters ${write_tsv(adapters)} \; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3032#issuecomment-350283048
https://github.com/broadinstitute/cromwell/issues/3032#issuecomment-350283048:216,Modifiability,adapt,adapters,216,"While this is investigated, you should be able to work around this by moving the constant string outside the `${}`s, eg ; ```; python $(which encode_trim_adapter.py) \; ${write_tsv(fastqs)} \; --adapters ${write_tsv(adapters)} \; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3032#issuecomment-350283048
https://github.com/broadinstitute/cromwell/issues/3032#issuecomment-484095411:147,Availability,error,error,147,"I am experiencing an issue that may also be related to this, using WDL draft-2 spec and cromwell-39.; Here is a dummy example I created off a real error I received, it is minimal but hopefully descriptive enough:. ```WDL; task example {; Map[String, File] sample_files; Array[Array[String]]? tax_id_and_name; String? summary_report_name. String default_summary_report = select_first([summary_report_name, 'summary_report.txt']). command <<<; set -ex; example_command \; -o ${default_summary_report} \; -i ${write_json(sample_files)} \; ${ if defined(tax_id_and_name) then '-t ' + write_tsv(tax_id_and_name) else '' }; >>>; runtime {; docker: ""<local or private image name with the custom `example_command` installed>""; }; output {; File summary_report = ""${default_summary_report}""; }; }; ```; The run fails and the offending log output from Cromwell says:. ```commandline; example_command -o summary_report.txt -i /cromwell-executions/test_example_workflow/1d0ebc28-df3c-4e8c-9ade-7cae41513fcc/call-example/execution/write_json_b428b2ef25b3a99656256ecf58545736.tmp -t /Users/myuser/projects/wdl_example/cromwell-executions/test_example_workflow/1d0ebc28-df3c-4e8c-9ade-7cae41513fcc/call-example/execution/write_tsv_c317cbd4e3102b89210776bbc6430eeb.tmp; E Unable to open file /Users/myuser/projects/wdl_example/cromwell-executions/test_example_workflow/1d0ebc28-df3c-4e8c-9ade-7cae41513fcc/call-example/execution/write_tsv_c317cbd4e3102b89210776bbc6430eeb.tmp for reading (No such file or directory). Stopped at /usr/bin/example_command line 192.; ```. `write_json()` has no issue creating a path within the container, while `write_tsv()` returns a host path which is not found within the container.; I am able to workaround this at the moment by using `basename(write_tsv())` since the file is still in the execution directory.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3032#issuecomment-484095411
https://github.com/broadinstitute/cromwell/issues/3032#issuecomment-484095411:706,Deployability,install,installed,706,"I am experiencing an issue that may also be related to this, using WDL draft-2 spec and cromwell-39.; Here is a dummy example I created off a real error I received, it is minimal but hopefully descriptive enough:. ```WDL; task example {; Map[String, File] sample_files; Array[Array[String]]? tax_id_and_name; String? summary_report_name. String default_summary_report = select_first([summary_report_name, 'summary_report.txt']). command <<<; set -ex; example_command \; -o ${default_summary_report} \; -i ${write_json(sample_files)} \; ${ if defined(tax_id_and_name) then '-t ' + write_tsv(tax_id_and_name) else '' }; >>>; runtime {; docker: ""<local or private image name with the custom `example_command` installed>""; }; output {; File summary_report = ""${default_summary_report}""; }; }; ```; The run fails and the offending log output from Cromwell says:. ```commandline; example_command -o summary_report.txt -i /cromwell-executions/test_example_workflow/1d0ebc28-df3c-4e8c-9ade-7cae41513fcc/call-example/execution/write_json_b428b2ef25b3a99656256ecf58545736.tmp -t /Users/myuser/projects/wdl_example/cromwell-executions/test_example_workflow/1d0ebc28-df3c-4e8c-9ade-7cae41513fcc/call-example/execution/write_tsv_c317cbd4e3102b89210776bbc6430eeb.tmp; E Unable to open file /Users/myuser/projects/wdl_example/cromwell-executions/test_example_workflow/1d0ebc28-df3c-4e8c-9ade-7cae41513fcc/call-example/execution/write_tsv_c317cbd4e3102b89210776bbc6430eeb.tmp for reading (No such file or directory). Stopped at /usr/bin/example_command line 192.; ```. `write_json()` has no issue creating a path within the container, while `write_tsv()` returns a host path which is not found within the container.; I am able to workaround this at the moment by using `basename(write_tsv())` since the file is still in the execution directory.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3032#issuecomment-484095411
https://github.com/broadinstitute/cromwell/issues/3032#issuecomment-484095411:826,Testability,log,log,826,"I am experiencing an issue that may also be related to this, using WDL draft-2 spec and cromwell-39.; Here is a dummy example I created off a real error I received, it is minimal but hopefully descriptive enough:. ```WDL; task example {; Map[String, File] sample_files; Array[Array[String]]? tax_id_and_name; String? summary_report_name. String default_summary_report = select_first([summary_report_name, 'summary_report.txt']). command <<<; set -ex; example_command \; -o ${default_summary_report} \; -i ${write_json(sample_files)} \; ${ if defined(tax_id_and_name) then '-t ' + write_tsv(tax_id_and_name) else '' }; >>>; runtime {; docker: ""<local or private image name with the custom `example_command` installed>""; }; output {; File summary_report = ""${default_summary_report}""; }; }; ```; The run fails and the offending log output from Cromwell says:. ```commandline; example_command -o summary_report.txt -i /cromwell-executions/test_example_workflow/1d0ebc28-df3c-4e8c-9ade-7cae41513fcc/call-example/execution/write_json_b428b2ef25b3a99656256ecf58545736.tmp -t /Users/myuser/projects/wdl_example/cromwell-executions/test_example_workflow/1d0ebc28-df3c-4e8c-9ade-7cae41513fcc/call-example/execution/write_tsv_c317cbd4e3102b89210776bbc6430eeb.tmp; E Unable to open file /Users/myuser/projects/wdl_example/cromwell-executions/test_example_workflow/1d0ebc28-df3c-4e8c-9ade-7cae41513fcc/call-example/execution/write_tsv_c317cbd4e3102b89210776bbc6430eeb.tmp for reading (No such file or directory). Stopped at /usr/bin/example_command line 192.; ```. `write_json()` has no issue creating a path within the container, while `write_tsv()` returns a host path which is not found within the container.; I am able to workaround this at the moment by using `basename(write_tsv())` since the file is still in the execution directory.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3032#issuecomment-484095411
https://github.com/broadinstitute/cromwell/issues/3035#issuecomment-354841065:69,Testability,test,tests,69,"I believe @Horneth put in a short term fix for this by excluding CWL tests from the set of restart tests, but presumably we'll want restart support for our CWL workflows at some point.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3035#issuecomment-354841065
https://github.com/broadinstitute/cromwell/issues/3035#issuecomment-354841065:99,Testability,test,tests,99,"I believe @Horneth put in a short term fix for this by excluding CWL tests from the set of restart tests, but presumably we'll want restart support for our CWL workflows at some point.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3035#issuecomment-354841065
https://github.com/broadinstitute/cromwell/issues/3037#issuecomment-350774716:14,Deployability,Hotfix,Hotfix,14,Definitely a `Hotfix Candidate`!,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3037#issuecomment-350774716
https://github.com/broadinstitute/cromwell/issues/3038#issuecomment-350738471:147,Deployability,rolling,rolling,147,"For this one, I basically just worked around it. The other one is still an issue. I'll send it to you with the workaround in place. We can discuss rolling back the workaround when issue #3039 is sorted. I'm hoping that is a typo.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3038#issuecomment-350738471
https://github.com/broadinstitute/cromwell/pull/3040#issuecomment-350391674:36,Testability,test,tests,36,It might also be a plus if the unit tests compiled.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3040#issuecomment-350391674
https://github.com/broadinstitute/cromwell/issues/3043#issuecomment-350786499:101,Testability,test,test,101,"~~On the other hand it might not be a CWL spec thing but just an artifact of how the CWL conformance test submit some tests.. ?~~; It is not, this is the relevant doc http://www.commonwl.org/v1.0/SchemaSalad.html#Explicit_context",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3043#issuecomment-350786499
https://github.com/broadinstitute/cromwell/issues/3043#issuecomment-350786499:118,Testability,test,tests,118,"~~On the other hand it might not be a CWL spec thing but just an artifact of how the CWL conformance test submit some tests.. ?~~; It is not, this is the relevant doc http://www.commonwl.org/v1.0/SchemaSalad.html#Explicit_context",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3043#issuecomment-350786499
https://github.com/broadinstitute/cromwell/issues/3044#issuecomment-351070649:65,Performance,cache,cache,65,"@Horneth here is my metadata. I enclose first run from which the cache was created. There I made a mistake in input and gave graywhale_in_human_blastp output name for the cow data. In two runs that followed I tried to fix this mistake by giving graywhale_in_cow_blastp instead, but it cached the copy task from the first run, so nothing changed.; [metadata_false_positive.zip](https://github.com/broadinstitute/cromwell/files/1551960/metadata_false_positive.zip)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3044#issuecomment-351070649
https://github.com/broadinstitute/cromwell/issues/3044#issuecomment-351070649:285,Performance,cache,cached,285,"@Horneth here is my metadata. I enclose first run from which the cache was created. There I made a mistake in input and gave graywhale_in_human_blastp output name for the cow data. In two runs that followed I tried to fix this mistake by giving graywhale_in_cow_blastp instead, but it cached the copy task from the first run, so nothing changed.; [metadata_false_positive.zip](https://github.com/broadinstitute/cromwell/files/1551960/metadata_false_positive.zip)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3044#issuecomment-351070649
https://github.com/broadinstitute/cromwell/issues/3044#issuecomment-351125450:632,Deployability,pipeline,pipelines,632,"@antonkulaga It appears that changing the `name` only changes the filename of the output produced by your task, but not the actual processing. So I bet if you look at the files produced by the diamond blast task for all 3 workflows you'll see that even though their names differ they have the same content.; Cromwell by default only cares about the content of a file with respect to call caching and its name is ignored. In this case it likely md5ed the files and found they had the same hash so the copy task was cached.; I'll wait for you to confirm that the output files have indeed the same hash before closing this:. ```; md5 /pipelines/cromwell_1/cromwell-executions/Diamond_Blast/ab101af5-26ba-45c8-b592-fb37e06a523d/call-diamond_blast/execution/graywhale_in_human_blastp.m8; md5 /pipelines/cromwell_1/cromwell-executions/Diamond_Blast/3d75657d-7dc9-4b6f-bbc8-ae579a3fa773/call-diamond_blast/execution/graywhale_in_cow_blastp.m8; md5 /pipelines/cromwell_1/cromwell-executions/Diamond_Blast/276d6f9e-15b1-4dc3-a8a7-889414406511/call-diamond_blast/execution/graywhale_in_cow_blastp.m8; ```. should all produce the same hash",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3044#issuecomment-351125450
https://github.com/broadinstitute/cromwell/issues/3044#issuecomment-351125450:788,Deployability,pipeline,pipelines,788,"@antonkulaga It appears that changing the `name` only changes the filename of the output produced by your task, but not the actual processing. So I bet if you look at the files produced by the diamond blast task for all 3 workflows you'll see that even though their names differ they have the same content.; Cromwell by default only cares about the content of a file with respect to call caching and its name is ignored. In this case it likely md5ed the files and found they had the same hash so the copy task was cached.; I'll wait for you to confirm that the output files have indeed the same hash before closing this:. ```; md5 /pipelines/cromwell_1/cromwell-executions/Diamond_Blast/ab101af5-26ba-45c8-b592-fb37e06a523d/call-diamond_blast/execution/graywhale_in_human_blastp.m8; md5 /pipelines/cromwell_1/cromwell-executions/Diamond_Blast/3d75657d-7dc9-4b6f-bbc8-ae579a3fa773/call-diamond_blast/execution/graywhale_in_cow_blastp.m8; md5 /pipelines/cromwell_1/cromwell-executions/Diamond_Blast/276d6f9e-15b1-4dc3-a8a7-889414406511/call-diamond_blast/execution/graywhale_in_cow_blastp.m8; ```. should all produce the same hash",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3044#issuecomment-351125450
https://github.com/broadinstitute/cromwell/issues/3044#issuecomment-351125450:942,Deployability,pipeline,pipelines,942,"@antonkulaga It appears that changing the `name` only changes the filename of the output produced by your task, but not the actual processing. So I bet if you look at the files produced by the diamond blast task for all 3 workflows you'll see that even though their names differ they have the same content.; Cromwell by default only cares about the content of a file with respect to call caching and its name is ignored. In this case it likely md5ed the files and found they had the same hash so the copy task was cached.; I'll wait for you to confirm that the output files have indeed the same hash before closing this:. ```; md5 /pipelines/cromwell_1/cromwell-executions/Diamond_Blast/ab101af5-26ba-45c8-b592-fb37e06a523d/call-diamond_blast/execution/graywhale_in_human_blastp.m8; md5 /pipelines/cromwell_1/cromwell-executions/Diamond_Blast/3d75657d-7dc9-4b6f-bbc8-ae579a3fa773/call-diamond_blast/execution/graywhale_in_cow_blastp.m8; md5 /pipelines/cromwell_1/cromwell-executions/Diamond_Blast/276d6f9e-15b1-4dc3-a8a7-889414406511/call-diamond_blast/execution/graywhale_in_cow_blastp.m8; ```. should all produce the same hash",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3044#issuecomment-351125450
https://github.com/broadinstitute/cromwell/issues/3044#issuecomment-351125450:514,Performance,cache,cached,514,"@antonkulaga It appears that changing the `name` only changes the filename of the output produced by your task, but not the actual processing. So I bet if you look at the files produced by the diamond blast task for all 3 workflows you'll see that even though their names differ they have the same content.; Cromwell by default only cares about the content of a file with respect to call caching and its name is ignored. In this case it likely md5ed the files and found they had the same hash so the copy task was cached.; I'll wait for you to confirm that the output files have indeed the same hash before closing this:. ```; md5 /pipelines/cromwell_1/cromwell-executions/Diamond_Blast/ab101af5-26ba-45c8-b592-fb37e06a523d/call-diamond_blast/execution/graywhale_in_human_blastp.m8; md5 /pipelines/cromwell_1/cromwell-executions/Diamond_Blast/3d75657d-7dc9-4b6f-bbc8-ae579a3fa773/call-diamond_blast/execution/graywhale_in_cow_blastp.m8; md5 /pipelines/cromwell_1/cromwell-executions/Diamond_Blast/276d6f9e-15b1-4dc3-a8a7-889414406511/call-diamond_blast/execution/graywhale_in_cow_blastp.m8; ```. should all produce the same hash",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3044#issuecomment-351125450
https://github.com/broadinstitute/cromwell/issues/3044#issuecomment-351125450:488,Security,hash,hash,488,"@antonkulaga It appears that changing the `name` only changes the filename of the output produced by your task, but not the actual processing. So I bet if you look at the files produced by the diamond blast task for all 3 workflows you'll see that even though their names differ they have the same content.; Cromwell by default only cares about the content of a file with respect to call caching and its name is ignored. In this case it likely md5ed the files and found they had the same hash so the copy task was cached.; I'll wait for you to confirm that the output files have indeed the same hash before closing this:. ```; md5 /pipelines/cromwell_1/cromwell-executions/Diamond_Blast/ab101af5-26ba-45c8-b592-fb37e06a523d/call-diamond_blast/execution/graywhale_in_human_blastp.m8; md5 /pipelines/cromwell_1/cromwell-executions/Diamond_Blast/3d75657d-7dc9-4b6f-bbc8-ae579a3fa773/call-diamond_blast/execution/graywhale_in_cow_blastp.m8; md5 /pipelines/cromwell_1/cromwell-executions/Diamond_Blast/276d6f9e-15b1-4dc3-a8a7-889414406511/call-diamond_blast/execution/graywhale_in_cow_blastp.m8; ```. should all produce the same hash",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3044#issuecomment-351125450
https://github.com/broadinstitute/cromwell/issues/3044#issuecomment-351125450:595,Security,hash,hash,595,"@antonkulaga It appears that changing the `name` only changes the filename of the output produced by your task, but not the actual processing. So I bet if you look at the files produced by the diamond blast task for all 3 workflows you'll see that even though their names differ they have the same content.; Cromwell by default only cares about the content of a file with respect to call caching and its name is ignored. In this case it likely md5ed the files and found they had the same hash so the copy task was cached.; I'll wait for you to confirm that the output files have indeed the same hash before closing this:. ```; md5 /pipelines/cromwell_1/cromwell-executions/Diamond_Blast/ab101af5-26ba-45c8-b592-fb37e06a523d/call-diamond_blast/execution/graywhale_in_human_blastp.m8; md5 /pipelines/cromwell_1/cromwell-executions/Diamond_Blast/3d75657d-7dc9-4b6f-bbc8-ae579a3fa773/call-diamond_blast/execution/graywhale_in_cow_blastp.m8; md5 /pipelines/cromwell_1/cromwell-executions/Diamond_Blast/276d6f9e-15b1-4dc3-a8a7-889414406511/call-diamond_blast/execution/graywhale_in_cow_blastp.m8; ```. should all produce the same hash",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3044#issuecomment-351125450
https://github.com/broadinstitute/cromwell/issues/3044#issuecomment-351125450:1124,Security,hash,hash,1124,"@antonkulaga It appears that changing the `name` only changes the filename of the output produced by your task, but not the actual processing. So I bet if you look at the files produced by the diamond blast task for all 3 workflows you'll see that even though their names differ they have the same content.; Cromwell by default only cares about the content of a file with respect to call caching and its name is ignored. In this case it likely md5ed the files and found they had the same hash so the copy task was cached.; I'll wait for you to confirm that the output files have indeed the same hash before closing this:. ```; md5 /pipelines/cromwell_1/cromwell-executions/Diamond_Blast/ab101af5-26ba-45c8-b592-fb37e06a523d/call-diamond_blast/execution/graywhale_in_human_blastp.m8; md5 /pipelines/cromwell_1/cromwell-executions/Diamond_Blast/3d75657d-7dc9-4b6f-bbc8-ae579a3fa773/call-diamond_blast/execution/graywhale_in_cow_blastp.m8; md5 /pipelines/cromwell_1/cromwell-executions/Diamond_Blast/276d6f9e-15b1-4dc3-a8a7-889414406511/call-diamond_blast/execution/graywhale_in_cow_blastp.m8; ```. should all produce the same hash",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3044#issuecomment-351125450
https://github.com/broadinstitute/cromwell/issues/3044#issuecomment-351129209:31,Deployability,configurat,configuration,31,@Horneth could you add a cache configuration option that will switch on caring about the filenames when caching?; Non-chaching of filenames can get many users in a really big trouble and sometimes screw whole research or medical diagnosis. If I did not discover that the files were not written because of caching my colleagues would have treated cow data as if it was human.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3044#issuecomment-351129209
https://github.com/broadinstitute/cromwell/issues/3044#issuecomment-351129209:31,Modifiability,config,configuration,31,@Horneth could you add a cache configuration option that will switch on caring about the filenames when caching?; Non-chaching of filenames can get many users in a really big trouble and sometimes screw whole research or medical diagnosis. If I did not discover that the files were not written because of caching my colleagues would have treated cow data as if it was human.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3044#issuecomment-351129209
https://github.com/broadinstitute/cromwell/issues/3044#issuecomment-351129209:25,Performance,cache,cache,25,@Horneth could you add a cache configuration option that will switch on caring about the filenames when caching?; Non-chaching of filenames can get many users in a really big trouble and sometimes screw whole research or medical diagnosis. If I did not discover that the files were not written because of caching my colleagues would have treated cow data as if it was human.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3044#issuecomment-351129209
https://github.com/broadinstitute/cromwell/issues/3051#issuecomment-350848249:26,Availability,error,error,26,@ruchim is this a parsing error or a runtime error?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3051#issuecomment-350848249
https://github.com/broadinstitute/cromwell/issues/3051#issuecomment-350848249:45,Availability,error,error,45,@ruchim is this a parsing error or a runtime error?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3051#issuecomment-350848249
https://github.com/broadinstitute/cromwell/issues/3060#issuecomment-351556853:96,Availability,error,error,96,"Also, if I change the type of the output from `Object` to `Map[String, String]` I get a similar error:; ```; ""failures"": [; {; ""causedBy"": [; {; ""causedBy"": [],; ""message"": ""Some([Declaration type=Map[String, String] name=prep.inputs expr=Some(prep.inputs)]) (of class scala.Some)""; }; ],; ""message"": ""Workflow input processing failed""; }; ]; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3060#issuecomment-351556853
https://github.com/broadinstitute/cromwell/issues/3060#issuecomment-351556853:110,Availability,failure,failures,110,"Also, if I change the type of the output from `Object` to `Map[String, String]` I get a similar error:; ```; ""failures"": [; {; ""causedBy"": [; {; ""causedBy"": [],; ""message"": ""Some([Declaration type=Map[String, String] name=prep.inputs expr=Some(prep.inputs)]) (of class scala.Some)""; }; ],; ""message"": ""Workflow input processing failed""; }; ]; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3060#issuecomment-351556853
https://github.com/broadinstitute/cromwell/issues/3060#issuecomment-351556853:163,Integrability,message,message,163,"Also, if I change the type of the output from `Object` to `Map[String, String]` I get a similar error:; ```; ""failures"": [; {; ""causedBy"": [; {; ""causedBy"": [],; ""message"": ""Some([Declaration type=Map[String, String] name=prep.inputs expr=Some(prep.inputs)]) (of class scala.Some)""; }; ],; ""message"": ""Workflow input processing failed""; }; ]; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3060#issuecomment-351556853
https://github.com/broadinstitute/cromwell/issues/3060#issuecomment-351556853:291,Integrability,message,message,291,"Also, if I change the type of the output from `Object` to `Map[String, String]` I get a similar error:; ```; ""failures"": [; {; ""causedBy"": [; {; ""causedBy"": [],; ""message"": ""Some([Declaration type=Map[String, String] name=prep.inputs expr=Some(prep.inputs)]) (of class scala.Some)""; }; ],; ""message"": ""Workflow input processing failed""; }; ]; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3060#issuecomment-351556853
https://github.com/broadinstitute/cromwell/issues/3060#issuecomment-351777550:724,Availability,Down,Downloading,724,"Here's the full metadata @danbills:. ```; {; ""submittedFiles"": {; ""workflow"": ""import \""ss2_single_sample.wdl\"" as ss2\nimport \""submit.wdl\"" as submit_wdl\n\n\ntask GetInputs {\n String bundle_uuid\n String bundle_version\n String dss_url\n Int retry_seconds\n Int timeout_seconds\n\n command <<<\n python <<CODE\n from pipeline_tools import utils\n\n # Get bundle manifest\n uuid = '${bundle_uuid}'\n version = '${bundle_version}'\n dss_url = '${dss_url}'\n retry_seconds = ${retry_seconds}\n timeout_seconds = ${timeout_seconds}\n print('Getting bundle manifest for id {0}, version {1}'.format(uuid, version))\n manifest_files = utils.get_manifest_files(uuid, version, dss_url, timeout_seconds, retry_seconds)\n\n print('Downloading assay.json')\n assay_json_uuid = manifest_files['name_to_meta']['assay.json']['uuid']\n assay_json = utils.get_file_by_uuid(assay_json_uuid, dss_url)\n\n sample_id = assay_json['sample_id']\n fastq_1_name = assay_json['seq']['lanes'][0]['r1']\n fastq_2_name = assay_json['seq']['lanes'][0]['r2']\n fastq_1_url = manifest_files['name_to_meta'][fastq_1_name]['url']\n fastq_2_url = manifest_files['name_to_meta'][fastq_2_name]['url']\n\n print('Creating input map')\n with open('inputs.tsv', 'w') as f:\n f.write('fastq_1\\tfastq_2\\tsample_id\\n')\n f.write('{0}\\t{1}\\t{2}\\n'.format(fastq_1_url, fastq_2_url, sample_id))\n print('Wrote input map')\n CODE\n >>>\n runtime {\n docker: \""humancellatlas/pipeline-tools:0.1.4\""\n }\n output {\n Object inputs = read_object(\""inputs.tsv\"")\n }\n}\n\nworkflow AdapterSs2RsemSingleSample {\n String bundle_uuid\n String bundle_version\n\n File gtf\n File ref_fasta\n File rrna_interval\n File ref_flat\n String star_genome\n String rsem_genome\n String reference_bundle\n\n # Submission\n File format_map\n String dss_url\n String submit_url\n String method\n String schema_version\n String run_type\n Int retry_seconds\n Int timeout_seconds\n\n # Set runtime environment such as \""dev\"" or \""staging\"" or \""prod\"" so sub",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3060#issuecomment-351777550
https://github.com/broadinstitute/cromwell/issues/3060#issuecomment-351777550:5686,Availability,failure,failures,5686,"rence_bundle\"":\""bf51d668-3e14-4843-9bc7-5d676fdf0e01\"",\""AdapterSs2RsemSingleSample.rrna_interval\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/hg19.rRNA.interval_list\"",\""AdapterSs2RsemSingleSample.rsem_genome\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/rsem_hg19_gencode_v19.tar.gz\"",\""AdapterSs2RsemSingleSample.runtime_environment\"":\""dev\"",\""AdapterSs2RsemSingleSample.ref_flat\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/refFlat.txt\"",\""AdapterSs2RsemSingleSample.format_map\"":\""gs://broad-dsde-mint-dev-teststorage/format_map_example.json\"",\""AdapterSs2RsemSingleSample.bundle_uuid\"":\""c59a5720-ca82-429d-9d5b-6116987e221d\"",\""AdapterSs2RsemSingleSample.ref_fasta\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/Hg19.fa\"",\""AdapterSs2RsemSingleSample.run_type\"":\""run\"",\""AdapterSs2RsemSingleSample.bundle_version\"":\""2017-09-20T211432.976293Z\"",\""AdapterSs2RsemSingleSample.gtf\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/Gencode_v19/Gencode_v19.GTF\"",\""AdapterSs2RsemSingleSample.retry_seconds\"":1E+1,\""AdapterSs2RsemSingleSample.method\"":\""Ss2RsemSingleSample\"",\""AdapterSs2RsemSingleSample.dss_url\"":\""https://dss.staging.data.humancellatlas.org/v1\"",\""AdapterSs2RsemSingleSample.submit_url\"":\""http://api.ingest.staging.data.humancellatlas.org/\"",\""AdapterSs2RsemSingleSample.star_genome\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/star_hg19_gencode_v19.tar.gz\"",\""AdapterSs2RsemSingleSample.schema_version\"":\""v3\""}"",; ""labels"": ""{}""; },; ""calls"": {},; ""outputs"": {},; ""id"": ""f1ccad5e-73d4-4905-b62f-81ab96dded19"",; ""inputs"": {},; ""submission"": ""2017-12-14T17:16:01.748Z"",; ""status"": ""Failed"",; ""failures"": [; {; ""causedBy"": [; {; ""causedBy"": [],; ""message"": ""Some([Declaration type=Object name=prep.inputs expr=Some(prep.inputs)]) (of class scala.Some)""; }; ],; ""message"": ""Workflow input processing failed""; }; ],; ""end"": ""2017-12-14T17:16:20.791Z"",; ""start"": ""2017-12-14T17:16:20.747Z""; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3060#issuecomment-351777550
https://github.com/broadinstitute/cromwell/issues/3060#issuecomment-351777550:1438,Deployability,pipeline,pipeline-tools,1438,"'${bundle_uuid}'\n version = '${bundle_version}'\n dss_url = '${dss_url}'\n retry_seconds = ${retry_seconds}\n timeout_seconds = ${timeout_seconds}\n print('Getting bundle manifest for id {0}, version {1}'.format(uuid, version))\n manifest_files = utils.get_manifest_files(uuid, version, dss_url, timeout_seconds, retry_seconds)\n\n print('Downloading assay.json')\n assay_json_uuid = manifest_files['name_to_meta']['assay.json']['uuid']\n assay_json = utils.get_file_by_uuid(assay_json_uuid, dss_url)\n\n sample_id = assay_json['sample_id']\n fastq_1_name = assay_json['seq']['lanes'][0]['r1']\n fastq_2_name = assay_json['seq']['lanes'][0]['r2']\n fastq_1_url = manifest_files['name_to_meta'][fastq_1_name]['url']\n fastq_2_url = manifest_files['name_to_meta'][fastq_2_name]['url']\n\n print('Creating input map')\n with open('inputs.tsv', 'w') as f:\n f.write('fastq_1\\tfastq_2\\tsample_id\\n')\n f.write('{0}\\t{1}\\t{2}\\n'.format(fastq_1_url, fastq_2_url, sample_id))\n print('Wrote input map')\n CODE\n >>>\n runtime {\n docker: \""humancellatlas/pipeline-tools:0.1.4\""\n }\n output {\n Object inputs = read_object(\""inputs.tsv\"")\n }\n}\n\nworkflow AdapterSs2RsemSingleSample {\n String bundle_uuid\n String bundle_version\n\n File gtf\n File ref_fasta\n File rrna_interval\n File ref_flat\n String star_genome\n String rsem_genome\n String reference_bundle\n\n # Submission\n File format_map\n String dss_url\n String submit_url\n String method\n String schema_version\n String run_type\n Int retry_seconds\n Int timeout_seconds\n\n # Set runtime environment such as \""dev\"" or \""staging\"" or \""prod\"" so submit task could choose proper docker image to use\n String runtime_environment\n\n call GetInputs as prep {\n input:\n bundle_uuid = bundle_uuid,\n bundle_version = bundle_version,\n dss_url = dss_url,\n retry_seconds = retry_seconds,\n timeout_seconds = timeout_seconds\n }\n\n call ss2.Ss2RsemSingleSample as analysis {\n input:\n fastq_read1 = prep.inputs.fastq_1,\n fastq_read2 = p",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3060#issuecomment-351777550
https://github.com/broadinstitute/cromwell/issues/3060#issuecomment-351777550:5739,Integrability,message,message,5739,"rence_bundle\"":\""bf51d668-3e14-4843-9bc7-5d676fdf0e01\"",\""AdapterSs2RsemSingleSample.rrna_interval\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/hg19.rRNA.interval_list\"",\""AdapterSs2RsemSingleSample.rsem_genome\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/rsem_hg19_gencode_v19.tar.gz\"",\""AdapterSs2RsemSingleSample.runtime_environment\"":\""dev\"",\""AdapterSs2RsemSingleSample.ref_flat\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/refFlat.txt\"",\""AdapterSs2RsemSingleSample.format_map\"":\""gs://broad-dsde-mint-dev-teststorage/format_map_example.json\"",\""AdapterSs2RsemSingleSample.bundle_uuid\"":\""c59a5720-ca82-429d-9d5b-6116987e221d\"",\""AdapterSs2RsemSingleSample.ref_fasta\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/Hg19.fa\"",\""AdapterSs2RsemSingleSample.run_type\"":\""run\"",\""AdapterSs2RsemSingleSample.bundle_version\"":\""2017-09-20T211432.976293Z\"",\""AdapterSs2RsemSingleSample.gtf\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/Gencode_v19/Gencode_v19.GTF\"",\""AdapterSs2RsemSingleSample.retry_seconds\"":1E+1,\""AdapterSs2RsemSingleSample.method\"":\""Ss2RsemSingleSample\"",\""AdapterSs2RsemSingleSample.dss_url\"":\""https://dss.staging.data.humancellatlas.org/v1\"",\""AdapterSs2RsemSingleSample.submit_url\"":\""http://api.ingest.staging.data.humancellatlas.org/\"",\""AdapterSs2RsemSingleSample.star_genome\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/star_hg19_gencode_v19.tar.gz\"",\""AdapterSs2RsemSingleSample.schema_version\"":\""v3\""}"",; ""labels"": ""{}""; },; ""calls"": {},; ""outputs"": {},; ""id"": ""f1ccad5e-73d4-4905-b62f-81ab96dded19"",; ""inputs"": {},; ""submission"": ""2017-12-14T17:16:01.748Z"",; ""status"": ""Failed"",; ""failures"": [; {; ""causedBy"": [; {; ""causedBy"": [],; ""message"": ""Some([Declaration type=Object name=prep.inputs expr=Some(prep.inputs)]) (of class scala.Some)""; }; ],; ""message"": ""Workflow input processing failed""; }; ],; ""end"": ""2017-12-14T17:16:20.791Z"",; ""start"": ""2017-12-14T17:16:20.747Z""; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3060#issuecomment-351777550
https://github.com/broadinstitute/cromwell/issues/3060#issuecomment-351777550:5854,Integrability,message,message,5854,"rence_bundle\"":\""bf51d668-3e14-4843-9bc7-5d676fdf0e01\"",\""AdapterSs2RsemSingleSample.rrna_interval\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/hg19.rRNA.interval_list\"",\""AdapterSs2RsemSingleSample.rsem_genome\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/rsem_hg19_gencode_v19.tar.gz\"",\""AdapterSs2RsemSingleSample.runtime_environment\"":\""dev\"",\""AdapterSs2RsemSingleSample.ref_flat\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/refFlat.txt\"",\""AdapterSs2RsemSingleSample.format_map\"":\""gs://broad-dsde-mint-dev-teststorage/format_map_example.json\"",\""AdapterSs2RsemSingleSample.bundle_uuid\"":\""c59a5720-ca82-429d-9d5b-6116987e221d\"",\""AdapterSs2RsemSingleSample.ref_fasta\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/Hg19.fa\"",\""AdapterSs2RsemSingleSample.run_type\"":\""run\"",\""AdapterSs2RsemSingleSample.bundle_version\"":\""2017-09-20T211432.976293Z\"",\""AdapterSs2RsemSingleSample.gtf\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/Gencode_v19/Gencode_v19.GTF\"",\""AdapterSs2RsemSingleSample.retry_seconds\"":1E+1,\""AdapterSs2RsemSingleSample.method\"":\""Ss2RsemSingleSample\"",\""AdapterSs2RsemSingleSample.dss_url\"":\""https://dss.staging.data.humancellatlas.org/v1\"",\""AdapterSs2RsemSingleSample.submit_url\"":\""http://api.ingest.staging.data.humancellatlas.org/\"",\""AdapterSs2RsemSingleSample.star_genome\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/star_hg19_gencode_v19.tar.gz\"",\""AdapterSs2RsemSingleSample.schema_version\"":\""v3\""}"",; ""labels"": ""{}""; },; ""calls"": {},; ""outputs"": {},; ""id"": ""f1ccad5e-73d4-4905-b62f-81ab96dded19"",; ""inputs"": {},; ""submission"": ""2017-12-14T17:16:01.748Z"",; ""status"": ""Failed"",; ""failures"": [; {; ""causedBy"": [; {; ""causedBy"": [],; ""message"": ""Some([Declaration type=Object name=prep.inputs expr=Some(prep.inputs)]) (of class scala.Some)""; }; ],; ""message"": ""Workflow input processing failed""; }; ],; ""end"": ""2017-12-14T17:16:20.791Z"",; ""start"": ""2017-12-14T17:16:20.747Z""; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3060#issuecomment-351777550
https://github.com/broadinstitute/cromwell/issues/3060#issuecomment-351777550:4114,Testability,test,teststorage,4114,"enome,\n },\n {\n 'name': 'rsem_genome',\n 'value': rsem_genome,\n }\n ],\n outputs = [\n analysis.bam_file,\n analysis.bam_trans,\n analysis.rna_metrics,\n analysis.aln_metrics,\n analysis.rsem_gene_results,\n analysis.rsem_isoform_results,\n analysis.rsem_gene_count,\n analysis.gene_unique_counts,\n analysis.exon_unique_counts,\n analysis.transcript_unique_counts\n ],\n format_map = format_map,\n submit_url = submit_url,\n input_bundle_uuid = bundle_uuid,\n reference_bundle = reference_bundle,\n run_type = run_type,\n schema_version = schema_version,\n method = method,\n retry_seconds = retry_seconds,\n timeout_seconds = timeout_seconds,\n runtime_environment = runtime_environment\n }\n}\n"",; ""workflowType"": ""WDL"",; ""options"": ""{\n \""read_from_cache\"": false\n}"",; ""inputs"": ""{\""AdapterSs2RsemSingleSample.timeout_seconds\"":1.2E+2,\""AdapterSs2RsemSingleSample.reference_bundle\"":\""bf51d668-3e14-4843-9bc7-5d676fdf0e01\"",\""AdapterSs2RsemSingleSample.rrna_interval\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/hg19.rRNA.interval_list\"",\""AdapterSs2RsemSingleSample.rsem_genome\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/rsem_hg19_gencode_v19.tar.gz\"",\""AdapterSs2RsemSingleSample.runtime_environment\"":\""dev\"",\""AdapterSs2RsemSingleSample.ref_flat\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/refFlat.txt\"",\""AdapterSs2RsemSingleSample.format_map\"":\""gs://broad-dsde-mint-dev-teststorage/format_map_example.json\"",\""AdapterSs2RsemSingleSample.bundle_uuid\"":\""c59a5720-ca82-429d-9d5b-6116987e221d\"",\""AdapterSs2RsemSingleSample.ref_fasta\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/Hg19.fa\"",\""AdapterSs2RsemSingleSample.run_type\"":\""run\"",\""AdapterSs2RsemSingleSample.bundle_version\"":\""2017-09-20T211432.976293Z\"",\""AdapterSs2RsemSingleSample.gtf\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/Gencode_v19/Gencode_v19.GTF\"",\""AdapterSs2RsemSingleSample.retry_seconds\"":1E+1,\""AdapterSs2RsemSingleSample.method\"":\""",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3060#issuecomment-351777550
https://github.com/broadinstitute/cromwell/issues/3060#issuecomment-351777550:4241,Testability,test,teststorage,4241,"ysis.rna_metrics,\n analysis.aln_metrics,\n analysis.rsem_gene_results,\n analysis.rsem_isoform_results,\n analysis.rsem_gene_count,\n analysis.gene_unique_counts,\n analysis.exon_unique_counts,\n analysis.transcript_unique_counts\n ],\n format_map = format_map,\n submit_url = submit_url,\n input_bundle_uuid = bundle_uuid,\n reference_bundle = reference_bundle,\n run_type = run_type,\n schema_version = schema_version,\n method = method,\n retry_seconds = retry_seconds,\n timeout_seconds = timeout_seconds,\n runtime_environment = runtime_environment\n }\n}\n"",; ""workflowType"": ""WDL"",; ""options"": ""{\n \""read_from_cache\"": false\n}"",; ""inputs"": ""{\""AdapterSs2RsemSingleSample.timeout_seconds\"":1.2E+2,\""AdapterSs2RsemSingleSample.reference_bundle\"":\""bf51d668-3e14-4843-9bc7-5d676fdf0e01\"",\""AdapterSs2RsemSingleSample.rrna_interval\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/hg19.rRNA.interval_list\"",\""AdapterSs2RsemSingleSample.rsem_genome\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/rsem_hg19_gencode_v19.tar.gz\"",\""AdapterSs2RsemSingleSample.runtime_environment\"":\""dev\"",\""AdapterSs2RsemSingleSample.ref_flat\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/refFlat.txt\"",\""AdapterSs2RsemSingleSample.format_map\"":\""gs://broad-dsde-mint-dev-teststorage/format_map_example.json\"",\""AdapterSs2RsemSingleSample.bundle_uuid\"":\""c59a5720-ca82-429d-9d5b-6116987e221d\"",\""AdapterSs2RsemSingleSample.ref_fasta\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/Hg19.fa\"",\""AdapterSs2RsemSingleSample.run_type\"":\""run\"",\""AdapterSs2RsemSingleSample.bundle_version\"":\""2017-09-20T211432.976293Z\"",\""AdapterSs2RsemSingleSample.gtf\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/Gencode_v19/Gencode_v19.GTF\"",\""AdapterSs2RsemSingleSample.retry_seconds\"":1E+1,\""AdapterSs2RsemSingleSample.method\"":\""Ss2RsemSingleSample\"",\""AdapterSs2RsemSingleSample.dss_url\"":\""https://dss.staging.data.humancellatlas.org/v1\"",\""AdapterSs2RsemSingleSa",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3060#issuecomment-351777550
https://github.com/broadinstitute/cromwell/issues/3060#issuecomment-351777550:4429,Testability,test,teststorage,4429,"ique_counts,\n analysis.transcript_unique_counts\n ],\n format_map = format_map,\n submit_url = submit_url,\n input_bundle_uuid = bundle_uuid,\n reference_bundle = reference_bundle,\n run_type = run_type,\n schema_version = schema_version,\n method = method,\n retry_seconds = retry_seconds,\n timeout_seconds = timeout_seconds,\n runtime_environment = runtime_environment\n }\n}\n"",; ""workflowType"": ""WDL"",; ""options"": ""{\n \""read_from_cache\"": false\n}"",; ""inputs"": ""{\""AdapterSs2RsemSingleSample.timeout_seconds\"":1.2E+2,\""AdapterSs2RsemSingleSample.reference_bundle\"":\""bf51d668-3e14-4843-9bc7-5d676fdf0e01\"",\""AdapterSs2RsemSingleSample.rrna_interval\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/hg19.rRNA.interval_list\"",\""AdapterSs2RsemSingleSample.rsem_genome\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/rsem_hg19_gencode_v19.tar.gz\"",\""AdapterSs2RsemSingleSample.runtime_environment\"":\""dev\"",\""AdapterSs2RsemSingleSample.ref_flat\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/refFlat.txt\"",\""AdapterSs2RsemSingleSample.format_map\"":\""gs://broad-dsde-mint-dev-teststorage/format_map_example.json\"",\""AdapterSs2RsemSingleSample.bundle_uuid\"":\""c59a5720-ca82-429d-9d5b-6116987e221d\"",\""AdapterSs2RsemSingleSample.ref_fasta\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/Hg19.fa\"",\""AdapterSs2RsemSingleSample.run_type\"":\""run\"",\""AdapterSs2RsemSingleSample.bundle_version\"":\""2017-09-20T211432.976293Z\"",\""AdapterSs2RsemSingleSample.gtf\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/Gencode_v19/Gencode_v19.GTF\"",\""AdapterSs2RsemSingleSample.retry_seconds\"":1E+1,\""AdapterSs2RsemSingleSample.method\"":\""Ss2RsemSingleSample\"",\""AdapterSs2RsemSingleSample.dss_url\"":\""https://dss.staging.data.humancellatlas.org/v1\"",\""AdapterSs2RsemSingleSample.submit_url\"":\""http://api.ingest.staging.data.humancellatlas.org/\"",\""AdapterSs2RsemSingleSample.star_genome\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/star_hg19",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3060#issuecomment-351777550
https://github.com/broadinstitute/cromwell/issues/3060#issuecomment-351777550:4543,Testability,test,teststorage,4543," input_bundle_uuid = bundle_uuid,\n reference_bundle = reference_bundle,\n run_type = run_type,\n schema_version = schema_version,\n method = method,\n retry_seconds = retry_seconds,\n timeout_seconds = timeout_seconds,\n runtime_environment = runtime_environment\n }\n}\n"",; ""workflowType"": ""WDL"",; ""options"": ""{\n \""read_from_cache\"": false\n}"",; ""inputs"": ""{\""AdapterSs2RsemSingleSample.timeout_seconds\"":1.2E+2,\""AdapterSs2RsemSingleSample.reference_bundle\"":\""bf51d668-3e14-4843-9bc7-5d676fdf0e01\"",\""AdapterSs2RsemSingleSample.rrna_interval\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/hg19.rRNA.interval_list\"",\""AdapterSs2RsemSingleSample.rsem_genome\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/rsem_hg19_gencode_v19.tar.gz\"",\""AdapterSs2RsemSingleSample.runtime_environment\"":\""dev\"",\""AdapterSs2RsemSingleSample.ref_flat\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/refFlat.txt\"",\""AdapterSs2RsemSingleSample.format_map\"":\""gs://broad-dsde-mint-dev-teststorage/format_map_example.json\"",\""AdapterSs2RsemSingleSample.bundle_uuid\"":\""c59a5720-ca82-429d-9d5b-6116987e221d\"",\""AdapterSs2RsemSingleSample.ref_fasta\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/Hg19.fa\"",\""AdapterSs2RsemSingleSample.run_type\"":\""run\"",\""AdapterSs2RsemSingleSample.bundle_version\"":\""2017-09-20T211432.976293Z\"",\""AdapterSs2RsemSingleSample.gtf\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/Gencode_v19/Gencode_v19.GTF\"",\""AdapterSs2RsemSingleSample.retry_seconds\"":1E+1,\""AdapterSs2RsemSingleSample.method\"":\""Ss2RsemSingleSample\"",\""AdapterSs2RsemSingleSample.dss_url\"":\""https://dss.staging.data.humancellatlas.org/v1\"",\""AdapterSs2RsemSingleSample.submit_url\"":\""http://api.ingest.staging.data.humancellatlas.org/\"",\""AdapterSs2RsemSingleSample.star_genome\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/star_hg19_gencode_v19.tar.gz\"",\""AdapterSs2RsemSingleSample.schema_version\"":\""v3\""}"",; ""labels"": ""{}""; },; ""calls"": {",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3060#issuecomment-351777550
https://github.com/broadinstitute/cromwell/issues/3060#issuecomment-351777550:4733,Testability,test,teststorage,4733,"seconds = timeout_seconds,\n runtime_environment = runtime_environment\n }\n}\n"",; ""workflowType"": ""WDL"",; ""options"": ""{\n \""read_from_cache\"": false\n}"",; ""inputs"": ""{\""AdapterSs2RsemSingleSample.timeout_seconds\"":1.2E+2,\""AdapterSs2RsemSingleSample.reference_bundle\"":\""bf51d668-3e14-4843-9bc7-5d676fdf0e01\"",\""AdapterSs2RsemSingleSample.rrna_interval\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/hg19.rRNA.interval_list\"",\""AdapterSs2RsemSingleSample.rsem_genome\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/rsem_hg19_gencode_v19.tar.gz\"",\""AdapterSs2RsemSingleSample.runtime_environment\"":\""dev\"",\""AdapterSs2RsemSingleSample.ref_flat\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/refFlat.txt\"",\""AdapterSs2RsemSingleSample.format_map\"":\""gs://broad-dsde-mint-dev-teststorage/format_map_example.json\"",\""AdapterSs2RsemSingleSample.bundle_uuid\"":\""c59a5720-ca82-429d-9d5b-6116987e221d\"",\""AdapterSs2RsemSingleSample.ref_fasta\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/Hg19.fa\"",\""AdapterSs2RsemSingleSample.run_type\"":\""run\"",\""AdapterSs2RsemSingleSample.bundle_version\"":\""2017-09-20T211432.976293Z\"",\""AdapterSs2RsemSingleSample.gtf\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/Gencode_v19/Gencode_v19.GTF\"",\""AdapterSs2RsemSingleSample.retry_seconds\"":1E+1,\""AdapterSs2RsemSingleSample.method\"":\""Ss2RsemSingleSample\"",\""AdapterSs2RsemSingleSample.dss_url\"":\""https://dss.staging.data.humancellatlas.org/v1\"",\""AdapterSs2RsemSingleSample.submit_url\"":\""http://api.ingest.staging.data.humancellatlas.org/\"",\""AdapterSs2RsemSingleSample.star_genome\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/star_hg19_gencode_v19.tar.gz\"",\""AdapterSs2RsemSingleSample.schema_version\"":\""v3\""}"",; ""labels"": ""{}""; },; ""calls"": {},; ""outputs"": {},; ""id"": ""f1ccad5e-73d4-4905-b62f-81ab96dded19"",; ""inputs"": {},; ""submission"": ""2017-12-14T17:16:01.748Z"",; ""status"": ""Failed"",; ""failures"": [; {; ""causedBy"": [; {; ""causedBy"":",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3060#issuecomment-351777550
https://github.com/broadinstitute/cromwell/issues/3060#issuecomment-351777550:4960,Testability,test,teststorage,4960,"ngleSample.reference_bundle\"":\""bf51d668-3e14-4843-9bc7-5d676fdf0e01\"",\""AdapterSs2RsemSingleSample.rrna_interval\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/hg19.rRNA.interval_list\"",\""AdapterSs2RsemSingleSample.rsem_genome\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/rsem_hg19_gencode_v19.tar.gz\"",\""AdapterSs2RsemSingleSample.runtime_environment\"":\""dev\"",\""AdapterSs2RsemSingleSample.ref_flat\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/refFlat.txt\"",\""AdapterSs2RsemSingleSample.format_map\"":\""gs://broad-dsde-mint-dev-teststorage/format_map_example.json\"",\""AdapterSs2RsemSingleSample.bundle_uuid\"":\""c59a5720-ca82-429d-9d5b-6116987e221d\"",\""AdapterSs2RsemSingleSample.ref_fasta\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/Hg19.fa\"",\""AdapterSs2RsemSingleSample.run_type\"":\""run\"",\""AdapterSs2RsemSingleSample.bundle_version\"":\""2017-09-20T211432.976293Z\"",\""AdapterSs2RsemSingleSample.gtf\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/Gencode_v19/Gencode_v19.GTF\"",\""AdapterSs2RsemSingleSample.retry_seconds\"":1E+1,\""AdapterSs2RsemSingleSample.method\"":\""Ss2RsemSingleSample\"",\""AdapterSs2RsemSingleSample.dss_url\"":\""https://dss.staging.data.humancellatlas.org/v1\"",\""AdapterSs2RsemSingleSample.submit_url\"":\""http://api.ingest.staging.data.humancellatlas.org/\"",\""AdapterSs2RsemSingleSample.star_genome\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/star_hg19_gencode_v19.tar.gz\"",\""AdapterSs2RsemSingleSample.schema_version\"":\""v3\""}"",; ""labels"": ""{}""; },; ""calls"": {},; ""outputs"": {},; ""id"": ""f1ccad5e-73d4-4905-b62f-81ab96dded19"",; ""inputs"": {},; ""submission"": ""2017-12-14T17:16:01.748Z"",; ""status"": ""Failed"",; ""failures"": [; {; ""causedBy"": [; {; ""causedBy"": [],; ""message"": ""Some([Declaration type=Object name=prep.inputs expr=Some(prep.inputs)]) (of class scala.Some)""; }; ],; ""message"": ""Workflow input processing failed""; }; ],; ""end"": ""2017-12-14T17:16:20.791Z"",; ""start"": ""2017-12-14T17:16:2",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3060#issuecomment-351777550
https://github.com/broadinstitute/cromwell/issues/3060#issuecomment-351777550:5390,Testability,test,teststorage,5390,"rence_bundle\"":\""bf51d668-3e14-4843-9bc7-5d676fdf0e01\"",\""AdapterSs2RsemSingleSample.rrna_interval\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/hg19.rRNA.interval_list\"",\""AdapterSs2RsemSingleSample.rsem_genome\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/rsem_hg19_gencode_v19.tar.gz\"",\""AdapterSs2RsemSingleSample.runtime_environment\"":\""dev\"",\""AdapterSs2RsemSingleSample.ref_flat\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/refFlat.txt\"",\""AdapterSs2RsemSingleSample.format_map\"":\""gs://broad-dsde-mint-dev-teststorage/format_map_example.json\"",\""AdapterSs2RsemSingleSample.bundle_uuid\"":\""c59a5720-ca82-429d-9d5b-6116987e221d\"",\""AdapterSs2RsemSingleSample.ref_fasta\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/Hg19.fa\"",\""AdapterSs2RsemSingleSample.run_type\"":\""run\"",\""AdapterSs2RsemSingleSample.bundle_version\"":\""2017-09-20T211432.976293Z\"",\""AdapterSs2RsemSingleSample.gtf\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/Gencode_v19/Gencode_v19.GTF\"",\""AdapterSs2RsemSingleSample.retry_seconds\"":1E+1,\""AdapterSs2RsemSingleSample.method\"":\""Ss2RsemSingleSample\"",\""AdapterSs2RsemSingleSample.dss_url\"":\""https://dss.staging.data.humancellatlas.org/v1\"",\""AdapterSs2RsemSingleSample.submit_url\"":\""http://api.ingest.staging.data.humancellatlas.org/\"",\""AdapterSs2RsemSingleSample.star_genome\"":\""gs://broad-dsde-mint-dev-teststorage/reference/Hg19_kco/star_hg19_gencode_v19.tar.gz\"",\""AdapterSs2RsemSingleSample.schema_version\"":\""v3\""}"",; ""labels"": ""{}""; },; ""calls"": {},; ""outputs"": {},; ""id"": ""f1ccad5e-73d4-4905-b62f-81ab96dded19"",; ""inputs"": {},; ""submission"": ""2017-12-14T17:16:01.748Z"",; ""status"": ""Failed"",; ""failures"": [; {; ""causedBy"": [; {; ""causedBy"": [],; ""message"": ""Some([Declaration type=Object name=prep.inputs expr=Some(prep.inputs)]) (of class scala.Some)""; }; ],; ""message"": ""Workflow input processing failed""; }; ],; ""end"": ""2017-12-14T17:16:20.791Z"",; ""start"": ""2017-12-14T17:16:20.747Z""; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3060#issuecomment-351777550
https://github.com/broadinstitute/cromwell/issues/3065#issuecomment-353106597:94,Deployability,Pipeline,Pipelines,94,"Just to clarify -- this isn't currently not possible on the JES backend, only Local. However, Pipelines APIv2 would allow for more flexible delocalization.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3065#issuecomment-353106597
https://github.com/broadinstitute/cromwell/issues/3065#issuecomment-353106597:131,Modifiability,flexible,flexible,131,"Just to clarify -- this isn't currently not possible on the JES backend, only Local. However, Pipelines APIv2 would allow for more flexible delocalization.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3065#issuecomment-353106597
https://github.com/broadinstitute/cromwell/issues/3065#issuecomment-395424176:102,Testability,log,logic,102,"No, although we've briefly discussed it with Chris and Miguel I think. We already implemented similar logic for CWL but not for WDL (which will admittedly be a little more complicated). There's quite a few other cases like that that we can now cover in Papi2, basically any file/directory to delocalize that can't be determined statically before the job is submitted we couldn't support in v1 but could now in v2.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3065#issuecomment-395424176
https://github.com/broadinstitute/cromwell/pull/3066#issuecomment-352044523:94,Deployability,integrat,integrationTestCases,94,"@cjllanwarne new lines adjusted, so are my intellij settings thanks to Jose. I'm thinking the integrationTestCases should run weekly instead of nightly even. @jsotobroad as the original creator of the integrationTestCases -- does that sound okay?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3066#issuecomment-352044523
https://github.com/broadinstitute/cromwell/pull/3066#issuecomment-352044523:201,Deployability,integrat,integrationTestCases,201,"@cjllanwarne new lines adjusted, so are my intellij settings thanks to Jose. I'm thinking the integrationTestCases should run weekly instead of nightly even. @jsotobroad as the original creator of the integrationTestCases -- does that sound okay?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3066#issuecomment-352044523
https://github.com/broadinstitute/cromwell/pull/3066#issuecomment-352044523:94,Integrability,integrat,integrationTestCases,94,"@cjllanwarne new lines adjusted, so are my intellij settings thanks to Jose. I'm thinking the integrationTestCases should run weekly instead of nightly even. @jsotobroad as the original creator of the integrationTestCases -- does that sound okay?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3066#issuecomment-352044523
https://github.com/broadinstitute/cromwell/pull/3066#issuecomment-352044523:201,Integrability,integrat,integrationTestCases,201,"@cjllanwarne new lines adjusted, so are my intellij settings thanks to Jose. I'm thinking the integrationTestCases should run weekly instead of nightly even. @jsotobroad as the original creator of the integrationTestCases -- does that sound okay?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3066#issuecomment-352044523
https://github.com/broadinstitute/cromwell/pull/3066#issuecomment-352071974:187,Testability,test,tests,187,The team should decide at what cadence they want to see that current develop does have any regression as far as whatever workflows it runs is concerned. At the time when we created those tests it was decided the team wanted to see them daily. If its a larger test bed then maybe weekly makes sense in terms of $$ and how little/much does the team get out of seeing it daily.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3066#issuecomment-352071974
https://github.com/broadinstitute/cromwell/pull/3066#issuecomment-352071974:259,Testability,test,test,259,The team should decide at what cadence they want to see that current develop does have any regression as far as whatever workflows it runs is concerned. At the time when we created those tests it was decided the team wanted to see them daily. If its a larger test bed then maybe weekly makes sense in terms of $$ and how little/much does the team get out of seeing it daily.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3066#issuecomment-352071974
https://github.com/broadinstitute/cromwell/pull/3066#issuecomment-352072779:44,Availability,down,down,44,In that case I‚Äôd side with more and dialing down instead of less and dialing up,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3066#issuecomment-352072779
https://github.com/broadinstitute/cromwell/pull/3066#issuecomment-352073368:115,Availability,down,down,115,"@geoffjentry The main advantage of running these test cases daily vs weekly seems to be that it‚Äôs easier to narrow down which change couldve caused this test suite to fail. However, it seems unlikely to me that these tests could find breaking changes everyday that the centaur standard test cases wouldn‚Äôt already uncover. I see these tests as a release requirement for Cromwell more than anything else. However, it‚Äôs totally upto the team on whatever makes them most comfortable, I don‚Äôt have a strong opinion on it.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3066#issuecomment-352073368
https://github.com/broadinstitute/cromwell/pull/3066#issuecomment-352073368:346,Deployability,release,release,346,"@geoffjentry The main advantage of running these test cases daily vs weekly seems to be that it‚Äôs easier to narrow down which change couldve caused this test suite to fail. However, it seems unlikely to me that these tests could find breaking changes everyday that the centaur standard test cases wouldn‚Äôt already uncover. I see these tests as a release requirement for Cromwell more than anything else. However, it‚Äôs totally upto the team on whatever makes them most comfortable, I don‚Äôt have a strong opinion on it.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3066#issuecomment-352073368
https://github.com/broadinstitute/cromwell/pull/3066#issuecomment-352073368:49,Testability,test,test,49,"@geoffjentry The main advantage of running these test cases daily vs weekly seems to be that it‚Äôs easier to narrow down which change couldve caused this test suite to fail. However, it seems unlikely to me that these tests could find breaking changes everyday that the centaur standard test cases wouldn‚Äôt already uncover. I see these tests as a release requirement for Cromwell more than anything else. However, it‚Äôs totally upto the team on whatever makes them most comfortable, I don‚Äôt have a strong opinion on it.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3066#issuecomment-352073368
https://github.com/broadinstitute/cromwell/pull/3066#issuecomment-352073368:153,Testability,test,test,153,"@geoffjentry The main advantage of running these test cases daily vs weekly seems to be that it‚Äôs easier to narrow down which change couldve caused this test suite to fail. However, it seems unlikely to me that these tests could find breaking changes everyday that the centaur standard test cases wouldn‚Äôt already uncover. I see these tests as a release requirement for Cromwell more than anything else. However, it‚Äôs totally upto the team on whatever makes them most comfortable, I don‚Äôt have a strong opinion on it.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3066#issuecomment-352073368
https://github.com/broadinstitute/cromwell/pull/3066#issuecomment-352073368:217,Testability,test,tests,217,"@geoffjentry The main advantage of running these test cases daily vs weekly seems to be that it‚Äôs easier to narrow down which change couldve caused this test suite to fail. However, it seems unlikely to me that these tests could find breaking changes everyday that the centaur standard test cases wouldn‚Äôt already uncover. I see these tests as a release requirement for Cromwell more than anything else. However, it‚Äôs totally upto the team on whatever makes them most comfortable, I don‚Äôt have a strong opinion on it.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3066#issuecomment-352073368
https://github.com/broadinstitute/cromwell/pull/3066#issuecomment-352073368:286,Testability,test,test,286,"@geoffjentry The main advantage of running these test cases daily vs weekly seems to be that it‚Äôs easier to narrow down which change couldve caused this test suite to fail. However, it seems unlikely to me that these tests could find breaking changes everyday that the centaur standard test cases wouldn‚Äôt already uncover. I see these tests as a release requirement for Cromwell more than anything else. However, it‚Äôs totally upto the team on whatever makes them most comfortable, I don‚Äôt have a strong opinion on it.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3066#issuecomment-352073368
https://github.com/broadinstitute/cromwell/pull/3066#issuecomment-352073368:335,Testability,test,tests,335,"@geoffjentry The main advantage of running these test cases daily vs weekly seems to be that it‚Äôs easier to narrow down which change couldve caused this test suite to fail. However, it seems unlikely to me that these tests could find breaking changes everyday that the centaur standard test cases wouldn‚Äôt already uncover. I see these tests as a release requirement for Cromwell more than anything else. However, it‚Äôs totally upto the team on whatever makes them most comfortable, I don‚Äôt have a strong opinion on it.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3066#issuecomment-352073368
https://github.com/broadinstitute/cromwell/pull/3072#issuecomment-352212169:120,Deployability,hotfix,hotfix,120,There was indeed a case where a workflow could get stuck. I added a commit to this PR that fixed it.; I think we should hotfix this to 30 (at least the last commit for sure),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3072#issuecomment-352212169
https://github.com/broadinstitute/cromwell/issues/3073#issuecomment-516557267:116,Availability,down,down,116,Updating to say that I ran across the other day and it was only a vague memory of this issue which led me to not go down a giant rabbit hole of WTF,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3073#issuecomment-516557267
https://github.com/broadinstitute/cromwell/issues/3074#issuecomment-378353821:39,Performance,cache,cache,39,This also causes flakiness in the call cache capoeira centaur test,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3074#issuecomment-378353821
https://github.com/broadinstitute/cromwell/issues/3074#issuecomment-378353821:62,Testability,test,test,62,This also causes flakiness in the call cache capoeira centaur test,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3074#issuecomment-378353821
https://github.com/broadinstitute/cromwell/pull/3076#issuecomment-352557525:34,Deployability,Hotfix,Hotfix,34,"I'd just mark the original PR as ""Hotfix Candidate"" tbh, then we can do everything all in one commit",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3076#issuecomment-352557525
https://github.com/broadinstitute/cromwell/pull/3077#issuecomment-352869302:36,Testability,test,test,36,@cjllanwarne I just added a centaur test. I used the metadata to check the instance type on JES but I could see about using unix commands too.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3077#issuecomment-352869302
https://github.com/broadinstitute/cromwell/pull/3079#issuecomment-355723031:195,Deployability,patch,patches,195,"PR comments addressed, and tests re-passing. Changes include:. - Primitive and non-primitive file types.; - Primitive 'Dir' now 'Directory'.; - Split up and fixed test descriptions.; - Exception patches.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3079#issuecomment-355723031
https://github.com/broadinstitute/cromwell/pull/3079#issuecomment-355723031:27,Testability,test,tests,27,"PR comments addressed, and tests re-passing. Changes include:. - Primitive and non-primitive file types.; - Primitive 'Dir' now 'Directory'.; - Split up and fixed test descriptions.; - Exception patches.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3079#issuecomment-355723031
https://github.com/broadinstitute/cromwell/pull/3079#issuecomment-355723031:163,Testability,test,test,163,"PR comments addressed, and tests re-passing. Changes include:. - Primitive and non-primitive file types.; - Primitive 'Dir' now 'Directory'.; - Split up and fixed test descriptions.; - Exception patches.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3079#issuecomment-355723031
https://github.com/broadinstitute/cromwell/issues/3083#issuecomment-359793700:210,Deployability,hotfix,hotfix,210,"Yes, we'd still like to be able to get the total results count in the json response, which is a little more convenient and gives us a little more info than a total page count. Thanks for putting that in the 30 hotfix https://github.com/broadinstitute/cromwell/pull/3145. We would definitely like to continue to have that functionality in future versions of Cromwell.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3083#issuecomment-359793700
https://github.com/broadinstitute/cromwell/issues/3085#issuecomment-353350550:160,Security,access,access,160,Just to note that it might be slightly not backward compatible as people who have their accounts set up such that they gave the default compute service account access to the data they need will now also have to ensure the `user_service_account` also has access to the data (which may already be the case but..); Otherwise it should be pretty straightforward to do.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3085#issuecomment-353350550
https://github.com/broadinstitute/cromwell/issues/3085#issuecomment-353350550:254,Security,access,access,254,Just to note that it might be slightly not backward compatible as people who have their accounts set up such that they gave the default compute service account access to the data they need will now also have to ensure the `user_service_account` also has access to the data (which may already be the case but..); Otherwise it should be pretty straightforward to do.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3085#issuecomment-353350550
https://github.com/broadinstitute/cromwell/issues/3088#issuecomment-353467537:0,Deployability,Update,Update,0,"Update: I think this is caused by the `.toTry.get` here: https://github.com/broadinstitute/cromwell/blob/f9cfd25fcf6f29ce50ea532334f30a38a247a7dd/backend/src/main/scala/cromwell/backend/standard/StandardAsyncExecutionActor.scala#L257-L260. When the evaluation fails, the actor crashes, and the supervisor must be restarting it indefinitely to try again... EDIT: Switched floating link to permalink. -kshakir",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3088#issuecomment-353467537
https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573:7165,Integrability,depend,depending,7165,"c754c8936/src/jdk.scripting.nashorn/share/classes/jdk/nashorn/internal/runtime/linker/JSObjectLinker.java#l87. The BeanLinker generates the dynamic call to the map getter:. - https://github.com/JetBrains/jdk8u_nashorn/blob/jdk8u76-b03/src/jdk/internal/dynalink/beans/BeanLinker.java#L179-L205; - http://hg.openjdk.java.net/jdk9/jdk9/nashorn/file/17cc754c8936/src/jdk.dynalink/share/classes/jdk/dynalink/beans/BeanLinker.java#l218; */; final String expr = expr(; ""print('testKeyMapNonString hello ' + obj[true]);"",; ""obj;""; );; final Map<Object, Object> obj = Collections.singletonMap(true, ""world"");; final Map<String, Object> args = Collections.singletonMap(""obj"", obj);; eval(expr, args);; }. /**; * Fail to stringify a java.util.Map.; */; private static void testStringifyMap() throws ScriptException {; /*; Nashorn's JSON.stringify identifies that a map is an object, but doesn't convert Java maps (nor Java arrays) to; a string. NOTE: There has been some work in jdk8u and jdk9 to fix issues with stringify, so the code varies a; bit depending on the jdk version. - https://github.com/JetBrains/jdk8u_nashorn/blob/jdk8u76-b03/src/jdk/nashorn/internal/objects/NativeJSON.java#L267-L272; - http://hg.openjdk.java.net/jdk9/jdk9/nashorn/file/17cc754c8936/src/jdk.scripting.nashorn/share/classes/jdk/nashorn/internal/objects/NativeJSON.java#l288. Maps do get special treatment in Nashorn and are passed around internally:. - https://wiki.openjdk.java.net/display/Nashorn/Nashorn+extensions#Nashornextensions-SpecialtreatmentofobjectsofspecificJavaclasses. In this case the value within NativeJSON.str() is the Java map instance and not a ScriptObject nor a JSObject.; Thus the code falls through and returns UNDEFINED. If the code didn't bypass the if-statement the block would; run NativeJSON.JO() and attempt to get the value's keys. - https://github.com/JetBrains/jdk8u_nashorn/blob/jdk8u76-b03/src/jdk/nashorn/internal/objects/NativeJSON.java#L287; - http://hg.openjdk.java.net/jdk9/jdk9/nashorn/f",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573
https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573:12639,Performance,load,loader,12639,"(expr, context);; }. private static final NashornScriptEngineFactory ENGINE_FACTORY = new NashornScriptEngineFactory();. /**; * Add stricter Nashorn arguments to the default `-doe`.; *; * @see <a href=""https://docs.oracle.com/javase/8/docs/technotes/tools/windows/jjs.html"">JJS docs and options</a>; * @see <a href=""https://github.com/JetBrains/jdk8u_nashorn/blob/jdk8u76-b03/src/jdk/nashorn/internal/runtime/resources/Options.properties"">Nashorn supported options (github) </a>; * @see <a href=""http://hg.openjdk.java.net/jdk8/jdk8/nashorn/file/5dbdae28a6f3/src/jdk/nashorn/internal/runtime/resources/Options.properties"">Nashorn supported options</a>; * @see jdk.nashorn.api.scripting.NashornScriptEngineFactory#DEFAULT_OPTIONS; */; private static String[] nashornStrictArgs = {; ""-doe"", ""-strict"", ""--no-java"", ""--no-syntax-extensions"", ""--language=es5""; };. /**; * Don't allow any java classes.; */; private static ClassFilter noJavaClassFilter = anyClass -> false;. /**; * Copy/paste of the private jdk.nashorn.api.scripting.NashornScriptEngineFactory#getAppClassLoader().; * Of all the overloads of jdk.nashorn.api.scripting.NashornScriptEngineFactory#getScriptEngine, there is no jdk8; * one that receives just args and a class filter.; *; * @see jdk.nashorn.api.scripting.NashornScriptEngineFactory#getScriptEngine; * @see jdk.nashorn.api.scripting.NashornScriptEngineFactory#getAppClassLoader; */; private static ClassLoader getNashornClassLoader() {; // Revisit: script engine implementation needs the capability to; // find the class loader of the context in which the script engine; // is running so that classes will be found and loaded properly; final ClassLoader ccl = Thread.currentThread().getContextClassLoader();; return (ccl == null) ? NashornScriptEngineFactory.class.getClassLoader() : ccl;; }. private static final String LINE_SEPARATOR = System.getProperty(""line.separator"");. private static String expr(String... lines) {; return String.join(LINE_SEPARATOR, lines);; }; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573
https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573:12737,Performance,load,loaded,12737,"(expr, context);; }. private static final NashornScriptEngineFactory ENGINE_FACTORY = new NashornScriptEngineFactory();. /**; * Add stricter Nashorn arguments to the default `-doe`.; *; * @see <a href=""https://docs.oracle.com/javase/8/docs/technotes/tools/windows/jjs.html"">JJS docs and options</a>; * @see <a href=""https://github.com/JetBrains/jdk8u_nashorn/blob/jdk8u76-b03/src/jdk/nashorn/internal/runtime/resources/Options.properties"">Nashorn supported options (github) </a>; * @see <a href=""http://hg.openjdk.java.net/jdk8/jdk8/nashorn/file/5dbdae28a6f3/src/jdk/nashorn/internal/runtime/resources/Options.properties"">Nashorn supported options</a>; * @see jdk.nashorn.api.scripting.NashornScriptEngineFactory#DEFAULT_OPTIONS; */; private static String[] nashornStrictArgs = {; ""-doe"", ""-strict"", ""--no-java"", ""--no-syntax-extensions"", ""--language=es5""; };. /**; * Don't allow any java classes.; */; private static ClassFilter noJavaClassFilter = anyClass -> false;. /**; * Copy/paste of the private jdk.nashorn.api.scripting.NashornScriptEngineFactory#getAppClassLoader().; * Of all the overloads of jdk.nashorn.api.scripting.NashornScriptEngineFactory#getScriptEngine, there is no jdk8; * one that receives just args and a class filter.; *; * @see jdk.nashorn.api.scripting.NashornScriptEngineFactory#getScriptEngine; * @see jdk.nashorn.api.scripting.NashornScriptEngineFactory#getAppClassLoader; */; private static ClassLoader getNashornClassLoader() {; // Revisit: script engine implementation needs the capability to; // find the class loader of the context in which the script engine; // is running so that classes will be found and loaded properly; final ClassLoader ccl = Thread.currentThread().getContextClassLoader();; return (ccl == null) ? NashornScriptEngineFactory.class.getClassLoader() : ccl;; }. private static final String LINE_SEPARATOR = System.getProperty(""line.separator"");. private static String expr(String... lines) {; return String.join(LINE_SEPARATOR, lines);; }; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573
https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573:2174,Security,access,accessors,2174,"StringifyJSObject();; testStringifyScriptObject();; }. /**; * Create and use an object in Javascript, return it to Java, and then pass it back into similar Javascript. In the; * second Javascript call we cannot use our key in the same way.; */; private static void testKeyCastImplicit() throws ScriptException {; final String expr1 = expr(; ""var obj = {};"",; ""obj[true] = 'world';"",; ""print('testKeyCastImplicit hello init ' + obj[true]);"",; ""obj;""; );; final Map<String, Object> args1 = Collections.emptyMap();; final JSObject result1 = (JSObject) eval(expr1, args1);; ; /*; JSObjectLinker does not cast keys to strings during get (and similarly in put).; - https://github.com/JetBrains/jdk8u_nashorn/blob/jdk8u76-b03/src/jdk/nashorn/internal/runtime/linker/JSObjectLinker.java#L179; - http://hg.openjdk.java.net/jdk9/jdk9/nashorn/file/17cc754c8936/src/jdk.scripting.nashorn/share/classes/jdk/nashorn/internal/runtime/linker/JSObjectLinker.java#l190. According to ECMA, property accessors in brackets are expressions and not identifier-name-string:. > 3. Let propertyNameReference be the result of evaluating Expression.; > 4. Let propertyNameValue be GetValue(propertyNameReference).; > ...; > 6. Let propertyNameString be ToString(propertyNameValue). - https://www.ecma-international.org/ecma-262/5.1/#sec-11.2.1. Similarly according to the MDN:. > Property names must be strings. This means that non-string objects cannot be used as keys in the object. Any; > non-string object, including a number, is typecasted into a string via the toString method. - https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Property_Accessors#Property_names. This is not totally unexpected as according to the Nashorn engine notes:. > not every operation and script API (JSON, Array, Function's properties/functions) treats ScriptObjectMirror; > and jdk.nashorn.internal.runtime.ScriptObject uniformly. There are places where ScriptObjects work as; > expected but if you pass ScriptObjectMir",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573
https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573:1020,Testability,test,testKeyCastImplicit,1020,"*TL;DR Good news: I can fix JSON.stringify in my upcoming PR. Bad news: it breaks other JSON**. ```java; import jdk.nashorn.api.scripting.AbstractJSObject;; import jdk.nashorn.api.scripting.ClassFilter;; import jdk.nashorn.api.scripting.JSObject;; import jdk.nashorn.api.scripting.NashornScriptEngineFactory;. import javax.script.Bindings;; import javax.script.ScriptContext;; import javax.script.ScriptEngine;; import javax.script.ScriptException;; import javax.script.SimpleScriptContext;; import java.util.Collection;; import java.util.Collections;; import java.util.Map;; import java.util.Set;. /**; * Example showing that a JSObject will not cast a property key to string, plus an example showing how JSON.stringify; * returns null for Java maps. So:; * - If you need non-string key expressions ex: 'myObj[true]', then do not pass in a JSObject.; * - If you need to use JSON.stringify, then do not pass in a java.util.Map.; */; public class Main {; public static void main(String[] args) throws ScriptException {; testKeyCastImplicit();; testKeyCastExplicit();; System.out.println(""---"");; testKeyMapString();; testKeyMapNonString();; System.out.println(""---"");; testStringifyMap();; testStringifyJSObject();; testStringifyScriptObject();; }. /**; * Create and use an object in Javascript, return it to Java, and then pass it back into similar Javascript. In the; * second Javascript call we cannot use our key in the same way.; */; private static void testKeyCastImplicit() throws ScriptException {; final String expr1 = expr(; ""var obj = {};"",; ""obj[true] = 'world';"",; ""print('testKeyCastImplicit hello init ' + obj[true]);"",; ""obj;""; );; final Map<String, Object> args1 = Collections.emptyMap();; final JSObject result1 = (JSObject) eval(expr1, args1);; ; /*; JSObjectLinker does not cast keys to strings during get (and similarly in put).; - https://github.com/JetBrains/jdk8u_nashorn/blob/jdk8u76-b03/src/jdk/nashorn/internal/runtime/linker/JSObjectLinker.java#L179; - http://hg.openjdk.jav",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573
https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573:1044,Testability,test,testKeyCastExplicit,1044,"*TL;DR Good news: I can fix JSON.stringify in my upcoming PR. Bad news: it breaks other JSON**. ```java; import jdk.nashorn.api.scripting.AbstractJSObject;; import jdk.nashorn.api.scripting.ClassFilter;; import jdk.nashorn.api.scripting.JSObject;; import jdk.nashorn.api.scripting.NashornScriptEngineFactory;. import javax.script.Bindings;; import javax.script.ScriptContext;; import javax.script.ScriptEngine;; import javax.script.ScriptException;; import javax.script.SimpleScriptContext;; import java.util.Collection;; import java.util.Collections;; import java.util.Map;; import java.util.Set;. /**; * Example showing that a JSObject will not cast a property key to string, plus an example showing how JSON.stringify; * returns null for Java maps. So:; * - If you need non-string key expressions ex: 'myObj[true]', then do not pass in a JSObject.; * - If you need to use JSON.stringify, then do not pass in a java.util.Map.; */; public class Main {; public static void main(String[] args) throws ScriptException {; testKeyCastImplicit();; testKeyCastExplicit();; System.out.println(""---"");; testKeyMapString();; testKeyMapNonString();; System.out.println(""---"");; testStringifyMap();; testStringifyJSObject();; testStringifyScriptObject();; }. /**; * Create and use an object in Javascript, return it to Java, and then pass it back into similar Javascript. In the; * second Javascript call we cannot use our key in the same way.; */; private static void testKeyCastImplicit() throws ScriptException {; final String expr1 = expr(; ""var obj = {};"",; ""obj[true] = 'world';"",; ""print('testKeyCastImplicit hello init ' + obj[true]);"",; ""obj;""; );; final Map<String, Object> args1 = Collections.emptyMap();; final JSObject result1 = (JSObject) eval(expr1, args1);; ; /*; JSObjectLinker does not cast keys to strings during get (and similarly in put).; - https://github.com/JetBrains/jdk8u_nashorn/blob/jdk8u76-b03/src/jdk/nashorn/internal/runtime/linker/JSObjectLinker.java#L179; - http://hg.openjdk.jav",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573
https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573:1096,Testability,test,testKeyMapString,1096,"jdk.nashorn.api.scripting.AbstractJSObject;; import jdk.nashorn.api.scripting.ClassFilter;; import jdk.nashorn.api.scripting.JSObject;; import jdk.nashorn.api.scripting.NashornScriptEngineFactory;. import javax.script.Bindings;; import javax.script.ScriptContext;; import javax.script.ScriptEngine;; import javax.script.ScriptException;; import javax.script.SimpleScriptContext;; import java.util.Collection;; import java.util.Collections;; import java.util.Map;; import java.util.Set;. /**; * Example showing that a JSObject will not cast a property key to string, plus an example showing how JSON.stringify; * returns null for Java maps. So:; * - If you need non-string key expressions ex: 'myObj[true]', then do not pass in a JSObject.; * - If you need to use JSON.stringify, then do not pass in a java.util.Map.; */; public class Main {; public static void main(String[] args) throws ScriptException {; testKeyCastImplicit();; testKeyCastExplicit();; System.out.println(""---"");; testKeyMapString();; testKeyMapNonString();; System.out.println(""---"");; testStringifyMap();; testStringifyJSObject();; testStringifyScriptObject();; }. /**; * Create and use an object in Javascript, return it to Java, and then pass it back into similar Javascript. In the; * second Javascript call we cannot use our key in the same way.; */; private static void testKeyCastImplicit() throws ScriptException {; final String expr1 = expr(; ""var obj = {};"",; ""obj[true] = 'world';"",; ""print('testKeyCastImplicit hello init ' + obj[true]);"",; ""obj;""; );; final Map<String, Object> args1 = Collections.emptyMap();; final JSObject result1 = (JSObject) eval(expr1, args1);; ; /*; JSObjectLinker does not cast keys to strings during get (and similarly in put).; - https://github.com/JetBrains/jdk8u_nashorn/blob/jdk8u76-b03/src/jdk/nashorn/internal/runtime/linker/JSObjectLinker.java#L179; - http://hg.openjdk.java.net/jdk9/jdk9/nashorn/file/17cc754c8936/src/jdk.scripting.nashorn/share/classes/jdk/nashorn/internal/runtime/l",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573
https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573:1117,Testability,test,testKeyMapNonString,1117,"jdk.nashorn.api.scripting.AbstractJSObject;; import jdk.nashorn.api.scripting.ClassFilter;; import jdk.nashorn.api.scripting.JSObject;; import jdk.nashorn.api.scripting.NashornScriptEngineFactory;. import javax.script.Bindings;; import javax.script.ScriptContext;; import javax.script.ScriptEngine;; import javax.script.ScriptException;; import javax.script.SimpleScriptContext;; import java.util.Collection;; import java.util.Collections;; import java.util.Map;; import java.util.Set;. /**; * Example showing that a JSObject will not cast a property key to string, plus an example showing how JSON.stringify; * returns null for Java maps. So:; * - If you need non-string key expressions ex: 'myObj[true]', then do not pass in a JSObject.; * - If you need to use JSON.stringify, then do not pass in a java.util.Map.; */; public class Main {; public static void main(String[] args) throws ScriptException {; testKeyCastImplicit();; testKeyCastExplicit();; System.out.println(""---"");; testKeyMapString();; testKeyMapNonString();; System.out.println(""---"");; testStringifyMap();; testStringifyJSObject();; testStringifyScriptObject();; }. /**; * Create and use an object in Javascript, return it to Java, and then pass it back into similar Javascript. In the; * second Javascript call we cannot use our key in the same way.; */; private static void testKeyCastImplicit() throws ScriptException {; final String expr1 = expr(; ""var obj = {};"",; ""obj[true] = 'world';"",; ""print('testKeyCastImplicit hello init ' + obj[true]);"",; ""obj;""; );; final Map<String, Object> args1 = Collections.emptyMap();; final JSObject result1 = (JSObject) eval(expr1, args1);; ; /*; JSObjectLinker does not cast keys to strings during get (and similarly in put).; - https://github.com/JetBrains/jdk8u_nashorn/blob/jdk8u76-b03/src/jdk/nashorn/internal/runtime/linker/JSObjectLinker.java#L179; - http://hg.openjdk.java.net/jdk9/jdk9/nashorn/file/17cc754c8936/src/jdk.scripting.nashorn/share/classes/jdk/nashorn/internal/runtime/l",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573
https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573:1169,Testability,test,testStringifyMap,1169,"er;; import jdk.nashorn.api.scripting.JSObject;; import jdk.nashorn.api.scripting.NashornScriptEngineFactory;. import javax.script.Bindings;; import javax.script.ScriptContext;; import javax.script.ScriptEngine;; import javax.script.ScriptException;; import javax.script.SimpleScriptContext;; import java.util.Collection;; import java.util.Collections;; import java.util.Map;; import java.util.Set;. /**; * Example showing that a JSObject will not cast a property key to string, plus an example showing how JSON.stringify; * returns null for Java maps. So:; * - If you need non-string key expressions ex: 'myObj[true]', then do not pass in a JSObject.; * - If you need to use JSON.stringify, then do not pass in a java.util.Map.; */; public class Main {; public static void main(String[] args) throws ScriptException {; testKeyCastImplicit();; testKeyCastExplicit();; System.out.println(""---"");; testKeyMapString();; testKeyMapNonString();; System.out.println(""---"");; testStringifyMap();; testStringifyJSObject();; testStringifyScriptObject();; }. /**; * Create and use an object in Javascript, return it to Java, and then pass it back into similar Javascript. In the; * second Javascript call we cannot use our key in the same way.; */; private static void testKeyCastImplicit() throws ScriptException {; final String expr1 = expr(; ""var obj = {};"",; ""obj[true] = 'world';"",; ""print('testKeyCastImplicit hello init ' + obj[true]);"",; ""obj;""; );; final Map<String, Object> args1 = Collections.emptyMap();; final JSObject result1 = (JSObject) eval(expr1, args1);; ; /*; JSObjectLinker does not cast keys to strings during get (and similarly in put).; - https://github.com/JetBrains/jdk8u_nashorn/blob/jdk8u76-b03/src/jdk/nashorn/internal/runtime/linker/JSObjectLinker.java#L179; - http://hg.openjdk.java.net/jdk9/jdk9/nashorn/file/17cc754c8936/src/jdk.scripting.nashorn/share/classes/jdk/nashorn/internal/runtime/linker/JSObjectLinker.java#l190. According to ECMA, property accessors in brackets are ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573
https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573:1190,Testability,test,testStringifyJSObject,1190,"er;; import jdk.nashorn.api.scripting.JSObject;; import jdk.nashorn.api.scripting.NashornScriptEngineFactory;. import javax.script.Bindings;; import javax.script.ScriptContext;; import javax.script.ScriptEngine;; import javax.script.ScriptException;; import javax.script.SimpleScriptContext;; import java.util.Collection;; import java.util.Collections;; import java.util.Map;; import java.util.Set;. /**; * Example showing that a JSObject will not cast a property key to string, plus an example showing how JSON.stringify; * returns null for Java maps. So:; * - If you need non-string key expressions ex: 'myObj[true]', then do not pass in a JSObject.; * - If you need to use JSON.stringify, then do not pass in a java.util.Map.; */; public class Main {; public static void main(String[] args) throws ScriptException {; testKeyCastImplicit();; testKeyCastExplicit();; System.out.println(""---"");; testKeyMapString();; testKeyMapNonString();; System.out.println(""---"");; testStringifyMap();; testStringifyJSObject();; testStringifyScriptObject();; }. /**; * Create and use an object in Javascript, return it to Java, and then pass it back into similar Javascript. In the; * second Javascript call we cannot use our key in the same way.; */; private static void testKeyCastImplicit() throws ScriptException {; final String expr1 = expr(; ""var obj = {};"",; ""obj[true] = 'world';"",; ""print('testKeyCastImplicit hello init ' + obj[true]);"",; ""obj;""; );; final Map<String, Object> args1 = Collections.emptyMap();; final JSObject result1 = (JSObject) eval(expr1, args1);; ; /*; JSObjectLinker does not cast keys to strings during get (and similarly in put).; - https://github.com/JetBrains/jdk8u_nashorn/blob/jdk8u76-b03/src/jdk/nashorn/internal/runtime/linker/JSObjectLinker.java#L179; - http://hg.openjdk.java.net/jdk9/jdk9/nashorn/file/17cc754c8936/src/jdk.scripting.nashorn/share/classes/jdk/nashorn/internal/runtime/linker/JSObjectLinker.java#l190. According to ECMA, property accessors in brackets are ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573
https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573:1216,Testability,test,testStringifyScriptObject,1216,"er;; import jdk.nashorn.api.scripting.JSObject;; import jdk.nashorn.api.scripting.NashornScriptEngineFactory;. import javax.script.Bindings;; import javax.script.ScriptContext;; import javax.script.ScriptEngine;; import javax.script.ScriptException;; import javax.script.SimpleScriptContext;; import java.util.Collection;; import java.util.Collections;; import java.util.Map;; import java.util.Set;. /**; * Example showing that a JSObject will not cast a property key to string, plus an example showing how JSON.stringify; * returns null for Java maps. So:; * - If you need non-string key expressions ex: 'myObj[true]', then do not pass in a JSObject.; * - If you need to use JSON.stringify, then do not pass in a java.util.Map.; */; public class Main {; public static void main(String[] args) throws ScriptException {; testKeyCastImplicit();; testKeyCastExplicit();; System.out.println(""---"");; testKeyMapString();; testKeyMapNonString();; System.out.println(""---"");; testStringifyMap();; testStringifyJSObject();; testStringifyScriptObject();; }. /**; * Create and use an object in Javascript, return it to Java, and then pass it back into similar Javascript. In the; * second Javascript call we cannot use our key in the same way.; */; private static void testKeyCastImplicit() throws ScriptException {; final String expr1 = expr(; ""var obj = {};"",; ""obj[true] = 'world';"",; ""print('testKeyCastImplicit hello init ' + obj[true]);"",; ""obj;""; );; final Map<String, Object> args1 = Collections.emptyMap();; final JSObject result1 = (JSObject) eval(expr1, args1);; ; /*; JSObjectLinker does not cast keys to strings during get (and similarly in put).; - https://github.com/JetBrains/jdk8u_nashorn/blob/jdk8u76-b03/src/jdk/nashorn/internal/runtime/linker/JSObjectLinker.java#L179; - http://hg.openjdk.java.net/jdk9/jdk9/nashorn/file/17cc754c8936/src/jdk.scripting.nashorn/share/classes/jdk/nashorn/internal/runtime/linker/JSObjectLinker.java#l190. According to ECMA, property accessors in brackets are ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573
https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573:1459,Testability,test,testKeyCastImplicit,1459,"va.util.Map;; import java.util.Set;. /**; * Example showing that a JSObject will not cast a property key to string, plus an example showing how JSON.stringify; * returns null for Java maps. So:; * - If you need non-string key expressions ex: 'myObj[true]', then do not pass in a JSObject.; * - If you need to use JSON.stringify, then do not pass in a java.util.Map.; */; public class Main {; public static void main(String[] args) throws ScriptException {; testKeyCastImplicit();; testKeyCastExplicit();; System.out.println(""---"");; testKeyMapString();; testKeyMapNonString();; System.out.println(""---"");; testStringifyMap();; testStringifyJSObject();; testStringifyScriptObject();; }. /**; * Create and use an object in Javascript, return it to Java, and then pass it back into similar Javascript. In the; * second Javascript call we cannot use our key in the same way.; */; private static void testKeyCastImplicit() throws ScriptException {; final String expr1 = expr(; ""var obj = {};"",; ""obj[true] = 'world';"",; ""print('testKeyCastImplicit hello init ' + obj[true]);"",; ""obj;""; );; final Map<String, Object> args1 = Collections.emptyMap();; final JSObject result1 = (JSObject) eval(expr1, args1);; ; /*; JSObjectLinker does not cast keys to strings during get (and similarly in put).; - https://github.com/JetBrains/jdk8u_nashorn/blob/jdk8u76-b03/src/jdk/nashorn/internal/runtime/linker/JSObjectLinker.java#L179; - http://hg.openjdk.java.net/jdk9/jdk9/nashorn/file/17cc754c8936/src/jdk.scripting.nashorn/share/classes/jdk/nashorn/internal/runtime/linker/JSObjectLinker.java#l190. According to ECMA, property accessors in brackets are expressions and not identifier-name-string:. > 3. Let propertyNameReference be the result of evaluating Expression.; > 4. Let propertyNameValue be GetValue(propertyNameReference).; > ...; > 6. Let propertyNameString be ToString(propertyNameValue). - https://www.ecma-international.org/ecma-262/5.1/#sec-11.2.1. Similarly according to the MDN:. > Property names mus",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573
https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573:1586,Testability,test,testKeyCastImplicit,1586,"va.util.Map;; import java.util.Set;. /**; * Example showing that a JSObject will not cast a property key to string, plus an example showing how JSON.stringify; * returns null for Java maps. So:; * - If you need non-string key expressions ex: 'myObj[true]', then do not pass in a JSObject.; * - If you need to use JSON.stringify, then do not pass in a java.util.Map.; */; public class Main {; public static void main(String[] args) throws ScriptException {; testKeyCastImplicit();; testKeyCastExplicit();; System.out.println(""---"");; testKeyMapString();; testKeyMapNonString();; System.out.println(""---"");; testStringifyMap();; testStringifyJSObject();; testStringifyScriptObject();; }. /**; * Create and use an object in Javascript, return it to Java, and then pass it back into similar Javascript. In the; * second Javascript call we cannot use our key in the same way.; */; private static void testKeyCastImplicit() throws ScriptException {; final String expr1 = expr(; ""var obj = {};"",; ""obj[true] = 'world';"",; ""print('testKeyCastImplicit hello init ' + obj[true]);"",; ""obj;""; );; final Map<String, Object> args1 = Collections.emptyMap();; final JSObject result1 = (JSObject) eval(expr1, args1);; ; /*; JSObjectLinker does not cast keys to strings during get (and similarly in put).; - https://github.com/JetBrains/jdk8u_nashorn/blob/jdk8u76-b03/src/jdk/nashorn/internal/runtime/linker/JSObjectLinker.java#L179; - http://hg.openjdk.java.net/jdk9/jdk9/nashorn/file/17cc754c8936/src/jdk.scripting.nashorn/share/classes/jdk/nashorn/internal/runtime/linker/JSObjectLinker.java#l190. According to ECMA, property accessors in brackets are expressions and not identifier-name-string:. > 3. Let propertyNameReference be the result of evaluating Expression.; > 4. Let propertyNameValue be GetValue(propertyNameReference).; > ...; > 6. Let propertyNameString be ToString(propertyNameValue). - https://www.ecma-international.org/ecma-262/5.1/#sec-11.2.1. Similarly according to the MDN:. > Property names mus",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573
https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573:3527,Testability,test,testKeyCastImplicit,3527,"ec-11.2.1. Similarly according to the MDN:. > Property names must be strings. This means that non-string objects cannot be used as keys in the object. Any; > non-string object, including a number, is typecasted into a string via the toString method. - https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Property_Accessors#Property_names. This is not totally unexpected as according to the Nashorn engine notes:. > not every operation and script API (JSON, Array, Function's properties/functions) treats ScriptObjectMirror; > and jdk.nashorn.internal.runtime.ScriptObject uniformly. There are places where ScriptObjects work as; > expected but if you pass ScriptObjectMirror or your own JSObject implementation, it won't work as expected. - https://wiki.openjdk.java.net/display/Nashorn/Nashorn+jsr223+engine+notes. See also:. - https://stackoverflow.com/questions/44232013/is-there-a-way-to-make-a-custom-implementation-of-nashorn-jsobject-work-with-obj#44246540; */; final String expr2 = expr(""print('testKeyCastImplicit hello again ' + obj[true]);"");; final Map<String, Object> args2 = Collections.singletonMap(""obj"", result1);; eval(expr2, args2);; }. /**; * Create and use an object in Javascript, return it to Java, and then pass it back into similar Javascript. In the; * second Javascript call we only get a non-null result when the key is explicitly cast to a string.; */; private static void testKeyCastExplicit() throws ScriptException {; final String expr1 = expr(; ""var obj = {};"",; ""obj[true] = 'world';"",; ""print('testKeyCastExplicit hello init ' + obj[true]);"",; ""obj;""; );; final Map<String, Object> args1 = Collections.emptyMap();; final JSObject result1 = (JSObject) eval(expr1, args1);. final String expr2 = expr(""print('testKeyCastExplicit hello again ' + obj[true.toString()]);"");; final Map<String, Object> args2 = Collections.singletonMap(""obj"", result1);; eval(expr2, args2);; }. /**; * Show that keys do not coerce to a string in a java.util.Map.; */",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573
https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573:3926,Testability,test,testKeyCastExplicit,3926,"riptObjectMirror; > and jdk.nashorn.internal.runtime.ScriptObject uniformly. There are places where ScriptObjects work as; > expected but if you pass ScriptObjectMirror or your own JSObject implementation, it won't work as expected. - https://wiki.openjdk.java.net/display/Nashorn/Nashorn+jsr223+engine+notes. See also:. - https://stackoverflow.com/questions/44232013/is-there-a-way-to-make-a-custom-implementation-of-nashorn-jsobject-work-with-obj#44246540; */; final String expr2 = expr(""print('testKeyCastImplicit hello again ' + obj[true]);"");; final Map<String, Object> args2 = Collections.singletonMap(""obj"", result1);; eval(expr2, args2);; }. /**; * Create and use an object in Javascript, return it to Java, and then pass it back into similar Javascript. In the; * second Javascript call we only get a non-null result when the key is explicitly cast to a string.; */; private static void testKeyCastExplicit() throws ScriptException {; final String expr1 = expr(; ""var obj = {};"",; ""obj[true] = 'world';"",; ""print('testKeyCastExplicit hello init ' + obj[true]);"",; ""obj;""; );; final Map<String, Object> args1 = Collections.emptyMap();; final JSObject result1 = (JSObject) eval(expr1, args1);. final String expr2 = expr(""print('testKeyCastExplicit hello again ' + obj[true.toString()]);"");; final Map<String, Object> args2 = Collections.singletonMap(""obj"", result1);; eval(expr2, args2);; }. /**; * Show that keys do not coerce to a string in a java.util.Map.; */; private static void testKeyMapString() throws ScriptException {; /*; See notes in testKeyCastImplicit regarding keys should be cast to strings. Because ECMA says that keys are strings, this lookup should work but doesn't.; */; final String expr = expr(; ""print('testKeyMapString hello ' + obj[true]);"",; ""obj;""; );; final Map<String, Object> obj = Collections.singletonMap(""true"", ""world"");; final Map<String, Object> args = Collections.singletonMap(""obj"", obj);; eval(expr, args);; }. /**; * Show that key equality works for non",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573
https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573:4053,Testability,test,testKeyCastExplicit,4053,"riptObjectMirror; > and jdk.nashorn.internal.runtime.ScriptObject uniformly. There are places where ScriptObjects work as; > expected but if you pass ScriptObjectMirror or your own JSObject implementation, it won't work as expected. - https://wiki.openjdk.java.net/display/Nashorn/Nashorn+jsr223+engine+notes. See also:. - https://stackoverflow.com/questions/44232013/is-there-a-way-to-make-a-custom-implementation-of-nashorn-jsobject-work-with-obj#44246540; */; final String expr2 = expr(""print('testKeyCastImplicit hello again ' + obj[true]);"");; final Map<String, Object> args2 = Collections.singletonMap(""obj"", result1);; eval(expr2, args2);; }. /**; * Create and use an object in Javascript, return it to Java, and then pass it back into similar Javascript. In the; * second Javascript call we only get a non-null result when the key is explicitly cast to a string.; */; private static void testKeyCastExplicit() throws ScriptException {; final String expr1 = expr(; ""var obj = {};"",; ""obj[true] = 'world';"",; ""print('testKeyCastExplicit hello init ' + obj[true]);"",; ""obj;""; );; final Map<String, Object> args1 = Collections.emptyMap();; final JSObject result1 = (JSObject) eval(expr1, args1);. final String expr2 = expr(""print('testKeyCastExplicit hello again ' + obj[true.toString()]);"");; final Map<String, Object> args2 = Collections.singletonMap(""obj"", result1);; eval(expr2, args2);; }. /**; * Show that keys do not coerce to a string in a java.util.Map.; */; private static void testKeyMapString() throws ScriptException {; /*; See notes in testKeyCastImplicit regarding keys should be cast to strings. Because ECMA says that keys are strings, this lookup should work but doesn't.; */; final String expr = expr(; ""print('testKeyMapString hello ' + obj[true]);"",; ""obj;""; );; final Map<String, Object> obj = Collections.singletonMap(""true"", ""world"");; final Map<String, Object> args = Collections.singletonMap(""obj"", obj);; eval(expr, args);; }. /**; * Show that key equality works for non",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573
https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573:4265,Testability,test,testKeyCastExplicit,4265,"://wiki.openjdk.java.net/display/Nashorn/Nashorn+jsr223+engine+notes. See also:. - https://stackoverflow.com/questions/44232013/is-there-a-way-to-make-a-custom-implementation-of-nashorn-jsobject-work-with-obj#44246540; */; final String expr2 = expr(""print('testKeyCastImplicit hello again ' + obj[true]);"");; final Map<String, Object> args2 = Collections.singletonMap(""obj"", result1);; eval(expr2, args2);; }. /**; * Create and use an object in Javascript, return it to Java, and then pass it back into similar Javascript. In the; * second Javascript call we only get a non-null result when the key is explicitly cast to a string.; */; private static void testKeyCastExplicit() throws ScriptException {; final String expr1 = expr(; ""var obj = {};"",; ""obj[true] = 'world';"",; ""print('testKeyCastExplicit hello init ' + obj[true]);"",; ""obj;""; );; final Map<String, Object> args1 = Collections.emptyMap();; final JSObject result1 = (JSObject) eval(expr1, args1);. final String expr2 = expr(""print('testKeyCastExplicit hello again ' + obj[true.toString()]);"");; final Map<String, Object> args2 = Collections.singletonMap(""obj"", result1);; eval(expr2, args2);; }. /**; * Show that keys do not coerce to a string in a java.util.Map.; */; private static void testKeyMapString() throws ScriptException {; /*; See notes in testKeyCastImplicit regarding keys should be cast to strings. Because ECMA says that keys are strings, this lookup should work but doesn't.; */; final String expr = expr(; ""print('testKeyMapString hello ' + obj[true]);"",; ""obj;""; );; final Map<String, Object> obj = Collections.singletonMap(""true"", ""world"");; final Map<String, Object> args = Collections.singletonMap(""obj"", obj);; eval(expr, args);; }. /**; * Show that key equality works for non-strings in a java.util.Map.; */; private static void testKeyMapNonString() throws ScriptException {; /*; See notes in testKeyCastImplicit regarding keys should be cast to strings. Keys are not coerced to strings upon lookup nor internally",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573
https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573:4522,Testability,test,testKeyMapString,4522,"e]);"");; final Map<String, Object> args2 = Collections.singletonMap(""obj"", result1);; eval(expr2, args2);; }. /**; * Create and use an object in Javascript, return it to Java, and then pass it back into similar Javascript. In the; * second Javascript call we only get a non-null result when the key is explicitly cast to a string.; */; private static void testKeyCastExplicit() throws ScriptException {; final String expr1 = expr(; ""var obj = {};"",; ""obj[true] = 'world';"",; ""print('testKeyCastExplicit hello init ' + obj[true]);"",; ""obj;""; );; final Map<String, Object> args1 = Collections.emptyMap();; final JSObject result1 = (JSObject) eval(expr1, args1);. final String expr2 = expr(""print('testKeyCastExplicit hello again ' + obj[true.toString()]);"");; final Map<String, Object> args2 = Collections.singletonMap(""obj"", result1);; eval(expr2, args2);; }. /**; * Show that keys do not coerce to a string in a java.util.Map.; */; private static void testKeyMapString() throws ScriptException {; /*; See notes in testKeyCastImplicit regarding keys should be cast to strings. Because ECMA says that keys are strings, this lookup should work but doesn't.; */; final String expr = expr(; ""print('testKeyMapString hello ' + obj[true]);"",; ""obj;""; );; final Map<String, Object> obj = Collections.singletonMap(""true"", ""world"");; final Map<String, Object> args = Collections.singletonMap(""obj"", obj);; eval(expr, args);; }. /**; * Show that key equality works for non-strings in a java.util.Map.; */; private static void testKeyMapNonString() throws ScriptException {; /*; See notes in testKeyCastImplicit regarding keys should be cast to strings. Keys are not coerced to strings upon lookup nor internally, meaning we actually get a match on a Map with; non-string keys. Ideally instead of passing the lookup directly to java.util.Map.get() a coerced string should be passed. However; if the lookup keys are going to be coerced, the map's keys should have already been coerced also. The internal; map must ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573
https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573:4584,Testability,test,testKeyCastImplicit,4584,"e]);"");; final Map<String, Object> args2 = Collections.singletonMap(""obj"", result1);; eval(expr2, args2);; }. /**; * Create and use an object in Javascript, return it to Java, and then pass it back into similar Javascript. In the; * second Javascript call we only get a non-null result when the key is explicitly cast to a string.; */; private static void testKeyCastExplicit() throws ScriptException {; final String expr1 = expr(; ""var obj = {};"",; ""obj[true] = 'world';"",; ""print('testKeyCastExplicit hello init ' + obj[true]);"",; ""obj;""; );; final Map<String, Object> args1 = Collections.emptyMap();; final JSObject result1 = (JSObject) eval(expr1, args1);. final String expr2 = expr(""print('testKeyCastExplicit hello again ' + obj[true.toString()]);"");; final Map<String, Object> args2 = Collections.singletonMap(""obj"", result1);; eval(expr2, args2);; }. /**; * Show that keys do not coerce to a string in a java.util.Map.; */; private static void testKeyMapString() throws ScriptException {; /*; See notes in testKeyCastImplicit regarding keys should be cast to strings. Because ECMA says that keys are strings, this lookup should work but doesn't.; */; final String expr = expr(; ""print('testKeyMapString hello ' + obj[true]);"",; ""obj;""; );; final Map<String, Object> obj = Collections.singletonMap(""true"", ""world"");; final Map<String, Object> args = Collections.singletonMap(""obj"", obj);; eval(expr, args);; }. /**; * Show that key equality works for non-strings in a java.util.Map.; */; private static void testKeyMapNonString() throws ScriptException {; /*; See notes in testKeyCastImplicit regarding keys should be cast to strings. Keys are not coerced to strings upon lookup nor internally, meaning we actually get a match on a Map with; non-string keys. Ideally instead of passing the lookup directly to java.util.Map.get() a coerced string should be passed. However; if the lookup keys are going to be coerced, the map's keys should have already been coerced also. The internal; map must ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573
https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573:4764,Testability,test,testKeyMapString,4764," In the; * second Javascript call we only get a non-null result when the key is explicitly cast to a string.; */; private static void testKeyCastExplicit() throws ScriptException {; final String expr1 = expr(; ""var obj = {};"",; ""obj[true] = 'world';"",; ""print('testKeyCastExplicit hello init ' + obj[true]);"",; ""obj;""; );; final Map<String, Object> args1 = Collections.emptyMap();; final JSObject result1 = (JSObject) eval(expr1, args1);. final String expr2 = expr(""print('testKeyCastExplicit hello again ' + obj[true.toString()]);"");; final Map<String, Object> args2 = Collections.singletonMap(""obj"", result1);; eval(expr2, args2);; }. /**; * Show that keys do not coerce to a string in a java.util.Map.; */; private static void testKeyMapString() throws ScriptException {; /*; See notes in testKeyCastImplicit regarding keys should be cast to strings. Because ECMA says that keys are strings, this lookup should work but doesn't.; */; final String expr = expr(; ""print('testKeyMapString hello ' + obj[true]);"",; ""obj;""; );; final Map<String, Object> obj = Collections.singletonMap(""true"", ""world"");; final Map<String, Object> args = Collections.singletonMap(""obj"", obj);; eval(expr, args);; }. /**; * Show that key equality works for non-strings in a java.util.Map.; */; private static void testKeyMapNonString() throws ScriptException {; /*; See notes in testKeyCastImplicit regarding keys should be cast to strings. Keys are not coerced to strings upon lookup nor internally, meaning we actually get a match on a Map with; non-string keys. Ideally instead of passing the lookup directly to java.util.Map.get() a coerced string should be passed. However; if the lookup keys are going to be coerced, the map's keys should have already been coerced also. The internal; map must contain string keys anyway to be ECMA compliant. Thus a java.util.Map<Object, Object> should be; converted to a Map<String, Object> where the keys are coerced to strings. Ideally this test should still work; after any fix ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573
https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573:5085,Testability,test,testKeyMapNonString,5085,"ject> args1 = Collections.emptyMap();; final JSObject result1 = (JSObject) eval(expr1, args1);. final String expr2 = expr(""print('testKeyCastExplicit hello again ' + obj[true.toString()]);"");; final Map<String, Object> args2 = Collections.singletonMap(""obj"", result1);; eval(expr2, args2);; }. /**; * Show that keys do not coerce to a string in a java.util.Map.; */; private static void testKeyMapString() throws ScriptException {; /*; See notes in testKeyCastImplicit regarding keys should be cast to strings. Because ECMA says that keys are strings, this lookup should work but doesn't.; */; final String expr = expr(; ""print('testKeyMapString hello ' + obj[true]);"",; ""obj;""; );; final Map<String, Object> obj = Collections.singletonMap(""true"", ""world"");; final Map<String, Object> args = Collections.singletonMap(""obj"", obj);; eval(expr, args);; }. /**; * Show that key equality works for non-strings in a java.util.Map.; */; private static void testKeyMapNonString() throws ScriptException {; /*; See notes in testKeyCastImplicit regarding keys should be cast to strings. Keys are not coerced to strings upon lookup nor internally, meaning we actually get a match on a Map with; non-string keys. Ideally instead of passing the lookup directly to java.util.Map.get() a coerced string should be passed. However; if the lookup keys are going to be coerced, the map's keys should have already been coerced also. The internal; map must contain string keys anyway to be ECMA compliant. Thus a java.util.Map<Object, Object> should be; converted to a Map<String, Object> where the keys are coerced to strings. Ideally this test should still work; after any fix OR Nashorn should not explicitly not support java.util.Map with non-string keys. For now, the JSObjectLinker is directly invoking the map getter:. - https://github.com/JetBrains/jdk8u_nashorn/blob/jdk8u76-b03/src/jdk/nashorn/internal/runtime/linker/JSObjectLinker.java#L84-L86; - http://hg.openjdk.java.net/jdk9/jdk9/nashorn/file/17cc754c8936",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573
https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573:5150,Testability,test,testKeyCastImplicit,5150,"ject> args1 = Collections.emptyMap();; final JSObject result1 = (JSObject) eval(expr1, args1);. final String expr2 = expr(""print('testKeyCastExplicit hello again ' + obj[true.toString()]);"");; final Map<String, Object> args2 = Collections.singletonMap(""obj"", result1);; eval(expr2, args2);; }. /**; * Show that keys do not coerce to a string in a java.util.Map.; */; private static void testKeyMapString() throws ScriptException {; /*; See notes in testKeyCastImplicit regarding keys should be cast to strings. Because ECMA says that keys are strings, this lookup should work but doesn't.; */; final String expr = expr(; ""print('testKeyMapString hello ' + obj[true]);"",; ""obj;""; );; final Map<String, Object> obj = Collections.singletonMap(""true"", ""world"");; final Map<String, Object> args = Collections.singletonMap(""obj"", obj);; eval(expr, args);; }. /**; * Show that key equality works for non-strings in a java.util.Map.; */; private static void testKeyMapNonString() throws ScriptException {; /*; See notes in testKeyCastImplicit regarding keys should be cast to strings. Keys are not coerced to strings upon lookup nor internally, meaning we actually get a match on a Map with; non-string keys. Ideally instead of passing the lookup directly to java.util.Map.get() a coerced string should be passed. However; if the lookup keys are going to be coerced, the map's keys should have already been coerced also. The internal; map must contain string keys anyway to be ECMA compliant. Thus a java.util.Map<Object, Object> should be; converted to a Map<String, Object> where the keys are coerced to strings. Ideally this test should still work; after any fix OR Nashorn should not explicitly not support java.util.Map with non-string keys. For now, the JSObjectLinker is directly invoking the map getter:. - https://github.com/JetBrains/jdk8u_nashorn/blob/jdk8u76-b03/src/jdk/nashorn/internal/runtime/linker/JSObjectLinker.java#L84-L86; - http://hg.openjdk.java.net/jdk9/jdk9/nashorn/file/17cc754c8936",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573
https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573:5755,Testability,test,test,5755,"bj[true]);"",; ""obj;""; );; final Map<String, Object> obj = Collections.singletonMap(""true"", ""world"");; final Map<String, Object> args = Collections.singletonMap(""obj"", obj);; eval(expr, args);; }. /**; * Show that key equality works for non-strings in a java.util.Map.; */; private static void testKeyMapNonString() throws ScriptException {; /*; See notes in testKeyCastImplicit regarding keys should be cast to strings. Keys are not coerced to strings upon lookup nor internally, meaning we actually get a match on a Map with; non-string keys. Ideally instead of passing the lookup directly to java.util.Map.get() a coerced string should be passed. However; if the lookup keys are going to be coerced, the map's keys should have already been coerced also. The internal; map must contain string keys anyway to be ECMA compliant. Thus a java.util.Map<Object, Object> should be; converted to a Map<String, Object> where the keys are coerced to strings. Ideally this test should still work; after any fix OR Nashorn should not explicitly not support java.util.Map with non-string keys. For now, the JSObjectLinker is directly invoking the map getter:. - https://github.com/JetBrains/jdk8u_nashorn/blob/jdk8u76-b03/src/jdk/nashorn/internal/runtime/linker/JSObjectLinker.java#L84-L86; - http://hg.openjdk.java.net/jdk9/jdk9/nashorn/file/17cc754c8936/src/jdk.scripting.nashorn/share/classes/jdk/nashorn/internal/runtime/linker/JSObjectLinker.java#l87. The BeanLinker generates the dynamic call to the map getter:. - https://github.com/JetBrains/jdk8u_nashorn/blob/jdk8u76-b03/src/jdk/internal/dynalink/beans/BeanLinker.java#L179-L205; - http://hg.openjdk.java.net/jdk9/jdk9/nashorn/file/17cc754c8936/src/jdk.dynalink/share/classes/jdk/dynalink/beans/BeanLinker.java#l218; */; final String expr = expr(; ""print('testKeyMapNonString hello ' + obj[true]);"",; ""obj;""; );; final Map<Object, Object> obj = Collections.singletonMap(true, ""world"");; final Map<String, Object> args = Collections.singletonMap(""obj"", ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573
https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573:6596,Testability,test,testKeyMapNonString,6596,"hus a java.util.Map<Object, Object> should be; converted to a Map<String, Object> where the keys are coerced to strings. Ideally this test should still work; after any fix OR Nashorn should not explicitly not support java.util.Map with non-string keys. For now, the JSObjectLinker is directly invoking the map getter:. - https://github.com/JetBrains/jdk8u_nashorn/blob/jdk8u76-b03/src/jdk/nashorn/internal/runtime/linker/JSObjectLinker.java#L84-L86; - http://hg.openjdk.java.net/jdk9/jdk9/nashorn/file/17cc754c8936/src/jdk.scripting.nashorn/share/classes/jdk/nashorn/internal/runtime/linker/JSObjectLinker.java#l87. The BeanLinker generates the dynamic call to the map getter:. - https://github.com/JetBrains/jdk8u_nashorn/blob/jdk8u76-b03/src/jdk/internal/dynalink/beans/BeanLinker.java#L179-L205; - http://hg.openjdk.java.net/jdk9/jdk9/nashorn/file/17cc754c8936/src/jdk.dynalink/share/classes/jdk/dynalink/beans/BeanLinker.java#l218; */; final String expr = expr(; ""print('testKeyMapNonString hello ' + obj[true]);"",; ""obj;""; );; final Map<Object, Object> obj = Collections.singletonMap(true, ""world"");; final Map<String, Object> args = Collections.singletonMap(""obj"", obj);; eval(expr, args);; }. /**; * Fail to stringify a java.util.Map.; */; private static void testStringifyMap() throws ScriptException {; /*; Nashorn's JSON.stringify identifies that a map is an object, but doesn't convert Java maps (nor Java arrays) to; a string. NOTE: There has been some work in jdk8u and jdk9 to fix issues with stringify, so the code varies a; bit depending on the jdk version. - https://github.com/JetBrains/jdk8u_nashorn/blob/jdk8u76-b03/src/jdk/nashorn/internal/objects/NativeJSON.java#L267-L272; - http://hg.openjdk.java.net/jdk9/jdk9/nashorn/file/17cc754c8936/src/jdk.scripting.nashorn/share/classes/jdk/nashorn/internal/objects/NativeJSON.java#l288. Maps do get special treatment in Nashorn and are passed around internally:. - https://wiki.openjdk.java.net/display/Nashorn/Nashorn+extensions#Nashor",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573
https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573:6888,Testability,test,testStringifyMap,6888,"rectly invoking the map getter:. - https://github.com/JetBrains/jdk8u_nashorn/blob/jdk8u76-b03/src/jdk/nashorn/internal/runtime/linker/JSObjectLinker.java#L84-L86; - http://hg.openjdk.java.net/jdk9/jdk9/nashorn/file/17cc754c8936/src/jdk.scripting.nashorn/share/classes/jdk/nashorn/internal/runtime/linker/JSObjectLinker.java#l87. The BeanLinker generates the dynamic call to the map getter:. - https://github.com/JetBrains/jdk8u_nashorn/blob/jdk8u76-b03/src/jdk/internal/dynalink/beans/BeanLinker.java#L179-L205; - http://hg.openjdk.java.net/jdk9/jdk9/nashorn/file/17cc754c8936/src/jdk.dynalink/share/classes/jdk/dynalink/beans/BeanLinker.java#l218; */; final String expr = expr(; ""print('testKeyMapNonString hello ' + obj[true]);"",; ""obj;""; );; final Map<Object, Object> obj = Collections.singletonMap(true, ""world"");; final Map<String, Object> args = Collections.singletonMap(""obj"", obj);; eval(expr, args);; }. /**; * Fail to stringify a java.util.Map.; */; private static void testStringifyMap() throws ScriptException {; /*; Nashorn's JSON.stringify identifies that a map is an object, but doesn't convert Java maps (nor Java arrays) to; a string. NOTE: There has been some work in jdk8u and jdk9 to fix issues with stringify, so the code varies a; bit depending on the jdk version. - https://github.com/JetBrains/jdk8u_nashorn/blob/jdk8u76-b03/src/jdk/nashorn/internal/objects/NativeJSON.java#L267-L272; - http://hg.openjdk.java.net/jdk9/jdk9/nashorn/file/17cc754c8936/src/jdk.scripting.nashorn/share/classes/jdk/nashorn/internal/objects/NativeJSON.java#l288. Maps do get special treatment in Nashorn and are passed around internally:. - https://wiki.openjdk.java.net/display/Nashorn/Nashorn+extensions#Nashornextensions-SpecialtreatmentofobjectsofspecificJavaclasses. In this case the value within NativeJSON.str() is the Java map instance and not a ScriptObject nor a JSObject.; Thus the code falls through and returns UNDEFINED. If the code didn't bypass the if-statement the block would; ru",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573
https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573:8980,Testability,test,testStringifyMap,8980,"tps://github.com/JetBrains/jdk8u_nashorn/blob/jdk8u76-b03/src/jdk/nashorn/internal/objects/NativeJSON.java#L287; - http://hg.openjdk.java.net/jdk9/jdk9/nashorn/file/17cc754c8936/src/jdk.scripting.nashorn/share/classes/jdk/nashorn/internal/objects/NativeJSON.java#l311. Even in the latest code, getting an object's keys is not expecting a java.util.Map:. - http://hg.openjdk.java.net/jdk9/jdk9/nashorn/file/17cc754c8936/src/jdk.scripting.nashorn/share/classes/jdk/nashorn/internal/objects/NativeJSON.java#l443. There is also bug 8181203 that mentions that Object.keys should work on any JSObject, not just; ScriptObjectMirror. - https://bugs.openjdk.java.net/browse/JDK-8181203. As maps have special treatment in Nashorn, perhaps stringify should be expecting these Java maps (and Java; arrays) also?. See also:. - https://www.ecma-international.org/ecma-262/5.1/#sec-15.12.3; - https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/stringify; */; final String expr = expr(; ""print('testStringifyMap type ' + typeof(obj));"",; ""print('testStringifyMap json ' + JSON.stringify(obj));""; );; final Map<String, Object> obj = Collections.singletonMap(""true"", ""world"");; final Map<String, Object> args = Collections.singletonMap(""obj"", obj);; eval(expr, args);; }. /**; * Stringify a JSObject.; */; private static void testStringifyJSObject() throws ScriptException {; // JSON.stringify works fine on JSObject; final String expr = expr(; ""print('testStringifyJSObject type ' + typeof(obj));"",; ""print('testStringifyJSObject json ' + JSON.stringify(obj));""; );; final JSObject obj = new AbstractJSObject() {; // @formatter:off; final Map<String, Object> map = Collections.singletonMap(""true"", ""world"");; @Override public Object getMember(String name) { return map.get(name); }; @Override public boolean hasMember(String name) { return map.containsKey(name); }; @Override public Set<String> keySet() { return map.keySet(); }; @Override public Collection<Object> values() { retur",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573
https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573:9031,Testability,test,testStringifyMap,9031,"tps://github.com/JetBrains/jdk8u_nashorn/blob/jdk8u76-b03/src/jdk/nashorn/internal/objects/NativeJSON.java#L287; - http://hg.openjdk.java.net/jdk9/jdk9/nashorn/file/17cc754c8936/src/jdk.scripting.nashorn/share/classes/jdk/nashorn/internal/objects/NativeJSON.java#l311. Even in the latest code, getting an object's keys is not expecting a java.util.Map:. - http://hg.openjdk.java.net/jdk9/jdk9/nashorn/file/17cc754c8936/src/jdk.scripting.nashorn/share/classes/jdk/nashorn/internal/objects/NativeJSON.java#l443. There is also bug 8181203 that mentions that Object.keys should work on any JSObject, not just; ScriptObjectMirror. - https://bugs.openjdk.java.net/browse/JDK-8181203. As maps have special treatment in Nashorn, perhaps stringify should be expecting these Java maps (and Java; arrays) also?. See also:. - https://www.ecma-international.org/ecma-262/5.1/#sec-15.12.3; - https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/stringify; */; final String expr = expr(; ""print('testStringifyMap type ' + typeof(obj));"",; ""print('testStringifyMap json ' + JSON.stringify(obj));""; );; final Map<String, Object> obj = Collections.singletonMap(""true"", ""world"");; final Map<String, Object> args = Collections.singletonMap(""obj"", obj);; eval(expr, args);; }. /**; * Stringify a JSObject.; */; private static void testStringifyJSObject() throws ScriptException {; // JSON.stringify works fine on JSObject; final String expr = expr(; ""print('testStringifyJSObject type ' + typeof(obj));"",; ""print('testStringifyJSObject json ' + JSON.stringify(obj));""; );; final JSObject obj = new AbstractJSObject() {; // @formatter:off; final Map<String, Object> map = Collections.singletonMap(""true"", ""world"");; @Override public Object getMember(String name) { return map.get(name); }; @Override public boolean hasMember(String name) { return map.containsKey(name); }; @Override public Set<String> keySet() { return map.keySet(); }; @Override public Collection<Object> values() { retur",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573
https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573:9309,Testability,test,testStringifyJSObject,9309,"p://hg.openjdk.java.net/jdk9/jdk9/nashorn/file/17cc754c8936/src/jdk.scripting.nashorn/share/classes/jdk/nashorn/internal/objects/NativeJSON.java#l443. There is also bug 8181203 that mentions that Object.keys should work on any JSObject, not just; ScriptObjectMirror. - https://bugs.openjdk.java.net/browse/JDK-8181203. As maps have special treatment in Nashorn, perhaps stringify should be expecting these Java maps (and Java; arrays) also?. See also:. - https://www.ecma-international.org/ecma-262/5.1/#sec-15.12.3; - https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/stringify; */; final String expr = expr(; ""print('testStringifyMap type ' + typeof(obj));"",; ""print('testStringifyMap json ' + JSON.stringify(obj));""; );; final Map<String, Object> obj = Collections.singletonMap(""true"", ""world"");; final Map<String, Object> args = Collections.singletonMap(""obj"", obj);; eval(expr, args);; }. /**; * Stringify a JSObject.; */; private static void testStringifyJSObject() throws ScriptException {; // JSON.stringify works fine on JSObject; final String expr = expr(; ""print('testStringifyJSObject type ' + typeof(obj));"",; ""print('testStringifyJSObject json ' + JSON.stringify(obj));""; );; final JSObject obj = new AbstractJSObject() {; // @formatter:off; final Map<String, Object> map = Collections.singletonMap(""true"", ""world"");; @Override public Object getMember(String name) { return map.get(name); }; @Override public boolean hasMember(String name) { return map.containsKey(name); }; @Override public Set<String> keySet() { return map.keySet(); }; @Override public Collection<Object> values() { return map.values(); }; // @formatter:on; };; final Map<String, Object> args = Collections.singletonMap(""obj"", obj);; eval(expr, args);; }. /**; * Stringify a ScriptObject.; */; private static void testStringifyScriptObject() throws ScriptException {; // JSON.stringify works fine on ScriptObject; final String expr = expr(; ""var obj = {};"",; ""obj[true] = 'world';",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573
https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573:9436,Testability,test,testStringifyJSObject,9436,"bjects/NativeJSON.java#l443. There is also bug 8181203 that mentions that Object.keys should work on any JSObject, not just; ScriptObjectMirror. - https://bugs.openjdk.java.net/browse/JDK-8181203. As maps have special treatment in Nashorn, perhaps stringify should be expecting these Java maps (and Java; arrays) also?. See also:. - https://www.ecma-international.org/ecma-262/5.1/#sec-15.12.3; - https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/stringify; */; final String expr = expr(; ""print('testStringifyMap type ' + typeof(obj));"",; ""print('testStringifyMap json ' + JSON.stringify(obj));""; );; final Map<String, Object> obj = Collections.singletonMap(""true"", ""world"");; final Map<String, Object> args = Collections.singletonMap(""obj"", obj);; eval(expr, args);; }. /**; * Stringify a JSObject.; */; private static void testStringifyJSObject() throws ScriptException {; // JSON.stringify works fine on JSObject; final String expr = expr(; ""print('testStringifyJSObject type ' + typeof(obj));"",; ""print('testStringifyJSObject json ' + JSON.stringify(obj));""; );; final JSObject obj = new AbstractJSObject() {; // @formatter:off; final Map<String, Object> map = Collections.singletonMap(""true"", ""world"");; @Override public Object getMember(String name) { return map.get(name); }; @Override public boolean hasMember(String name) { return map.containsKey(name); }; @Override public Set<String> keySet() { return map.keySet(); }; @Override public Collection<Object> values() { return map.values(); }; // @formatter:on; };; final Map<String, Object> args = Collections.singletonMap(""obj"", obj);; eval(expr, args);; }. /**; * Stringify a ScriptObject.; */; private static void testStringifyScriptObject() throws ScriptException {; // JSON.stringify works fine on ScriptObject; final String expr = expr(; ""var obj = {};"",; ""obj[true] = 'world';"",; ""print('testStringifyScriptObject type ' + typeof(obj));"",; ""print('testStringifyScriptObject json ' + JSON.stringify(o",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573
https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573:9492,Testability,test,testStringifyJSObject,9492,"bjects/NativeJSON.java#l443. There is also bug 8181203 that mentions that Object.keys should work on any JSObject, not just; ScriptObjectMirror. - https://bugs.openjdk.java.net/browse/JDK-8181203. As maps have special treatment in Nashorn, perhaps stringify should be expecting these Java maps (and Java; arrays) also?. See also:. - https://www.ecma-international.org/ecma-262/5.1/#sec-15.12.3; - https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/stringify; */; final String expr = expr(; ""print('testStringifyMap type ' + typeof(obj));"",; ""print('testStringifyMap json ' + JSON.stringify(obj));""; );; final Map<String, Object> obj = Collections.singletonMap(""true"", ""world"");; final Map<String, Object> args = Collections.singletonMap(""obj"", obj);; eval(expr, args);; }. /**; * Stringify a JSObject.; */; private static void testStringifyJSObject() throws ScriptException {; // JSON.stringify works fine on JSObject; final String expr = expr(; ""print('testStringifyJSObject type ' + typeof(obj));"",; ""print('testStringifyJSObject json ' + JSON.stringify(obj));""; );; final JSObject obj = new AbstractJSObject() {; // @formatter:off; final Map<String, Object> map = Collections.singletonMap(""true"", ""world"");; @Override public Object getMember(String name) { return map.get(name); }; @Override public boolean hasMember(String name) { return map.containsKey(name); }; @Override public Set<String> keySet() { return map.keySet(); }; @Override public Collection<Object> values() { return map.values(); }; // @formatter:on; };; final Map<String, Object> args = Collections.singletonMap(""obj"", obj);; eval(expr, args);; }. /**; * Stringify a ScriptObject.; */; private static void testStringifyScriptObject() throws ScriptException {; // JSON.stringify works fine on ScriptObject; final String expr = expr(; ""var obj = {};"",; ""obj[true] = 'world';"",; ""print('testStringifyScriptObject type ' + typeof(obj));"",; ""print('testStringifyScriptObject json ' + JSON.stringify(o",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573
https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573:10159,Testability,test,testStringifyScriptObject,10159,", Object> args = Collections.singletonMap(""obj"", obj);; eval(expr, args);; }. /**; * Stringify a JSObject.; */; private static void testStringifyJSObject() throws ScriptException {; // JSON.stringify works fine on JSObject; final String expr = expr(; ""print('testStringifyJSObject type ' + typeof(obj));"",; ""print('testStringifyJSObject json ' + JSON.stringify(obj));""; );; final JSObject obj = new AbstractJSObject() {; // @formatter:off; final Map<String, Object> map = Collections.singletonMap(""true"", ""world"");; @Override public Object getMember(String name) { return map.get(name); }; @Override public boolean hasMember(String name) { return map.containsKey(name); }; @Override public Set<String> keySet() { return map.keySet(); }; @Override public Collection<Object> values() { return map.values(); }; // @formatter:on; };; final Map<String, Object> args = Collections.singletonMap(""obj"", obj);; eval(expr, args);; }. /**; * Stringify a ScriptObject.; */; private static void testStringifyScriptObject() throws ScriptException {; // JSON.stringify works fine on ScriptObject; final String expr = expr(; ""var obj = {};"",; ""obj[true] = 'world';"",; ""print('testStringifyScriptObject type ' + typeof(obj));"",; ""print('testStringifyScriptObject json ' + JSON.stringify(obj));""; );; final Map<String, Object> args = Collections.emptyMap();; eval(expr, args);; }. private static Object eval(final String expr, final Map<String, Object> values) throws ScriptException {; // The engine could be static, but for example purposes making a new engine/context/bindings per evaluation.; final ScriptEngine engine =; ENGINE_FACTORY.getScriptEngine(nashornStrictArgs, getNashornClassLoader(), noJavaClassFilter);; final Bindings bindings = engine.createBindings();; bindings.putAll(values);. final ScriptContext context = new SimpleScriptContext();; context.setBindings(bindings, ScriptContext.ENGINE_SCOPE);; return engine.eval(expr, context);; }. private static final NashornScriptEngineFactory ENGINE_FACTOR",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573
https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573:10337,Testability,test,testStringifyScriptObject,10337,"t() throws ScriptException {; // JSON.stringify works fine on JSObject; final String expr = expr(; ""print('testStringifyJSObject type ' + typeof(obj));"",; ""print('testStringifyJSObject json ' + JSON.stringify(obj));""; );; final JSObject obj = new AbstractJSObject() {; // @formatter:off; final Map<String, Object> map = Collections.singletonMap(""true"", ""world"");; @Override public Object getMember(String name) { return map.get(name); }; @Override public boolean hasMember(String name) { return map.containsKey(name); }; @Override public Set<String> keySet() { return map.keySet(); }; @Override public Collection<Object> values() { return map.values(); }; // @formatter:on; };; final Map<String, Object> args = Collections.singletonMap(""obj"", obj);; eval(expr, args);; }. /**; * Stringify a ScriptObject.; */; private static void testStringifyScriptObject() throws ScriptException {; // JSON.stringify works fine on ScriptObject; final String expr = expr(; ""var obj = {};"",; ""obj[true] = 'world';"",; ""print('testStringifyScriptObject type ' + typeof(obj));"",; ""print('testStringifyScriptObject json ' + JSON.stringify(obj));""; );; final Map<String, Object> args = Collections.emptyMap();; eval(expr, args);; }. private static Object eval(final String expr, final Map<String, Object> values) throws ScriptException {; // The engine could be static, but for example purposes making a new engine/context/bindings per evaluation.; final ScriptEngine engine =; ENGINE_FACTORY.getScriptEngine(nashornStrictArgs, getNashornClassLoader(), noJavaClassFilter);; final Bindings bindings = engine.createBindings();; bindings.putAll(values);. final ScriptContext context = new SimpleScriptContext();; context.setBindings(bindings, ScriptContext.ENGINE_SCOPE);; return engine.eval(expr, context);; }. private static final NashornScriptEngineFactory ENGINE_FACTORY = new NashornScriptEngineFactory();. /**; * Add stricter Nashorn arguments to the default `-doe`.; *; * @see <a href=""https://docs.oracle.com/javase/8",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573
https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573:10397,Testability,test,testStringifyScriptObject,10397,"t() throws ScriptException {; // JSON.stringify works fine on JSObject; final String expr = expr(; ""print('testStringifyJSObject type ' + typeof(obj));"",; ""print('testStringifyJSObject json ' + JSON.stringify(obj));""; );; final JSObject obj = new AbstractJSObject() {; // @formatter:off; final Map<String, Object> map = Collections.singletonMap(""true"", ""world"");; @Override public Object getMember(String name) { return map.get(name); }; @Override public boolean hasMember(String name) { return map.containsKey(name); }; @Override public Set<String> keySet() { return map.keySet(); }; @Override public Collection<Object> values() { return map.values(); }; // @formatter:on; };; final Map<String, Object> args = Collections.singletonMap(""obj"", obj);; eval(expr, args);; }. /**; * Stringify a ScriptObject.; */; private static void testStringifyScriptObject() throws ScriptException {; // JSON.stringify works fine on ScriptObject; final String expr = expr(; ""var obj = {};"",; ""obj[true] = 'world';"",; ""print('testStringifyScriptObject type ' + typeof(obj));"",; ""print('testStringifyScriptObject json ' + JSON.stringify(obj));""; );; final Map<String, Object> args = Collections.emptyMap();; eval(expr, args);; }. private static Object eval(final String expr, final Map<String, Object> values) throws ScriptException {; // The engine could be static, but for example purposes making a new engine/context/bindings per evaluation.; final ScriptEngine engine =; ENGINE_FACTORY.getScriptEngine(nashornStrictArgs, getNashornClassLoader(), noJavaClassFilter);; final Bindings bindings = engine.createBindings();; bindings.putAll(values);. final ScriptContext context = new SimpleScriptContext();; context.setBindings(bindings, ScriptContext.ENGINE_SCOPE);; return engine.eval(expr, context);; }. private static final NashornScriptEngineFactory ENGINE_FACTORY = new NashornScriptEngineFactory();. /**; * Add stricter Nashorn arguments to the default `-doe`.; *; * @see <a href=""https://docs.oracle.com/javase/8",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573
https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573:471,Usability,Simpl,SimpleScriptContext,471,"**TL;DR Good news: I can fix JSON.stringify in my upcoming PR. Bad news: it breaks other JSON**. ```java; import jdk.nashorn.api.scripting.AbstractJSObject;; import jdk.nashorn.api.scripting.ClassFilter;; import jdk.nashorn.api.scripting.JSObject;; import jdk.nashorn.api.scripting.NashornScriptEngineFactory;. import javax.script.Bindings;; import javax.script.ScriptContext;; import javax.script.ScriptEngine;; import javax.script.ScriptException;; import javax.script.SimpleScriptContext;; import java.util.Collection;; import java.util.Collections;; import java.util.Map;; import java.util.Set;. /**; * Example showing that a JSObject will not cast a property key to string, plus an example showing how JSON.stringify; * returns null for Java maps. So:; * - If you need non-string key expressions ex: 'myObj[true]', then do not pass in a JSObject.; * - If you need to use JSON.stringify, then do not pass in a java.util.Map.; */; public class Main {; public static void main(String[] args) throws ScriptException {; testKeyCastImplicit();; testKeyCastExplicit();; System.out.println(""---"");; testKeyMapString();; testKeyMapNonString();; System.out.println(""---"");; testStringifyMap();; testStringifyJSObject();; testStringifyScriptObject();; }. /**; * Create and use an object in Javascript, return it to Java, and then pass it back into similar Javascript. In the; * second Javascript call we cannot use our key in the same way.; */; private static void testKeyCastImplicit() throws ScriptException {; final String expr1 = expr(; ""var obj = {};"",; ""obj[true] = 'world';"",; ""print('testKeyCastImplicit hello init ' + obj[true]);"",; ""obj;""; );; final Map<String, Object> args1 = Collections.emptyMap();; final JSObject result1 = (JSObject) eval(expr1, args1);; ; /*; JSObjectLinker does not cast keys to strings during get (and similarly in put).; - https://github.com/JetBrains/jdk8u_nashorn/blob/jdk8u76-b03/src/jdk/nashorn/internal/runtime/linker/JSObjectLinker.java#L179; - http://hg.openjdk.ja",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573
https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573:10993,Usability,Simpl,SimpleScriptContext,10993,"rmatter:on; };; final Map<String, Object> args = Collections.singletonMap(""obj"", obj);; eval(expr, args);; }. /**; * Stringify a ScriptObject.; */; private static void testStringifyScriptObject() throws ScriptException {; // JSON.stringify works fine on ScriptObject; final String expr = expr(; ""var obj = {};"",; ""obj[true] = 'world';"",; ""print('testStringifyScriptObject type ' + typeof(obj));"",; ""print('testStringifyScriptObject json ' + JSON.stringify(obj));""; );; final Map<String, Object> args = Collections.emptyMap();; eval(expr, args);; }. private static Object eval(final String expr, final Map<String, Object> values) throws ScriptException {; // The engine could be static, but for example purposes making a new engine/context/bindings per evaluation.; final ScriptEngine engine =; ENGINE_FACTORY.getScriptEngine(nashornStrictArgs, getNashornClassLoader(), noJavaClassFilter);; final Bindings bindings = engine.createBindings();; bindings.putAll(values);. final ScriptContext context = new SimpleScriptContext();; context.setBindings(bindings, ScriptContext.ENGINE_SCOPE);; return engine.eval(expr, context);; }. private static final NashornScriptEngineFactory ENGINE_FACTORY = new NashornScriptEngineFactory();. /**; * Add stricter Nashorn arguments to the default `-doe`.; *; * @see <a href=""https://docs.oracle.com/javase/8/docs/technotes/tools/windows/jjs.html"">JJS docs and options</a>; * @see <a href=""https://github.com/JetBrains/jdk8u_nashorn/blob/jdk8u76-b03/src/jdk/nashorn/internal/runtime/resources/Options.properties"">Nashorn supported options (github) </a>; * @see <a href=""http://hg.openjdk.java.net/jdk8/jdk8/nashorn/file/5dbdae28a6f3/src/jdk/nashorn/internal/runtime/resources/Options.properties"">Nashorn supported options</a>; * @see jdk.nashorn.api.scripting.NashornScriptEngineFactory#DEFAULT_OPTIONS; */; private static String[] nashornStrictArgs = {; ""-doe"", ""-strict"", ""--no-java"", ""--no-syntax-extensions"", ""--language=es5""; };. /**; * Don't allow any java classes.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573
https://github.com/broadinstitute/cromwell/pull/3091#issuecomment-353687364:89,Integrability,rout,route,89,"It's technically not what we call the IoActor anymore but instead _some_ actor that will route I/O related commands to either the IoActor or its proxy, so I came up with ""endpoint"" but I'm totally open to other naming suggestions !",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3091#issuecomment-353687364
https://github.com/broadinstitute/cromwell/pull/3091#issuecomment-354340319:122,Integrability,rout,router,122,"@Horneth my concern on `endpoint` is its overloaded with the REST API endpoints. Realizing that it's also not an **akka** router, it seems to be serving a similar role. Proxy also seems viable (granted you're using that term in your description, but not in the code)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3091#issuecomment-354340319
https://github.com/broadinstitute/cromwell/issues/3092#issuecomment-354785169:79,Testability,test,test,79,"@Horneth I did see them talking about adding it in gitter, it was to provide a test for a bug which was found in toil. we should probably ask what the bug was and see if perhaps we're failing it for the same reason or if this was just an unfortunate side effect.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3092#issuecomment-354785169
https://github.com/broadinstitute/cromwell/issues/3093#issuecomment-359959967:196,Security,access,accesses,196,"@rhpvorderman great comment, I don't think there's an especially nice workaround to this right now. This is caused because `defined` operates on optional values (eg `File?`) whereas object member accesses either returns a value, or fail the workflow. We could fix this in a couple of ways:. - Change member access to always return optional values. This would have the side effect of forcing subsequent usages to handle the optional result even if you know the object has that key.; - Add a `hasKey(object, key)` method for objects, roughly equivalent to how you're trying to use `defined`. ; - Maybe adding a `getPath(object, path)` method that returns an optional value which is set if the path exists in the object, or empty if it isn't. And with my apologies, I'm now going to immediately redirect you elsewhere... Since any of the above suggestions would require a change to the [WDL spec](https://github.com/openwdl/wdl), I suggest you open this as a new issue in that repo. Once the change is accepted there I'll be able to make a new issue here to implement the change in Cromwell.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3093#issuecomment-359959967
https://github.com/broadinstitute/cromwell/issues/3093#issuecomment-359959967:307,Security,access,access,307,"@rhpvorderman great comment, I don't think there's an especially nice workaround to this right now. This is caused because `defined` operates on optional values (eg `File?`) whereas object member accesses either returns a value, or fail the workflow. We could fix this in a couple of ways:. - Change member access to always return optional values. This would have the side effect of forcing subsequent usages to handle the optional result even if you know the object has that key.; - Add a `hasKey(object, key)` method for objects, roughly equivalent to how you're trying to use `defined`. ; - Maybe adding a `getPath(object, path)` method that returns an optional value which is set if the path exists in the object, or empty if it isn't. And with my apologies, I'm now going to immediately redirect you elsewhere... Since any of the above suggestions would require a change to the [WDL spec](https://github.com/openwdl/wdl), I suggest you open this as a new issue in that repo. Once the change is accepted there I'll be able to make a new issue here to implement the change in Cromwell.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3093#issuecomment-359959967
https://github.com/broadinstitute/cromwell/issues/3093#issuecomment-361298736:142,Usability,simpl,simpler,142,"Thank you @cjllanwarne . A `Struct` would be indeed a nicer way to fix this as you can define all the items. An `object` can then be used for simpler things. Extra methods just add clutter. I will check it out. EDIT: on second thought, best to leave this issue open until structs are actually there.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3093#issuecomment-361298736
https://github.com/broadinstitute/cromwell/pull/3101#issuecomment-355339696:150,Availability,failure,failure,150,There was a [bug](https://github.com/broadinstitute/cromwell/issues/3102) in the centaurCwlConformancePAPI test script that would have caused a false failure for you. The fixes for this bug are on develop so when you rebase this should no longer be an issue.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3101#issuecomment-355339696
https://github.com/broadinstitute/cromwell/pull/3101#issuecomment-355339696:107,Testability,test,test,107,There was a [bug](https://github.com/broadinstitute/cromwell/issues/3102) in the centaurCwlConformancePAPI test script that would have caused a false failure for you. The fixes for this bug are on develop so when you rebase this should no longer be an issue.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3101#issuecomment-355339696
https://github.com/broadinstitute/cromwell/issues/3109#issuecomment-356091101:203,Testability,log,log,203,Is your task using docker ? If you are `soft-link` is not tried as it doesn't play well with docker.; It should still try to `copy` though. Do you see any failed attempt to copy the files earlier in the log ?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3109#issuecomment-356091101
https://github.com/broadinstitute/cromwell/issues/3109#issuecomment-356221440:284,Availability,error,error,284,"My task are not using docker. Also I see no attempts at all to copy or softlink the files. Not in the log, and not in the cromwell-executions folder.; Also hard-linking seems to persist using the `SGE` backend. Even though the localization has the same configuration as above. So the error is not backend specific. Fortunately, all the other values in the config are used. Which makes me think that either my configuration file has some error (keys in wrong place). But I have checked this over and over again already with the example files and it seems to be correct (though I am not infallible of course).; Or the backend just ignores the values due to a bug.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3109#issuecomment-356221440
https://github.com/broadinstitute/cromwell/issues/3109#issuecomment-356221440:437,Availability,error,error,437,"My task are not using docker. Also I see no attempts at all to copy or softlink the files. Not in the log, and not in the cromwell-executions folder.; Also hard-linking seems to persist using the `SGE` backend. Even though the localization has the same configuration as above. So the error is not backend specific. Fortunately, all the other values in the config are used. Which makes me think that either my configuration file has some error (keys in wrong place). But I have checked this over and over again already with the example files and it seems to be correct (though I am not infallible of course).; Or the backend just ignores the values due to a bug.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3109#issuecomment-356221440
https://github.com/broadinstitute/cromwell/issues/3109#issuecomment-356221440:253,Deployability,configurat,configuration,253,"My task are not using docker. Also I see no attempts at all to copy or softlink the files. Not in the log, and not in the cromwell-executions folder.; Also hard-linking seems to persist using the `SGE` backend. Even though the localization has the same configuration as above. So the error is not backend specific. Fortunately, all the other values in the config are used. Which makes me think that either my configuration file has some error (keys in wrong place). But I have checked this over and over again already with the example files and it seems to be correct (though I am not infallible of course).; Or the backend just ignores the values due to a bug.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3109#issuecomment-356221440
https://github.com/broadinstitute/cromwell/issues/3109#issuecomment-356221440:409,Deployability,configurat,configuration,409,"My task are not using docker. Also I see no attempts at all to copy or softlink the files. Not in the log, and not in the cromwell-executions folder.; Also hard-linking seems to persist using the `SGE` backend. Even though the localization has the same configuration as above. So the error is not backend specific. Fortunately, all the other values in the config are used. Which makes me think that either my configuration file has some error (keys in wrong place). But I have checked this over and over again already with the example files and it seems to be correct (though I am not infallible of course).; Or the backend just ignores the values due to a bug.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3109#issuecomment-356221440
https://github.com/broadinstitute/cromwell/issues/3109#issuecomment-356221440:253,Modifiability,config,configuration,253,"My task are not using docker. Also I see no attempts at all to copy or softlink the files. Not in the log, and not in the cromwell-executions folder.; Also hard-linking seems to persist using the `SGE` backend. Even though the localization has the same configuration as above. So the error is not backend specific. Fortunately, all the other values in the config are used. Which makes me think that either my configuration file has some error (keys in wrong place). But I have checked this over and over again already with the example files and it seems to be correct (though I am not infallible of course).; Or the backend just ignores the values due to a bug.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3109#issuecomment-356221440
https://github.com/broadinstitute/cromwell/issues/3109#issuecomment-356221440:356,Modifiability,config,config,356,"My task are not using docker. Also I see no attempts at all to copy or softlink the files. Not in the log, and not in the cromwell-executions folder.; Also hard-linking seems to persist using the `SGE` backend. Even though the localization has the same configuration as above. So the error is not backend specific. Fortunately, all the other values in the config are used. Which makes me think that either my configuration file has some error (keys in wrong place). But I have checked this over and over again already with the example files and it seems to be correct (though I am not infallible of course).; Or the backend just ignores the values due to a bug.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3109#issuecomment-356221440
https://github.com/broadinstitute/cromwell/issues/3109#issuecomment-356221440:409,Modifiability,config,configuration,409,"My task are not using docker. Also I see no attempts at all to copy or softlink the files. Not in the log, and not in the cromwell-executions folder.; Also hard-linking seems to persist using the `SGE` backend. Even though the localization has the same configuration as above. So the error is not backend specific. Fortunately, all the other values in the config are used. Which makes me think that either my configuration file has some error (keys in wrong place). But I have checked this over and over again already with the example files and it seems to be correct (though I am not infallible of course).; Or the backend just ignores the values due to a bug.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3109#issuecomment-356221440
https://github.com/broadinstitute/cromwell/issues/3109#issuecomment-356221440:102,Testability,log,log,102,"My task are not using docker. Also I see no attempts at all to copy or softlink the files. Not in the log, and not in the cromwell-executions folder.; Also hard-linking seems to persist using the `SGE` backend. Even though the localization has the same configuration as above. So the error is not backend specific. Fortunately, all the other values in the config are used. Which makes me think that either my configuration file has some error (keys in wrong place). But I have checked this over and over again already with the example files and it seems to be correct (though I am not infallible of course).; Or the backend just ignores the values due to a bug.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3109#issuecomment-356221440
https://github.com/broadinstitute/cromwell/issues/3109#issuecomment-402984197:40,Availability,error,errorred,40,"Managed to fix the problem. Cromwell 32 errorred and explained the problem. The filesystem section was moved to the SGE section. Are config file now looks like this:; ```HOCON; backend {; default=""SGE""; providers {; SGE {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; concurrent-job-limit = 10000; runtime-attributes= """"""; Int? cpu=1; Int? memory=4; """"""; submit = """"""; qsub \; -terse \; -V \; -b n \; -wd ${cwd} \; -N ${job_name} \; ${'-pe BWA ' + cpu} \; ${'-l h_vmem=' + memory + ""G""} \; -o ${out} \; -e ${err} \; ${script}; """"""; kill = ""qdel ${job_id}""; check-alive = ""qstat -j ${job_id}""; job-id-regex = ""(\\d+)"". filesystems {; local {; localization: [; ""soft-link"", ""copy"", ""hard-link""; ]; caching {; duplication-strategy: [ ""soft-link"", ""copy"", ""hard-link"" ]; hashing-strategy: ""file""; }; }; }; }; }; }; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3109#issuecomment-402984197
https://github.com/broadinstitute/cromwell/issues/3109#issuecomment-402984197:615,Availability,alive,alive,615,"Managed to fix the problem. Cromwell 32 errorred and explained the problem. The filesystem section was moved to the SGE section. Are config file now looks like this:; ```HOCON; backend {; default=""SGE""; providers {; SGE {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; concurrent-job-limit = 10000; runtime-attributes= """"""; Int? cpu=1; Int? memory=4; """"""; submit = """"""; qsub \; -terse \; -V \; -b n \; -wd ${cwd} \; -N ${job_name} \; ${'-pe BWA ' + cpu} \; ${'-l h_vmem=' + memory + ""G""} \; -o ${out} \; -e ${err} \; ${script}; """"""; kill = ""qdel ${job_id}""; check-alive = ""qstat -j ${job_id}""; job-id-regex = ""(\\d+)"". filesystems {; local {; localization: [; ""soft-link"", ""copy"", ""hard-link""; ]; caching {; duplication-strategy: [ ""soft-link"", ""copy"", ""hard-link"" ]; hashing-strategy: ""file""; }; }; }; }; }; }; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3109#issuecomment-402984197
https://github.com/broadinstitute/cromwell/issues/3109#issuecomment-402984197:133,Modifiability,config,config,133,"Managed to fix the problem. Cromwell 32 errorred and explained the problem. The filesystem section was moved to the SGE section. Are config file now looks like this:; ```HOCON; backend {; default=""SGE""; providers {; SGE {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; concurrent-job-limit = 10000; runtime-attributes= """"""; Int? cpu=1; Int? memory=4; """"""; submit = """"""; qsub \; -terse \; -V \; -b n \; -wd ${cwd} \; -N ${job_name} \; ${'-pe BWA ' + cpu} \; ${'-l h_vmem=' + memory + ""G""} \; -o ${out} \; -e ${err} \; ${script}; """"""; kill = ""qdel ${job_id}""; check-alive = ""qstat -j ${job_id}""; job-id-regex = ""(\\d+)"". filesystems {; local {; localization: [; ""soft-link"", ""copy"", ""hard-link""; ]; caching {; duplication-strategy: [ ""soft-link"", ""copy"", ""hard-link"" ]; hashing-strategy: ""file""; }; }; }; }; }; }; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3109#issuecomment-402984197
https://github.com/broadinstitute/cromwell/issues/3109#issuecomment-402984197:266,Modifiability,config,config,266,"Managed to fix the problem. Cromwell 32 errorred and explained the problem. The filesystem section was moved to the SGE section. Are config file now looks like this:; ```HOCON; backend {; default=""SGE""; providers {; SGE {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; concurrent-job-limit = 10000; runtime-attributes= """"""; Int? cpu=1; Int? memory=4; """"""; submit = """"""; qsub \; -terse \; -V \; -b n \; -wd ${cwd} \; -N ${job_name} \; ${'-pe BWA ' + cpu} \; ${'-l h_vmem=' + memory + ""G""} \; -o ${out} \; -e ${err} \; ${script}; """"""; kill = ""qdel ${job_id}""; check-alive = ""qstat -j ${job_id}""; job-id-regex = ""(\\d+)"". filesystems {; local {; localization: [; ""soft-link"", ""copy"", ""hard-link""; ]; caching {; duplication-strategy: [ ""soft-link"", ""copy"", ""hard-link"" ]; hashing-strategy: ""file""; }; }; }; }; }; }; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3109#issuecomment-402984197
https://github.com/broadinstitute/cromwell/issues/3109#issuecomment-402984197:273,Modifiability,Config,ConfigBackendLifecycleActorFactory,273,"Managed to fix the problem. Cromwell 32 errorred and explained the problem. The filesystem section was moved to the SGE section. Are config file now looks like this:; ```HOCON; backend {; default=""SGE""; providers {; SGE {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; concurrent-job-limit = 10000; runtime-attributes= """"""; Int? cpu=1; Int? memory=4; """"""; submit = """"""; qsub \; -terse \; -V \; -b n \; -wd ${cwd} \; -N ${job_name} \; ${'-pe BWA ' + cpu} \; ${'-l h_vmem=' + memory + ""G""} \; -o ${out} \; -e ${err} \; ${script}; """"""; kill = ""qdel ${job_id}""; check-alive = ""qstat -j ${job_id}""; job-id-regex = ""(\\d+)"". filesystems {; local {; localization: [; ""soft-link"", ""copy"", ""hard-link""; ]; caching {; duplication-strategy: [ ""soft-link"", ""copy"", ""hard-link"" ]; hashing-strategy: ""file""; }; }; }; }; }; }; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3109#issuecomment-402984197
https://github.com/broadinstitute/cromwell/issues/3109#issuecomment-402984197:310,Modifiability,config,config,310,"Managed to fix the problem. Cromwell 32 errorred and explained the problem. The filesystem section was moved to the SGE section. Are config file now looks like this:; ```HOCON; backend {; default=""SGE""; providers {; SGE {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; concurrent-job-limit = 10000; runtime-attributes= """"""; Int? cpu=1; Int? memory=4; """"""; submit = """"""; qsub \; -terse \; -V \; -b n \; -wd ${cwd} \; -N ${job_name} \; ${'-pe BWA ' + cpu} \; ${'-l h_vmem=' + memory + ""G""} \; -o ${out} \; -e ${err} \; ${script}; """"""; kill = ""qdel ${job_id}""; check-alive = ""qstat -j ${job_id}""; job-id-regex = ""(\\d+)"". filesystems {; local {; localization: [; ""soft-link"", ""copy"", ""hard-link""; ]; caching {; duplication-strategy: [ ""soft-link"", ""copy"", ""hard-link"" ]; hashing-strategy: ""file""; }; }; }; }; }; }; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3109#issuecomment-402984197
https://github.com/broadinstitute/cromwell/issues/3109#issuecomment-402984197:320,Performance,concurren,concurrent-job-limit,320,"Managed to fix the problem. Cromwell 32 errorred and explained the problem. The filesystem section was moved to the SGE section. Are config file now looks like this:; ```HOCON; backend {; default=""SGE""; providers {; SGE {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; concurrent-job-limit = 10000; runtime-attributes= """"""; Int? cpu=1; Int? memory=4; """"""; submit = """"""; qsub \; -terse \; -V \; -b n \; -wd ${cwd} \; -N ${job_name} \; ${'-pe BWA ' + cpu} \; ${'-l h_vmem=' + memory + ""G""} \; -o ${out} \; -e ${err} \; ${script}; """"""; kill = ""qdel ${job_id}""; check-alive = ""qstat -j ${job_id}""; job-id-regex = ""(\\d+)"". filesystems {; local {; localization: [; ""soft-link"", ""copy"", ""hard-link""; ]; caching {; duplication-strategy: [ ""soft-link"", ""copy"", ""hard-link"" ]; hashing-strategy: ""file""; }; }; }; }; }; }; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3109#issuecomment-402984197
https://github.com/broadinstitute/cromwell/issues/3109#issuecomment-402984197:819,Security,hash,hashing-strategy,819,"Managed to fix the problem. Cromwell 32 errorred and explained the problem. The filesystem section was moved to the SGE section. Are config file now looks like this:; ```HOCON; backend {; default=""SGE""; providers {; SGE {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; concurrent-job-limit = 10000; runtime-attributes= """"""; Int? cpu=1; Int? memory=4; """"""; submit = """"""; qsub \; -terse \; -V \; -b n \; -wd ${cwd} \; -N ${job_name} \; ${'-pe BWA ' + cpu} \; ${'-l h_vmem=' + memory + ""G""} \; -o ${out} \; -e ${err} \; ${script}; """"""; kill = ""qdel ${job_id}""; check-alive = ""qstat -j ${job_id}""; job-id-regex = ""(\\d+)"". filesystems {; local {; localization: [; ""soft-link"", ""copy"", ""hard-link""; ]; caching {; duplication-strategy: [ ""soft-link"", ""copy"", ""hard-link"" ]; hashing-strategy: ""file""; }; }; }; }; }; }; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3109#issuecomment-402984197
https://github.com/broadinstitute/cromwell/issues/3115#issuecomment-453156671:12,Deployability,update,updates,12,"@ruchim Any updates on this issue? We are running this issue with CaaS/Cromwell again, unfortunately :( The current workaround is, for a query of 1000 workflows, we send 1000 individual requests to the Cromwell, which could also put pressure to Cromwell.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3115#issuecomment-453156671
https://github.com/broadinstitute/cromwell/issues/3115#issuecomment-455263017:139,Availability,error,error,139,"@cjllanwarne Thanks for looking into it! Our current use case is heavily relying on `""additionalQueryResultFields"": [""labels""]`, with this error we have to loop through all workflows and make X thousands requests each time :( And I assume JMUI is relying on `""additionalQueryResultFields"": ""parentWorkflowId""`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3115#issuecomment-455263017
https://github.com/broadinstitute/cromwell/pull/3139#issuecomment-357999800:89,Deployability,update,updated,89,FYI The conformance test that's failing can't pass until the `OutputManipulator` is also updated - I'm doing that today,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3139#issuecomment-357999800
https://github.com/broadinstitute/cromwell/pull/3139#issuecomment-357999800:20,Testability,test,test,20,FYI The conformance test that's failing can't pass until the `OutputManipulator` is also updated - I'm doing that today,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3139#issuecomment-357999800
https://github.com/broadinstitute/cromwell/pull/3140#issuecomment-358177285:259,Deployability,update,update,259,"> ‚Ä¶it is not strictly the case that every time \[expressionLib\] appears, it is ""next to"" a Parameter Context. Meant the other way around, Parameter Context is always ""next to"" a expressionLib. If it continues to be that way as CWL settles, one can always be update the Parameter Context via a future PR.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3140#issuecomment-358177285
https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502:21,Availability,error,error,21,"I'm getting the same error with this wdl: [mutect2-replicate-validation.zip](https://github.com/broadinstitute/cromwell/files/2242528/mutect2-replicate-validation.zip). And here is the dependency file: [wdl-dependencies.zip](https://github.com/broadinstitute/cromwell/files/2242529/wdl-dependencies.zip). This happens in versions 30 and up. When I run this in v29, cromwell doesn't throw an error but it hangs after completing the first task. . tsato@gsa5:novaseq: java -jar $wom validate mutect2-replicate-validation.wdl; Exception in thread ""main"" java.lang.RuntimeException: This workflow contains a cyclic dependency on m2.Mutect2.filtered_vcf; 	at wdl.draft2.model.Scope.childGraphNodesSorted(Scope.scala:53); 	at wdl.draft2.model.Scope.childGraphNodesSorted$(Scope.scala:44); 	at wdl.draft2.model.WdlWorkflow.childGraphNodesSorted$lzycompute(WdlWorkflow.scala:46); 	at wdl.draft2.model.WdlWorkflow.childGraphNodesSorted(WdlWorkflow.scala:46); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:97); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:18); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph$(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$ops$$anon$1.toWomGraph(WomGraphMaker.scala:8); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomWorkflowDefinitionMaker$.toWomWorkflowDefinition(WdlDraft2WomWorkflowDefinitionMaker.scala:14); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomWorkflowDefinitionMaker$.toWomWorkflowDefinition(WdlDraft2WomWorkflowDefinitionMaker.scala:10); 	at wom.transforms.WomWorkflowDefinitionMaker$Ops.toWomWorkflowDefinition(WomWorkflowDefinitionMaker.scala:8); 	at wom.transforms.WomWorkflowDefinitionMaker$Ops.toWomWorkflowDefinition$(WomWorkflowDefinitionMaker.scala:8); 	at wom.transforms.WomWorkflowDefinitionMaker$ops$$anon$1.toWomWorkflowDefinition(WomWorkflowDefinitionMak",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502
https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502:391,Availability,error,error,391,"I'm getting the same error with this wdl: [mutect2-replicate-validation.zip](https://github.com/broadinstitute/cromwell/files/2242528/mutect2-replicate-validation.zip). And here is the dependency file: [wdl-dependencies.zip](https://github.com/broadinstitute/cromwell/files/2242529/wdl-dependencies.zip). This happens in versions 30 and up. When I run this in v29, cromwell doesn't throw an error but it hangs after completing the first task. . tsato@gsa5:novaseq: java -jar $wom validate mutect2-replicate-validation.wdl; Exception in thread ""main"" java.lang.RuntimeException: This workflow contains a cyclic dependency on m2.Mutect2.filtered_vcf; 	at wdl.draft2.model.Scope.childGraphNodesSorted(Scope.scala:53); 	at wdl.draft2.model.Scope.childGraphNodesSorted$(Scope.scala:44); 	at wdl.draft2.model.WdlWorkflow.childGraphNodesSorted$lzycompute(WdlWorkflow.scala:46); 	at wdl.draft2.model.WdlWorkflow.childGraphNodesSorted(WdlWorkflow.scala:46); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:97); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:18); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph$(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$ops$$anon$1.toWomGraph(WomGraphMaker.scala:8); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomWorkflowDefinitionMaker$.toWomWorkflowDefinition(WdlDraft2WomWorkflowDefinitionMaker.scala:14); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomWorkflowDefinitionMaker$.toWomWorkflowDefinition(WdlDraft2WomWorkflowDefinitionMaker.scala:10); 	at wom.transforms.WomWorkflowDefinitionMaker$Ops.toWomWorkflowDefinition(WomWorkflowDefinitionMaker.scala:8); 	at wom.transforms.WomWorkflowDefinitionMaker$Ops.toWomWorkflowDefinition$(WomWorkflowDefinitionMaker.scala:8); 	at wom.transforms.WomWorkflowDefinitionMaker$ops$$anon$1.toWomWorkflowDefinition(WomWorkflowDefinitionMak",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502
https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502:3219,Availability,Error,ErrorOr,3219,a:11); 	at wom.transforms.WomCallableMaker$Ops.toWomCallable(WomCallableMaker.scala:8); 	at wom.transforms.WomCallableMaker$Ops.toWomCallable$(WomCallableMaker.scala:8); 	at wom.transforms.WomCallableMaker$ops$$anon$1.toWomCallable(WomCallableMaker.scala:8); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomCallNodeMaker$.toWomCallNode(WdlDraft2WomCallNodeMaker.scala:129); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomCallNodeMaker$.toWomCallNode(WdlDraft2WomCallNodeMaker.scala:21); 	at wom.transforms.WomCallNodeMaker$Ops.toWomCallNode(WomCallNodeMaker.scala:9); 	at wom.transforms.WomCallNodeMaker$Ops.toWomCallNode$(WomCallNodeMaker.scala:9); 	at wom.transforms.WomCallNodeMaker$ops$$anon$1.toWomCallNode(WomCallNodeMaker.scala:9); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.buildNode$1(WdlDraft2WomGraphMaker.scala:68); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.$anonfun$toWomGraph$3(WdlDraft2WomGraphMaker.scala:38); 	at common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.foldFunction$1(WdlDraft2WomGraphMaker.scala:37); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.$anonfun$toWomGraph$14(WdlDraft2WomGraphMaker.scala:98); 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:122); 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:118); 	at scala.collection.immutable.List.foldLeft(List.scala:86); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:98); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:18); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph$(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$ops$$anon$1.toWomGraph(WomGraphMaker.scala:8); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomScatterNodeMaker,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502
https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502:3269,Availability,Error,ErrorOr,3269,CallableMaker$Ops.toWomCallable(WomCallableMaker.scala:8); 	at wom.transforms.WomCallableMaker$Ops.toWomCallable$(WomCallableMaker.scala:8); 	at wom.transforms.WomCallableMaker$ops$$anon$1.toWomCallable(WomCallableMaker.scala:8); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomCallNodeMaker$.toWomCallNode(WdlDraft2WomCallNodeMaker.scala:129); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomCallNodeMaker$.toWomCallNode(WdlDraft2WomCallNodeMaker.scala:21); 	at wom.transforms.WomCallNodeMaker$Ops.toWomCallNode(WomCallNodeMaker.scala:9); 	at wom.transforms.WomCallNodeMaker$Ops.toWomCallNode$(WomCallNodeMaker.scala:9); 	at wom.transforms.WomCallNodeMaker$ops$$anon$1.toWomCallNode(WomCallNodeMaker.scala:9); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.buildNode$1(WdlDraft2WomGraphMaker.scala:68); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.$anonfun$toWomGraph$3(WdlDraft2WomGraphMaker.scala:38); 	at common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.foldFunction$1(WdlDraft2WomGraphMaker.scala:37); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.$anonfun$toWomGraph$14(WdlDraft2WomGraphMaker.scala:98); 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:122); 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:118); 	at scala.collection.immutable.List.foldLeft(List.scala:86); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:98); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:18); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph$(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$ops$$anon$1.toWomGraph(WomGraphMaker.scala:8); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomScatterNodeMaker$.$anonfun$toWomScatterNode$9,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502
https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502:4327,Availability,Error,ErrorOr,4327,ker$.foldFunction$1(WdlDraft2WomGraphMaker.scala:37); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.$anonfun$toWomGraph$14(WdlDraft2WomGraphMaker.scala:98); 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:122); 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:118); 	at scala.collection.immutable.List.foldLeft(List.scala:86); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:98); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:18); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph$(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$ops$$anon$1.toWomGraph(WomGraphMaker.scala:8); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomScatterNodeMaker$.$anonfun$toWomScatterNode$9(WdlDraft2WomScatterNodeMaker.scala:55); 	at common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomScatterNodeMaker$.$anonfun$toWomScatterNode$7(WdlDraft2WomScatterNodeMaker.scala:52); 	at common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomScatterNodeMaker$.toWomScatterNode(WdlDraft2WomScatterNodeMaker.scala:51); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomScatterNodeMaker$.toWomScatterNode(WdlDraft2WomScatterNodeMaker.scala:15); 	at wom.transforms.WomScatterNodeMaker$Ops.toWomScatterNode(WomScatterNodeMaker.scala:10); 	at wom.transforms.WomScatterNodeMaker$Ops.toWomScatterNode$(WomScatterNodeMaker.scala:10); 	at wom.transforms.WomScatterNodeMaker$ops$$anon$1.toWomScatterNode(WomScatterNodeMaker.scala:10); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.buildNode$1(WdlDraft2WomGraphMaker.scala:90); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.$anonfun$toWomGraph$3(WdlDra,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502
https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502:4377,Availability,Error,ErrorOr,4377,WomGraphMaker.scala:37); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.$anonfun$toWomGraph$14(WdlDraft2WomGraphMaker.scala:98); 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:122); 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:118); 	at scala.collection.immutable.List.foldLeft(List.scala:86); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:98); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:18); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph$(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$ops$$anon$1.toWomGraph(WomGraphMaker.scala:8); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomScatterNodeMaker$.$anonfun$toWomScatterNode$9(WdlDraft2WomScatterNodeMaker.scala:55); 	at common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomScatterNodeMaker$.$anonfun$toWomScatterNode$7(WdlDraft2WomScatterNodeMaker.scala:52); 	at common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomScatterNodeMaker$.toWomScatterNode(WdlDraft2WomScatterNodeMaker.scala:51); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomScatterNodeMaker$.toWomScatterNode(WdlDraft2WomScatterNodeMaker.scala:15); 	at wom.transforms.WomScatterNodeMaker$Ops.toWomScatterNode(WomScatterNodeMaker.scala:10); 	at wom.transforms.WomScatterNodeMaker$Ops.toWomScatterNode$(WomScatterNodeMaker.scala:10); 	at wom.transforms.WomScatterNodeMaker$ops$$anon$1.toWomScatterNode(WomScatterNodeMaker.scala:10); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.buildNode$1(WdlDraft2WomGraphMaker.scala:90); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.$anonfun$toWomGraph$3(WdlDraft2WomGraphMaker.scala:38); 	,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502
https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502:4552,Availability,Error,ErrorOr,4552,rSeqOptimized.scala:122); 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:118); 	at scala.collection.immutable.List.foldLeft(List.scala:86); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:98); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:18); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph$(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$ops$$anon$1.toWomGraph(WomGraphMaker.scala:8); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomScatterNodeMaker$.$anonfun$toWomScatterNode$9(WdlDraft2WomScatterNodeMaker.scala:55); 	at common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomScatterNodeMaker$.$anonfun$toWomScatterNode$7(WdlDraft2WomScatterNodeMaker.scala:52); 	at common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomScatterNodeMaker$.toWomScatterNode(WdlDraft2WomScatterNodeMaker.scala:51); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomScatterNodeMaker$.toWomScatterNode(WdlDraft2WomScatterNodeMaker.scala:15); 	at wom.transforms.WomScatterNodeMaker$Ops.toWomScatterNode(WomScatterNodeMaker.scala:10); 	at wom.transforms.WomScatterNodeMaker$Ops.toWomScatterNode$(WomScatterNodeMaker.scala:10); 	at wom.transforms.WomScatterNodeMaker$ops$$anon$1.toWomScatterNode(WomScatterNodeMaker.scala:10); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.buildNode$1(WdlDraft2WomGraphMaker.scala:90); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.$anonfun$toWomGraph$3(WdlDraft2WomGraphMaker.scala:38); 	at common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.foldFunction$1(WdlDraft2WomGraphMaker.scala:37,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502
https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502:4602,Availability,Error,ErrorOr,4602, scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:118); 	at scala.collection.immutable.List.foldLeft(List.scala:86); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:98); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:18); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph$(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$ops$$anon$1.toWomGraph(WomGraphMaker.scala:8); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomScatterNodeMaker$.$anonfun$toWomScatterNode$9(WdlDraft2WomScatterNodeMaker.scala:55); 	at common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomScatterNodeMaker$.$anonfun$toWomScatterNode$7(WdlDraft2WomScatterNodeMaker.scala:52); 	at common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomScatterNodeMaker$.toWomScatterNode(WdlDraft2WomScatterNodeMaker.scala:51); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomScatterNodeMaker$.toWomScatterNode(WdlDraft2WomScatterNodeMaker.scala:15); 	at wom.transforms.WomScatterNodeMaker$Ops.toWomScatterNode(WomScatterNodeMaker.scala:10); 	at wom.transforms.WomScatterNodeMaker$Ops.toWomScatterNode$(WomScatterNodeMaker.scala:10); 	at wom.transforms.WomScatterNodeMaker$ops$$anon$1.toWomScatterNode(WomScatterNodeMaker.scala:10); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.buildNode$1(WdlDraft2WomGraphMaker.scala:90); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.$anonfun$toWomGraph$3(WdlDraft2WomGraphMaker.scala:38); 	at common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.foldFunction$1(WdlDraft2WomGraphMaker.scala:37); 	at wdl.transforms.draft2.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502
https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502:5393,Availability,Error,ErrorOr,5393,forms.draft2.wdlom2wom.WdlDraft2WomScatterNodeMaker$.$anonfun$toWomScatterNode$7(WdlDraft2WomScatterNodeMaker.scala:52); 	at common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomScatterNodeMaker$.toWomScatterNode(WdlDraft2WomScatterNodeMaker.scala:51); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomScatterNodeMaker$.toWomScatterNode(WdlDraft2WomScatterNodeMaker.scala:15); 	at wom.transforms.WomScatterNodeMaker$Ops.toWomScatterNode(WomScatterNodeMaker.scala:10); 	at wom.transforms.WomScatterNodeMaker$Ops.toWomScatterNode$(WomScatterNodeMaker.scala:10); 	at wom.transforms.WomScatterNodeMaker$ops$$anon$1.toWomScatterNode(WomScatterNodeMaker.scala:10); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.buildNode$1(WdlDraft2WomGraphMaker.scala:90); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.$anonfun$toWomGraph$3(WdlDraft2WomGraphMaker.scala:38); 	at common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.foldFunction$1(WdlDraft2WomGraphMaker.scala:37); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.$anonfun$toWomGraph$14(WdlDraft2WomGraphMaker.scala:98); 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:122); 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:118); 	at scala.collection.immutable.List.foldLeft(List.scala:86); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:98); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:18); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph$(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$ops$$anon$1.toWomGraph(WomGraphMaker.scala:8); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomWorkflowDefiniti,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502
https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502:5443,Availability,Error,ErrorOr,5443,ft2WomScatterNodeMaker$.$anonfun$toWomScatterNode$7(WdlDraft2WomScatterNodeMaker.scala:52); 	at common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomScatterNodeMaker$.toWomScatterNode(WdlDraft2WomScatterNodeMaker.scala:51); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomScatterNodeMaker$.toWomScatterNode(WdlDraft2WomScatterNodeMaker.scala:15); 	at wom.transforms.WomScatterNodeMaker$Ops.toWomScatterNode(WomScatterNodeMaker.scala:10); 	at wom.transforms.WomScatterNodeMaker$Ops.toWomScatterNode$(WomScatterNodeMaker.scala:10); 	at wom.transforms.WomScatterNodeMaker$ops$$anon$1.toWomScatterNode(WomScatterNodeMaker.scala:10); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.buildNode$1(WdlDraft2WomGraphMaker.scala:90); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.$anonfun$toWomGraph$3(WdlDraft2WomGraphMaker.scala:38); 	at common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.foldFunction$1(WdlDraft2WomGraphMaker.scala:37); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.$anonfun$toWomGraph$14(WdlDraft2WomGraphMaker.scala:98); 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:122); 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:118); 	at scala.collection.immutable.List.foldLeft(List.scala:86); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:98); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:18); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph$(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$ops$$anon$1.toWomGraph(WomGraphMaker.scala:8); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomWorkflowDefinitionMaker$.toWomWorkflowDefinit,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502
https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502:9545,Energy Efficiency,adapt,adapted,9545,; 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomBundleMakers$$anon$1.toWomBundle(WdlDraft2WomBundleMakers.scala:19); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomBundleMakers$$anon$1.toWomBundle(WdlDraft2WomBundleMakers.scala:17); 	at wom.transforms.WomBundleMaker$Ops.toWomBundle(WomExecutableMaker.scala:16); 	at wom.transforms.WomBundleMaker$Ops.toWomBundle$(WomExecutableMaker.scala:16); 	at wom.transforms.WomBundleMaker$ops$$anon$2.toWomBundle(WomExecutableMaker.scala:16); 	at languages.wdl.draft2.WdlDraft2LanguageFactory.$anonfun$getWomBundle$3(WdlDraft2LanguageFactory.scala:120); 	at scala.util.Either.flatMap(Either.scala:338); 	at languages.wdl.draft2.WdlDraft2LanguageFactory.$anonfun$getWomBundle$1(WdlDraft2LanguageFactory.scala:119); 	at scala.util.Either.flatMap(Either.scala:338); 	at languages.wdl.draft2.WdlDraft2LanguageFactory.getWomBundle(WdlDraft2LanguageFactory.scala:118); 	at womtool.input.WomGraphMaker$.$anonfun$getBundleAndFactory$1(WomGraphMaker.scala:49); 	at scala.util.Either.flatMap(Either.scala:338); 	at womtool.input.WomGraphMaker$.getBundleAndFactory(WomGraphMaker.scala:40); 	at womtool.input.WomGraphMaker$.getBundle(WomGraphMaker.scala:22); 	at womtool.validate.Validate$.validate(Validate.scala:14); 	at womtool.WomtoolMain$.dispatchCommand(WomtoolMain.scala:47); 	at womtool.WomtoolMain$.runWomtool(WomtoolMain.scala:134); 	at womtool.WomtoolMain$.delayedEndpoint$womtool$WomtoolMain$1(WomtoolMain.scala:139); 	at womtool.WomtoolMain$delayedInit$body.apply(WomtoolMain.scala:21); 	at scala.Function0.apply$mcV$sp(Function0.scala:34); 	at scala.Function0.apply$mcV$sp$(Function0.scala:34); 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12); 	at scala.App.$anonfun$main$1$adapted(App.scala:76); 	at scala.collection.immutable.List.foreach(List.scala:389); 	at scala.App.main(App.scala:76); 	at scala.App.main$(App.scala:74); 	at womtool.WomtoolMain$.main(WomtoolMain.scala:21); 	at womtool.WomtoolMain.main(WomtoolMain.scala),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502
https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502:185,Integrability,depend,dependency,185,"I'm getting the same error with this wdl: [mutect2-replicate-validation.zip](https://github.com/broadinstitute/cromwell/files/2242528/mutect2-replicate-validation.zip). And here is the dependency file: [wdl-dependencies.zip](https://github.com/broadinstitute/cromwell/files/2242529/wdl-dependencies.zip). This happens in versions 30 and up. When I run this in v29, cromwell doesn't throw an error but it hangs after completing the first task. . tsato@gsa5:novaseq: java -jar $wom validate mutect2-replicate-validation.wdl; Exception in thread ""main"" java.lang.RuntimeException: This workflow contains a cyclic dependency on m2.Mutect2.filtered_vcf; 	at wdl.draft2.model.Scope.childGraphNodesSorted(Scope.scala:53); 	at wdl.draft2.model.Scope.childGraphNodesSorted$(Scope.scala:44); 	at wdl.draft2.model.WdlWorkflow.childGraphNodesSorted$lzycompute(WdlWorkflow.scala:46); 	at wdl.draft2.model.WdlWorkflow.childGraphNodesSorted(WdlWorkflow.scala:46); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:97); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:18); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph$(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$ops$$anon$1.toWomGraph(WomGraphMaker.scala:8); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomWorkflowDefinitionMaker$.toWomWorkflowDefinition(WdlDraft2WomWorkflowDefinitionMaker.scala:14); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomWorkflowDefinitionMaker$.toWomWorkflowDefinition(WdlDraft2WomWorkflowDefinitionMaker.scala:10); 	at wom.transforms.WomWorkflowDefinitionMaker$Ops.toWomWorkflowDefinition(WomWorkflowDefinitionMaker.scala:8); 	at wom.transforms.WomWorkflowDefinitionMaker$Ops.toWomWorkflowDefinition$(WomWorkflowDefinitionMaker.scala:8); 	at wom.transforms.WomWorkflowDefinitionMaker$ops$$anon$1.toWomWorkflowDefinition(WomWorkflowDefinitionMak",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502
https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502:207,Integrability,depend,dependencies,207,"I'm getting the same error with this wdl: [mutect2-replicate-validation.zip](https://github.com/broadinstitute/cromwell/files/2242528/mutect2-replicate-validation.zip). And here is the dependency file: [wdl-dependencies.zip](https://github.com/broadinstitute/cromwell/files/2242529/wdl-dependencies.zip). This happens in versions 30 and up. When I run this in v29, cromwell doesn't throw an error but it hangs after completing the first task. . tsato@gsa5:novaseq: java -jar $wom validate mutect2-replicate-validation.wdl; Exception in thread ""main"" java.lang.RuntimeException: This workflow contains a cyclic dependency on m2.Mutect2.filtered_vcf; 	at wdl.draft2.model.Scope.childGraphNodesSorted(Scope.scala:53); 	at wdl.draft2.model.Scope.childGraphNodesSorted$(Scope.scala:44); 	at wdl.draft2.model.WdlWorkflow.childGraphNodesSorted$lzycompute(WdlWorkflow.scala:46); 	at wdl.draft2.model.WdlWorkflow.childGraphNodesSorted(WdlWorkflow.scala:46); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:97); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:18); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph$(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$ops$$anon$1.toWomGraph(WomGraphMaker.scala:8); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomWorkflowDefinitionMaker$.toWomWorkflowDefinition(WdlDraft2WomWorkflowDefinitionMaker.scala:14); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomWorkflowDefinitionMaker$.toWomWorkflowDefinition(WdlDraft2WomWorkflowDefinitionMaker.scala:10); 	at wom.transforms.WomWorkflowDefinitionMaker$Ops.toWomWorkflowDefinition(WomWorkflowDefinitionMaker.scala:8); 	at wom.transforms.WomWorkflowDefinitionMaker$Ops.toWomWorkflowDefinition$(WomWorkflowDefinitionMaker.scala:8); 	at wom.transforms.WomWorkflowDefinitionMaker$ops$$anon$1.toWomWorkflowDefinition(WomWorkflowDefinitionMak",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502
https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502:286,Integrability,depend,dependencies,286,"I'm getting the same error with this wdl: [mutect2-replicate-validation.zip](https://github.com/broadinstitute/cromwell/files/2242528/mutect2-replicate-validation.zip). And here is the dependency file: [wdl-dependencies.zip](https://github.com/broadinstitute/cromwell/files/2242529/wdl-dependencies.zip). This happens in versions 30 and up. When I run this in v29, cromwell doesn't throw an error but it hangs after completing the first task. . tsato@gsa5:novaseq: java -jar $wom validate mutect2-replicate-validation.wdl; Exception in thread ""main"" java.lang.RuntimeException: This workflow contains a cyclic dependency on m2.Mutect2.filtered_vcf; 	at wdl.draft2.model.Scope.childGraphNodesSorted(Scope.scala:53); 	at wdl.draft2.model.Scope.childGraphNodesSorted$(Scope.scala:44); 	at wdl.draft2.model.WdlWorkflow.childGraphNodesSorted$lzycompute(WdlWorkflow.scala:46); 	at wdl.draft2.model.WdlWorkflow.childGraphNodesSorted(WdlWorkflow.scala:46); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:97); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:18); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph$(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$ops$$anon$1.toWomGraph(WomGraphMaker.scala:8); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomWorkflowDefinitionMaker$.toWomWorkflowDefinition(WdlDraft2WomWorkflowDefinitionMaker.scala:14); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomWorkflowDefinitionMaker$.toWomWorkflowDefinition(WdlDraft2WomWorkflowDefinitionMaker.scala:10); 	at wom.transforms.WomWorkflowDefinitionMaker$Ops.toWomWorkflowDefinition(WomWorkflowDefinitionMaker.scala:8); 	at wom.transforms.WomWorkflowDefinitionMaker$Ops.toWomWorkflowDefinition$(WomWorkflowDefinitionMaker.scala:8); 	at wom.transforms.WomWorkflowDefinitionMaker$ops$$anon$1.toWomWorkflowDefinition(WomWorkflowDefinitionMak",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502
https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502:610,Integrability,depend,dependency,610,"I'm getting the same error with this wdl: [mutect2-replicate-validation.zip](https://github.com/broadinstitute/cromwell/files/2242528/mutect2-replicate-validation.zip). And here is the dependency file: [wdl-dependencies.zip](https://github.com/broadinstitute/cromwell/files/2242529/wdl-dependencies.zip). This happens in versions 30 and up. When I run this in v29, cromwell doesn't throw an error but it hangs after completing the first task. . tsato@gsa5:novaseq: java -jar $wom validate mutect2-replicate-validation.wdl; Exception in thread ""main"" java.lang.RuntimeException: This workflow contains a cyclic dependency on m2.Mutect2.filtered_vcf; 	at wdl.draft2.model.Scope.childGraphNodesSorted(Scope.scala:53); 	at wdl.draft2.model.Scope.childGraphNodesSorted$(Scope.scala:44); 	at wdl.draft2.model.WdlWorkflow.childGraphNodesSorted$lzycompute(WdlWorkflow.scala:46); 	at wdl.draft2.model.WdlWorkflow.childGraphNodesSorted(WdlWorkflow.scala:46); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:97); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:18); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph$(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$ops$$anon$1.toWomGraph(WomGraphMaker.scala:8); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomWorkflowDefinitionMaker$.toWomWorkflowDefinition(WdlDraft2WomWorkflowDefinitionMaker.scala:14); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomWorkflowDefinitionMaker$.toWomWorkflowDefinition(WdlDraft2WomWorkflowDefinitionMaker.scala:10); 	at wom.transforms.WomWorkflowDefinitionMaker$Ops.toWomWorkflowDefinition(WomWorkflowDefinitionMaker.scala:8); 	at wom.transforms.WomWorkflowDefinitionMaker$Ops.toWomWorkflowDefinition$(WomWorkflowDefinitionMaker.scala:8); 	at wom.transforms.WomWorkflowDefinitionMaker$ops$$anon$1.toWomWorkflowDefinition(WomWorkflowDefinitionMak",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502
https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502:9545,Modifiability,adapt,adapted,9545,; 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomBundleMakers$$anon$1.toWomBundle(WdlDraft2WomBundleMakers.scala:19); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomBundleMakers$$anon$1.toWomBundle(WdlDraft2WomBundleMakers.scala:17); 	at wom.transforms.WomBundleMaker$Ops.toWomBundle(WomExecutableMaker.scala:16); 	at wom.transforms.WomBundleMaker$Ops.toWomBundle$(WomExecutableMaker.scala:16); 	at wom.transforms.WomBundleMaker$ops$$anon$2.toWomBundle(WomExecutableMaker.scala:16); 	at languages.wdl.draft2.WdlDraft2LanguageFactory.$anonfun$getWomBundle$3(WdlDraft2LanguageFactory.scala:120); 	at scala.util.Either.flatMap(Either.scala:338); 	at languages.wdl.draft2.WdlDraft2LanguageFactory.$anonfun$getWomBundle$1(WdlDraft2LanguageFactory.scala:119); 	at scala.util.Either.flatMap(Either.scala:338); 	at languages.wdl.draft2.WdlDraft2LanguageFactory.getWomBundle(WdlDraft2LanguageFactory.scala:118); 	at womtool.input.WomGraphMaker$.$anonfun$getBundleAndFactory$1(WomGraphMaker.scala:49); 	at scala.util.Either.flatMap(Either.scala:338); 	at womtool.input.WomGraphMaker$.getBundleAndFactory(WomGraphMaker.scala:40); 	at womtool.input.WomGraphMaker$.getBundle(WomGraphMaker.scala:22); 	at womtool.validate.Validate$.validate(Validate.scala:14); 	at womtool.WomtoolMain$.dispatchCommand(WomtoolMain.scala:47); 	at womtool.WomtoolMain$.runWomtool(WomtoolMain.scala:134); 	at womtool.WomtoolMain$.delayedEndpoint$womtool$WomtoolMain$1(WomtoolMain.scala:139); 	at womtool.WomtoolMain$delayedInit$body.apply(WomtoolMain.scala:21); 	at scala.Function0.apply$mcV$sp(Function0.scala:34); 	at scala.Function0.apply$mcV$sp$(Function0.scala:34); 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12); 	at scala.App.$anonfun$main$1$adapted(App.scala:76); 	at scala.collection.immutable.List.foreach(List.scala:389); 	at scala.App.main(App.scala:76); 	at scala.App.main$(App.scala:74); 	at womtool.WomtoolMain$.main(WomtoolMain.scala:21); 	at womtool.WomtoolMain.main(WomtoolMain.scala),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502
https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502:61,Security,validat,validation,61,"I'm getting the same error with this wdl: [mutect2-replicate-validation.zip](https://github.com/broadinstitute/cromwell/files/2242528/mutect2-replicate-validation.zip). And here is the dependency file: [wdl-dependencies.zip](https://github.com/broadinstitute/cromwell/files/2242529/wdl-dependencies.zip). This happens in versions 30 and up. When I run this in v29, cromwell doesn't throw an error but it hangs after completing the first task. . tsato@gsa5:novaseq: java -jar $wom validate mutect2-replicate-validation.wdl; Exception in thread ""main"" java.lang.RuntimeException: This workflow contains a cyclic dependency on m2.Mutect2.filtered_vcf; 	at wdl.draft2.model.Scope.childGraphNodesSorted(Scope.scala:53); 	at wdl.draft2.model.Scope.childGraphNodesSorted$(Scope.scala:44); 	at wdl.draft2.model.WdlWorkflow.childGraphNodesSorted$lzycompute(WdlWorkflow.scala:46); 	at wdl.draft2.model.WdlWorkflow.childGraphNodesSorted(WdlWorkflow.scala:46); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:97); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:18); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph$(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$ops$$anon$1.toWomGraph(WomGraphMaker.scala:8); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomWorkflowDefinitionMaker$.toWomWorkflowDefinition(WdlDraft2WomWorkflowDefinitionMaker.scala:14); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomWorkflowDefinitionMaker$.toWomWorkflowDefinition(WdlDraft2WomWorkflowDefinitionMaker.scala:10); 	at wom.transforms.WomWorkflowDefinitionMaker$Ops.toWomWorkflowDefinition(WomWorkflowDefinitionMaker.scala:8); 	at wom.transforms.WomWorkflowDefinitionMaker$Ops.toWomWorkflowDefinition$(WomWorkflowDefinitionMaker.scala:8); 	at wom.transforms.WomWorkflowDefinitionMaker$ops$$anon$1.toWomWorkflowDefinition(WomWorkflowDefinitionMak",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502
https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502:152,Security,validat,validation,152,"I'm getting the same error with this wdl: [mutect2-replicate-validation.zip](https://github.com/broadinstitute/cromwell/files/2242528/mutect2-replicate-validation.zip). And here is the dependency file: [wdl-dependencies.zip](https://github.com/broadinstitute/cromwell/files/2242529/wdl-dependencies.zip). This happens in versions 30 and up. When I run this in v29, cromwell doesn't throw an error but it hangs after completing the first task. . tsato@gsa5:novaseq: java -jar $wom validate mutect2-replicate-validation.wdl; Exception in thread ""main"" java.lang.RuntimeException: This workflow contains a cyclic dependency on m2.Mutect2.filtered_vcf; 	at wdl.draft2.model.Scope.childGraphNodesSorted(Scope.scala:53); 	at wdl.draft2.model.Scope.childGraphNodesSorted$(Scope.scala:44); 	at wdl.draft2.model.WdlWorkflow.childGraphNodesSorted$lzycompute(WdlWorkflow.scala:46); 	at wdl.draft2.model.WdlWorkflow.childGraphNodesSorted(WdlWorkflow.scala:46); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:97); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:18); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph$(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$ops$$anon$1.toWomGraph(WomGraphMaker.scala:8); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomWorkflowDefinitionMaker$.toWomWorkflowDefinition(WdlDraft2WomWorkflowDefinitionMaker.scala:14); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomWorkflowDefinitionMaker$.toWomWorkflowDefinition(WdlDraft2WomWorkflowDefinitionMaker.scala:10); 	at wom.transforms.WomWorkflowDefinitionMaker$Ops.toWomWorkflowDefinition(WomWorkflowDefinitionMaker.scala:8); 	at wom.transforms.WomWorkflowDefinitionMaker$Ops.toWomWorkflowDefinition$(WomWorkflowDefinitionMaker.scala:8); 	at wom.transforms.WomWorkflowDefinitionMaker$ops$$anon$1.toWomWorkflowDefinition(WomWorkflowDefinitionMak",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502
https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502:480,Security,validat,validate,480,"I'm getting the same error with this wdl: [mutect2-replicate-validation.zip](https://github.com/broadinstitute/cromwell/files/2242528/mutect2-replicate-validation.zip). And here is the dependency file: [wdl-dependencies.zip](https://github.com/broadinstitute/cromwell/files/2242529/wdl-dependencies.zip). This happens in versions 30 and up. When I run this in v29, cromwell doesn't throw an error but it hangs after completing the first task. . tsato@gsa5:novaseq: java -jar $wom validate mutect2-replicate-validation.wdl; Exception in thread ""main"" java.lang.RuntimeException: This workflow contains a cyclic dependency on m2.Mutect2.filtered_vcf; 	at wdl.draft2.model.Scope.childGraphNodesSorted(Scope.scala:53); 	at wdl.draft2.model.Scope.childGraphNodesSorted$(Scope.scala:44); 	at wdl.draft2.model.WdlWorkflow.childGraphNodesSorted$lzycompute(WdlWorkflow.scala:46); 	at wdl.draft2.model.WdlWorkflow.childGraphNodesSorted(WdlWorkflow.scala:46); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:97); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:18); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph$(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$ops$$anon$1.toWomGraph(WomGraphMaker.scala:8); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomWorkflowDefinitionMaker$.toWomWorkflowDefinition(WdlDraft2WomWorkflowDefinitionMaker.scala:14); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomWorkflowDefinitionMaker$.toWomWorkflowDefinition(WdlDraft2WomWorkflowDefinitionMaker.scala:10); 	at wom.transforms.WomWorkflowDefinitionMaker$Ops.toWomWorkflowDefinition(WomWorkflowDefinitionMaker.scala:8); 	at wom.transforms.WomWorkflowDefinitionMaker$Ops.toWomWorkflowDefinition$(WomWorkflowDefinitionMaker.scala:8); 	at wom.transforms.WomWorkflowDefinitionMaker$ops$$anon$1.toWomWorkflowDefinition(WomWorkflowDefinitionMak",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502
https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502:507,Security,validat,validation,507,"I'm getting the same error with this wdl: [mutect2-replicate-validation.zip](https://github.com/broadinstitute/cromwell/files/2242528/mutect2-replicate-validation.zip). And here is the dependency file: [wdl-dependencies.zip](https://github.com/broadinstitute/cromwell/files/2242529/wdl-dependencies.zip). This happens in versions 30 and up. When I run this in v29, cromwell doesn't throw an error but it hangs after completing the first task. . tsato@gsa5:novaseq: java -jar $wom validate mutect2-replicate-validation.wdl; Exception in thread ""main"" java.lang.RuntimeException: This workflow contains a cyclic dependency on m2.Mutect2.filtered_vcf; 	at wdl.draft2.model.Scope.childGraphNodesSorted(Scope.scala:53); 	at wdl.draft2.model.Scope.childGraphNodesSorted$(Scope.scala:44); 	at wdl.draft2.model.WdlWorkflow.childGraphNodesSorted$lzycompute(WdlWorkflow.scala:46); 	at wdl.draft2.model.WdlWorkflow.childGraphNodesSorted(WdlWorkflow.scala:46); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:97); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:18); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph$(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$ops$$anon$1.toWomGraph(WomGraphMaker.scala:8); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomWorkflowDefinitionMaker$.toWomWorkflowDefinition(WdlDraft2WomWorkflowDefinitionMaker.scala:14); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomWorkflowDefinitionMaker$.toWomWorkflowDefinition(WdlDraft2WomWorkflowDefinitionMaker.scala:10); 	at wom.transforms.WomWorkflowDefinitionMaker$Ops.toWomWorkflowDefinition(WomWorkflowDefinitionMaker.scala:8); 	at wom.transforms.WomWorkflowDefinitionMaker$Ops.toWomWorkflowDefinition$(WomWorkflowDefinitionMaker.scala:8); 	at wom.transforms.WomWorkflowDefinitionMaker$ops$$anon$1.toWomWorkflowDefinition(WomWorkflowDefinitionMak",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502
https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502:3208,Security,validat,validation,3208,2WomCallableMaker.scala:11); 	at wom.transforms.WomCallableMaker$Ops.toWomCallable(WomCallableMaker.scala:8); 	at wom.transforms.WomCallableMaker$Ops.toWomCallable$(WomCallableMaker.scala:8); 	at wom.transforms.WomCallableMaker$ops$$anon$1.toWomCallable(WomCallableMaker.scala:8); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomCallNodeMaker$.toWomCallNode(WdlDraft2WomCallNodeMaker.scala:129); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomCallNodeMaker$.toWomCallNode(WdlDraft2WomCallNodeMaker.scala:21); 	at wom.transforms.WomCallNodeMaker$Ops.toWomCallNode(WomCallNodeMaker.scala:9); 	at wom.transforms.WomCallNodeMaker$Ops.toWomCallNode$(WomCallNodeMaker.scala:9); 	at wom.transforms.WomCallNodeMaker$ops$$anon$1.toWomCallNode(WomCallNodeMaker.scala:9); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.buildNode$1(WdlDraft2WomGraphMaker.scala:68); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.$anonfun$toWomGraph$3(WdlDraft2WomGraphMaker.scala:38); 	at common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.foldFunction$1(WdlDraft2WomGraphMaker.scala:37); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.$anonfun$toWomGraph$14(WdlDraft2WomGraphMaker.scala:98); 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:122); 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:118); 	at scala.collection.immutable.List.foldLeft(List.scala:86); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:98); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:18); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph$(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$ops$$anon$1.toWomGraph(WomGraphMaker.scala:8); 	at wdl.transforms.draft2.wdlom2wom.WdlDraf,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502
https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502:4316,Security,validat,validation,4316,om.WdlDraft2WomGraphMaker$.foldFunction$1(WdlDraft2WomGraphMaker.scala:37); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.$anonfun$toWomGraph$14(WdlDraft2WomGraphMaker.scala:98); 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:122); 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:118); 	at scala.collection.immutable.List.foldLeft(List.scala:86); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:98); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:18); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph$(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$ops$$anon$1.toWomGraph(WomGraphMaker.scala:8); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomScatterNodeMaker$.$anonfun$toWomScatterNode$9(WdlDraft2WomScatterNodeMaker.scala:55); 	at common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomScatterNodeMaker$.$anonfun$toWomScatterNode$7(WdlDraft2WomScatterNodeMaker.scala:52); 	at common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomScatterNodeMaker$.toWomScatterNode(WdlDraft2WomScatterNodeMaker.scala:51); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomScatterNodeMaker$.toWomScatterNode(WdlDraft2WomScatterNodeMaker.scala:15); 	at wom.transforms.WomScatterNodeMaker$Ops.toWomScatterNode(WomScatterNodeMaker.scala:10); 	at wom.transforms.WomScatterNodeMaker$Ops.toWomScatterNode$(WomScatterNodeMaker.scala:10); 	at wom.transforms.WomScatterNodeMaker$ops$$anon$1.toWomScatterNode(WomScatterNodeMaker.scala:10); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.buildNode$1(WdlDraft2WomGraphMaker.scala:90); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.$anonfu,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502
https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502:4541,Security,validat,validation,4541,timized.foldLeft(LinearSeqOptimized.scala:122); 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:118); 	at scala.collection.immutable.List.foldLeft(List.scala:86); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:98); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:18); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph$(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$ops$$anon$1.toWomGraph(WomGraphMaker.scala:8); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomScatterNodeMaker$.$anonfun$toWomScatterNode$9(WdlDraft2WomScatterNodeMaker.scala:55); 	at common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomScatterNodeMaker$.$anonfun$toWomScatterNode$7(WdlDraft2WomScatterNodeMaker.scala:52); 	at common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomScatterNodeMaker$.toWomScatterNode(WdlDraft2WomScatterNodeMaker.scala:51); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomScatterNodeMaker$.toWomScatterNode(WdlDraft2WomScatterNodeMaker.scala:15); 	at wom.transforms.WomScatterNodeMaker$Ops.toWomScatterNode(WomScatterNodeMaker.scala:10); 	at wom.transforms.WomScatterNodeMaker$Ops.toWomScatterNode$(WomScatterNodeMaker.scala:10); 	at wom.transforms.WomScatterNodeMaker$ops$$anon$1.toWomScatterNode(WomScatterNodeMaker.scala:10); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.buildNode$1(WdlDraft2WomGraphMaker.scala:90); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.$anonfun$toWomGraph$3(WdlDraft2WomGraphMaker.scala:38); 	at common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.foldFunction$1(WdlDraft2W,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502
https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502:5382,Security,validat,validation,5382,ala:27); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomScatterNodeMaker$.$anonfun$toWomScatterNode$7(WdlDraft2WomScatterNodeMaker.scala:52); 	at common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomScatterNodeMaker$.toWomScatterNode(WdlDraft2WomScatterNodeMaker.scala:51); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomScatterNodeMaker$.toWomScatterNode(WdlDraft2WomScatterNodeMaker.scala:15); 	at wom.transforms.WomScatterNodeMaker$Ops.toWomScatterNode(WomScatterNodeMaker.scala:10); 	at wom.transforms.WomScatterNodeMaker$Ops.toWomScatterNode$(WomScatterNodeMaker.scala:10); 	at wom.transforms.WomScatterNodeMaker$ops$$anon$1.toWomScatterNode(WomScatterNodeMaker.scala:10); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.buildNode$1(WdlDraft2WomGraphMaker.scala:90); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.$anonfun$toWomGraph$3(WdlDraft2WomGraphMaker.scala:38); 	at common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.foldFunction$1(WdlDraft2WomGraphMaker.scala:37); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.$anonfun$toWomGraph$14(WdlDraft2WomGraphMaker.scala:98); 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:122); 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:118); 	at scala.collection.immutable.List.foldLeft(List.scala:86); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:98); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:18); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph$(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$ops$$anon$1.toWomGraph(WomGraphMaker.scala:8); 	at wdl.transforms.draft2.wdlom2wom.WdlDraf,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502
https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502:8999,Security,validat,validate,8999,; 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomBundleMakers$$anon$1.toWomBundle(WdlDraft2WomBundleMakers.scala:19); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomBundleMakers$$anon$1.toWomBundle(WdlDraft2WomBundleMakers.scala:17); 	at wom.transforms.WomBundleMaker$Ops.toWomBundle(WomExecutableMaker.scala:16); 	at wom.transforms.WomBundleMaker$Ops.toWomBundle$(WomExecutableMaker.scala:16); 	at wom.transforms.WomBundleMaker$ops$$anon$2.toWomBundle(WomExecutableMaker.scala:16); 	at languages.wdl.draft2.WdlDraft2LanguageFactory.$anonfun$getWomBundle$3(WdlDraft2LanguageFactory.scala:120); 	at scala.util.Either.flatMap(Either.scala:338); 	at languages.wdl.draft2.WdlDraft2LanguageFactory.$anonfun$getWomBundle$1(WdlDraft2LanguageFactory.scala:119); 	at scala.util.Either.flatMap(Either.scala:338); 	at languages.wdl.draft2.WdlDraft2LanguageFactory.getWomBundle(WdlDraft2LanguageFactory.scala:118); 	at womtool.input.WomGraphMaker$.$anonfun$getBundleAndFactory$1(WomGraphMaker.scala:49); 	at scala.util.Either.flatMap(Either.scala:338); 	at womtool.input.WomGraphMaker$.getBundleAndFactory(WomGraphMaker.scala:40); 	at womtool.input.WomGraphMaker$.getBundle(WomGraphMaker.scala:22); 	at womtool.validate.Validate$.validate(Validate.scala:14); 	at womtool.WomtoolMain$.dispatchCommand(WomtoolMain.scala:47); 	at womtool.WomtoolMain$.runWomtool(WomtoolMain.scala:134); 	at womtool.WomtoolMain$.delayedEndpoint$womtool$WomtoolMain$1(WomtoolMain.scala:139); 	at womtool.WomtoolMain$delayedInit$body.apply(WomtoolMain.scala:21); 	at scala.Function0.apply$mcV$sp(Function0.scala:34); 	at scala.Function0.apply$mcV$sp$(Function0.scala:34); 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12); 	at scala.App.$anonfun$main$1$adapted(App.scala:76); 	at scala.collection.immutable.List.foreach(List.scala:389); 	at scala.App.main(App.scala:76); 	at scala.App.main$(App.scala:74); 	at womtool.WomtoolMain$.main(WomtoolMain.scala:21); 	at womtool.WomtoolMain.main(WomtoolMain.scala),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502
https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502:9008,Security,Validat,Validate,9008,; 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomBundleMakers$$anon$1.toWomBundle(WdlDraft2WomBundleMakers.scala:19); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomBundleMakers$$anon$1.toWomBundle(WdlDraft2WomBundleMakers.scala:17); 	at wom.transforms.WomBundleMaker$Ops.toWomBundle(WomExecutableMaker.scala:16); 	at wom.transforms.WomBundleMaker$Ops.toWomBundle$(WomExecutableMaker.scala:16); 	at wom.transforms.WomBundleMaker$ops$$anon$2.toWomBundle(WomExecutableMaker.scala:16); 	at languages.wdl.draft2.WdlDraft2LanguageFactory.$anonfun$getWomBundle$3(WdlDraft2LanguageFactory.scala:120); 	at scala.util.Either.flatMap(Either.scala:338); 	at languages.wdl.draft2.WdlDraft2LanguageFactory.$anonfun$getWomBundle$1(WdlDraft2LanguageFactory.scala:119); 	at scala.util.Either.flatMap(Either.scala:338); 	at languages.wdl.draft2.WdlDraft2LanguageFactory.getWomBundle(WdlDraft2LanguageFactory.scala:118); 	at womtool.input.WomGraphMaker$.$anonfun$getBundleAndFactory$1(WomGraphMaker.scala:49); 	at scala.util.Either.flatMap(Either.scala:338); 	at womtool.input.WomGraphMaker$.getBundleAndFactory(WomGraphMaker.scala:40); 	at womtool.input.WomGraphMaker$.getBundle(WomGraphMaker.scala:22); 	at womtool.validate.Validate$.validate(Validate.scala:14); 	at womtool.WomtoolMain$.dispatchCommand(WomtoolMain.scala:47); 	at womtool.WomtoolMain$.runWomtool(WomtoolMain.scala:134); 	at womtool.WomtoolMain$.delayedEndpoint$womtool$WomtoolMain$1(WomtoolMain.scala:139); 	at womtool.WomtoolMain$delayedInit$body.apply(WomtoolMain.scala:21); 	at scala.Function0.apply$mcV$sp(Function0.scala:34); 	at scala.Function0.apply$mcV$sp$(Function0.scala:34); 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12); 	at scala.App.$anonfun$main$1$adapted(App.scala:76); 	at scala.collection.immutable.List.foreach(List.scala:389); 	at scala.App.main(App.scala:76); 	at scala.App.main$(App.scala:74); 	at womtool.WomtoolMain$.main(WomtoolMain.scala:21); 	at womtool.WomtoolMain.main(WomtoolMain.scala),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502
https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502:9018,Security,validat,validate,9018,; 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomBundleMakers$$anon$1.toWomBundle(WdlDraft2WomBundleMakers.scala:19); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomBundleMakers$$anon$1.toWomBundle(WdlDraft2WomBundleMakers.scala:17); 	at wom.transforms.WomBundleMaker$Ops.toWomBundle(WomExecutableMaker.scala:16); 	at wom.transforms.WomBundleMaker$Ops.toWomBundle$(WomExecutableMaker.scala:16); 	at wom.transforms.WomBundleMaker$ops$$anon$2.toWomBundle(WomExecutableMaker.scala:16); 	at languages.wdl.draft2.WdlDraft2LanguageFactory.$anonfun$getWomBundle$3(WdlDraft2LanguageFactory.scala:120); 	at scala.util.Either.flatMap(Either.scala:338); 	at languages.wdl.draft2.WdlDraft2LanguageFactory.$anonfun$getWomBundle$1(WdlDraft2LanguageFactory.scala:119); 	at scala.util.Either.flatMap(Either.scala:338); 	at languages.wdl.draft2.WdlDraft2LanguageFactory.getWomBundle(WdlDraft2LanguageFactory.scala:118); 	at womtool.input.WomGraphMaker$.$anonfun$getBundleAndFactory$1(WomGraphMaker.scala:49); 	at scala.util.Either.flatMap(Either.scala:338); 	at womtool.input.WomGraphMaker$.getBundleAndFactory(WomGraphMaker.scala:40); 	at womtool.input.WomGraphMaker$.getBundle(WomGraphMaker.scala:22); 	at womtool.validate.Validate$.validate(Validate.scala:14); 	at womtool.WomtoolMain$.dispatchCommand(WomtoolMain.scala:47); 	at womtool.WomtoolMain$.runWomtool(WomtoolMain.scala:134); 	at womtool.WomtoolMain$.delayedEndpoint$womtool$WomtoolMain$1(WomtoolMain.scala:139); 	at womtool.WomtoolMain$delayedInit$body.apply(WomtoolMain.scala:21); 	at scala.Function0.apply$mcV$sp(Function0.scala:34); 	at scala.Function0.apply$mcV$sp$(Function0.scala:34); 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12); 	at scala.App.$anonfun$main$1$adapted(App.scala:76); 	at scala.collection.immutable.List.foreach(List.scala:389); 	at scala.App.main(App.scala:76); 	at scala.App.main$(App.scala:74); 	at womtool.WomtoolMain$.main(WomtoolMain.scala:21); 	at womtool.WomtoolMain.main(WomtoolMain.scala),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502
https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502:9027,Security,Validat,Validate,9027,; 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomBundleMakers$$anon$1.toWomBundle(WdlDraft2WomBundleMakers.scala:19); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomBundleMakers$$anon$1.toWomBundle(WdlDraft2WomBundleMakers.scala:17); 	at wom.transforms.WomBundleMaker$Ops.toWomBundle(WomExecutableMaker.scala:16); 	at wom.transforms.WomBundleMaker$Ops.toWomBundle$(WomExecutableMaker.scala:16); 	at wom.transforms.WomBundleMaker$ops$$anon$2.toWomBundle(WomExecutableMaker.scala:16); 	at languages.wdl.draft2.WdlDraft2LanguageFactory.$anonfun$getWomBundle$3(WdlDraft2LanguageFactory.scala:120); 	at scala.util.Either.flatMap(Either.scala:338); 	at languages.wdl.draft2.WdlDraft2LanguageFactory.$anonfun$getWomBundle$1(WdlDraft2LanguageFactory.scala:119); 	at scala.util.Either.flatMap(Either.scala:338); 	at languages.wdl.draft2.WdlDraft2LanguageFactory.getWomBundle(WdlDraft2LanguageFactory.scala:118); 	at womtool.input.WomGraphMaker$.$anonfun$getBundleAndFactory$1(WomGraphMaker.scala:49); 	at scala.util.Either.flatMap(Either.scala:338); 	at womtool.input.WomGraphMaker$.getBundleAndFactory(WomGraphMaker.scala:40); 	at womtool.input.WomGraphMaker$.getBundle(WomGraphMaker.scala:22); 	at womtool.validate.Validate$.validate(Validate.scala:14); 	at womtool.WomtoolMain$.dispatchCommand(WomtoolMain.scala:47); 	at womtool.WomtoolMain$.runWomtool(WomtoolMain.scala:134); 	at womtool.WomtoolMain$.delayedEndpoint$womtool$WomtoolMain$1(WomtoolMain.scala:139); 	at womtool.WomtoolMain$delayedInit$body.apply(WomtoolMain.scala:21); 	at scala.Function0.apply$mcV$sp(Function0.scala:34); 	at scala.Function0.apply$mcV$sp$(Function0.scala:34); 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12); 	at scala.App.$anonfun$main$1$adapted(App.scala:76); 	at scala.collection.immutable.List.foreach(List.scala:389); 	at scala.App.main(App.scala:76); 	at scala.App.main$(App.scala:74); 	at womtool.WomtoolMain$.main(WomtoolMain.scala:21); 	at womtool.WomtoolMain.main(WomtoolMain.scala),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502
https://github.com/broadinstitute/cromwell/pull/3149#issuecomment-358985345:59,Testability,test,tests,59,"@mcovarr and thanks for pointing these out, I'll try those tests locally and see if I can suss out any other issues w/ optionals.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3149#issuecomment-358985345
https://github.com/broadinstitute/cromwell/pull/3149#issuecomment-359001636:12,Testability,test,test,12,Conformance test #5 is an optional input provided and should be passing. Fixing.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3149#issuecomment-359001636
https://github.com/broadinstitute/cromwell/issues/3151#issuecomment-359951122:116,Usability,simpl,simpleton,116,"I'll note that WDL only supports primitive keys. If CWL is the same, this problem might be a type fix rather than a simpleton fix.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3151#issuecomment-359951122
https://github.com/broadinstitute/cromwell/pull/3152#issuecomment-358426964:82,Testability,test,test,82,"If this does what I think it does, can we now add a WDL `""works for empty globs""` test?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3152#issuecomment-358426964
https://github.com/broadinstitute/cromwell/issues/3156#issuecomment-358515823:191,Deployability,integrat,integration,191,"I just want to point out that this used to work in Cromwell 29, so some sort of regression has happened such that sub workflows aren't working anymore. I'm not sure what kind of sub workflow integration tests you guys have, but it looks like they aren't comprehensive enough. Feel free to add this one to your test suite (it's actually not a super complicated sub workflow). . This is pretty important to some of the work we're doing with Gaddy to get the somatic genome pipeline ready (we can't run the samples for him). And the ultimate goal of this project is to bring more users to FireCloud...",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3156#issuecomment-358515823
https://github.com/broadinstitute/cromwell/issues/3156#issuecomment-358515823:471,Deployability,pipeline,pipeline,471,"I just want to point out that this used to work in Cromwell 29, so some sort of regression has happened such that sub workflows aren't working anymore. I'm not sure what kind of sub workflow integration tests you guys have, but it looks like they aren't comprehensive enough. Feel free to add this one to your test suite (it's actually not a super complicated sub workflow). . This is pretty important to some of the work we're doing with Gaddy to get the somatic genome pipeline ready (we can't run the samples for him). And the ultimate goal of this project is to bring more users to FireCloud...",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3156#issuecomment-358515823
https://github.com/broadinstitute/cromwell/issues/3156#issuecomment-358515823:191,Integrability,integrat,integration,191,"I just want to point out that this used to work in Cromwell 29, so some sort of regression has happened such that sub workflows aren't working anymore. I'm not sure what kind of sub workflow integration tests you guys have, but it looks like they aren't comprehensive enough. Feel free to add this one to your test suite (it's actually not a super complicated sub workflow). . This is pretty important to some of the work we're doing with Gaddy to get the somatic genome pipeline ready (we can't run the samples for him). And the ultimate goal of this project is to bring more users to FireCloud...",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3156#issuecomment-358515823
https://github.com/broadinstitute/cromwell/issues/3156#issuecomment-358515823:203,Testability,test,tests,203,"I just want to point out that this used to work in Cromwell 29, so some sort of regression has happened such that sub workflows aren't working anymore. I'm not sure what kind of sub workflow integration tests you guys have, but it looks like they aren't comprehensive enough. Feel free to add this one to your test suite (it's actually not a super complicated sub workflow). . This is pretty important to some of the work we're doing with Gaddy to get the somatic genome pipeline ready (we can't run the samples for him). And the ultimate goal of this project is to bring more users to FireCloud...",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3156#issuecomment-358515823
https://github.com/broadinstitute/cromwell/issues/3156#issuecomment-358515823:310,Testability,test,test,310,"I just want to point out that this used to work in Cromwell 29, so some sort of regression has happened such that sub workflows aren't working anymore. I'm not sure what kind of sub workflow integration tests you guys have, but it looks like they aren't comprehensive enough. Feel free to add this one to your test suite (it's actually not a super complicated sub workflow). . This is pretty important to some of the work we're doing with Gaddy to get the somatic genome pipeline ready (we can't run the samples for him). And the ultimate goal of this project is to bring more users to FireCloud...",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3156#issuecomment-358515823
https://github.com/broadinstitute/cromwell/issues/3156#issuecomment-358518084:31,Availability,down,down,31,"We are trying to be 100% heads down on cwl work for probably another couple of weeks. If this is a raging fire we can divert attention from that but that not without cost towards that and the ripple effect on other goals. So is this ‚Äúthis sucks please fix soon‚Äù or ‚ÄúOMG we‚Äôre blocked, at the risk of cheesing off other users this needs to be fixed right this second‚Äù",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3156#issuecomment-358518084
https://github.com/broadinstitute/cromwell/issues/3156#issuecomment-358518084:292,Safety,risk,risk,292,"We are trying to be 100% heads down on cwl work for probably another couple of weeks. If this is a raging fire we can divert attention from that but that not without cost towards that and the ripple effect on other goals. So is this ‚Äúthis sucks please fix soon‚Äù or ‚ÄúOMG we‚Äôre blocked, at the risk of cheesing off other users this needs to be fixed right this second‚Äù",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3156#issuecomment-358518084
https://github.com/broadinstitute/cromwell/issues/3156#issuecomment-358537997:168,Modifiability,variab,variable,168,"I may have found a quick fix actually (will confirm in the morning).; In the meantime I think you could work around it by re-declaring `GetBwaVersion.version` as a new variable inside the scatter and using that instead of `GetBwaVersion.version` directly:. ```; call GetBwaVersion. # Align flowcell-level unmapped input bams in parallel; scatter (unmapped_bam in flowcell_unmapped_bams) {; String bwaVersion = GetBwaVersion.version; ; ... if (unmapped_bam_size > cutoff_for_large_rg_in_gb) {; # Split bam into multiple smaller bams,; # map reads to reference and recombine into one bam; call splitRG.SplitLargeRG as SplitRG {; input:; input_bam = unmapped_bam,; bwa_commandline = bwa_commandline,; bwa_version = bwaVersion,; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3156#issuecomment-358537997
https://github.com/broadinstitute/cromwell/issues/3156#issuecomment-358618004:26,Modifiability,variab,variable,26,I tried the local version variable and it doesn't seem to work but I could be doing it wrong. We can talk faces real quick to make sure I at least tried it correctly.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3156#issuecomment-358618004
https://github.com/broadinstitute/cromwell/issues/3156#issuecomment-358657812:155,Modifiability,variab,variable,155,"Hmm you're right, I had simplified the workflow too much to reproduce the blocking but going back to your workflow I still can get it stuck with the local variable.; Looking into it now.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3156#issuecomment-358657812
https://github.com/broadinstitute/cromwell/issues/3156#issuecomment-358657812:24,Usability,simpl,simplified,24,"Hmm you're right, I had simplified the workflow too much to reproduce the blocking but going back to your workflow I still can get it stuck with the local variable.; Looking into it now.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3156#issuecomment-358657812
https://github.com/broadinstitute/cromwell/issues/3156#issuecomment-358672373:58,Modifiability,variab,variables,58,"@jsotobroad ; Ok so I think you need to take all workflow variables that use some sort of expression and redeclare them inside the scatter. You actually don't need to use them, just redeclaring them should be enough. ```; workflow {; Float myVar = size(...); scatter(...) {; Float myVar_redeclared = myVar; if(...) {; call myCall { input: i = myVar }; }; }; }; ```. From what I can see in the workflow, those variables would be `additional_disk`, `recalibrated_bam_basename`, `ref_size`, `bwa_ref_size` and `dbsnp_size`.; This is not related to subworkflows AFAICT but rather `if`s in `scatter`s referencing variables with expressions declared outside of the scatter. Again this is a workaround, I'm trying to find the right way to fix this.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3156#issuecomment-358672373
https://github.com/broadinstitute/cromwell/issues/3156#issuecomment-358672373:409,Modifiability,variab,variables,409,"@jsotobroad ; Ok so I think you need to take all workflow variables that use some sort of expression and redeclare them inside the scatter. You actually don't need to use them, just redeclaring them should be enough. ```; workflow {; Float myVar = size(...); scatter(...) {; Float myVar_redeclared = myVar; if(...) {; call myCall { input: i = myVar }; }; }; }; ```. From what I can see in the workflow, those variables would be `additional_disk`, `recalibrated_bam_basename`, `ref_size`, `bwa_ref_size` and `dbsnp_size`.; This is not related to subworkflows AFAICT but rather `if`s in `scatter`s referencing variables with expressions declared outside of the scatter. Again this is a workaround, I'm trying to find the right way to fix this.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3156#issuecomment-358672373
https://github.com/broadinstitute/cromwell/issues/3156#issuecomment-358672373:608,Modifiability,variab,variables,608,"@jsotobroad ; Ok so I think you need to take all workflow variables that use some sort of expression and redeclare them inside the scatter. You actually don't need to use them, just redeclaring them should be enough. ```; workflow {; Float myVar = size(...); scatter(...) {; Float myVar_redeclared = myVar; if(...) {; call myCall { input: i = myVar }; }; }; }; ```. From what I can see in the workflow, those variables would be `additional_disk`, `recalibrated_bam_basename`, `ref_size`, `bwa_ref_size` and `dbsnp_size`.; This is not related to subworkflows AFAICT but rather `if`s in `scatter`s referencing variables with expressions declared outside of the scatter. Again this is a workaround, I'm trying to find the right way to fix this.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3156#issuecomment-358672373
https://github.com/broadinstitute/cromwell/issues/3161#issuecomment-358781998:41,Availability,failure,failures,41,"I remember we added this for certain JES failures so the backend plumbing might already be there (although IIRC we called it ""unexpected failure"" and it was hard coded to 3)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3161#issuecomment-358781998
https://github.com/broadinstitute/cromwell/issues/3161#issuecomment-358781998:137,Availability,failure,failure,137,"I remember we added this for certain JES failures so the backend plumbing might already be there (although IIRC we called it ""unexpected failure"" and it was hard coded to 3)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3161#issuecomment-358781998
https://github.com/broadinstitute/cromwell/issues/3161#issuecomment-358986427:42,Availability,failure,failures,42,"**Update: Non-additive retry counts**. If failures due to preemption can be clearly distinguished from failures due to other causes, I would prefer the failed_task_retries count to be independent of the preemptible count, rather than additive. For example, with failed_task_retries: 2 and preemptible: 2, I would expect the following behavior:; - try 1: preemptible machine, got preempted; - try 2: preemptible machine, other error (not preemption); - try 3: non-preemptible machine, error; - try 4: non-preemptible machine, error; - task fails. We have only retried 3 times here, because one of the non-preemption retries was ""used up"" when try 2 failed. (With additive behavior, we would have retried 4 times.). This behavior would allow users to independently set the retries due to preemption from those due to other causes, to more finely tune the desired behavior. However, if this can't be accommodated, this feature would still be very valuable with the additive behavior.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3161#issuecomment-358986427
https://github.com/broadinstitute/cromwell/issues/3161#issuecomment-358986427:103,Availability,failure,failures,103,"**Update: Non-additive retry counts**. If failures due to preemption can be clearly distinguished from failures due to other causes, I would prefer the failed_task_retries count to be independent of the preemptible count, rather than additive. For example, with failed_task_retries: 2 and preemptible: 2, I would expect the following behavior:; - try 1: preemptible machine, got preempted; - try 2: preemptible machine, other error (not preemption); - try 3: non-preemptible machine, error; - try 4: non-preemptible machine, error; - task fails. We have only retried 3 times here, because one of the non-preemption retries was ""used up"" when try 2 failed. (With additive behavior, we would have retried 4 times.). This behavior would allow users to independently set the retries due to preemption from those due to other causes, to more finely tune the desired behavior. However, if this can't be accommodated, this feature would still be very valuable with the additive behavior.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3161#issuecomment-358986427
https://github.com/broadinstitute/cromwell/issues/3161#issuecomment-358986427:426,Availability,error,error,426,"**Update: Non-additive retry counts**. If failures due to preemption can be clearly distinguished from failures due to other causes, I would prefer the failed_task_retries count to be independent of the preemptible count, rather than additive. For example, with failed_task_retries: 2 and preemptible: 2, I would expect the following behavior:; - try 1: preemptible machine, got preempted; - try 2: preemptible machine, other error (not preemption); - try 3: non-preemptible machine, error; - try 4: non-preemptible machine, error; - task fails. We have only retried 3 times here, because one of the non-preemption retries was ""used up"" when try 2 failed. (With additive behavior, we would have retried 4 times.). This behavior would allow users to independently set the retries due to preemption from those due to other causes, to more finely tune the desired behavior. However, if this can't be accommodated, this feature would still be very valuable with the additive behavior.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3161#issuecomment-358986427
https://github.com/broadinstitute/cromwell/issues/3161#issuecomment-358986427:484,Availability,error,error,484,"**Update: Non-additive retry counts**. If failures due to preemption can be clearly distinguished from failures due to other causes, I would prefer the failed_task_retries count to be independent of the preemptible count, rather than additive. For example, with failed_task_retries: 2 and preemptible: 2, I would expect the following behavior:; - try 1: preemptible machine, got preempted; - try 2: preemptible machine, other error (not preemption); - try 3: non-preemptible machine, error; - try 4: non-preemptible machine, error; - task fails. We have only retried 3 times here, because one of the non-preemption retries was ""used up"" when try 2 failed. (With additive behavior, we would have retried 4 times.). This behavior would allow users to independently set the retries due to preemption from those due to other causes, to more finely tune the desired behavior. However, if this can't be accommodated, this feature would still be very valuable with the additive behavior.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3161#issuecomment-358986427
https://github.com/broadinstitute/cromwell/issues/3161#issuecomment-358986427:525,Availability,error,error,525,"**Update: Non-additive retry counts**. If failures due to preemption can be clearly distinguished from failures due to other causes, I would prefer the failed_task_retries count to be independent of the preemptible count, rather than additive. For example, with failed_task_retries: 2 and preemptible: 2, I would expect the following behavior:; - try 1: preemptible machine, got preempted; - try 2: preemptible machine, other error (not preemption); - try 3: non-preemptible machine, error; - try 4: non-preemptible machine, error; - task fails. We have only retried 3 times here, because one of the non-preemption retries was ""used up"" when try 2 failed. (With additive behavior, we would have retried 4 times.). This behavior would allow users to independently set the retries due to preemption from those due to other causes, to more finely tune the desired behavior. However, if this can't be accommodated, this feature would still be very valuable with the additive behavior.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3161#issuecomment-358986427
https://github.com/broadinstitute/cromwell/issues/3161#issuecomment-358986427:2,Deployability,Update,Update,2,"**Update: Non-additive retry counts**. If failures due to preemption can be clearly distinguished from failures due to other causes, I would prefer the failed_task_retries count to be independent of the preemptible count, rather than additive. For example, with failed_task_retries: 2 and preemptible: 2, I would expect the following behavior:; - try 1: preemptible machine, got preempted; - try 2: preemptible machine, other error (not preemption); - try 3: non-preemptible machine, error; - try 4: non-preemptible machine, error; - task fails. We have only retried 3 times here, because one of the non-preemption retries was ""used up"" when try 2 failed. (With additive behavior, we would have retried 4 times.). This behavior would allow users to independently set the retries due to preemption from those due to other causes, to more finely tune the desired behavior. However, if this can't be accommodated, this feature would still be very valuable with the additive behavior.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3161#issuecomment-358986427
https://github.com/broadinstitute/cromwell/issues/3161#issuecomment-358986427:844,Performance,tune,tune,844,"**Update: Non-additive retry counts**. If failures due to preemption can be clearly distinguished from failures due to other causes, I would prefer the failed_task_retries count to be independent of the preemptible count, rather than additive. For example, with failed_task_retries: 2 and preemptible: 2, I would expect the following behavior:; - try 1: preemptible machine, got preempted; - try 2: preemptible machine, other error (not preemption); - try 3: non-preemptible machine, error; - try 4: non-preemptible machine, error; - task fails. We have only retried 3 times here, because one of the non-preemption retries was ""used up"" when try 2 failed. (With additive behavior, we would have retried 4 times.). This behavior would allow users to independently set the retries due to preemption from those due to other causes, to more finely tune the desired behavior. However, if this can't be accommodated, this feature would still be very valuable with the additive behavior.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3161#issuecomment-358986427
https://github.com/broadinstitute/cromwell/issues/3161#issuecomment-358986427:76,Usability,clear,clearly,76,"**Update: Non-additive retry counts**. If failures due to preemption can be clearly distinguished from failures due to other causes, I would prefer the failed_task_retries count to be independent of the preemptible count, rather than additive. For example, with failed_task_retries: 2 and preemptible: 2, I would expect the following behavior:; - try 1: preemptible machine, got preempted; - try 2: preemptible machine, other error (not preemption); - try 3: non-preemptible machine, error; - try 4: non-preemptible machine, error; - task fails. We have only retried 3 times here, because one of the non-preemption retries was ""used up"" when try 2 failed. (With additive behavior, we would have retried 4 times.). This behavior would allow users to independently set the retries due to preemption from those due to other causes, to more finely tune the desired behavior. However, if this can't be accommodated, this feature would still be very valuable with the additive behavior.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3161#issuecomment-358986427
https://github.com/broadinstitute/cromwell/issues/3161#issuecomment-379321032:149,Modifiability,config,configured,149,@dshiga: @ruchim talked to myself and @samanehsan today about whether it would be ok for this to be implemented as a runtime attribute that could be configured per task and we thought that would be ok. It is the way they prefer to implement it.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3161#issuecomment-379321032
https://github.com/broadinstitute/cromwell/issues/3161#issuecomment-391433515:239,Availability,alive,alive,239,"Any thoughts on how a general task retry policy may interact with [#1499](https://github.com/broadinstitute/cromwell/issues/1499) when the job scheduler (or user) kills a job on sge and the server is restarted?. I'm envisioning the ""check-alive"" result showing no job on sge invoking one of the task retries that a user specifies (whereas currently it'd be marked as failed). Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3161#issuecomment-391433515
https://github.com/broadinstitute/cromwell/issues/3161#issuecomment-391433515:143,Energy Efficiency,schedul,scheduler,143,"Any thoughts on how a general task retry policy may interact with [#1499](https://github.com/broadinstitute/cromwell/issues/1499) when the job scheduler (or user) kills a job on sge and the server is restarted?. I'm envisioning the ""check-alive"" result showing no job on sge invoking one of the task retries that a user specifies (whereas currently it'd be marked as failed). Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3161#issuecomment-391433515
https://github.com/broadinstitute/cromwell/pull/3162#issuecomment-358785007:203,Availability,down,down,203,"@Horneth I don't think so, although I'm pretty sure what would work would be to add a case similar to the one on 481, but catching `UnsuccessfulRunStatus` w/ the isPreemptible if. I didn't originally go down that road because at the time I thought it wouldn't work, but I misunderstood how things were working and I'd forgotten about it by the end. I'm going to give that a whirl as it'd be a lot easier than digging into the op metadata",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3162#issuecomment-358785007
https://github.com/broadinstitute/cromwell/pull/3162#issuecomment-358788264:147,Availability,error,errors,147,"@Horneth although we're already mapping something else to preemptible in the spot where i'm doing it now, so this would mean we're mapping ""other"" errors to preemptible in 2 different spots",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3162#issuecomment-358788264
https://github.com/broadinstitute/cromwell/pull/3162#issuecomment-358791501:72,Testability,test,test,72,"Thinking about this I'm more and more confused why none of the existing test cases are now triggering as ""yes we should try to run this again""",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3162#issuecomment-358791501
https://github.com/broadinstitute/cromwell/issues/3166#issuecomment-359100108:35,Testability,test,tests,35,This covers (at least) conformance tests 13 and 18.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3166#issuecomment-359100108
https://github.com/broadinstitute/cromwell/pull/3171#issuecomment-359483234:54,Testability,test,tests,54,@cjllanwarne I removed the `path` prefixing and added tests for `location` in `default`.; Also added the file prefixing to CWL workflows (was only for input files before). If @danbills's PR on cwltool gets merged and we can salad CWL workflows with gcs path it should unlock at least another test I believe.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3171#issuecomment-359483234
https://github.com/broadinstitute/cromwell/pull/3171#issuecomment-359483234:292,Testability,test,test,292,@cjllanwarne I removed the `path` prefixing and added tests for `location` in `default`.; Also added the file prefixing to CWL workflows (was only for input files before). If @danbills's PR on cwltool gets merged and we can salad CWL workflows with gcs path it should unlock at least another test I believe.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3171#issuecomment-359483234
https://github.com/broadinstitute/cromwell/issues/3176#issuecomment-359898327:248,Modifiability,variab,variable,248,"Thanks @antonkulaga - this is weird, it looks like the validator is incorrectly confusing the workflow output `out` and the `task get_sample` output `out`. I'm not 100% sure why, but until we fix this if you rename the `get_sample` temporary `out` variable it seems to work, eg:; ```; Array[Array[String]] out2 = read_tsv(""output.tsv""); File reads_1 = out2[0][0]; File reads_2 = out2[0][1]; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3176#issuecomment-359898327
https://github.com/broadinstitute/cromwell/issues/3176#issuecomment-359898327:55,Security,validat,validator,55,"Thanks @antonkulaga - this is weird, it looks like the validator is incorrectly confusing the workflow output `out` and the `task get_sample` output `out`. I'm not 100% sure why, but until we fix this if you rename the `get_sample` temporary `out` variable it seems to work, eg:; ```; Array[Array[String]] out2 = read_tsv(""output.tsv""); File reads_1 = out2[0][0]; File reads_2 = out2[0][1]; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3176#issuecomment-359898327
https://github.com/broadinstitute/cromwell/pull/3181#issuecomment-360556825:179,Testability,test,tests,179,"@mcovarr @geoffjentry . The line was making `object_lookup` and `member_lookup` pass. See the new way of making them pass in commit ""Fixup member_access and object_access centaur tests"". This new way of making the tests work feels much correct-er to me and removes that special case that (a) didn't make sense prima-facie and (b) was causing problems elsewhere.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3181#issuecomment-360556825
https://github.com/broadinstitute/cromwell/pull/3181#issuecomment-360556825:214,Testability,test,tests,214,"@mcovarr @geoffjentry . The line was making `object_lookup` and `member_lookup` pass. See the new way of making them pass in commit ""Fixup member_access and object_access centaur tests"". This new way of making the tests work feels much correct-er to me and removes that special case that (a) didn't make sense prima-facie and (b) was causing problems elsewhere.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3181#issuecomment-360556825
https://github.com/broadinstitute/cromwell/pull/3182#issuecomment-360157283:141,Availability,failure,failure,141,I heard chatter about a 30.2 release ...is there any chance this change can make it in that release? It's mostly for FC users as the current failure logs are sent to the server logs and basically the user never sees call caching fail even though the job succeeds.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3182#issuecomment-360157283
https://github.com/broadinstitute/cromwell/pull/3182#issuecomment-360157283:29,Deployability,release,release,29,I heard chatter about a 30.2 release ...is there any chance this change can make it in that release? It's mostly for FC users as the current failure logs are sent to the server logs and basically the user never sees call caching fail even though the job succeeds.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3182#issuecomment-360157283
https://github.com/broadinstitute/cromwell/pull/3182#issuecomment-360157283:92,Deployability,release,release,92,I heard chatter about a 30.2 release ...is there any chance this change can make it in that release? It's mostly for FC users as the current failure logs are sent to the server logs and basically the user never sees call caching fail even though the job succeeds.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3182#issuecomment-360157283
https://github.com/broadinstitute/cromwell/pull/3182#issuecomment-360157283:149,Testability,log,logs,149,I heard chatter about a 30.2 release ...is there any chance this change can make it in that release? It's mostly for FC users as the current failure logs are sent to the server logs and basically the user never sees call caching fail even though the job succeeds.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3182#issuecomment-360157283
https://github.com/broadinstitute/cromwell/pull/3182#issuecomment-360157283:177,Testability,log,logs,177,I heard chatter about a 30.2 release ...is there any chance this change can make it in that release? It's mostly for FC users as the current failure logs are sent to the server logs and basically the user never sees call caching fail even though the job succeeds.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3182#issuecomment-360157283
https://github.com/broadinstitute/cromwell/issues/3183#issuecomment-402844677:17,Deployability,release,released,17,This was already released in Cromwell 32,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3183#issuecomment-402844677
https://github.com/broadinstitute/cromwell/issues/3183#issuecomment-662042665:827,Energy Efficiency,efficient,efficient,827,"I want to comment on the fact that there are hidden dangers in using the function `Float size(Array[File])` as shown in a Terra community forum [post](https://support.terra.bio/hc/en-us/community/posts/360071583412-PreparingJob-state-consumes-most-of-a-task-running-time-how-to-avoid-). For large arrays, this can cause tasks to take forever to start in Google Cloud. Although this is not a WDL specification issue, developers need somehow to be made aware of this, especially in cases where the array contains files that are known in advance to have similar sizes, in which case the following code:; ```; input {; Array[File]+ files; }; Float arr_size = size(files, ""GiB""); ```; Could be replaced by:; ```; input {; Array[File]+ files; }; Float arr_size = length(files) * size(files[0], ""GiB""); ```; And be significantly more efficient.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3183#issuecomment-662042665
https://github.com/broadinstitute/cromwell/issues/3183#issuecomment-662042665:278,Safety,avoid,avoid,278,"I want to comment on the fact that there are hidden dangers in using the function `Float size(Array[File])` as shown in a Terra community forum [post](https://support.terra.bio/hc/en-us/community/posts/360071583412-PreparingJob-state-consumes-most-of-a-task-running-time-how-to-avoid-). For large arrays, this can cause tasks to take forever to start in Google Cloud. Although this is not a WDL specification issue, developers need somehow to be made aware of this, especially in cases where the array contains files that are known in advance to have similar sizes, in which case the following code:; ```; input {; Array[File]+ files; }; Float arr_size = size(files, ""GiB""); ```; Could be replaced by:; ```; input {; Array[File]+ files; }; Float arr_size = length(files) * size(files[0], ""GiB""); ```; And be significantly more efficient.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3183#issuecomment-662042665
https://github.com/broadinstitute/cromwell/issues/3186#issuecomment-383250045:210,Testability,test,test,210,"> Why do we need them for the duration of the workflow ?. Just getting to this now and I don't 100% remember why. I would try deleting them and ""see what happens"". From what I remember at least one conformance test crashed due to missing files.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3186#issuecomment-383250045
https://github.com/broadinstitute/cromwell/issues/3186#issuecomment-383252320:74,Testability,test,test,74,The original issue _might_ be alleviated by the fact that the conformance test runner (as well as `cromwell submit`) now salads everything in place and inlines all imported cwls into a single standalone CWL workflow,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3186#issuecomment-383252320
https://github.com/broadinstitute/cromwell/pull/3187#issuecomment-360253011:470,Availability,failure,failure,470,"The urgency of this particular fix came as we starting adding more valid CWL to PAPI and the tests were creeping past 70 minutes. I'm open to parallelizing local too. The workflow is reusable and there's currently nothing technically stopping us from switching local to parallel also. Cromwell's ""randomization"" (aka internally using unordered sets/hashmaps) when launching scatter jobs makes debugging the entire suite of tests wicked painful. It's hard to tell when a failure occurs what test was running. While CWL is in a state of flux I kind of like slowly working my way through the serial logs of local-conformance when I break something. My 2¬¢/ToL",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3187#issuecomment-360253011
https://github.com/broadinstitute/cromwell/pull/3187#issuecomment-360253011:349,Security,hash,hashmaps,349,"The urgency of this particular fix came as we starting adding more valid CWL to PAPI and the tests were creeping past 70 minutes. I'm open to parallelizing local too. The workflow is reusable and there's currently nothing technically stopping us from switching local to parallel also. Cromwell's ""randomization"" (aka internally using unordered sets/hashmaps) when launching scatter jobs makes debugging the entire suite of tests wicked painful. It's hard to tell when a failure occurs what test was running. While CWL is in a state of flux I kind of like slowly working my way through the serial logs of local-conformance when I break something. My 2¬¢/ToL",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3187#issuecomment-360253011
https://github.com/broadinstitute/cromwell/pull/3187#issuecomment-360253011:93,Testability,test,tests,93,"The urgency of this particular fix came as we starting adding more valid CWL to PAPI and the tests were creeping past 70 minutes. I'm open to parallelizing local too. The workflow is reusable and there's currently nothing technically stopping us from switching local to parallel also. Cromwell's ""randomization"" (aka internally using unordered sets/hashmaps) when launching scatter jobs makes debugging the entire suite of tests wicked painful. It's hard to tell when a failure occurs what test was running. While CWL is in a state of flux I kind of like slowly working my way through the serial logs of local-conformance when I break something. My 2¬¢/ToL",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3187#issuecomment-360253011
https://github.com/broadinstitute/cromwell/pull/3187#issuecomment-360253011:423,Testability,test,tests,423,"The urgency of this particular fix came as we starting adding more valid CWL to PAPI and the tests were creeping past 70 minutes. I'm open to parallelizing local too. The workflow is reusable and there's currently nothing technically stopping us from switching local to parallel also. Cromwell's ""randomization"" (aka internally using unordered sets/hashmaps) when launching scatter jobs makes debugging the entire suite of tests wicked painful. It's hard to tell when a failure occurs what test was running. While CWL is in a state of flux I kind of like slowly working my way through the serial logs of local-conformance when I break something. My 2¬¢/ToL",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3187#issuecomment-360253011
https://github.com/broadinstitute/cromwell/pull/3187#issuecomment-360253011:490,Testability,test,test,490,"The urgency of this particular fix came as we starting adding more valid CWL to PAPI and the tests were creeping past 70 minutes. I'm open to parallelizing local too. The workflow is reusable and there's currently nothing technically stopping us from switching local to parallel also. Cromwell's ""randomization"" (aka internally using unordered sets/hashmaps) when launching scatter jobs makes debugging the entire suite of tests wicked painful. It's hard to tell when a failure occurs what test was running. While CWL is in a state of flux I kind of like slowly working my way through the serial logs of local-conformance when I break something. My 2¬¢/ToL",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3187#issuecomment-360253011
https://github.com/broadinstitute/cromwell/pull/3187#issuecomment-360253011:596,Testability,log,logs,596,"The urgency of this particular fix came as we starting adding more valid CWL to PAPI and the tests were creeping past 70 minutes. I'm open to parallelizing local too. The workflow is reusable and there's currently nothing technically stopping us from switching local to parallel also. Cromwell's ""randomization"" (aka internally using unordered sets/hashmaps) when launching scatter jobs makes debugging the entire suite of tests wicked painful. It's hard to tell when a failure occurs what test was running. While CWL is in a state of flux I kind of like slowly working my way through the serial logs of local-conformance when I break something. My 2¬¢/ToL",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3187#issuecomment-360253011
https://github.com/broadinstitute/cromwell/issues/3190#issuecomment-360554624:66,Deployability,release,releases,66,Fixed in develop. The fix will appear in 30.2 and the upcoming 31 releases.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3190#issuecomment-360554624
https://github.com/broadinstitute/cromwell/issues/3201#issuecomment-579545087:257,Availability,echo,echo,257,"I just ran into this as well--cromwell does not work on OSes without `/bin/bash`. `/usr/bin/env bash` is more portable and IMHO the better option. The following fails to execute for me:. ```; workflow myWorkflow {; call myTask; }. task myTask {; command {; echo ""hello world""; }; output {; String out = read_string(stdout()); }; }; ```. Unfortunately this precludes me from using Cromwell.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3201#issuecomment-579545087
https://github.com/broadinstitute/cromwell/issues/3201#issuecomment-579545087:110,Modifiability,portab,portable,110,"I just ran into this as well--cromwell does not work on OSes without `/bin/bash`. `/usr/bin/env bash` is more portable and IMHO the better option. The following fails to execute for me:. ```; workflow myWorkflow {; call myTask; }. task myTask {; command {; echo ""hello world""; }; output {; String out = read_string(stdout()); }; }; ```. Unfortunately this precludes me from using Cromwell.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3201#issuecomment-579545087
https://github.com/broadinstitute/cromwell/issues/3208#issuecomment-361771938:37,Deployability,update,update,37,"Yup, thanks. I never circled back to update this. üòÑ It actually was being set but not quite correctly and also some environment variables aren't quite right, that's still WIP.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3208#issuecomment-361771938
https://github.com/broadinstitute/cromwell/issues/3208#issuecomment-361771938:128,Modifiability,variab,variables,128,"Yup, thanks. I never circled back to update this. üòÑ It actually was being set but not quite correctly and also some environment variables aren't quite right, that's still WIP.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3208#issuecomment-361771938
https://github.com/broadinstitute/cromwell/issues/3210#issuecomment-382814261:55,Usability,simpl,simply,55,To what extent can we merge the two? Is it possible to simply override where necessary on the cromiam side?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3210#issuecomment-382814261
https://github.com/broadinstitute/cromwell/issues/3210#issuecomment-429449186:95,Usability,clear,clearly,95,Discussed in person. As the long term plan is to do away with CromIAM as a separate server and clearly any deltas aren't bothering anyone at the moment we're closing this,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3210#issuecomment-429449186
https://github.com/broadinstitute/cromwell/pull/3211#issuecomment-361667890:16,Modifiability,config,config,16,"New `languages` config style:; ```. languages {; WDL {; versions {; ""draft-2"" {; language-factory = ""languages.wdl.WdlDraft2LanguageFactory""; }; }; }; CWL {; versions {; ""v1.0"" {; language-factory = ""languages.cwl.CwlV1LanguageFactory""; }; }; }; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3211#issuecomment-361667890
https://github.com/broadinstitute/cromwell/issues/3224#issuecomment-456487959:101,Availability,error,error,101,@samanehsan @geoffjentry -- is there a good message you'd like to see in replacement of the existing error?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3224#issuecomment-456487959
https://github.com/broadinstitute/cromwell/issues/3224#issuecomment-456487959:44,Integrability,message,message,44,@samanehsan @geoffjentry -- is there a good message you'd like to see in replacement of the existing error?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3224#issuecomment-456487959
https://github.com/broadinstitute/cromwell/issues/3224#issuecomment-458344447:15,Availability,error,error,15,"Good news: the error message is now spot on. Bad news: unmarshalling error. ```; CromIAM unexpected error: cromwell.api.CromwellClient$UnsuccessfulRequestException: Unmarshalling error: HttpResponse(404 Not Found,List(Server: akka-http/10.1.5, Date: Mon, 28 Jan 2019 23:23:57 GMT),HttpEntity.Strict(text/plain; charset=UTF-8,{; ""status"": ""fail"",; ""message"": ""Unrecognized workflow ID: ...""; }),HttpProtocol(HTTP/1.1)); ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3224#issuecomment-458344447
https://github.com/broadinstitute/cromwell/issues/3224#issuecomment-458344447:69,Availability,error,error,69,"Good news: the error message is now spot on. Bad news: unmarshalling error. ```; CromIAM unexpected error: cromwell.api.CromwellClient$UnsuccessfulRequestException: Unmarshalling error: HttpResponse(404 Not Found,List(Server: akka-http/10.1.5, Date: Mon, 28 Jan 2019 23:23:57 GMT),HttpEntity.Strict(text/plain; charset=UTF-8,{; ""status"": ""fail"",; ""message"": ""Unrecognized workflow ID: ...""; }),HttpProtocol(HTTP/1.1)); ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3224#issuecomment-458344447
https://github.com/broadinstitute/cromwell/issues/3224#issuecomment-458344447:100,Availability,error,error,100,"Good news: the error message is now spot on. Bad news: unmarshalling error. ```; CromIAM unexpected error: cromwell.api.CromwellClient$UnsuccessfulRequestException: Unmarshalling error: HttpResponse(404 Not Found,List(Server: akka-http/10.1.5, Date: Mon, 28 Jan 2019 23:23:57 GMT),HttpEntity.Strict(text/plain; charset=UTF-8,{; ""status"": ""fail"",; ""message"": ""Unrecognized workflow ID: ...""; }),HttpProtocol(HTTP/1.1)); ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3224#issuecomment-458344447
https://github.com/broadinstitute/cromwell/issues/3224#issuecomment-458344447:179,Availability,error,error,179,"Good news: the error message is now spot on. Bad news: unmarshalling error. ```; CromIAM unexpected error: cromwell.api.CromwellClient$UnsuccessfulRequestException: Unmarshalling error: HttpResponse(404 Not Found,List(Server: akka-http/10.1.5, Date: Mon, 28 Jan 2019 23:23:57 GMT),HttpEntity.Strict(text/plain; charset=UTF-8,{; ""status"": ""fail"",; ""message"": ""Unrecognized workflow ID: ...""; }),HttpProtocol(HTTP/1.1)); ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3224#issuecomment-458344447
https://github.com/broadinstitute/cromwell/issues/3224#issuecomment-458344447:21,Integrability,message,message,21,"Good news: the error message is now spot on. Bad news: unmarshalling error. ```; CromIAM unexpected error: cromwell.api.CromwellClient$UnsuccessfulRequestException: Unmarshalling error: HttpResponse(404 Not Found,List(Server: akka-http/10.1.5, Date: Mon, 28 Jan 2019 23:23:57 GMT),HttpEntity.Strict(text/plain; charset=UTF-8,{; ""status"": ""fail"",; ""message"": ""Unrecognized workflow ID: ...""; }),HttpProtocol(HTTP/1.1)); ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3224#issuecomment-458344447
https://github.com/broadinstitute/cromwell/issues/3224#issuecomment-458344447:348,Integrability,message,message,348,"Good news: the error message is now spot on. Bad news: unmarshalling error. ```; CromIAM unexpected error: cromwell.api.CromwellClient$UnsuccessfulRequestException: Unmarshalling error: HttpResponse(404 Not Found,List(Server: akka-http/10.1.5, Date: Mon, 28 Jan 2019 23:23:57 GMT),HttpEntity.Strict(text/plain; charset=UTF-8,{; ""status"": ""fail"",; ""message"": ""Unrecognized workflow ID: ...""; }),HttpProtocol(HTTP/1.1)); ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3224#issuecomment-458344447
https://github.com/broadinstitute/cromwell/issues/3226#issuecomment-362041035:121,Testability,log,logs,121,"This is effectifely a duplicate of an issue I can't find right now (@katevoss - do you know where the user persona based logs thing is?). Ultimately the root of the problem is that there are several different user personas who all want something completely different out of a Cromwell log, and we've handled that in a worst of all worlds sort of way by trying to jam all the info into a single blast. . We've talked in the past about splitting out different logs entirely and a user can select which of those they want to see",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3226#issuecomment-362041035
https://github.com/broadinstitute/cromwell/issues/3226#issuecomment-362041035:285,Testability,log,log,285,"This is effectifely a duplicate of an issue I can't find right now (@katevoss - do you know where the user persona based logs thing is?). Ultimately the root of the problem is that there are several different user personas who all want something completely different out of a Cromwell log, and we've handled that in a worst of all worlds sort of way by trying to jam all the info into a single blast. . We've talked in the past about splitting out different logs entirely and a user can select which of those they want to see",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3226#issuecomment-362041035
https://github.com/broadinstitute/cromwell/issues/3226#issuecomment-362041035:458,Testability,log,logs,458,"This is effectifely a duplicate of an issue I can't find right now (@katevoss - do you know where the user persona based logs thing is?). Ultimately the root of the problem is that there are several different user personas who all want something completely different out of a Cromwell log, and we've handled that in a worst of all worlds sort of way by trying to jam all the info into a single blast. . We've talked in the past about splitting out different logs entirely and a user can select which of those they want to see",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3226#issuecomment-362041035
https://github.com/broadinstitute/cromwell/issues/3226#issuecomment-362042424:24,Testability,Log,Logging,24,"There are many existing Logging issues, marked by the [Logs label](https://github.com/broadinstitute/cromwell/labels/Logs). ; Here is the [user persona doc](https://docs.google.com/document/d/1Dc37EaPDoWXacSSzLgCdndx9zo5k6EmE5tvg-2fisPo/edit#heading=h.wu6j4hvix240), feel free to add to it!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3226#issuecomment-362042424
https://github.com/broadinstitute/cromwell/issues/3226#issuecomment-362042424:55,Testability,Log,Logs,55,"There are many existing Logging issues, marked by the [Logs label](https://github.com/broadinstitute/cromwell/labels/Logs). ; Here is the [user persona doc](https://docs.google.com/document/d/1Dc37EaPDoWXacSSzLgCdndx9zo5k6EmE5tvg-2fisPo/edit#heading=h.wu6j4hvix240), feel free to add to it!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3226#issuecomment-362042424
https://github.com/broadinstitute/cromwell/issues/3226#issuecomment-362042424:117,Testability,Log,Logs,117,"There are many existing Logging issues, marked by the [Logs label](https://github.com/broadinstitute/cromwell/labels/Logs). ; Here is the [user persona doc](https://docs.google.com/document/d/1Dc37EaPDoWXacSSzLgCdndx9zo5k6EmE5tvg-2fisPo/edit#heading=h.wu6j4hvix240), feel free to add to it!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3226#issuecomment-362042424
https://github.com/broadinstitute/cromwell/pull/3228#issuecomment-362119021:149,Availability,failure,failure,149,Presumably to ensure we get the labels even when the workflow was invalid?. I think we can centaur that... I‚Äôm pretty sure we check metadata even on failure tests.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3228#issuecomment-362119021
https://github.com/broadinstitute/cromwell/pull/3228#issuecomment-362119021:157,Testability,test,tests,157,Presumably to ensure we get the labels even when the workflow was invalid?. I think we can centaur that... I‚Äôm pretty sure we check metadata even on failure tests.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3228#issuecomment-362119021
https://github.com/broadinstitute/cromwell/pull/3228#issuecomment-362119435:71,Security,validat,validate,71,"Exactly why. Since Cromiam fiddles with labels, if a workflow fails to validate that control information is lost",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3228#issuecomment-362119435
https://github.com/broadinstitute/cromwell/pull/3228#issuecomment-362304815:48,Testability,test,test,48,"Great, I'm happy to +1 but would like a centaur test to prevent regressions. . Just a new `.labels` and verification of metadata on an existing failing test would be fine.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3228#issuecomment-362304815
https://github.com/broadinstitute/cromwell/pull/3228#issuecomment-362304815:152,Testability,test,test,152,"Great, I'm happy to +1 but would like a centaur test to prevent regressions. . Just a new `.labels` and verification of metadata on an existing failing test would be fine.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3228#issuecomment-362304815
https://github.com/broadinstitute/cromwell/pull/3229#issuecomment-363646996:100,Integrability,rout,route,100,Closing for now. I'll use my lessons learned here to advise the trajectory of the tech debt paydown route.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3229#issuecomment-363646996
https://github.com/broadinstitute/cromwell/pull/3229#issuecomment-363646996:37,Usability,learn,learned,37,Closing for now. I'll use my lessons learned here to advise the trajectory of the tech debt paydown route.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3229#issuecomment-363646996
https://github.com/broadinstitute/cromwell/pull/3234#issuecomment-363647088:127,Integrability,rout,route,127,Closing for now. Thank you all for looking. I'll use my lessons learned here to advise the trajectory of the tech debt paydown route.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3234#issuecomment-363647088
https://github.com/broadinstitute/cromwell/pull/3234#issuecomment-363647088:64,Usability,learn,learned,64,Closing for now. Thank you all for looking. I'll use my lessons learned here to advise the trajectory of the tech debt paydown route.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3234#issuecomment-363647088
https://github.com/broadinstitute/cromwell/pull/3239#issuecomment-363230176:270,Integrability,depend,dependency,270,"I tried to further decompose `core` into submodules to be more exact about what I was bringing in to `languageFactory`, but I was ending up with 50 different sub-core projects and honestly I don't think super fine-grain imports are such a big deal now that the circular dependency problems are gone.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3239#issuecomment-363230176
https://github.com/broadinstitute/cromwell/issues/3240#issuecomment-380172244:29,Testability,test,tests,29,"We were running some scaling tests today in our cromwell. One of them was 60,000 workflows submitted with 1 subworkflow each. This was enough to essentially break JMUI, because we are doing a workaround to exclude the subworkflows after we query and after enough pagination, which is taking too long and timing out. Just for some recent context on this issue!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3240#issuecomment-380172244
https://github.com/broadinstitute/cromwell/issues/3240#issuecomment-382108058:280,Availability,fault,fault,280,"I just realized that we essentially blocked ourselves because of the comment above, where we now have so many subworkflows that we can't stand up a job manager on that cromwell because it can't filter them out quickly enough on the JMUI server side to render the website. Our own fault, but we'll be happy to see this functionality go in!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3240#issuecomment-382108058
https://github.com/broadinstitute/cromwell/issues/3241#issuecomment-366954601:657,Deployability,configurat,configuration,657,"Running into this problem again today. Having true modularity would be nice. So I can make a workflow, that imports a workflow, that imports a workflow. Imports need to be evaluated at the file level to handle this. ; This could be set as a config option to not break backwards compatibility.; I have some experience in scala myself as most of the tools in our institute are programmed in scala as well. If given some pointers I could maybe help in implementing this?. Am I correct in thinking that imports are evaluated [here](https://github.com/broadinstitute/cromwell/blob/develop/wdl/model/draft2/src/main/scala/wdl/draft2/model/Import.scala)?; Default configuration is in [here](https://github.com/broadinstitute/cromwell/blob/2cd38db0eb818b07ad38463183fe7a8af4706899/core/src/main/resources/reference.conf) right? Can I just add a new key,value pair which I can call from `import.scala` or are some changes to a code file required?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3241#issuecomment-366954601
https://github.com/broadinstitute/cromwell/issues/3241#issuecomment-366954601:241,Modifiability,config,config,241,"Running into this problem again today. Having true modularity would be nice. So I can make a workflow, that imports a workflow, that imports a workflow. Imports need to be evaluated at the file level to handle this. ; This could be set as a config option to not break backwards compatibility.; I have some experience in scala myself as most of the tools in our institute are programmed in scala as well. If given some pointers I could maybe help in implementing this?. Am I correct in thinking that imports are evaluated [here](https://github.com/broadinstitute/cromwell/blob/develop/wdl/model/draft2/src/main/scala/wdl/draft2/model/Import.scala)?; Default configuration is in [here](https://github.com/broadinstitute/cromwell/blob/2cd38db0eb818b07ad38463183fe7a8af4706899/core/src/main/resources/reference.conf) right? Can I just add a new key,value pair which I can call from `import.scala` or are some changes to a code file required?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3241#issuecomment-366954601
https://github.com/broadinstitute/cromwell/issues/3241#issuecomment-366954601:657,Modifiability,config,configuration,657,"Running into this problem again today. Having true modularity would be nice. So I can make a workflow, that imports a workflow, that imports a workflow. Imports need to be evaluated at the file level to handle this. ; This could be set as a config option to not break backwards compatibility.; I have some experience in scala myself as most of the tools in our institute are programmed in scala as well. If given some pointers I could maybe help in implementing this?. Am I correct in thinking that imports are evaluated [here](https://github.com/broadinstitute/cromwell/blob/develop/wdl/model/draft2/src/main/scala/wdl/draft2/model/Import.scala)?; Default configuration is in [here](https://github.com/broadinstitute/cromwell/blob/2cd38db0eb818b07ad38463183fe7a8af4706899/core/src/main/resources/reference.conf) right? Can I just add a new key,value pair which I can call from `import.scala` or are some changes to a code file required?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3241#issuecomment-366954601
https://github.com/broadinstitute/cromwell/issues/3241#issuecomment-366981017:0,Availability,Ping,Pinging,0,Pinging @cjllanwarne as I believe he has opinions on this :),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3241#issuecomment-366981017
https://github.com/broadinstitute/cromwell/issues/3241#issuecomment-367252775:327,Deployability,patch,patch,327,"As a follow up I did some extra testing. As cromwell evaluates imports from `$PWD`. This means that ; ```; java -jar /some/absolute/path/cromwell-<version>.jar /another/absolute/path/workflow.wdl; ```; yields different results depending on the current working directory. In my opinion this is not desirable behavior. The small patch code that I wrote does not solve this issue. If cromwell is run from the same directory as the workflow.wdl it works, but in other cases it does not. . In an ideal case ; ```; java -jar /some/absolute/path/cromwell-<version>.jar /another/absolute/path/workflow.wdl; ```; will always lead to the same result no matter what $PWD is. This makes workflows reproducible and easy to be reused. ; This means that cromwell should use the absolute parent path of `workflow.wdl` to evaluate its imports from.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3241#issuecomment-367252775
https://github.com/broadinstitute/cromwell/issues/3241#issuecomment-367252775:227,Integrability,depend,depending,227,"As a follow up I did some extra testing. As cromwell evaluates imports from `$PWD`. This means that ; ```; java -jar /some/absolute/path/cromwell-<version>.jar /another/absolute/path/workflow.wdl; ```; yields different results depending on the current working directory. In my opinion this is not desirable behavior. The small patch code that I wrote does not solve this issue. If cromwell is run from the same directory as the workflow.wdl it works, but in other cases it does not. . In an ideal case ; ```; java -jar /some/absolute/path/cromwell-<version>.jar /another/absolute/path/workflow.wdl; ```; will always lead to the same result no matter what $PWD is. This makes workflows reproducible and easy to be reused. ; This means that cromwell should use the absolute parent path of `workflow.wdl` to evaluate its imports from.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3241#issuecomment-367252775
https://github.com/broadinstitute/cromwell/issues/3241#issuecomment-367252775:32,Testability,test,testing,32,"As a follow up I did some extra testing. As cromwell evaluates imports from `$PWD`. This means that ; ```; java -jar /some/absolute/path/cromwell-<version>.jar /another/absolute/path/workflow.wdl; ```; yields different results depending on the current working directory. In my opinion this is not desirable behavior. The small patch code that I wrote does not solve this issue. If cromwell is run from the same directory as the workflow.wdl it works, but in other cases it does not. . In an ideal case ; ```; java -jar /some/absolute/path/cromwell-<version>.jar /another/absolute/path/workflow.wdl; ```; will always lead to the same result no matter what $PWD is. This makes workflows reproducible and easy to be reused. ; This means that cromwell should use the absolute parent path of `workflow.wdl` to evaluate its imports from.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3241#issuecomment-367252775
https://github.com/broadinstitute/cromwell/issues/3241#issuecomment-369579047:708,Availability,Failure,Failure,708,"Fixed the [proof of concept code](https://github.com/broadinstitute/cromwell/compare/develop...rhpvorderman:relativeImports). Now the WOMTOOL is able to handle absolute paths correctly. I can run `java -jar /home/ruben/test/base/womtool-31-1df94fa-SNAP.jar validate /home/ruben/test/base/workflow.wdl ` in any directory on the filesystem and get the same result. However cromwell still uses $PWD to evaluate the base directory. I can see the WOMtool uses the following code to load the WDL file:; ```scala; private[this] def loadWdl(path: String)(f: WdlNamespace => Termination): Termination = {; WdlNamespace.loadUsingPath(Paths.get(path), None, None) match {; case Success(namespace) => f(namespace); case Failure(r: RuntimeException) => throw new RuntimeException(""Unexpected failure mode"", r); case Failure(t) => UnsuccessfulTermination(t.getMessage); }; }; ```; But for cromwell there does not seem to be such a straightforward loading of the wdlfile. Can somebody point me to this?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3241#issuecomment-369579047
https://github.com/broadinstitute/cromwell/issues/3241#issuecomment-369579047:779,Availability,failure,failure,779,"Fixed the [proof of concept code](https://github.com/broadinstitute/cromwell/compare/develop...rhpvorderman:relativeImports). Now the WOMTOOL is able to handle absolute paths correctly. I can run `java -jar /home/ruben/test/base/womtool-31-1df94fa-SNAP.jar validate /home/ruben/test/base/workflow.wdl ` in any directory on the filesystem and get the same result. However cromwell still uses $PWD to evaluate the base directory. I can see the WOMtool uses the following code to load the WDL file:; ```scala; private[this] def loadWdl(path: String)(f: WdlNamespace => Termination): Termination = {; WdlNamespace.loadUsingPath(Paths.get(path), None, None) match {; case Success(namespace) => f(namespace); case Failure(r: RuntimeException) => throw new RuntimeException(""Unexpected failure mode"", r); case Failure(t) => UnsuccessfulTermination(t.getMessage); }; }; ```; But for cromwell there does not seem to be such a straightforward loading of the wdlfile. Can somebody point me to this?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3241#issuecomment-369579047
https://github.com/broadinstitute/cromwell/issues/3241#issuecomment-369579047:803,Availability,Failure,Failure,803,"Fixed the [proof of concept code](https://github.com/broadinstitute/cromwell/compare/develop...rhpvorderman:relativeImports). Now the WOMTOOL is able to handle absolute paths correctly. I can run `java -jar /home/ruben/test/base/womtool-31-1df94fa-SNAP.jar validate /home/ruben/test/base/workflow.wdl ` in any directory on the filesystem and get the same result. However cromwell still uses $PWD to evaluate the base directory. I can see the WOMtool uses the following code to load the WDL file:; ```scala; private[this] def loadWdl(path: String)(f: WdlNamespace => Termination): Termination = {; WdlNamespace.loadUsingPath(Paths.get(path), None, None) match {; case Success(namespace) => f(namespace); case Failure(r: RuntimeException) => throw new RuntimeException(""Unexpected failure mode"", r); case Failure(t) => UnsuccessfulTermination(t.getMessage); }; }; ```; But for cromwell there does not seem to be such a straightforward loading of the wdlfile. Can somebody point me to this?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3241#issuecomment-369579047
https://github.com/broadinstitute/cromwell/issues/3241#issuecomment-369579047:477,Performance,load,load,477,"Fixed the [proof of concept code](https://github.com/broadinstitute/cromwell/compare/develop...rhpvorderman:relativeImports). Now the WOMTOOL is able to handle absolute paths correctly. I can run `java -jar /home/ruben/test/base/womtool-31-1df94fa-SNAP.jar validate /home/ruben/test/base/workflow.wdl ` in any directory on the filesystem and get the same result. However cromwell still uses $PWD to evaluate the base directory. I can see the WOMtool uses the following code to load the WDL file:; ```scala; private[this] def loadWdl(path: String)(f: WdlNamespace => Termination): Termination = {; WdlNamespace.loadUsingPath(Paths.get(path), None, None) match {; case Success(namespace) => f(namespace); case Failure(r: RuntimeException) => throw new RuntimeException(""Unexpected failure mode"", r); case Failure(t) => UnsuccessfulTermination(t.getMessage); }; }; ```; But for cromwell there does not seem to be such a straightforward loading of the wdlfile. Can somebody point me to this?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3241#issuecomment-369579047
https://github.com/broadinstitute/cromwell/issues/3241#issuecomment-369579047:525,Performance,load,loadWdl,525,"Fixed the [proof of concept code](https://github.com/broadinstitute/cromwell/compare/develop...rhpvorderman:relativeImports). Now the WOMTOOL is able to handle absolute paths correctly. I can run `java -jar /home/ruben/test/base/womtool-31-1df94fa-SNAP.jar validate /home/ruben/test/base/workflow.wdl ` in any directory on the filesystem and get the same result. However cromwell still uses $PWD to evaluate the base directory. I can see the WOMtool uses the following code to load the WDL file:; ```scala; private[this] def loadWdl(path: String)(f: WdlNamespace => Termination): Termination = {; WdlNamespace.loadUsingPath(Paths.get(path), None, None) match {; case Success(namespace) => f(namespace); case Failure(r: RuntimeException) => throw new RuntimeException(""Unexpected failure mode"", r); case Failure(t) => UnsuccessfulTermination(t.getMessage); }; }; ```; But for cromwell there does not seem to be such a straightforward loading of the wdlfile. Can somebody point me to this?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3241#issuecomment-369579047
https://github.com/broadinstitute/cromwell/issues/3241#issuecomment-369579047:610,Performance,load,loadUsingPath,610,"Fixed the [proof of concept code](https://github.com/broadinstitute/cromwell/compare/develop...rhpvorderman:relativeImports). Now the WOMTOOL is able to handle absolute paths correctly. I can run `java -jar /home/ruben/test/base/womtool-31-1df94fa-SNAP.jar validate /home/ruben/test/base/workflow.wdl ` in any directory on the filesystem and get the same result. However cromwell still uses $PWD to evaluate the base directory. I can see the WOMtool uses the following code to load the WDL file:; ```scala; private[this] def loadWdl(path: String)(f: WdlNamespace => Termination): Termination = {; WdlNamespace.loadUsingPath(Paths.get(path), None, None) match {; case Success(namespace) => f(namespace); case Failure(r: RuntimeException) => throw new RuntimeException(""Unexpected failure mode"", r); case Failure(t) => UnsuccessfulTermination(t.getMessage); }; }; ```; But for cromwell there does not seem to be such a straightforward loading of the wdlfile. Can somebody point me to this?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3241#issuecomment-369579047
https://github.com/broadinstitute/cromwell/issues/3241#issuecomment-369579047:933,Performance,load,loading,933,"Fixed the [proof of concept code](https://github.com/broadinstitute/cromwell/compare/develop...rhpvorderman:relativeImports). Now the WOMTOOL is able to handle absolute paths correctly. I can run `java -jar /home/ruben/test/base/womtool-31-1df94fa-SNAP.jar validate /home/ruben/test/base/workflow.wdl ` in any directory on the filesystem and get the same result. However cromwell still uses $PWD to evaluate the base directory. I can see the WOMtool uses the following code to load the WDL file:; ```scala; private[this] def loadWdl(path: String)(f: WdlNamespace => Termination): Termination = {; WdlNamespace.loadUsingPath(Paths.get(path), None, None) match {; case Success(namespace) => f(namespace); case Failure(r: RuntimeException) => throw new RuntimeException(""Unexpected failure mode"", r); case Failure(t) => UnsuccessfulTermination(t.getMessage); }; }; ```; But for cromwell there does not seem to be such a straightforward loading of the wdlfile. Can somebody point me to this?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3241#issuecomment-369579047
https://github.com/broadinstitute/cromwell/issues/3241#issuecomment-369579047:257,Security,validat,validate,257,"Fixed the [proof of concept code](https://github.com/broadinstitute/cromwell/compare/develop...rhpvorderman:relativeImports). Now the WOMTOOL is able to handle absolute paths correctly. I can run `java -jar /home/ruben/test/base/womtool-31-1df94fa-SNAP.jar validate /home/ruben/test/base/workflow.wdl ` in any directory on the filesystem and get the same result. However cromwell still uses $PWD to evaluate the base directory. I can see the WOMtool uses the following code to load the WDL file:; ```scala; private[this] def loadWdl(path: String)(f: WdlNamespace => Termination): Termination = {; WdlNamespace.loadUsingPath(Paths.get(path), None, None) match {; case Success(namespace) => f(namespace); case Failure(r: RuntimeException) => throw new RuntimeException(""Unexpected failure mode"", r); case Failure(t) => UnsuccessfulTermination(t.getMessage); }; }; ```; But for cromwell there does not seem to be such a straightforward loading of the wdlfile. Can somebody point me to this?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3241#issuecomment-369579047
https://github.com/broadinstitute/cromwell/issues/3241#issuecomment-369579047:219,Testability,test,test,219,"Fixed the [proof of concept code](https://github.com/broadinstitute/cromwell/compare/develop...rhpvorderman:relativeImports). Now the WOMTOOL is able to handle absolute paths correctly. I can run `java -jar /home/ruben/test/base/womtool-31-1df94fa-SNAP.jar validate /home/ruben/test/base/workflow.wdl ` in any directory on the filesystem and get the same result. However cromwell still uses $PWD to evaluate the base directory. I can see the WOMtool uses the following code to load the WDL file:; ```scala; private[this] def loadWdl(path: String)(f: WdlNamespace => Termination): Termination = {; WdlNamespace.loadUsingPath(Paths.get(path), None, None) match {; case Success(namespace) => f(namespace); case Failure(r: RuntimeException) => throw new RuntimeException(""Unexpected failure mode"", r); case Failure(t) => UnsuccessfulTermination(t.getMessage); }; }; ```; But for cromwell there does not seem to be such a straightforward loading of the wdlfile. Can somebody point me to this?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3241#issuecomment-369579047
https://github.com/broadinstitute/cromwell/issues/3241#issuecomment-369579047:278,Testability,test,test,278,"Fixed the [proof of concept code](https://github.com/broadinstitute/cromwell/compare/develop...rhpvorderman:relativeImports). Now the WOMTOOL is able to handle absolute paths correctly. I can run `java -jar /home/ruben/test/base/womtool-31-1df94fa-SNAP.jar validate /home/ruben/test/base/workflow.wdl ` in any directory on the filesystem and get the same result. However cromwell still uses $PWD to evaluate the base directory. I can see the WOMtool uses the following code to load the WDL file:; ```scala; private[this] def loadWdl(path: String)(f: WdlNamespace => Termination): Termination = {; WdlNamespace.loadUsingPath(Paths.get(path), None, None) match {; case Success(namespace) => f(namespace); case Failure(r: RuntimeException) => throw new RuntimeException(""Unexpected failure mode"", r); case Failure(t) => UnsuccessfulTermination(t.getMessage); }; }; ```; But for cromwell there does not seem to be such a straightforward loading of the wdlfile. Can somebody point me to this?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3241#issuecomment-369579047
https://github.com/broadinstitute/cromwell/issues/3259#issuecomment-365100944:106,Deployability,hotfix,hotfixed,106,This has been fixed today in [`develop`](https://github.com/broadinstitute/cromwell/pull/3260) as well as hotfixed on the latest release branch ([`30_hotfix`](https://github.com/broadinstitute/cromwell/pull/3261)); Thanks again for spotting it !; Do not hesitate to re-open if you still encounter the issue.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3259#issuecomment-365100944
https://github.com/broadinstitute/cromwell/issues/3259#issuecomment-365100944:129,Deployability,release,release,129,This has been fixed today in [`develop`](https://github.com/broadinstitute/cromwell/pull/3260) as well as hotfixed on the latest release branch ([`30_hotfix`](https://github.com/broadinstitute/cromwell/pull/3261)); Thanks again for spotting it !; Do not hesitate to re-open if you still encounter the issue.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3259#issuecomment-365100944
https://github.com/broadinstitute/cromwell/issues/3259#issuecomment-367435337:5,Availability,down,downloaded,5,"I've downloaded the new jar file, still showing version 30.2, but still seeing the problem in some situations:. 2018-02-21 11:03:39,563 cromwell-system-akka.dispatchers.engine-dispatcher-95 INFO - Abort requested for workflow f0bff6e2-77a6-46f5-b226-13a64339a286.; 2018-02-21 11:03:39,564 cromwell-system-akka.dispatchers.engine-dispatcher-95 INFO - WorkflowExecutionActor-f0bff6e2-77a6-46f5-b226-13a64339a286 [UUID(f0bff6e2)]: Aborting workflow; 2018-02-21 11:03:39,567 cromwell-system-akka.dispatchers.engine-dispatcher-50 WARN - unhandled event EngineLifecycleActorAbortCommand in state SubWorkflowRunningState. Several SGE queue jobs continue to run/stay in the queue waiting state. Terminating the server with a ctrl-C does not affect the queued jobs.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3259#issuecomment-367435337
https://github.com/broadinstitute/cromwell/issues/3259#issuecomment-367435337:627,Performance,queue,queue,627,"I've downloaded the new jar file, still showing version 30.2, but still seeing the problem in some situations:. 2018-02-21 11:03:39,563 cromwell-system-akka.dispatchers.engine-dispatcher-95 INFO - Abort requested for workflow f0bff6e2-77a6-46f5-b226-13a64339a286.; 2018-02-21 11:03:39,564 cromwell-system-akka.dispatchers.engine-dispatcher-95 INFO - WorkflowExecutionActor-f0bff6e2-77a6-46f5-b226-13a64339a286 [UUID(f0bff6e2)]: Aborting workflow; 2018-02-21 11:03:39,567 cromwell-system-akka.dispatchers.engine-dispatcher-50 WARN - unhandled event EngineLifecycleActorAbortCommand in state SubWorkflowRunningState. Several SGE queue jobs continue to run/stay in the queue waiting state. Terminating the server with a ctrl-C does not affect the queued jobs.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3259#issuecomment-367435337
https://github.com/broadinstitute/cromwell/issues/3259#issuecomment-367435337:666,Performance,queue,queue,666,"I've downloaded the new jar file, still showing version 30.2, but still seeing the problem in some situations:. 2018-02-21 11:03:39,563 cromwell-system-akka.dispatchers.engine-dispatcher-95 INFO - Abort requested for workflow f0bff6e2-77a6-46f5-b226-13a64339a286.; 2018-02-21 11:03:39,564 cromwell-system-akka.dispatchers.engine-dispatcher-95 INFO - WorkflowExecutionActor-f0bff6e2-77a6-46f5-b226-13a64339a286 [UUID(f0bff6e2)]: Aborting workflow; 2018-02-21 11:03:39,567 cromwell-system-akka.dispatchers.engine-dispatcher-50 WARN - unhandled event EngineLifecycleActorAbortCommand in state SubWorkflowRunningState. Several SGE queue jobs continue to run/stay in the queue waiting state. Terminating the server with a ctrl-C does not affect the queued jobs.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3259#issuecomment-367435337
https://github.com/broadinstitute/cromwell/issues/3259#issuecomment-367435337:744,Performance,queue,queued,744,"I've downloaded the new jar file, still showing version 30.2, but still seeing the problem in some situations:. 2018-02-21 11:03:39,563 cromwell-system-akka.dispatchers.engine-dispatcher-95 INFO - Abort requested for workflow f0bff6e2-77a6-46f5-b226-13a64339a286.; 2018-02-21 11:03:39,564 cromwell-system-akka.dispatchers.engine-dispatcher-95 INFO - WorkflowExecutionActor-f0bff6e2-77a6-46f5-b226-13a64339a286 [UUID(f0bff6e2)]: Aborting workflow; 2018-02-21 11:03:39,567 cromwell-system-akka.dispatchers.engine-dispatcher-50 WARN - unhandled event EngineLifecycleActorAbortCommand in state SubWorkflowRunningState. Several SGE queue jobs continue to run/stay in the queue waiting state. Terminating the server with a ctrl-C does not affect the queued jobs.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3259#issuecomment-367435337
https://github.com/broadinstitute/cromwell/issues/3259#issuecomment-367435337:197,Safety,Abort,Abort,197,"I've downloaded the new jar file, still showing version 30.2, but still seeing the problem in some situations:. 2018-02-21 11:03:39,563 cromwell-system-akka.dispatchers.engine-dispatcher-95 INFO - Abort requested for workflow f0bff6e2-77a6-46f5-b226-13a64339a286.; 2018-02-21 11:03:39,564 cromwell-system-akka.dispatchers.engine-dispatcher-95 INFO - WorkflowExecutionActor-f0bff6e2-77a6-46f5-b226-13a64339a286 [UUID(f0bff6e2)]: Aborting workflow; 2018-02-21 11:03:39,567 cromwell-system-akka.dispatchers.engine-dispatcher-50 WARN - unhandled event EngineLifecycleActorAbortCommand in state SubWorkflowRunningState. Several SGE queue jobs continue to run/stay in the queue waiting state. Terminating the server with a ctrl-C does not affect the queued jobs.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3259#issuecomment-367435337
https://github.com/broadinstitute/cromwell/issues/3259#issuecomment-367435337:428,Safety,Abort,Aborting,428,"I've downloaded the new jar file, still showing version 30.2, but still seeing the problem in some situations:. 2018-02-21 11:03:39,563 cromwell-system-akka.dispatchers.engine-dispatcher-95 INFO - Abort requested for workflow f0bff6e2-77a6-46f5-b226-13a64339a286.; 2018-02-21 11:03:39,564 cromwell-system-akka.dispatchers.engine-dispatcher-95 INFO - WorkflowExecutionActor-f0bff6e2-77a6-46f5-b226-13a64339a286 [UUID(f0bff6e2)]: Aborting workflow; 2018-02-21 11:03:39,567 cromwell-system-akka.dispatchers.engine-dispatcher-50 WARN - unhandled event EngineLifecycleActorAbortCommand in state SubWorkflowRunningState. Several SGE queue jobs continue to run/stay in the queue waiting state. Terminating the server with a ctrl-C does not affect the queued jobs.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3259#issuecomment-367435337
https://github.com/broadinstitute/cromwell/issues/3262#issuecomment-365552356:63,Modifiability,variab,variable,63,"Open a PR for a temporary fix using a `JAVA_OPT` environmental variable, although it is too generic.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3262#issuecomment-365552356
https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-365310137:97,Deployability,release,released,97,"Looking into it more closely, there's a good chance we fixed this issue already, we just haven't released a 30.3 jar yet. Meanwhile if you're able to build from the `30_hotfix` branch you might want to try that.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-365310137
https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-367032664:280,Integrability,message,message,280,"Interesting, could you look at the content of `stdout` and `stderr` for those stuck tasks ? Does it look like it's still doing work ?; It looks like you're running this locally on your machine ? How big are the samples in your `test.json` ?; I don't think the docker dead letters message are actually the issue (even though I'm not sure why they're appearing I'll look int that).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-367032664
https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-367032664:228,Testability,test,test,228,"Interesting, could you look at the content of `stdout` and `stderr` for those stuck tasks ? Does it look like it's still doing work ?; It looks like you're running this locally on your machine ? How big are the samples in your `test.json` ?; I don't think the docker dead letters message are actually the issue (even though I'm not sure why they're appearing I'll look int that).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-367032664
https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-367256315:427,Availability,ERROR,ERROR,427,"Yes, I also think dead letters message is no issue. . root@d0ef87b8b6b8:/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution# **cat stderr**; > Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution/tmp.rmIqEe; > ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console.; > [M::bwa_idx_load_from_disk] read 0 ALT contigs; > [W::main_mem] when '-p' is in use, the second query file is ignored.; > . stdout is 0 byte. I'm running on local machine. ; Just I used 2 bam file only.; $ /BiO/Project/brandon-genome-analysis/data/NA12878_24RG_small.txt; /BiO/Project/brandon-genome-analysis/data/HJYFJ.4.NA12878.downsampled.query.sorted.unmapped.bam; /BiO/Project/brandon-genome-analysis/data/HJYFJ.5.NA12878.downsampled.query.sorted.unmapped.bam. I found some issue in stderr file. > Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution/tmp.rmIqEe; > ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console. Could you suggest any comment for this ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-367256315
https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-367256315:524,Availability,error,errors,524,"Yes, I also think dead letters message is no issue. . root@d0ef87b8b6b8:/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution# **cat stderr**; > Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution/tmp.rmIqEe; > ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console.; > [M::bwa_idx_load_from_disk] read 0 ALT contigs; > [W::main_mem] when '-p' is in use, the second query file is ignored.; > . stdout is 0 byte. I'm running on local machine. ; Just I used 2 bam file only.; $ /BiO/Project/brandon-genome-analysis/data/NA12878_24RG_small.txt; /BiO/Project/brandon-genome-analysis/data/HJYFJ.4.NA12878.downsampled.query.sorted.unmapped.bam; /BiO/Project/brandon-genome-analysis/data/HJYFJ.5.NA12878.downsampled.query.sorted.unmapped.bam. I found some issue in stderr file. > Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution/tmp.rmIqEe; > ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console. Could you suggest any comment for this ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-367256315
https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-367256315:880,Availability,down,downsampled,880,"Yes, I also think dead letters message is no issue. . root@d0ef87b8b6b8:/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution# **cat stderr**; > Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution/tmp.rmIqEe; > ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console.; > [M::bwa_idx_load_from_disk] read 0 ALT contigs; > [W::main_mem] when '-p' is in use, the second query file is ignored.; > . stdout is 0 byte. I'm running on local machine. ; Just I used 2 bam file only.; $ /BiO/Project/brandon-genome-analysis/data/NA12878_24RG_small.txt; /BiO/Project/brandon-genome-analysis/data/HJYFJ.4.NA12878.downsampled.query.sorted.unmapped.bam; /BiO/Project/brandon-genome-analysis/data/HJYFJ.5.NA12878.downsampled.query.sorted.unmapped.bam. I found some issue in stderr file. > Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution/tmp.rmIqEe; > ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console. Could you suggest any comment for this ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-367256315
https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-367256315:977,Availability,down,downsampled,977,"Yes, I also think dead letters message is no issue. . root@d0ef87b8b6b8:/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution# **cat stderr**; > Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution/tmp.rmIqEe; > ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console.; > [M::bwa_idx_load_from_disk] read 0 ALT contigs; > [W::main_mem] when '-p' is in use, the second query file is ignored.; > . stdout is 0 byte. I'm running on local machine. ; Just I used 2 bam file only.; $ /BiO/Project/brandon-genome-analysis/data/NA12878_24RG_small.txt; /BiO/Project/brandon-genome-analysis/data/HJYFJ.4.NA12878.downsampled.query.sorted.unmapped.bam; /BiO/Project/brandon-genome-analysis/data/HJYFJ.5.NA12878.downsampled.query.sorted.unmapped.bam. I found some issue in stderr file. > Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution/tmp.rmIqEe; > ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console. Could you suggest any comment for this ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-367256315
https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-367256315:1249,Availability,ERROR,ERROR,1249,"Yes, I also think dead letters message is no issue. . root@d0ef87b8b6b8:/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution# **cat stderr**; > Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution/tmp.rmIqEe; > ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console.; > [M::bwa_idx_load_from_disk] read 0 ALT contigs; > [W::main_mem] when '-p' is in use, the second query file is ignored.; > . stdout is 0 byte. I'm running on local machine. ; Just I used 2 bam file only.; $ /BiO/Project/brandon-genome-analysis/data/NA12878_24RG_small.txt; /BiO/Project/brandon-genome-analysis/data/HJYFJ.4.NA12878.downsampled.query.sorted.unmapped.bam; /BiO/Project/brandon-genome-analysis/data/HJYFJ.5.NA12878.downsampled.query.sorted.unmapped.bam. I found some issue in stderr file. > Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution/tmp.rmIqEe; > ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console. Could you suggest any comment for this ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-367256315
https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-367256315:1346,Availability,error,errors,1346,"Yes, I also think dead letters message is no issue. . root@d0ef87b8b6b8:/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution# **cat stderr**; > Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution/tmp.rmIqEe; > ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console.; > [M::bwa_idx_load_from_disk] read 0 ALT contigs; > [W::main_mem] when '-p' is in use, the second query file is ignored.; > . stdout is 0 byte. I'm running on local machine. ; Just I used 2 bam file only.; $ /BiO/Project/brandon-genome-analysis/data/NA12878_24RG_small.txt; /BiO/Project/brandon-genome-analysis/data/HJYFJ.4.NA12878.downsampled.query.sorted.unmapped.bam; /BiO/Project/brandon-genome-analysis/data/HJYFJ.5.NA12878.downsampled.query.sorted.unmapped.bam. I found some issue in stderr file. > Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution/tmp.rmIqEe; > ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console. Could you suggest any comment for this ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-367256315
https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-367256315:456,Deployability,configurat,configuration,456,"Yes, I also think dead letters message is no issue. . root@d0ef87b8b6b8:/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution# **cat stderr**; > Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution/tmp.rmIqEe; > ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console.; > [M::bwa_idx_load_from_disk] read 0 ALT contigs; > [W::main_mem] when '-p' is in use, the second query file is ignored.; > . stdout is 0 byte. I'm running on local machine. ; Just I used 2 bam file only.; $ /BiO/Project/brandon-genome-analysis/data/NA12878_24RG_small.txt; /BiO/Project/brandon-genome-analysis/data/HJYFJ.4.NA12878.downsampled.query.sorted.unmapped.bam; /BiO/Project/brandon-genome-analysis/data/HJYFJ.5.NA12878.downsampled.query.sorted.unmapped.bam. I found some issue in stderr file. > Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution/tmp.rmIqEe; > ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console. Could you suggest any comment for this ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-367256315
https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-367256315:496,Deployability,configurat,configuration,496,"Yes, I also think dead letters message is no issue. . root@d0ef87b8b6b8:/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution# **cat stderr**; > Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution/tmp.rmIqEe; > ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console.; > [M::bwa_idx_load_from_disk] read 0 ALT contigs; > [W::main_mem] when '-p' is in use, the second query file is ignored.; > . stdout is 0 byte. I'm running on local machine. ; Just I used 2 bam file only.; $ /BiO/Project/brandon-genome-analysis/data/NA12878_24RG_small.txt; /BiO/Project/brandon-genome-analysis/data/HJYFJ.4.NA12878.downsampled.query.sorted.unmapped.bam; /BiO/Project/brandon-genome-analysis/data/HJYFJ.5.NA12878.downsampled.query.sorted.unmapped.bam. I found some issue in stderr file. > Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution/tmp.rmIqEe; > ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console. Could you suggest any comment for this ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-367256315
https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-367256315:1278,Deployability,configurat,configuration,1278,"Yes, I also think dead letters message is no issue. . root@d0ef87b8b6b8:/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution# **cat stderr**; > Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution/tmp.rmIqEe; > ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console.; > [M::bwa_idx_load_from_disk] read 0 ALT contigs; > [W::main_mem] when '-p' is in use, the second query file is ignored.; > . stdout is 0 byte. I'm running on local machine. ; Just I used 2 bam file only.; $ /BiO/Project/brandon-genome-analysis/data/NA12878_24RG_small.txt; /BiO/Project/brandon-genome-analysis/data/HJYFJ.4.NA12878.downsampled.query.sorted.unmapped.bam; /BiO/Project/brandon-genome-analysis/data/HJYFJ.5.NA12878.downsampled.query.sorted.unmapped.bam. I found some issue in stderr file. > Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution/tmp.rmIqEe; > ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console. Could you suggest any comment for this ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-367256315
https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-367256315:1318,Deployability,configurat,configuration,1318,"Yes, I also think dead letters message is no issue. . root@d0ef87b8b6b8:/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution# **cat stderr**; > Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution/tmp.rmIqEe; > ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console.; > [M::bwa_idx_load_from_disk] read 0 ALT contigs; > [W::main_mem] when '-p' is in use, the second query file is ignored.; > . stdout is 0 byte. I'm running on local machine. ; Just I used 2 bam file only.; $ /BiO/Project/brandon-genome-analysis/data/NA12878_24RG_small.txt; /BiO/Project/brandon-genome-analysis/data/HJYFJ.4.NA12878.downsampled.query.sorted.unmapped.bam; /BiO/Project/brandon-genome-analysis/data/HJYFJ.5.NA12878.downsampled.query.sorted.unmapped.bam. I found some issue in stderr file. > Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution/tmp.rmIqEe; > ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console. Could you suggest any comment for this ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-367256315
https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-367256315:31,Integrability,message,message,31,"Yes, I also think dead letters message is no issue. . root@d0ef87b8b6b8:/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution# **cat stderr**; > Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution/tmp.rmIqEe; > ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console.; > [M::bwa_idx_load_from_disk] read 0 ALT contigs; > [W::main_mem] when '-p' is in use, the second query file is ignored.; > . stdout is 0 byte. I'm running on local machine. ; Just I used 2 bam file only.; $ /BiO/Project/brandon-genome-analysis/data/NA12878_24RG_small.txt; /BiO/Project/brandon-genome-analysis/data/HJYFJ.4.NA12878.downsampled.query.sorted.unmapped.bam; /BiO/Project/brandon-genome-analysis/data/HJYFJ.5.NA12878.downsampled.query.sorted.unmapped.bam. I found some issue in stderr file. > Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution/tmp.rmIqEe; > ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console. Could you suggest any comment for this ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-367256315
https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-367256315:456,Modifiability,config,configuration,456,"Yes, I also think dead letters message is no issue. . root@d0ef87b8b6b8:/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution# **cat stderr**; > Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution/tmp.rmIqEe; > ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console.; > [M::bwa_idx_load_from_disk] read 0 ALT contigs; > [W::main_mem] when '-p' is in use, the second query file is ignored.; > . stdout is 0 byte. I'm running on local machine. ; Just I used 2 bam file only.; $ /BiO/Project/brandon-genome-analysis/data/NA12878_24RG_small.txt; /BiO/Project/brandon-genome-analysis/data/HJYFJ.4.NA12878.downsampled.query.sorted.unmapped.bam; /BiO/Project/brandon-genome-analysis/data/HJYFJ.5.NA12878.downsampled.query.sorted.unmapped.bam. I found some issue in stderr file. > Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution/tmp.rmIqEe; > ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console. Could you suggest any comment for this ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-367256315
https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-367256315:496,Modifiability,config,configuration,496,"Yes, I also think dead letters message is no issue. . root@d0ef87b8b6b8:/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution# **cat stderr**; > Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution/tmp.rmIqEe; > ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console.; > [M::bwa_idx_load_from_disk] read 0 ALT contigs; > [W::main_mem] when '-p' is in use, the second query file is ignored.; > . stdout is 0 byte. I'm running on local machine. ; Just I used 2 bam file only.; $ /BiO/Project/brandon-genome-analysis/data/NA12878_24RG_small.txt; /BiO/Project/brandon-genome-analysis/data/HJYFJ.4.NA12878.downsampled.query.sorted.unmapped.bam; /BiO/Project/brandon-genome-analysis/data/HJYFJ.5.NA12878.downsampled.query.sorted.unmapped.bam. I found some issue in stderr file. > Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution/tmp.rmIqEe; > ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console. Could you suggest any comment for this ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-367256315
https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-367256315:1278,Modifiability,config,configuration,1278,"Yes, I also think dead letters message is no issue. . root@d0ef87b8b6b8:/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution# **cat stderr**; > Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution/tmp.rmIqEe; > ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console.; > [M::bwa_idx_load_from_disk] read 0 ALT contigs; > [W::main_mem] when '-p' is in use, the second query file is ignored.; > . stdout is 0 byte. I'm running on local machine. ; Just I used 2 bam file only.; $ /BiO/Project/brandon-genome-analysis/data/NA12878_24RG_small.txt; /BiO/Project/brandon-genome-analysis/data/HJYFJ.4.NA12878.downsampled.query.sorted.unmapped.bam; /BiO/Project/brandon-genome-analysis/data/HJYFJ.5.NA12878.downsampled.query.sorted.unmapped.bam. I found some issue in stderr file. > Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution/tmp.rmIqEe; > ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console. Could you suggest any comment for this ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-367256315
https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-367256315:1318,Modifiability,config,configuration,1318,"Yes, I also think dead letters message is no issue. . root@d0ef87b8b6b8:/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution# **cat stderr**; > Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution/tmp.rmIqEe; > ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console.; > [M::bwa_idx_load_from_disk] read 0 ALT contigs; > [W::main_mem] when '-p' is in use, the second query file is ignored.; > . stdout is 0 byte. I'm running on local machine. ; Just I used 2 bam file only.; $ /BiO/Project/brandon-genome-analysis/data/NA12878_24RG_small.txt; /BiO/Project/brandon-genome-analysis/data/HJYFJ.4.NA12878.downsampled.query.sorted.unmapped.bam; /BiO/Project/brandon-genome-analysis/data/HJYFJ.5.NA12878.downsampled.query.sorted.unmapped.bam. I found some issue in stderr file. > Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution/tmp.rmIqEe; > ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console. Could you suggest any comment for this ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-367256315
https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-367256315:511,Testability,log,logging,511,"Yes, I also think dead letters message is no issue. . root@d0ef87b8b6b8:/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution# **cat stderr**; > Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution/tmp.rmIqEe; > ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console.; > [M::bwa_idx_load_from_disk] read 0 ALT contigs; > [W::main_mem] when '-p' is in use, the second query file is ignored.; > . stdout is 0 byte. I'm running on local machine. ; Just I used 2 bam file only.; $ /BiO/Project/brandon-genome-analysis/data/NA12878_24RG_small.txt; /BiO/Project/brandon-genome-analysis/data/HJYFJ.4.NA12878.downsampled.query.sorted.unmapped.bam; /BiO/Project/brandon-genome-analysis/data/HJYFJ.5.NA12878.downsampled.query.sorted.unmapped.bam. I found some issue in stderr file. > Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution/tmp.rmIqEe; > ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console. Could you suggest any comment for this ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-367256315
https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-367256315:1333,Testability,log,logging,1333,"Yes, I also think dead letters message is no issue. . root@d0ef87b8b6b8:/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution# **cat stderr**; > Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution/tmp.rmIqEe; > ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console.; > [M::bwa_idx_load_from_disk] read 0 ALT contigs; > [W::main_mem] when '-p' is in use, the second query file is ignored.; > . stdout is 0 byte. I'm running on local machine. ; Just I used 2 bam file only.; $ /BiO/Project/brandon-genome-analysis/data/NA12878_24RG_small.txt; /BiO/Project/brandon-genome-analysis/data/HJYFJ.4.NA12878.downsampled.query.sorted.unmapped.bam; /BiO/Project/brandon-genome-analysis/data/HJYFJ.5.NA12878.downsampled.query.sorted.unmapped.bam. I found some issue in stderr file. > Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/7ffcdf28-2324-4c07-8e87-926a150334d9/call-SamToFastqAndBwaMem/shard-0/execution/tmp.rmIqEe; > ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console. Could you suggest any comment for this ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-367256315
https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-367368011:38,Availability,error,error,38,"I'm not a specialist of GATK but this error doesn't seem like a big deal, it looks like it's defaulting to another logging mode. Maybe @vdauwera would know more ?; If you `ps -elf | grep java` is there anything still running in this docker container ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-367368011
https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-367368011:115,Testability,log,logging,115,"I'm not a specialist of GATK but this error doesn't seem like a big deal, it looks like it's defaulting to another logging mode. Maybe @vdauwera would know more ?; If you `ps -elf | grep java` is there anything still running in this docker container ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-367368011
https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-449074013:9,Availability,error,error,9,"No fatal error. so, close.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3269#issuecomment-449074013
https://github.com/broadinstitute/cromwell/pull/3281#issuecomment-366056325:12,Testability,test,tests,12,adding unit tests for WomCoproductType coercion,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3281#issuecomment-366056325
https://github.com/broadinstitute/cromwell/issues/3286#issuecomment-394931718:45,Deployability,integrat,integration,45,Unit tests are passing. Centaur provides the integration tests we should be using - no need for separate tests. Centaur script was added in rev 3bd9b6a. Closing,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3286#issuecomment-394931718
https://github.com/broadinstitute/cromwell/issues/3286#issuecomment-394931718:45,Integrability,integrat,integration,45,Unit tests are passing. Centaur provides the integration tests we should be using - no need for separate tests. Centaur script was added in rev 3bd9b6a. Closing,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3286#issuecomment-394931718
https://github.com/broadinstitute/cromwell/issues/3286#issuecomment-394931718:5,Testability,test,tests,5,Unit tests are passing. Centaur provides the integration tests we should be using - no need for separate tests. Centaur script was added in rev 3bd9b6a. Closing,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3286#issuecomment-394931718
https://github.com/broadinstitute/cromwell/issues/3286#issuecomment-394931718:57,Testability,test,tests,57,Unit tests are passing. Centaur provides the integration tests we should be using - no need for separate tests. Centaur script was added in rev 3bd9b6a. Closing,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3286#issuecomment-394931718
https://github.com/broadinstitute/cromwell/issues/3286#issuecomment-394931718:105,Testability,test,tests,105,Unit tests are passing. Centaur provides the integration tests we should be using - no need for separate tests. Centaur script was added in rev 3bd9b6a. Closing,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3286#issuecomment-394931718
https://github.com/broadinstitute/cromwell/pull/3294#issuecomment-367017359:271,Integrability,interface,interfaces,271,ToL: . The title made me a little nervous that this was adding more coupling that would make things hard in a world where these services are different implementations or instantiated on remote servers. But since it looks like it's all being directed through the standard interfaces in the service registry it all looks OK. And I assume we can still give the `serviceRegistryActor: ActorRef` argument to a new service that's created remotely.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3294#issuecomment-367017359
https://github.com/broadinstitute/cromwell/pull/3294#issuecomment-367017359:68,Modifiability,coupling,coupling,68,ToL: . The title made me a little nervous that this was adding more coupling that would make things hard in a world where these services are different implementations or instantiated on remote servers. But since it looks like it's all being directed through the standard interfaces in the service registry it all looks OK. And I assume we can still give the `serviceRegistryActor: ActorRef` argument to a new service that's created remotely.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3294#issuecomment-367017359
https://github.com/broadinstitute/cromwell/pull/3294#issuecomment-367025969:246,Availability,avail,available,246,"@mcovarr it does seem to have worked üòÑ; @cjllanwarne @geoffjentry Good point, my main goal was to make it possible for the metadata service to report statsd metrics, which is done through another service. But like you said since it's just making available the service registry actor to the services I don't think it introduces any additional coupling.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3294#issuecomment-367025969
https://github.com/broadinstitute/cromwell/pull/3294#issuecomment-367025969:342,Modifiability,coupling,coupling,342,"@mcovarr it does seem to have worked üòÑ; @cjllanwarne @geoffjentry Good point, my main goal was to make it possible for the metadata service to report statsd metrics, which is done through another service. But like you said since it's just making available the service registry actor to the services I don't think it introduces any additional coupling.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3294#issuecomment-367025969
https://github.com/broadinstitute/cromwell/issues/3297#issuecomment-373942284:868,Availability,error,error,868,"I am having an issue when trying to use `--imports tasks.zip` with Cromwell v31. I assume it is related to this issue. I can't seem to make it work with imports. I assume the parameter `--workflow-root` may be an alternative to using `imports`? However, instead of using zip imports, I tried using `--workflow-root` and still did not work. Thanks in advance for any help. Details of my scenario:. In my workflow I have:. ```; import ""tasks/task-1.wdl"" as task1; import ""tasks/task-2.wdl"" as task2; ```. my zip file looks like this:. ```; c4b301bb01ef:Desktop gonzalezma$ unzip -l tasks.zip ; Archive: tasks.zip; Length Date Time Name; -------- ---- ---- ----; 128 03-17-18 11:57 tasks/task-1.wdl; 119 03-17-18 11:57 tasks/task-2.wdl; -------- -------; 247 2 files; ```. Cromwell fails and says it can't find the task wdl files. How do I make this work? . The detailed error is as follows:. ```; [2018-03-17 14:23:42,03] [error] WorkflowManagerActor Workflow 6d61108d-3a3c-4850-8bd9-2862660f953c failed (during MaterializingWorkflowDescriptorState): Workflow input processing failed:; /var/folders/zm/35r081w17gn1nw2kksqjlp6dyhcq01/T/7591430002708022127.zip7406634406151397777/tasks/task-1.wdl; cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; /var/folders/zm/35r081w17gn1nw2kksqjlp6dyhcq01/T/7591430002708022127.zip7406634406151397777/tasks/task-1.wdl; 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$workflowInitializationFailed(MaterializeWorkflowDescriptorActor.scala:203); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:173); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3297#issuecomment-373942284
https://github.com/broadinstitute/cromwell/issues/3297#issuecomment-373942284:921,Availability,error,error,921,"when trying to use `--imports tasks.zip` with Cromwell v31. I assume it is related to this issue. I can't seem to make it work with imports. I assume the parameter `--workflow-root` may be an alternative to using `imports`? However, instead of using zip imports, I tried using `--workflow-root` and still did not work. Thanks in advance for any help. Details of my scenario:. In my workflow I have:. ```; import ""tasks/task-1.wdl"" as task1; import ""tasks/task-2.wdl"" as task2; ```. my zip file looks like this:. ```; c4b301bb01ef:Desktop gonzalezma$ unzip -l tasks.zip ; Archive: tasks.zip; Length Date Time Name; -------- ---- ---- ----; 128 03-17-18 11:57 tasks/task-1.wdl; 119 03-17-18 11:57 tasks/task-2.wdl; -------- -------; 247 2 files; ```. Cromwell fails and says it can't find the task wdl files. How do I make this work? . The detailed error is as follows:. ```; [2018-03-17 14:23:42,03] [error] WorkflowManagerActor Workflow 6d61108d-3a3c-4850-8bd9-2862660f953c failed (during MaterializingWorkflowDescriptorState): Workflow input processing failed:; /var/folders/zm/35r081w17gn1nw2kksqjlp6dyhcq01/T/7591430002708022127.zip7406634406151397777/tasks/task-1.wdl; cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; /var/folders/zm/35r081w17gn1nw2kksqjlp6dyhcq01/T/7591430002708022127.zip7406634406151397777/tasks/task-1.wdl; 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$workflowInitializationFailed(MaterializeWorkflowDescriptorActor.scala:203); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:173); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:168); 	at scala.runt",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3297#issuecomment-373942284
https://github.com/broadinstitute/cromwell/issues/3297#issuecomment-373942284:2288,Testability,Log,LoggingFSM,2288,failed:; /var/folders/zm/35r081w17gn1nw2kksqjlp6dyhcq01/T/7591430002708022127.zip7406634406151397777/tasks/task-1.wdl; 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$workflowInitializationFailed(MaterializeWorkflowDescriptorActor.scala:203); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:173); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:168); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); 	at akka.actor.FSM.processEvent(FSM.scala:665); 	at akka.actor.FSM.processEvent$(FSM.scala:662); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:126); 	at akka.actor.LoggingFSM.processEvent(FSM.scala:801); 	at akka.actor.LoggingFSM.processEvent$(FSM.scala:783); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.processEvent(MaterializeWorkflowDescriptorActor.scala:126); 	at akka.actor.FSM.akka$actor$FSM$$processMsg(FSM.scala:659); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:653); 	at akka.actor.Actor.aroundReceive(Actor.scala:514); 	at akka.actor.Actor.aroundReceive$(Actor.scala:512); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:126); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); 	at akka.actor.ActorCell.invoke(ActorCell.scala:496); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at akka.dispatch.forkjoi,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3297#issuecomment-373942284
https://github.com/broadinstitute/cromwell/issues/3297#issuecomment-373942284:2381,Testability,Log,LoggingFSM,2381,022127.zip7406634406151397777/tasks/task-1.wdl; 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$workflowInitializationFailed(MaterializeWorkflowDescriptorActor.scala:203); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:173); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:168); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); 	at akka.actor.FSM.processEvent(FSM.scala:665); 	at akka.actor.FSM.processEvent$(FSM.scala:662); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:126); 	at akka.actor.LoggingFSM.processEvent(FSM.scala:801); 	at akka.actor.LoggingFSM.processEvent$(FSM.scala:783); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.processEvent(MaterializeWorkflowDescriptorActor.scala:126); 	at akka.actor.FSM.akka$actor$FSM$$processMsg(FSM.scala:659); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:653); 	at akka.actor.Actor.aroundReceive(Actor.scala:514); 	at akka.actor.Actor.aroundReceive$(Actor.scala:512); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:126); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); 	at akka.actor.ActorCell.invoke(ActorCell.scala:496); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoi,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3297#issuecomment-373942284
https://github.com/broadinstitute/cromwell/issues/3297#issuecomment-373942284:2436,Testability,Log,LoggingFSM,2436,mwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$workflowInitializationFailed(MaterializeWorkflowDescriptorActor.scala:203); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:173); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:168); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); 	at akka.actor.FSM.processEvent(FSM.scala:665); 	at akka.actor.FSM.processEvent$(FSM.scala:662); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:126); 	at akka.actor.LoggingFSM.processEvent(FSM.scala:801); 	at akka.actor.LoggingFSM.processEvent$(FSM.scala:783); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.processEvent(MaterializeWorkflowDescriptorActor.scala:126); 	at akka.actor.FSM.akka$actor$FSM$$processMsg(FSM.scala:659); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:653); 	at akka.actor.Actor.aroundReceive(Actor.scala:514); 	at akka.actor.Actor.aroundReceive$(Actor.scala:512); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:126); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); 	at akka.actor.ActorCell.invoke(ActorCell.scala:496); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3297#issuecomment-373942284
https://github.com/broadinstitute/cromwell/issues/3297#issuecomment-374289503:240,Availability,down,down,240,"@Horneth - thanks for the information - this works. . So I had organized my WDL tasks into folders just for organizational purposes (just like you had posted above). Sorry if you have answered this before, but is this going to be supported down the road? Or should is it always going to be recommended to have all WDL tasks are in one folder at the same level? . Thanks again for getting back to me so quickly",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3297#issuecomment-374289503
https://github.com/broadinstitute/cromwell/issues/3305#issuecomment-367423915:95,Deployability,pipeline,pipelines,95,"@geoffjentry in such case I have not idea how I can do anything other than super-simple linear pipelines with wdl: tsv-s with headers cannot be read, read_json does not work, loops do not work, I cannot make even simpliest preprocessing of input arrays or maps with wdl!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3305#issuecomment-367423915
https://github.com/broadinstitute/cromwell/issues/3305#issuecomment-367423915:81,Usability,simpl,simple,81,"@geoffjentry in such case I have not idea how I can do anything other than super-simple linear pipelines with wdl: tsv-s with headers cannot be read, read_json does not work, loops do not work, I cannot make even simpliest preprocessing of input arrays or maps with wdl!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3305#issuecomment-367423915
https://github.com/broadinstitute/cromwell/issues/3305#issuecomment-367423915:213,Usability,simpl,simpliest,213,"@geoffjentry in such case I have not idea how I can do anything other than super-simple linear pipelines with wdl: tsv-s with headers cannot be read, read_json does not work, loops do not work, I cannot make even simpliest preprocessing of input arrays or maps with wdl!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3305#issuecomment-367423915
https://github.com/broadinstitute/cromwell/issues/3305#issuecomment-367444645:64,Energy Efficiency,adapt,adapt,64,"@geoffjentry my labmates prefer TSV-s with headers and I had to adapt, so I tried loops as a solution. Going through Array[Array[String]] and turning it into Array[Map[String, String]] in a loop looked like the best solution for me. I tried both while loops and scatters and both of them could not change the array announced before the loop.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3305#issuecomment-367444645
https://github.com/broadinstitute/cromwell/issues/3305#issuecomment-367444645:64,Modifiability,adapt,adapt,64,"@geoffjentry my labmates prefer TSV-s with headers and I had to adapt, so I tried loops as a solution. Going through Array[Array[String]] and turning it into Array[Map[String, String]] in a loop looked like the best solution for me. I tried both while loops and scatters and both of them could not change the array announced before the loop.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3305#issuecomment-367444645
https://github.com/broadinstitute/cromwell/issues/3305#issuecomment-367445161:438,Modifiability,variab,variables,438,"* This actually has been officially removed from the draft-3 spec on account of it never being implemented by any engine.; * The read_json and write_json (and structs in draft-3) will hopefully ease a lot of the annoyances you're finding here (it's been known to be annoying, we're just finally able to put resources towards easing it now); * All WDL values are immutable as an early design choice for the language. Think of them less as variables in an imperative language and more as write-once declarations in a DAG (ie an execution graph). Say some subsequent task uses (edit: ~~len~~) `i` in your example above. If values are mutable then how can Cromwell know when it's safe to use the value? If you force all tasks to complete before anything after them starts then one slow task cannot run in parallel with several fast tasks.; * I think what you really want is some kind of list comprehension (eg equivalent to python's `[x + 1 for x in x_list]`). You can get something similar by using the implicit gather on a scatter. eg I could map over an array to calculate the ""values plus one"" array like this:; ```wdl; workflow foo {; Array[Int] input_array; scatter(i in input_array) {; plus_ones = i + 1; }; Array[Int] input_array_plus_ones = plus_ones # gathers the results from the plus-one'ing; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3305#issuecomment-367445161
https://github.com/broadinstitute/cromwell/issues/3305#issuecomment-367445161:676,Safety,safe,safe,676,"* This actually has been officially removed from the draft-3 spec on account of it never being implemented by any engine.; * The read_json and write_json (and structs in draft-3) will hopefully ease a lot of the annoyances you're finding here (it's been known to be annoying, we're just finally able to put resources towards easing it now); * All WDL values are immutable as an early design choice for the language. Think of them less as variables in an imperative language and more as write-once declarations in a DAG (ie an execution graph). Say some subsequent task uses (edit: ~~len~~) `i` in your example above. If values are mutable then how can Cromwell know when it's safe to use the value? If you force all tasks to complete before anything after them starts then one slow task cannot run in parallel with several fast tasks.; * I think what you really want is some kind of list comprehension (eg equivalent to python's `[x + 1 for x in x_list]`). You can get something similar by using the implicit gather on a scatter. eg I could map over an array to calculate the ""values plus one"" array like this:; ```wdl; workflow foo {; Array[Int] input_array; scatter(i in input_array) {; plus_ones = i + 1; }; Array[Int] input_array_plus_ones = plus_ones # gathers the results from the plus-one'ing; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3305#issuecomment-367445161
https://github.com/broadinstitute/cromwell/issues/3305#issuecomment-367449569:394,Energy Efficiency,power,powerful,394,"@cjllanwarne you are totally right, if read/write_json worked it would not be such a pain, I would simple write everything to json, give it to a task with some Scala (or whatever language I want) script that return json and then read it to a cromwell Map. >All WDL values are immutable as an early design choice for the language. I do not mind it, I am used to it in Scala, but in Scala I have powerful filter/map/flatMap/foldLeft are you going to give any of them to WDL?. >You can get something similar by using the implicit gather on a scatter. eg I could map over an array to calculate the ""values plus one"" array like this:. Thanks, I did not know that such thing is possible, I thought that all variables declared inside loops/scatter are not visible from outside",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3305#issuecomment-367449569
https://github.com/broadinstitute/cromwell/issues/3305#issuecomment-367449569:701,Modifiability,variab,variables,701,"@cjllanwarne you are totally right, if read/write_json worked it would not be such a pain, I would simple write everything to json, give it to a task with some Scala (or whatever language I want) script that return json and then read it to a cromwell Map. >All WDL values are immutable as an early design choice for the language. I do not mind it, I am used to it in Scala, but in Scala I have powerful filter/map/flatMap/foldLeft are you going to give any of them to WDL?. >You can get something similar by using the implicit gather on a scatter. eg I could map over an array to calculate the ""values plus one"" array like this:. Thanks, I did not know that such thing is possible, I thought that all variables declared inside loops/scatter are not visible from outside",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3305#issuecomment-367449569
https://github.com/broadinstitute/cromwell/issues/3305#issuecomment-367449569:99,Usability,simpl,simple,99,"@cjllanwarne you are totally right, if read/write_json worked it would not be such a pain, I would simple write everything to json, give it to a task with some Scala (or whatever language I want) script that return json and then read it to a cromwell Map. >All WDL values are immutable as an early design choice for the language. I do not mind it, I am used to it in Scala, but in Scala I have powerful filter/map/flatMap/foldLeft are you going to give any of them to WDL?. >You can get something similar by using the implicit gather on a scatter. eg I could map over an array to calculate the ""values plus one"" array like this:. Thanks, I did not know that such thing is possible, I thought that all variables declared inside loops/scatter are not visible from outside",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3305#issuecomment-367449569
https://github.com/broadinstitute/cromwell/issues/3305#issuecomment-367483310:479,Availability,avail,available,479,"@antonkulaga -. 1. If you use read_json the type you get will actually be a WDL `Object`. You should be able to coerce to map but only if the values are all the right type. Also look out for better `object` support with draft 3's `struct`s. 2. you're right, some kind of list comprehension (equivalent to a scala map function) has certainly come up before (they'd need to be spec changes in openWDL, but I'd certainly be happy to see those sorts of PR popping up). 3. for values available outside scatters - it's just like call outputs - we add implicit gatherers for Declarations too. The syntax is ugly but hopefully it works for you until we get some sugar around it in the spec via openwdl üòÑ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3305#issuecomment-367483310
https://github.com/broadinstitute/cromwell/issues/3306#issuecomment-367441100:245,Availability,avail,available,245,"Hey @antonkulaga, are you running this in Cromwell 30?. The good news: this was indeed a known issue for a long time but I believe it's finally been fixed as of https://github.com/broadinstitute/cromwell/pull/3175. ; The bad news: that won't be available until the next Cromwell release. If you're comfortable building from develop you're welcome to do that and try it out!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3306#issuecomment-367441100
https://github.com/broadinstitute/cromwell/issues/3306#issuecomment-367441100:279,Deployability,release,release,279,"Hey @antonkulaga, are you running this in Cromwell 30?. The good news: this was indeed a known issue for a long time but I believe it's finally been fixed as of https://github.com/broadinstitute/cromwell/pull/3175. ; The bad news: that won't be available until the next Cromwell release. If you're comfortable building from develop you're welcome to do that and try it out!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3306#issuecomment-367441100
https://github.com/broadinstitute/cromwell/issues/3306#issuecomment-367442607:39,Deployability,release,release,39,"@cjllanwarne I run it on cromwell 30.2 release, the latest release at the moment",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3306#issuecomment-367442607
https://github.com/broadinstitute/cromwell/issues/3306#issuecomment-367442607:59,Deployability,release,release,59,"@cjllanwarne I run it on cromwell 30.2 release, the latest release at the moment",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3306#issuecomment-367442607
https://github.com/broadinstitute/cromwell/issues/3306#issuecomment-367443014:151,Deployability,release,release,151,"@antonkulaga What @cjllanwarne means is that if you build off of the `develop` branch it should work for you. If you're ok with waiting until the next release (likely 31, potentially 30.3), it'll also be fixed for you.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3306#issuecomment-367443014
https://github.com/broadinstitute/cromwell/issues/3306#issuecomment-367445273:42,Deployability,release,release,42,">If you're ok with waiting until the next release (likely 31, potentially 30.3), it'll also be fixed for you. Everything depends on how soon you are agoing to publish 30.3 If it is a week, I am ok to wait, if it will take longer - I will build from source",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3306#issuecomment-367445273
https://github.com/broadinstitute/cromwell/issues/3306#issuecomment-367445273:121,Integrability,depend,depends,121,">If you're ok with waiting until the next release (likely 31, potentially 30.3), it'll also be fixed for you. Everything depends on how soon you are agoing to publish 30.3 If it is a week, I am ok to wait, if it will take longer - I will build from source",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3306#issuecomment-367445273
https://github.com/broadinstitute/cromwell/issues/3306#issuecomment-367445955:83,Deployability,release,releases,83,@antonkulaga It'll probably be > 1 week. We can't predict the frequency of the dot releases as they're almost always in response to some fire that erupts in production.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3306#issuecomment-367445955
https://github.com/broadinstitute/cromwell/issues/3306#issuecomment-367445955:50,Safety,predict,predict,50,@antonkulaga It'll probably be > 1 week. We can't predict the frequency of the dot releases as they're almost always in response to some fire that erupts in production.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3306#issuecomment-367445955
https://github.com/broadinstitute/cromwell/issues/3306#issuecomment-370112127:679,Availability,ERROR,ERROR,679,"Looks like read_json in current trunk still has some issues.; When I give a json like this:; ```json; {; ""Homo sapiens"": {; ""transcriptome"" : ""/pipelines/indexes/HUMAN/27/gencode.v27.transcripts.fa"",; ""gtf"": ""/pipelines/indexes/HUMAN/27/"",; ""salmon"": ""/pipelines/indexes/HUMAN/27/salmon""; },; ""Mus musculus"": {; ""transcriptome"" : ""/pipelines/indexes/MOUSE/M16/gencode.vM16.transcripts.fa"",; ""gtf"": ""/pipelines/indexes/MOUSE/M16/gencode.vM16.annotation.gtf"",; ""salmon"": ""/pipelines/indexes/MOUSE/M16/salmon""; }; }; ```; with wdl like this; ```; Map[String, Map[String, String]] indexes = read_json(references) ; ```; I get:; ```; Workflow input processing failed; WorkflowFailure(ERROR: indexes is declared as a Map[String, Map[String, String]] but the expression evaluates to a Object: Map[String, Map[String, String]] indexes = read_json(references) ^ ,List()); ```; I do not get what is wrong there, I've tried different type combinations.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3306#issuecomment-370112127
https://github.com/broadinstitute/cromwell/issues/3306#issuecomment-370112127:144,Deployability,pipeline,pipelines,144,"Looks like read_json in current trunk still has some issues.; When I give a json like this:; ```json; {; ""Homo sapiens"": {; ""transcriptome"" : ""/pipelines/indexes/HUMAN/27/gencode.v27.transcripts.fa"",; ""gtf"": ""/pipelines/indexes/HUMAN/27/"",; ""salmon"": ""/pipelines/indexes/HUMAN/27/salmon""; },; ""Mus musculus"": {; ""transcriptome"" : ""/pipelines/indexes/MOUSE/M16/gencode.vM16.transcripts.fa"",; ""gtf"": ""/pipelines/indexes/MOUSE/M16/gencode.vM16.annotation.gtf"",; ""salmon"": ""/pipelines/indexes/MOUSE/M16/salmon""; }; }; ```; with wdl like this; ```; Map[String, Map[String, String]] indexes = read_json(references) ; ```; I get:; ```; Workflow input processing failed; WorkflowFailure(ERROR: indexes is declared as a Map[String, Map[String, String]] but the expression evaluates to a Object: Map[String, Map[String, String]] indexes = read_json(references) ^ ,List()); ```; I do not get what is wrong there, I've tried different type combinations.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3306#issuecomment-370112127
https://github.com/broadinstitute/cromwell/issues/3306#issuecomment-370112127:210,Deployability,pipeline,pipelines,210,"Looks like read_json in current trunk still has some issues.; When I give a json like this:; ```json; {; ""Homo sapiens"": {; ""transcriptome"" : ""/pipelines/indexes/HUMAN/27/gencode.v27.transcripts.fa"",; ""gtf"": ""/pipelines/indexes/HUMAN/27/"",; ""salmon"": ""/pipelines/indexes/HUMAN/27/salmon""; },; ""Mus musculus"": {; ""transcriptome"" : ""/pipelines/indexes/MOUSE/M16/gencode.vM16.transcripts.fa"",; ""gtf"": ""/pipelines/indexes/MOUSE/M16/gencode.vM16.annotation.gtf"",; ""salmon"": ""/pipelines/indexes/MOUSE/M16/salmon""; }; }; ```; with wdl like this; ```; Map[String, Map[String, String]] indexes = read_json(references) ; ```; I get:; ```; Workflow input processing failed; WorkflowFailure(ERROR: indexes is declared as a Map[String, Map[String, String]] but the expression evaluates to a Object: Map[String, Map[String, String]] indexes = read_json(references) ^ ,List()); ```; I do not get what is wrong there, I've tried different type combinations.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3306#issuecomment-370112127
https://github.com/broadinstitute/cromwell/issues/3306#issuecomment-370112127:253,Deployability,pipeline,pipelines,253,"Looks like read_json in current trunk still has some issues.; When I give a json like this:; ```json; {; ""Homo sapiens"": {; ""transcriptome"" : ""/pipelines/indexes/HUMAN/27/gencode.v27.transcripts.fa"",; ""gtf"": ""/pipelines/indexes/HUMAN/27/"",; ""salmon"": ""/pipelines/indexes/HUMAN/27/salmon""; },; ""Mus musculus"": {; ""transcriptome"" : ""/pipelines/indexes/MOUSE/M16/gencode.vM16.transcripts.fa"",; ""gtf"": ""/pipelines/indexes/MOUSE/M16/gencode.vM16.annotation.gtf"",; ""salmon"": ""/pipelines/indexes/MOUSE/M16/salmon""; }; }; ```; with wdl like this; ```; Map[String, Map[String, String]] indexes = read_json(references) ; ```; I get:; ```; Workflow input processing failed; WorkflowFailure(ERROR: indexes is declared as a Map[String, Map[String, String]] but the expression evaluates to a Object: Map[String, Map[String, String]] indexes = read_json(references) ^ ,List()); ```; I do not get what is wrong there, I've tried different type combinations.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3306#issuecomment-370112127
https://github.com/broadinstitute/cromwell/issues/3306#issuecomment-370112127:332,Deployability,pipeline,pipelines,332,"Looks like read_json in current trunk still has some issues.; When I give a json like this:; ```json; {; ""Homo sapiens"": {; ""transcriptome"" : ""/pipelines/indexes/HUMAN/27/gencode.v27.transcripts.fa"",; ""gtf"": ""/pipelines/indexes/HUMAN/27/"",; ""salmon"": ""/pipelines/indexes/HUMAN/27/salmon""; },; ""Mus musculus"": {; ""transcriptome"" : ""/pipelines/indexes/MOUSE/M16/gencode.vM16.transcripts.fa"",; ""gtf"": ""/pipelines/indexes/MOUSE/M16/gencode.vM16.annotation.gtf"",; ""salmon"": ""/pipelines/indexes/MOUSE/M16/salmon""; }; }; ```; with wdl like this; ```; Map[String, Map[String, String]] indexes = read_json(references) ; ```; I get:; ```; Workflow input processing failed; WorkflowFailure(ERROR: indexes is declared as a Map[String, Map[String, String]] but the expression evaluates to a Object: Map[String, Map[String, String]] indexes = read_json(references) ^ ,List()); ```; I do not get what is wrong there, I've tried different type combinations.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3306#issuecomment-370112127
https://github.com/broadinstitute/cromwell/issues/3306#issuecomment-370112127:400,Deployability,pipeline,pipelines,400,"Looks like read_json in current trunk still has some issues.; When I give a json like this:; ```json; {; ""Homo sapiens"": {; ""transcriptome"" : ""/pipelines/indexes/HUMAN/27/gencode.v27.transcripts.fa"",; ""gtf"": ""/pipelines/indexes/HUMAN/27/"",; ""salmon"": ""/pipelines/indexes/HUMAN/27/salmon""; },; ""Mus musculus"": {; ""transcriptome"" : ""/pipelines/indexes/MOUSE/M16/gencode.vM16.transcripts.fa"",; ""gtf"": ""/pipelines/indexes/MOUSE/M16/gencode.vM16.annotation.gtf"",; ""salmon"": ""/pipelines/indexes/MOUSE/M16/salmon""; }; }; ```; with wdl like this; ```; Map[String, Map[String, String]] indexes = read_json(references) ; ```; I get:; ```; Workflow input processing failed; WorkflowFailure(ERROR: indexes is declared as a Map[String, Map[String, String]] but the expression evaluates to a Object: Map[String, Map[String, String]] indexes = read_json(references) ^ ,List()); ```; I do not get what is wrong there, I've tried different type combinations.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3306#issuecomment-370112127
https://github.com/broadinstitute/cromwell/issues/3306#issuecomment-370112127:471,Deployability,pipeline,pipelines,471,"Looks like read_json in current trunk still has some issues.; When I give a json like this:; ```json; {; ""Homo sapiens"": {; ""transcriptome"" : ""/pipelines/indexes/HUMAN/27/gencode.v27.transcripts.fa"",; ""gtf"": ""/pipelines/indexes/HUMAN/27/"",; ""salmon"": ""/pipelines/indexes/HUMAN/27/salmon""; },; ""Mus musculus"": {; ""transcriptome"" : ""/pipelines/indexes/MOUSE/M16/gencode.vM16.transcripts.fa"",; ""gtf"": ""/pipelines/indexes/MOUSE/M16/gencode.vM16.annotation.gtf"",; ""salmon"": ""/pipelines/indexes/MOUSE/M16/salmon""; }; }; ```; with wdl like this; ```; Map[String, Map[String, String]] indexes = read_json(references) ; ```; I get:; ```; Workflow input processing failed; WorkflowFailure(ERROR: indexes is declared as a Map[String, Map[String, String]] but the expression evaluates to a Object: Map[String, Map[String, String]] indexes = read_json(references) ^ ,List()); ```; I do not get what is wrong there, I've tried different type combinations.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3306#issuecomment-370112127
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368074313:212,Availability,error,error,212,"That is surprising, the order should be preserved. Is the order you're seeing consistently the same or does it randomly change if you run it several times ?; If you have a small set of inputs that reproduces the error that would be helpful too.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368074313
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:511,Availability,echo,echo,511,"I reviewed my script and I realized that the scatter is done in a more complicated way. Here is a toy-example of what I am doing:. ```wdl; workflow TestWorkflow {; Array[Int] my_array; ; call GenerateMap {; input:; i = length(my_array); }; scatter (entry in GenerateMap.map_output) {; call CopyFile {; input:; file = entry.right; }; }; ; output {; Array[Pair[Int, Array[File]]] final_out = zip(my_array, CopyFile.out); }; }. task GenerateMap {; Int i; command <<<; for n in `seq 1 ${i}`; do \; touch $n.txt; \; echo -e ""$n\t$n.txt"" >> my_map.txt; \; done; >>>. output {; Map[Int, File] map_output = read_map(""my_map.txt""); }; }. task CopyFile {; File file. String copy_file = basename(file) + "".copy""; command <<<; cp ${file} ${copy_file}; >>>. output {; Array[File] out = [""${file}"", ""${copy_file}""]; }; }; ```. And my outputs after running with the input array with `[1,2,3,4,5,6,7,8,9]` are the following:. ```json; {; ""outputs"": {; ""TestWorkflow.final_out"": [{; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/10.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-0/execution/10.txt.copy""],; ""left"": 1; }, {; ""left"": 2,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/4.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-1/execution/4.txt.copy""]; }, {; ""left"": 3,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/6.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-2/execution/6.txt.copy""]; }, {; ""left"": 4,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:4375,Performance,perform,performed,4375,"Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-6/execution/5.txt.copy""]; }, {; ""left"": 8,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/8.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-7/execution/8.txt.copy""]; }, {; ""left"": 9,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/9.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-8/execution/9.txt.copy""]; }, {; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/2.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-9/execution/2.txt.copy""],; ""left"": 10; }]; },; ""id"": ""67295907-5ffe-486e-8c7d-2bfdc5c5f97d""; }; ```. This results are always the same between runs. It looks more like a problem in the way that the maps are handled, either one or both of this:. * `read_map` initializes an unsorted map, which does not preserve the file order when scatter is performed; * Scatter a map does not preserve the order of iteration, even if the `read_map` maintains the insertion order. I am not sure if in a `Map` the order is supposed to be preserved, but it would be nice in the case something like this toy-script works to keep an ordered map. I can work around this by using two files in `GenerateMap` (one for the numbers and one for the files), read both with `read_lines` and then `zip` both of them to return an `Array[Pair[Int, File]]` instead of a map. Nevertheless, I think that this would be nicer if it works out-of-the-box (e.g., maintaining order of map from a file).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:148,Testability,Test,TestWorkflow,148,"I reviewed my script and I realized that the scatter is done in a more complicated way. Here is a toy-example of what I am doing:. ```wdl; workflow TestWorkflow {; Array[Int] my_array; ; call GenerateMap {; input:; i = length(my_array); }; scatter (entry in GenerateMap.map_output) {; call CopyFile {; input:; file = entry.right; }; }; ; output {; Array[Pair[Int, Array[File]]] final_out = zip(my_array, CopyFile.out); }; }. task GenerateMap {; Int i; command <<<; for n in `seq 1 ${i}`; do \; touch $n.txt; \; echo -e ""$n\t$n.txt"" >> my_map.txt; \; done; >>>. output {; Map[Int, File] map_output = read_map(""my_map.txt""); }; }. task CopyFile {; File file. String copy_file = basename(file) + "".copy""; command <<<; cp ${file} ${copy_file}; >>>. output {; Array[File] out = [""${file}"", ""${copy_file}""]; }; }; ```. And my outputs after running with the input array with `[1,2,3,4,5,6,7,8,9]` are the following:. ```json; {; ""outputs"": {; ""TestWorkflow.final_out"": [{; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/10.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-0/execution/10.txt.copy""],; ""left"": 1; }, {; ""left"": 2,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/4.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-1/execution/4.txt.copy""]; }, {; ""left"": 3,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/6.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-2/execution/6.txt.copy""]; }, {; ""left"": 4,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:937,Testability,Test,TestWorkflow,937,"I reviewed my script and I realized that the scatter is done in a more complicated way. Here is a toy-example of what I am doing:. ```wdl; workflow TestWorkflow {; Array[Int] my_array; ; call GenerateMap {; input:; i = length(my_array); }; scatter (entry in GenerateMap.map_output) {; call CopyFile {; input:; file = entry.right; }; }; ; output {; Array[Pair[Int, Array[File]]] final_out = zip(my_array, CopyFile.out); }; }. task GenerateMap {; Int i; command <<<; for n in `seq 1 ${i}`; do \; touch $n.txt; \; echo -e ""$n\t$n.txt"" >> my_map.txt; \; done; >>>. output {; Map[Int, File] map_output = read_map(""my_map.txt""); }; }. task CopyFile {; File file. String copy_file = basename(file) + "".copy""; command <<<; cp ${file} ${copy_file}; >>>. output {; Array[File] out = [""${file}"", ""${copy_file}""]; }; }; ```. And my outputs after running with the input array with `[1,2,3,4,5,6,7,8,9]` are the following:. ```json; {; ""outputs"": {; ""TestWorkflow.final_out"": [{; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/10.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-0/execution/10.txt.copy""],; ""left"": 1; }, {; ""left"": 2,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/4.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-1/execution/4.txt.copy""]; }, {; ""left"": 3,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/6.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-2/execution/6.txt.copy""]; }, {; ""left"": 4,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:999,Testability,test,test-cromwell-map,999,"ealized that the scatter is done in a more complicated way. Here is a toy-example of what I am doing:. ```wdl; workflow TestWorkflow {; Array[Int] my_array; ; call GenerateMap {; input:; i = length(my_array); }; scatter (entry in GenerateMap.map_output) {; call CopyFile {; input:; file = entry.right; }; }; ; output {; Array[Pair[Int, Array[File]]] final_out = zip(my_array, CopyFile.out); }; }. task GenerateMap {; Int i; command <<<; for n in `seq 1 ${i}`; do \; touch $n.txt; \; echo -e ""$n\t$n.txt"" >> my_map.txt; \; done; >>>. output {; Map[Int, File] map_output = read_map(""my_map.txt""); }; }. task CopyFile {; File file. String copy_file = basename(file) + "".copy""; command <<<; cp ${file} ${copy_file}; >>>. output {; Array[File] out = [""${file}"", ""${copy_file}""]; }; }; ```. And my outputs after running with the input array with `[1,2,3,4,5,6,7,8,9]` are the following:. ```json; {; ""outputs"": {; ""TestWorkflow.final_out"": [{; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/10.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-0/execution/10.txt.copy""],; ""left"": 1; }, {; ""left"": 2,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/4.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-1/execution/4.txt.copy""]; }, {; ""left"": 3,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/6.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-2/execution/6.txt.copy""]; }, {; ""left"": 4,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:1027,Testability,Test,TestWorkflow,1027,"ealized that the scatter is done in a more complicated way. Here is a toy-example of what I am doing:. ```wdl; workflow TestWorkflow {; Array[Int] my_array; ; call GenerateMap {; input:; i = length(my_array); }; scatter (entry in GenerateMap.map_output) {; call CopyFile {; input:; file = entry.right; }; }; ; output {; Array[Pair[Int, Array[File]]] final_out = zip(my_array, CopyFile.out); }; }. task GenerateMap {; Int i; command <<<; for n in `seq 1 ${i}`; do \; touch $n.txt; \; echo -e ""$n\t$n.txt"" >> my_map.txt; \; done; >>>. output {; Map[Int, File] map_output = read_map(""my_map.txt""); }; }. task CopyFile {; File file. String copy_file = basename(file) + "".copy""; command <<<; cp ${file} ${copy_file}; >>>. output {; Array[File] out = [""${file}"", ""${copy_file}""]; }; }; ```. And my outputs after running with the input array with `[1,2,3,4,5,6,7,8,9]` are the following:. ```json; {; ""outputs"": {; ""TestWorkflow.final_out"": [{; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/10.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-0/execution/10.txt.copy""],; ""left"": 1; }, {; ""left"": 2,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/4.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-1/execution/4.txt.copy""]; }, {; ""left"": 3,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/6.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-2/execution/6.txt.copy""]; }, {; ""left"": 4,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:1136,Testability,test,test-cromwell-map,1136,"array; ; call GenerateMap {; input:; i = length(my_array); }; scatter (entry in GenerateMap.map_output) {; call CopyFile {; input:; file = entry.right; }; }; ; output {; Array[Pair[Int, Array[File]]] final_out = zip(my_array, CopyFile.out); }; }. task GenerateMap {; Int i; command <<<; for n in `seq 1 ${i}`; do \; touch $n.txt; \; echo -e ""$n\t$n.txt"" >> my_map.txt; \; done; >>>. output {; Map[Int, File] map_output = read_map(""my_map.txt""); }; }. task CopyFile {; File file. String copy_file = basename(file) + "".copy""; command <<<; cp ${file} ${copy_file}; >>>. output {; Array[File] out = [""${file}"", ""${copy_file}""]; }; }; ```. And my outputs after running with the input array with `[1,2,3,4,5,6,7,8,9]` are the following:. ```json; {; ""outputs"": {; ""TestWorkflow.final_out"": [{; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/10.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-0/execution/10.txt.copy""],; ""left"": 1; }, {; ""left"": 2,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/4.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-1/execution/4.txt.copy""]; }, {; ""left"": 3,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/6.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-2/execution/6.txt.copy""]; }, {; ""left"": 4,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/7.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shar",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:1164,Testability,Test,TestWorkflow,1164,"array; ; call GenerateMap {; input:; i = length(my_array); }; scatter (entry in GenerateMap.map_output) {; call CopyFile {; input:; file = entry.right; }; }; ; output {; Array[Pair[Int, Array[File]]] final_out = zip(my_array, CopyFile.out); }; }. task GenerateMap {; Int i; command <<<; for n in `seq 1 ${i}`; do \; touch $n.txt; \; echo -e ""$n\t$n.txt"" >> my_map.txt; \; done; >>>. output {; Map[Int, File] map_output = read_map(""my_map.txt""); }; }. task CopyFile {; File file. String copy_file = basename(file) + "".copy""; command <<<; cp ${file} ${copy_file}; >>>. output {; Array[File] out = [""${file}"", ""${copy_file}""]; }; }; ```. And my outputs after running with the input array with `[1,2,3,4,5,6,7,8,9]` are the following:. ```json; {; ""outputs"": {; ""TestWorkflow.final_out"": [{; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/10.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-0/execution/10.txt.copy""],; ""left"": 1; }, {; ""left"": 2,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/4.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-1/execution/4.txt.copy""]; }, {; ""left"": 3,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/6.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-2/execution/6.txt.copy""]; }, {; ""left"": 4,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/7.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shar",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:1324,Testability,test,test-cromwell-map,1324,"ut {; Array[Pair[Int, Array[File]]] final_out = zip(my_array, CopyFile.out); }; }. task GenerateMap {; Int i; command <<<; for n in `seq 1 ${i}`; do \; touch $n.txt; \; echo -e ""$n\t$n.txt"" >> my_map.txt; \; done; >>>. output {; Map[Int, File] map_output = read_map(""my_map.txt""); }; }. task CopyFile {; File file. String copy_file = basename(file) + "".copy""; command <<<; cp ${file} ${copy_file}; >>>. output {; Array[File] out = [""${file}"", ""${copy_file}""]; }; }; ```. And my outputs after running with the input array with `[1,2,3,4,5,6,7,8,9]` are the following:. ```json; {; ""outputs"": {; ""TestWorkflow.final_out"": [{; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/10.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-0/execution/10.txt.copy""],; ""left"": 1; }, {; ""left"": 2,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/4.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-1/execution/4.txt.copy""]; }, {; ""left"": 3,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/6.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-2/execution/6.txt.copy""]; }, {; ""left"": 4,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/7.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-3/execution/7.txt.copy""]; }, {; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/ex",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:1352,Testability,Test,TestWorkflow,1352,"ut {; Array[Pair[Int, Array[File]]] final_out = zip(my_array, CopyFile.out); }; }. task GenerateMap {; Int i; command <<<; for n in `seq 1 ${i}`; do \; touch $n.txt; \; echo -e ""$n\t$n.txt"" >> my_map.txt; \; done; >>>. output {; Map[Int, File] map_output = read_map(""my_map.txt""); }; }. task CopyFile {; File file. String copy_file = basename(file) + "".copy""; command <<<; cp ${file} ${copy_file}; >>>. output {; Array[File] out = [""${file}"", ""${copy_file}""]; }; }; ```. And my outputs after running with the input array with `[1,2,3,4,5,6,7,8,9]` are the following:. ```json; {; ""outputs"": {; ""TestWorkflow.final_out"": [{; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/10.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-0/execution/10.txt.copy""],; ""left"": 1; }, {; ""left"": 2,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/4.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-1/execution/4.txt.copy""]; }, {; ""left"": 3,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/6.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-2/execution/6.txt.copy""]; }, {; ""left"": 4,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/7.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-3/execution/7.txt.copy""]; }, {; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/ex",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:1460,Testability,test,test-cromwell-map,1460,"n.txt; \; echo -e ""$n\t$n.txt"" >> my_map.txt; \; done; >>>. output {; Map[Int, File] map_output = read_map(""my_map.txt""); }; }. task CopyFile {; File file. String copy_file = basename(file) + "".copy""; command <<<; cp ${file} ${copy_file}; >>>. output {; Array[File] out = [""${file}"", ""${copy_file}""]; }; }; ```. And my outputs after running with the input array with `[1,2,3,4,5,6,7,8,9]` are the following:. ```json; {; ""outputs"": {; ""TestWorkflow.final_out"": [{; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/10.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-0/execution/10.txt.copy""],; ""left"": 1; }, {; ""left"": 2,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/4.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-1/execution/4.txt.copy""]; }, {; ""left"": 3,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/6.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-2/execution/6.txt.copy""]; }, {; ""left"": 4,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/7.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-3/execution/7.txt.copy""]; }, {; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/1.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-4/execution/1.txt.copy""",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:1488,Testability,Test,TestWorkflow,1488,"n.txt; \; echo -e ""$n\t$n.txt"" >> my_map.txt; \; done; >>>. output {; Map[Int, File] map_output = read_map(""my_map.txt""); }; }. task CopyFile {; File file. String copy_file = basename(file) + "".copy""; command <<<; cp ${file} ${copy_file}; >>>. output {; Array[File] out = [""${file}"", ""${copy_file}""]; }; }; ```. And my outputs after running with the input array with `[1,2,3,4,5,6,7,8,9]` are the following:. ```json; {; ""outputs"": {; ""TestWorkflow.final_out"": [{; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/10.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-0/execution/10.txt.copy""],; ""left"": 1; }, {; ""left"": 2,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/4.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-1/execution/4.txt.copy""]; }, {; ""left"": 3,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/6.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-2/execution/6.txt.copy""]; }, {; ""left"": 4,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/7.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-3/execution/7.txt.copy""]; }, {; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/1.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-4/execution/1.txt.copy""",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:1635,Testability,test,test-cromwell-map,1635,"ring copy_file = basename(file) + "".copy""; command <<<; cp ${file} ${copy_file}; >>>. output {; Array[File] out = [""${file}"", ""${copy_file}""]; }; }; ```. And my outputs after running with the input array with `[1,2,3,4,5,6,7,8,9]` are the following:. ```json; {; ""outputs"": {; ""TestWorkflow.final_out"": [{; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/10.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-0/execution/10.txt.copy""],; ""left"": 1; }, {; ""left"": 2,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/4.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-1/execution/4.txt.copy""]; }, {; ""left"": 3,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/6.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-2/execution/6.txt.copy""]; }, {; ""left"": 4,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/7.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-3/execution/7.txt.copy""]; }, {; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/1.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-4/execution/1.txt.copy""],; ""left"": 5; }, {; ""left"": 6,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-Generate",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:1663,Testability,Test,TestWorkflow,1663,"ring copy_file = basename(file) + "".copy""; command <<<; cp ${file} ${copy_file}; >>>. output {; Array[File] out = [""${file}"", ""${copy_file}""]; }; }; ```. And my outputs after running with the input array with `[1,2,3,4,5,6,7,8,9]` are the following:. ```json; {; ""outputs"": {; ""TestWorkflow.final_out"": [{; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/10.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-0/execution/10.txt.copy""],; ""left"": 1; }, {; ""left"": 2,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/4.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-1/execution/4.txt.copy""]; }, {; ""left"": 3,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/6.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-2/execution/6.txt.copy""]; }, {; ""left"": 4,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/7.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-3/execution/7.txt.copy""]; }, {; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/1.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-4/execution/1.txt.copy""],; ""left"": 5; }, {; ""left"": 6,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-Generate",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:1771,Testability,test,test-cromwell-map,1771," And my outputs after running with the input array with `[1,2,3,4,5,6,7,8,9]` are the following:. ```json; {; ""outputs"": {; ""TestWorkflow.final_out"": [{; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/10.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-0/execution/10.txt.copy""],; ""left"": 1; }, {; ""left"": 2,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/4.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-1/execution/4.txt.copy""]; }, {; ""left"": 3,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/6.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-2/execution/6.txt.copy""]; }, {; ""left"": 4,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/7.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-3/execution/7.txt.copy""]; }, {; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/1.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-4/execution/1.txt.copy""],; ""left"": 5; }, {; ""left"": 6,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/3.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-5/execution",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:1799,Testability,Test,TestWorkflow,1799," And my outputs after running with the input array with `[1,2,3,4,5,6,7,8,9]` are the following:. ```json; {; ""outputs"": {; ""TestWorkflow.final_out"": [{; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/10.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-0/execution/10.txt.copy""],; ""left"": 1; }, {; ""left"": 2,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/4.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-1/execution/4.txt.copy""]; }, {; ""left"": 3,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/6.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-2/execution/6.txt.copy""]; }, {; ""left"": 4,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/7.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-3/execution/7.txt.copy""]; }, {; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/1.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-4/execution/1.txt.copy""],; ""left"": 5; }, {; ""left"": 6,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/3.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-5/execution",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:1946,Testability,test,test-cromwell-map,1946,"ht"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/10.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-0/execution/10.txt.copy""],; ""left"": 1; }, {; ""left"": 2,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/4.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-1/execution/4.txt.copy""]; }, {; ""left"": 3,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/6.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-2/execution/6.txt.copy""]; }, {; ""left"": 4,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/7.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-3/execution/7.txt.copy""]; }, {; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/1.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-4/execution/1.txt.copy""],; ""left"": 5; }, {; ""left"": 6,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/3.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-5/execution/3.txt.copy""]; }, {; ""left"": 7,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-Generate",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:1974,Testability,Test,TestWorkflow,1974,"ht"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/10.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-0/execution/10.txt.copy""],; ""left"": 1; }, {; ""left"": 2,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/4.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-1/execution/4.txt.copy""]; }, {; ""left"": 3,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/6.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-2/execution/6.txt.copy""]; }, {; ""left"": 4,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/7.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-3/execution/7.txt.copy""]; }, {; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/1.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-4/execution/1.txt.copy""],; ""left"": 5; }, {; ""left"": 6,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/3.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-5/execution/3.txt.copy""]; }, {; ""left"": 7,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-Generate",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:2082,Testability,test,test-cromwell-map,2082,"niel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-0/execution/10.txt.copy""],; ""left"": 1; }, {; ""left"": 2,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/4.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-1/execution/4.txt.copy""]; }, {; ""left"": 3,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/6.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-2/execution/6.txt.copy""]; }, {; ""left"": 4,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/7.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-3/execution/7.txt.copy""]; }, {; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/1.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-4/execution/1.txt.copy""],; ""left"": 5; }, {; ""left"": 6,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/3.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-5/execution/3.txt.copy""]; }, {; ""left"": 7,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/5.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-6/execution",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:2110,Testability,Test,TestWorkflow,2110,"niel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-0/execution/10.txt.copy""],; ""left"": 1; }, {; ""left"": 2,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/4.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-1/execution/4.txt.copy""]; }, {; ""left"": 3,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/6.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-2/execution/6.txt.copy""]; }, {; ""left"": 4,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/7.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-3/execution/7.txt.copy""]; }, {; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/1.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-4/execution/1.txt.copy""],; ""left"": 5; }, {; ""left"": 6,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/3.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-5/execution/3.txt.copy""]; }, {; ""left"": 7,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/5.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-6/execution",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:2245,Testability,test,test-cromwell-map,2245," {; ""left"": 2,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/4.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-1/execution/4.txt.copy""]; }, {; ""left"": 3,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/6.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-2/execution/6.txt.copy""]; }, {; ""left"": 4,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/7.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-3/execution/7.txt.copy""]; }, {; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/1.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-4/execution/1.txt.copy""],; ""left"": 5; }, {; ""left"": 6,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/3.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-5/execution/3.txt.copy""]; }, {; ""left"": 7,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/5.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-6/execution/5.txt.copy""]; }, {; ""left"": 8,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-Ge",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:2273,Testability,Test,TestWorkflow,2273," {; ""left"": 2,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/4.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-1/execution/4.txt.copy""]; }, {; ""left"": 3,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/6.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-2/execution/6.txt.copy""]; }, {; ""left"": 4,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/7.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-3/execution/7.txt.copy""]; }, {; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/1.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-4/execution/1.txt.copy""],; ""left"": 5; }, {; ""left"": 6,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/3.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-5/execution/3.txt.copy""]; }, {; ""left"": 7,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/5.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-6/execution/5.txt.copy""]; }, {; ""left"": 8,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-Ge",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:2381,Testability,test,test-cromwell-map,2381,"cution/4.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-1/execution/4.txt.copy""]; }, {; ""left"": 3,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/6.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-2/execution/6.txt.copy""]; }, {; ""left"": 4,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/7.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-3/execution/7.txt.copy""]; }, {; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/1.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-4/execution/1.txt.copy""],; ""left"": 5; }, {; ""left"": 6,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/3.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-5/execution/3.txt.copy""]; }, {; ""left"": 7,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/5.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-6/execution/5.txt.copy""]; }, {; ""left"": 8,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/8.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:2409,Testability,Test,TestWorkflow,2409,"cution/4.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-1/execution/4.txt.copy""]; }, {; ""left"": 3,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/6.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-2/execution/6.txt.copy""]; }, {; ""left"": 4,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/7.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-3/execution/7.txt.copy""]; }, {; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/1.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-4/execution/1.txt.copy""],; ""left"": 5; }, {; ""left"": 6,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/3.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-5/execution/3.txt.copy""]; }, {; ""left"": 7,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/5.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-6/execution/5.txt.copy""]; }, {; ""left"": 8,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/8.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:2568,Testability,test,test-cromwell-map,2568," {; ""left"": 3,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/6.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-2/execution/6.txt.copy""]; }, {; ""left"": 4,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/7.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-3/execution/7.txt.copy""]; }, {; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/1.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-4/execution/1.txt.copy""],; ""left"": 5; }, {; ""left"": 6,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/3.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-5/execution/3.txt.copy""]; }, {; ""left"": 7,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/5.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-6/execution/5.txt.copy""]; }, {; ""left"": 8,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/8.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-7/execution/8.txt.copy""]; }, {; ""left"": 9,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-Ge",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:2596,Testability,Test,TestWorkflow,2596," {; ""left"": 3,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/6.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-2/execution/6.txt.copy""]; }, {; ""left"": 4,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/7.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-3/execution/7.txt.copy""]; }, {; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/1.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-4/execution/1.txt.copy""],; ""left"": 5; }, {; ""left"": 6,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/3.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-5/execution/3.txt.copy""]; }, {; ""left"": 7,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/5.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-6/execution/5.txt.copy""]; }, {; ""left"": 8,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/8.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-7/execution/8.txt.copy""]; }, {; ""left"": 9,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-Ge",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:2704,Testability,test,test-cromwell-map,2704,""", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-2/execution/6.txt.copy""]; }, {; ""left"": 4,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/7.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-3/execution/7.txt.copy""]; }, {; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/1.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-4/execution/1.txt.copy""],; ""left"": 5; }, {; ""left"": 6,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/3.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-5/execution/3.txt.copy""]; }, {; ""left"": 7,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/5.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-6/execution/5.txt.copy""]; }, {; ""left"": 8,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/8.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-7/execution/8.txt.copy""]; }, {; ""left"": 9,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/9.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-8/execution",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:2732,Testability,Test,TestWorkflow,2732,""", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-2/execution/6.txt.copy""]; }, {; ""left"": 4,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/7.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-3/execution/7.txt.copy""]; }, {; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/1.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-4/execution/1.txt.copy""],; ""left"": 5; }, {; ""left"": 6,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/3.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-5/execution/3.txt.copy""]; }, {; ""left"": 7,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/5.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-6/execution/5.txt.copy""]; }, {; ""left"": 8,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/8.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-7/execution/8.txt.copy""]; }, {; ""left"": 9,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/9.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-8/execution",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:2879,Testability,test,test-cromwell-map,2879,"eft"": 4,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/7.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-3/execution/7.txt.copy""]; }, {; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/1.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-4/execution/1.txt.copy""],; ""left"": 5; }, {; ""left"": 6,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/3.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-5/execution/3.txt.copy""]; }, {; ""left"": 7,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/5.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-6/execution/5.txt.copy""]; }, {; ""left"": 8,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/8.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-7/execution/8.txt.copy""]; }, {; ""left"": 9,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/9.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-8/execution/9.txt.copy""]; }, {; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/executio",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:2907,Testability,Test,TestWorkflow,2907,"eft"": 4,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/7.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-3/execution/7.txt.copy""]; }, {; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/1.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-4/execution/1.txt.copy""],; ""left"": 5; }, {; ""left"": 6,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/3.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-5/execution/3.txt.copy""]; }, {; ""left"": 7,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/5.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-6/execution/5.txt.copy""]; }, {; ""left"": 8,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/8.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-7/execution/8.txt.copy""]; }, {; ""left"": 9,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/9.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-8/execution/9.txt.copy""]; }, {; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/executio",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:3015,Testability,test,test-cromwell-map,3015,""", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-3/execution/7.txt.copy""]; }, {; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/1.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-4/execution/1.txt.copy""],; ""left"": 5; }, {; ""left"": 6,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/3.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-5/execution/3.txt.copy""]; }, {; ""left"": 7,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/5.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-6/execution/5.txt.copy""]; }, {; ""left"": 8,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/8.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-7/execution/8.txt.copy""]; }, {; ""left"": 9,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/9.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-8/execution/9.txt.copy""]; }, {; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/2.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-9/execution/2.txt.copy""",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:3043,Testability,Test,TestWorkflow,3043,""", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-3/execution/7.txt.copy""]; }, {; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/1.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-4/execution/1.txt.copy""],; ""left"": 5; }, {; ""left"": 6,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/3.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-5/execution/3.txt.copy""]; }, {; ""left"": 7,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/5.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-6/execution/5.txt.copy""]; }, {; ""left"": 8,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/8.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-7/execution/8.txt.copy""]; }, {; ""left"": 9,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/9.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-8/execution/9.txt.copy""]; }, {; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/2.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-9/execution/2.txt.copy""",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:3190,Testability,test,test-cromwell-map,3190,"ight"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/1.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-4/execution/1.txt.copy""],; ""left"": 5; }, {; ""left"": 6,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/3.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-5/execution/3.txt.copy""]; }, {; ""left"": 7,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/5.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-6/execution/5.txt.copy""]; }, {; ""left"": 8,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/8.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-7/execution/8.txt.copy""]; }, {; ""left"": 9,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/9.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-8/execution/9.txt.copy""]; }, {; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/2.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-9/execution/2.txt.copy""],; ""left"": 10; }]; },; ""id"": ""67295907-5ffe-486e-8c7d-2bfdc5c5f97d""; }; ```. This results are always the same between runs. It looks more like a problem in ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:3218,Testability,Test,TestWorkflow,3218,"ight"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/1.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-4/execution/1.txt.copy""],; ""left"": 5; }, {; ""left"": 6,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/3.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-5/execution/3.txt.copy""]; }, {; ""left"": 7,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/5.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-6/execution/5.txt.copy""]; }, {; ""left"": 8,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/8.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-7/execution/8.txt.copy""]; }, {; ""left"": 9,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/9.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-8/execution/9.txt.copy""]; }, {; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/2.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-9/execution/2.txt.copy""],; ""left"": 10; }]; },; ""id"": ""67295907-5ffe-486e-8c7d-2bfdc5c5f97d""; }; ```. This results are always the same between runs. It looks more like a problem in ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:3326,Testability,test,test-cromwell-map,3326,"aniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-4/execution/1.txt.copy""],; ""left"": 5; }, {; ""left"": 6,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/3.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-5/execution/3.txt.copy""]; }, {; ""left"": 7,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/5.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-6/execution/5.txt.copy""]; }, {; ""left"": 8,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/8.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-7/execution/8.txt.copy""]; }, {; ""left"": 9,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/9.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-8/execution/9.txt.copy""]; }, {; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/2.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-9/execution/2.txt.copy""],; ""left"": 10; }]; },; ""id"": ""67295907-5ffe-486e-8c7d-2bfdc5c5f97d""; }; ```. This results are always the same between runs. It looks more like a problem in the way that the maps are handled, either one or both of this:. * `read_map` initializes an unsorted map, which does not preserve the file order when scat",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:3354,Testability,Test,TestWorkflow,3354,"aniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-4/execution/1.txt.copy""],; ""left"": 5; }, {; ""left"": 6,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/3.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-5/execution/3.txt.copy""]; }, {; ""left"": 7,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/5.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-6/execution/5.txt.copy""]; }, {; ""left"": 8,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/8.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-7/execution/8.txt.copy""]; }, {; ""left"": 9,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/9.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-8/execution/9.txt.copy""]; }, {; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/2.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-9/execution/2.txt.copy""],; ""left"": 10; }]; },; ""id"": ""67295907-5ffe-486e-8c7d-2bfdc5c5f97d""; }; ```. This results are always the same between runs. It looks more like a problem in the way that the maps are handled, either one or both of this:. * `read_map` initializes an unsorted map, which does not preserve the file order when scat",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:3501,Testability,test,test-cromwell-map,3501,"eft"": 6,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/3.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-5/execution/3.txt.copy""]; }, {; ""left"": 7,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/5.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-6/execution/5.txt.copy""]; }, {; ""left"": 8,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/8.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-7/execution/8.txt.copy""]; }, {; ""left"": 9,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/9.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-8/execution/9.txt.copy""]; }, {; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/2.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-9/execution/2.txt.copy""],; ""left"": 10; }]; },; ""id"": ""67295907-5ffe-486e-8c7d-2bfdc5c5f97d""; }; ```. This results are always the same between runs. It looks more like a problem in the way that the maps are handled, either one or both of this:. * `read_map` initializes an unsorted map, which does not preserve the file order when scatter is performed; * Scatter a map does not preserve the order of iteration, even if the `read_map` maintains the insertion order. I am not sure if in a `Map`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:3529,Testability,Test,TestWorkflow,3529,"eft"": 6,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/3.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-5/execution/3.txt.copy""]; }, {; ""left"": 7,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/5.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-6/execution/5.txt.copy""]; }, {; ""left"": 8,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/8.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-7/execution/8.txt.copy""]; }, {; ""left"": 9,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/9.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-8/execution/9.txt.copy""]; }, {; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/2.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-9/execution/2.txt.copy""],; ""left"": 10; }]; },; ""id"": ""67295907-5ffe-486e-8c7d-2bfdc5c5f97d""; }; ```. This results are always the same between runs. It looks more like a problem in the way that the maps are handled, either one or both of this:. * `read_map` initializes an unsorted map, which does not preserve the file order when scatter is performed; * Scatter a map does not preserve the order of iteration, even if the `read_map` maintains the insertion order. I am not sure if in a `Map`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:3637,Testability,test,test-cromwell-map,3637,""", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-5/execution/3.txt.copy""]; }, {; ""left"": 7,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/5.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-6/execution/5.txt.copy""]; }, {; ""left"": 8,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/8.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-7/execution/8.txt.copy""]; }, {; ""left"": 9,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/9.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-8/execution/9.txt.copy""]; }, {; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/2.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-9/execution/2.txt.copy""],; ""left"": 10; }]; },; ""id"": ""67295907-5ffe-486e-8c7d-2bfdc5c5f97d""; }; ```. This results are always the same between runs. It looks more like a problem in the way that the maps are handled, either one or both of this:. * `read_map` initializes an unsorted map, which does not preserve the file order when scatter is performed; * Scatter a map does not preserve the order of iteration, even if the `read_map` maintains the insertion order. I am not sure if in a `Map` the order is supposed to be preserved, but it would be nice in the case something like this toy-script works to keep an ordered map. I can work around th",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:3665,Testability,Test,TestWorkflow,3665,""", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-5/execution/3.txt.copy""]; }, {; ""left"": 7,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/5.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-6/execution/5.txt.copy""]; }, {; ""left"": 8,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/8.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-7/execution/8.txt.copy""]; }, {; ""left"": 9,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/9.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-8/execution/9.txt.copy""]; }, {; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/2.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-9/execution/2.txt.copy""],; ""left"": 10; }]; },; ""id"": ""67295907-5ffe-486e-8c7d-2bfdc5c5f97d""; }; ```. This results are always the same between runs. It looks more like a problem in the way that the maps are handled, either one or both of this:. * `read_map` initializes an unsorted map, which does not preserve the file order when scatter is performed; * Scatter a map does not preserve the order of iteration, even if the `read_map` maintains the insertion order. I am not sure if in a `Map` the order is supposed to be preserved, but it would be nice in the case something like this toy-script works to keep an ordered map. I can work around th",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:3800,Testability,test,test-cromwell-map,3800," {; ""left"": 7,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/5.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-6/execution/5.txt.copy""]; }, {; ""left"": 8,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/8.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-7/execution/8.txt.copy""]; }, {; ""left"": 9,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/9.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-8/execution/9.txt.copy""]; }, {; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/2.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-9/execution/2.txt.copy""],; ""left"": 10; }]; },; ""id"": ""67295907-5ffe-486e-8c7d-2bfdc5c5f97d""; }; ```. This results are always the same between runs. It looks more like a problem in the way that the maps are handled, either one or both of this:. * `read_map` initializes an unsorted map, which does not preserve the file order when scatter is performed; * Scatter a map does not preserve the order of iteration, even if the `read_map` maintains the insertion order. I am not sure if in a `Map` the order is supposed to be preserved, but it would be nice in the case something like this toy-script works to keep an ordered map. I can work around this by using two files in `GenerateMap` (one for the numbers and one for the files), read both with `read_lines` and then `zip` both of them to return a",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:3828,Testability,Test,TestWorkflow,3828," {; ""left"": 7,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/5.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-6/execution/5.txt.copy""]; }, {; ""left"": 8,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/8.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-7/execution/8.txt.copy""]; }, {; ""left"": 9,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/9.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-8/execution/9.txt.copy""]; }, {; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/2.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-9/execution/2.txt.copy""],; ""left"": 10; }]; },; ""id"": ""67295907-5ffe-486e-8c7d-2bfdc5c5f97d""; }; ```. This results are always the same between runs. It looks more like a problem in the way that the maps are handled, either one or both of this:. * `read_map` initializes an unsorted map, which does not preserve the file order when scatter is performed; * Scatter a map does not preserve the order of iteration, even if the `read_map` maintains the insertion order. I am not sure if in a `Map` the order is supposed to be preserved, but it would be nice in the case something like this toy-script works to keep an ordered map. I can work around this by using two files in `GenerateMap` (one for the numbers and one for the files), read both with `read_lines` and then `zip` both of them to return a",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:3936,Testability,test,test-cromwell-map,3936,"cution/5.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-6/execution/5.txt.copy""]; }, {; ""left"": 8,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/8.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-7/execution/8.txt.copy""]; }, {; ""left"": 9,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/9.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-8/execution/9.txt.copy""]; }, {; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/2.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-9/execution/2.txt.copy""],; ""left"": 10; }]; },; ""id"": ""67295907-5ffe-486e-8c7d-2bfdc5c5f97d""; }; ```. This results are always the same between runs. It looks more like a problem in the way that the maps are handled, either one or both of this:. * `read_map` initializes an unsorted map, which does not preserve the file order when scatter is performed; * Scatter a map does not preserve the order of iteration, even if the `read_map` maintains the insertion order. I am not sure if in a `Map` the order is supposed to be preserved, but it would be nice in the case something like this toy-script works to keep an ordered map. I can work around this by using two files in `GenerateMap` (one for the numbers and one for the files), read both with `read_lines` and then `zip` both of them to return an `Array[Pair[Int, File]]` instead of a map. Nevertheless, I think that this would be nicer if it works out-of-the-box (e.g., maintaining order of m",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779:3964,Testability,Test,TestWorkflow,3964,"cution/5.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-6/execution/5.txt.copy""]; }, {; ""left"": 8,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/8.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-7/execution/8.txt.copy""]; }, {; ""left"": 9,; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/9.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-8/execution/9.txt.copy""]; }, {; ""right"": [""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-GenerateMap/execution/2.txt"", ""/Users/daniel/Desktop/test-cromwell-map/execution/TestWorkflow/67295907-5ffe-486e-8c7d-2bfdc5c5f97d/call-CopyFile/shard-9/execution/2.txt.copy""],; ""left"": 10; }]; },; ""id"": ""67295907-5ffe-486e-8c7d-2bfdc5c5f97d""; }; ```. This results are always the same between runs. It looks more like a problem in the way that the maps are handled, either one or both of this:. * `read_map` initializes an unsorted map, which does not preserve the file order when scatter is performed; * Scatter a map does not preserve the order of iteration, even if the `read_map` maintains the insertion order. I am not sure if in a `Map` the order is supposed to be preserved, but it would be nice in the case something like this toy-script works to keep an ordered map. I can work around this by using two files in `GenerateMap` (one for the numbers and one for the files), read both with `read_lines` and then `zip` both of them to return an `Array[Pair[Int, File]]` instead of a map. Nevertheless, I think that this would be nicer if it works out-of-the-box (e.g., maintaining order of m",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368445779
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368531271:144,Performance,perform,performance,144,"Oh I see, insertion order in a map is definitely NOT preserved currently. They're backed by a classic unsorted HashMap. There would probably be performance implications if we were to switch to LinkedHashMap or a TreeMap to preserve order but maybe a `sort` function on arrays could make this easier.; Tagging @cjllanwarne who might want to chime in as this relates cloesly to WDL.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368531271
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368531271:111,Security,Hash,HashMap,111,"Oh I see, insertion order in a map is definitely NOT preserved currently. They're backed by a classic unsorted HashMap. There would probably be performance implications if we were to switch to LinkedHashMap or a TreeMap to preserve order but maybe a `sort` function on arrays could make this easier.; Tagging @cjllanwarne who might want to chime in as this relates cloesly to WDL.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368531271
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368548965:433,Performance,perform,performance,433,"I see how this is related to the WDL description and not to much with the implementation. For `read_lines` WDL specification, it says that the order should be the same as in the file-like object; but it is unclear if map is ordered, and there is no specific behavior to the `read_map` function. I would say that whenever things comes from a file it would be a good idea to keep the order, but I understand the possible problems with performance. Although if `LinkedHashMap` is used I can only see problems with performance if deletion/insertion in concrete indexes is required; definitely a `TreeMap` does not look like a good idea because the ""natural order"" might not be the one for the final user. Thanks for looking into this @Horneth and @cjllanwarne!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368548965
https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368548965:511,Performance,perform,performance,511,"I see how this is related to the WDL description and not to much with the implementation. For `read_lines` WDL specification, it says that the order should be the same as in the file-like object; but it is unclear if map is ordered, and there is no specific behavior to the `read_map` function. I would say that whenever things comes from a file it would be a good idea to keep the order, but I understand the possible problems with performance. Although if `LinkedHashMap` is used I can only see problems with performance if deletion/insertion in concrete indexes is required; definitely a `TreeMap` does not look like a good idea because the ""natural order"" might not be the one for the final user. Thanks for looking into this @Horneth and @cjllanwarne!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368548965
https://github.com/broadinstitute/cromwell/issues/3315#issuecomment-368136214:114,Integrability,depend,dependent,114,"To elaborate the idea a bit further... I'd like to be able to make the following transformations:. Easiest (add a dependent step):; ```wdl; workflow foo{; call A{}; }; ```; and ; ""Add B to FOO""; Becomes:; ```wdl; workflow FOO{; call A{}. call B{ inputs:; foo=A.foo}; }; ```; 2. Harder (replace a task); ```wdl; workflow FOO{; call A{}. call B{inputs: foo=A.foo}. call C{inputs: bar=B.bar}; } ; ```; and ; ""override B in FOO by B_Prime"". Becomes:; ```wdl; workflow FOO{; call A{}. call B_Prime{inputs: foo=A.foo}. call C{inputs: bar=B_Prime.bar}; }; ```; 3. even harder (replace a single call by multiple calls); ```wdl; workflow FOO{; call A{}. call B{inputs: foo=A.foo}. call C{inputs: bar=B.bar}; } ; ```; and ; ""override B in FOO by B_Prime_one and B_Prime_two"". Becomes:; ```wdl; workflow FOO{; call A{}. call B_Prime_one{inputs: foo=A.foo}; call B_Prime_two{inputs: baz=B_prime.baz}; call C{inputs: bar=B_Prime_two.bar}; }; ```; 3 might be solvable by implementing B_Prime_one and B_Prime_two as a workflow, and then invoking 2) and replacing call B by a call to that workflow.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3315#issuecomment-368136214
https://github.com/broadinstitute/cromwell/pull/3322#issuecomment-368688690:43,Testability,test,test,43,"For a change like this I'd prefer to see a test that proves that it works (eg, a call with one of these inputs being correctly converted into WDLOM). Even for a change like this I'd still let sbt tests run to make sure this change hasn't regressed any draft-3 parsing code elsewhere.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3322#issuecomment-368688690
https://github.com/broadinstitute/cromwell/pull/3322#issuecomment-368688690:196,Testability,test,tests,196,"For a change like this I'd prefer to see a test that proves that it works (eg, a call with one of these inputs being correctly converted into WDLOM). Even for a change like this I'd still let sbt tests run to make sure this change hasn't regressed any draft-3 parsing code elsewhere.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3322#issuecomment-368688690
https://github.com/broadinstitute/cromwell/pull/3322#issuecomment-369031380:31,Deployability,update,update,31,Closing this and including the update to WdlParser in the call element PR that I'm working on.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3322#issuecomment-369031380
https://github.com/broadinstitute/cromwell/issues/3325#issuecomment-368998293:54,Deployability,release,released,54,this has been fixed on the `30_hotfix` branch but not released. The next release will have the fix.; In the meantime you could either build the jar yourself either from `develop` or from `30_hotffix`,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3325#issuecomment-368998293
https://github.com/broadinstitute/cromwell/issues/3325#issuecomment-368998293:73,Deployability,release,release,73,this has been fixed on the `30_hotfix` branch but not released. The next release will have the fix.; In the meantime you could either build the jar yourself either from `develop` or from `30_hotffix`,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3325#issuecomment-368998293
https://github.com/broadinstitute/cromwell/issues/3325#issuecomment-371209125:138,Deployability,hotfix,hotfix,138,"As per the comment @Horneth made I'm going to close this. @rgobbel if you still see this behavior in the newest versions (`develop` or a `hotfix` releas), please reopen",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3325#issuecomment-371209125
https://github.com/broadinstitute/cromwell/issues/3326#issuecomment-368974102:120,Deployability,integrat,integrationTestCases,120,NB this will also require a fixup of https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/integrationTestCases/germline/joint-discovery-gatk/joint-discovery-gatk4.wdl#L341,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3326#issuecomment-368974102
https://github.com/broadinstitute/cromwell/issues/3326#issuecomment-368974102:120,Integrability,integrat,integrationTestCases,120,NB this will also require a fixup of https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/integrationTestCases/germline/joint-discovery-gatk/joint-discovery-gatk4.wdl#L341,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3326#issuecomment-368974102
https://github.com/broadinstitute/cromwell/issues/3328#issuecomment-369956933:83,Deployability,update,updated,83,"In general, it seems like the swagger spec, which can be very useful, has not been updated to reflect recent changes to the cromwell API.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3328#issuecomment-369956933
https://github.com/broadinstitute/cromwell/issues/3328#issuecomment-372387957:64,Deployability,update,update,64,"Ok, I see! Now as you mentioned, I think the problem here is to update the doc, to distinguish between execution statuses and workflow statuses, and elaborate execution statuses. Glad to know more about the internal mechanism of Cromwell and thanks for the explanation here!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3328#issuecomment-372387957
https://github.com/broadinstitute/cromwell/issues/3333#issuecomment-374695606:29,Deployability,configurat,configuration,29,Hi @carolynlawrence. Would a configuration option to remove this privilege re-assignment be sufficient to fix this?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3333#issuecomment-374695606
https://github.com/broadinstitute/cromwell/issues/3333#issuecomment-374695606:29,Modifiability,config,configuration,29,Hi @carolynlawrence. Would a configuration option to remove this privilege re-assignment be sufficient to fix this?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3333#issuecomment-374695606
https://github.com/broadinstitute/cromwell/issues/3333#issuecomment-374703828:156,Availability,error,errors,156,"From my testing, it seems that anything that runs a ""chmod""-like command disrupts the ACL-controlled permissions, leading to permission denied and/or other errors. I think if the configuration option wrapped any commands that did this, it would fix the issue. In the meantime I was able to come up with a few workarounds to fix the permissions so that we were happy with the system (moved some files around so cromwell wasn't accessing or trying to move anything past our ACL, and added a ""chmod o-wrx..."" command to my submit script), but a configuration option that did this by default would be great!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3333#issuecomment-374703828
https://github.com/broadinstitute/cromwell/issues/3333#issuecomment-374703828:179,Deployability,configurat,configuration,179,"From my testing, it seems that anything that runs a ""chmod""-like command disrupts the ACL-controlled permissions, leading to permission denied and/or other errors. I think if the configuration option wrapped any commands that did this, it would fix the issue. In the meantime I was able to come up with a few workarounds to fix the permissions so that we were happy with the system (moved some files around so cromwell wasn't accessing or trying to move anything past our ACL, and added a ""chmod o-wrx..."" command to my submit script), but a configuration option that did this by default would be great!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3333#issuecomment-374703828
https://github.com/broadinstitute/cromwell/issues/3333#issuecomment-374703828:542,Deployability,configurat,configuration,542,"From my testing, it seems that anything that runs a ""chmod""-like command disrupts the ACL-controlled permissions, leading to permission denied and/or other errors. I think if the configuration option wrapped any commands that did this, it would fix the issue. In the meantime I was able to come up with a few workarounds to fix the permissions so that we were happy with the system (moved some files around so cromwell wasn't accessing or trying to move anything past our ACL, and added a ""chmod o-wrx..."" command to my submit script), but a configuration option that did this by default would be great!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3333#issuecomment-374703828
https://github.com/broadinstitute/cromwell/issues/3333#issuecomment-374703828:200,Integrability,wrap,wrapped,200,"From my testing, it seems that anything that runs a ""chmod""-like command disrupts the ACL-controlled permissions, leading to permission denied and/or other errors. I think if the configuration option wrapped any commands that did this, it would fix the issue. In the meantime I was able to come up with a few workarounds to fix the permissions so that we were happy with the system (moved some files around so cromwell wasn't accessing or trying to move anything past our ACL, and added a ""chmod o-wrx..."" command to my submit script), but a configuration option that did this by default would be great!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3333#issuecomment-374703828
https://github.com/broadinstitute/cromwell/issues/3333#issuecomment-374703828:179,Modifiability,config,configuration,179,"From my testing, it seems that anything that runs a ""chmod""-like command disrupts the ACL-controlled permissions, leading to permission denied and/or other errors. I think if the configuration option wrapped any commands that did this, it would fix the issue. In the meantime I was able to come up with a few workarounds to fix the permissions so that we were happy with the system (moved some files around so cromwell wasn't accessing or trying to move anything past our ACL, and added a ""chmod o-wrx..."" command to my submit script), but a configuration option that did this by default would be great!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3333#issuecomment-374703828
https://github.com/broadinstitute/cromwell/issues/3333#issuecomment-374703828:542,Modifiability,config,configuration,542,"From my testing, it seems that anything that runs a ""chmod""-like command disrupts the ACL-controlled permissions, leading to permission denied and/or other errors. I think if the configuration option wrapped any commands that did this, it would fix the issue. In the meantime I was able to come up with a few workarounds to fix the permissions so that we were happy with the system (moved some files around so cromwell wasn't accessing or trying to move anything past our ACL, and added a ""chmod o-wrx..."" command to my submit script), but a configuration option that did this by default would be great!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3333#issuecomment-374703828
https://github.com/broadinstitute/cromwell/issues/3333#issuecomment-374703828:426,Security,access,accessing,426,"From my testing, it seems that anything that runs a ""chmod""-like command disrupts the ACL-controlled permissions, leading to permission denied and/or other errors. I think if the configuration option wrapped any commands that did this, it would fix the issue. In the meantime I was able to come up with a few workarounds to fix the permissions so that we were happy with the system (moved some files around so cromwell wasn't accessing or trying to move anything past our ACL, and added a ""chmod o-wrx..."" command to my submit script), but a configuration option that did this by default would be great!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3333#issuecomment-374703828
https://github.com/broadinstitute/cromwell/issues/3333#issuecomment-374703828:8,Testability,test,testing,8,"From my testing, it seems that anything that runs a ""chmod""-like command disrupts the ACL-controlled permissions, leading to permission denied and/or other errors. I think if the configuration option wrapped any commands that did this, it would fix the issue. In the meantime I was able to come up with a few workarounds to fix the permissions so that we were happy with the system (moved some files around so cromwell wasn't accessing or trying to move anything past our ACL, and added a ""chmod o-wrx..."" command to my submit script), but a configuration option that did this by default would be great!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3333#issuecomment-374703828
https://github.com/broadinstitute/cromwell/issues/3333#issuecomment-374722237:419,Deployability,configurat,configuration,419,"@carolynlawrence Just to double check, are you all using Docker in your workflow tasks? The only reason we're fiddling with permissions is due to Docker, and I don't know of anyone using Docker w/ Cromwell in an HPC environment - so my thought was that we could simply disable that permission activity for tasks which are not using docker. . To tie it into what @danbills suggested, perhaps **that** should be what the configuration flag is doing, just to be sure it's not breaking anyone's reliance on current behavior either way.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3333#issuecomment-374722237
https://github.com/broadinstitute/cromwell/issues/3333#issuecomment-374722237:419,Modifiability,config,configuration,419,"@carolynlawrence Just to double check, are you all using Docker in your workflow tasks? The only reason we're fiddling with permissions is due to Docker, and I don't know of anyone using Docker w/ Cromwell in an HPC environment - so my thought was that we could simply disable that permission activity for tasks which are not using docker. . To tie it into what @danbills suggested, perhaps **that** should be what the configuration flag is doing, just to be sure it's not breaking anyone's reliance on current behavior either way.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3333#issuecomment-374722237
https://github.com/broadinstitute/cromwell/issues/3333#issuecomment-374722237:262,Usability,simpl,simply,262,"@carolynlawrence Just to double check, are you all using Docker in your workflow tasks? The only reason we're fiddling with permissions is due to Docker, and I don't know of anyone using Docker w/ Cromwell in an HPC environment - so my thought was that we could simply disable that permission activity for tasks which are not using docker. . To tie it into what @danbills suggested, perhaps **that** should be what the configuration flag is doing, just to be sure it's not breaking anyone's reliance on current behavior either way.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3333#issuecomment-374722237
https://github.com/broadinstitute/cromwell/issues/3333#issuecomment-374724001:93,Deployability,configurat,configuration,93,"@geoffjentry We are not using Docker, but you are right that it might be better to make it a configuration flag like @danbills initially suggested, rather than automatic, in case it would break someone's workflow... like maybe if they were using Docker and non-Docker in the same workflow?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3333#issuecomment-374724001
https://github.com/broadinstitute/cromwell/issues/3333#issuecomment-374724001:93,Modifiability,config,configuration,93,"@geoffjentry We are not using Docker, but you are right that it might be better to make it a configuration flag like @danbills initially suggested, rather than automatic, in case it would break someone's workflow... like maybe if they were using Docker and non-Docker in the same workflow?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3333#issuecomment-374724001
https://github.com/broadinstitute/cromwell/issues/3333#issuecomment-376196463:210,Deployability,Configurat,Configuration,210,"Debrief here from a face-to-face w/ @geoffjentry :. So the config flag should be set _AND_ the call should be using docker to do the override. To be clear, the truth table here is . Using Docker on this call | Configuration Flag is set to true | Should reassign; --|--|--; T|T|T; T|F|F; F|T|F; F|F|F. Config flag should be `docker.override_umask_when_creating_directories`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3333#issuecomment-376196463
https://github.com/broadinstitute/cromwell/issues/3333#issuecomment-376196463:59,Modifiability,config,config,59,"Debrief here from a face-to-face w/ @geoffjentry :. So the config flag should be set _AND_ the call should be using docker to do the override. To be clear, the truth table here is . Using Docker on this call | Configuration Flag is set to true | Should reassign; --|--|--; T|T|T; T|F|F; F|T|F; F|F|F. Config flag should be `docker.override_umask_when_creating_directories`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3333#issuecomment-376196463
https://github.com/broadinstitute/cromwell/issues/3333#issuecomment-376196463:210,Modifiability,Config,Configuration,210,"Debrief here from a face-to-face w/ @geoffjentry :. So the config flag should be set _AND_ the call should be using docker to do the override. To be clear, the truth table here is . Using Docker on this call | Configuration Flag is set to true | Should reassign; --|--|--; T|T|T; T|F|F; F|T|F; F|F|F. Config flag should be `docker.override_umask_when_creating_directories`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3333#issuecomment-376196463
https://github.com/broadinstitute/cromwell/issues/3333#issuecomment-376196463:301,Modifiability,Config,Config,301,"Debrief here from a face-to-face w/ @geoffjentry :. So the config flag should be set _AND_ the call should be using docker to do the override. To be clear, the truth table here is . Using Docker on this call | Configuration Flag is set to true | Should reassign; --|--|--; T|T|T; T|F|F; F|T|F; F|F|F. Config flag should be `docker.override_umask_when_creating_directories`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3333#issuecomment-376196463
https://github.com/broadinstitute/cromwell/issues/3333#issuecomment-376196463:149,Usability,clear,clear,149,"Debrief here from a face-to-face w/ @geoffjentry :. So the config flag should be set _AND_ the call should be using docker to do the override. To be clear, the truth table here is . Using Docker on this call | Configuration Flag is set to true | Should reassign; --|--|--; T|T|T; T|F|F; F|T|F; F|F|F. Config flag should be `docker.override_umask_when_creating_directories`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3333#issuecomment-376196463
https://github.com/broadinstitute/cromwell/pull/3335#issuecomment-369979437:157,Modifiability,refactor,refactoring,157,"@mcovarr sounds good, I've manually merged this PR and the job token one to another branch and have been working from there to wire everything up, including refactoring this.; I think I can manage to separate out this refactoring from the rest though.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3335#issuecomment-369979437
https://github.com/broadinstitute/cromwell/pull/3335#issuecomment-369979437:218,Modifiability,refactor,refactoring,218,"@mcovarr sounds good, I've manually merged this PR and the job token one to another branch and have been working from there to wire everything up, including refactoring this.; I think I can manage to separate out this refactoring from the rest though.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3335#issuecomment-369979437
https://github.com/broadinstitute/cromwell/issues/3339#issuecomment-371822508:55,Performance,scalab,scalability,55,"@geoffjentry is the idea for this to enable horizontal scalability of cromwell? If so, we are much looking forward to this support!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3339#issuecomment-371822508
https://github.com/broadinstitute/cromwell/issues/3340#issuecomment-371247207:529,Availability,echo,echo,529,"host/port is nice when you think about autoscaling. having the config file need to be different on every machine will be a headache when you want an ELB to spin up more nodes based on load. in a non-container world, that's straightforward. In a container world, the hostname (as defined by /etc/hostname, which is what typical java apis use to determine hostname) is set to a unique container id. So even if you're running multiple containers on the same host on the same port (pre-NAT) you'll get unique IDs. ```; wm80b-899:~ $ echo $HOSTNAME; wm80b-899; wm80b-899:~ $ docker run -it ubuntu /bin/bash -i; root@62d62e5dc805:/# echo $HOSTNAME; 62d62e5dc805; root@62d62e5dc805:/# cat /etc/hostname; 62d62e5dc805; root@62d62e5dc805:/# ; ```. @jacmrob",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3340#issuecomment-371247207
https://github.com/broadinstitute/cromwell/issues/3340#issuecomment-371247207:627,Availability,echo,echo,627,"host/port is nice when you think about autoscaling. having the config file need to be different on every machine will be a headache when you want an ELB to spin up more nodes based on load. in a non-container world, that's straightforward. In a container world, the hostname (as defined by /etc/hostname, which is what typical java apis use to determine hostname) is set to a unique container id. So even if you're running multiple containers on the same host on the same port (pre-NAT) you'll get unique IDs. ```; wm80b-899:~ $ echo $HOSTNAME; wm80b-899; wm80b-899:~ $ docker run -it ubuntu /bin/bash -i; root@62d62e5dc805:/# echo $HOSTNAME; 62d62e5dc805; root@62d62e5dc805:/# cat /etc/hostname; 62d62e5dc805; root@62d62e5dc805:/# ; ```. @jacmrob",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3340#issuecomment-371247207
https://github.com/broadinstitute/cromwell/issues/3340#issuecomment-371247207:63,Modifiability,config,config,63,"host/port is nice when you think about autoscaling. having the config file need to be different on every machine will be a headache when you want an ELB to spin up more nodes based on load. in a non-container world, that's straightforward. In a container world, the hostname (as defined by /etc/hostname, which is what typical java apis use to determine hostname) is set to a unique container id. So even if you're running multiple containers on the same host on the same port (pre-NAT) you'll get unique IDs. ```; wm80b-899:~ $ echo $HOSTNAME; wm80b-899; wm80b-899:~ $ docker run -it ubuntu /bin/bash -i; root@62d62e5dc805:/# echo $HOSTNAME; 62d62e5dc805; root@62d62e5dc805:/# cat /etc/hostname; 62d62e5dc805; root@62d62e5dc805:/# ; ```. @jacmrob",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3340#issuecomment-371247207
https://github.com/broadinstitute/cromwell/issues/3340#issuecomment-371247207:184,Performance,load,load,184,"host/port is nice when you think about autoscaling. having the config file need to be different on every machine will be a headache when you want an ELB to spin up more nodes based on load. in a non-container world, that's straightforward. In a container world, the hostname (as defined by /etc/hostname, which is what typical java apis use to determine hostname) is set to a unique container id. So even if you're running multiple containers on the same host on the same port (pre-NAT) you'll get unique IDs. ```; wm80b-899:~ $ echo $HOSTNAME; wm80b-899; wm80b-899:~ $ docker run -it ubuntu /bin/bash -i; root@62d62e5dc805:/# echo $HOSTNAME; 62d62e5dc805; root@62d62e5dc805:/# cat /etc/hostname; 62d62e5dc805; root@62d62e5dc805:/# ; ```. @jacmrob",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3340#issuecomment-371247207
https://github.com/broadinstitute/cromwell/issues/3340#issuecomment-371248096:203,Performance,load,load,203,"@kcibul what port, the web server associated with the Cromwell?. It can't be just the host as the host might have multiple cromwells running on it and this needs to work in all situations, not just in a load balanced world.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3340#issuecomment-371248096
https://github.com/broadinstitute/cromwell/issues/3340#issuecomment-371703999:44,Modifiability,config,config,44,There's code now on develop that looks at a config value. It's not clear from the discussion above if that's enough to satisfy this ticket?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3340#issuecomment-371703999
https://github.com/broadinstitute/cromwell/issues/3340#issuecomment-371703999:67,Usability,clear,clear,67,There's code now on develop that looks at a config value. It's not clear from the discussion above if that's enough to satisfy this ticket?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3340#issuecomment-371703999
https://github.com/broadinstitute/cromwell/issues/3340#issuecomment-371786829:224,Modifiability,config,config,224,"Let‚Äôs talk after standup. In this case I think the port that Cromwell itself is listening on works. > On Mar 8, 2018, at 10:40 PM, mcovarr <notifications@github.com> wrote:; > ; > There's code now on develop that looks at a config value. It's not clear from the discussion above if that's enough to satisfy this ticket?; > ; > ‚Äî; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub, or mute the thread.; >",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3340#issuecomment-371786829
https://github.com/broadinstitute/cromwell/issues/3340#issuecomment-371786829:247,Usability,clear,clear,247,"Let‚Äôs talk after standup. In this case I think the port that Cromwell itself is listening on works. > On Mar 8, 2018, at 10:40 PM, mcovarr <notifications@github.com> wrote:; > ; > There's code now on develop that looks at a config value. It's not clear from the discussion above if that's enough to satisfy this ticket?; > ; > ‚Äî; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub, or mute the thread.; >",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3340#issuecomment-371786829
https://github.com/broadinstitute/cromwell/issues/3342#issuecomment-371248824:109,Deployability,UPDATE,UPDATE,109,"Hey Miguel -- happy to brainstorm/tagdeam on the tools for this if you need help. I think the ""SELECT... FOR UPDATE"" semantics are what we need here. See https://dev.mysql.com/doc/refman/5.7/en/innodb-locking-reads.html. Basically when you do the something like . SELECT ... FROM workflow_store WHERE [is new or dead workflow] ORDER BY submission_time LIMIT n FOR UPDATE. will prevent two things from touching that workflow at the same time. Then just make sure the update of status happens in the same transaction and you're all set. . Give a shout... my next two days are shockingly meeting light!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3342#issuecomment-371248824
https://github.com/broadinstitute/cromwell/issues/3342#issuecomment-371248824:364,Deployability,UPDATE,UPDATE,364,"Hey Miguel -- happy to brainstorm/tagdeam on the tools for this if you need help. I think the ""SELECT... FOR UPDATE"" semantics are what we need here. See https://dev.mysql.com/doc/refman/5.7/en/innodb-locking-reads.html. Basically when you do the something like . SELECT ... FROM workflow_store WHERE [is new or dead workflow] ORDER BY submission_time LIMIT n FOR UPDATE. will prevent two things from touching that workflow at the same time. Then just make sure the update of status happens in the same transaction and you're all set. . Give a shout... my next two days are shockingly meeting light!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3342#issuecomment-371248824
https://github.com/broadinstitute/cromwell/issues/3342#issuecomment-371248824:466,Deployability,update,update,466,"Hey Miguel -- happy to brainstorm/tagdeam on the tools for this if you need help. I think the ""SELECT... FOR UPDATE"" semantics are what we need here. See https://dev.mysql.com/doc/refman/5.7/en/innodb-locking-reads.html. Basically when you do the something like . SELECT ... FROM workflow_store WHERE [is new or dead workflow] ORDER BY submission_time LIMIT n FOR UPDATE. will prevent two things from touching that workflow at the same time. Then just make sure the update of status happens in the same transaction and you're all set. . Give a shout... my next two days are shockingly meeting light!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3342#issuecomment-371248824
https://github.com/broadinstitute/cromwell/issues/3344#issuecomment-370523886:115,Safety,abort,abort,115,Not 100% sure there's a locking issue in this case as there should be only one Cromwell processing the append-only abort request and at most one Cromwell running an abortable workflow?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3344#issuecomment-370523886
https://github.com/broadinstitute/cromwell/issues/3344#issuecomment-370523886:165,Safety,abort,abortable,165,Not 100% sure there's a locking issue in this case as there should be only one Cromwell processing the append-only abort request and at most one Cromwell running an abortable workflow?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3344#issuecomment-370523886
https://github.com/broadinstitute/cromwell/issues/3344#issuecomment-437031892:19,Deployability,update,updated,19,IMO anything being updated in a shared environment should be protected but i also loathe shared mutable state so YMMV,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3344#issuecomment-437031892
https://github.com/broadinstitute/cromwell/issues/3346#issuecomment-373590817:99,Deployability,UPDATE,UPDATE,99,"Caused by: liquibase.exception.DatabaseException: Unknown column '' in 'where clause' [Failed SQL: UPDATE WORKFLOW_STORE_ENTRY; SET CUSTOM_LABELS = ""{}""; WHERE CUSTOM_LABELS = """"]; new issues",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3346#issuecomment-373590817
https://github.com/broadinstitute/cromwell/issues/3346#issuecomment-404688457:127,Deployability,release,releases,127,"Hi ChenYong,. I'm closing this issue here on GitHub as Cromwell [30-16f3632 / 30.2](https://github.com/broadinstitute/cromwell/releases/tag/30.2) seems to run fine against a basic MariaDB 5.5.56. I also tried changing the database initialization script to run with-and-without setting `SET GLOBAL sql_mode = 'ANSI_QUOTES';`. If you're still running into problems, can you please create a post over in the [Ask the WDL team](https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team) forum? There please provide as many logs and configuration files as possible (without passwords) so that your issue may be reproduced. ---. To test Cromwell with MariaDB I combined the following files and ran them from an `issues_3346/` directory with `docker-compose up`. - `issues_3346/compose/cromwell/app-config/application.conf`; - `issues_3346/compose/cromwell/Dockerfile`; - `issues_3346/compose/mysql/init/init_user.sql`; - `issues_3346/docker-compose.yml`. The files are in this archive: [issues_3346.tar.gz](https://github.com/broadinstitute/cromwell/files/2190721/issues_3346.tar.gz). Cromwell started and connected to the db. I was able to browse to `http://localhost:80` and submit a workflow.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3346#issuecomment-404688457
https://github.com/broadinstitute/cromwell/issues/3346#issuecomment-404688457:540,Deployability,configurat,configuration,540,"Hi ChenYong,. I'm closing this issue here on GitHub as Cromwell [30-16f3632 / 30.2](https://github.com/broadinstitute/cromwell/releases/tag/30.2) seems to run fine against a basic MariaDB 5.5.56. I also tried changing the database initialization script to run with-and-without setting `SET GLOBAL sql_mode = 'ANSI_QUOTES';`. If you're still running into problems, can you please create a post over in the [Ask the WDL team](https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team) forum? There please provide as many logs and configuration files as possible (without passwords) so that your issue may be reproduced. ---. To test Cromwell with MariaDB I combined the following files and ran them from an `issues_3346/` directory with `docker-compose up`. - `issues_3346/compose/cromwell/app-config/application.conf`; - `issues_3346/compose/cromwell/Dockerfile`; - `issues_3346/compose/mysql/init/init_user.sql`; - `issues_3346/docker-compose.yml`. The files are in this archive: [issues_3346.tar.gz](https://github.com/broadinstitute/cromwell/files/2190721/issues_3346.tar.gz). Cromwell started and connected to the db. I was able to browse to `http://localhost:80` and submit a workflow.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3346#issuecomment-404688457
https://github.com/broadinstitute/cromwell/issues/3346#issuecomment-404688457:540,Modifiability,config,configuration,540,"Hi ChenYong,. I'm closing this issue here on GitHub as Cromwell [30-16f3632 / 30.2](https://github.com/broadinstitute/cromwell/releases/tag/30.2) seems to run fine against a basic MariaDB 5.5.56. I also tried changing the database initialization script to run with-and-without setting `SET GLOBAL sql_mode = 'ANSI_QUOTES';`. If you're still running into problems, can you please create a post over in the [Ask the WDL team](https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team) forum? There please provide as many logs and configuration files as possible (without passwords) so that your issue may be reproduced. ---. To test Cromwell with MariaDB I combined the following files and ran them from an `issues_3346/` directory with `docker-compose up`. - `issues_3346/compose/cromwell/app-config/application.conf`; - `issues_3346/compose/cromwell/Dockerfile`; - `issues_3346/compose/mysql/init/init_user.sql`; - `issues_3346/docker-compose.yml`. The files are in this archive: [issues_3346.tar.gz](https://github.com/broadinstitute/cromwell/files/2190721/issues_3346.tar.gz). Cromwell started and connected to the db. I was able to browse to `http://localhost:80` and submit a workflow.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3346#issuecomment-404688457
https://github.com/broadinstitute/cromwell/issues/3346#issuecomment-404688457:804,Modifiability,config,config,804,"Hi ChenYong,. I'm closing this issue here on GitHub as Cromwell [30-16f3632 / 30.2](https://github.com/broadinstitute/cromwell/releases/tag/30.2) seems to run fine against a basic MariaDB 5.5.56. I also tried changing the database initialization script to run with-and-without setting `SET GLOBAL sql_mode = 'ANSI_QUOTES';`. If you're still running into problems, can you please create a post over in the [Ask the WDL team](https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team) forum? There please provide as many logs and configuration files as possible (without passwords) so that your issue may be reproduced. ---. To test Cromwell with MariaDB I combined the following files and ran them from an `issues_3346/` directory with `docker-compose up`. - `issues_3346/compose/cromwell/app-config/application.conf`; - `issues_3346/compose/cromwell/Dockerfile`; - `issues_3346/compose/mysql/init/init_user.sql`; - `issues_3346/docker-compose.yml`. The files are in this archive: [issues_3346.tar.gz](https://github.com/broadinstitute/cromwell/files/2190721/issues_3346.tar.gz). Cromwell started and connected to the db. I was able to browse to `http://localhost:80` and submit a workflow.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3346#issuecomment-404688457
https://github.com/broadinstitute/cromwell/issues/3346#issuecomment-404688457:581,Security,password,passwords,581,"Hi ChenYong,. I'm closing this issue here on GitHub as Cromwell [30-16f3632 / 30.2](https://github.com/broadinstitute/cromwell/releases/tag/30.2) seems to run fine against a basic MariaDB 5.5.56. I also tried changing the database initialization script to run with-and-without setting `SET GLOBAL sql_mode = 'ANSI_QUOTES';`. If you're still running into problems, can you please create a post over in the [Ask the WDL team](https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team) forum? There please provide as many logs and configuration files as possible (without passwords) so that your issue may be reproduced. ---. To test Cromwell with MariaDB I combined the following files and ran them from an `issues_3346/` directory with `docker-compose up`. - `issues_3346/compose/cromwell/app-config/application.conf`; - `issues_3346/compose/cromwell/Dockerfile`; - `issues_3346/compose/mysql/init/init_user.sql`; - `issues_3346/docker-compose.yml`. The files are in this archive: [issues_3346.tar.gz](https://github.com/broadinstitute/cromwell/files/2190721/issues_3346.tar.gz). Cromwell started and connected to the db. I was able to browse to `http://localhost:80` and submit a workflow.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3346#issuecomment-404688457
https://github.com/broadinstitute/cromwell/issues/3346#issuecomment-404688457:531,Testability,log,logs,531,"Hi ChenYong,. I'm closing this issue here on GitHub as Cromwell [30-16f3632 / 30.2](https://github.com/broadinstitute/cromwell/releases/tag/30.2) seems to run fine against a basic MariaDB 5.5.56. I also tried changing the database initialization script to run with-and-without setting `SET GLOBAL sql_mode = 'ANSI_QUOTES';`. If you're still running into problems, can you please create a post over in the [Ask the WDL team](https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team) forum? There please provide as many logs and configuration files as possible (without passwords) so that your issue may be reproduced. ---. To test Cromwell with MariaDB I combined the following files and ran them from an `issues_3346/` directory with `docker-compose up`. - `issues_3346/compose/cromwell/app-config/application.conf`; - `issues_3346/compose/cromwell/Dockerfile`; - `issues_3346/compose/mysql/init/init_user.sql`; - `issues_3346/docker-compose.yml`. The files are in this archive: [issues_3346.tar.gz](https://github.com/broadinstitute/cromwell/files/2190721/issues_3346.tar.gz). Cromwell started and connected to the db. I was able to browse to `http://localhost:80` and submit a workflow.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3346#issuecomment-404688457
https://github.com/broadinstitute/cromwell/issues/3346#issuecomment-404688457:638,Testability,test,test,638,"Hi ChenYong,. I'm closing this issue here on GitHub as Cromwell [30-16f3632 / 30.2](https://github.com/broadinstitute/cromwell/releases/tag/30.2) seems to run fine against a basic MariaDB 5.5.56. I also tried changing the database initialization script to run with-and-without setting `SET GLOBAL sql_mode = 'ANSI_QUOTES';`. If you're still running into problems, can you please create a post over in the [Ask the WDL team](https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team) forum? There please provide as many logs and configuration files as possible (without passwords) so that your issue may be reproduced. ---. To test Cromwell with MariaDB I combined the following files and ran them from an `issues_3346/` directory with `docker-compose up`. - `issues_3346/compose/cromwell/app-config/application.conf`; - `issues_3346/compose/cromwell/Dockerfile`; - `issues_3346/compose/mysql/init/init_user.sql`; - `issues_3346/docker-compose.yml`. The files are in this archive: [issues_3346.tar.gz](https://github.com/broadinstitute/cromwell/files/2190721/issues_3346.tar.gz). Cromwell started and connected to the db. I was able to browse to `http://localhost:80` and submit a workflow.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3346#issuecomment-404688457
https://github.com/broadinstitute/cromwell/issues/3348#issuecomment-383682658:142,Availability,failure,failures,142,"@ruchim I think we talked about this offline, but it'd be workflow level info. Except I guess for the aforementioned idea of grouping by task failures.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3348#issuecomment-383682658
https://github.com/broadinstitute/cromwell/pull/3350#issuecomment-370128184:421,Security,checksum,checksum,421,"Via ""the docker"":. ```; [2018-03-03 01:11:21,96] [info] SingleWorkflowRunnerActor workflow finished with status 'Succeeded'.; { ; ""outputs"": {; ""workflow.cwl.mark_duplicates_metrics_file"": {; ""format"": null,; ""location"": ""/root/cromwell-executions/workflow.cwl/b745d4f8-aa09-402c-b612-fb112fe8d983/call-mark_duplicates_and_sort/execution/mark_dups_metrics.txt"",; ""size"": null,; ""secondaryFiles"": [],; ""contents"": null,; ""checksum"": null,; ""class"": ""File""; },; ""workflow.cwl.final_cram"": {; ""format"": null,; ""location"": ""/root/cromwell-executions/workflow.cwl/b745d4f8-aa09-402c-b612-fb112fe8d983/call-index_cram/execution/final.cram"",; ""size"": null,; ""secondaryFiles"": [""/root/cromwell-executions/workflow.cwl/b745d4f8-aa09-402c-b612-fb112fe8d983/call-index_cram/execution/final.cram.crai"", ""/root/cromwell-executions/workflow.cwl/b745d4f8-aa09-402c-b612-fb112fe8d983/call-index_cram/execution/final.crai""],; ""contents"": null,; ""checksum"": null,; ""class"": ""File""; }; },; ""id"": ""b745d4f8-aa09-402c-b612-fb112fe8d983""; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3350#issuecomment-370128184
https://github.com/broadinstitute/cromwell/pull/3350#issuecomment-370128184:929,Security,checksum,checksum,929,"Via ""the docker"":. ```; [2018-03-03 01:11:21,96] [info] SingleWorkflowRunnerActor workflow finished with status 'Succeeded'.; { ; ""outputs"": {; ""workflow.cwl.mark_duplicates_metrics_file"": {; ""format"": null,; ""location"": ""/root/cromwell-executions/workflow.cwl/b745d4f8-aa09-402c-b612-fb112fe8d983/call-mark_duplicates_and_sort/execution/mark_dups_metrics.txt"",; ""size"": null,; ""secondaryFiles"": [],; ""contents"": null,; ""checksum"": null,; ""class"": ""File""; },; ""workflow.cwl.final_cram"": {; ""format"": null,; ""location"": ""/root/cromwell-executions/workflow.cwl/b745d4f8-aa09-402c-b612-fb112fe8d983/call-index_cram/execution/final.cram"",; ""size"": null,; ""secondaryFiles"": [""/root/cromwell-executions/workflow.cwl/b745d4f8-aa09-402c-b612-fb112fe8d983/call-index_cram/execution/final.cram.crai"", ""/root/cromwell-executions/workflow.cwl/b745d4f8-aa09-402c-b612-fb112fe8d983/call-index_cram/execution/final.crai""],; ""contents"": null,; ""checksum"": null,; ""class"": ""File""; }; },; ""id"": ""b745d4f8-aa09-402c-b612-fb112fe8d983""; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3350#issuecomment-370128184
https://github.com/broadinstitute/cromwell/pull/3350#issuecomment-370195869:225,Modifiability,refactor,refactor,225,Could you give a high-level overview of the changes here? Obviously the state machine is the star of this PR but there are quite a few changes in IWD and other spots where I wasn't expecting them. It looks like it's mostly a refactor but I'm not completely sure.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3350#issuecomment-370195869
https://github.com/broadinstitute/cromwell/pull/3350#issuecomment-370296979:1388,Availability,Error,Error,1388,"In addition to the commit comments. Specifically for ""the docker"":; - InputParameters weren't wired in for secondary files. Now they are, with Polys and a bit of borrowing from the OutputParameters. The common code was refactored into FileParameter.; - CWL spec says InputArraySchema's can't have secondary files, and that they should be specified on the InputBinding. The CWL via ""the docker"" wants them on the IAS anyway. The IAS secondary files are now wired in through a Poly.; - ""The docker"" was using strings like `$(""foo"")/$(""bar"")` that was tripping up our various expression regex patterns. This PR replaces them with the (latest as of Friday) copy-port of cwltool's state machine. The state machine works on _any_ string, even those without `""$(""`. But the spec for secondary files says that only expressions should be returned-as-rendered, while plain strings should be instead appended instead of used as literals. It turns out this discrimination is done in cwltool `""$("" in expr` (see numerous links in the scala comments). So the presence of `""$(""` is now used for our `ECMAScriptExpression` to similarly guess if a string is a interpolated string or a regular string. `ECMAScriptExpression` and `InterpolatedString` were pretty much the same thing and were merged back together. There was also a bit of code where if a malicious (or errant) CWL was submitted a `java.lang.Error` would be thrown possibly exiting the JVM. The code around this section was refactored to use a compile-time-checked Poly instead of hope-we-got-them-all pattern matching.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3350#issuecomment-370296979
https://github.com/broadinstitute/cromwell/pull/3350#issuecomment-370296979:219,Modifiability,refactor,refactored,219,"In addition to the commit comments. Specifically for ""the docker"":; - InputParameters weren't wired in for secondary files. Now they are, with Polys and a bit of borrowing from the OutputParameters. The common code was refactored into FileParameter.; - CWL spec says InputArraySchema's can't have secondary files, and that they should be specified on the InputBinding. The CWL via ""the docker"" wants them on the IAS anyway. The IAS secondary files are now wired in through a Poly.; - ""The docker"" was using strings like `$(""foo"")/$(""bar"")` that was tripping up our various expression regex patterns. This PR replaces them with the (latest as of Friday) copy-port of cwltool's state machine. The state machine works on _any_ string, even those without `""$(""`. But the spec for secondary files says that only expressions should be returned-as-rendered, while plain strings should be instead appended instead of used as literals. It turns out this discrimination is done in cwltool `""$("" in expr` (see numerous links in the scala comments). So the presence of `""$(""` is now used for our `ECMAScriptExpression` to similarly guess if a string is a interpolated string or a regular string. `ECMAScriptExpression` and `InterpolatedString` were pretty much the same thing and were merged back together. There was also a bit of code where if a malicious (or errant) CWL was submitted a `java.lang.Error` would be thrown possibly exiting the JVM. The code around this section was refactored to use a compile-time-checked Poly instead of hope-we-got-them-all pattern matching.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3350#issuecomment-370296979
https://github.com/broadinstitute/cromwell/pull/3350#issuecomment-370296979:1470,Modifiability,refactor,refactored,1470,"In addition to the commit comments. Specifically for ""the docker"":; - InputParameters weren't wired in for secondary files. Now they are, with Polys and a bit of borrowing from the OutputParameters. The common code was refactored into FileParameter.; - CWL spec says InputArraySchema's can't have secondary files, and that they should be specified on the InputBinding. The CWL via ""the docker"" wants them on the IAS anyway. The IAS secondary files are now wired in through a Poly.; - ""The docker"" was using strings like `$(""foo"")/$(""bar"")` that was tripping up our various expression regex patterns. This PR replaces them with the (latest as of Friday) copy-port of cwltool's state machine. The state machine works on _any_ string, even those without `""$(""`. But the spec for secondary files says that only expressions should be returned-as-rendered, while plain strings should be instead appended instead of used as literals. It turns out this discrimination is done in cwltool `""$("" in expr` (see numerous links in the scala comments). So the presence of `""$(""` is now used for our `ECMAScriptExpression` to similarly guess if a string is a interpolated string or a regular string. `ECMAScriptExpression` and `InterpolatedString` were pretty much the same thing and were merged back together. There was also a bit of code where if a malicious (or errant) CWL was submitted a `java.lang.Error` would be thrown possibly exiting the JVM. The code around this section was refactored to use a compile-time-checked Poly instead of hope-we-got-them-all pattern matching.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3350#issuecomment-370296979
https://github.com/broadinstitute/cromwell/pull/3354#issuecomment-370592084:53,Testability,test,test,53,"@cjllanwarne I don't know why the `docker_hash_quay` test is failing, but I don't think this is related to my changes.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3354#issuecomment-370592084
https://github.com/broadinstitute/cromwell/pull/3354#issuecomment-370594386:60,Security,hash,hash,60,"@orodeh yeah, I wouldn't worry about that (it sounds like a hash was changed in quay.io for the first time in 2 years and it broke that test. Nothing for us to worry about in this PR!). I'll wait for the tests to complete again and as long as it's still looking good, I'll merge",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3354#issuecomment-370594386
https://github.com/broadinstitute/cromwell/pull/3354#issuecomment-370594386:136,Testability,test,test,136,"@orodeh yeah, I wouldn't worry about that (it sounds like a hash was changed in quay.io for the first time in 2 years and it broke that test. Nothing for us to worry about in this PR!). I'll wait for the tests to complete again and as long as it's still looking good, I'll merge",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3354#issuecomment-370594386
https://github.com/broadinstitute/cromwell/pull/3354#issuecomment-370594386:204,Testability,test,tests,204,"@orodeh yeah, I wouldn't worry about that (it sounds like a hash was changed in quay.io for the first time in 2 years and it broke that test. Nothing for us to worry about in this PR!). I'll wait for the tests to complete again and as long as it's still looking good, I'll merge",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3354#issuecomment-370594386
https://github.com/broadinstitute/cromwell/pull/3356#issuecomment-370562042:16,Availability,redundant,redundant,16,Is this kind of redundant to the token system?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3356#issuecomment-370562042
https://github.com/broadinstitute/cromwell/pull/3356#issuecomment-370562042:16,Safety,redund,redundant,16,Is this kind of redundant to the token system?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3356#issuecomment-370562042
https://github.com/broadinstitute/cromwell/pull/3356#issuecomment-370564846:367,Energy Efficiency,reduce,reduces,367,"In a sense yes, but it's upstream of it.; Currently if you scatter 10 million wide, Cromwell still creates 10 million EJEAs that are going to ask for a token.; This stops it from even creating EJEAs if it knows they won't be able to run anyway (yet).; To be perfectly honest I just wanted to kinda float the idea as I haven't gotten to precisely measure if it indeed reduces cpu / memory load (I'm strongly guessing yes though since it's less work being done but...).; I wanted to get people's opinion and if it's a no go already I won't bother measuring.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3356#issuecomment-370564846
https://github.com/broadinstitute/cromwell/pull/3356#issuecomment-370564846:388,Performance,load,load,388,"In a sense yes, but it's upstream of it.; Currently if you scatter 10 million wide, Cromwell still creates 10 million EJEAs that are going to ask for a token.; This stops it from even creating EJEAs if it knows they won't be able to run anyway (yet).; To be perfectly honest I just wanted to kinda float the idea as I haven't gotten to precisely measure if it indeed reduces cpu / memory load (I'm strongly guessing yes though since it's less work being done but...).; I wanted to get people's opinion and if it's a no go already I won't bother measuring.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3356#issuecomment-370564846
https://github.com/broadinstitute/cromwell/pull/3356#issuecomment-370571661:403,Integrability,depend,dependencies,403,"To clarify after discussion with @mcovarr:; This is a per-workflow limitation: each workflow chooses not to start new jobs until it sees its number of ""queued jobs"" go under a certain limit.; It doesn't protect against someone starting 10 million workflows with 1 job. That's what the token dispenser does.; It would make it more difficult to distinguish between a job that can't be started because its dependencies are not fulfilled and a job that is not being started because there are too many queued jobs already: they would both have the same `NotStarted` status. We could introduce a new status but this has a cost in terms of educating users etc...; This seems TechTalk worthy",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3356#issuecomment-370571661
https://github.com/broadinstitute/cromwell/pull/3356#issuecomment-370571661:152,Performance,queue,queued,152,"To clarify after discussion with @mcovarr:; This is a per-workflow limitation: each workflow chooses not to start new jobs until it sees its number of ""queued jobs"" go under a certain limit.; It doesn't protect against someone starting 10 million workflows with 1 job. That's what the token dispenser does.; It would make it more difficult to distinguish between a job that can't be started because its dependencies are not fulfilled and a job that is not being started because there are too many queued jobs already: they would both have the same `NotStarted` status. We could introduce a new status but this has a cost in terms of educating users etc...; This seems TechTalk worthy",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3356#issuecomment-370571661
https://github.com/broadinstitute/cromwell/pull/3356#issuecomment-370571661:497,Performance,queue,queued,497,"To clarify after discussion with @mcovarr:; This is a per-workflow limitation: each workflow chooses not to start new jobs until it sees its number of ""queued jobs"" go under a certain limit.; It doesn't protect against someone starting 10 million workflows with 1 job. That's what the token dispenser does.; It would make it more difficult to distinguish between a job that can't be started because its dependencies are not fulfilled and a job that is not being started because there are too many queued jobs already: they would both have the same `NotStarted` status. We could introduce a new status but this has a cost in terms of educating users etc...; This seems TechTalk worthy",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3356#issuecomment-370571661
https://github.com/broadinstitute/cromwell/pull/3356#issuecomment-370621740:419,Availability,resilien,resiliency,419,"I think the effect is fine. We often tell people that once a job is runnable that Cromwell fires it off, but that's always used as a way to help them understand that Cromwell isn't partaking in true scheduling (ie resource based negotiation via SGE, PAPI, etc). IMO it's absolutely ok for jobs which are runnable to have not started if that's the limitation the system imposes. Further, I think it's a good move in the resiliency front. Infinite scalability is a great goal, but from a practical perspective a limit is always going to be reached, so finding ways to make the system manage to keep on ticking ok when that happens is a good thing. That's generally going to involve slowing things down.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3356#issuecomment-370621740
https://github.com/broadinstitute/cromwell/pull/3356#issuecomment-370621740:695,Availability,down,down,695,"I think the effect is fine. We often tell people that once a job is runnable that Cromwell fires it off, but that's always used as a way to help them understand that Cromwell isn't partaking in true scheduling (ie resource based negotiation via SGE, PAPI, etc). IMO it's absolutely ok for jobs which are runnable to have not started if that's the limitation the system imposes. Further, I think it's a good move in the resiliency front. Infinite scalability is a great goal, but from a practical perspective a limit is always going to be reached, so finding ways to make the system manage to keep on ticking ok when that happens is a good thing. That's generally going to involve slowing things down.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3356#issuecomment-370621740
https://github.com/broadinstitute/cromwell/pull/3356#issuecomment-370621740:199,Energy Efficiency,schedul,scheduling,199,"I think the effect is fine. We often tell people that once a job is runnable that Cromwell fires it off, but that's always used as a way to help them understand that Cromwell isn't partaking in true scheduling (ie resource based negotiation via SGE, PAPI, etc). IMO it's absolutely ok for jobs which are runnable to have not started if that's the limitation the system imposes. Further, I think it's a good move in the resiliency front. Infinite scalability is a great goal, but from a practical perspective a limit is always going to be reached, so finding ways to make the system manage to keep on ticking ok when that happens is a good thing. That's generally going to involve slowing things down.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3356#issuecomment-370621740
https://github.com/broadinstitute/cromwell/pull/3356#issuecomment-370621740:446,Performance,scalab,scalability,446,"I think the effect is fine. We often tell people that once a job is runnable that Cromwell fires it off, but that's always used as a way to help them understand that Cromwell isn't partaking in true scheduling (ie resource based negotiation via SGE, PAPI, etc). IMO it's absolutely ok for jobs which are runnable to have not started if that's the limitation the system imposes. Further, I think it's a good move in the resiliency front. Infinite scalability is a great goal, but from a practical perspective a limit is always going to be reached, so finding ways to make the system manage to keep on ticking ok when that happens is a good thing. That's generally going to involve slowing things down.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3356#issuecomment-370621740
https://github.com/broadinstitute/cromwell/pull/3356#issuecomment-371150276:61,Deployability,release,release,61,After tech talk discussion this is in standby until after we release,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3356#issuecomment-371150276
https://github.com/broadinstitute/cromwell/pull/3356#issuecomment-373187082:34,Deployability,release,released,34,mergeable now that we've (you've) released?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3356#issuecomment-373187082
https://github.com/broadinstitute/cromwell/pull/3356#issuecomment-373188385:115,Deployability,update,updated,115,"I think so, if you and @kshakir or someone else don't mind giving it a second look that'd be nice though because I updated it a bit last week after realizing it was broken in some case.; I should also probably update the changelog to advertise the introduction of `WaitingForQueueSpace` status",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3356#issuecomment-373188385
https://github.com/broadinstitute/cromwell/pull/3356#issuecomment-373188385:210,Deployability,update,update,210,"I think so, if you and @kshakir or someone else don't mind giving it a second look that'd be nice though because I updated it a bit last week after realizing it was broken in some case.; I should also probably update the changelog to advertise the introduction of `WaitingForQueueSpace` status",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3356#issuecomment-373188385
https://github.com/broadinstitute/cromwell/issues/3359#issuecomment-370636226:170,Performance,optimiz,optimization,170,Note from [an earlier PR](https://github.com/broadinstitute/cromwell/pull/3350#discussion_r172275966): File literals can happen on input or output. There may be room for optimization if a file has already loaded contents we may not need to reload it twice. Follow the wiring/specs/conformance-tests and see if this makes sense.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3359#issuecomment-370636226
https://github.com/broadinstitute/cromwell/issues/3359#issuecomment-370636226:205,Performance,load,loaded,205,Note from [an earlier PR](https://github.com/broadinstitute/cromwell/pull/3350#discussion_r172275966): File literals can happen on input or output. There may be room for optimization if a file has already loaded contents we may not need to reload it twice. Follow the wiring/specs/conformance-tests and see if this makes sense.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3359#issuecomment-370636226
https://github.com/broadinstitute/cromwell/issues/3359#issuecomment-370636226:293,Testability,test,tests,293,Note from [an earlier PR](https://github.com/broadinstitute/cromwell/pull/3350#discussion_r172275966): File literals can happen on input or output. There may be room for optimization if a file has already loaded contents we may not need to reload it twice. Follow the wiring/specs/conformance-tests and see if this makes sense.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3359#issuecomment-370636226
https://github.com/broadinstitute/cromwell/pull/3366#issuecomment-370923521:94,Performance,load,load,94,"ToL: (you can never get enough of a good thing...): being able to see a graph of components' ""load level"" over time would be awesome...!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3366#issuecomment-370923521
https://github.com/broadinstitute/cromwell/pull/3366#issuecomment-370929227:78,Performance,throughput,throughput,78,"@cjllanwarne yep ! üòÑ That was an earlier run I've been trying to improve PAPI throughput but it's one of the highest ""load generators"" for now",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3366#issuecomment-370929227
https://github.com/broadinstitute/cromwell/pull/3366#issuecomment-370929227:118,Performance,load,load,118,"@cjllanwarne yep ! üòÑ That was an earlier run I've been trying to improve PAPI throughput but it's one of the highest ""load generators"" for now",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3366#issuecomment-370929227
https://github.com/broadinstitute/cromwell/pull/3366#issuecomment-370929479:8,Integrability,depend,depends,8,"It also depends on the situation Cromwell is dealing with, in other circumstances I/O was the main limiter for instance",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3366#issuecomment-370929479
https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371154240:121,Availability,robust,robust,121,"I think that this is related with https://github.com/docker/machine/issues/2517, but I believe that cromwell can be more robust to a container still running but detached due to timeout.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371154240
https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371154240:177,Safety,timeout,timeout,177,"I think that this is related with https://github.com/docker/machine/issues/2517, but I believe that cromwell can be more robust to a container still running but detached due to timeout.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371154240
https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371448526:73,Deployability,configurat,configuration,73,"I came out with a custom and dirty way of going around this issue. In my configuration file, I changed the `backend.providers.Local.config.submit-docker` script for the following:. ```bash; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile ${docker_cid} \; -i \; ${""--user "" + docker_user} \; --entrypoint /bin/bash \; -v ${cwd}:${docker_cwd} \; ${docker} ${script}. # get the return code (working even if the container was detached); rc=$(docker wait `cat ${docker_cid}`). # remove the container after waiting; docker rm `cat ${docker_cid}`. # return exit code; exit $rc; ```. Maybe this could be the default value in the [reference configuration file](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf) to solve the problem, but maybe it is better to have a `post-docker` configuration which is added to the pipeline similar to the `script-epilogue`. This would make easier the configuration of docker runs, separating submission and checks. By now, I will use the following local configuration to continue my work with the cromwell runner:. ```; include required(classpath(""application"")). ## keep always the workflow logs; workflow-options.workflow-log-temporary: false. backend.providers.Local.config {; ## limit the number of jobs; concurrent-job-limit = 15; # set the root directory to the run; filesystems.local {; ## do not allow copy (huge files); localization: [""hard-link"", ""soft-link""]; caching.duplication-strategy: [""hard-link"", ""soft-link""]; }; # custom submit-docker to workaround detached container due to timeout in the virtual machine; # first, we do not remove the container until it really finishes (no --rm flag); # if the docker run command fails, then it runs docker wait to wait until it finishes and store the return code; # if the docker run command fails, then it runs docker wait to return the real exit code even if detached; # once it finishes, removes the docker containe",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371448526
https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371448526:215,Deployability,configurat,configuration,215,"I came out with a custom and dirty way of going around this issue. In my configuration file, I changed the `backend.providers.Local.config.submit-docker` script for the following:. ```bash; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile ${docker_cid} \; -i \; ${""--user "" + docker_user} \; --entrypoint /bin/bash \; -v ${cwd}:${docker_cwd} \; ${docker} ${script}. # get the return code (working even if the container was detached); rc=$(docker wait `cat ${docker_cid}`). # remove the container after waiting; docker rm `cat ${docker_cid}`. # return exit code; exit $rc; ```. Maybe this could be the default value in the [reference configuration file](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf) to solve the problem, but maybe it is better to have a `post-docker` configuration which is added to the pipeline similar to the `script-epilogue`. This would make easier the configuration of docker runs, separating submission and checks. By now, I will use the following local configuration to continue my work with the cromwell runner:. ```; include required(classpath(""application"")). ## keep always the workflow logs; workflow-options.workflow-log-temporary: false. backend.providers.Local.config {; ## limit the number of jobs; concurrent-job-limit = 15; # set the root directory to the run; filesystems.local {; ## do not allow copy (huge files); localization: [""hard-link"", ""soft-link""]; caching.duplication-strategy: [""hard-link"", ""soft-link""]; }; # custom submit-docker to workaround detached container due to timeout in the virtual machine; # first, we do not remove the container until it really finishes (no --rm flag); # if the docker run command fails, then it runs docker wait to wait until it finishes and store the return code; # if the docker run command fails, then it runs docker wait to return the real exit code even if detached; # once it finishes, removes the docker containe",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371448526
https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371448526:686,Deployability,configurat,configuration,686,"I came out with a custom and dirty way of going around this issue. In my configuration file, I changed the `backend.providers.Local.config.submit-docker` script for the following:. ```bash; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile ${docker_cid} \; -i \; ${""--user "" + docker_user} \; --entrypoint /bin/bash \; -v ${cwd}:${docker_cwd} \; ${docker} ${script}. # get the return code (working even if the container was detached); rc=$(docker wait `cat ${docker_cid}`). # remove the container after waiting; docker rm `cat ${docker_cid}`. # return exit code; exit $rc; ```. Maybe this could be the default value in the [reference configuration file](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf) to solve the problem, but maybe it is better to have a `post-docker` configuration which is added to the pipeline similar to the `script-epilogue`. This would make easier the configuration of docker runs, separating submission and checks. By now, I will use the following local configuration to continue my work with the cromwell runner:. ```; include required(classpath(""application"")). ## keep always the workflow logs; workflow-options.workflow-log-temporary: false. backend.providers.Local.config {; ## limit the number of jobs; concurrent-job-limit = 15; # set the root directory to the run; filesystems.local {; ## do not allow copy (huge files); localization: [""hard-link"", ""soft-link""]; caching.duplication-strategy: [""hard-link"", ""soft-link""]; }; # custom submit-docker to workaround detached container due to timeout in the virtual machine; # first, we do not remove the container until it really finishes (no --rm flag); # if the docker run command fails, then it runs docker wait to wait until it finishes and store the return code; # if the docker run command fails, then it runs docker wait to return the real exit code even if detached; # once it finishes, removes the docker containe",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371448526
https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371448526:871,Deployability,configurat,configuration,871,"I came out with a custom and dirty way of going around this issue. In my configuration file, I changed the `backend.providers.Local.config.submit-docker` script for the following:. ```bash; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile ${docker_cid} \; -i \; ${""--user "" + docker_user} \; --entrypoint /bin/bash \; -v ${cwd}:${docker_cwd} \; ${docker} ${script}. # get the return code (working even if the container was detached); rc=$(docker wait `cat ${docker_cid}`). # remove the container after waiting; docker rm `cat ${docker_cid}`. # return exit code; exit $rc; ```. Maybe this could be the default value in the [reference configuration file](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf) to solve the problem, but maybe it is better to have a `post-docker` configuration which is added to the pipeline similar to the `script-epilogue`. This would make easier the configuration of docker runs, separating submission and checks. By now, I will use the following local configuration to continue my work with the cromwell runner:. ```; include required(classpath(""application"")). ## keep always the workflow logs; workflow-options.workflow-log-temporary: false. backend.providers.Local.config {; ## limit the number of jobs; concurrent-job-limit = 15; # set the root directory to the run; filesystems.local {; ## do not allow copy (huge files); localization: [""hard-link"", ""soft-link""]; caching.duplication-strategy: [""hard-link"", ""soft-link""]; }; # custom submit-docker to workaround detached container due to timeout in the virtual machine; # first, we do not remove the container until it really finishes (no --rm flag); # if the docker run command fails, then it runs docker wait to wait until it finishes and store the return code; # if the docker run command fails, then it runs docker wait to return the real exit code even if detached; # once it finishes, removes the docker containe",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371448526
https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371448526:907,Deployability,pipeline,pipeline,907,"I came out with a custom and dirty way of going around this issue. In my configuration file, I changed the `backend.providers.Local.config.submit-docker` script for the following:. ```bash; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile ${docker_cid} \; -i \; ${""--user "" + docker_user} \; --entrypoint /bin/bash \; -v ${cwd}:${docker_cwd} \; ${docker} ${script}. # get the return code (working even if the container was detached); rc=$(docker wait `cat ${docker_cid}`). # remove the container after waiting; docker rm `cat ${docker_cid}`. # return exit code; exit $rc; ```. Maybe this could be the default value in the [reference configuration file](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf) to solve the problem, but maybe it is better to have a `post-docker` configuration which is added to the pipeline similar to the `script-epilogue`. This would make easier the configuration of docker runs, separating submission and checks. By now, I will use the following local configuration to continue my work with the cromwell runner:. ```; include required(classpath(""application"")). ## keep always the workflow logs; workflow-options.workflow-log-temporary: false. backend.providers.Local.config {; ## limit the number of jobs; concurrent-job-limit = 15; # set the root directory to the run; filesystems.local {; ## do not allow copy (huge files); localization: [""hard-link"", ""soft-link""]; caching.duplication-strategy: [""hard-link"", ""soft-link""]; }; # custom submit-docker to workaround detached container due to timeout in the virtual machine; # first, we do not remove the container until it really finishes (no --rm flag); # if the docker run command fails, then it runs docker wait to wait until it finishes and store the return code; # if the docker run command fails, then it runs docker wait to return the real exit code even if detached; # once it finishes, removes the docker containe",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371448526
https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371448526:977,Deployability,configurat,configuration,977,"I came out with a custom and dirty way of going around this issue. In my configuration file, I changed the `backend.providers.Local.config.submit-docker` script for the following:. ```bash; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile ${docker_cid} \; -i \; ${""--user "" + docker_user} \; --entrypoint /bin/bash \; -v ${cwd}:${docker_cwd} \; ${docker} ${script}. # get the return code (working even if the container was detached); rc=$(docker wait `cat ${docker_cid}`). # remove the container after waiting; docker rm `cat ${docker_cid}`. # return exit code; exit $rc; ```. Maybe this could be the default value in the [reference configuration file](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf) to solve the problem, but maybe it is better to have a `post-docker` configuration which is added to the pipeline similar to the `script-epilogue`. This would make easier the configuration of docker runs, separating submission and checks. By now, I will use the following local configuration to continue my work with the cromwell runner:. ```; include required(classpath(""application"")). ## keep always the workflow logs; workflow-options.workflow-log-temporary: false. backend.providers.Local.config {; ## limit the number of jobs; concurrent-job-limit = 15; # set the root directory to the run; filesystems.local {; ## do not allow copy (huge files); localization: [""hard-link"", ""soft-link""]; caching.duplication-strategy: [""hard-link"", ""soft-link""]; }; # custom submit-docker to workaround detached container due to timeout in the virtual machine; # first, we do not remove the container until it really finishes (no --rm flag); # if the docker run command fails, then it runs docker wait to wait until it finishes and store the return code; # if the docker run command fails, then it runs docker wait to return the real exit code even if detached; # once it finishes, removes the docker containe",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371448526
https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371448526:1080,Deployability,configurat,configuration,1080,"e, I changed the `backend.providers.Local.config.submit-docker` script for the following:. ```bash; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile ${docker_cid} \; -i \; ${""--user "" + docker_user} \; --entrypoint /bin/bash \; -v ${cwd}:${docker_cwd} \; ${docker} ${script}. # get the return code (working even if the container was detached); rc=$(docker wait `cat ${docker_cid}`). # remove the container after waiting; docker rm `cat ${docker_cid}`. # return exit code; exit $rc; ```. Maybe this could be the default value in the [reference configuration file](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf) to solve the problem, but maybe it is better to have a `post-docker` configuration which is added to the pipeline similar to the `script-epilogue`. This would make easier the configuration of docker runs, separating submission and checks. By now, I will use the following local configuration to continue my work with the cromwell runner:. ```; include required(classpath(""application"")). ## keep always the workflow logs; workflow-options.workflow-log-temporary: false. backend.providers.Local.config {; ## limit the number of jobs; concurrent-job-limit = 15; # set the root directory to the run; filesystems.local {; ## do not allow copy (huge files); localization: [""hard-link"", ""soft-link""]; caching.duplication-strategy: [""hard-link"", ""soft-link""]; }; # custom submit-docker to workaround detached container due to timeout in the virtual machine; # first, we do not remove the container until it really finishes (no --rm flag); # if the docker run command fails, then it runs docker wait to wait until it finishes and store the return code; # if the docker run command fails, then it runs docker wait to return the real exit code even if detached; # once it finishes, removes the docker container with docker rm; # finally, returns the ""real return code"" stored; submit-docker = """"""; ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371448526
https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371448526:2364,Deployability,configurat,configuration,2364,"com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf) to solve the problem, but maybe it is better to have a `post-docker` configuration which is added to the pipeline similar to the `script-epilogue`. This would make easier the configuration of docker runs, separating submission and checks. By now, I will use the following local configuration to continue my work with the cromwell runner:. ```; include required(classpath(""application"")). ## keep always the workflow logs; workflow-options.workflow-log-temporary: false. backend.providers.Local.config {; ## limit the number of jobs; concurrent-job-limit = 15; # set the root directory to the run; filesystems.local {; ## do not allow copy (huge files); localization: [""hard-link"", ""soft-link""]; caching.duplication-strategy: [""hard-link"", ""soft-link""]; }; # custom submit-docker to workaround detached container due to timeout in the virtual machine; # first, we do not remove the container until it really finishes (no --rm flag); # if the docker run command fails, then it runs docker wait to wait until it finishes and store the return code; # if the docker run command fails, then it runs docker wait to return the real exit code even if detached; # once it finishes, removes the docker container with docker rm; # finally, returns the ""real return code"" stored; submit-docker = """"""; docker run \; --cidfile ${docker_cid} \; -i \; ${""--user "" + docker_user} \; --entrypoint /bin/bash \; -v ${cwd}:${docker_cwd} \; ${docker} ${script}; rc=$(docker wait `cat ${docker_cid}`); docker rm `cat ${docker_cid}`; exit $rc; """"""; }; ```. By the way, it looks like the configuration of the local backend in the docs is still under development (http://cromwell.readthedocs.io/en/develop/tutorials/LocalBackendIntro/). I think that this kind of things can be part of the docs if not included as default in the source code - let me know if I can do something to help documenting the local end, which I am using as my default one.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371448526
https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371448526:73,Modifiability,config,configuration,73,"I came out with a custom and dirty way of going around this issue. In my configuration file, I changed the `backend.providers.Local.config.submit-docker` script for the following:. ```bash; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile ${docker_cid} \; -i \; ${""--user "" + docker_user} \; --entrypoint /bin/bash \; -v ${cwd}:${docker_cwd} \; ${docker} ${script}. # get the return code (working even if the container was detached); rc=$(docker wait `cat ${docker_cid}`). # remove the container after waiting; docker rm `cat ${docker_cid}`. # return exit code; exit $rc; ```. Maybe this could be the default value in the [reference configuration file](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf) to solve the problem, but maybe it is better to have a `post-docker` configuration which is added to the pipeline similar to the `script-epilogue`. This would make easier the configuration of docker runs, separating submission and checks. By now, I will use the following local configuration to continue my work with the cromwell runner:. ```; include required(classpath(""application"")). ## keep always the workflow logs; workflow-options.workflow-log-temporary: false. backend.providers.Local.config {; ## limit the number of jobs; concurrent-job-limit = 15; # set the root directory to the run; filesystems.local {; ## do not allow copy (huge files); localization: [""hard-link"", ""soft-link""]; caching.duplication-strategy: [""hard-link"", ""soft-link""]; }; # custom submit-docker to workaround detached container due to timeout in the virtual machine; # first, we do not remove the container until it really finishes (no --rm flag); # if the docker run command fails, then it runs docker wait to wait until it finishes and store the return code; # if the docker run command fails, then it runs docker wait to return the real exit code even if detached; # once it finishes, removes the docker containe",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371448526
https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371448526:132,Modifiability,config,config,132,"I came out with a custom and dirty way of going around this issue. In my configuration file, I changed the `backend.providers.Local.config.submit-docker` script for the following:. ```bash; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile ${docker_cid} \; -i \; ${""--user "" + docker_user} \; --entrypoint /bin/bash \; -v ${cwd}:${docker_cwd} \; ${docker} ${script}. # get the return code (working even if the container was detached); rc=$(docker wait `cat ${docker_cid}`). # remove the container after waiting; docker rm `cat ${docker_cid}`. # return exit code; exit $rc; ```. Maybe this could be the default value in the [reference configuration file](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf) to solve the problem, but maybe it is better to have a `post-docker` configuration which is added to the pipeline similar to the `script-epilogue`. This would make easier the configuration of docker runs, separating submission and checks. By now, I will use the following local configuration to continue my work with the cromwell runner:. ```; include required(classpath(""application"")). ## keep always the workflow logs; workflow-options.workflow-log-temporary: false. backend.providers.Local.config {; ## limit the number of jobs; concurrent-job-limit = 15; # set the root directory to the run; filesystems.local {; ## do not allow copy (huge files); localization: [""hard-link"", ""soft-link""]; caching.duplication-strategy: [""hard-link"", ""soft-link""]; }; # custom submit-docker to workaround detached container due to timeout in the virtual machine; # first, we do not remove the container until it really finishes (no --rm flag); # if the docker run command fails, then it runs docker wait to wait until it finishes and store the return code; # if the docker run command fails, then it runs docker wait to return the real exit code even if detached; # once it finishes, removes the docker containe",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371448526
https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371448526:215,Modifiability,config,configuration,215,"I came out with a custom and dirty way of going around this issue. In my configuration file, I changed the `backend.providers.Local.config.submit-docker` script for the following:. ```bash; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile ${docker_cid} \; -i \; ${""--user "" + docker_user} \; --entrypoint /bin/bash \; -v ${cwd}:${docker_cwd} \; ${docker} ${script}. # get the return code (working even if the container was detached); rc=$(docker wait `cat ${docker_cid}`). # remove the container after waiting; docker rm `cat ${docker_cid}`. # return exit code; exit $rc; ```. Maybe this could be the default value in the [reference configuration file](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf) to solve the problem, but maybe it is better to have a `post-docker` configuration which is added to the pipeline similar to the `script-epilogue`. This would make easier the configuration of docker runs, separating submission and checks. By now, I will use the following local configuration to continue my work with the cromwell runner:. ```; include required(classpath(""application"")). ## keep always the workflow logs; workflow-options.workflow-log-temporary: false. backend.providers.Local.config {; ## limit the number of jobs; concurrent-job-limit = 15; # set the root directory to the run; filesystems.local {; ## do not allow copy (huge files); localization: [""hard-link"", ""soft-link""]; caching.duplication-strategy: [""hard-link"", ""soft-link""]; }; # custom submit-docker to workaround detached container due to timeout in the virtual machine; # first, we do not remove the container until it really finishes (no --rm flag); # if the docker run command fails, then it runs docker wait to wait until it finishes and store the return code; # if the docker run command fails, then it runs docker wait to return the real exit code even if detached; # once it finishes, removes the docker containe",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371448526
https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371448526:686,Modifiability,config,configuration,686,"I came out with a custom and dirty way of going around this issue. In my configuration file, I changed the `backend.providers.Local.config.submit-docker` script for the following:. ```bash; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile ${docker_cid} \; -i \; ${""--user "" + docker_user} \; --entrypoint /bin/bash \; -v ${cwd}:${docker_cwd} \; ${docker} ${script}. # get the return code (working even if the container was detached); rc=$(docker wait `cat ${docker_cid}`). # remove the container after waiting; docker rm `cat ${docker_cid}`. # return exit code; exit $rc; ```. Maybe this could be the default value in the [reference configuration file](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf) to solve the problem, but maybe it is better to have a `post-docker` configuration which is added to the pipeline similar to the `script-epilogue`. This would make easier the configuration of docker runs, separating submission and checks. By now, I will use the following local configuration to continue my work with the cromwell runner:. ```; include required(classpath(""application"")). ## keep always the workflow logs; workflow-options.workflow-log-temporary: false. backend.providers.Local.config {; ## limit the number of jobs; concurrent-job-limit = 15; # set the root directory to the run; filesystems.local {; ## do not allow copy (huge files); localization: [""hard-link"", ""soft-link""]; caching.duplication-strategy: [""hard-link"", ""soft-link""]; }; # custom submit-docker to workaround detached container due to timeout in the virtual machine; # first, we do not remove the container until it really finishes (no --rm flag); # if the docker run command fails, then it runs docker wait to wait until it finishes and store the return code; # if the docker run command fails, then it runs docker wait to return the real exit code even if detached; # once it finishes, removes the docker containe",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371448526
https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371448526:871,Modifiability,config,configuration,871,"I came out with a custom and dirty way of going around this issue. In my configuration file, I changed the `backend.providers.Local.config.submit-docker` script for the following:. ```bash; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile ${docker_cid} \; -i \; ${""--user "" + docker_user} \; --entrypoint /bin/bash \; -v ${cwd}:${docker_cwd} \; ${docker} ${script}. # get the return code (working even if the container was detached); rc=$(docker wait `cat ${docker_cid}`). # remove the container after waiting; docker rm `cat ${docker_cid}`. # return exit code; exit $rc; ```. Maybe this could be the default value in the [reference configuration file](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf) to solve the problem, but maybe it is better to have a `post-docker` configuration which is added to the pipeline similar to the `script-epilogue`. This would make easier the configuration of docker runs, separating submission and checks. By now, I will use the following local configuration to continue my work with the cromwell runner:. ```; include required(classpath(""application"")). ## keep always the workflow logs; workflow-options.workflow-log-temporary: false. backend.providers.Local.config {; ## limit the number of jobs; concurrent-job-limit = 15; # set the root directory to the run; filesystems.local {; ## do not allow copy (huge files); localization: [""hard-link"", ""soft-link""]; caching.duplication-strategy: [""hard-link"", ""soft-link""]; }; # custom submit-docker to workaround detached container due to timeout in the virtual machine; # first, we do not remove the container until it really finishes (no --rm flag); # if the docker run command fails, then it runs docker wait to wait until it finishes and store the return code; # if the docker run command fails, then it runs docker wait to return the real exit code even if detached; # once it finishes, removes the docker containe",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371448526
https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371448526:977,Modifiability,config,configuration,977,"I came out with a custom and dirty way of going around this issue. In my configuration file, I changed the `backend.providers.Local.config.submit-docker` script for the following:. ```bash; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile ${docker_cid} \; -i \; ${""--user "" + docker_user} \; --entrypoint /bin/bash \; -v ${cwd}:${docker_cwd} \; ${docker} ${script}. # get the return code (working even if the container was detached); rc=$(docker wait `cat ${docker_cid}`). # remove the container after waiting; docker rm `cat ${docker_cid}`. # return exit code; exit $rc; ```. Maybe this could be the default value in the [reference configuration file](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf) to solve the problem, but maybe it is better to have a `post-docker` configuration which is added to the pipeline similar to the `script-epilogue`. This would make easier the configuration of docker runs, separating submission and checks. By now, I will use the following local configuration to continue my work with the cromwell runner:. ```; include required(classpath(""application"")). ## keep always the workflow logs; workflow-options.workflow-log-temporary: false. backend.providers.Local.config {; ## limit the number of jobs; concurrent-job-limit = 15; # set the root directory to the run; filesystems.local {; ## do not allow copy (huge files); localization: [""hard-link"", ""soft-link""]; caching.duplication-strategy: [""hard-link"", ""soft-link""]; }; # custom submit-docker to workaround detached container due to timeout in the virtual machine; # first, we do not remove the container until it really finishes (no --rm flag); # if the docker run command fails, then it runs docker wait to wait until it finishes and store the return code; # if the docker run command fails, then it runs docker wait to return the real exit code even if detached; # once it finishes, removes the docker containe",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371448526
https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371448526:1080,Modifiability,config,configuration,1080,"e, I changed the `backend.providers.Local.config.submit-docker` script for the following:. ```bash; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile ${docker_cid} \; -i \; ${""--user "" + docker_user} \; --entrypoint /bin/bash \; -v ${cwd}:${docker_cwd} \; ${docker} ${script}. # get the return code (working even if the container was detached); rc=$(docker wait `cat ${docker_cid}`). # remove the container after waiting; docker rm `cat ${docker_cid}`. # return exit code; exit $rc; ```. Maybe this could be the default value in the [reference configuration file](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf) to solve the problem, but maybe it is better to have a `post-docker` configuration which is added to the pipeline similar to the `script-epilogue`. This would make easier the configuration of docker runs, separating submission and checks. By now, I will use the following local configuration to continue my work with the cromwell runner:. ```; include required(classpath(""application"")). ## keep always the workflow logs; workflow-options.workflow-log-temporary: false. backend.providers.Local.config {; ## limit the number of jobs; concurrent-job-limit = 15; # set the root directory to the run; filesystems.local {; ## do not allow copy (huge files); localization: [""hard-link"", ""soft-link""]; caching.duplication-strategy: [""hard-link"", ""soft-link""]; }; # custom submit-docker to workaround detached container due to timeout in the virtual machine; # first, we do not remove the container until it really finishes (no --rm flag); # if the docker run command fails, then it runs docker wait to wait until it finishes and store the return code; # if the docker run command fails, then it runs docker wait to return the real exit code even if detached; # once it finishes, removes the docker container with docker rm; # finally, returns the ""real return code"" stored; submit-docker = """"""; ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371448526
https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371448526:1296,Modifiability,config,config,1296,"oint /bin/bash \; -v ${cwd}:${docker_cwd} \; ${docker} ${script}. # get the return code (working even if the container was detached); rc=$(docker wait `cat ${docker_cid}`). # remove the container after waiting; docker rm `cat ${docker_cid}`. # return exit code; exit $rc; ```. Maybe this could be the default value in the [reference configuration file](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf) to solve the problem, but maybe it is better to have a `post-docker` configuration which is added to the pipeline similar to the `script-epilogue`. This would make easier the configuration of docker runs, separating submission and checks. By now, I will use the following local configuration to continue my work with the cromwell runner:. ```; include required(classpath(""application"")). ## keep always the workflow logs; workflow-options.workflow-log-temporary: false. backend.providers.Local.config {; ## limit the number of jobs; concurrent-job-limit = 15; # set the root directory to the run; filesystems.local {; ## do not allow copy (huge files); localization: [""hard-link"", ""soft-link""]; caching.duplication-strategy: [""hard-link"", ""soft-link""]; }; # custom submit-docker to workaround detached container due to timeout in the virtual machine; # first, we do not remove the container until it really finishes (no --rm flag); # if the docker run command fails, then it runs docker wait to wait until it finishes and store the return code; # if the docker run command fails, then it runs docker wait to return the real exit code even if detached; # once it finishes, removes the docker container with docker rm; # finally, returns the ""real return code"" stored; submit-docker = """"""; docker run \; --cidfile ${docker_cid} \; -i \; ${""--user "" + docker_user} \; --entrypoint /bin/bash \; -v ${cwd}:${docker_cwd} \; ${docker} ${script}; rc=$(docker wait `cat ${docker_cid}`); docker rm `cat ${docker_cid}`; exit $rc; """"""; }; ```. By the way, it looks",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371448526
https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371448526:2364,Modifiability,config,configuration,2364,"com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf) to solve the problem, but maybe it is better to have a `post-docker` configuration which is added to the pipeline similar to the `script-epilogue`. This would make easier the configuration of docker runs, separating submission and checks. By now, I will use the following local configuration to continue my work with the cromwell runner:. ```; include required(classpath(""application"")). ## keep always the workflow logs; workflow-options.workflow-log-temporary: false. backend.providers.Local.config {; ## limit the number of jobs; concurrent-job-limit = 15; # set the root directory to the run; filesystems.local {; ## do not allow copy (huge files); localization: [""hard-link"", ""soft-link""]; caching.duplication-strategy: [""hard-link"", ""soft-link""]; }; # custom submit-docker to workaround detached container due to timeout in the virtual machine; # first, we do not remove the container until it really finishes (no --rm flag); # if the docker run command fails, then it runs docker wait to wait until it finishes and store the return code; # if the docker run command fails, then it runs docker wait to return the real exit code even if detached; # once it finishes, removes the docker container with docker rm; # finally, returns the ""real return code"" stored; submit-docker = """"""; docker run \; --cidfile ${docker_cid} \; -i \; ${""--user "" + docker_user} \; --entrypoint /bin/bash \; -v ${cwd}:${docker_cwd} \; ${docker} ${script}; rc=$(docker wait `cat ${docker_cid}`); docker rm `cat ${docker_cid}`; exit $rc; """"""; }; ```. By the way, it looks like the configuration of the local backend in the docs is still under development (http://cromwell.readthedocs.io/en/develop/tutorials/LocalBackendIntro/). I think that this kind of things can be part of the docs if not included as default in the source code - let me know if I can do something to help documenting the local end, which I am using as my default one.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371448526
https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371448526:1335,Performance,concurren,concurrent-job-limit,1335,"oint /bin/bash \; -v ${cwd}:${docker_cwd} \; ${docker} ${script}. # get the return code (working even if the container was detached); rc=$(docker wait `cat ${docker_cid}`). # remove the container after waiting; docker rm `cat ${docker_cid}`. # return exit code; exit $rc; ```. Maybe this could be the default value in the [reference configuration file](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf) to solve the problem, but maybe it is better to have a `post-docker` configuration which is added to the pipeline similar to the `script-epilogue`. This would make easier the configuration of docker runs, separating submission and checks. By now, I will use the following local configuration to continue my work with the cromwell runner:. ```; include required(classpath(""application"")). ## keep always the workflow logs; workflow-options.workflow-log-temporary: false. backend.providers.Local.config {; ## limit the number of jobs; concurrent-job-limit = 15; # set the root directory to the run; filesystems.local {; ## do not allow copy (huge files); localization: [""hard-link"", ""soft-link""]; caching.duplication-strategy: [""hard-link"", ""soft-link""]; }; # custom submit-docker to workaround detached container due to timeout in the virtual machine; # first, we do not remove the container until it really finishes (no --rm flag); # if the docker run command fails, then it runs docker wait to wait until it finishes and store the return code; # if the docker run command fails, then it runs docker wait to return the real exit code even if detached; # once it finishes, removes the docker container with docker rm; # finally, returns the ""real return code"" stored; submit-docker = """"""; docker run \; --cidfile ${docker_cid} \; -i \; ${""--user "" + docker_user} \; --entrypoint /bin/bash \; -v ${cwd}:${docker_cwd} \; ${docker} ${script}; rc=$(docker wait `cat ${docker_cid}`); docker rm `cat ${docker_cid}`; exit $rc; """"""; }; ```. By the way, it looks",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371448526
https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371448526:1621,Safety,timeout,timeout,1621,"com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf) to solve the problem, but maybe it is better to have a `post-docker` configuration which is added to the pipeline similar to the `script-epilogue`. This would make easier the configuration of docker runs, separating submission and checks. By now, I will use the following local configuration to continue my work with the cromwell runner:. ```; include required(classpath(""application"")). ## keep always the workflow logs; workflow-options.workflow-log-temporary: false. backend.providers.Local.config {; ## limit the number of jobs; concurrent-job-limit = 15; # set the root directory to the run; filesystems.local {; ## do not allow copy (huge files); localization: [""hard-link"", ""soft-link""]; caching.duplication-strategy: [""hard-link"", ""soft-link""]; }; # custom submit-docker to workaround detached container due to timeout in the virtual machine; # first, we do not remove the container until it really finishes (no --rm flag); # if the docker run command fails, then it runs docker wait to wait until it finishes and store the return code; # if the docker run command fails, then it runs docker wait to return the real exit code even if detached; # once it finishes, removes the docker container with docker rm; # finally, returns the ""real return code"" stored; submit-docker = """"""; docker run \; --cidfile ${docker_cid} \; -i \; ${""--user "" + docker_user} \; --entrypoint /bin/bash \; -v ${cwd}:${docker_cwd} \; ${docker} ${script}; rc=$(docker wait `cat ${docker_cid}`); docker rm `cat ${docker_cid}`; exit $rc; """"""; }; ```. By the way, it looks like the configuration of the local backend in the docs is still under development (http://cromwell.readthedocs.io/en/develop/tutorials/LocalBackendIntro/). I think that this kind of things can be part of the docs if not included as default in the source code - let me know if I can do something to help documenting the local end, which I am using as my default one.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371448526
https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371448526:1218,Testability,log,logs,1218,"configuration without --rm flag (will remove later); docker run \; --cidfile ${docker_cid} \; -i \; ${""--user "" + docker_user} \; --entrypoint /bin/bash \; -v ${cwd}:${docker_cwd} \; ${docker} ${script}. # get the return code (working even if the container was detached); rc=$(docker wait `cat ${docker_cid}`). # remove the container after waiting; docker rm `cat ${docker_cid}`. # return exit code; exit $rc; ```. Maybe this could be the default value in the [reference configuration file](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf) to solve the problem, but maybe it is better to have a `post-docker` configuration which is added to the pipeline similar to the `script-epilogue`. This would make easier the configuration of docker runs, separating submission and checks. By now, I will use the following local configuration to continue my work with the cromwell runner:. ```; include required(classpath(""application"")). ## keep always the workflow logs; workflow-options.workflow-log-temporary: false. backend.providers.Local.config {; ## limit the number of jobs; concurrent-job-limit = 15; # set the root directory to the run; filesystems.local {; ## do not allow copy (huge files); localization: [""hard-link"", ""soft-link""]; caching.duplication-strategy: [""hard-link"", ""soft-link""]; }; # custom submit-docker to workaround detached container due to timeout in the virtual machine; # first, we do not remove the container until it really finishes (no --rm flag); # if the docker run command fails, then it runs docker wait to wait until it finishes and store the return code; # if the docker run command fails, then it runs docker wait to return the real exit code even if detached; # once it finishes, removes the docker container with docker rm; # finally, returns the ""real return code"" stored; submit-docker = """"""; docker run \; --cidfile ${docker_cid} \; -i \; ${""--user "" + docker_user} \; --entrypoint /bin/bash \; -v ${cwd}:${docker_cwd",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371448526
https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371448526:1250,Testability,log,log-temporary,1250,"ove later); docker run \; --cidfile ${docker_cid} \; -i \; ${""--user "" + docker_user} \; --entrypoint /bin/bash \; -v ${cwd}:${docker_cwd} \; ${docker} ${script}. # get the return code (working even if the container was detached); rc=$(docker wait `cat ${docker_cid}`). # remove the container after waiting; docker rm `cat ${docker_cid}`. # return exit code; exit $rc; ```. Maybe this could be the default value in the [reference configuration file](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf) to solve the problem, but maybe it is better to have a `post-docker` configuration which is added to the pipeline similar to the `script-epilogue`. This would make easier the configuration of docker runs, separating submission and checks. By now, I will use the following local configuration to continue my work with the cromwell runner:. ```; include required(classpath(""application"")). ## keep always the workflow logs; workflow-options.workflow-log-temporary: false. backend.providers.Local.config {; ## limit the number of jobs; concurrent-job-limit = 15; # set the root directory to the run; filesystems.local {; ## do not allow copy (huge files); localization: [""hard-link"", ""soft-link""]; caching.duplication-strategy: [""hard-link"", ""soft-link""]; }; # custom submit-docker to workaround detached container due to timeout in the virtual machine; # first, we do not remove the container until it really finishes (no --rm flag); # if the docker run command fails, then it runs docker wait to wait until it finishes and store the return code; # if the docker run command fails, then it runs docker wait to return the real exit code even if detached; # once it finishes, removes the docker container with docker rm; # finally, returns the ""real return code"" stored; submit-docker = """"""; docker run \; --cidfile ${docker_cid} \; -i \; ${""--user "" + docker_user} \; --entrypoint /bin/bash \; -v ${cwd}:${docker_cwd} \; ${docker} ${script}; rc=$(docker wai",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3370#issuecomment-371448526
https://github.com/broadinstitute/cromwell/pull/3374#issuecomment-371528065:132,Availability,error,error,132,Red thumb required for two minor WOM changes (two files changed at the bottom of the PR - one gets a scaladoc and the other gets an error message improvement),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3374#issuecomment-371528065
https://github.com/broadinstitute/cromwell/pull/3374#issuecomment-371528065:138,Integrability,message,message,138,Red thumb required for two minor WOM changes (two files changed at the bottom of the PR - one gets a scaladoc and the other gets an error message improvement),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3374#issuecomment-371528065
https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580:345,Integrability,message,messages,345,"This PR merges into @Horneth's branch. Good news: The tests-formerly-known-as-root are now running under `server`!; Bad news:; ```; *** 3 TESTS FAILED ***; SimpleWorkflowActorSpec:; A WorkflowActor should ; - start, run, succeed and die *** FAILED *** (10 seconds, 174 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; SimpleWorkflowActorSpec:; A WorkflowActor should ; - fail when a call fails *** FAILED *** (10 seconds, 35 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_goodbye.goodbye:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; WorkflowExecutionActorSpec:; WorkflowExecutionActor ; - should allow a backend to tell it to retry... up to a point *** FAILED *** (10 seconds, 170 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 3 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActorSpec.$anonfun$new$1(WorkflowExecutionActorSpec.scala:84); ```. Still, as this isn't merging into develop feel free to press merge if you'd like.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580
https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580:861,Integrability,message,messages,861,"This PR merges into @Horneth's branch. Good news: The tests-formerly-known-as-root are now running under `server`!; Bad news:; ```; *** 3 TESTS FAILED ***; SimpleWorkflowActorSpec:; A WorkflowActor should ; - start, run, succeed and die *** FAILED *** (10 seconds, 174 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; SimpleWorkflowActorSpec:; A WorkflowActor should ; - fail when a call fails *** FAILED *** (10 seconds, 35 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_goodbye.goodbye:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; WorkflowExecutionActorSpec:; WorkflowExecutionActor ; - should allow a backend to tell it to retry... up to a point *** FAILED *** (10 seconds, 170 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 3 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActorSpec.$anonfun$new$1(WorkflowExecutionActorSpec.scala:84); ```. Still, as this isn't merging into develop feel free to press merge if you'd like.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580
https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580:1422,Integrability,message,messages,1422,"This PR merges into @Horneth's branch. Good news: The tests-formerly-known-as-root are now running under `server`!; Bad news:; ```; *** 3 TESTS FAILED ***; SimpleWorkflowActorSpec:; A WorkflowActor should ; - start, run, succeed and die *** FAILED *** (10 seconds, 174 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; SimpleWorkflowActorSpec:; A WorkflowActor should ; - fail when a call fails *** FAILED *** (10 seconds, 35 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_goodbye.goodbye:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; WorkflowExecutionActorSpec:; WorkflowExecutionActor ; - should allow a backend to tell it to retry... up to a point *** FAILED *** (10 seconds, 170 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 3 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActorSpec.$anonfun$new$1(WorkflowExecutionActorSpec.scala:84); ```. Still, as this isn't merging into develop feel free to press merge if you'd like.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580
https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580:310,Safety,timeout,timeout,310,"This PR merges into @Horneth's branch. Good news: The tests-formerly-known-as-root are now running under `server`!; Bad news:; ```; *** 3 TESTS FAILED ***; SimpleWorkflowActorSpec:; A WorkflowActor should ; - start, run, succeed and die *** FAILED *** (10 seconds, 174 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; SimpleWorkflowActorSpec:; A WorkflowActor should ; - fail when a call fails *** FAILED *** (10 seconds, 35 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_goodbye.goodbye:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; WorkflowExecutionActorSpec:; WorkflowExecutionActor ; - should allow a backend to tell it to retry... up to a point *** FAILED *** (10 seconds, 170 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 3 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActorSpec.$anonfun$new$1(WorkflowExecutionActorSpec.scala:84); ```. Still, as this isn't merging into develop feel free to press merge if you'd like.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580
https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580:826,Safety,timeout,timeout,826,"This PR merges into @Horneth's branch. Good news: The tests-formerly-known-as-root are now running under `server`!; Bad news:; ```; *** 3 TESTS FAILED ***; SimpleWorkflowActorSpec:; A WorkflowActor should ; - start, run, succeed and die *** FAILED *** (10 seconds, 174 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; SimpleWorkflowActorSpec:; A WorkflowActor should ; - fail when a call fails *** FAILED *** (10 seconds, 35 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_goodbye.goodbye:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; WorkflowExecutionActorSpec:; WorkflowExecutionActor ; - should allow a backend to tell it to retry... up to a point *** FAILED *** (10 seconds, 170 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 3 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActorSpec.$anonfun$new$1(WorkflowExecutionActorSpec.scala:84); ```. Still, as this isn't merging into develop feel free to press merge if you'd like.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580
https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580:1387,Safety,timeout,timeout,1387,"This PR merges into @Horneth's branch. Good news: The tests-formerly-known-as-root are now running under `server`!; Bad news:; ```; *** 3 TESTS FAILED ***; SimpleWorkflowActorSpec:; A WorkflowActor should ; - start, run, succeed and die *** FAILED *** (10 seconds, 174 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; SimpleWorkflowActorSpec:; A WorkflowActor should ; - fail when a call fails *** FAILED *** (10 seconds, 35 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_goodbye.goodbye:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; WorkflowExecutionActorSpec:; WorkflowExecutionActor ; - should allow a backend to tell it to retry... up to a point *** FAILED *** (10 seconds, 170 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 3 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActorSpec.$anonfun$new$1(WorkflowExecutionActorSpec.scala:84); ```. Still, as this isn't merging into develop feel free to press merge if you'd like.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580
https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580:54,Testability,test,tests-formerly-known-as-root,54,"This PR merges into @Horneth's branch. Good news: The tests-formerly-known-as-root are now running under `server`!; Bad news:; ```; *** 3 TESTS FAILED ***; SimpleWorkflowActorSpec:; A WorkflowActor should ; - start, run, succeed and die *** FAILED *** (10 seconds, 174 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; SimpleWorkflowActorSpec:; A WorkflowActor should ; - fail when a call fails *** FAILED *** (10 seconds, 35 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_goodbye.goodbye:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; WorkflowExecutionActorSpec:; WorkflowExecutionActor ; - should allow a backend to tell it to retry... up to a point *** FAILED *** (10 seconds, 170 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 3 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActorSpec.$anonfun$new$1(WorkflowExecutionActorSpec.scala:84); ```. Still, as this isn't merging into develop feel free to press merge if you'd like.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580
https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580:138,Testability,TEST,TESTS,138,"This PR merges into @Horneth's branch. Good news: The tests-formerly-known-as-root are now running under `server`!; Bad news:; ```; *** 3 TESTS FAILED ***; SimpleWorkflowActorSpec:; A WorkflowActor should ; - start, run, succeed and die *** FAILED *** (10 seconds, 174 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; SimpleWorkflowActorSpec:; A WorkflowActor should ; - fail when a call fails *** FAILED *** (10 seconds, 35 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_goodbye.goodbye:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; WorkflowExecutionActorSpec:; WorkflowExecutionActor ; - should allow a backend to tell it to retry... up to a point *** FAILED *** (10 seconds, 170 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 3 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActorSpec.$anonfun$new$1(WorkflowExecutionActorSpec.scala:84); ```. Still, as this isn't merging into develop feel free to press merge if you'd like.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580
https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580:294,Testability,Assert,AssertionError,294,"This PR merges into @Horneth's branch. Good news: The tests-formerly-known-as-root are now running under `server`!; Bad news:; ```; *** 3 TESTS FAILED ***; SimpleWorkflowActorSpec:; A WorkflowActor should ; - start, run, succeed and die *** FAILED *** (10 seconds, 174 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; SimpleWorkflowActorSpec:; A WorkflowActor should ; - fail when a call fails *** FAILED *** (10 seconds, 35 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_goodbye.goodbye:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; WorkflowExecutionActorSpec:; WorkflowExecutionActor ; - should allow a backend to tell it to retry... up to a point *** FAILED *** (10 seconds, 170 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 3 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActorSpec.$anonfun$new$1(WorkflowExecutionActorSpec.scala:84); ```. Still, as this isn't merging into develop feel free to press merge if you'd like.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580
https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580:433,Testability,test,testkit,433,"This PR merges into @Horneth's branch. Good news: The tests-formerly-known-as-root are now running under `server`!; Bad news:; ```; *** 3 TESTS FAILED ***; SimpleWorkflowActorSpec:; A WorkflowActor should ; - start, run, succeed and die *** FAILED *** (10 seconds, 174 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; SimpleWorkflowActorSpec:; A WorkflowActor should ; - fail when a call fails *** FAILED *** (10 seconds, 35 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_goodbye.goodbye:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; WorkflowExecutionActorSpec:; WorkflowExecutionActor ; - should allow a backend to tell it to retry... up to a point *** FAILED *** (10 seconds, 170 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 3 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActorSpec.$anonfun$new$1(WorkflowExecutionActorSpec.scala:84); ```. Still, as this isn't merging into develop feel free to press merge if you'd like.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580
https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580:463,Testability,Test,TestEventListener,463,"This PR merges into @Horneth's branch. Good news: The tests-formerly-known-as-root are now running under `server`!; Bad news:; ```; *** 3 TESTS FAILED ***; SimpleWorkflowActorSpec:; A WorkflowActor should ; - start, run, succeed and die *** FAILED *** (10 seconds, 174 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; SimpleWorkflowActorSpec:; A WorkflowActor should ; - fail when a call fails *** FAILED *** (10 seconds, 35 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_goodbye.goodbye:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; WorkflowExecutionActorSpec:; WorkflowExecutionActor ; - should allow a backend to tell it to retry... up to a point *** FAILED *** (10 seconds, 170 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 3 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActorSpec.$anonfun$new$1(WorkflowExecutionActorSpec.scala:84); ```. Still, as this isn't merging into develop feel free to press merge if you'd like.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580
https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580:810,Testability,Assert,AssertionError,810,"This PR merges into @Horneth's branch. Good news: The tests-formerly-known-as-root are now running under `server`!; Bad news:; ```; *** 3 TESTS FAILED ***; SimpleWorkflowActorSpec:; A WorkflowActor should ; - start, run, succeed and die *** FAILED *** (10 seconds, 174 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; SimpleWorkflowActorSpec:; A WorkflowActor should ; - fail when a call fails *** FAILED *** (10 seconds, 35 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_goodbye.goodbye:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; WorkflowExecutionActorSpec:; WorkflowExecutionActor ; - should allow a backend to tell it to retry... up to a point *** FAILED *** (10 seconds, 170 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 3 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActorSpec.$anonfun$new$1(WorkflowExecutionActorSpec.scala:84); ```. Still, as this isn't merging into develop feel free to press merge if you'd like.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580
https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580:953,Testability,test,testkit,953,"This PR merges into @Horneth's branch. Good news: The tests-formerly-known-as-root are now running under `server`!; Bad news:; ```; *** 3 TESTS FAILED ***; SimpleWorkflowActorSpec:; A WorkflowActor should ; - start, run, succeed and die *** FAILED *** (10 seconds, 174 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; SimpleWorkflowActorSpec:; A WorkflowActor should ; - fail when a call fails *** FAILED *** (10 seconds, 35 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_goodbye.goodbye:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; WorkflowExecutionActorSpec:; WorkflowExecutionActor ; - should allow a backend to tell it to retry... up to a point *** FAILED *** (10 seconds, 170 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 3 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActorSpec.$anonfun$new$1(WorkflowExecutionActorSpec.scala:84); ```. Still, as this isn't merging into develop feel free to press merge if you'd like.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580
https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580:983,Testability,Test,TestEventListener,983,"This PR merges into @Horneth's branch. Good news: The tests-formerly-known-as-root are now running under `server`!; Bad news:; ```; *** 3 TESTS FAILED ***; SimpleWorkflowActorSpec:; A WorkflowActor should ; - start, run, succeed and die *** FAILED *** (10 seconds, 174 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; SimpleWorkflowActorSpec:; A WorkflowActor should ; - fail when a call fails *** FAILED *** (10 seconds, 35 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_goodbye.goodbye:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; WorkflowExecutionActorSpec:; WorkflowExecutionActor ; - should allow a backend to tell it to retry... up to a point *** FAILED *** (10 seconds, 170 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 3 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActorSpec.$anonfun$new$1(WorkflowExecutionActorSpec.scala:84); ```. Still, as this isn't merging into develop feel free to press merge if you'd like.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580
https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580:1371,Testability,Assert,AssertionError,1371,"This PR merges into @Horneth's branch. Good news: The tests-formerly-known-as-root are now running under `server`!; Bad news:; ```; *** 3 TESTS FAILED ***; SimpleWorkflowActorSpec:; A WorkflowActor should ; - start, run, succeed and die *** FAILED *** (10 seconds, 174 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; SimpleWorkflowActorSpec:; A WorkflowActor should ; - fail when a call fails *** FAILED *** (10 seconds, 35 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_goodbye.goodbye:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; WorkflowExecutionActorSpec:; WorkflowExecutionActor ; - should allow a backend to tell it to retry... up to a point *** FAILED *** (10 seconds, 170 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 3 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActorSpec.$anonfun$new$1(WorkflowExecutionActorSpec.scala:84); ```. Still, as this isn't merging into develop feel free to press merge if you'd like.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580
https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580:1504,Testability,test,testkit,1504,"This PR merges into @Horneth's branch. Good news: The tests-formerly-known-as-root are now running under `server`!; Bad news:; ```; *** 3 TESTS FAILED ***; SimpleWorkflowActorSpec:; A WorkflowActor should ; - start, run, succeed and die *** FAILED *** (10 seconds, 174 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; SimpleWorkflowActorSpec:; A WorkflowActor should ; - fail when a call fails *** FAILED *** (10 seconds, 35 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_goodbye.goodbye:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; WorkflowExecutionActorSpec:; WorkflowExecutionActor ; - should allow a backend to tell it to retry... up to a point *** FAILED *** (10 seconds, 170 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 3 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActorSpec.$anonfun$new$1(WorkflowExecutionActorSpec.scala:84); ```. Still, as this isn't merging into develop feel free to press merge if you'd like.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580
https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580:1534,Testability,Test,TestEventListener,1534,"This PR merges into @Horneth's branch. Good news: The tests-formerly-known-as-root are now running under `server`!; Bad news:; ```; *** 3 TESTS FAILED ***; SimpleWorkflowActorSpec:; A WorkflowActor should ; - start, run, succeed and die *** FAILED *** (10 seconds, 174 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; SimpleWorkflowActorSpec:; A WorkflowActor should ; - fail when a call fails *** FAILED *** (10 seconds, 35 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_goodbye.goodbye:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; WorkflowExecutionActorSpec:; WorkflowExecutionActor ; - should allow a backend to tell it to retry... up to a point *** FAILED *** (10 seconds, 170 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 3 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActorSpec.$anonfun$new$1(WorkflowExecutionActorSpec.scala:84); ```. Still, as this isn't merging into develop feel free to press merge if you'd like.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580
https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580:156,Usability,Simpl,SimpleWorkflowActorSpec,156,"This PR merges into @Horneth's branch. Good news: The tests-formerly-known-as-root are now running under `server`!; Bad news:; ```; *** 3 TESTS FAILED ***; SimpleWorkflowActorSpec:; A WorkflowActor should ; - start, run, succeed and die *** FAILED *** (10 seconds, 174 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; SimpleWorkflowActorSpec:; A WorkflowActor should ; - fail when a call fails *** FAILED *** (10 seconds, 35 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_goodbye.goodbye:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; WorkflowExecutionActorSpec:; WorkflowExecutionActor ; - should allow a backend to tell it to retry... up to a point *** FAILED *** (10 seconds, 170 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 3 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActorSpec.$anonfun$new$1(WorkflowExecutionActorSpec.scala:84); ```. Still, as this isn't merging into develop feel free to press merge if you'd like.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580
https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580:582,Usability,Simpl,SimpleWorkflowActorSpec,582,"This PR merges into @Horneth's branch. Good news: The tests-formerly-known-as-root are now running under `server`!; Bad news:; ```; *** 3 TESTS FAILED ***; SimpleWorkflowActorSpec:; A WorkflowActor should ; - start, run, succeed and die *** FAILED *** (10 seconds, 174 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; SimpleWorkflowActorSpec:; A WorkflowActor should ; - fail when a call fails *** FAILED *** (10 seconds, 35 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_goodbye.goodbye:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; WorkflowExecutionActorSpec:; WorkflowExecutionActor ; - should allow a backend to tell it to retry... up to a point *** FAILED *** (10 seconds, 170 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 3 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActorSpec.$anonfun$new$1(WorkflowExecutionActorSpec.scala:84); ```. Still, as this isn't merging into develop feel free to press merge if you'd like.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580
https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580:637,Usability,Simpl,SimpleWorkflowActorSpec,637,"This PR merges into @Horneth's branch. Good news: The tests-formerly-known-as-root are now running under `server`!; Bad news:; ```; *** 3 TESTS FAILED ***; SimpleWorkflowActorSpec:; A WorkflowActor should ; - start, run, succeed and die *** FAILED *** (10 seconds, 174 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; SimpleWorkflowActorSpec:; A WorkflowActor should ; - fail when a call fails *** FAILED *** (10 seconds, 35 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_goodbye.goodbye:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; WorkflowExecutionActorSpec:; WorkflowExecutionActor ; - should allow a backend to tell it to retry... up to a point *** FAILED *** (10 seconds, 170 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 3 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActorSpec.$anonfun$new$1(WorkflowExecutionActorSpec.scala:84); ```. Still, as this isn't merging into develop feel free to press merge if you'd like.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580
https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580:678,Usability,Simpl,SimpleWorkflowActorSpec,678,"This PR merges into @Horneth's branch. Good news: The tests-formerly-known-as-root are now running under `server`!; Bad news:; ```; *** 3 TESTS FAILED ***; SimpleWorkflowActorSpec:; A WorkflowActor should ; - start, run, succeed and die *** FAILED *** (10 seconds, 174 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; SimpleWorkflowActorSpec:; A WorkflowActor should ; - fail when a call fails *** FAILED *** (10 seconds, 35 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_goodbye.goodbye:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; WorkflowExecutionActorSpec:; WorkflowExecutionActor ; - should allow a backend to tell it to retry... up to a point *** FAILED *** (10 seconds, 170 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 3 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActorSpec.$anonfun$new$1(WorkflowExecutionActorSpec.scala:84); ```. Still, as this isn't merging into develop feel free to press merge if you'd like.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580
https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580:1102,Usability,Simpl,SimpleWorkflowActorSpec,1102,"This PR merges into @Horneth's branch. Good news: The tests-formerly-known-as-root are now running under `server`!; Bad news:; ```; *** 3 TESTS FAILED ***; SimpleWorkflowActorSpec:; A WorkflowActor should ; - start, run, succeed and die *** FAILED *** (10 seconds, 174 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; SimpleWorkflowActorSpec:; A WorkflowActor should ; - fail when a call fails *** FAILED *** (10 seconds, 35 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_goodbye.goodbye:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; WorkflowExecutionActorSpec:; WorkflowExecutionActor ; - should allow a backend to tell it to retry... up to a point *** FAILED *** (10 seconds, 170 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 3 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActorSpec.$anonfun$new$1(WorkflowExecutionActorSpec.scala:84); ```. Still, as this isn't merging into develop feel free to press merge if you'd like.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580
https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580:1157,Usability,Simpl,SimpleWorkflowActorSpec,1157,"This PR merges into @Horneth's branch. Good news: The tests-formerly-known-as-root are now running under `server`!; Bad news:; ```; *** 3 TESTS FAILED ***; SimpleWorkflowActorSpec:; A WorkflowActor should ; - start, run, succeed and die *** FAILED *** (10 seconds, 174 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; SimpleWorkflowActorSpec:; A WorkflowActor should ; - fail when a call fails *** FAILED *** (10 seconds, 35 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 1 messages on InfoFilter(None,Right(Starting calls: wf_goodbye.goodbye:NA:1$),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.CromwellTestKitSpec$.waitForInfo(CromwellTestKitSpec.scala:129); at cromwell.SimpleWorkflowActorSpec.$anonfun$startingCallsFilter$1(SimpleWorkflowActorSpec.scala:186); ...; WorkflowExecutionActorSpec:; WorkflowExecutionActor ; - should allow a backend to tell it to retry... up to a point *** FAILED *** (10 seconds, 170 milliseconds); java.lang.AssertionError: timeout (10 seconds) waiting for 3 messages on InfoFilter(None,Right(Starting calls: wf_hello.hello),false); at akka.testkit.EventFilter.intercept(TestEventListener.scala:114); at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActorSpec.$anonfun$new$1(WorkflowExecutionActorSpec.scala:84); ```. Still, as this isn't merging into develop feel free to press merge if you'd like.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371344580
https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371351341:73,Integrability,message,message,73,Ahhh I remember asking myself why no test failed when I changed this log message.; Those test should be fixable easily,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371351341
https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371351341:37,Testability,test,test,37,Ahhh I remember asking myself why no test failed when I changed this log message.; Those test should be fixable easily,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371351341
https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371351341:69,Testability,log,log,69,Ahhh I remember asking myself why no test failed when I changed this log message.; Those test should be fixable easily,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371351341
https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371351341:89,Testability,test,test,89,Ahhh I remember asking myself why no test failed when I changed this log message.; Those test should be fixable easily,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3375#issuecomment-371351341
https://github.com/broadinstitute/cromwell/pull/3379#issuecomment-371580539:10,Deployability,patch,patch,10,> codecov/patch ‚Äî 100% of diff hit (target 50%). ... nice!,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3379#issuecomment-371580539
https://github.com/broadinstitute/cromwell/issues/3383#issuecomment-414086585:239,Deployability,pipeline,pipeline,239,">. As you're aware there's a discussion on OpenWDL regarding the Directory type. closing in favor of that. The key question is when are you going to add Directory type to cromwell? I am quite pragmatic regarding cromwell, many tools in my pipeline require folders instead of files and I have to make it work somehow",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3383#issuecomment-414086585
https://github.com/broadinstitute/cromwell/issues/3384#issuecomment-371697922:22,Usability,clear,clear,22,"@yfarjoun just so i'm clear are you providing the version number to suggest that it used to work, or just because it's generally a useful thing to include?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3384#issuecomment-371697922
https://github.com/broadinstitute/cromwell/issues/3384#issuecomment-371866116:15,Usability,simpl,simple,15,This should be simple enough to fix for 31 (I think I still have time...). interestingly the if/then/else do already short circuit so this should work:; ```wdl; if (if defined(optional_int) then select_first([optional_int]) == 2 else false) { ... }; ```; ... on the other hand the nested if is probably an even easier workaround,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3384#issuecomment-371866116
https://github.com/broadinstitute/cromwell/issues/3384#issuecomment-888789768:290,Modifiability,plugin,plugin,290,"Is this valid WDL from mutect2.wdl line [982](https://github.com/broadinstitute/gatk/blob/4.2.0.0/scripts/mutect2_wdl/mutect2.wdl#L982)?; `String filter_funcotations_args = if defined(filter_funcotations) && (filter_funcotations) then "" --remove-filtered-variants "" else """"`. Visual Studio plugin seems to complain with `optional Boolean? operand to &&` probably because in the task `filter_funcotations` is optional. Just wondering???",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3384#issuecomment-888789768
https://github.com/broadinstitute/cromwell/issues/3387#issuecomment-372264453:2613,Availability,avail,available,2613,"Try.scala:209); 	at cromwell.CromwellEntryPoint$.buildCromwellSystem(CromwellEntryPoint.scala:63); 	at cromwell.CromwellEntryPoint$.runSingle(CromwellEntryPoint.scala:47); 	at cromwell.CommandLineParser$.runCromwell(CommandLineParser.scala:95); 	at cromwell.CommandLineParser$.delayedEndpoint$cromwell$CommandLineParser$1(CommandLineParser.scala:105); 	at cromwell.CommandLineParser$delayedInit$body.apply(CommandLineParser.scala:8); 	at scala.Function0.apply$mcV$sp(Function0.scala:34); 	at scala.Function0.apply$mcV$sp$(Function0.scala:34); 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12); 	at scala.App.$anonfun$main$1$adapted(App.scala:76); 	at scala.collection.immutable.List.foreach(List.scala:389); 	at scala.App.main(App.scala:76); 	at scala.App.main$(App.scala:74); 	at cromwell.CommandLineParser$.main(CommandLineParser.scala:8); 	at cromwell.CommandLineParser.main(CommandLineParser.scala); Caused by: java.sql.SQLTransientConnectionException: db - Connection is not available, request timed out after 5004ms.; 	at com.zaxxer.hikari.pool.HikariPool.createTimeoutException(HikariPool.java:548); 	at com.zaxxer.hikari.pool.HikariPool.getConnection(HikariPool.java:186); 	at com.zaxxer.hikari.pool.HikariPool.getConnection(HikariPool.java:145); 	at com.zaxxer.hikari.HikariDataSource.getConnection(HikariDataSource.java:83); 	at slick.jdbc.hikaricp.HikariCPJdbcDataSource.createConnection(HikariCPJdbcDataSource.scala:18); 	at slick.jdbc.JdbcBackend$BaseSession.<init>(JdbcBackend.scala:439); 	at slick.jdbc.JdbcBackend$DatabaseDef.createSession(JdbcBackend.scala:47); 	at slick.jdbc.JdbcBackend$DatabaseDef.createSession(JdbcBackend.scala:38); 	at slick.basic.BasicBackend$DatabaseDef.acquireSession(BasicBackend.scala:218); 	at slick.basic.BasicBackend$DatabaseDef.acquireSession$(BasicBackend.scala:217); 	at slick.jdbc.JdbcBackend$DatabaseDef.acquireSession(JdbcBackend.scala:38); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:239); ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3387#issuecomment-372264453
https://github.com/broadinstitute/cromwell/issues/3387#issuecomment-372264453:3907,Availability,failure,failure,3907,	at com.zaxxer.hikari.HikariDataSource.getConnection(HikariDataSource.java:83); 	at slick.jdbc.hikaricp.HikariCPJdbcDataSource.createConnection(HikariCPJdbcDataSource.scala:18); 	at slick.jdbc.JdbcBackend$BaseSession.<init>(JdbcBackend.scala:439); 	at slick.jdbc.JdbcBackend$DatabaseDef.createSession(JdbcBackend.scala:47); 	at slick.jdbc.JdbcBackend$DatabaseDef.createSession(JdbcBackend.scala:38); 	at slick.basic.BasicBackend$DatabaseDef.acquireSession(BasicBackend.scala:218); 	at slick.basic.BasicBackend$DatabaseDef.acquireSession$(BasicBackend.scala:217); 	at slick.jdbc.JdbcBackend$DatabaseDef.acquireSession(JdbcBackend.scala:38); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:239); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure. The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.; 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); 	at java.lang.reflect.Constructor.newInstance(Constructor.java:422); 	at com.mysql.jdbc.Util.handleNewInstance(Util.java:425); 	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:989); 	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:341); 	at com.mysql.jdbc.ConnectionImpl.coreConnect(ConnectionImpl.java:2192); 	at com.mysql.jdbc.ConnectionImpl.connectOneTryOnly(ConnectionImpl.java:2225); 	at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2024); 	at com.mysql.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:779); 	at com.mysql.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3387#issuecomment-372264453
https://github.com/broadinstitute/cromwell/issues/3387#issuecomment-372264453:676,Deployability,configurat,configuration,676,"Configuring as you suggested (following the instructions on the provided URL) does not even start the process. Apart of some typos in the instructions (e.g., `MYPASSWORD` instead of `MYSQL_PASSWORD`), it looks that there is a conectivity problem with the docker container running mysql. Steps to reproduce:. ```bash; # start mysql-server container; docker run -p 3306:3306 --name cromwell_db -e MYSQL_ROOT_PASSWORD=`cat my_sql.root.pwd` -e MYSQL_DATABASE=cromwell -e MYSQL_USER=cromwell -e MYSQL_PASSWORD=cromwell -d mysql/mysql-server:5.7; ```. The docker server is working and I can access the database using `docker exec -it cromwell_db mysql -u cromwell -p`. Adding to my configuration file:. ```; database {; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://localhost/cromwell?useSSL=false""; user = ""cromwell""; password = ""cromwell""; connectionTimeout = 5000; }; }; ```. And running locally:. ```bash; JAVA_OPTS=""-Dconfig.file=local.conf"" cromwell run --inputs inputs.json --metadata-output metadata-output.json workflow.wdl; ```. Produces the following log, which is the same even increasing the timeout:. ```; [2018-03-12 11:25:38,45] [info] Running with database db.url = jdbc:mysql://localhost/cromwell?useSSL=false; Exception in thread ""main"" java.lang.ExceptionInInitializerError; 	at cromwell.server.CromwellSystem.$init$(CromwellSystem.scala:24); 	at cromwell.CromwellEntryPoint$$anon$2.<init>(CromwellEntryPoint.scala:63); 	at cromwell.CromwellEntryPoint$.$anonfun$buildCromwellSystem$1(CromwellEntryPoint.scala:63); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.CromwellEntryPoint$.buildCromwellSystem(CromwellEntryPoint.scala:63); 	at cromwell.CromwellEntryPoint$.runSingle(CromwellEntryPoint.scala:47); 	at cromwell.CommandLineParser$.runCromwell(CommandLineParser.scala:95); 	at cromwell.CommandLineParser$.delayedEndpoint$cromwell$CommandLineParser$1(CommandLineParser.scala:105); 	at cromwell.CommandLineParser$delayedInit$",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3387#issuecomment-372264453
https://github.com/broadinstitute/cromwell/issues/3387#issuecomment-372264453:2257,Energy Efficiency,adapt,adapted,2257,"mwell?useSSL=false; Exception in thread ""main"" java.lang.ExceptionInInitializerError; 	at cromwell.server.CromwellSystem.$init$(CromwellSystem.scala:24); 	at cromwell.CromwellEntryPoint$$anon$2.<init>(CromwellEntryPoint.scala:63); 	at cromwell.CromwellEntryPoint$.$anonfun$buildCromwellSystem$1(CromwellEntryPoint.scala:63); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.CromwellEntryPoint$.buildCromwellSystem(CromwellEntryPoint.scala:63); 	at cromwell.CromwellEntryPoint$.runSingle(CromwellEntryPoint.scala:47); 	at cromwell.CommandLineParser$.runCromwell(CommandLineParser.scala:95); 	at cromwell.CommandLineParser$.delayedEndpoint$cromwell$CommandLineParser$1(CommandLineParser.scala:105); 	at cromwell.CommandLineParser$delayedInit$body.apply(CommandLineParser.scala:8); 	at scala.Function0.apply$mcV$sp(Function0.scala:34); 	at scala.Function0.apply$mcV$sp$(Function0.scala:34); 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12); 	at scala.App.$anonfun$main$1$adapted(App.scala:76); 	at scala.collection.immutable.List.foreach(List.scala:389); 	at scala.App.main(App.scala:76); 	at scala.App.main$(App.scala:74); 	at cromwell.CommandLineParser$.main(CommandLineParser.scala:8); 	at cromwell.CommandLineParser.main(CommandLineParser.scala); Caused by: java.sql.SQLTransientConnectionException: db - Connection is not available, request timed out after 5004ms.; 	at com.zaxxer.hikari.pool.HikariPool.createTimeoutException(HikariPool.java:548); 	at com.zaxxer.hikari.pool.HikariPool.getConnection(HikariPool.java:186); 	at com.zaxxer.hikari.pool.HikariPool.getConnection(HikariPool.java:145); 	at com.zaxxer.hikari.HikariDataSource.getConnection(HikariDataSource.java:83); 	at slick.jdbc.hikaricp.HikariCPJdbcDataSource.createConnection(HikariCPJdbcDataSource.scala:18); 	at slick.jdbc.JdbcBackend$BaseSession.<init>(JdbcBackend.scala:439); 	at slick.jdbc.JdbcBackend$DatabaseDef.createSession(JdbcBackend.scala:47); 	at slick.jdbc.JdbcBackend$DatabaseDef.crea",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3387#issuecomment-372264453
https://github.com/broadinstitute/cromwell/issues/3387#issuecomment-372264453:0,Modifiability,Config,Configuring,0,"Configuring as you suggested (following the instructions on the provided URL) does not even start the process. Apart of some typos in the instructions (e.g., `MYPASSWORD` instead of `MYSQL_PASSWORD`), it looks that there is a conectivity problem with the docker container running mysql. Steps to reproduce:. ```bash; # start mysql-server container; docker run -p 3306:3306 --name cromwell_db -e MYSQL_ROOT_PASSWORD=`cat my_sql.root.pwd` -e MYSQL_DATABASE=cromwell -e MYSQL_USER=cromwell -e MYSQL_PASSWORD=cromwell -d mysql/mysql-server:5.7; ```. The docker server is working and I can access the database using `docker exec -it cromwell_db mysql -u cromwell -p`. Adding to my configuration file:. ```; database {; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://localhost/cromwell?useSSL=false""; user = ""cromwell""; password = ""cromwell""; connectionTimeout = 5000; }; }; ```. And running locally:. ```bash; JAVA_OPTS=""-Dconfig.file=local.conf"" cromwell run --inputs inputs.json --metadata-output metadata-output.json workflow.wdl; ```. Produces the following log, which is the same even increasing the timeout:. ```; [2018-03-12 11:25:38,45] [info] Running with database db.url = jdbc:mysql://localhost/cromwell?useSSL=false; Exception in thread ""main"" java.lang.ExceptionInInitializerError; 	at cromwell.server.CromwellSystem.$init$(CromwellSystem.scala:24); 	at cromwell.CromwellEntryPoint$$anon$2.<init>(CromwellEntryPoint.scala:63); 	at cromwell.CromwellEntryPoint$.$anonfun$buildCromwellSystem$1(CromwellEntryPoint.scala:63); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.CromwellEntryPoint$.buildCromwellSystem(CromwellEntryPoint.scala:63); 	at cromwell.CromwellEntryPoint$.runSingle(CromwellEntryPoint.scala:47); 	at cromwell.CommandLineParser$.runCromwell(CommandLineParser.scala:95); 	at cromwell.CommandLineParser$.delayedEndpoint$cromwell$CommandLineParser$1(CommandLineParser.scala:105); 	at cromwell.CommandLineParser$delayedInit$",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3387#issuecomment-372264453
https://github.com/broadinstitute/cromwell/issues/3387#issuecomment-372264453:676,Modifiability,config,configuration,676,"Configuring as you suggested (following the instructions on the provided URL) does not even start the process. Apart of some typos in the instructions (e.g., `MYPASSWORD` instead of `MYSQL_PASSWORD`), it looks that there is a conectivity problem with the docker container running mysql. Steps to reproduce:. ```bash; # start mysql-server container; docker run -p 3306:3306 --name cromwell_db -e MYSQL_ROOT_PASSWORD=`cat my_sql.root.pwd` -e MYSQL_DATABASE=cromwell -e MYSQL_USER=cromwell -e MYSQL_PASSWORD=cromwell -d mysql/mysql-server:5.7; ```. The docker server is working and I can access the database using `docker exec -it cromwell_db mysql -u cromwell -p`. Adding to my configuration file:. ```; database {; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://localhost/cromwell?useSSL=false""; user = ""cromwell""; password = ""cromwell""; connectionTimeout = 5000; }; }; ```. And running locally:. ```bash; JAVA_OPTS=""-Dconfig.file=local.conf"" cromwell run --inputs inputs.json --metadata-output metadata-output.json workflow.wdl; ```. Produces the following log, which is the same even increasing the timeout:. ```; [2018-03-12 11:25:38,45] [info] Running with database db.url = jdbc:mysql://localhost/cromwell?useSSL=false; Exception in thread ""main"" java.lang.ExceptionInInitializerError; 	at cromwell.server.CromwellSystem.$init$(CromwellSystem.scala:24); 	at cromwell.CromwellEntryPoint$$anon$2.<init>(CromwellEntryPoint.scala:63); 	at cromwell.CromwellEntryPoint$.$anonfun$buildCromwellSystem$1(CromwellEntryPoint.scala:63); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.CromwellEntryPoint$.buildCromwellSystem(CromwellEntryPoint.scala:63); 	at cromwell.CromwellEntryPoint$.runSingle(CromwellEntryPoint.scala:47); 	at cromwell.CommandLineParser$.runCromwell(CommandLineParser.scala:95); 	at cromwell.CommandLineParser$.delayedEndpoint$cromwell$CommandLineParser$1(CommandLineParser.scala:105); 	at cromwell.CommandLineParser$delayedInit$",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3387#issuecomment-372264453
https://github.com/broadinstitute/cromwell/issues/3387#issuecomment-372264453:2257,Modifiability,adapt,adapted,2257,"mwell?useSSL=false; Exception in thread ""main"" java.lang.ExceptionInInitializerError; 	at cromwell.server.CromwellSystem.$init$(CromwellSystem.scala:24); 	at cromwell.CromwellEntryPoint$$anon$2.<init>(CromwellEntryPoint.scala:63); 	at cromwell.CromwellEntryPoint$.$anonfun$buildCromwellSystem$1(CromwellEntryPoint.scala:63); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.CromwellEntryPoint$.buildCromwellSystem(CromwellEntryPoint.scala:63); 	at cromwell.CromwellEntryPoint$.runSingle(CromwellEntryPoint.scala:47); 	at cromwell.CommandLineParser$.runCromwell(CommandLineParser.scala:95); 	at cromwell.CommandLineParser$.delayedEndpoint$cromwell$CommandLineParser$1(CommandLineParser.scala:105); 	at cromwell.CommandLineParser$delayedInit$body.apply(CommandLineParser.scala:8); 	at scala.Function0.apply$mcV$sp(Function0.scala:34); 	at scala.Function0.apply$mcV$sp$(Function0.scala:34); 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12); 	at scala.App.$anonfun$main$1$adapted(App.scala:76); 	at scala.collection.immutable.List.foreach(List.scala:389); 	at scala.App.main(App.scala:76); 	at scala.App.main$(App.scala:74); 	at cromwell.CommandLineParser$.main(CommandLineParser.scala:8); 	at cromwell.CommandLineParser.main(CommandLineParser.scala); Caused by: java.sql.SQLTransientConnectionException: db - Connection is not available, request timed out after 5004ms.; 	at com.zaxxer.hikari.pool.HikariPool.createTimeoutException(HikariPool.java:548); 	at com.zaxxer.hikari.pool.HikariPool.getConnection(HikariPool.java:186); 	at com.zaxxer.hikari.pool.HikariPool.getConnection(HikariPool.java:145); 	at com.zaxxer.hikari.HikariDataSource.getConnection(HikariDataSource.java:83); 	at slick.jdbc.hikaricp.HikariCPJdbcDataSource.createConnection(HikariCPJdbcDataSource.scala:18); 	at slick.jdbc.JdbcBackend$BaseSession.<init>(JdbcBackend.scala:439); 	at slick.jdbc.JdbcBackend$DatabaseDef.createSession(JdbcBackend.scala:47); 	at slick.jdbc.JdbcBackend$DatabaseDef.crea",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3387#issuecomment-372264453
https://github.com/broadinstitute/cromwell/issues/3387#issuecomment-372264453:6847,Modifiability,config,configure,6847,BC4Connection.java:47); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); 	at java.lang.reflect.Constructor.newInstance(Constructor.java:422); 	at com.mysql.jdbc.Util.handleNewInstance(Util.java:425); 	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:389); 	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:330); 	at com.zaxxer.hikari.util.DriverDataSource.getConnection(DriverDataSource.java:95); 	at com.zaxxer.hikari.util.DriverDataSource.getConnection(DriverDataSource.java:101); 	at com.zaxxer.hikari.pool.PoolBase.newConnection(PoolBase.java:341); 	at com.zaxxer.hikari.pool.PoolBase.newPoolEntry(PoolBase.java:193); 	at com.zaxxer.hikari.pool.HikariPool.createPoolEntry(HikariPool.java:430); 	at com.zaxxer.hikari.pool.HikariPool.access$500(HikariPool.java:64); 	at com.zaxxer.hikari.pool.HikariPool$PoolEntryCreator.call(HikariPool.java:570); 	at com.zaxxer.hikari.pool.HikariPool$PoolEntryCreator.call(HikariPool.java:563); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	... 3 more; Caused by: java.net.ConnectException: Connection refused; 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:211); 	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:300); 	... 24 more; ```; How can I properly configure the database to work properly in the local command? Thank you!,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3387#issuecomment-372264453
https://github.com/broadinstitute/cromwell/issues/3387#issuecomment-372264453:3620,Performance,concurren,concurrent,3620,equest timed out after 5004ms.; 	at com.zaxxer.hikari.pool.HikariPool.createTimeoutException(HikariPool.java:548); 	at com.zaxxer.hikari.pool.HikariPool.getConnection(HikariPool.java:186); 	at com.zaxxer.hikari.pool.HikariPool.getConnection(HikariPool.java:145); 	at com.zaxxer.hikari.HikariDataSource.getConnection(HikariDataSource.java:83); 	at slick.jdbc.hikaricp.HikariCPJdbcDataSource.createConnection(HikariCPJdbcDataSource.scala:18); 	at slick.jdbc.JdbcBackend$BaseSession.<init>(JdbcBackend.scala:439); 	at slick.jdbc.JdbcBackend$DatabaseDef.createSession(JdbcBackend.scala:47); 	at slick.jdbc.JdbcBackend$DatabaseDef.createSession(JdbcBackend.scala:38); 	at slick.basic.BasicBackend$DatabaseDef.acquireSession(BasicBackend.scala:218); 	at slick.basic.BasicBackend$DatabaseDef.acquireSession$(BasicBackend.scala:217); 	at slick.jdbc.JdbcBackend$DatabaseDef.acquireSession(JdbcBackend.scala:38); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:239); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure. The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.; 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); 	at java.lang.reflect.Constructor.newInstance(Constructor.java:422); 	at com.mysql.jdbc.Util.handleNewInstance(Util.java:425); 	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:989); 	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:341); 	at com.mysql.jdbc.ConnectionImpl.coreConne,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3387#issuecomment-372264453
https://github.com/broadinstitute/cromwell/issues/3387#issuecomment-372264453:3705,Performance,concurren,concurrent,3705,ception(HikariPool.java:548); 	at com.zaxxer.hikari.pool.HikariPool.getConnection(HikariPool.java:186); 	at com.zaxxer.hikari.pool.HikariPool.getConnection(HikariPool.java:145); 	at com.zaxxer.hikari.HikariDataSource.getConnection(HikariDataSource.java:83); 	at slick.jdbc.hikaricp.HikariCPJdbcDataSource.createConnection(HikariCPJdbcDataSource.scala:18); 	at slick.jdbc.JdbcBackend$BaseSession.<init>(JdbcBackend.scala:439); 	at slick.jdbc.JdbcBackend$DatabaseDef.createSession(JdbcBackend.scala:47); 	at slick.jdbc.JdbcBackend$DatabaseDef.createSession(JdbcBackend.scala:38); 	at slick.basic.BasicBackend$DatabaseDef.acquireSession(BasicBackend.scala:218); 	at slick.basic.BasicBackend$DatabaseDef.acquireSession$(BasicBackend.scala:217); 	at slick.jdbc.JdbcBackend$DatabaseDef.acquireSession(JdbcBackend.scala:38); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:239); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure. The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.; 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); 	at java.lang.reflect.Constructor.newInstance(Constructor.java:422); 	at com.mysql.jdbc.Util.handleNewInstance(Util.java:425); 	at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:989); 	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:341); 	at com.mysql.jdbc.ConnectionImpl.coreConnect(ConnectionImpl.java:2192); 	at com.mysql.jdbc.ConnectionImpl.connectOneTryOnly(Con,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3387#issuecomment-372264453
https://github.com/broadinstitute/cromwell/issues/3387#issuecomment-372264453:6135,Performance,concurren,concurrent,6135,BC4Connection.java:47); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); 	at java.lang.reflect.Constructor.newInstance(Constructor.java:422); 	at com.mysql.jdbc.Util.handleNewInstance(Util.java:425); 	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:389); 	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:330); 	at com.zaxxer.hikari.util.DriverDataSource.getConnection(DriverDataSource.java:95); 	at com.zaxxer.hikari.util.DriverDataSource.getConnection(DriverDataSource.java:101); 	at com.zaxxer.hikari.pool.PoolBase.newConnection(PoolBase.java:341); 	at com.zaxxer.hikari.pool.PoolBase.newPoolEntry(PoolBase.java:193); 	at com.zaxxer.hikari.pool.HikariPool.createPoolEntry(HikariPool.java:430); 	at com.zaxxer.hikari.pool.HikariPool.access$500(HikariPool.java:64); 	at com.zaxxer.hikari.pool.HikariPool$PoolEntryCreator.call(HikariPool.java:570); 	at com.zaxxer.hikari.pool.HikariPool$PoolEntryCreator.call(HikariPool.java:563); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	... 3 more; Caused by: java.net.ConnectException: Connection refused; 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:211); 	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:300); 	... 24 more; ```; How can I properly configure the database to work properly in the local command? Thank you!,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3387#issuecomment-372264453
https://github.com/broadinstitute/cromwell/issues/3387#issuecomment-372264453:1151,Safety,timeout,timeout,1151,"me typos in the instructions (e.g., `MYPASSWORD` instead of `MYSQL_PASSWORD`), it looks that there is a conectivity problem with the docker container running mysql. Steps to reproduce:. ```bash; # start mysql-server container; docker run -p 3306:3306 --name cromwell_db -e MYSQL_ROOT_PASSWORD=`cat my_sql.root.pwd` -e MYSQL_DATABASE=cromwell -e MYSQL_USER=cromwell -e MYSQL_PASSWORD=cromwell -d mysql/mysql-server:5.7; ```. The docker server is working and I can access the database using `docker exec -it cromwell_db mysql -u cromwell -p`. Adding to my configuration file:. ```; database {; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://localhost/cromwell?useSSL=false""; user = ""cromwell""; password = ""cromwell""; connectionTimeout = 5000; }; }; ```. And running locally:. ```bash; JAVA_OPTS=""-Dconfig.file=local.conf"" cromwell run --inputs inputs.json --metadata-output metadata-output.json workflow.wdl; ```. Produces the following log, which is the same even increasing the timeout:. ```; [2018-03-12 11:25:38,45] [info] Running with database db.url = jdbc:mysql://localhost/cromwell?useSSL=false; Exception in thread ""main"" java.lang.ExceptionInInitializerError; 	at cromwell.server.CromwellSystem.$init$(CromwellSystem.scala:24); 	at cromwell.CromwellEntryPoint$$anon$2.<init>(CromwellEntryPoint.scala:63); 	at cromwell.CromwellEntryPoint$.$anonfun$buildCromwellSystem$1(CromwellEntryPoint.scala:63); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.CromwellEntryPoint$.buildCromwellSystem(CromwellEntryPoint.scala:63); 	at cromwell.CromwellEntryPoint$.runSingle(CromwellEntryPoint.scala:47); 	at cromwell.CommandLineParser$.runCromwell(CommandLineParser.scala:95); 	at cromwell.CommandLineParser$.delayedEndpoint$cromwell$CommandLineParser$1(CommandLineParser.scala:105); 	at cromwell.CommandLineParser$delayedInit$body.apply(CommandLineParser.scala:8); 	at scala.Function0.apply$mcV$sp(Function0.scala:34); 	at scala.Function0.apply$mc",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3387#issuecomment-372264453
https://github.com/broadinstitute/cromwell/issues/3387#issuecomment-372264453:585,Security,access,access,585,"Configuring as you suggested (following the instructions on the provided URL) does not even start the process. Apart of some typos in the instructions (e.g., `MYPASSWORD` instead of `MYSQL_PASSWORD`), it looks that there is a conectivity problem with the docker container running mysql. Steps to reproduce:. ```bash; # start mysql-server container; docker run -p 3306:3306 --name cromwell_db -e MYSQL_ROOT_PASSWORD=`cat my_sql.root.pwd` -e MYSQL_DATABASE=cromwell -e MYSQL_USER=cromwell -e MYSQL_PASSWORD=cromwell -d mysql/mysql-server:5.7; ```. The docker server is working and I can access the database using `docker exec -it cromwell_db mysql -u cromwell -p`. Adding to my configuration file:. ```; database {; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://localhost/cromwell?useSSL=false""; user = ""cromwell""; password = ""cromwell""; connectionTimeout = 5000; }; }; ```. And running locally:. ```bash; JAVA_OPTS=""-Dconfig.file=local.conf"" cromwell run --inputs inputs.json --metadata-output metadata-output.json workflow.wdl; ```. Produces the following log, which is the same even increasing the timeout:. ```; [2018-03-12 11:25:38,45] [info] Running with database db.url = jdbc:mysql://localhost/cromwell?useSSL=false; Exception in thread ""main"" java.lang.ExceptionInInitializerError; 	at cromwell.server.CromwellSystem.$init$(CromwellSystem.scala:24); 	at cromwell.CromwellEntryPoint$$anon$2.<init>(CromwellEntryPoint.scala:63); 	at cromwell.CromwellEntryPoint$.$anonfun$buildCromwellSystem$1(CromwellEntryPoint.scala:63); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.CromwellEntryPoint$.buildCromwellSystem(CromwellEntryPoint.scala:63); 	at cromwell.CromwellEntryPoint$.runSingle(CromwellEntryPoint.scala:47); 	at cromwell.CommandLineParser$.runCromwell(CommandLineParser.scala:95); 	at cromwell.CommandLineParser$.delayedEndpoint$cromwell$CommandLineParser$1(CommandLineParser.scala:105); 	at cromwell.CommandLineParser$delayedInit$",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3387#issuecomment-372264453
https://github.com/broadinstitute/cromwell/issues/3387#issuecomment-372264453:865,Security,password,password,865,"Configuring as you suggested (following the instructions on the provided URL) does not even start the process. Apart of some typos in the instructions (e.g., `MYPASSWORD` instead of `MYSQL_PASSWORD`), it looks that there is a conectivity problem with the docker container running mysql. Steps to reproduce:. ```bash; # start mysql-server container; docker run -p 3306:3306 --name cromwell_db -e MYSQL_ROOT_PASSWORD=`cat my_sql.root.pwd` -e MYSQL_DATABASE=cromwell -e MYSQL_USER=cromwell -e MYSQL_PASSWORD=cromwell -d mysql/mysql-server:5.7; ```. The docker server is working and I can access the database using `docker exec -it cromwell_db mysql -u cromwell -p`. Adding to my configuration file:. ```; database {; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://localhost/cromwell?useSSL=false""; user = ""cromwell""; password = ""cromwell""; connectionTimeout = 5000; }; }; ```. And running locally:. ```bash; JAVA_OPTS=""-Dconfig.file=local.conf"" cromwell run --inputs inputs.json --metadata-output metadata-output.json workflow.wdl; ```. Produces the following log, which is the same even increasing the timeout:. ```; [2018-03-12 11:25:38,45] [info] Running with database db.url = jdbc:mysql://localhost/cromwell?useSSL=false; Exception in thread ""main"" java.lang.ExceptionInInitializerError; 	at cromwell.server.CromwellSystem.$init$(CromwellSystem.scala:24); 	at cromwell.CromwellEntryPoint$$anon$2.<init>(CromwellEntryPoint.scala:63); 	at cromwell.CromwellEntryPoint$.$anonfun$buildCromwellSystem$1(CromwellEntryPoint.scala:63); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.CromwellEntryPoint$.buildCromwellSystem(CromwellEntryPoint.scala:63); 	at cromwell.CromwellEntryPoint$.runSingle(CromwellEntryPoint.scala:47); 	at cromwell.CommandLineParser$.runCromwell(CommandLineParser.scala:95); 	at cromwell.CommandLineParser$.delayedEndpoint$cromwell$CommandLineParser$1(CommandLineParser.scala:105); 	at cromwell.CommandLineParser$delayedInit$",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3387#issuecomment-372264453
https://github.com/broadinstitute/cromwell/issues/3387#issuecomment-372264453:5925,Security,access,access,5925,BC4Connection.java:47); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); 	at java.lang.reflect.Constructor.newInstance(Constructor.java:422); 	at com.mysql.jdbc.Util.handleNewInstance(Util.java:425); 	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:389); 	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:330); 	at com.zaxxer.hikari.util.DriverDataSource.getConnection(DriverDataSource.java:95); 	at com.zaxxer.hikari.util.DriverDataSource.getConnection(DriverDataSource.java:101); 	at com.zaxxer.hikari.pool.PoolBase.newConnection(PoolBase.java:341); 	at com.zaxxer.hikari.pool.PoolBase.newPoolEntry(PoolBase.java:193); 	at com.zaxxer.hikari.pool.HikariPool.createPoolEntry(HikariPool.java:430); 	at com.zaxxer.hikari.pool.HikariPool.access$500(HikariPool.java:64); 	at com.zaxxer.hikari.pool.HikariPool$PoolEntryCreator.call(HikariPool.java:570); 	at com.zaxxer.hikari.pool.HikariPool$PoolEntryCreator.call(HikariPool.java:563); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	... 3 more; Caused by: java.net.ConnectException: Connection refused; 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:211); 	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:300); 	... 24 more; ```; How can I properly configure the database to work properly in the local command? Thank you!,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3387#issuecomment-372264453
https://github.com/broadinstitute/cromwell/issues/3387#issuecomment-372264453:1108,Testability,log,log,1108,"me typos in the instructions (e.g., `MYPASSWORD` instead of `MYSQL_PASSWORD`), it looks that there is a conectivity problem with the docker container running mysql. Steps to reproduce:. ```bash; # start mysql-server container; docker run -p 3306:3306 --name cromwell_db -e MYSQL_ROOT_PASSWORD=`cat my_sql.root.pwd` -e MYSQL_DATABASE=cromwell -e MYSQL_USER=cromwell -e MYSQL_PASSWORD=cromwell -d mysql/mysql-server:5.7; ```. The docker server is working and I can access the database using `docker exec -it cromwell_db mysql -u cromwell -p`. Adding to my configuration file:. ```; database {; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://localhost/cromwell?useSSL=false""; user = ""cromwell""; password = ""cromwell""; connectionTimeout = 5000; }; }; ```. And running locally:. ```bash; JAVA_OPTS=""-Dconfig.file=local.conf"" cromwell run --inputs inputs.json --metadata-output metadata-output.json workflow.wdl; ```. Produces the following log, which is the same even increasing the timeout:. ```; [2018-03-12 11:25:38,45] [info] Running with database db.url = jdbc:mysql://localhost/cromwell?useSSL=false; Exception in thread ""main"" java.lang.ExceptionInInitializerError; 	at cromwell.server.CromwellSystem.$init$(CromwellSystem.scala:24); 	at cromwell.CromwellEntryPoint$$anon$2.<init>(CromwellEntryPoint.scala:63); 	at cromwell.CromwellEntryPoint$.$anonfun$buildCromwellSystem$1(CromwellEntryPoint.scala:63); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.CromwellEntryPoint$.buildCromwellSystem(CromwellEntryPoint.scala:63); 	at cromwell.CromwellEntryPoint$.runSingle(CromwellEntryPoint.scala:47); 	at cromwell.CommandLineParser$.runCromwell(CommandLineParser.scala:95); 	at cromwell.CommandLineParser$.delayedEndpoint$cromwell$CommandLineParser$1(CommandLineParser.scala:105); 	at cromwell.CommandLineParser$delayedInit$body.apply(CommandLineParser.scala:8); 	at scala.Function0.apply$mcV$sp(Function0.scala:34); 	at scala.Function0.apply$mc",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3387#issuecomment-372264453
https://github.com/broadinstitute/cromwell/issues/3387#issuecomment-373069972:53,Deployability,update,update,53,"Hmm, ok, sounds like the documentation might need an update - otherwise, can you double check that you can connect to the mysql instance from outside of its docker container (ie running `mysql -u cromwell -p` from where Cromwell will run instead of where `mysql` is running?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3387#issuecomment-373069972
https://github.com/broadinstitute/cromwell/issues/3387#issuecomment-373318603:8,Deployability,configurat,configuration,8,"I did a configuration using a local MySQL server without docker. I guess that the problem was that my docker machine does not connect the `localhost` address from the VM to the host machine. Thus, the `localhost` port was not providing the connection to the MySQL server. This might be a common problem in MacOS computers, which are running `boot2docker`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3387#issuecomment-373318603
https://github.com/broadinstitute/cromwell/issues/3387#issuecomment-373318603:8,Modifiability,config,configuration,8,"I did a configuration using a local MySQL server without docker. I guess that the problem was that my docker machine does not connect the `localhost` address from the VM to the host machine. Thus, the `localhost` port was not providing the connection to the MySQL server. This might be a common problem in MacOS computers, which are running `boot2docker`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3387#issuecomment-373318603
https://github.com/broadinstitute/cromwell/pull/3388#issuecomment-371860973:297,Availability,down,down,297,"I need a red thumb because of some changes in WOM - specifically I needed some way to indicate that a not-really-a subworkflow call should not get its subworkflow name prepended. I'm also curious whether the ""make up a random UUID for the not-really-a-subworkflow name"" is going to cause problems down the road (eg does restart rely on stable subworkflow names?)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3388#issuecomment-371860973
https://github.com/broadinstitute/cromwell/pull/3388#issuecomment-372432202:128,Deployability,update,updated,128,"@Horneth right, and we don't need to do that any more because we rebuild the entire execution store every time we restart. I've updated this to now have stable subworkflow names for those ""nested scatter"" subworkflows. Do we have an existing ""check subworkflows restart correctly"" test I can duplicate for draft 3?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3388#issuecomment-372432202
https://github.com/broadinstitute/cromwell/pull/3388#issuecomment-372432202:281,Testability,test,test,281,"@Horneth right, and we don't need to do that any more because we rebuild the entire execution store every time we restart. I've updated this to now have stable subworkflow names for those ""nested scatter"" subworkflows. Do we have an existing ""check subworkflows restart correctly"" test I can duplicate for draft 3?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3388#issuecomment-372432202
https://github.com/broadinstitute/cromwell/pull/3388#issuecomment-372489504:83,Deployability,release,released,83,"@mcovarr I think the intention is to start moving people ASAP to WDL 1.0 once it's released next month. We'll need to support workflows which predate that, but it doesn't mean that we need to give those users new functionality and thus reasons to not upgrade",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3388#issuecomment-372489504
https://github.com/broadinstitute/cromwell/pull/3388#issuecomment-372489504:251,Deployability,upgrade,upgrade,251,"@mcovarr I think the intention is to start moving people ASAP to WDL 1.0 once it's released next month. We'll need to support workflows which predate that, but it doesn't mean that we need to give those users new functionality and thus reasons to not upgrade",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3388#issuecomment-372489504
https://github.com/broadinstitute/cromwell/pull/3389#issuecomment-371888809:11,Availability,failure,failure,11,The travis failure looks unrelated but sort of scary... perhaps one for the spreadsheet...,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3389#issuecomment-371888809
https://github.com/broadinstitute/cromwell/pull/3390#issuecomment-372422393:26,Availability,failure,failure,26,Merging despite known sbt failure.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3390#issuecomment-372422393
https://github.com/broadinstitute/cromwell/pull/3402#issuecomment-372489604:35,Testability,test,tests,35,"Nothing like ""sleep longer"" to fix tests :P. :+1:. [![Approved with PullApprove](https://img.shields.io/badge/two_reviewers-approved-brightgreen.svg)](https://pullapprove.com/broadinstitute/cromwell/pull-request/3402/?utm_source=github-pr&utm_medium=comment-badge&utm_campaign=broadinstitute/cromwell)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3402#issuecomment-372489604
https://github.com/broadinstitute/cromwell/issues/3408#issuecomment-463889255:545,Modifiability,variab,variable,545,"@cjllanwarne Scattering over a map does not work with Cromwell-37. The workflow below doesn't pass wom validation. ```wdl; version 1.0. task add {; input {; Int a; Int b; }; command {}; output {; Int result = a + b; }; }. workflow dict2 {; Map[Int, Float] mIF = {1: 1.2, 10: 113.0}. scatter (p in mIF) {; call add {; input: a=p.left, b=5; }; }. output {; Array[String] result = add.result; }; }; ```. ```bash; $ java -jar womtool-37.jar validate dict2.wdl. Failed to process workflow definition 'dict2' (reason 1 of 1): Invalid type for scatter variable 'p': Map[Int, Float]; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3408#issuecomment-463889255
https://github.com/broadinstitute/cromwell/issues/3408#issuecomment-463889255:103,Security,validat,validation,103,"@cjllanwarne Scattering over a map does not work with Cromwell-37. The workflow below doesn't pass wom validation. ```wdl; version 1.0. task add {; input {; Int a; Int b; }; command {}; output {; Int result = a + b; }; }. workflow dict2 {; Map[Int, Float] mIF = {1: 1.2, 10: 113.0}. scatter (p in mIF) {; call add {; input: a=p.left, b=5; }; }. output {; Array[String] result = add.result; }; }; ```. ```bash; $ java -jar womtool-37.jar validate dict2.wdl. Failed to process workflow definition 'dict2' (reason 1 of 1): Invalid type for scatter variable 'p': Map[Int, Float]; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3408#issuecomment-463889255
https://github.com/broadinstitute/cromwell/issues/3408#issuecomment-463889255:437,Security,validat,validate,437,"@cjllanwarne Scattering over a map does not work with Cromwell-37. The workflow below doesn't pass wom validation. ```wdl; version 1.0. task add {; input {; Int a; Int b; }; command {}; output {; Int result = a + b; }; }. workflow dict2 {; Map[Int, Float] mIF = {1: 1.2, 10: 113.0}. scatter (p in mIF) {; call add {; input: a=p.left, b=5; }; }. output {; Array[String] result = add.result; }; }; ```. ```bash; $ java -jar womtool-37.jar validate dict2.wdl. Failed to process workflow definition 'dict2' (reason 1 of 1): Invalid type for scatter variable 'p': Map[Int, Float]; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3408#issuecomment-463889255
https://github.com/broadinstitute/cromwell/pull/3411#issuecomment-373500372:122,Availability,robust,robust,122,"@Horneth Per our discussion this morning, it was already a blocking call, this just makes retrieving the return code more robust in case of disconnect.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3411#issuecomment-373500372
https://github.com/broadinstitute/cromwell/pull/3413#issuecomment-373570762:504,Deployability,rolling,rolling,504,Cool! I've been thinking about how to approach this too. I looked at [shapeless' Typeable](https://github.com/milessabin/shapeless/blob/master/core/src/main/scala/shapeless/typeable.scala#L28) (and [docs](https://github.com/milessabin/shapeless/wiki/Feature-overview:-shapeless-2.0.0#type-safe-cast)) which co-exists with [ValueTypeable](https://github.com/milessabin/shapeless/blob/master/core/src/main/scala/shapeless/typeable.scala#L53) (declare from -> to types). Dunno if it has any advantages over rolling your own but it's worth a look to see if there are any.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3413#issuecomment-373570762
https://github.com/broadinstitute/cromwell/pull/3413#issuecomment-373570762:289,Safety,safe,safe-cast,289,Cool! I've been thinking about how to approach this too. I looked at [shapeless' Typeable](https://github.com/milessabin/shapeless/blob/master/core/src/main/scala/shapeless/typeable.scala#L28) (and [docs](https://github.com/milessabin/shapeless/wiki/Feature-overview:-shapeless-2.0.0#type-safe-cast)) which co-exists with [ValueTypeable](https://github.com/milessabin/shapeless/blob/master/core/src/main/scala/shapeless/typeable.scala#L53) (declare from -> to types). Dunno if it has any advantages over rolling your own but it's worth a look to see if there are any.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3413#issuecomment-373570762
https://github.com/broadinstitute/cromwell/pull/3413#issuecomment-373823911:174,Availability,down,down,174,":+1: It seems there's a potential to reduce some of the boilerplate around instances dealing with `ExpressionElement`. It seems like those instances exist to refine the type down to the ""leaf"" level where the more specific type can do its thing. I would try to eliminate one of these and see if you can parameterize the callers with a `[T]` or `[T <: ExpressionElement]` to save you from the trouble of specializing/refining/narrowing/casting (not sure the right word) the type yourself. [![Approved with PullApprove](https://img.shields.io/badge/one_reviewer-approved-brightgreen.svg)](https://pullapprove.com/broadinstitute/cromwell/pull-request/3413/?utm_source=github-pr&utm_medium=comment-badge&utm_campaign=broadinstitute/cromwell) [![Approved with PullApprove](https://img.shields.io/badge/two_reviewers-approved-brightgreen.svg)](https://pullapprove.com/broadinstitute/cromwell/pull-request/3413/?utm_source=github-pr&utm_medium=comment-badge&utm_campaign=broadinstitute/cromwell)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3413#issuecomment-373823911
https://github.com/broadinstitute/cromwell/pull/3413#issuecomment-373823911:37,Energy Efficiency,reduce,reduce,37,":+1: It seems there's a potential to reduce some of the boilerplate around instances dealing with `ExpressionElement`. It seems like those instances exist to refine the type down to the ""leaf"" level where the more specific type can do its thing. I would try to eliminate one of these and see if you can parameterize the callers with a `[T]` or `[T <: ExpressionElement]` to save you from the trouble of specializing/refining/narrowing/casting (not sure the right word) the type yourself. [![Approved with PullApprove](https://img.shields.io/badge/one_reviewer-approved-brightgreen.svg)](https://pullapprove.com/broadinstitute/cromwell/pull-request/3413/?utm_source=github-pr&utm_medium=comment-badge&utm_campaign=broadinstitute/cromwell) [![Approved with PullApprove](https://img.shields.io/badge/two_reviewers-approved-brightgreen.svg)](https://pullapprove.com/broadinstitute/cromwell/pull-request/3413/?utm_source=github-pr&utm_medium=comment-badge&utm_campaign=broadinstitute/cromwell)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3413#issuecomment-373823911
https://github.com/broadinstitute/cromwell/pull/3413#issuecomment-373823911:303,Modifiability,parameteriz,parameterize,303,":+1: It seems there's a potential to reduce some of the boilerplate around instances dealing with `ExpressionElement`. It seems like those instances exist to refine the type down to the ""leaf"" level where the more specific type can do its thing. I would try to eliminate one of these and see if you can parameterize the callers with a `[T]` or `[T <: ExpressionElement]` to save you from the trouble of specializing/refining/narrowing/casting (not sure the right word) the type yourself. [![Approved with PullApprove](https://img.shields.io/badge/one_reviewer-approved-brightgreen.svg)](https://pullapprove.com/broadinstitute/cromwell/pull-request/3413/?utm_source=github-pr&utm_medium=comment-badge&utm_campaign=broadinstitute/cromwell) [![Approved with PullApprove](https://img.shields.io/badge/two_reviewers-approved-brightgreen.svg)](https://pullapprove.com/broadinstitute/cromwell/pull-request/3413/?utm_source=github-pr&utm_medium=comment-badge&utm_campaign=broadinstitute/cromwell)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3413#issuecomment-373823911
https://github.com/broadinstitute/cromwell/pull/3414#issuecomment-373351153:0,Deployability,Update,Update,0,Update: now pointed to Slick 3.2.2 that was released last week. Not sure how I missed this yesterday especially when I deliberately went looking for it... üò¶,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3414#issuecomment-373351153
https://github.com/broadinstitute/cromwell/pull/3414#issuecomment-373351153:44,Deployability,release,released,44,Update: now pointed to Slick 3.2.2 that was released last week. Not sure how I missed this yesterday especially when I deliberately went looking for it... üò¶,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3414#issuecomment-373351153
https://github.com/broadinstitute/cromwell/issues/3415#issuecomment-373394497:251,Availability,failure,failures,251,"I was using before the in-memory database, and I use the `--metadata-output` to dump a JSON with the metadata of the workflow. What I am experimenting at the moment is to use the call-caching and the database to run the workflow to account for random failures of docker containers (see https://github.com/broadinstitute/cromwell/issues/3370) . It is unclear for me how the database is setup and which information stores, so I am not sure what can be clean and what is important/usuful for later use. That's why I think that it will be nice to have a documentation page showing how the database can be managed to grab information and clean the unnecessary data from time to time. Thank you!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3415#issuecomment-373394497
https://github.com/broadinstitute/cromwell/issues/3417#issuecomment-373403073:70,Availability,fault,fault,70,"Sorry, I use to search in previous issues but I didn't this time - my fault. Issue #3161 is the one that describes what I would like to have in cromwell. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3417#issuecomment-373403073
https://github.com/broadinstitute/cromwell/issues/3420#issuecomment-373493373:340,Performance,cache,cache,340,"FWIW this was inspired by the conversation here: (https://gatkforums.broadinstitute.org/wdl/discussion/9031/intermediate-outputs#latest). In particular I wonder whether this might maybe help with the unfortunate interaction of ""intermediate files"" and ""call caching"". In particular it gives users something a bit bigger than a task to call cache against, so there are more options, eg; * delete all intermediates (and never call cache); * delete job outputs (but maybe I can still cache subworkflows that haven't changed); * delete no intermediates (and call cache at the finest grain)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3420#issuecomment-373493373
https://github.com/broadinstitute/cromwell/issues/3420#issuecomment-373493373:429,Performance,cache,cache,429,"FWIW this was inspired by the conversation here: (https://gatkforums.broadinstitute.org/wdl/discussion/9031/intermediate-outputs#latest). In particular I wonder whether this might maybe help with the unfortunate interaction of ""intermediate files"" and ""call caching"". In particular it gives users something a bit bigger than a task to call cache against, so there are more options, eg; * delete all intermediates (and never call cache); * delete job outputs (but maybe I can still cache subworkflows that haven't changed); * delete no intermediates (and call cache at the finest grain)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3420#issuecomment-373493373
https://github.com/broadinstitute/cromwell/issues/3420#issuecomment-373493373:481,Performance,cache,cache,481,"FWIW this was inspired by the conversation here: (https://gatkforums.broadinstitute.org/wdl/discussion/9031/intermediate-outputs#latest). In particular I wonder whether this might maybe help with the unfortunate interaction of ""intermediate files"" and ""call caching"". In particular it gives users something a bit bigger than a task to call cache against, so there are more options, eg; * delete all intermediates (and never call cache); * delete job outputs (but maybe I can still cache subworkflows that haven't changed); * delete no intermediates (and call cache at the finest grain)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3420#issuecomment-373493373
https://github.com/broadinstitute/cromwell/issues/3420#issuecomment-373493373:559,Performance,cache,cache,559,"FWIW this was inspired by the conversation here: (https://gatkforums.broadinstitute.org/wdl/discussion/9031/intermediate-outputs#latest). In particular I wonder whether this might maybe help with the unfortunate interaction of ""intermediate files"" and ""call caching"". In particular it gives users something a bit bigger than a task to call cache against, so there are more options, eg; * delete all intermediates (and never call cache); * delete job outputs (but maybe I can still cache subworkflows that haven't changed); * delete no intermediates (and call cache at the finest grain)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3420#issuecomment-373493373
https://github.com/broadinstitute/cromwell/issues/3421#issuecomment-373764453:35,Deployability,release,released,35,"@byoo fixed, will be in soon-to-be released 31.1 and next major version 32",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3421#issuecomment-373764453
https://github.com/broadinstitute/cromwell/pull/3423#issuecomment-373821451:11,Testability,test,tested,11,@mcovarr I tested the commands manually on my Cromwell fork and it worked so merging this,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3423#issuecomment-373821451
https://github.com/broadinstitute/cromwell/issues/3426#issuecomment-382881466:63,Deployability,integrat,integration,63,Initial implementation complete. Not yet closing this issue as integration tests are not yet operable and there are still several TODOs in the code. See commit f788704.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3426#issuecomment-382881466
https://github.com/broadinstitute/cromwell/issues/3426#issuecomment-382881466:63,Integrability,integrat,integration,63,Initial implementation complete. Not yet closing this issue as integration tests are not yet operable and there are still several TODOs in the code. See commit f788704.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3426#issuecomment-382881466
https://github.com/broadinstitute/cromwell/issues/3426#issuecomment-382881466:75,Testability,test,tests,75,Initial implementation complete. Not yet closing this issue as integration tests are not yet operable and there are still several TODOs in the code. See commit f788704.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3426#issuecomment-382881466
https://github.com/broadinstitute/cromwell/issues/3426#issuecomment-394931408:82,Testability,test,testing,82,"Closing this for now. Individual issues as we find them in Centaur and via manual testing can be reported individually. Last remaining major piece was S3 Filesystem support, delivered in aa99ec2.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3426#issuecomment-394931408
https://github.com/broadinstitute/cromwell/issues/3427#issuecomment-375820432:231,Modifiability,inherit,inheriting,231,"Initial support landed. Ref 1689e81 and ff89630. Some failing tests commented out. In order to pass these tests, S3Path (which should probably be broken out into another file) needs to implement the Path trait directly rather than inheriting from Path.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3427#issuecomment-375820432
https://github.com/broadinstitute/cromwell/issues/3427#issuecomment-375820432:62,Testability,test,tests,62,"Initial support landed. Ref 1689e81 and ff89630. Some failing tests commented out. In order to pass these tests, S3Path (which should probably be broken out into another file) needs to implement the Path trait directly rather than inheriting from Path.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3427#issuecomment-375820432
https://github.com/broadinstitute/cromwell/issues/3427#issuecomment-375820432:106,Testability,test,tests,106,"Initial support landed. Ref 1689e81 and ff89630. Some failing tests commented out. In order to pass these tests, S3Path (which should probably be broken out into another file) needs to implement the Path trait directly rather than inheriting from Path.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3427#issuecomment-375820432
https://github.com/broadinstitute/cromwell/issues/3427#issuecomment-394509732:160,Availability,error,error,160,"I am trying to use this. I switch to the ""aws_backend"" branch, checked it out, figured out how to build it, and now I have run into:. [2018-06-04 06:34:20,69] [error] java.lang.IllegalArgumentException: s3://atbiofx-cromwell/cromwell-execution exists on a filesystem not supported by this instance of Cromwell. Supported filesystems are: MacOSXFileSystem. Please refer to the documentation for more information on how to configure filesystems: http://cromwell.readthedocs.io/en/develop/backends/HPC/#filesystems; cromwell.core.path.PathParsingException: java.lang.IllegalArgumentException: s3://atbiofx-cromwell/cromwell-execution exists on a filesystem not supported by this instance of Cromwell. Supported filesystems are: MacOSXFileSystem. Please refer to the documentation for more information on how to configure filesystems: http://cromwell.readthedocs.io/en/develop/backends/HPC/#filesystems",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3427#issuecomment-394509732
https://github.com/broadinstitute/cromwell/issues/3427#issuecomment-394509732:421,Modifiability,config,configure,421,"I am trying to use this. I switch to the ""aws_backend"" branch, checked it out, figured out how to build it, and now I have run into:. [2018-06-04 06:34:20,69] [error] java.lang.IllegalArgumentException: s3://atbiofx-cromwell/cromwell-execution exists on a filesystem not supported by this instance of Cromwell. Supported filesystems are: MacOSXFileSystem. Please refer to the documentation for more information on how to configure filesystems: http://cromwell.readthedocs.io/en/develop/backends/HPC/#filesystems; cromwell.core.path.PathParsingException: java.lang.IllegalArgumentException: s3://atbiofx-cromwell/cromwell-execution exists on a filesystem not supported by this instance of Cromwell. Supported filesystems are: MacOSXFileSystem. Please refer to the documentation for more information on how to configure filesystems: http://cromwell.readthedocs.io/en/develop/backends/HPC/#filesystems",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3427#issuecomment-394509732
https://github.com/broadinstitute/cromwell/issues/3427#issuecomment-394509732:808,Modifiability,config,configure,808,"I am trying to use this. I switch to the ""aws_backend"" branch, checked it out, figured out how to build it, and now I have run into:. [2018-06-04 06:34:20,69] [error] java.lang.IllegalArgumentException: s3://atbiofx-cromwell/cromwell-execution exists on a filesystem not supported by this instance of Cromwell. Supported filesystems are: MacOSXFileSystem. Please refer to the documentation for more information on how to configure filesystems: http://cromwell.readthedocs.io/en/develop/backends/HPC/#filesystems; cromwell.core.path.PathParsingException: java.lang.IllegalArgumentException: s3://atbiofx-cromwell/cromwell-execution exists on a filesystem not supported by this instance of Cromwell. Supported filesystems are: MacOSXFileSystem. Please refer to the documentation for more information on how to configure filesystems: http://cromwell.readthedocs.io/en/develop/backends/HPC/#filesystems",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3427#issuecomment-394509732
https://github.com/broadinstitute/cromwell/issues/3427#issuecomment-394931237:49,Testability,test,test,49,"@tom-dyar Pull latest and try it now. My initial test is working and I'm running remaining Centaur tests on the code base. S3 FS support was added tonight in aa99ec2. Please open a new issue with the AWS Backend label for any bugs you see. This is still super-early, so I'm sure we'll run into some stuff. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3427#issuecomment-394931237
https://github.com/broadinstitute/cromwell/issues/3427#issuecomment-394931237:99,Testability,test,tests,99,"@tom-dyar Pull latest and try it now. My initial test is working and I'm running remaining Centaur tests on the code base. S3 FS support was added tonight in aa99ec2. Please open a new issue with the AWS Backend label for any bugs you see. This is still super-early, so I'm sure we'll run into some stuff. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3427#issuecomment-394931237
https://github.com/broadinstitute/cromwell/pull/3430#issuecomment-373823553:9,Integrability,depend,depends,9,"@Horneth depends when the `Any` coercions happen. If they only happen reading the inputs files then it's actually already separated out I think (and ""coercion"" and ""input parsing"" could easily be separate functions IMO)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3430#issuecomment-373823553
https://github.com/broadinstitute/cromwell/pull/3438#issuecomment-374715372:100,Modifiability,refactor,refactor,100,No conformance tests enabled? I'm in a similar predicament over on my Wash U branch where I want to refactor a bunch of stuff but there are no tests to keep me honest. üò¢,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3438#issuecomment-374715372
https://github.com/broadinstitute/cromwell/pull/3438#issuecomment-374715372:15,Testability,test,tests,15,No conformance tests enabled? I'm in a similar predicament over on my Wash U branch where I want to refactor a bunch of stuff but there are no tests to keep me honest. üò¢,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3438#issuecomment-374715372
https://github.com/broadinstitute/cromwell/pull/3438#issuecomment-374715372:143,Testability,test,tests,143,No conformance tests enabled? I'm in a similar predicament over on my Wash U branch where I want to refactor a bunch of stuff but there are no tests to keep me honest. üò¢,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3438#issuecomment-374715372
https://github.com/broadinstitute/cromwell/pull/3438#issuecomment-374726541:81,Testability,test,tests,81,Yeah those seem like things I would have expected to be failing some conformance tests but apparently not... :/,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3438#issuecomment-374726541
https://github.com/broadinstitute/cromwell/pull/3438#issuecomment-374914130:40,Testability,test,test,40,@mcovarr could we make a simple centaur test? Or even a PR into CWL‚Äôs suite?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3438#issuecomment-374914130
https://github.com/broadinstitute/cromwell/pull/3438#issuecomment-374914130:25,Usability,simpl,simple,25,@mcovarr could we make a simple centaur test? Or even a PR into CWL‚Äôs suite?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3438#issuecomment-374914130
https://github.com/broadinstitute/cromwell/pull/3438#issuecomment-374916603:53,Testability,test,tests,53,@cjllanwarne For my Wash U stuff I've now added some tests. I'm not sure what's involved for a test on this.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3438#issuecomment-374916603
https://github.com/broadinstitute/cromwell/pull/3438#issuecomment-374916603:95,Testability,test,test,95,@cjllanwarne For my Wash U stuff I've now added some tests. I'm not sure what's involved for a test on this.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3438#issuecomment-374916603
https://github.com/broadinstitute/cromwell/pull/3438#issuecomment-374939225:226,Deployability,update,update,226,I can add a test.; I'm all for making PRs to CWL conformance tests but it's going to increase the merge time of our PRs if we want to wait for it to be in the CWL repo. Also we'd need to unpin the hash for conformance test or update it every time..,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3438#issuecomment-374939225
https://github.com/broadinstitute/cromwell/pull/3438#issuecomment-374939225:197,Security,hash,hash,197,I can add a test.; I'm all for making PRs to CWL conformance tests but it's going to increase the merge time of our PRs if we want to wait for it to be in the CWL repo. Also we'd need to unpin the hash for conformance test or update it every time..,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3438#issuecomment-374939225
https://github.com/broadinstitute/cromwell/pull/3438#issuecomment-374939225:12,Testability,test,test,12,I can add a test.; I'm all for making PRs to CWL conformance tests but it's going to increase the merge time of our PRs if we want to wait for it to be in the CWL repo. Also we'd need to unpin the hash for conformance test or update it every time..,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3438#issuecomment-374939225
https://github.com/broadinstitute/cromwell/pull/3438#issuecomment-374939225:61,Testability,test,tests,61,I can add a test.; I'm all for making PRs to CWL conformance tests but it's going to increase the merge time of our PRs if we want to wait for it to be in the CWL repo. Also we'd need to unpin the hash for conformance test or update it every time..,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3438#issuecomment-374939225
https://github.com/broadinstitute/cromwell/pull/3438#issuecomment-374939225:218,Testability,test,test,218,I can add a test.; I'm all for making PRs to CWL conformance tests but it's going to increase the merge time of our PRs if we want to wait for it to be in the CWL repo. Also we'd need to unpin the hash for conformance test or update it every time..,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3438#issuecomment-374939225
https://github.com/broadinstitute/cromwell/pull/3439#issuecomment-374730690:29,Modifiability,refactor,refactored,29,Red thumb required because I refactored the `size` function in `IoFunctionSet` in `cromwell.backend`. Previously it was implementing a bunch of parameter parsing and implementing the WDL Draft 2 semantics. Now it tells you the size of a file and the language versions implement the semantics around that.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3439#issuecomment-374730690
https://github.com/broadinstitute/cromwell/pull/3442#issuecomment-375038040:2,Availability,down,download,2,![download](https://user-images.githubusercontent.com/961771/37727961-6b031812-2d0f-11e8-8150-cf0f1d2bbc00.jpg),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3442#issuecomment-375038040
https://github.com/broadinstitute/cromwell/pull/3443#issuecomment-375080865:229,Modifiability,refactor,refactor,229,"Discussed in person, a better way could be to do this work as a separate graph node. It would make the wiring a bit more complicated and the immediate gain isn't clear so I'll leave as is for now and we can revisit later when we refactor everything to finally achieve Cromwell singularity.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3443#issuecomment-375080865
https://github.com/broadinstitute/cromwell/pull/3443#issuecomment-375080865:162,Usability,clear,clear,162,"Discussed in person, a better way could be to do this work as a separate graph node. It would make the wiring a bit more complicated and the immediate gain isn't clear so I'll leave as is for now and we can revisit later when we refactor everything to finally achieve Cromwell singularity.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3443#issuecomment-375080865
https://github.com/broadinstitute/cromwell/pull/3446#issuecomment-375746261:71,Modifiability,config,config,71,Am just seeing the latest talk on the bug saying that this should be a config option. I will have to re-work this.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3446#issuecomment-375746261
https://github.com/broadinstitute/cromwell/issues/3449#issuecomment-387113756:110,Deployability,update,updates,110,"@nrockweiler hello, please refer to https://github.com/broadinstitute/cromwell/issues/2916 for requester pays updates.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3449#issuecomment-387113756
https://github.com/broadinstitute/cromwell/issues/3454#issuecomment-455367417:355,Energy Efficiency,schedul,scheduled,355,"I'm late to the party on this, but:. > Then chains of tasks could effectively become one task. I don't think merging of tasks works if you have certain resource or software dependencies, eg: inside a docker container. From a software engineering POV, is it easy / possible to detect and facilitate streaming between tasks like this, especially if they're scheduled as completely separate jobs? To me it sounds super difficult, like you'd have like a ""fuzzy"" dependency graph, and you could end up streaming your result data between nodes or tasks (and even worse if you're running on the cloud). (@mr-c, you've talked about this a [few times](https://github.com/common-workflow-language/cwltool/issues/644#issuecomment-366719563)). > parallel, rather than sequentially. Mostly, but what happens if two of the inputs are technically streamable, or even more complicated how would `stdin` fit into this. The [CWL documentation](https://www.commonwl.org/v1.0/CommandLineTool.html#CommandLineTool) says that it requires the path (eg: [`$(inputs.stdinRef.path)`](; https://www.biostars.org/p/258614/#290536)) which to me sounds like it isn't exactly streamable, but `stdout` [implicitly is?](https://www.commonwl.org/v1.0/CommandLineTool.html#stdout) WDL in the version [1.0 spec](https://github.com/openwdl/wdl/blob/master/versions/1.0/SPEC.md#language-specification) doesn't include any reference to 'stream', so I'm surprised to see the DNAnexus adding a separate tagging mechanism for this optimisation. _Late edit: reformatting for clarity_; Engine support:. - Cromwell (not supported) [[source](https://github.com/broadinstitute/cromwell/issues/3454#issuecomment-455542734)]; - CWLTool (not supported) [[source](https://github.com/common-workflow-language/cwltool/issues/644)]; - Toil (not supported) [[source](https://github.com/common-workflow-language/cwltool/issues/644#issuecomment-366719563)]. But piping (named and anonymous) is super easy in WDL because you have a command line, and in CWL yo",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3454#issuecomment-455367417
https://github.com/broadinstitute/cromwell/issues/3454#issuecomment-455367417:173,Integrability,depend,dependencies,173,"I'm late to the party on this, but:. > Then chains of tasks could effectively become one task. I don't think merging of tasks works if you have certain resource or software dependencies, eg: inside a docker container. From a software engineering POV, is it easy / possible to detect and facilitate streaming between tasks like this, especially if they're scheduled as completely separate jobs? To me it sounds super difficult, like you'd have like a ""fuzzy"" dependency graph, and you could end up streaming your result data between nodes or tasks (and even worse if you're running on the cloud). (@mr-c, you've talked about this a [few times](https://github.com/common-workflow-language/cwltool/issues/644#issuecomment-366719563)). > parallel, rather than sequentially. Mostly, but what happens if two of the inputs are technically streamable, or even more complicated how would `stdin` fit into this. The [CWL documentation](https://www.commonwl.org/v1.0/CommandLineTool.html#CommandLineTool) says that it requires the path (eg: [`$(inputs.stdinRef.path)`](; https://www.biostars.org/p/258614/#290536)) which to me sounds like it isn't exactly streamable, but `stdout` [implicitly is?](https://www.commonwl.org/v1.0/CommandLineTool.html#stdout) WDL in the version [1.0 spec](https://github.com/openwdl/wdl/blob/master/versions/1.0/SPEC.md#language-specification) doesn't include any reference to 'stream', so I'm surprised to see the DNAnexus adding a separate tagging mechanism for this optimisation. _Late edit: reformatting for clarity_; Engine support:. - Cromwell (not supported) [[source](https://github.com/broadinstitute/cromwell/issues/3454#issuecomment-455542734)]; - CWLTool (not supported) [[source](https://github.com/common-workflow-language/cwltool/issues/644)]; - Toil (not supported) [[source](https://github.com/common-workflow-language/cwltool/issues/644#issuecomment-366719563)]. But piping (named and anonymous) is super easy in WDL because you have a command line, and in CWL yo",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3454#issuecomment-455367417
https://github.com/broadinstitute/cromwell/issues/3454#issuecomment-455367417:458,Integrability,depend,dependency,458,"I'm late to the party on this, but:. > Then chains of tasks could effectively become one task. I don't think merging of tasks works if you have certain resource or software dependencies, eg: inside a docker container. From a software engineering POV, is it easy / possible to detect and facilitate streaming between tasks like this, especially if they're scheduled as completely separate jobs? To me it sounds super difficult, like you'd have like a ""fuzzy"" dependency graph, and you could end up streaming your result data between nodes or tasks (and even worse if you're running on the cloud). (@mr-c, you've talked about this a [few times](https://github.com/common-workflow-language/cwltool/issues/644#issuecomment-366719563)). > parallel, rather than sequentially. Mostly, but what happens if two of the inputs are technically streamable, or even more complicated how would `stdin` fit into this. The [CWL documentation](https://www.commonwl.org/v1.0/CommandLineTool.html#CommandLineTool) says that it requires the path (eg: [`$(inputs.stdinRef.path)`](; https://www.biostars.org/p/258614/#290536)) which to me sounds like it isn't exactly streamable, but `stdout` [implicitly is?](https://www.commonwl.org/v1.0/CommandLineTool.html#stdout) WDL in the version [1.0 spec](https://github.com/openwdl/wdl/blob/master/versions/1.0/SPEC.md#language-specification) doesn't include any reference to 'stream', so I'm surprised to see the DNAnexus adding a separate tagging mechanism for this optimisation. _Late edit: reformatting for clarity_; Engine support:. - Cromwell (not supported) [[source](https://github.com/broadinstitute/cromwell/issues/3454#issuecomment-455542734)]; - CWLTool (not supported) [[source](https://github.com/common-workflow-language/cwltool/issues/644)]; - Toil (not supported) [[source](https://github.com/common-workflow-language/cwltool/issues/644#issuecomment-366719563)]. But piping (named and anonymous) is super easy in WDL because you have a command line, and in CWL yo",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3454#issuecomment-455367417
https://github.com/broadinstitute/cromwell/issues/3454#issuecomment-455367417:276,Safety,detect,detect,276,"I'm late to the party on this, but:. > Then chains of tasks could effectively become one task. I don't think merging of tasks works if you have certain resource or software dependencies, eg: inside a docker container. From a software engineering POV, is it easy / possible to detect and facilitate streaming between tasks like this, especially if they're scheduled as completely separate jobs? To me it sounds super difficult, like you'd have like a ""fuzzy"" dependency graph, and you could end up streaming your result data between nodes or tasks (and even worse if you're running on the cloud). (@mr-c, you've talked about this a [few times](https://github.com/common-workflow-language/cwltool/issues/644#issuecomment-366719563)). > parallel, rather than sequentially. Mostly, but what happens if two of the inputs are technically streamable, or even more complicated how would `stdin` fit into this. The [CWL documentation](https://www.commonwl.org/v1.0/CommandLineTool.html#CommandLineTool) says that it requires the path (eg: [`$(inputs.stdinRef.path)`](; https://www.biostars.org/p/258614/#290536)) which to me sounds like it isn't exactly streamable, but `stdout` [implicitly is?](https://www.commonwl.org/v1.0/CommandLineTool.html#stdout) WDL in the version [1.0 spec](https://github.com/openwdl/wdl/blob/master/versions/1.0/SPEC.md#language-specification) doesn't include any reference to 'stream', so I'm surprised to see the DNAnexus adding a separate tagging mechanism for this optimisation. _Late edit: reformatting for clarity_; Engine support:. - Cromwell (not supported) [[source](https://github.com/broadinstitute/cromwell/issues/3454#issuecomment-455542734)]; - CWLTool (not supported) [[source](https://github.com/common-workflow-language/cwltool/issues/644)]; - Toil (not supported) [[source](https://github.com/common-workflow-language/cwltool/issues/644#issuecomment-366719563)]. But piping (named and anonymous) is super easy in WDL because you have a command line, and in CWL yo",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3454#issuecomment-455367417
https://github.com/broadinstitute/cromwell/issues/3454#issuecomment-455542734:103,Integrability,depend,depending,103,"Cromwell itself doesn't implement streaming for tasks in either WDL or CWL, mostly. The one exception, depending on how broadly one wants to define streaming, is Cromwell can understand a WDL ""hint"" (in quotes as there's not an official concept) that a cloud native path in a `File` variable can be handed directly to the task instead of converted to a local file on the POSIX filesystem. This is using the same sort of markup that DNANexus is using in the task metadata of the WDL.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3454#issuecomment-455542734
https://github.com/broadinstitute/cromwell/issues/3454#issuecomment-455542734:283,Modifiability,variab,variable,283,"Cromwell itself doesn't implement streaming for tasks in either WDL or CWL, mostly. The one exception, depending on how broadly one wants to define streaming, is Cromwell can understand a WDL ""hint"" (in quotes as there's not an official concept) that a cloud native path in a `File` variable can be handed directly to the task instead of converted to a local file on the POSIX filesystem. This is using the same sort of markup that DNANexus is using in the task metadata of the WDL.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3454#issuecomment-455542734
https://github.com/broadinstitute/cromwell/issues/3454#issuecomment-860446694:239,Availability,down,downloads,239,"> Engine support:. For streaming to/from the data storage system, the Arvados Keep data system means that the Arvados Crunch workflow manager doesn't have to wait for input files to be staged (copied) in. The Arvados Keep FUSE plugin only downloads data as the tool requests access to a particular offset. I don't think they co-schedule tasks (either on the same system or ""nearby"" nodes) for direct streaming yet",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3454#issuecomment-860446694
https://github.com/broadinstitute/cromwell/issues/3454#issuecomment-860446694:328,Energy Efficiency,schedul,schedule,328,"> Engine support:. For streaming to/from the data storage system, the Arvados Keep data system means that the Arvados Crunch workflow manager doesn't have to wait for input files to be staged (copied) in. The Arvados Keep FUSE plugin only downloads data as the tool requests access to a particular offset. I don't think they co-schedule tasks (either on the same system or ""nearby"" nodes) for direct streaming yet",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3454#issuecomment-860446694
https://github.com/broadinstitute/cromwell/issues/3454#issuecomment-860446694:227,Modifiability,plugin,plugin,227,"> Engine support:. For streaming to/from the data storage system, the Arvados Keep data system means that the Arvados Crunch workflow manager doesn't have to wait for input files to be staged (copied) in. The Arvados Keep FUSE plugin only downloads data as the tool requests access to a particular offset. I don't think they co-schedule tasks (either on the same system or ""nearby"" nodes) for direct streaming yet",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3454#issuecomment-860446694
https://github.com/broadinstitute/cromwell/issues/3454#issuecomment-860446694:275,Security,access,access,275,"> Engine support:. For streaming to/from the data storage system, the Arvados Keep data system means that the Arvados Crunch workflow manager doesn't have to wait for input files to be staged (copied) in. The Arvados Keep FUSE plugin only downloads data as the tool requests access to a particular offset. I don't think they co-schedule tasks (either on the same system or ""nearby"" nodes) for direct streaming yet",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3454#issuecomment-860446694
https://github.com/broadinstitute/cromwell/pull/3455#issuecomment-376360340:60,Performance,load,loaded,60,Assuming the 0% coverage is an artifact of this class being loaded through reflection or something?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3455#issuecomment-376360340
https://github.com/broadinstitute/cromwell/pull/3455#issuecomment-376364550:98,Testability,test,test,98,@mcovarr hmm I guess technically this `NoopServiceActor` is 100% untested...; I'll move it to the test folder or test that it indeed does nothing,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3455#issuecomment-376364550
https://github.com/broadinstitute/cromwell/pull/3455#issuecomment-376364550:113,Testability,test,test,113,@mcovarr hmm I guess technically this `NoopServiceActor` is 100% untested...; I'll move it to the test folder or test that it indeed does nothing,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3455#issuecomment-376364550
https://github.com/broadinstitute/cromwell/pull/3455#issuecomment-376547433:29,Testability,Test,TestKit,29,I can't imagine the standard TestKit actor responds to `cromwell.util.GracefulShutdownHelper.ShutdownCommand` though...,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3455#issuecomment-376547433
https://github.com/broadinstitute/cromwell/pull/3455#issuecomment-376551184:134,Availability,down,down,134,"The constructor signature needs to be exactly that since it's built reflectively, and like Miguel said it's better if it shuts itself down with the ShutdownCommand. Plus it's literally 5 lines so.. üòÑ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3455#issuecomment-376551184
https://github.com/broadinstitute/cromwell/pull/3457#issuecomment-376602036:55,Availability,failure,failures,55,I don't think so but it's the first layer of the multi-failures test I was trying to fix. The rest is not ready yet but I though I'd PR that already in case other tests fail because of it,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3457#issuecomment-376602036
https://github.com/broadinstitute/cromwell/pull/3457#issuecomment-376602036:64,Testability,test,test,64,I don't think so but it's the first layer of the multi-failures test I was trying to fix. The rest is not ready yet but I though I'd PR that already in case other tests fail because of it,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3457#issuecomment-376602036
https://github.com/broadinstitute/cromwell/pull/3457#issuecomment-376602036:163,Testability,test,tests,163,I don't think so but it's the first layer of the multi-failures test I was trying to fix. The rest is not ready yet but I though I'd PR that already in case other tests fail because of it,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3457#issuecomment-376602036
https://github.com/broadinstitute/cromwell/pull/3460#issuecomment-377043537:315,Integrability,wrap,wrapped,315,"Lots of changes here for reviewer comments: this now works for expression dirents that evaluate to arrays of `WomSingleFile`s and not just ""scalar"" `WomSingleFile`s, although there isn't currently a test for arrays. We could possibly PR such a test into CWL (it's the same as the scalar test with the JS expression wrapped in square brackets)? We definitely shouldn't PR any tests for expression dirents that evaluate to `WomMaybePopulatedFile`s (scalar or array) since we wouldn't pass such a test atm. üò¶",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3460#issuecomment-377043537
https://github.com/broadinstitute/cromwell/pull/3460#issuecomment-377043537:199,Testability,test,test,199,"Lots of changes here for reviewer comments: this now works for expression dirents that evaluate to arrays of `WomSingleFile`s and not just ""scalar"" `WomSingleFile`s, although there isn't currently a test for arrays. We could possibly PR such a test into CWL (it's the same as the scalar test with the JS expression wrapped in square brackets)? We definitely shouldn't PR any tests for expression dirents that evaluate to `WomMaybePopulatedFile`s (scalar or array) since we wouldn't pass such a test atm. üò¶",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3460#issuecomment-377043537
https://github.com/broadinstitute/cromwell/pull/3460#issuecomment-377043537:244,Testability,test,test,244,"Lots of changes here for reviewer comments: this now works for expression dirents that evaluate to arrays of `WomSingleFile`s and not just ""scalar"" `WomSingleFile`s, although there isn't currently a test for arrays. We could possibly PR such a test into CWL (it's the same as the scalar test with the JS expression wrapped in square brackets)? We definitely shouldn't PR any tests for expression dirents that evaluate to `WomMaybePopulatedFile`s (scalar or array) since we wouldn't pass such a test atm. üò¶",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3460#issuecomment-377043537
https://github.com/broadinstitute/cromwell/pull/3460#issuecomment-377043537:287,Testability,test,test,287,"Lots of changes here for reviewer comments: this now works for expression dirents that evaluate to arrays of `WomSingleFile`s and not just ""scalar"" `WomSingleFile`s, although there isn't currently a test for arrays. We could possibly PR such a test into CWL (it's the same as the scalar test with the JS expression wrapped in square brackets)? We definitely shouldn't PR any tests for expression dirents that evaluate to `WomMaybePopulatedFile`s (scalar or array) since we wouldn't pass such a test atm. üò¶",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3460#issuecomment-377043537
https://github.com/broadinstitute/cromwell/pull/3460#issuecomment-377043537:375,Testability,test,tests,375,"Lots of changes here for reviewer comments: this now works for expression dirents that evaluate to arrays of `WomSingleFile`s and not just ""scalar"" `WomSingleFile`s, although there isn't currently a test for arrays. We could possibly PR such a test into CWL (it's the same as the scalar test with the JS expression wrapped in square brackets)? We definitely shouldn't PR any tests for expression dirents that evaluate to `WomMaybePopulatedFile`s (scalar or array) since we wouldn't pass such a test atm. üò¶",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3460#issuecomment-377043537
https://github.com/broadinstitute/cromwell/pull/3460#issuecomment-377043537:494,Testability,test,test,494,"Lots of changes here for reviewer comments: this now works for expression dirents that evaluate to arrays of `WomSingleFile`s and not just ""scalar"" `WomSingleFile`s, although there isn't currently a test for arrays. We could possibly PR such a test into CWL (it's the same as the scalar test with the JS expression wrapped in square brackets)? We definitely shouldn't PR any tests for expression dirents that evaluate to `WomMaybePopulatedFile`s (scalar or array) since we wouldn't pass such a test atm. üò¶",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3460#issuecomment-377043537
https://github.com/broadinstitute/cromwell/pull/3460#issuecomment-377046137:0,Availability,Error,Error,0,Error message from this failed test on PAPI ü§î . ```Could not copy gs://cloud-cromwell-dev/cromwell_execution/travis/linkfile.cwl/5c134cd8-80d5-47d1-a635-e4dd5df2356d/call-linkfile.cwl/home/travis/build/broadinstitute/cromwell/common-workflow-language/v1.0/v1.0/gs://centaur-cwl-conformance/cwl-inputs/Hello.java to gs://cloud-cromwell-dev/cromwell_execution/travis/linkfile.cwl/5c134cd8-80d5-47d1-a635-e4dd5df2356d/call-linkfile.cwl/Hello.java```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3460#issuecomment-377046137
https://github.com/broadinstitute/cromwell/pull/3460#issuecomment-377046137:6,Integrability,message,message,6,Error message from this failed test on PAPI ü§î . ```Could not copy gs://cloud-cromwell-dev/cromwell_execution/travis/linkfile.cwl/5c134cd8-80d5-47d1-a635-e4dd5df2356d/call-linkfile.cwl/home/travis/build/broadinstitute/cromwell/common-workflow-language/v1.0/v1.0/gs://centaur-cwl-conformance/cwl-inputs/Hello.java to gs://cloud-cromwell-dev/cromwell_execution/travis/linkfile.cwl/5c134cd8-80d5-47d1-a635-e4dd5df2356d/call-linkfile.cwl/Hello.java```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3460#issuecomment-377046137
https://github.com/broadinstitute/cromwell/pull/3460#issuecomment-377046137:31,Testability,test,test,31,Error message from this failed test on PAPI ü§î . ```Could not copy gs://cloud-cromwell-dev/cromwell_execution/travis/linkfile.cwl/5c134cd8-80d5-47d1-a635-e4dd5df2356d/call-linkfile.cwl/home/travis/build/broadinstitute/cromwell/common-workflow-language/v1.0/v1.0/gs://centaur-cwl-conformance/cwl-inputs/Hello.java to gs://cloud-cromwell-dev/cromwell_execution/travis/linkfile.cwl/5c134cd8-80d5-47d1-a635-e4dd5df2356d/call-linkfile.cwl/Hello.java```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3460#issuecomment-377046137
https://github.com/broadinstitute/cromwell/issues/3461#issuecomment-388333576:692,Deployability,integrat,integrated,692,"It would be very nice to support Mesos, as it is a very nice framework for in house cloud computing systems. Not everyone is able to launch their jobs into the cloud. I see you already have support for Yarn here: . http://cromwell.readthedocs.io/en/develop/backends/Spark/. And we also have this:; ```; A not so widely known fact is that Spark has its root in Mesos: it was ; initially developed at the AMPLab as a proof-of-concept Mesos ; framework to demonstrate how easy and fast ; it is to develop a distributed platform on top of Mesos; ```; taken from here : ; * https://mesosphere.com/blog/spark-mesos-shared-history-and-future-mesosphere-hackweek/. Spark and Mesos was really closely integrated, though I see that Spark has created their own scheduler, Mesos is still a very good way of running Spark jobs. It would be a very nice addition to the Chromwell framework! . Mesos is used in many other Big Data cloud environments outside of the Bioinformatics pipelines.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3461#issuecomment-388333576
https://github.com/broadinstitute/cromwell/issues/3461#issuecomment-388333576:964,Deployability,pipeline,pipelines,964,"It would be very nice to support Mesos, as it is a very nice framework for in house cloud computing systems. Not everyone is able to launch their jobs into the cloud. I see you already have support for Yarn here: . http://cromwell.readthedocs.io/en/develop/backends/Spark/. And we also have this:; ```; A not so widely known fact is that Spark has its root in Mesos: it was ; initially developed at the AMPLab as a proof-of-concept Mesos ; framework to demonstrate how easy and fast ; it is to develop a distributed platform on top of Mesos; ```; taken from here : ; * https://mesosphere.com/blog/spark-mesos-shared-history-and-future-mesosphere-hackweek/. Spark and Mesos was really closely integrated, though I see that Spark has created their own scheduler, Mesos is still a very good way of running Spark jobs. It would be a very nice addition to the Chromwell framework! . Mesos is used in many other Big Data cloud environments outside of the Bioinformatics pipelines.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3461#issuecomment-388333576
https://github.com/broadinstitute/cromwell/issues/3461#issuecomment-388333576:750,Energy Efficiency,schedul,scheduler,750,"It would be very nice to support Mesos, as it is a very nice framework for in house cloud computing systems. Not everyone is able to launch their jobs into the cloud. I see you already have support for Yarn here: . http://cromwell.readthedocs.io/en/develop/backends/Spark/. And we also have this:; ```; A not so widely known fact is that Spark has its root in Mesos: it was ; initially developed at the AMPLab as a proof-of-concept Mesos ; framework to demonstrate how easy and fast ; it is to develop a distributed platform on top of Mesos; ```; taken from here : ; * https://mesosphere.com/blog/spark-mesos-shared-history-and-future-mesosphere-hackweek/. Spark and Mesos was really closely integrated, though I see that Spark has created their own scheduler, Mesos is still a very good way of running Spark jobs. It would be a very nice addition to the Chromwell framework! . Mesos is used in many other Big Data cloud environments outside of the Bioinformatics pipelines.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3461#issuecomment-388333576
https://github.com/broadinstitute/cromwell/issues/3461#issuecomment-388333576:692,Integrability,integrat,integrated,692,"It would be very nice to support Mesos, as it is a very nice framework for in house cloud computing systems. Not everyone is able to launch their jobs into the cloud. I see you already have support for Yarn here: . http://cromwell.readthedocs.io/en/develop/backends/Spark/. And we also have this:; ```; A not so widely known fact is that Spark has its root in Mesos: it was ; initially developed at the AMPLab as a proof-of-concept Mesos ; framework to demonstrate how easy and fast ; it is to develop a distributed platform on top of Mesos; ```; taken from here : ; * https://mesosphere.com/blog/spark-mesos-shared-history-and-future-mesosphere-hackweek/. Spark and Mesos was really closely integrated, though I see that Spark has created their own scheduler, Mesos is still a very good way of running Spark jobs. It would be a very nice addition to the Chromwell framework! . Mesos is used in many other Big Data cloud environments outside of the Bioinformatics pipelines.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3461#issuecomment-388333576
https://github.com/broadinstitute/cromwell/issues/3461#issuecomment-416991555:100,Availability,avail,available,100,"Hi @ruchim,. Personally, the reason I'm asking for Mesos support is because we have a Mesos cluster available, but no yarn. It's awesome cromwell already supports yarn, but it'd be great to have even more options. Cheers; M",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3461#issuecomment-416991555
https://github.com/broadinstitute/cromwell/issues/3461#issuecomment-417230977:440,Energy Efficiency,schedul,schedule,440,"Hello @ruchim :-). The Spark job will run just as good in Yarn as in Mesos, I am pretty sure about that. Main difference is that Mesos is much more advanced than Yarn. It is more scalable, both in terms of nr of nodes, nr of jobs, and types of jobs and applications. . In Mesos, you can run both normal applications (web apps etc.), like you do in Kubernetes, and you can run compute / Big Data processing jobs in the same cluster. You can schedule both cpu and memory usage, not only memory usage as in Yarn. Mesos creates a virtual operating system on top of your cluster, kind of. Yarn is not capable of that as I know it. You can even run Yarn and Kubernetes on top of Mesos etc. Choosing Mesos over Yarn, will therefor make sense for many companies, because you get one system to rule them all. It might add more complexity also though ... I am a bit dated on this, Yarn might have evolved since I looked at it. This article is good at explaining the difference:. https://www.oreilly.com/ideas/a-tale-of-two-clusters-mesos-and-yarn. Here is a nice summary of the main differences:; https://data-flair.training/blogs/comparison-between-apache-mesos-vs-hadoop-yarn/. Hope this give some answers :-)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3461#issuecomment-417230977
https://github.com/broadinstitute/cromwell/issues/3461#issuecomment-417230977:887,Modifiability,evolve,evolved,887,"Hello @ruchim :-). The Spark job will run just as good in Yarn as in Mesos, I am pretty sure about that. Main difference is that Mesos is much more advanced than Yarn. It is more scalable, both in terms of nr of nodes, nr of jobs, and types of jobs and applications. . In Mesos, you can run both normal applications (web apps etc.), like you do in Kubernetes, and you can run compute / Big Data processing jobs in the same cluster. You can schedule both cpu and memory usage, not only memory usage as in Yarn. Mesos creates a virtual operating system on top of your cluster, kind of. Yarn is not capable of that as I know it. You can even run Yarn and Kubernetes on top of Mesos etc. Choosing Mesos over Yarn, will therefor make sense for many companies, because you get one system to rule them all. It might add more complexity also though ... I am a bit dated on this, Yarn might have evolved since I looked at it. This article is good at explaining the difference:. https://www.oreilly.com/ideas/a-tale-of-two-clusters-mesos-and-yarn. Here is a nice summary of the main differences:; https://data-flair.training/blogs/comparison-between-apache-mesos-vs-hadoop-yarn/. Hope this give some answers :-)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3461#issuecomment-417230977
https://github.com/broadinstitute/cromwell/issues/3461#issuecomment-417230977:179,Performance,scalab,scalable,179,"Hello @ruchim :-). The Spark job will run just as good in Yarn as in Mesos, I am pretty sure about that. Main difference is that Mesos is much more advanced than Yarn. It is more scalable, both in terms of nr of nodes, nr of jobs, and types of jobs and applications. . In Mesos, you can run both normal applications (web apps etc.), like you do in Kubernetes, and you can run compute / Big Data processing jobs in the same cluster. You can schedule both cpu and memory usage, not only memory usage as in Yarn. Mesos creates a virtual operating system on top of your cluster, kind of. Yarn is not capable of that as I know it. You can even run Yarn and Kubernetes on top of Mesos etc. Choosing Mesos over Yarn, will therefor make sense for many companies, because you get one system to rule them all. It might add more complexity also though ... I am a bit dated on this, Yarn might have evolved since I looked at it. This article is good at explaining the difference:. https://www.oreilly.com/ideas/a-tale-of-two-clusters-mesos-and-yarn. Here is a nice summary of the main differences:; https://data-flair.training/blogs/comparison-between-apache-mesos-vs-hadoop-yarn/. Hope this give some answers :-)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3461#issuecomment-417230977
https://github.com/broadinstitute/cromwell/pull/3462#issuecomment-377018271:47,Deployability,update,update,47,"~~possibly yes~~; probably not, however I will update the doc to point to what will (help).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3462#issuecomment-377018271
https://github.com/broadinstitute/cromwell/pull/3463#issuecomment-377288935:189,Integrability,depend,depend,189,"For TPUs, good question but I don't know. From the [doc](https://cloud.google.com/tpu/docs/quickstart) it seems relatively different, but AFAICT PAPI doesn't support that yet so it'll also depend on how what information they expect to be passed in.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3463#issuecomment-377288935
https://github.com/broadinstitute/cromwell/pull/3464#issuecomment-377058006:206,Availability,down,down,206,"Apologies if it's there & i misunderstood what was going on, but would it be feasible to add a test somehow checking that it's working as intended?. I know, I know, Jeff is actually asking for tests? Up is down, cats and dogs living together in sin ....",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3464#issuecomment-377058006
https://github.com/broadinstitute/cromwell/pull/3464#issuecomment-377058006:95,Testability,test,test,95,"Apologies if it's there & i misunderstood what was going on, but would it be feasible to add a test somehow checking that it's working as intended?. I know, I know, Jeff is actually asking for tests? Up is down, cats and dogs living together in sin ....",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3464#issuecomment-377058006
https://github.com/broadinstitute/cromwell/pull/3464#issuecomment-377058006:193,Testability,test,tests,193,"Apologies if it's there & i misunderstood what was going on, but would it be feasible to add a test somehow checking that it's working as intended?. I know, I know, Jeff is actually asking for tests? Up is down, cats and dogs living together in sin ....",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3464#issuecomment-377058006
https://github.com/broadinstitute/cromwell/pull/3474#issuecomment-378407007:51,Testability,log,logic,51,It could also be worth considering having the same logic when determining the host/container paths of inputs for PAPI jobs. I think they also end up with concatenated paths,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3474#issuecomment-378407007
https://github.com/broadinstitute/cromwell/pull/3474#issuecomment-378633488:315,Testability,test,test,315,"Minutes from recent in-person discussions:. * other teams are not using prior knowledge of these paths (namely mint team is looking at outputs, not input paths).; * other backends do nothing during ""preProcess"" stage, thus do not have to conform to this new arrangement. also since I've heard nothing regarding the test deletion I proposed I'm going to proceed as planned",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3474#issuecomment-378633488
https://github.com/broadinstitute/cromwell/pull/3474#issuecomment-378742018:96,Testability,test,test,96,"@danbills it makes me nervous that we're changing how something works in a way that enables one test, and then deleting an old test which was no longer working. Not saying this is bad or wrong (and the fewer of those old ""run a workflow"" tests the better)... this is just a request to check through the centaur tests and make sure they really do cover the case which you're assuming they do",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3474#issuecomment-378742018
https://github.com/broadinstitute/cromwell/pull/3474#issuecomment-378742018:127,Testability,test,test,127,"@danbills it makes me nervous that we're changing how something works in a way that enables one test, and then deleting an old test which was no longer working. Not saying this is bad or wrong (and the fewer of those old ""run a workflow"" tests the better)... this is just a request to check through the centaur tests and make sure they really do cover the case which you're assuming they do",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3474#issuecomment-378742018
https://github.com/broadinstitute/cromwell/pull/3474#issuecomment-378742018:238,Testability,test,tests,238,"@danbills it makes me nervous that we're changing how something works in a way that enables one test, and then deleting an old test which was no longer working. Not saying this is bad or wrong (and the fewer of those old ""run a workflow"" tests the better)... this is just a request to check through the centaur tests and make sure they really do cover the case which you're assuming they do",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3474#issuecomment-378742018
https://github.com/broadinstitute/cromwell/pull/3474#issuecomment-378742018:311,Testability,test,tests,311,"@danbills it makes me nervous that we're changing how something works in a way that enables one test, and then deleting an old test which was no longer working. Not saying this is bad or wrong (and the fewer of those old ""run a workflow"" tests the better)... this is just a request to check through the centaur tests and make sure they really do cover the case which you're assuming they do",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3474#issuecomment-378742018
https://github.com/broadinstitute/cromwell/pull/3474#issuecomment-378990425:61,Testability,test,tested,61,@cjllanwarne Indeed `read_map` and `write_map` was not being tested in centaur. I will migrate this test.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3474#issuecomment-378990425
https://github.com/broadinstitute/cromwell/pull/3474#issuecomment-378990425:100,Testability,test,test,100,@cjllanwarne Indeed `read_map` and `write_map` was not being tested in centaur. I will migrate this test.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3474#issuecomment-378990425
https://github.com/broadinstitute/cromwell/pull/3474#issuecomment-379322151:29,Testability,test,test,29,"@geoffjentry no, in fact the test I took screenshots from is a filename collision test, notice they're both name `out.txt`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3474#issuecomment-379322151
https://github.com/broadinstitute/cromwell/pull/3474#issuecomment-379322151:82,Testability,test,test,82,"@geoffjentry no, in fact the test I took screenshots from is a filename collision test, notice they're both name `out.txt`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3474#issuecomment-379322151
https://github.com/broadinstitute/cromwell/issues/3477#issuecomment-378636936:775,Deployability,configurat,configuration,775,"Hi @rasmuse - a few thoughts. In terms of the submit time keep in mind things like JVM initialization. Calling individual invocations of a java program like that for what's effectively a blink of an eye operation is never going to be ideal from a performance perspective. If you're submitting to a Cromwell server consider using something like `curl` instead. . On the second part, there are a few things potentially going on here. First is that Cromwell doesn't necessarily immediately start a workflow. It scans every `n` seconds for new workflows to start, which defaults to `20`. In a worst case scenario `21` of your `20` seconds could be due to that, although that seems unlikely. You can make that time window shorter by overriding the `system.new-workflow-poll-rate` configuration setting to something smaller, e.g. `1`. Even then, there's a some overhead in there as ultimately we're trying to optimize for a case that's not running single, extremely short tasks. I just ran the moral equivalent of a hello world workflow locally with that config setting set to 1 second. The workflow was picked up for execution at `11:08:44` and registered as complete at `11:08:51` with exactly half of that time spent with the system running the underlying job (i.e. not in Cromwell) so it might be worth revisiting this w/ a combination of using `curl` and speeding up the workflow polling rate. That said while I'd love you to continue to use Cromwell/WDL, it might not wind up being the best tool for your job. If these workflows are purely for yourself & you don't intend on building them up over time and/or distributing them to others, you might want to check out Snakemake which is more intended to be a direct Makefile replacement.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3477#issuecomment-378636936
https://github.com/broadinstitute/cromwell/issues/3477#issuecomment-378636936:775,Modifiability,config,configuration,775,"Hi @rasmuse - a few thoughts. In terms of the submit time keep in mind things like JVM initialization. Calling individual invocations of a java program like that for what's effectively a blink of an eye operation is never going to be ideal from a performance perspective. If you're submitting to a Cromwell server consider using something like `curl` instead. . On the second part, there are a few things potentially going on here. First is that Cromwell doesn't necessarily immediately start a workflow. It scans every `n` seconds for new workflows to start, which defaults to `20`. In a worst case scenario `21` of your `20` seconds could be due to that, although that seems unlikely. You can make that time window shorter by overriding the `system.new-workflow-poll-rate` configuration setting to something smaller, e.g. `1`. Even then, there's a some overhead in there as ultimately we're trying to optimize for a case that's not running single, extremely short tasks. I just ran the moral equivalent of a hello world workflow locally with that config setting set to 1 second. The workflow was picked up for execution at `11:08:44` and registered as complete at `11:08:51` with exactly half of that time spent with the system running the underlying job (i.e. not in Cromwell) so it might be worth revisiting this w/ a combination of using `curl` and speeding up the workflow polling rate. That said while I'd love you to continue to use Cromwell/WDL, it might not wind up being the best tool for your job. If these workflows are purely for yourself & you don't intend on building them up over time and/or distributing them to others, you might want to check out Snakemake which is more intended to be a direct Makefile replacement.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3477#issuecomment-378636936
https://github.com/broadinstitute/cromwell/issues/3477#issuecomment-378636936:1049,Modifiability,config,config,1049,"Hi @rasmuse - a few thoughts. In terms of the submit time keep in mind things like JVM initialization. Calling individual invocations of a java program like that for what's effectively a blink of an eye operation is never going to be ideal from a performance perspective. If you're submitting to a Cromwell server consider using something like `curl` instead. . On the second part, there are a few things potentially going on here. First is that Cromwell doesn't necessarily immediately start a workflow. It scans every `n` seconds for new workflows to start, which defaults to `20`. In a worst case scenario `21` of your `20` seconds could be due to that, although that seems unlikely. You can make that time window shorter by overriding the `system.new-workflow-poll-rate` configuration setting to something smaller, e.g. `1`. Even then, there's a some overhead in there as ultimately we're trying to optimize for a case that's not running single, extremely short tasks. I just ran the moral equivalent of a hello world workflow locally with that config setting set to 1 second. The workflow was picked up for execution at `11:08:44` and registered as complete at `11:08:51` with exactly half of that time spent with the system running the underlying job (i.e. not in Cromwell) so it might be worth revisiting this w/ a combination of using `curl` and speeding up the workflow polling rate. That said while I'd love you to continue to use Cromwell/WDL, it might not wind up being the best tool for your job. If these workflows are purely for yourself & you don't intend on building them up over time and/or distributing them to others, you might want to check out Snakemake which is more intended to be a direct Makefile replacement.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3477#issuecomment-378636936
https://github.com/broadinstitute/cromwell/issues/3477#issuecomment-378636936:247,Performance,perform,performance,247,"Hi @rasmuse - a few thoughts. In terms of the submit time keep in mind things like JVM initialization. Calling individual invocations of a java program like that for what's effectively a blink of an eye operation is never going to be ideal from a performance perspective. If you're submitting to a Cromwell server consider using something like `curl` instead. . On the second part, there are a few things potentially going on here. First is that Cromwell doesn't necessarily immediately start a workflow. It scans every `n` seconds for new workflows to start, which defaults to `20`. In a worst case scenario `21` of your `20` seconds could be due to that, although that seems unlikely. You can make that time window shorter by overriding the `system.new-workflow-poll-rate` configuration setting to something smaller, e.g. `1`. Even then, there's a some overhead in there as ultimately we're trying to optimize for a case that's not running single, extremely short tasks. I just ran the moral equivalent of a hello world workflow locally with that config setting set to 1 second. The workflow was picked up for execution at `11:08:44` and registered as complete at `11:08:51` with exactly half of that time spent with the system running the underlying job (i.e. not in Cromwell) so it might be worth revisiting this w/ a combination of using `curl` and speeding up the workflow polling rate. That said while I'd love you to continue to use Cromwell/WDL, it might not wind up being the best tool for your job. If these workflows are purely for yourself & you don't intend on building them up over time and/or distributing them to others, you might want to check out Snakemake which is more intended to be a direct Makefile replacement.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3477#issuecomment-378636936
https://github.com/broadinstitute/cromwell/issues/3477#issuecomment-378636936:903,Performance,optimiz,optimize,903,"Hi @rasmuse - a few thoughts. In terms of the submit time keep in mind things like JVM initialization. Calling individual invocations of a java program like that for what's effectively a blink of an eye operation is never going to be ideal from a performance perspective. If you're submitting to a Cromwell server consider using something like `curl` instead. . On the second part, there are a few things potentially going on here. First is that Cromwell doesn't necessarily immediately start a workflow. It scans every `n` seconds for new workflows to start, which defaults to `20`. In a worst case scenario `21` of your `20` seconds could be due to that, although that seems unlikely. You can make that time window shorter by overriding the `system.new-workflow-poll-rate` configuration setting to something smaller, e.g. `1`. Even then, there's a some overhead in there as ultimately we're trying to optimize for a case that's not running single, extremely short tasks. I just ran the moral equivalent of a hello world workflow locally with that config setting set to 1 second. The workflow was picked up for execution at `11:08:44` and registered as complete at `11:08:51` with exactly half of that time spent with the system running the underlying job (i.e. not in Cromwell) so it might be worth revisiting this w/ a combination of using `curl` and speeding up the workflow polling rate. That said while I'd love you to continue to use Cromwell/WDL, it might not wind up being the best tool for your job. If these workflows are purely for yourself & you don't intend on building them up over time and/or distributing them to others, you might want to check out Snakemake which is more intended to be a direct Makefile replacement.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3477#issuecomment-378636936
https://github.com/broadinstitute/cromwell/issues/3477#issuecomment-378866720:189,Testability,test,test,189,"Hi @geoffjentry - thanks for the prompt and detailed response. It makes sense to submit using curl instead. That might save most of the 2.5 seconds. But since your fast-polling hello world test still took 7 seconds from pickup to completion, I still think this would be frustratingly slow. I'm familiar with Snakemake (and about two dozen other similar tools to be found scattered across the web) but I think WDL is better in a number of ways. The main points that I like are (1) that the workflow language is clearly separated from the execution engine, (2) that the language is much more human-readable than CWL, and (3) the possibility to serialize/deserialize values, e.g., so that (3a) simple operations, e.g., concatenation of different results can be done in the workflow language and (3b) one can do things like mapping a task over a set of values coming out of another task. It is also nice that (4) there is a rather solid set of backing organizations behind WDL and Cromwell. As far as I know, this combination of properties gives WDL a rather unique value proposition. Maybe there is room for a simpler local-only WDL execution engine focused on speed and rapid iteration. That could be used for development and then the execution of production workflows on various cloud backends etc could still be done by Cromwell. I was dabbling one weekend a few months ago with a local-only Python compiler/execution engine for WDL. If optimal execution speed is not a must, it does not look too hard to support most of the WDL spec on a local machine. I'm closing this issue for now. Thank you again for the input!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3477#issuecomment-378866720
https://github.com/broadinstitute/cromwell/issues/3477#issuecomment-378866720:510,Usability,clear,clearly,510,"Hi @geoffjentry - thanks for the prompt and detailed response. It makes sense to submit using curl instead. That might save most of the 2.5 seconds. But since your fast-polling hello world test still took 7 seconds from pickup to completion, I still think this would be frustratingly slow. I'm familiar with Snakemake (and about two dozen other similar tools to be found scattered across the web) but I think WDL is better in a number of ways. The main points that I like are (1) that the workflow language is clearly separated from the execution engine, (2) that the language is much more human-readable than CWL, and (3) the possibility to serialize/deserialize values, e.g., so that (3a) simple operations, e.g., concatenation of different results can be done in the workflow language and (3b) one can do things like mapping a task over a set of values coming out of another task. It is also nice that (4) there is a rather solid set of backing organizations behind WDL and Cromwell. As far as I know, this combination of properties gives WDL a rather unique value proposition. Maybe there is room for a simpler local-only WDL execution engine focused on speed and rapid iteration. That could be used for development and then the execution of production workflows on various cloud backends etc could still be done by Cromwell. I was dabbling one weekend a few months ago with a local-only Python compiler/execution engine for WDL. If optimal execution speed is not a must, it does not look too hard to support most of the WDL spec on a local machine. I'm closing this issue for now. Thank you again for the input!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3477#issuecomment-378866720
https://github.com/broadinstitute/cromwell/issues/3477#issuecomment-378866720:691,Usability,simpl,simple,691,"Hi @geoffjentry - thanks for the prompt and detailed response. It makes sense to submit using curl instead. That might save most of the 2.5 seconds. But since your fast-polling hello world test still took 7 seconds from pickup to completion, I still think this would be frustratingly slow. I'm familiar with Snakemake (and about two dozen other similar tools to be found scattered across the web) but I think WDL is better in a number of ways. The main points that I like are (1) that the workflow language is clearly separated from the execution engine, (2) that the language is much more human-readable than CWL, and (3) the possibility to serialize/deserialize values, e.g., so that (3a) simple operations, e.g., concatenation of different results can be done in the workflow language and (3b) one can do things like mapping a task over a set of values coming out of another task. It is also nice that (4) there is a rather solid set of backing organizations behind WDL and Cromwell. As far as I know, this combination of properties gives WDL a rather unique value proposition. Maybe there is room for a simpler local-only WDL execution engine focused on speed and rapid iteration. That could be used for development and then the execution of production workflows on various cloud backends etc could still be done by Cromwell. I was dabbling one weekend a few months ago with a local-only Python compiler/execution engine for WDL. If optimal execution speed is not a must, it does not look too hard to support most of the WDL spec on a local machine. I'm closing this issue for now. Thank you again for the input!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3477#issuecomment-378866720
https://github.com/broadinstitute/cromwell/issues/3477#issuecomment-378866720:1107,Usability,simpl,simpler,1107,"Hi @geoffjentry - thanks for the prompt and detailed response. It makes sense to submit using curl instead. That might save most of the 2.5 seconds. But since your fast-polling hello world test still took 7 seconds from pickup to completion, I still think this would be frustratingly slow. I'm familiar with Snakemake (and about two dozen other similar tools to be found scattered across the web) but I think WDL is better in a number of ways. The main points that I like are (1) that the workflow language is clearly separated from the execution engine, (2) that the language is much more human-readable than CWL, and (3) the possibility to serialize/deserialize values, e.g., so that (3a) simple operations, e.g., concatenation of different results can be done in the workflow language and (3b) one can do things like mapping a task over a set of values coming out of another task. It is also nice that (4) there is a rather solid set of backing organizations behind WDL and Cromwell. As far as I know, this combination of properties gives WDL a rather unique value proposition. Maybe there is room for a simpler local-only WDL execution engine focused on speed and rapid iteration. That could be used for development and then the execution of production workflows on various cloud backends etc could still be done by Cromwell. I was dabbling one weekend a few months ago with a local-only Python compiler/execution engine for WDL. If optimal execution speed is not a must, it does not look too hard to support most of the WDL spec on a local machine. I'm closing this issue for now. Thank you again for the input!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3477#issuecomment-378866720
https://github.com/broadinstitute/cromwell/issues/3477#issuecomment-379006890:376,Usability,simpl,simple,376,"Hi @rasmuse That's fair, and again I'm not going to try too hard to sway you away from WDL :). I'd be very much in favor of more WDL runner implementations out there if that's a path you wanted to explore. . It's pretty out of date but you might find some inspiration in [PyWDL](https://github.com/broadinstitute/pywdl). If you go back far enough in its history it was even a simple python based WDL runner. If you're interested in Go, there's also [Maple](https://github.com/scottfrazer/maple) from the originator of WDL, although it's certainly out of date w/ the latest WDL features.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3477#issuecomment-379006890
https://github.com/broadinstitute/cromwell/issues/3477#issuecomment-379037212:372,Performance,optimiz,optimized,372,"Hi @rasmuse, I lead the Cromwell Languages team here at the Broad (a small offshoot team from the main Cromwell team). Ultimately, Cromwell will always aim to be a production scale engine, but my team is especially interested in anything that makes reading, writing, testing, experimenting with and debugging workflows easier... If you're serious about trying to make an ""optimized for small local tasks"" implementation of a WDL engine, that definitely sounds like something that could definitely help out our workflow authors too... so do let me know if it goes anywhere and if we can help out at all! Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3477#issuecomment-379037212
https://github.com/broadinstitute/cromwell/issues/3477#issuecomment-379037212:267,Testability,test,testing,267,"Hi @rasmuse, I lead the Cromwell Languages team here at the Broad (a small offshoot team from the main Cromwell team). Ultimately, Cromwell will always aim to be a production scale engine, but my team is especially interested in anything that makes reading, writing, testing, experimenting with and debugging workflows easier... If you're serious about trying to make an ""optimized for small local tasks"" implementation of a WDL engine, that definitely sounds like something that could definitely help out our workflow authors too... so do let me know if it goes anywhere and if we can help out at all! Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3477#issuecomment-379037212
https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-379059328:4532,Performance,Cache,Cache,4532,"n"": ""WaitingForValueStore"",; ""endTime"": ""2018-04-04T03:54:17.588Z""; }; ]; }; ],; ""MarkDuplicates.ClassicMarkDuplicates"": [; {; ""preemptible"": false,; ""executionStatus"": ""Running"",; ""stdout"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-ClassicMarkDuplicates/ClassicMarkDuplicates-stdout.log"",; ""backendStatus"": ""Running"",; ""shardIndex"": -1,; ""jes"": {; ""executionBucket"": ""gs://broad-dsde-methods/cromwell-execution-30"",; ""endpointUrl"": ""https://genomics.googleapis.com/"",; ""googleProject"": ""broad-dsde-methods""; },; ""runtimeAttributes"": {; ""preemptible"": ""0"",; ""failOnStderr"": ""false"",; ""bootDiskSizeGb"": ""10"",; ""disks"": ""local-disk 1 LOCAL"",; ""continueOnReturnCode"": ""0"",; ""docker"": ""us.gcr.io/broad-gatk/gatk:4.0.2.1"",; ""cpu"": ""4"",; ""noAddress"": ""false"",; ""zones"": ""us-central1-a,us-central1-b,us-east1-d,us-central1-c,us-central1-f,us-east1-c"",; ""memory"": ""16 GB""; },; ""callCaching"": {; ""allowResultReuse"": true,; ""effectiveCallCachingMode"": ""ReadAndWriteCache"",; ""hit"": false,; ""result"": ""Cache Miss""; },; ""inputs"": {; ""outputName"": ""md"",; ""bam"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-PreSort/md.sorted.bam"",; ""docker"": ""us.gcr.io/broad-gatk/gatk:4.0.2.1""; },; ""backendLabels"": {; ""cromwell-workflow-id"": ""cromwell-01c7d76f-5b2b-48cd-be08-ce75b923666e"",; ""wdl-task-name"": ""classicmarkduplicates""; },; ""labels"": {; ""wdl-task-name"": ""ClassicMarkDuplicates"",; ""cromwell-workflow-id"": ""cromwell-01c7d76f-5b2b-48cd-be08-ce75b923666e""; },; ""jobId"": ""operations/EI-bgPCoLBiv-9bxttKRjqUBIJ-XkZe9BioPcHJvZHVjdGlvblF1ZXVl"",; ""backend"": ""JES"",; ""stderr"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-ClassicMarkDuplicates/ClassicMarkDuplicates-stderr.log"",; ""callRoot"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-ClassicMarkDuplicates"",; ""attempt"": 1,; ""backendLo",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-379059328
https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-379059328:6841,Performance,Cache,Cache,6841,"cket"": ""gs://broad-dsde-methods/cromwell-execution-30"",; ""zone"": ""us-east1-d"",; ""instanceName"": ""ggp-10276417784841300252""; },; ""outputs"": {; ""outBam"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-PreSort/md.sorted.bam""; },; ""runtimeAttributes"": {; ""preemptible"": ""0"",; ""failOnStderr"": ""false"",; ""bootDiskSizeGb"": ""10"",; ""disks"": ""local-disk 1 LOCAL"",; ""continueOnReturnCode"": ""0"",; ""docker"": ""us.gcr.io/broad-gatk/gatk:4.0.2.1"",; ""cpu"": ""4"",; ""noAddress"": ""false"",; ""zones"": ""us-central1-a,us-central1-b,us-east1-d,us-central1-c,us-central1-f,us-east1-c"",; ""memory"": ""16 GB""; },; ""callCaching"": {; ""allowResultReuse"": true,; ""hit"": false,; ""result"": ""Cache Miss"",; ""hashes"": {; ""output count"": ""C4CA4238A0B923820DCC509A6F75849B"",; ""runtime attribute"": {; ""docker"": ""727DC68A78243A55A510496DBD51C8FD"",; ""continueOnReturnCode"": ""CFCD208495D565EF66E7DFF9F98764DA"",; ""failOnStderr"": ""68934A3E9455FA72420237EB05902327""; },; ""output expression"": {; ""File outBam"": ""51E81723BF4AE3737FA7A05AD3C404E0""; },; ""input count"": ""A87FF679A2F3E71D9181A67B7542122C"",; ""backend name"": ""5BAA79C7C5A573C899A61D342AA00484"",; ""command template"": ""7F303905B5A7C3C5E133EEA5D655F93F"",; ""input"": {; ""String docker"": ""5FFD9AB91DECDD52945847CAED219F0A"",; ""String outputName"": ""A3830295D56B220883B7627EB49D6ECD"",; ""String sortOrder"": ""33D645FB17F6C04818DAB3100252CF39"",; ""File bam"": ""v+At8g==""; }; },; ""effectiveCallCachingMode"": ""ReadAndWriteCache""; },; ""inputs"": {; ""outputName"": ""md.sorted"",; ""bam"": ""gs://broad-public-datasets/NA12878/NA12878.hg38.aligned.unsorted.duplicates_marked.bam"",; ""docker"": ""us.gcr.io/broad-gatk/gatk:4.0.2.1"",; ""sortOrder"": ""queryname""; },; ""backendLabels"": {; ""wdl-task-name"": ""sortsam"",; ""wdl-call-alias"": ""presort"",; ""cromwell-workflow-id"": ""cromwell-01c7d76f-5b2b-48cd-be08-ce75b923666e""; },; ""returnCode"": 0,; ""labels"": {; ""wdl-call-alias"": ""PreSort"",; ""cromwell-workflow-id"": ""cromwell-01c7d76f-5b2b-48cd-be08-ce75b923666e"",; ""wdl-tas",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-379059328
https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-379059328:482,Security,hash,hashes,482,"Here's the metadata; ```; {; ""workflowName"": ""MarkDuplicates"",; ""calls"": {; ""MarkDuplicates.SortSam"": [; {; ""executionStatus"": ""Done"",; ""backendStatus"": ""Success"",; ""shardIndex"": -1,; ""jes"": {; ""instanceName"": ""ggp-8929414080671740740"",; ""machineType"": ""us-east1-d/n1-highmem-4"",; ""zone"": ""us-east1-d""; },; ""outputs"": {; ""outBam"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-SortSam/md.sorted.bam""; },; ""callCaching"": {; ""hashes"": {; ""output count"": ""C4CA4238A0B923820DCC509A6F75849B"",; ""runtime attribute"": {; ""docker"": ""727DC68A78243A55A510496DBD51C8FD"",; ""continueOnReturnCode"": ""CFCD208495D565EF66E7DFF9F98764DA"",; ""failOnStderr"": ""68934A3E9455FA72420237EB05902327""; },; ""output expression"": {; ""File outBam"": ""51E81723BF4AE3737FA7A05AD3C404E0""; },; ""input count"": ""A87FF679A2F3E71D9181A67B7542122C"",; ""backend name"": ""5BAA79C7C5A573C899A61D342AA00484"",; ""command template"": ""7F303905B5A7C3C5E133EEA5D655F93F"",; ""input"": {; ""String docker"": ""5FFD9AB91DECDD52945847CAED219F0A"",; ""String outputName"": ""A3830295D56B220883B7627EB49D6ECD"",; ""String sortOrder"": ""D68E1AF2DA2A70598DD21717D8621A4C"",; ""File bam"": ""WRKp1w==""; }; }; },; ""returnCode"": 0,; ""end"": ""2018-04-04T06:49:15.680Z"",; ""dockerImageUsed"": ""us.gcr.io/broad-gatk/gatk@sha256:fd8e7a9e65e6a981ab3b92305492d54c3baef7a803ec3fcb895e5ebeedf824e7"",; ""attempt"": 1,; ""executionEvents"": [; {; ""startTime"": ""2018-04-04T03:54:17.587Z"",; ""description"": ""Pending"",; ""endTime"": ""2018-04-04T03:54:17.587Z""; },; {; ""startTime"": ""2018-04-04T06:49:04.424457737Z"",; ""description"": ""cromwell poll interval"",; ""endTime"": ""2018-04-04T06:49:12.726Z""; },; {; ""startTime"": ""2018-04-04T06:49:12.726Z"",; ""description"": ""UpdatingCallCache"",; ""endTime"": ""2018-04-04T06:49:14.698Z""; },; {; ""startTime"": ""2018-04-04T03:54:17.588Z"",; ""description"": ""PreparingJob"",; ""endTime"": ""2018-04-04T03:54:17.593Z""; },; {; ""startTime"": ""2018-04-04T06:35:13.639652324Z"",; ""description"": ""delocalizing-files"",; ""endTime"": ""2",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-379059328
https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-379059328:6856,Security,hash,hashes,6856,"cket"": ""gs://broad-dsde-methods/cromwell-execution-30"",; ""zone"": ""us-east1-d"",; ""instanceName"": ""ggp-10276417784841300252""; },; ""outputs"": {; ""outBam"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-PreSort/md.sorted.bam""; },; ""runtimeAttributes"": {; ""preemptible"": ""0"",; ""failOnStderr"": ""false"",; ""bootDiskSizeGb"": ""10"",; ""disks"": ""local-disk 1 LOCAL"",; ""continueOnReturnCode"": ""0"",; ""docker"": ""us.gcr.io/broad-gatk/gatk:4.0.2.1"",; ""cpu"": ""4"",; ""noAddress"": ""false"",; ""zones"": ""us-central1-a,us-central1-b,us-east1-d,us-central1-c,us-central1-f,us-east1-c"",; ""memory"": ""16 GB""; },; ""callCaching"": {; ""allowResultReuse"": true,; ""hit"": false,; ""result"": ""Cache Miss"",; ""hashes"": {; ""output count"": ""C4CA4238A0B923820DCC509A6F75849B"",; ""runtime attribute"": {; ""docker"": ""727DC68A78243A55A510496DBD51C8FD"",; ""continueOnReturnCode"": ""CFCD208495D565EF66E7DFF9F98764DA"",; ""failOnStderr"": ""68934A3E9455FA72420237EB05902327""; },; ""output expression"": {; ""File outBam"": ""51E81723BF4AE3737FA7A05AD3C404E0""; },; ""input count"": ""A87FF679A2F3E71D9181A67B7542122C"",; ""backend name"": ""5BAA79C7C5A573C899A61D342AA00484"",; ""command template"": ""7F303905B5A7C3C5E133EEA5D655F93F"",; ""input"": {; ""String docker"": ""5FFD9AB91DECDD52945847CAED219F0A"",; ""String outputName"": ""A3830295D56B220883B7627EB49D6ECD"",; ""String sortOrder"": ""33D645FB17F6C04818DAB3100252CF39"",; ""File bam"": ""v+At8g==""; }; },; ""effectiveCallCachingMode"": ""ReadAndWriteCache""; },; ""inputs"": {; ""outputName"": ""md.sorted"",; ""bam"": ""gs://broad-public-datasets/NA12878/NA12878.hg38.aligned.unsorted.duplicates_marked.bam"",; ""docker"": ""us.gcr.io/broad-gatk/gatk:4.0.2.1"",; ""sortOrder"": ""queryname""; },; ""backendLabels"": {; ""wdl-task-name"": ""sortsam"",; ""wdl-call-alias"": ""presort"",; ""cromwell-workflow-id"": ""cromwell-01c7d76f-5b2b-48cd-be08-ce75b923666e""; },; ""returnCode"": 0,; ""labels"": {; ""wdl-call-alias"": ""PreSort"",; ""cromwell-workflow-id"": ""cromwell-01c7d76f-5b2b-48cd-be08-ce75b923666e"",; ""wdl-tas",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-379059328
https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-379059328:3826,Testability,log,log,3826,"""; },; {; ""startTime"": ""2018-04-04T06:49:14.698Z"",; ""description"": ""UpdatingJobStore"",; ""endTime"": ""2018-04-04T06:49:15.680Z""; },; {; ""startTime"": ""2018-04-04T03:55:10.042468067Z"",; ""description"": ""start"",; ""endTime"": ""2018-04-04T03:55:14.019652794Z""; },; {; ""startTime"": ""2018-04-04T03:54:17.593Z"",; ""description"": ""CheckingCallCache"",; ""endTime"": ""2018-04-04T03:54:20.370Z""; },; {; ""startTime"": ""2018-04-04T04:20:16.453751287Z"",; ""description"": ""running-docker"",; ""endTime"": ""2018-04-04T06:35:13.639652324Z""; },; {; ""startTime"": ""2018-04-04T03:54:17.587Z"",; ""description"": ""WaitingForValueStore"",; ""endTime"": ""2018-04-04T03:54:17.588Z""; }; ]; }; ],; ""MarkDuplicates.ClassicMarkDuplicates"": [; {; ""preemptible"": false,; ""executionStatus"": ""Running"",; ""stdout"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-ClassicMarkDuplicates/ClassicMarkDuplicates-stdout.log"",; ""backendStatus"": ""Running"",; ""shardIndex"": -1,; ""jes"": {; ""executionBucket"": ""gs://broad-dsde-methods/cromwell-execution-30"",; ""endpointUrl"": ""https://genomics.googleapis.com/"",; ""googleProject"": ""broad-dsde-methods""; },; ""runtimeAttributes"": {; ""preemptible"": ""0"",; ""failOnStderr"": ""false"",; ""bootDiskSizeGb"": ""10"",; ""disks"": ""local-disk 1 LOCAL"",; ""continueOnReturnCode"": ""0"",; ""docker"": ""us.gcr.io/broad-gatk/gatk:4.0.2.1"",; ""cpu"": ""4"",; ""noAddress"": ""false"",; ""zones"": ""us-central1-a,us-central1-b,us-east1-d,us-central1-c,us-central1-f,us-east1-c"",; ""memory"": ""16 GB""; },; ""callCaching"": {; ""allowResultReuse"": true,; ""effectiveCallCachingMode"": ""ReadAndWriteCache"",; ""hit"": false,; ""result"": ""Cache Miss""; },; ""inputs"": {; ""outputName"": ""md"",; ""bam"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-PreSort/md.sorted.bam"",; ""docker"": ""us.gcr.io/broad-gatk/gatk:4.0.2.1""; },; ""backendLabels"": {; ""cromwell-workflow-id"": ""cromwell-01c7d76f-5b2b-48cd-be08-ce75b923666e"",; ""wdl-task-name"": ""classicmarkduplicates""; },; ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-379059328
https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-379059328:5308,Testability,log,log,5308,"gMode"": ""ReadAndWriteCache"",; ""hit"": false,; ""result"": ""Cache Miss""; },; ""inputs"": {; ""outputName"": ""md"",; ""bam"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-PreSort/md.sorted.bam"",; ""docker"": ""us.gcr.io/broad-gatk/gatk:4.0.2.1""; },; ""backendLabels"": {; ""cromwell-workflow-id"": ""cromwell-01c7d76f-5b2b-48cd-be08-ce75b923666e"",; ""wdl-task-name"": ""classicmarkduplicates""; },; ""labels"": {; ""wdl-task-name"": ""ClassicMarkDuplicates"",; ""cromwell-workflow-id"": ""cromwell-01c7d76f-5b2b-48cd-be08-ce75b923666e""; },; ""jobId"": ""operations/EI-bgPCoLBiv-9bxttKRjqUBIJ-XkZe9BioPcHJvZHVjdGlvblF1ZXVl"",; ""backend"": ""JES"",; ""stderr"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-ClassicMarkDuplicates/ClassicMarkDuplicates-stderr.log"",; ""callRoot"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-ClassicMarkDuplicates"",; ""attempt"": 1,; ""backendLogs"": {; ""log"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-ClassicMarkDuplicates/ClassicMarkDuplicates.log""; },; ""start"": ""2018-04-04T00:13:08.587Z""; }; ],; ""MarkDuplicates.PreSort"": [; {; ""preemptible"": false,; ""executionStatus"": ""Done"",; ""stdout"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-PreSort/PreSort-stdout.log"",; ""backendStatus"": ""Success"",; ""shardIndex"": -1,; ""jes"": {; ""endpointUrl"": ""https://genomics.googleapis.com/"",; ""machineType"": ""us-east1-d/n1-highmem-4"",; ""googleProject"": ""broad-dsde-methods"",; ""executionBucket"": ""gs://broad-dsde-methods/cromwell-execution-30"",; ""zone"": ""us-east1-d"",; ""instanceName"": ""ggp-10276417784841300252""; },; ""outputs"": {; ""outBam"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-PreSort/md.sorted.bam""; },; ""runtimeAttributes"": {; ""preemptible"": ""0"",; ""failOnStderr"": """,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-379059328
https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-379059328:5490,Testability,log,log,5490,"gMode"": ""ReadAndWriteCache"",; ""hit"": false,; ""result"": ""Cache Miss""; },; ""inputs"": {; ""outputName"": ""md"",; ""bam"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-PreSort/md.sorted.bam"",; ""docker"": ""us.gcr.io/broad-gatk/gatk:4.0.2.1""; },; ""backendLabels"": {; ""cromwell-workflow-id"": ""cromwell-01c7d76f-5b2b-48cd-be08-ce75b923666e"",; ""wdl-task-name"": ""classicmarkduplicates""; },; ""labels"": {; ""wdl-task-name"": ""ClassicMarkDuplicates"",; ""cromwell-workflow-id"": ""cromwell-01c7d76f-5b2b-48cd-be08-ce75b923666e""; },; ""jobId"": ""operations/EI-bgPCoLBiv-9bxttKRjqUBIJ-XkZe9BioPcHJvZHVjdGlvblF1ZXVl"",; ""backend"": ""JES"",; ""stderr"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-ClassicMarkDuplicates/ClassicMarkDuplicates-stderr.log"",; ""callRoot"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-ClassicMarkDuplicates"",; ""attempt"": 1,; ""backendLogs"": {; ""log"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-ClassicMarkDuplicates/ClassicMarkDuplicates.log""; },; ""start"": ""2018-04-04T00:13:08.587Z""; }; ],; ""MarkDuplicates.PreSort"": [; {; ""preemptible"": false,; ""executionStatus"": ""Done"",; ""stdout"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-PreSort/PreSort-stdout.log"",; ""backendStatus"": ""Success"",; ""shardIndex"": -1,; ""jes"": {; ""endpointUrl"": ""https://genomics.googleapis.com/"",; ""machineType"": ""us-east1-d/n1-highmem-4"",; ""googleProject"": ""broad-dsde-methods"",; ""executionBucket"": ""gs://broad-dsde-methods/cromwell-execution-30"",; ""zone"": ""us-east1-d"",; ""instanceName"": ""ggp-10276417784841300252""; },; ""outputs"": {; ""outBam"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-PreSort/md.sorted.bam""; },; ""runtimeAttributes"": {; ""preemptible"": ""0"",; ""failOnStderr"": """,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-379059328
https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-379059328:5644,Testability,log,log,5644,"b-48cd-be08-ce75b923666e/call-PreSort/md.sorted.bam"",; ""docker"": ""us.gcr.io/broad-gatk/gatk:4.0.2.1""; },; ""backendLabels"": {; ""cromwell-workflow-id"": ""cromwell-01c7d76f-5b2b-48cd-be08-ce75b923666e"",; ""wdl-task-name"": ""classicmarkduplicates""; },; ""labels"": {; ""wdl-task-name"": ""ClassicMarkDuplicates"",; ""cromwell-workflow-id"": ""cromwell-01c7d76f-5b2b-48cd-be08-ce75b923666e""; },; ""jobId"": ""operations/EI-bgPCoLBiv-9bxttKRjqUBIJ-XkZe9BioPcHJvZHVjdGlvblF1ZXVl"",; ""backend"": ""JES"",; ""stderr"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-ClassicMarkDuplicates/ClassicMarkDuplicates-stderr.log"",; ""callRoot"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-ClassicMarkDuplicates"",; ""attempt"": 1,; ""backendLogs"": {; ""log"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-ClassicMarkDuplicates/ClassicMarkDuplicates.log""; },; ""start"": ""2018-04-04T00:13:08.587Z""; }; ],; ""MarkDuplicates.PreSort"": [; {; ""preemptible"": false,; ""executionStatus"": ""Done"",; ""stdout"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-PreSort/PreSort-stdout.log"",; ""backendStatus"": ""Success"",; ""shardIndex"": -1,; ""jes"": {; ""endpointUrl"": ""https://genomics.googleapis.com/"",; ""machineType"": ""us-east1-d/n1-highmem-4"",; ""googleProject"": ""broad-dsde-methods"",; ""executionBucket"": ""gs://broad-dsde-methods/cromwell-execution-30"",; ""zone"": ""us-east1-d"",; ""instanceName"": ""ggp-10276417784841300252""; },; ""outputs"": {; ""outBam"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-PreSort/md.sorted.bam""; },; ""runtimeAttributes"": {; ""preemptible"": ""0"",; ""failOnStderr"": ""false"",; ""bootDiskSizeGb"": ""10"",; ""disks"": ""local-disk 1 LOCAL"",; ""continueOnReturnCode"": ""0"",; ""docker"": ""us.gcr.io/broad-gatk/gatk:4.0.2.1"",; ""cpu"": ""4"",; ""noAddress"": ""false"",; ""zones"":",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-379059328
https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-379059328:5918,Testability,log,log,5918,"cromwell-workflow-id"": ""cromwell-01c7d76f-5b2b-48cd-be08-ce75b923666e""; },; ""jobId"": ""operations/EI-bgPCoLBiv-9bxttKRjqUBIJ-XkZe9BioPcHJvZHVjdGlvblF1ZXVl"",; ""backend"": ""JES"",; ""stderr"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-ClassicMarkDuplicates/ClassicMarkDuplicates-stderr.log"",; ""callRoot"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-ClassicMarkDuplicates"",; ""attempt"": 1,; ""backendLogs"": {; ""log"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-ClassicMarkDuplicates/ClassicMarkDuplicates.log""; },; ""start"": ""2018-04-04T00:13:08.587Z""; }; ],; ""MarkDuplicates.PreSort"": [; {; ""preemptible"": false,; ""executionStatus"": ""Done"",; ""stdout"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-PreSort/PreSort-stdout.log"",; ""backendStatus"": ""Success"",; ""shardIndex"": -1,; ""jes"": {; ""endpointUrl"": ""https://genomics.googleapis.com/"",; ""machineType"": ""us-east1-d/n1-highmem-4"",; ""googleProject"": ""broad-dsde-methods"",; ""executionBucket"": ""gs://broad-dsde-methods/cromwell-execution-30"",; ""zone"": ""us-east1-d"",; ""instanceName"": ""ggp-10276417784841300252""; },; ""outputs"": {; ""outBam"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-PreSort/md.sorted.bam""; },; ""runtimeAttributes"": {; ""preemptible"": ""0"",; ""failOnStderr"": ""false"",; ""bootDiskSizeGb"": ""10"",; ""disks"": ""local-disk 1 LOCAL"",; ""continueOnReturnCode"": ""0"",; ""docker"": ""us.gcr.io/broad-gatk/gatk:4.0.2.1"",; ""cpu"": ""4"",; ""noAddress"": ""false"",; ""zones"": ""us-central1-a,us-central1-b,us-east1-d,us-central1-c,us-central1-f,us-east1-c"",; ""memory"": ""16 GB""; },; ""callCaching"": {; ""allowResultReuse"": true,; ""hit"": false,; ""result"": ""Cache Miss"",; ""hashes"": {; ""output count"": ""C4CA4238A0B923820DCC509A6F75849B"",; ""runtime attribute"": {; ""docker"": ""727DC68A782",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-379059328
https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-379059328:8549,Testability,log,log,8549,",; ""bam"": ""gs://broad-public-datasets/NA12878/NA12878.hg38.aligned.unsorted.duplicates_marked.bam"",; ""docker"": ""us.gcr.io/broad-gatk/gatk:4.0.2.1"",; ""sortOrder"": ""queryname""; },; ""backendLabels"": {; ""wdl-task-name"": ""sortsam"",; ""wdl-call-alias"": ""presort"",; ""cromwell-workflow-id"": ""cromwell-01c7d76f-5b2b-48cd-be08-ce75b923666e""; },; ""returnCode"": 0,; ""labels"": {; ""wdl-call-alias"": ""PreSort"",; ""cromwell-workflow-id"": ""cromwell-01c7d76f-5b2b-48cd-be08-ce75b923666e"",; ""wdl-task-name"": ""SortSam""; },; ""jobId"": ""operations/EKKkveuoLBic0uPn9PDKzo4BIJ-XkZe9BioPcHJvZHVjdGlvblF1ZXVl"",; ""backend"": ""JES"",; ""end"": ""2018-04-04T00:13:06.677Z"",; ""dockerImageUsed"": ""us.gcr.io/broad-gatk/gatk@sha256:fd8e7a9e65e6a981ab3b92305492d54c3baef7a803ec3fcb895e5ebeedf824e7"",; ""stderr"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-PreSort/PreSort-stderr.log"",; ""callRoot"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-PreSort"",; ""attempt"": 1,; ""executionEvents"": [; {; ""startTime"": ""2018-04-04T00:13:04.837Z"",; ""description"": ""UpdatingCallCache"",; ""endTime"": ""2018-04-04T00:13:05.697Z""; },; {; ""startTime"": ""2018-04-03T21:35:02.588Z"",; ""description"": ""PreparingJob"",; ""endTime"": ""2018-04-03T21:35:02.606Z""; },; {; ""startTime"": ""2018-04-03T21:35:02.606Z"",; ""description"": ""CheckingCallCache"",; ""endTime"": ""2018-04-03T21:35:05.337Z""; },; {; ""startTime"": ""2018-04-03T21:52:07.621362223Z"",; ""description"": ""running-docker"",; ""endTime"": ""2018-04-03T23:46:57.248430517Z""; },; {; ""startTime"": ""2018-04-03T23:46:57.248430517Z"",; ""description"": ""delocalizing-files"",; ""endTime"": ""2018-04-04T00:10:30.287776787Z""; },; {; ""startTime"": ""2018-04-03T21:35:05.337Z"",; ""description"": ""RunningJob"",; ""endTime"": ""2018-04-03T21:35:05Z""; },; {; ""startTime"": ""2018-04-04T00:10:30.287776787Z"",; ""description"": ""ok"",; ""endTime"": ""2018-04-04T00:10:30.287776787Z""; },; {; ""startTime"": ""2018-04-03T21:35:47.186424Z"",; ""descri",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-379059328
https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-379059328:10885,Testability,log,log,10885,"018-04-04T00:13:06.677Z""; },; {; ""description"": ""initializing VM"",; ""endTime"": ""2018-04-03T21:35:47.186424Z"",; ""startTime"": ""2018-04-03T21:35:09Z""; },; {; ""startTime"": ""2018-04-03T21:35:02.588Z"",; ""description"": ""Pending"",; ""endTime"": ""2018-04-03T21:35:02.588Z""; },; {; ""startTime"": ""2018-04-03T21:35:48.818896012Z"",; ""description"": ""pulling-image"",; ""endTime"": ""2018-04-03T21:37:50.448425714Z""; },; {; ""startTime"": ""2018-04-03T21:35:02.588Z"",; ""description"": ""WaitingForValueStore"",; ""endTime"": ""2018-04-03T21:35:02.588Z""; },; {; ""startTime"": ""2018-04-03T21:37:50.448425714Z"",; ""description"": ""localizing-files"",; ""endTime"": ""2018-04-03T21:52:07.621362223Z""; },; {; ""startTime"": ""2018-04-03T21:35:02.588Z"",; ""description"": ""RequestingExecutionToken"",; ""endTime"": ""2018-04-03T21:35:02.588Z""; },; {; ""startTime"": ""2018-04-04T00:10:30.287776787Z"",; ""description"": ""cromwell poll interval"",; ""endTime"": ""2018-04-04T00:13:04.837Z""; }; ],; ""backendLogs"": {; ""log"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-PreSort/PreSort.log""; },; ""start"": ""2018-04-03T21:35:02.588Z""; }; ]; },; ""outputs"": {; ""MarkDuplicates.ClassicMarkDuplicates.outputMetrics"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-ClassicMarkDuplicates/md.metrics"",; ""MarkDuplicates.SortSam.outBam"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-SortSam/md.sorted.bam"",; ""MarkDuplicates.ClassicMarkDuplicates.outBam"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-ClassicMarkDuplicates/md.bam"",; ""MarkDuplicates.PreSort.outBam"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-PreSort/md.sorted.bam""; },; ""workflowRoot"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/"",; ""id"": ""01c7d76f-5b2b-48cd-b",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-379059328
https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-379059328:11011,Testability,log,log,11011,"186424Z"",; ""startTime"": ""2018-04-03T21:35:09Z""; },; {; ""startTime"": ""2018-04-03T21:35:02.588Z"",; ""description"": ""Pending"",; ""endTime"": ""2018-04-03T21:35:02.588Z""; },; {; ""startTime"": ""2018-04-03T21:35:48.818896012Z"",; ""description"": ""pulling-image"",; ""endTime"": ""2018-04-03T21:37:50.448425714Z""; },; {; ""startTime"": ""2018-04-03T21:35:02.588Z"",; ""description"": ""WaitingForValueStore"",; ""endTime"": ""2018-04-03T21:35:02.588Z""; },; {; ""startTime"": ""2018-04-03T21:37:50.448425714Z"",; ""description"": ""localizing-files"",; ""endTime"": ""2018-04-03T21:52:07.621362223Z""; },; {; ""startTime"": ""2018-04-03T21:35:02.588Z"",; ""description"": ""RequestingExecutionToken"",; ""endTime"": ""2018-04-03T21:35:02.588Z""; },; {; ""startTime"": ""2018-04-04T00:10:30.287776787Z"",; ""description"": ""cromwell poll interval"",; ""endTime"": ""2018-04-04T00:13:04.837Z""; }; ],; ""backendLogs"": {; ""log"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-PreSort/PreSort.log""; },; ""start"": ""2018-04-03T21:35:02.588Z""; }; ]; },; ""outputs"": {; ""MarkDuplicates.ClassicMarkDuplicates.outputMetrics"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-ClassicMarkDuplicates/md.metrics"",; ""MarkDuplicates.SortSam.outBam"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-SortSam/md.sorted.bam"",; ""MarkDuplicates.ClassicMarkDuplicates.outBam"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-ClassicMarkDuplicates/md.bam"",; ""MarkDuplicates.PreSort.outBam"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-PreSort/md.sorted.bam""; },; ""workflowRoot"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/"",; ""id"": ""01c7d76f-5b2b-48cd-be08-ce75b923666e"",; ""inputs"": {; ""MarkDuplicates.inBam"": ""gs://broad-public-datasets/NA12878/NA1287",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-379059328
https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-390838429:80,Testability,test,test,80,@lbergelson -- is this a reproducible issue? Perhaps we can create a simplified test case for our debugging.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-390838429
https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-390838429:69,Usability,simpl,simplified,69,@lbergelson -- is this a reproducible issue? Perhaps we can create a simplified test case for our debugging.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-390838429
https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-391506371:42,Testability,log,logs,42,Do you happen to have the Cromwell server logs around the time the workflow was running ?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-391506371
https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-398134854:182,Availability,avail,available,182,@Horneth I totally missed your message here. It was on the methods cromwell 30 instance. I'm not sure how to find logs. My guess is that if they're produced by default they're still available somewhere.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-398134854
https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-398134854:31,Integrability,message,message,31,@Horneth I totally missed your message here. It was on the methods cromwell 30 instance. I'm not sure how to find logs. My guess is that if they're produced by default they're still available somewhere.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-398134854
https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-398134854:114,Testability,log,logs,114,@Horneth I totally missed your message here. It was on the methods cromwell 30 instance. I'm not sure how to find logs. My guess is that if they're produced by default they're still available somewhere.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-398134854
https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-444495905:173,Testability,log,logs,173,"Hi, I posted comments on #1489 but this is issue is probably the more relevant one. ; I'm getting this behaviour in Cromwell 36:. - Task finishes in SGE backend; - Cromwell logs show `Status change from Running to Done`; - However the metadata and status REST endpoints still show the workflow as `Running` (many hours after - now ~20hs - possibly indefinitely?); - Restarting Cromwell did not help (workflow still shows as ""running"")",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-444495905
https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-445193936:694,Testability,log,log,694,"Hi, here's some more, hopefully useful info:; I started a workflow yesterday, its last SGE job finished at 16:50, however Cromwell picked it up at 10AM this morning. . Cromwell seems to have worked very hard during the night even though it was not processing any workflows:. ![image](https://user-images.githubusercontent.com/13629974/49642727-c0bd0f00-fa0b-11e8-8f46-c950fc1cc54f.png). Then when it marked the workflow as finished, it stopped:. ![image](https://user-images.githubusercontent.com/13629974/49642653-98351500-fa0b-11e8-8fa9-0089c647294a.png). Cromwell did not process anything during the night except for a small workflow at 9pm, which finished quickly. Since that, there are no log entries until 10am today:; ```; Dec 06 16:51:02 cromwell-orchestrator docker[14229]: [INFO] [12/06/2018 16:51:02.807] [cromwell-system-akka.dispatchers.backend-dispatcher-2902] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor/WorkflowActor-c20aa0f7-88b3-46da-89d8-05b6d3632e1d/WorkflowExecutionActor-c20aa0f7-88b3-46da-89d8-05b6d3632e1d/c20aa0f7-88b3-46da-89d8-05b6d3632e1d-SubWorkflowExecutionActor-SubWorkflow-XXX:-1:1/eaf7979f-bca0-4c53-bed9-a9e90d585565-SubWorkflowActor-SubWorkflow-XXX:-1:1/eaf7979f-bca0-4c53-bed9-a9e90d585565-EngineJobExecutionActor-XXX.YYY:NA:1/eaf7979f-bca0-4c53-bed9-a9e90d585565-BackendJobExecutionActor-XXX.YYY:NA:1/DispatchedConfigAsyncJobExecutionActor] DispatchedConfigAsyncJobExecutionActor [UUID(eaf7979f)XXX.YYY:NA:1]: Status change from Running to Done; ...; Dec 06 21:47:12 cromwell-orchestrator [INFO] [12/06/2018 21:47:12.543] [cromwell-system-akka.dispatchers.engine-dispatcher-36] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor] WorkflowManagerActor WorkflowActor-404f9e8a-702c-4779-9a92-532c8abcfa4a is in a terminal state: WorkflowSucceededState; Dec 07 10:02:28 cromwell-orchestrator [INFO] [12/07/2018 10:02:28.694] [cromwell-system-akka.dispatchers.engine-dispatcher-33] [akka://cromwell-system/user/cromwell-service/Wo",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-445193936
https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-445245400:222,Availability,error,errors,222,"@ernoc So this sounds like there's a disconnect between the status changing in memory and getting updated in the db (as the REST endpoints report status from the db). . 1. Do you see anything in your logs that indicate db errors?; 2. What does your db config look like? ; 3. When you report the REST endpoint shows the workflow as 'Running', what about the `executionStatus` key in the metadata? Are some jobs marked as 'Running' as well?; 4. Do you see this behavior only with large scatters (10K) or do you see it with smaller scatters as well? Or any other type of workflow shape?. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-445245400
https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-445245400:98,Deployability,update,updated,98,"@ernoc So this sounds like there's a disconnect between the status changing in memory and getting updated in the db (as the REST endpoints report status from the db). . 1. Do you see anything in your logs that indicate db errors?; 2. What does your db config look like? ; 3. When you report the REST endpoint shows the workflow as 'Running', what about the `executionStatus` key in the metadata? Are some jobs marked as 'Running' as well?; 4. Do you see this behavior only with large scatters (10K) or do you see it with smaller scatters as well? Or any other type of workflow shape?. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-445245400
https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-445245400:252,Modifiability,config,config,252,"@ernoc So this sounds like there's a disconnect between the status changing in memory and getting updated in the db (as the REST endpoints report status from the db). . 1. Do you see anything in your logs that indicate db errors?; 2. What does your db config look like? ; 3. When you report the REST endpoint shows the workflow as 'Running', what about the `executionStatus` key in the metadata? Are some jobs marked as 'Running' as well?; 4. Do you see this behavior only with large scatters (10K) or do you see it with smaller scatters as well? Or any other type of workflow shape?. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-445245400
https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-445245400:200,Testability,log,logs,200,"@ernoc So this sounds like there's a disconnect between the status changing in memory and getting updated in the db (as the REST endpoints report status from the db). . 1. Do you see anything in your logs that indicate db errors?; 2. What does your db config look like? ; 3. When you report the REST endpoint shows the workflow as 'Running', what about the `executionStatus` key in the metadata? Are some jobs marked as 'Running' as well?; 4. Do you see this behavior only with large scatters (10K) or do you see it with smaller scatters as well? Or any other type of workflow shape?. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-445245400
https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-445788979:67,Availability,error,errors,67,"Hi @ruchim !. 1. Do you see anything in your logs that indicate db errors?. No. I see that the SGE job completed (`Status change from Running to Done`). 2. What does your db config look like?; ```; database {; db.url = ""jdbc:mysql://.../${CROMWELL_DB}?useSSL=false&rewriteBatchedStatements=true""; db.user = ...; db.password = ...; db.driver = ""com.mysql.jdbc.Driver""; profile = ""slick.jdbc.MySQLProfile$""; }; ```; backed by a MariaDB instance. 3. When you report the REST endpoint shows the workflow as 'Running', what about the executionStatus key in the metadata? Are some jobs marked as 'Running' as well?. The SGE job reported as running as well. I manually query the database, and I see no changes in the `JOB_STORE_ENTRY` table when the SGE job completes and the corresponding entry appears in the Cromwell logs (although not entirely sure I should see something). 4. Do you see this behavior only with large scatters (10K) or do you see it with smaller scatters as well? Or any other type of workflow shape?. I've only observed this behaviour with large scatters AND a file-of-file-names approach. I don't know exactly what combination of WDL features or what threshold of scatter width triggers it .",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-445788979
https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-445788979:174,Modifiability,config,config,174,"Hi @ruchim !. 1. Do you see anything in your logs that indicate db errors?. No. I see that the SGE job completed (`Status change from Running to Done`). 2. What does your db config look like?; ```; database {; db.url = ""jdbc:mysql://.../${CROMWELL_DB}?useSSL=false&rewriteBatchedStatements=true""; db.user = ...; db.password = ...; db.driver = ""com.mysql.jdbc.Driver""; profile = ""slick.jdbc.MySQLProfile$""; }; ```; backed by a MariaDB instance. 3. When you report the REST endpoint shows the workflow as 'Running', what about the executionStatus key in the metadata? Are some jobs marked as 'Running' as well?. The SGE job reported as running as well. I manually query the database, and I see no changes in the `JOB_STORE_ENTRY` table when the SGE job completes and the corresponding entry appears in the Cromwell logs (although not entirely sure I should see something). 4. Do you see this behavior only with large scatters (10K) or do you see it with smaller scatters as well? Or any other type of workflow shape?. I've only observed this behaviour with large scatters AND a file-of-file-names approach. I don't know exactly what combination of WDL features or what threshold of scatter width triggers it .",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-445788979
https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-445788979:265,Modifiability,rewrite,rewriteBatchedStatements,265,"Hi @ruchim !. 1. Do you see anything in your logs that indicate db errors?. No. I see that the SGE job completed (`Status change from Running to Done`). 2. What does your db config look like?; ```; database {; db.url = ""jdbc:mysql://.../${CROMWELL_DB}?useSSL=false&rewriteBatchedStatements=true""; db.user = ...; db.password = ...; db.driver = ""com.mysql.jdbc.Driver""; profile = ""slick.jdbc.MySQLProfile$""; }; ```; backed by a MariaDB instance. 3. When you report the REST endpoint shows the workflow as 'Running', what about the executionStatus key in the metadata? Are some jobs marked as 'Running' as well?. The SGE job reported as running as well. I manually query the database, and I see no changes in the `JOB_STORE_ENTRY` table when the SGE job completes and the corresponding entry appears in the Cromwell logs (although not entirely sure I should see something). 4. Do you see this behavior only with large scatters (10K) or do you see it with smaller scatters as well? Or any other type of workflow shape?. I've only observed this behaviour with large scatters AND a file-of-file-names approach. I don't know exactly what combination of WDL features or what threshold of scatter width triggers it .",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-445788979
https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-445788979:315,Security,password,password,315,"Hi @ruchim !. 1. Do you see anything in your logs that indicate db errors?. No. I see that the SGE job completed (`Status change from Running to Done`). 2. What does your db config look like?; ```; database {; db.url = ""jdbc:mysql://.../${CROMWELL_DB}?useSSL=false&rewriteBatchedStatements=true""; db.user = ...; db.password = ...; db.driver = ""com.mysql.jdbc.Driver""; profile = ""slick.jdbc.MySQLProfile$""; }; ```; backed by a MariaDB instance. 3. When you report the REST endpoint shows the workflow as 'Running', what about the executionStatus key in the metadata? Are some jobs marked as 'Running' as well?. The SGE job reported as running as well. I manually query the database, and I see no changes in the `JOB_STORE_ENTRY` table when the SGE job completes and the corresponding entry appears in the Cromwell logs (although not entirely sure I should see something). 4. Do you see this behavior only with large scatters (10K) or do you see it with smaller scatters as well? Or any other type of workflow shape?. I've only observed this behaviour with large scatters AND a file-of-file-names approach. I don't know exactly what combination of WDL features or what threshold of scatter width triggers it .",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-445788979
https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-445788979:45,Testability,log,logs,45,"Hi @ruchim !. 1. Do you see anything in your logs that indicate db errors?. No. I see that the SGE job completed (`Status change from Running to Done`). 2. What does your db config look like?; ```; database {; db.url = ""jdbc:mysql://.../${CROMWELL_DB}?useSSL=false&rewriteBatchedStatements=true""; db.user = ...; db.password = ...; db.driver = ""com.mysql.jdbc.Driver""; profile = ""slick.jdbc.MySQLProfile$""; }; ```; backed by a MariaDB instance. 3. When you report the REST endpoint shows the workflow as 'Running', what about the executionStatus key in the metadata? Are some jobs marked as 'Running' as well?. The SGE job reported as running as well. I manually query the database, and I see no changes in the `JOB_STORE_ENTRY` table when the SGE job completes and the corresponding entry appears in the Cromwell logs (although not entirely sure I should see something). 4. Do you see this behavior only with large scatters (10K) or do you see it with smaller scatters as well? Or any other type of workflow shape?. I've only observed this behaviour with large scatters AND a file-of-file-names approach. I don't know exactly what combination of WDL features or what threshold of scatter width triggers it .",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-445788979
https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-445788979:813,Testability,log,logs,813,"Hi @ruchim !. 1. Do you see anything in your logs that indicate db errors?. No. I see that the SGE job completed (`Status change from Running to Done`). 2. What does your db config look like?; ```; database {; db.url = ""jdbc:mysql://.../${CROMWELL_DB}?useSSL=false&rewriteBatchedStatements=true""; db.user = ...; db.password = ...; db.driver = ""com.mysql.jdbc.Driver""; profile = ""slick.jdbc.MySQLProfile$""; }; ```; backed by a MariaDB instance. 3. When you report the REST endpoint shows the workflow as 'Running', what about the executionStatus key in the metadata? Are some jobs marked as 'Running' as well?. The SGE job reported as running as well. I manually query the database, and I see no changes in the `JOB_STORE_ENTRY` table when the SGE job completes and the corresponding entry appears in the Cromwell logs (although not entirely sure I should see something). 4. Do you see this behavior only with large scatters (10K) or do you see it with smaller scatters as well? Or any other type of workflow shape?. I've only observed this behaviour with large scatters AND a file-of-file-names approach. I don't know exactly what combination of WDL features or what threshold of scatter width triggers it .",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-445788979
https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-447295280:104,Testability,log,logs,104,"@ruchim I was trying to follow the code path and it does seem that I see the effect of line 1012 in the logs:; https://github.com/broadinstitute/cromwell/blob/develop/backend/src/main/scala/cromwell/backend/standard/StandardAsyncExecutionActor.scala#L1012. but can't see the effect of line 1013 in the metadata, until many hours later ... maybe some contention handling / regulating code? I don't yet understand how MetadataBuilderRegulatorActor works but could this be involved?. ```; jobLogger.info(s""Status change from $prevStatusName to $state""); tellMetadata(Map(CallMetadataKeys.BackendStatus -> state)); ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-447295280
https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-453647237:117,Testability,test,tests,117,"This issue should be addressed by an issue we found with the metadata summarizer. It should be fixed, we are running tests to confirm",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-453647237
https://github.com/broadinstitute/cromwell/issues/3484#issuecomment-589577125:47,Deployability,pipeline,pipeline,47,"We have ran into this with nearly every single pipeline run. It has become quite irritating. Mainly because a side-effect is that due to the incorrect CSS `height` the bottom of the time diagram might be hiding with an hidden scrollbar. <img width=""1128"" alt=""Screenshot 2020-02-21 at 10 29 59"" src=""https://user-images.githubusercontent.com/7871310/75022381-48b6f980-5496-11ea-84df-014dcedae9fd.png"">. I concur with @cjllanwarne that this is because of a timing overlap (two events, same start time). For instance, here the `Pending` and `RequestingExecutionToken` startTime overlap for the `GermlineSingleSample.Picard` call at `2020-02-17T13:54:23.127Z`:. ```; ""executionEvents"": [; {; ""startTime"": ""2020-02-17T13:54:23.127Z"",; ""description"": ""Pending"",; ""endTime"": ""2020-02-17T13:54:23.127Z""; },; {; ""startTime"": ""2020-02-17T13:54:23.351Z"",; ""description"": ""RunningJob"",; ""endTime"": ""2020-02-17T13:54:54.304Z""; },; {; ""startTime"": ""2020-02-17T13:54:23.323Z"",; ""description"": ""PreparingJob"",; ""endTime"": ""2020-02-17T13:54:23.349Z""; },; {; ""startTime"": ""2020-02-17T13:54:23.349Z"",; ""description"": ""CallCacheReading"",; ""endTime"": ""2020-02-17T13:54:23.351Z""; },; {; ""startTime"": ""2020-02-17T13:54:23.323Z"",; ""description"": ""WaitingForValueStore"",; ""endTime"": ""2020-02-17T13:54:23.323Z""; },; {; ""startTime"": ""2020-02-17T13:54:54.304Z"",; ""description"": ""UpdatingJobStore"",; ""endTime"": ""2020-02-17T13:54:55.253Z""; },; {; ""startTime"": ""2020-02-17T13:54:23.127Z"",; ""description"": ""RequestingExecutionToken"",; ""endTime"": ""2020-02-17T13:54:23.323Z""; }; ],; ""start"": ""2020-02-17T13:54:23.127Z""; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3484#issuecomment-589577125
https://github.com/broadinstitute/cromwell/issues/3487#issuecomment-379127391:137,Security,validat,validation,137,"For the person (even if it's me) who picks this up -> I did a quick poke around and I **think** the reason for this is that our original validation in `PartialWorkflowSources` appears to be getting run through a YAML parser and tabs aren't valid YAML, but are ok in JSON.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3487#issuecomment-379127391
https://github.com/broadinstitute/cromwell/issues/3487#issuecomment-379232557:104,Security,validat,validation,104,Another few thoughts to the person who picks this up -> this bug likely also exists on whatever initial validation is being done for CWL files as they can also be json but presumably are being run through a yaml parser,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3487#issuecomment-379232557
https://github.com/broadinstitute/cromwell/issues/3487#issuecomment-379600556:353,Deployability,configurat,configuration,353,"YAML claims to be a superset of JSON, but it is not (as this proves). Every time I have encountered YAML in a project it has been a headache, just my 2c. It is a strange syntax, with the potential for infinite recursion and bombs. It makes for a hard parser implementation, and there have been security and perfomance issues in the past. Fine for local configuration files, but probably not a good idea for any public facing APIs.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3487#issuecomment-379600556
https://github.com/broadinstitute/cromwell/issues/3487#issuecomment-379600556:353,Modifiability,config,configuration,353,"YAML claims to be a superset of JSON, but it is not (as this proves). Every time I have encountered YAML in a project it has been a headache, just my 2c. It is a strange syntax, with the potential for infinite recursion and bombs. It makes for a hard parser implementation, and there have been security and perfomance issues in the past. Fine for local configuration files, but probably not a good idea for any public facing APIs.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3487#issuecomment-379600556
https://github.com/broadinstitute/cromwell/issues/3487#issuecomment-379600556:294,Security,secur,security,294,"YAML claims to be a superset of JSON, but it is not (as this proves). Every time I have encountered YAML in a project it has been a headache, just my 2c. It is a strange syntax, with the potential for infinite recursion and bombs. It makes for a hard parser implementation, and there have been security and perfomance issues in the past. Fine for local configuration files, but probably not a good idea for any public facing APIs.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3487#issuecomment-379600556
https://github.com/broadinstitute/cromwell/pull/3489#issuecomment-379263786:29,Integrability,depend,dependency,29,"I like this:; * it makes our dependency on bash explicit; * users can always turn it back if it doesn't work for them. I'm curous whether the `qsub` lets you specify what shell to use as a separate parameter rather than having to revert to full ""binary command submission"" mode?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3489#issuecomment-379263786
https://github.com/broadinstitute/cromwell/pull/3490#issuecomment-379274281:393,Availability,error,error,393,"I'm not sure the exact scenario people would want to use this in, but it seems to replace the previous behavior ""retry a few times for known flakinesses, otherwise fail"" - with a less tuned ""retry a custom number of times for all codes"". * Is there any possibility that users would want to continue retrying on known flakinesses (hint: I really think they do) but not blindly restart on other error codes (which could be expensive for typos!)?; ---; One other thought:; * This seems to only catch JES telling us the task has failed. If the task on JES ""succeeds"" but Cromwell later finds out that it cannot download or evaluate a result, does this still retry?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3490#issuecomment-379274281
https://github.com/broadinstitute/cromwell/pull/3490#issuecomment-379274281:607,Availability,down,download,607,"I'm not sure the exact scenario people would want to use this in, but it seems to replace the previous behavior ""retry a few times for known flakinesses, otherwise fail"" - with a less tuned ""retry a custom number of times for all codes"". * Is there any possibility that users would want to continue retrying on known flakinesses (hint: I really think they do) but not blindly restart on other error codes (which could be expensive for typos!)?; ---; One other thought:; * This seems to only catch JES telling us the task has failed. If the task on JES ""succeeds"" but Cromwell later finds out that it cannot download or evaluate a result, does this still retry?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3490#issuecomment-379274281
https://github.com/broadinstitute/cromwell/pull/3490#issuecomment-379274281:184,Performance,tune,tuned,184,"I'm not sure the exact scenario people would want to use this in, but it seems to replace the previous behavior ""retry a few times for known flakinesses, otherwise fail"" - with a less tuned ""retry a custom number of times for all codes"". * Is there any possibility that users would want to continue retrying on known flakinesses (hint: I really think they do) but not blindly restart on other error codes (which could be expensive for typos!)?; ---; One other thought:; * This seems to only catch JES telling us the task has failed. If the task on JES ""succeeds"" but Cromwell later finds out that it cannot download or evaluate a result, does this still retry?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3490#issuecomment-379274281
https://github.com/broadinstitute/cromwell/pull/3490#issuecomment-379276342:197,Modifiability,enhance,enhancement,197,"Deleted a few comments as I misread what @cola Warner said. Sorry I‚Äôm leaving that autocorrect typo as it‚Äôs awesome. We should discuss what this does and does not do. I viewed the request to be an enhancement on current behavior, so should ensure that‚Äôs the case",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3490#issuecomment-379276342
https://github.com/broadinstitute/cromwell/pull/3490#issuecomment-379372182:337,Integrability,rout,route,337,"@cjllanwarne @ruchim I've been going back and forth as to whether or not this retry count should replace or add on to the ""we know that's flakey so retried it for ya"" situation vs. adding on top of it. Chris, you seemed pretty sure it should be the latter, why do you view it that way? Ruchi, I know this was spec'd out to go the former route, but I think the person speccing it out didn't know that we already did some stuff - do you actually have an opinion here or is this just how you did it?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3490#issuecomment-379372182
https://github.com/broadinstitute/cromwell/issues/3500#issuecomment-380213827:32,Deployability,release,release,32,Are you running the cromwell 31 release jar or did you build Cromwell from the sources ?; We changed something related to permissions in the develop branch ~1 week ago but it's not in the released 31 jar so I want to (maybe) rule that out.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3500#issuecomment-380213827
https://github.com/broadinstitute/cromwell/issues/3500#issuecomment-380213827:188,Deployability,release,released,188,Are you running the cromwell 31 release jar or did you build Cromwell from the sources ?; We changed something related to permissions in the develop branch ~1 week ago but it's not in the released 31 jar so I want to (maybe) rule that out.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3500#issuecomment-380213827
https://github.com/broadinstitute/cromwell/issues/3501#issuecomment-397130609:59,Integrability,message,message,59,"I also cannot seem to make the correct zip format. I get a message like this:; ```; ""causedBy"": [; {; ""causedBy"": [],; ""message"": ""/tmp/2995465807561959992.zip5068472134395796754/imports/zipped.wdl""; }; ],; ""message"": ""Workflow input processing failed""; ```. @ruchim have you worked out how to make the zip correctly?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3501#issuecomment-397130609
https://github.com/broadinstitute/cromwell/issues/3501#issuecomment-397130609:120,Integrability,message,message,120,"I also cannot seem to make the correct zip format. I get a message like this:; ```; ""causedBy"": [; {; ""causedBy"": [],; ""message"": ""/tmp/2995465807561959992.zip5068472134395796754/imports/zipped.wdl""; }; ],; ""message"": ""Workflow input processing failed""; ```. @ruchim have you worked out how to make the zip correctly?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3501#issuecomment-397130609
https://github.com/broadinstitute/cromwell/issues/3501#issuecomment-397130609:208,Integrability,message,message,208,"I also cannot seem to make the correct zip format. I get a message like this:; ```; ""causedBy"": [; {; ""causedBy"": [],; ""message"": ""/tmp/2995465807561959992.zip5068472134395796754/imports/zipped.wdl""; }; ],; ""message"": ""Workflow input processing failed""; ```. @ruchim have you worked out how to make the zip correctly?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3501#issuecomment-397130609
https://github.com/broadinstitute/cromwell/issues/3503#issuecomment-380300215:73,Availability,failure,failure,73,@geoffjentry Thanks for the quick response. Goal here is to enable rapid failure detection. I'm very open to different approaches to this!,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3503#issuecomment-380300215
https://github.com/broadinstitute/cromwell/issues/3503#issuecomment-380300215:81,Safety,detect,detection,81,@geoffjentry Thanks for the quick response. Goal here is to enable rapid failure detection. I'm very open to different approaches to this!,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3503#issuecomment-380300215
https://github.com/broadinstitute/cromwell/issues/3503#issuecomment-382870074:114,Modifiability,plugin,plugin,114,"I think there was something about this being discussed by @cjllanwarne regarding input checking in the winstanley plugin, maybe?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3503#issuecomment-382870074
https://github.com/broadinstitute/cromwell/issues/3503#issuecomment-386009040:68,Deployability,release,released,68,"@kbergin `womtool validate` now (technically, next time Cromwell is released) has an optional flag to supply an `inputs.json` to validate against - is that what you meant?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3503#issuecomment-386009040
https://github.com/broadinstitute/cromwell/issues/3503#issuecomment-386009040:18,Security,validat,validate,18,"@kbergin `womtool validate` now (technically, next time Cromwell is released) has an optional flag to supply an `inputs.json` to validate against - is that what you meant?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3503#issuecomment-386009040
https://github.com/broadinstitute/cromwell/issues/3503#issuecomment-386009040:129,Security,validat,validate,129,"@kbergin `womtool validate` now (technically, next time Cromwell is released) has an optional flag to supply an `inputs.json` to validate against - is that what you meant?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3503#issuecomment-386009040
https://github.com/broadinstitute/cromwell/issues/3503#issuecomment-386025133:77,Security,validat,validation,77,"That's definitely a key aspect of the ask here, yea! We'd also love for some validation of the docker containers (and anything else that you can think to move into validate).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3503#issuecomment-386025133
https://github.com/broadinstitute/cromwell/issues/3503#issuecomment-386025133:164,Security,validat,validate,164,"That's definitely a key aspect of the ask here, yea! We'd also love for some validation of the docker containers (and anything else that you can think to move into validate).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3503#issuecomment-386025133
https://github.com/broadinstitute/cromwell/pull/3504#issuecomment-380422757:86,Availability,failure,failures,86,I have also sneakily added another commit that seems to fix persistent near-immediate failures to build Centaur TES.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3504#issuecomment-380422757
https://github.com/broadinstitute/cromwell/pull/3505#issuecomment-382572389:23,Security,audit,audit,23,Here's the pullapprove audit: https://pullapprove.com/broadinstitute/cromwell/pull-request/3505/reviews/,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3505#issuecomment-382572389
https://github.com/broadinstitute/cromwell/issues/3508#issuecomment-380942774:24,Performance,load,load,24,"I added an alert if the load stays ""high"" for at least 20 minutes (meaning jobs are not started) it should send a notification to the `cromwell-load-alerts` slack channel.; If it works and we want we can move them to the on call channel.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3508#issuecomment-380942774
https://github.com/broadinstitute/cromwell/issues/3508#issuecomment-380942774:144,Performance,load,load-alerts,144,"I added an alert if the load stays ""high"" for at least 20 minutes (meaning jobs are not started) it should send a notification to the `cromwell-load-alerts` slack channel.; If it works and we want we can move them to the on call channel.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3508#issuecomment-380942774
https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381408850:382,Deployability,release,releases,382,"Confirmed that AWS SDK has a dependency on netty version 4.1.22.Final from [line 93 of AWS SDK pom.xml](https://github.com/aws/aws-sdk-java-v2/blob/2.0.0-preview-9/pom.xml#L93). `<netty.version>4.1.22.Final</netty.version>`; ; This is likely coming from very old version of Scala HTTP client `val sttpV = ""0.0.16""` current version is `v.1.1.12` https://github.com/softwaremill/sttp/releases",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381408850
https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381408850:29,Integrability,depend,dependency,29,"Confirmed that AWS SDK has a dependency on netty version 4.1.22.Final from [line 93 of AWS SDK pom.xml](https://github.com/aws/aws-sdk-java-v2/blob/2.0.0-preview-9/pom.xml#L93). `<netty.version>4.1.22.Final</netty.version>`; ; This is likely coming from very old version of Scala HTTP client `val sttpV = ""0.0.16""` current version is `v.1.1.12` https://github.com/softwaremill/sttp/releases",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381408850
https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626:175,Availability,error,errors,175,"I've gone through and updated the dependency graph of updating sttp, you can view diff at https://github.com/delagoya/cromwell/tree/update-depversions . Still one more set of errors to fix: ; ```; root(update-depversions)> | 31>; [info] Compiling 4 Scala sources to $HOME/src/cromwell/womtool/target/scala-2.12/classes...; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:46: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val thisLevelNodesAndLinks: NodesAndLinks = callsAndDeclarations foldMap { graphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:56: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val subGraphNodesAndLinks: NodesAndLinks = subGraphs foldMap { wdlGraphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:26: private val clusterCount in object GraphPrint is never used; [error] private val clusterCount: AtomicInteger = new AtomicInteger(0); [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:40: local default argument in method listAllGraphNodes is never used; [error] def upstreamLinks(wdlGraphNode: WdlGraphNode, graphNodeName: String, suffix: String = """"): Set[String] = wdlGraphNode.upstream collect {; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:54: value foldMap is not a member of Set[wom.graph.GraphNode]; [error] graph.nodes foldMap nodesAndLinks _; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:89: private method nodesAndLinks in class WomGraph is never used; [error] private def nodesAndLinks(graphNode: GraphNode): NodesAndLinks = {; [error] ^; [error] 6 errors found; [error] (womtool/compile:compileIncremental) Compilation failed; [error] Total time: 4 s, completed Apr 16, 2018 9:00:54 AM; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626
https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626:324,Availability,error,error,324,"I've gone through and updated the dependency graph of updating sttp, you can view diff at https://github.com/delagoya/cromwell/tree/update-depversions . Still one more set of errors to fix: ; ```; root(update-depversions)> | 31>; [info] Compiling 4 Scala sources to $HOME/src/cromwell/womtool/target/scala-2.12/classes...; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:46: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val thisLevelNodesAndLinks: NodesAndLinks = callsAndDeclarations foldMap { graphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:56: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val subGraphNodesAndLinks: NodesAndLinks = subGraphs foldMap { wdlGraphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:26: private val clusterCount in object GraphPrint is never used; [error] private val clusterCount: AtomicInteger = new AtomicInteger(0); [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:40: local default argument in method listAllGraphNodes is never used; [error] def upstreamLinks(wdlGraphNode: WdlGraphNode, graphNodeName: String, suffix: String = """"): Set[String] = wdlGraphNode.upstream collect {; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:54: value foldMap is not a member of Set[wom.graph.GraphNode]; [error] graph.nodes foldMap nodesAndLinks _; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:89: private method nodesAndLinks in class WomGraph is never used; [error] private def nodesAndLinks(graphNode: GraphNode): NodesAndLinks = {; [error] ^; [error] 6 errors found; [error] (womtool/compile:compileIncremental) Compilation failed; [error] Total time: 4 s, completed Apr 16, 2018 9:00:54 AM; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626
https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626:478,Availability,error,error,478,"I've gone through and updated the dependency graph of updating sttp, you can view diff at https://github.com/delagoya/cromwell/tree/update-depversions . Still one more set of errors to fix: ; ```; root(update-depversions)> | 31>; [info] Compiling 4 Scala sources to $HOME/src/cromwell/womtool/target/scala-2.12/classes...; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:46: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val thisLevelNodesAndLinks: NodesAndLinks = callsAndDeclarations foldMap { graphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:56: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val subGraphNodesAndLinks: NodesAndLinks = subGraphs foldMap { wdlGraphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:26: private val clusterCount in object GraphPrint is never used; [error] private val clusterCount: AtomicInteger = new AtomicInteger(0); [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:40: local default argument in method listAllGraphNodes is never used; [error] def upstreamLinks(wdlGraphNode: WdlGraphNode, graphNodeName: String, suffix: String = """"): Set[String] = wdlGraphNode.upstream collect {; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:54: value foldMap is not a member of Set[wom.graph.GraphNode]; [error] graph.nodes foldMap nodesAndLinks _; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:89: private method nodesAndLinks in class WomGraph is never used; [error] private def nodesAndLinks(graphNode: GraphNode): NodesAndLinks = {; [error] ^; [error] 6 errors found; [error] (womtool/compile:compileIncremental) Compilation failed; [error] Total time: 4 s, completed Apr 16, 2018 9:00:54 AM; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626
https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626:575,Availability,error,error,575,"I've gone through and updated the dependency graph of updating sttp, you can view diff at https://github.com/delagoya/cromwell/tree/update-depversions . Still one more set of errors to fix: ; ```; root(update-depversions)> | 31>; [info] Compiling 4 Scala sources to $HOME/src/cromwell/womtool/target/scala-2.12/classes...; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:46: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val thisLevelNodesAndLinks: NodesAndLinks = callsAndDeclarations foldMap { graphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:56: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val subGraphNodesAndLinks: NodesAndLinks = subGraphs foldMap { wdlGraphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:26: private val clusterCount in object GraphPrint is never used; [error] private val clusterCount: AtomicInteger = new AtomicInteger(0); [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:40: local default argument in method listAllGraphNodes is never used; [error] def upstreamLinks(wdlGraphNode: WdlGraphNode, graphNodeName: String, suffix: String = """"): Set[String] = wdlGraphNode.upstream collect {; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:54: value foldMap is not a member of Set[wom.graph.GraphNode]; [error] graph.nodes foldMap nodesAndLinks _; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:89: private method nodesAndLinks in class WomGraph is never used; [error] private def nodesAndLinks(graphNode: GraphNode): NodesAndLinks = {; [error] ^; [error] 6 errors found; [error] (womtool/compile:compileIncremental) Compilation failed; [error] Total time: 4 s, completed Apr 16, 2018 9:00:54 AM; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626
https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626:586,Availability,error,error,586,"I've gone through and updated the dependency graph of updating sttp, you can view diff at https://github.com/delagoya/cromwell/tree/update-depversions . Still one more set of errors to fix: ; ```; root(update-depversions)> | 31>; [info] Compiling 4 Scala sources to $HOME/src/cromwell/womtool/target/scala-2.12/classes...; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:46: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val thisLevelNodesAndLinks: NodesAndLinks = callsAndDeclarations foldMap { graphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:56: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val subGraphNodesAndLinks: NodesAndLinks = subGraphs foldMap { wdlGraphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:26: private val clusterCount in object GraphPrint is never used; [error] private val clusterCount: AtomicInteger = new AtomicInteger(0); [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:40: local default argument in method listAllGraphNodes is never used; [error] def upstreamLinks(wdlGraphNode: WdlGraphNode, graphNodeName: String, suffix: String = """"): Set[String] = wdlGraphNode.upstream collect {; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:54: value foldMap is not a member of Set[wom.graph.GraphNode]; [error] graph.nodes foldMap nodesAndLinks _; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:89: private method nodesAndLinks in class WomGraph is never used; [error] private def nodesAndLinks(graphNode: GraphNode): NodesAndLinks = {; [error] ^; [error] 6 errors found; [error] (womtool/compile:compileIncremental) Compilation failed; [error] Total time: 4 s, completed Apr 16, 2018 9:00:54 AM; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626
https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626:740,Availability,error,error,740,"I've gone through and updated the dependency graph of updating sttp, you can view diff at https://github.com/delagoya/cromwell/tree/update-depversions . Still one more set of errors to fix: ; ```; root(update-depversions)> | 31>; [info] Compiling 4 Scala sources to $HOME/src/cromwell/womtool/target/scala-2.12/classes...; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:46: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val thisLevelNodesAndLinks: NodesAndLinks = callsAndDeclarations foldMap { graphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:56: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val subGraphNodesAndLinks: NodesAndLinks = subGraphs foldMap { wdlGraphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:26: private val clusterCount in object GraphPrint is never used; [error] private val clusterCount: AtomicInteger = new AtomicInteger(0); [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:40: local default argument in method listAllGraphNodes is never used; [error] def upstreamLinks(wdlGraphNode: WdlGraphNode, graphNodeName: String, suffix: String = """"): Set[String] = wdlGraphNode.upstream collect {; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:54: value foldMap is not a member of Set[wom.graph.GraphNode]; [error] graph.nodes foldMap nodesAndLinks _; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:89: private method nodesAndLinks in class WomGraph is never used; [error] private def nodesAndLinks(graphNode: GraphNode): NodesAndLinks = {; [error] ^; [error] 6 errors found; [error] (womtool/compile:compileIncremental) Compilation failed; [error] Total time: 4 s, completed Apr 16, 2018 9:00:54 AM; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626
https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626:828,Availability,error,error,828,"I've gone through and updated the dependency graph of updating sttp, you can view diff at https://github.com/delagoya/cromwell/tree/update-depversions . Still one more set of errors to fix: ; ```; root(update-depversions)> | 31>; [info] Compiling 4 Scala sources to $HOME/src/cromwell/womtool/target/scala-2.12/classes...; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:46: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val thisLevelNodesAndLinks: NodesAndLinks = callsAndDeclarations foldMap { graphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:56: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val subGraphNodesAndLinks: NodesAndLinks = subGraphs foldMap { wdlGraphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:26: private val clusterCount in object GraphPrint is never used; [error] private val clusterCount: AtomicInteger = new AtomicInteger(0); [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:40: local default argument in method listAllGraphNodes is never used; [error] def upstreamLinks(wdlGraphNode: WdlGraphNode, graphNodeName: String, suffix: String = """"): Set[String] = wdlGraphNode.upstream collect {; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:54: value foldMap is not a member of Set[wom.graph.GraphNode]; [error] graph.nodes foldMap nodesAndLinks _; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:89: private method nodesAndLinks in class WomGraph is never used; [error] private def nodesAndLinks(graphNode: GraphNode): NodesAndLinks = {; [error] ^; [error] 6 errors found; [error] (womtool/compile:compileIncremental) Compilation failed; [error] Total time: 4 s, completed Apr 16, 2018 9:00:54 AM; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626
https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626:839,Availability,error,error,839,"I've gone through and updated the dependency graph of updating sttp, you can view diff at https://github.com/delagoya/cromwell/tree/update-depversions . Still one more set of errors to fix: ; ```; root(update-depversions)> | 31>; [info] Compiling 4 Scala sources to $HOME/src/cromwell/womtool/target/scala-2.12/classes...; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:46: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val thisLevelNodesAndLinks: NodesAndLinks = callsAndDeclarations foldMap { graphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:56: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val subGraphNodesAndLinks: NodesAndLinks = subGraphs foldMap { wdlGraphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:26: private val clusterCount in object GraphPrint is never used; [error] private val clusterCount: AtomicInteger = new AtomicInteger(0); [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:40: local default argument in method listAllGraphNodes is never used; [error] def upstreamLinks(wdlGraphNode: WdlGraphNode, graphNodeName: String, suffix: String = """"): Set[String] = wdlGraphNode.upstream collect {; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:54: value foldMap is not a member of Set[wom.graph.GraphNode]; [error] graph.nodes foldMap nodesAndLinks _; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:89: private method nodesAndLinks in class WomGraph is never used; [error] private def nodesAndLinks(graphNode: GraphNode): NodesAndLinks = {; [error] ^; [error] 6 errors found; [error] (womtool/compile:compileIncremental) Compilation failed; [error] Total time: 4 s, completed Apr 16, 2018 9:00:54 AM; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626
https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626:985,Availability,error,error,985,"I've gone through and updated the dependency graph of updating sttp, you can view diff at https://github.com/delagoya/cromwell/tree/update-depversions . Still one more set of errors to fix: ; ```; root(update-depversions)> | 31>; [info] Compiling 4 Scala sources to $HOME/src/cromwell/womtool/target/scala-2.12/classes...; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:46: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val thisLevelNodesAndLinks: NodesAndLinks = callsAndDeclarations foldMap { graphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:56: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val subGraphNodesAndLinks: NodesAndLinks = subGraphs foldMap { wdlGraphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:26: private val clusterCount in object GraphPrint is never used; [error] private val clusterCount: AtomicInteger = new AtomicInteger(0); [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:40: local default argument in method listAllGraphNodes is never used; [error] def upstreamLinks(wdlGraphNode: WdlGraphNode, graphNodeName: String, suffix: String = """"): Set[String] = wdlGraphNode.upstream collect {; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:54: value foldMap is not a member of Set[wom.graph.GraphNode]; [error] graph.nodes foldMap nodesAndLinks _; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:89: private method nodesAndLinks in class WomGraph is never used; [error] private def nodesAndLinks(graphNode: GraphNode): NodesAndLinks = {; [error] ^; [error] 6 errors found; [error] (womtool/compile:compileIncremental) Compilation failed; [error] Total time: 4 s, completed Apr 16, 2018 9:00:54 AM; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626
https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626:1057,Availability,error,error,1057,"I've gone through and updated the dependency graph of updating sttp, you can view diff at https://github.com/delagoya/cromwell/tree/update-depversions . Still one more set of errors to fix: ; ```; root(update-depversions)> | 31>; [info] Compiling 4 Scala sources to $HOME/src/cromwell/womtool/target/scala-2.12/classes...; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:46: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val thisLevelNodesAndLinks: NodesAndLinks = callsAndDeclarations foldMap { graphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:56: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val subGraphNodesAndLinks: NodesAndLinks = subGraphs foldMap { wdlGraphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:26: private val clusterCount in object GraphPrint is never used; [error] private val clusterCount: AtomicInteger = new AtomicInteger(0); [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:40: local default argument in method listAllGraphNodes is never used; [error] def upstreamLinks(wdlGraphNode: WdlGraphNode, graphNodeName: String, suffix: String = """"): Set[String] = wdlGraphNode.upstream collect {; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:54: value foldMap is not a member of Set[wom.graph.GraphNode]; [error] graph.nodes foldMap nodesAndLinks _; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:89: private method nodesAndLinks in class WomGraph is never used; [error] private def nodesAndLinks(graphNode: GraphNode): NodesAndLinks = {; [error] ^; [error] 6 errors found; [error] (womtool/compile:compileIncremental) Compilation failed; [error] Total time: 4 s, completed Apr 16, 2018 9:00:54 AM; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626
https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626:1068,Availability,error,error,1068,"I've gone through and updated the dependency graph of updating sttp, you can view diff at https://github.com/delagoya/cromwell/tree/update-depversions . Still one more set of errors to fix: ; ```; root(update-depversions)> | 31>; [info] Compiling 4 Scala sources to $HOME/src/cromwell/womtool/target/scala-2.12/classes...; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:46: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val thisLevelNodesAndLinks: NodesAndLinks = callsAndDeclarations foldMap { graphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:56: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val subGraphNodesAndLinks: NodesAndLinks = subGraphs foldMap { wdlGraphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:26: private val clusterCount in object GraphPrint is never used; [error] private val clusterCount: AtomicInteger = new AtomicInteger(0); [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:40: local default argument in method listAllGraphNodes is never used; [error] def upstreamLinks(wdlGraphNode: WdlGraphNode, graphNodeName: String, suffix: String = """"): Set[String] = wdlGraphNode.upstream collect {; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:54: value foldMap is not a member of Set[wom.graph.GraphNode]; [error] graph.nodes foldMap nodesAndLinks _; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:89: private method nodesAndLinks in class WomGraph is never used; [error] private def nodesAndLinks(graphNode: GraphNode): NodesAndLinks = {; [error] ^; [error] 6 errors found; [error] (womtool/compile:compileIncremental) Compilation failed; [error] Total time: 4 s, completed Apr 16, 2018 9:00:54 AM; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626
https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626:1219,Availability,error,error,1219,"I've gone through and updated the dependency graph of updating sttp, you can view diff at https://github.com/delagoya/cromwell/tree/update-depversions . Still one more set of errors to fix: ; ```; root(update-depversions)> | 31>; [info] Compiling 4 Scala sources to $HOME/src/cromwell/womtool/target/scala-2.12/classes...; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:46: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val thisLevelNodesAndLinks: NodesAndLinks = callsAndDeclarations foldMap { graphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:56: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val subGraphNodesAndLinks: NodesAndLinks = subGraphs foldMap { wdlGraphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:26: private val clusterCount in object GraphPrint is never used; [error] private val clusterCount: AtomicInteger = new AtomicInteger(0); [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:40: local default argument in method listAllGraphNodes is never used; [error] def upstreamLinks(wdlGraphNode: WdlGraphNode, graphNodeName: String, suffix: String = """"): Set[String] = wdlGraphNode.upstream collect {; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:54: value foldMap is not a member of Set[wom.graph.GraphNode]; [error] graph.nodes foldMap nodesAndLinks _; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:89: private method nodesAndLinks in class WomGraph is never used; [error] private def nodesAndLinks(graphNode: GraphNode): NodesAndLinks = {; [error] ^; [error] 6 errors found; [error] (womtool/compile:compileIncremental) Compilation failed; [error] Total time: 4 s, completed Apr 16, 2018 9:00:54 AM; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626
https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626:1365,Availability,error,error,1365,"I've gone through and updated the dependency graph of updating sttp, you can view diff at https://github.com/delagoya/cromwell/tree/update-depversions . Still one more set of errors to fix: ; ```; root(update-depversions)> | 31>; [info] Compiling 4 Scala sources to $HOME/src/cromwell/womtool/target/scala-2.12/classes...; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:46: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val thisLevelNodesAndLinks: NodesAndLinks = callsAndDeclarations foldMap { graphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:56: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val subGraphNodesAndLinks: NodesAndLinks = subGraphs foldMap { wdlGraphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:26: private val clusterCount in object GraphPrint is never used; [error] private val clusterCount: AtomicInteger = new AtomicInteger(0); [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:40: local default argument in method listAllGraphNodes is never used; [error] def upstreamLinks(wdlGraphNode: WdlGraphNode, graphNodeName: String, suffix: String = """"): Set[String] = wdlGraphNode.upstream collect {; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:54: value foldMap is not a member of Set[wom.graph.GraphNode]; [error] graph.nodes foldMap nodesAndLinks _; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:89: private method nodesAndLinks in class WomGraph is never used; [error] private def nodesAndLinks(graphNode: GraphNode): NodesAndLinks = {; [error] ^; [error] 6 errors found; [error] (womtool/compile:compileIncremental) Compilation failed; [error] Total time: 4 s, completed Apr 16, 2018 9:00:54 AM; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626
https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626:1376,Availability,error,error,1376,"I've gone through and updated the dependency graph of updating sttp, you can view diff at https://github.com/delagoya/cromwell/tree/update-depversions . Still one more set of errors to fix: ; ```; root(update-depversions)> | 31>; [info] Compiling 4 Scala sources to $HOME/src/cromwell/womtool/target/scala-2.12/classes...; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:46: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val thisLevelNodesAndLinks: NodesAndLinks = callsAndDeclarations foldMap { graphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:56: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val subGraphNodesAndLinks: NodesAndLinks = subGraphs foldMap { wdlGraphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:26: private val clusterCount in object GraphPrint is never used; [error] private val clusterCount: AtomicInteger = new AtomicInteger(0); [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:40: local default argument in method listAllGraphNodes is never used; [error] def upstreamLinks(wdlGraphNode: WdlGraphNode, graphNodeName: String, suffix: String = """"): Set[String] = wdlGraphNode.upstream collect {; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:54: value foldMap is not a member of Set[wom.graph.GraphNode]; [error] graph.nodes foldMap nodesAndLinks _; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:89: private method nodesAndLinks in class WomGraph is never used; [error] private def nodesAndLinks(graphNode: GraphNode): NodesAndLinks = {; [error] ^; [error] 6 errors found; [error] (womtool/compile:compileIncremental) Compilation failed; [error] Total time: 4 s, completed Apr 16, 2018 9:00:54 AM; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626
https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626:1518,Availability,error,error,1518,"I've gone through and updated the dependency graph of updating sttp, you can view diff at https://github.com/delagoya/cromwell/tree/update-depversions . Still one more set of errors to fix: ; ```; root(update-depversions)> | 31>; [info] Compiling 4 Scala sources to $HOME/src/cromwell/womtool/target/scala-2.12/classes...; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:46: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val thisLevelNodesAndLinks: NodesAndLinks = callsAndDeclarations foldMap { graphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:56: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val subGraphNodesAndLinks: NodesAndLinks = subGraphs foldMap { wdlGraphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:26: private val clusterCount in object GraphPrint is never used; [error] private val clusterCount: AtomicInteger = new AtomicInteger(0); [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:40: local default argument in method listAllGraphNodes is never used; [error] def upstreamLinks(wdlGraphNode: WdlGraphNode, graphNodeName: String, suffix: String = """"): Set[String] = wdlGraphNode.upstream collect {; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:54: value foldMap is not a member of Set[wom.graph.GraphNode]; [error] graph.nodes foldMap nodesAndLinks _; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:89: private method nodesAndLinks in class WomGraph is never used; [error] private def nodesAndLinks(graphNode: GraphNode): NodesAndLinks = {; [error] ^; [error] 6 errors found; [error] (womtool/compile:compileIncremental) Compilation failed; [error] Total time: 4 s, completed Apr 16, 2018 9:00:54 AM; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626
https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626:1563,Availability,error,error,1563,"I've gone through and updated the dependency graph of updating sttp, you can view diff at https://github.com/delagoya/cromwell/tree/update-depversions . Still one more set of errors to fix: ; ```; root(update-depversions)> | 31>; [info] Compiling 4 Scala sources to $HOME/src/cromwell/womtool/target/scala-2.12/classes...; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:46: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val thisLevelNodesAndLinks: NodesAndLinks = callsAndDeclarations foldMap { graphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:56: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val subGraphNodesAndLinks: NodesAndLinks = subGraphs foldMap { wdlGraphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:26: private val clusterCount in object GraphPrint is never used; [error] private val clusterCount: AtomicInteger = new AtomicInteger(0); [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:40: local default argument in method listAllGraphNodes is never used; [error] def upstreamLinks(wdlGraphNode: WdlGraphNode, graphNodeName: String, suffix: String = """"): Set[String] = wdlGraphNode.upstream collect {; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:54: value foldMap is not a member of Set[wom.graph.GraphNode]; [error] graph.nodes foldMap nodesAndLinks _; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:89: private method nodesAndLinks in class WomGraph is never used; [error] private def nodesAndLinks(graphNode: GraphNode): NodesAndLinks = {; [error] ^; [error] 6 errors found; [error] (womtool/compile:compileIncremental) Compilation failed; [error] Total time: 4 s, completed Apr 16, 2018 9:00:54 AM; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626
https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626:1574,Availability,error,error,1574,"I've gone through and updated the dependency graph of updating sttp, you can view diff at https://github.com/delagoya/cromwell/tree/update-depversions . Still one more set of errors to fix: ; ```; root(update-depversions)> | 31>; [info] Compiling 4 Scala sources to $HOME/src/cromwell/womtool/target/scala-2.12/classes...; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:46: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val thisLevelNodesAndLinks: NodesAndLinks = callsAndDeclarations foldMap { graphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:56: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val subGraphNodesAndLinks: NodesAndLinks = subGraphs foldMap { wdlGraphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:26: private val clusterCount in object GraphPrint is never used; [error] private val clusterCount: AtomicInteger = new AtomicInteger(0); [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:40: local default argument in method listAllGraphNodes is never used; [error] def upstreamLinks(wdlGraphNode: WdlGraphNode, graphNodeName: String, suffix: String = """"): Set[String] = wdlGraphNode.upstream collect {; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:54: value foldMap is not a member of Set[wom.graph.GraphNode]; [error] graph.nodes foldMap nodesAndLinks _; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:89: private method nodesAndLinks in class WomGraph is never used; [error] private def nodesAndLinks(graphNode: GraphNode): NodesAndLinks = {; [error] ^; [error] 6 errors found; [error] (womtool/compile:compileIncremental) Compilation failed; [error] Total time: 4 s, completed Apr 16, 2018 9:00:54 AM; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626
https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626:1719,Availability,error,error,1719,"I've gone through and updated the dependency graph of updating sttp, you can view diff at https://github.com/delagoya/cromwell/tree/update-depversions . Still one more set of errors to fix: ; ```; root(update-depversions)> | 31>; [info] Compiling 4 Scala sources to $HOME/src/cromwell/womtool/target/scala-2.12/classes...; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:46: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val thisLevelNodesAndLinks: NodesAndLinks = callsAndDeclarations foldMap { graphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:56: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val subGraphNodesAndLinks: NodesAndLinks = subGraphs foldMap { wdlGraphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:26: private val clusterCount in object GraphPrint is never used; [error] private val clusterCount: AtomicInteger = new AtomicInteger(0); [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:40: local default argument in method listAllGraphNodes is never used; [error] def upstreamLinks(wdlGraphNode: WdlGraphNode, graphNodeName: String, suffix: String = """"): Set[String] = wdlGraphNode.upstream collect {; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:54: value foldMap is not a member of Set[wom.graph.GraphNode]; [error] graph.nodes foldMap nodesAndLinks _; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:89: private method nodesAndLinks in class WomGraph is never used; [error] private def nodesAndLinks(graphNode: GraphNode): NodesAndLinks = {; [error] ^; [error] 6 errors found; [error] (womtool/compile:compileIncremental) Compilation failed; [error] Total time: 4 s, completed Apr 16, 2018 9:00:54 AM; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626
https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626:1795,Availability,error,error,1795,"I've gone through and updated the dependency graph of updating sttp, you can view diff at https://github.com/delagoya/cromwell/tree/update-depversions . Still one more set of errors to fix: ; ```; root(update-depversions)> | 31>; [info] Compiling 4 Scala sources to $HOME/src/cromwell/womtool/target/scala-2.12/classes...; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:46: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val thisLevelNodesAndLinks: NodesAndLinks = callsAndDeclarations foldMap { graphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:56: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val subGraphNodesAndLinks: NodesAndLinks = subGraphs foldMap { wdlGraphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:26: private val clusterCount in object GraphPrint is never used; [error] private val clusterCount: AtomicInteger = new AtomicInteger(0); [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:40: local default argument in method listAllGraphNodes is never used; [error] def upstreamLinks(wdlGraphNode: WdlGraphNode, graphNodeName: String, suffix: String = """"): Set[String] = wdlGraphNode.upstream collect {; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:54: value foldMap is not a member of Set[wom.graph.GraphNode]; [error] graph.nodes foldMap nodesAndLinks _; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:89: private method nodesAndLinks in class WomGraph is never used; [error] private def nodesAndLinks(graphNode: GraphNode): NodesAndLinks = {; [error] ^; [error] 6 errors found; [error] (womtool/compile:compileIncremental) Compilation failed; [error] Total time: 4 s, completed Apr 16, 2018 9:00:54 AM; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626
https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626:1806,Availability,error,error,1806,"I've gone through and updated the dependency graph of updating sttp, you can view diff at https://github.com/delagoya/cromwell/tree/update-depversions . Still one more set of errors to fix: ; ```; root(update-depversions)> | 31>; [info] Compiling 4 Scala sources to $HOME/src/cromwell/womtool/target/scala-2.12/classes...; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:46: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val thisLevelNodesAndLinks: NodesAndLinks = callsAndDeclarations foldMap { graphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:56: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val subGraphNodesAndLinks: NodesAndLinks = subGraphs foldMap { wdlGraphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:26: private val clusterCount in object GraphPrint is never used; [error] private val clusterCount: AtomicInteger = new AtomicInteger(0); [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:40: local default argument in method listAllGraphNodes is never used; [error] def upstreamLinks(wdlGraphNode: WdlGraphNode, graphNodeName: String, suffix: String = """"): Set[String] = wdlGraphNode.upstream collect {; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:54: value foldMap is not a member of Set[wom.graph.GraphNode]; [error] graph.nodes foldMap nodesAndLinks _; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:89: private method nodesAndLinks in class WomGraph is never used; [error] private def nodesAndLinks(graphNode: GraphNode): NodesAndLinks = {; [error] ^; [error] 6 errors found; [error] (womtool/compile:compileIncremental) Compilation failed; [error] Total time: 4 s, completed Apr 16, 2018 9:00:54 AM; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626
https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626:1815,Availability,error,errors,1815,"I've gone through and updated the dependency graph of updating sttp, you can view diff at https://github.com/delagoya/cromwell/tree/update-depversions . Still one more set of errors to fix: ; ```; root(update-depversions)> | 31>; [info] Compiling 4 Scala sources to $HOME/src/cromwell/womtool/target/scala-2.12/classes...; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:46: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val thisLevelNodesAndLinks: NodesAndLinks = callsAndDeclarations foldMap { graphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:56: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val subGraphNodesAndLinks: NodesAndLinks = subGraphs foldMap { wdlGraphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:26: private val clusterCount in object GraphPrint is never used; [error] private val clusterCount: AtomicInteger = new AtomicInteger(0); [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:40: local default argument in method listAllGraphNodes is never used; [error] def upstreamLinks(wdlGraphNode: WdlGraphNode, graphNodeName: String, suffix: String = """"): Set[String] = wdlGraphNode.upstream collect {; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:54: value foldMap is not a member of Set[wom.graph.GraphNode]; [error] graph.nodes foldMap nodesAndLinks _; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:89: private method nodesAndLinks in class WomGraph is never used; [error] private def nodesAndLinks(graphNode: GraphNode): NodesAndLinks = {; [error] ^; [error] 6 errors found; [error] (womtool/compile:compileIncremental) Compilation failed; [error] Total time: 4 s, completed Apr 16, 2018 9:00:54 AM; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626
https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626:1830,Availability,error,error,1830,"I've gone through and updated the dependency graph of updating sttp, you can view diff at https://github.com/delagoya/cromwell/tree/update-depversions . Still one more set of errors to fix: ; ```; root(update-depversions)> | 31>; [info] Compiling 4 Scala sources to $HOME/src/cromwell/womtool/target/scala-2.12/classes...; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:46: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val thisLevelNodesAndLinks: NodesAndLinks = callsAndDeclarations foldMap { graphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:56: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val subGraphNodesAndLinks: NodesAndLinks = subGraphs foldMap { wdlGraphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:26: private val clusterCount in object GraphPrint is never used; [error] private val clusterCount: AtomicInteger = new AtomicInteger(0); [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:40: local default argument in method listAllGraphNodes is never used; [error] def upstreamLinks(wdlGraphNode: WdlGraphNode, graphNodeName: String, suffix: String = """"): Set[String] = wdlGraphNode.upstream collect {; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:54: value foldMap is not a member of Set[wom.graph.GraphNode]; [error] graph.nodes foldMap nodesAndLinks _; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:89: private method nodesAndLinks in class WomGraph is never used; [error] private def nodesAndLinks(graphNode: GraphNode): NodesAndLinks = {; [error] ^; [error] 6 errors found; [error] (womtool/compile:compileIncremental) Compilation failed; [error] Total time: 4 s, completed Apr 16, 2018 9:00:54 AM; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626
https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626:1895,Availability,error,error,1895,"I've gone through and updated the dependency graph of updating sttp, you can view diff at https://github.com/delagoya/cromwell/tree/update-depversions . Still one more set of errors to fix: ; ```; root(update-depversions)> | 31>; [info] Compiling 4 Scala sources to $HOME/src/cromwell/womtool/target/scala-2.12/classes...; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:46: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val thisLevelNodesAndLinks: NodesAndLinks = callsAndDeclarations foldMap { graphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:56: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val subGraphNodesAndLinks: NodesAndLinks = subGraphs foldMap { wdlGraphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:26: private val clusterCount in object GraphPrint is never used; [error] private val clusterCount: AtomicInteger = new AtomicInteger(0); [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:40: local default argument in method listAllGraphNodes is never used; [error] def upstreamLinks(wdlGraphNode: WdlGraphNode, graphNodeName: String, suffix: String = """"): Set[String] = wdlGraphNode.upstream collect {; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:54: value foldMap is not a member of Set[wom.graph.GraphNode]; [error] graph.nodes foldMap nodesAndLinks _; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:89: private method nodesAndLinks in class WomGraph is never used; [error] private def nodesAndLinks(graphNode: GraphNode): NodesAndLinks = {; [error] ^; [error] 6 errors found; [error] (womtool/compile:compileIncremental) Compilation failed; [error] Total time: 4 s, completed Apr 16, 2018 9:00:54 AM; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626
https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626:22,Deployability,update,updated,22,"I've gone through and updated the dependency graph of updating sttp, you can view diff at https://github.com/delagoya/cromwell/tree/update-depversions . Still one more set of errors to fix: ; ```; root(update-depversions)> | 31>; [info] Compiling 4 Scala sources to $HOME/src/cromwell/womtool/target/scala-2.12/classes...; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:46: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val thisLevelNodesAndLinks: NodesAndLinks = callsAndDeclarations foldMap { graphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:56: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val subGraphNodesAndLinks: NodesAndLinks = subGraphs foldMap { wdlGraphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:26: private val clusterCount in object GraphPrint is never used; [error] private val clusterCount: AtomicInteger = new AtomicInteger(0); [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:40: local default argument in method listAllGraphNodes is never used; [error] def upstreamLinks(wdlGraphNode: WdlGraphNode, graphNodeName: String, suffix: String = """"): Set[String] = wdlGraphNode.upstream collect {; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:54: value foldMap is not a member of Set[wom.graph.GraphNode]; [error] graph.nodes foldMap nodesAndLinks _; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:89: private method nodesAndLinks in class WomGraph is never used; [error] private def nodesAndLinks(graphNode: GraphNode): NodesAndLinks = {; [error] ^; [error] 6 errors found; [error] (womtool/compile:compileIncremental) Compilation failed; [error] Total time: 4 s, completed Apr 16, 2018 9:00:54 AM; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626
https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626:132,Deployability,update,update-depversions,132,"I've gone through and updated the dependency graph of updating sttp, you can view diff at https://github.com/delagoya/cromwell/tree/update-depversions . Still one more set of errors to fix: ; ```; root(update-depversions)> | 31>; [info] Compiling 4 Scala sources to $HOME/src/cromwell/womtool/target/scala-2.12/classes...; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:46: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val thisLevelNodesAndLinks: NodesAndLinks = callsAndDeclarations foldMap { graphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:56: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val subGraphNodesAndLinks: NodesAndLinks = subGraphs foldMap { wdlGraphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:26: private val clusterCount in object GraphPrint is never used; [error] private val clusterCount: AtomicInteger = new AtomicInteger(0); [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:40: local default argument in method listAllGraphNodes is never used; [error] def upstreamLinks(wdlGraphNode: WdlGraphNode, graphNodeName: String, suffix: String = """"): Set[String] = wdlGraphNode.upstream collect {; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:54: value foldMap is not a member of Set[wom.graph.GraphNode]; [error] graph.nodes foldMap nodesAndLinks _; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:89: private method nodesAndLinks in class WomGraph is never used; [error] private def nodesAndLinks(graphNode: GraphNode): NodesAndLinks = {; [error] ^; [error] 6 errors found; [error] (womtool/compile:compileIncremental) Compilation failed; [error] Total time: 4 s, completed Apr 16, 2018 9:00:54 AM; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626
https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626:202,Deployability,update,update-depversions,202,"I've gone through and updated the dependency graph of updating sttp, you can view diff at https://github.com/delagoya/cromwell/tree/update-depversions . Still one more set of errors to fix: ; ```; root(update-depversions)> | 31>; [info] Compiling 4 Scala sources to $HOME/src/cromwell/womtool/target/scala-2.12/classes...; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:46: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val thisLevelNodesAndLinks: NodesAndLinks = callsAndDeclarations foldMap { graphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:56: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val subGraphNodesAndLinks: NodesAndLinks = subGraphs foldMap { wdlGraphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:26: private val clusterCount in object GraphPrint is never used; [error] private val clusterCount: AtomicInteger = new AtomicInteger(0); [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:40: local default argument in method listAllGraphNodes is never used; [error] def upstreamLinks(wdlGraphNode: WdlGraphNode, graphNodeName: String, suffix: String = """"): Set[String] = wdlGraphNode.upstream collect {; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:54: value foldMap is not a member of Set[wom.graph.GraphNode]; [error] graph.nodes foldMap nodesAndLinks _; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:89: private method nodesAndLinks in class WomGraph is never used; [error] private def nodesAndLinks(graphNode: GraphNode): NodesAndLinks = {; [error] ^; [error] 6 errors found; [error] (womtool/compile:compileIncremental) Compilation failed; [error] Total time: 4 s, completed Apr 16, 2018 9:00:54 AM; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626
https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626:34,Integrability,depend,dependency,34,"I've gone through and updated the dependency graph of updating sttp, you can view diff at https://github.com/delagoya/cromwell/tree/update-depversions . Still one more set of errors to fix: ; ```; root(update-depversions)> | 31>; [info] Compiling 4 Scala sources to $HOME/src/cromwell/womtool/target/scala-2.12/classes...; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:46: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val thisLevelNodesAndLinks: NodesAndLinks = callsAndDeclarations foldMap { graphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:56: value foldMap is not a member of Set[wdl.draft2.model.WdlGraphNode]; [error] val subGraphNodesAndLinks: NodesAndLinks = subGraphs foldMap { wdlGraphNode =>; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:26: private val clusterCount in object GraphPrint is never used; [error] private val clusterCount: AtomicInteger = new AtomicInteger(0); [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/GraphPrint.scala:40: local default argument in method listAllGraphNodes is never used; [error] def upstreamLinks(wdlGraphNode: WdlGraphNode, graphNodeName: String, suffix: String = """"): Set[String] = wdlGraphNode.upstream collect {; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:54: value foldMap is not a member of Set[wom.graph.GraphNode]; [error] graph.nodes foldMap nodesAndLinks _; [error] ^; [error] $HOME/src/cromwell/womtool/src/main/scala/womtool/graph/WomGraph.scala:89: private method nodesAndLinks in class WomGraph is never used; [error] private def nodesAndLinks(graphNode: GraphNode): NodesAndLinks = {; [error] ^; [error] 6 errors found; [error] (womtool/compile:compileIncremental) Compilation failed; [error] Total time: 4 s, completed Apr 16, 2018 9:00:54 AM; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-381592626
https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-382077268:28,Deployability,update,update,28,"@delagoya your dependencies update might conflict with a round I just did in our `develop` branch. Namely we are using cats 1.0.1, and I'm not 100% sure 1.1 will work. So if you pull/rebase you will get most of what you posted minus the sttp update",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-382077268
https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-382077268:242,Deployability,update,update,242,"@delagoya your dependencies update might conflict with a round I just did in our `develop` branch. Namely we are using cats 1.0.1, and I'm not 100% sure 1.1 will work. So if you pull/rebase you will get most of what you posted minus the sttp update",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-382077268
https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-382077268:15,Integrability,depend,dependencies,15,"@delagoya your dependencies update might conflict with a round I just did in our `develop` branch. Namely we are using cats 1.0.1, and I'm not 100% sure 1.1 will work. So if you pull/rebase you will get most of what you posted minus the sttp update",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-382077268
https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-382390194:12,Deployability,update,update,12,Thanks will update,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3514#issuecomment-382390194
https://github.com/broadinstitute/cromwell/issues/3518#issuecomment-399762138:99,Availability,avail,available,99,"Additional info since the time this issue was filed: Alibaba's [Batch Compute service (BCS) is now available in the US](https://www.alibabacloud.com/help/doc-detail/61360.htm?spm=a2c63.l28256.a3.23.194f25719KjP66). This helps test Cromwell-in-the-US-using-DockerHub, but for CN users the above issues still need to be addressed, including figuring out a way for to check hashes from OSS.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3518#issuecomment-399762138
https://github.com/broadinstitute/cromwell/issues/3518#issuecomment-399762138:371,Security,hash,hashes,371,"Additional info since the time this issue was filed: Alibaba's [Batch Compute service (BCS) is now available in the US](https://www.alibabacloud.com/help/doc-detail/61360.htm?spm=a2c63.l28256.a3.23.194f25719KjP66). This helps test Cromwell-in-the-US-using-DockerHub, but for CN users the above issues still need to be addressed, including figuring out a way for to check hashes from OSS.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3518#issuecomment-399762138
https://github.com/broadinstitute/cromwell/issues/3518#issuecomment-399762138:226,Testability,test,test,226,"Additional info since the time this issue was filed: Alibaba's [Batch Compute service (BCS) is now available in the US](https://www.alibabacloud.com/help/doc-detail/61360.htm?spm=a2c63.l28256.a3.23.194f25719KjP66). This helps test Cromwell-in-the-US-using-DockerHub, but for CN users the above issues still need to be addressed, including figuring out a way for to check hashes from OSS.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3518#issuecomment-399762138
https://github.com/broadinstitute/cromwell/pull/3527#issuecomment-382756882:113,Testability,test,tests,113,"I tried the `semiauto` + `deriveDecoder` + type annotation suggestion in the Circe link - it compiles and passes tests, but the speed improvement goes away. I am going to put those particular implicits aside for now and measure whether the other (easy) changes make a worthwhile difference - I suspect they do",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3527#issuecomment-382756882
https://github.com/broadinstitute/cromwell/issues/3528#issuecomment-386302299:259,Integrability,depend,depending,259,"I agree that optional task inputs not being overridable from the inputs json is a bug and should be fixed. Regarding defaults vs fixing values, you're both right - values like that might be intended as inputs or might be intended as fixed intermediate values depending on the context and it's really hard to deduce which one an author intended just based on the WDL file. . That kind of confusion is exactly why WDL 1.0 (you're currently writing in draft-2) is adding `input` sections. Ie:. ```wdl; workflow foo {; input {; # input with default; Int threads = 1; }; }; ```; vs; ```wdl; workflow foo {; input {; ...; }; ; # intermediate value: cannot be overridden; Int threads = 1; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3528#issuecomment-386302299
https://github.com/broadinstitute/cromwell/issues/3528#issuecomment-386522096:173,Deployability,continuous,continuously,173,"> That kind of confusion is exactly why WDL 1.0 (you're currently writing in draft-2) is adding input sections. Ie:. Wow! That is some great functionality.I love how WDL is continuously identifying real problems, and finding solutions for them in a readable, logical and easily to understand syntax. :+1:. Will this inputs section solve this bug? Presumably it will make it at least easier to solve it for the Cromwell developers?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3528#issuecomment-386522096
https://github.com/broadinstitute/cromwell/issues/3528#issuecomment-386522096:259,Testability,log,logical,259,"> That kind of confusion is exactly why WDL 1.0 (you're currently writing in draft-2) is adding input sections. Ie:. Wow! That is some great functionality.I love how WDL is continuously identifying real problems, and finding solutions for them in a readable, logical and easily to understand syntax. :+1:. Will this inputs section solve this bug? Presumably it will make it at least easier to solve it for the Cromwell developers?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3528#issuecomment-386522096
https://github.com/broadinstitute/cromwell/pull/3532#issuecomment-382520351:23,Testability,test,test,23,ToL: is it possible to test that this doesn't unfix itself in the future?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3532#issuecomment-382520351
https://github.com/broadinstitute/cromwell/pull/3532#issuecomment-382531175:15,Availability,error,errors,15,"Detritus still errors on hard linking, I think we may not have created the execution directory first.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3532#issuecomment-382531175
https://github.com/broadinstitute/cromwell/pull/3532#issuecomment-382554577:49,Testability,test,tests,49,It looks like Chris is going to get his wish for tests since this fix seems to have broken some of the existing SFS hard linking tests. üòÆ,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3532#issuecomment-382554577
https://github.com/broadinstitute/cromwell/pull/3532#issuecomment-382554577:129,Testability,test,tests,129,It looks like Chris is going to get his wish for tests since this fix seems to have broken some of the existing SFS hard linking tests. üòÆ,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3532#issuecomment-382554577
https://github.com/broadinstitute/cromwell/pull/3532#issuecomment-382680928:50,Performance,cache,cache,50,So it appears my proposed changes here fixed call cache hit copy hard linking (except for detritus) but broke input localization hard linking. More investigation needed...,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3532#issuecomment-382680928
https://github.com/broadinstitute/cromwell/issues/3533#issuecomment-382796047:182,Availability,error,error,182,"4/19 PM Hi Evan, a patch went out to fix this at 10 AM this morning. Can you confirm that you no longer see this?. 4/19 AM Hi Evan - were you signed into the forum when you got this error? Can you send me the url of the page you were on?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3533#issuecomment-382796047
https://github.com/broadinstitute/cromwell/issues/3533#issuecomment-382796047:19,Deployability,patch,patch,19,"4/19 PM Hi Evan, a patch went out to fix this at 10 AM this morning. Can you confirm that you no longer see this?. 4/19 AM Hi Evan - were you signed into the forum when you got this error? Can you send me the url of the page you were on?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3533#issuecomment-382796047
https://github.com/broadinstitute/cromwell/issues/3533#issuecomment-382918043:266,Availability,error,error,266,"I have not reproduced the issue, I will try when I get a chance here. At the time I was modifying my backend's 'runtime-attributes'. I made all those attributes optional. I also removed all the 'runtime' stanzas in the wdl file I was testing. I believe there was an error in the 'submit' syntax of my backend config. . Is it possible a config file that fails to parse will cause backends to default to the Local backend? I know parts of the config are not parsed until a job is submitted. I will try to isolate the problem. Thanks",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3533#issuecomment-382918043
https://github.com/broadinstitute/cromwell/issues/3533#issuecomment-382918043:309,Modifiability,config,config,309,"I have not reproduced the issue, I will try when I get a chance here. At the time I was modifying my backend's 'runtime-attributes'. I made all those attributes optional. I also removed all the 'runtime' stanzas in the wdl file I was testing. I believe there was an error in the 'submit' syntax of my backend config. . Is it possible a config file that fails to parse will cause backends to default to the Local backend? I know parts of the config are not parsed until a job is submitted. I will try to isolate the problem. Thanks",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3533#issuecomment-382918043
https://github.com/broadinstitute/cromwell/issues/3533#issuecomment-382918043:336,Modifiability,config,config,336,"I have not reproduced the issue, I will try when I get a chance here. At the time I was modifying my backend's 'runtime-attributes'. I made all those attributes optional. I also removed all the 'runtime' stanzas in the wdl file I was testing. I believe there was an error in the 'submit' syntax of my backend config. . Is it possible a config file that fails to parse will cause backends to default to the Local backend? I know parts of the config are not parsed until a job is submitted. I will try to isolate the problem. Thanks",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3533#issuecomment-382918043
https://github.com/broadinstitute/cromwell/issues/3533#issuecomment-382918043:441,Modifiability,config,config,441,"I have not reproduced the issue, I will try when I get a chance here. At the time I was modifying my backend's 'runtime-attributes'. I made all those attributes optional. I also removed all the 'runtime' stanzas in the wdl file I was testing. I believe there was an error in the 'submit' syntax of my backend config. . Is it possible a config file that fails to parse will cause backends to default to the Local backend? I know parts of the config are not parsed until a job is submitted. I will try to isolate the problem. Thanks",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3533#issuecomment-382918043
https://github.com/broadinstitute/cromwell/issues/3533#issuecomment-382918043:234,Testability,test,testing,234,"I have not reproduced the issue, I will try when I get a chance here. At the time I was modifying my backend's 'runtime-attributes'. I made all those attributes optional. I also removed all the 'runtime' stanzas in the wdl file I was testing. I believe there was an error in the 'submit' syntax of my backend config. . Is it possible a config file that fails to parse will cause backends to default to the Local backend? I know parts of the config are not parsed until a job is submitted. I will try to isolate the problem. Thanks",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3533#issuecomment-382918043
https://github.com/broadinstitute/cromwell/pull/3537#issuecomment-384634147:69,Deployability,update,updates,69,"Hey @EvanTheB -- the docs around backends need more changes, and the updates will be easier to make on my own branch. I'm going to take your changes, adjust surrounding docs and have you review that instead -- hence closing out this PR.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3537#issuecomment-384634147
https://github.com/broadinstitute/cromwell/issues/3543#issuecomment-387146849:43,Testability,test,test,43,I think the description is correct but the test number was actually 102.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3543#issuecomment-387146849
https://github.com/broadinstitute/cromwell/pull/3557#issuecomment-385393714:35,Testability,test,tests,35,"seems some additional file literal tests have appeared, going to make sure we pass those before merging",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3557#issuecomment-385393714
https://github.com/broadinstitute/cromwell/pull/3562#issuecomment-385389043:351,Availability,down,downloads,351,"FYI there's a hidden watermark at the top of the file that one can use in PRs to tell if the RESTAPI.md was manually or automatically updated. Example: https://github.com/broadinstitute/cromwell/blame/31/docs/api/RESTAPI.md#L1-L8. Also if one doesn't have a dev environment locally they can still use any public sbt docker. It will take a while as it downloads ~the entire internet~ all of the un-cached cromwell dependencies, but something like this will work:. ```shell; docker \; run \; --rm \; -v $PWD:$PWD \; -w $PWD \; hseeberger/scala-sbt \; sbt generateRestApiDocs; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3562#issuecomment-385389043
https://github.com/broadinstitute/cromwell/pull/3562#issuecomment-385389043:134,Deployability,update,updated,134,"FYI there's a hidden watermark at the top of the file that one can use in PRs to tell if the RESTAPI.md was manually or automatically updated. Example: https://github.com/broadinstitute/cromwell/blame/31/docs/api/RESTAPI.md#L1-L8. Also if one doesn't have a dev environment locally they can still use any public sbt docker. It will take a while as it downloads ~the entire internet~ all of the un-cached cromwell dependencies, but something like this will work:. ```shell; docker \; run \; --rm \; -v $PWD:$PWD \; -w $PWD \; hseeberger/scala-sbt \; sbt generateRestApiDocs; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3562#issuecomment-385389043
https://github.com/broadinstitute/cromwell/pull/3562#issuecomment-385389043:413,Integrability,depend,dependencies,413,"FYI there's a hidden watermark at the top of the file that one can use in PRs to tell if the RESTAPI.md was manually or automatically updated. Example: https://github.com/broadinstitute/cromwell/blame/31/docs/api/RESTAPI.md#L1-L8. Also if one doesn't have a dev environment locally they can still use any public sbt docker. It will take a while as it downloads ~the entire internet~ all of the un-cached cromwell dependencies, but something like this will work:. ```shell; docker \; run \; --rm \; -v $PWD:$PWD \; -w $PWD \; hseeberger/scala-sbt \; sbt generateRestApiDocs; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3562#issuecomment-385389043
https://github.com/broadinstitute/cromwell/pull/3562#issuecomment-385389043:397,Performance,cache,cached,397,"FYI there's a hidden watermark at the top of the file that one can use in PRs to tell if the RESTAPI.md was manually or automatically updated. Example: https://github.com/broadinstitute/cromwell/blame/31/docs/api/RESTAPI.md#L1-L8. Also if one doesn't have a dev environment locally they can still use any public sbt docker. It will take a while as it downloads ~the entire internet~ all of the un-cached cromwell dependencies, but something like this will work:. ```shell; docker \; run \; --rm \; -v $PWD:$PWD \; -w $PWD \; hseeberger/scala-sbt \; sbt generateRestApiDocs; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3562#issuecomment-385389043
https://github.com/broadinstitute/cromwell/pull/3562#issuecomment-385389411:22,Deployability,update,update,22,Thanks @evantheb I‚Äôll update woth the aigogenerated version,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3562#issuecomment-385389411
https://github.com/broadinstitute/cromwell/issues/3574#issuecomment-788224575:165,Modifiability,config,config-block,165,@dfeinzeig for private registries I believe you have to use the Docker CLI as described here: https://cromwell.readthedocs.io/en/stable/tutorials/Containers/#docker-config-block,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3574#issuecomment-788224575
https://github.com/broadinstitute/cromwell/issues/3575#issuecomment-389168565:204,Availability,toler,tolerate,204,"Parting thoughts:. * The detritus portion of this was not handled at all so conformance test 87 is being skipped for the time being. Conformance 87 runs a `find` in the execution directory which will not tolerate detritus and defeats our current detritus filtering hack.; * It could also turn out the prepopulated-`listing` fix for the IWDR is too narrow and real dynamicism may be required for other non-`listing` IWDR operations.; * Somewhat aligned with the above, the `listing` runs before inputs have been localized so it is pointed to a filesystem location relative to where the Cromwell server is currently running rather than the call's inputs directory. Input localization should possibly happen before we try to do anything related to IWDR listing determination, but that's not the order of operations now.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3575#issuecomment-389168565
https://github.com/broadinstitute/cromwell/issues/3575#issuecomment-389168565:88,Testability,test,test,88,"Parting thoughts:. * The detritus portion of this was not handled at all so conformance test 87 is being skipped for the time being. Conformance 87 runs a `find` in the execution directory which will not tolerate detritus and defeats our current detritus filtering hack.; * It could also turn out the prepopulated-`listing` fix for the IWDR is too narrow and real dynamicism may be required for other non-`listing` IWDR operations.; * Somewhat aligned with the above, the `listing` runs before inputs have been localized so it is pointed to a filesystem location relative to where the Cromwell server is currently running rather than the call's inputs directory. Input localization should possibly happen before we try to do anything related to IWDR listing determination, but that's not the order of operations now.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3575#issuecomment-389168565
https://github.com/broadinstitute/cromwell/pull/3580#issuecomment-386051165:39,Usability,simpl,simple,39,"Ah, ok, I didn't know that it was that simple! I always leave these off if intellij is happy so on that basis leaving more off works for me üëç . [![Approved with PullApprove](https://img.shields.io/badge/one_reviewer-approved-brightgreen.svg)](https://pullapprove.com/broadinstitute/cromwell/pull-request/3580/?utm_source=github-pr&utm_medium=comment-badge&utm_campaign=broadinstitute/cromwell) [![Approved with PullApprove](https://img.shields.io/badge/two_reviewers-approved-brightgreen.svg)](https://pullapprove.com/broadinstitute/cromwell/pull-request/3580/?utm_source=github-pr&utm_medium=comment-badge&utm_campaign=broadinstitute/cromwell)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3580#issuecomment-386051165
https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386320045:42,Availability,error,error,42,"Hi Brad,. Thanks for reporting this. This error definitely should not occur but I'm surprised that it's causing Cromwell to freeze. Have you seen any other error in the log further down ?. Thanks",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386320045
https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386320045:156,Availability,error,error,156,"Hi Brad,. Thanks for reporting this. This error definitely should not occur but I'm surprised that it's causing Cromwell to freeze. Have you seen any other error in the log further down ?. Thanks",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386320045
https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386320045:181,Availability,down,down,181,"Hi Brad,. Thanks for reporting this. This error definitely should not occur but I'm surprised that it's causing Cromwell to freeze. Have you seen any other error in the log further down ?. Thanks",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386320045
https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386320045:169,Testability,log,log,169,"Hi Brad,. Thanks for reporting this. This error definitely should not occur but I'm surprised that it's causing Cromwell to freeze. Have you seen any other error in the log further down ?. Thanks",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386320045
https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386387039:53,Availability,error,errors,53,"Thanks so much, unfortunately there aren't any other errors. The runner kicks off 3 more jobs (for 3 variant callers on run on this failed cache input). Those all complete and then the main process just stops. There are no more submissions to the cluster or anything beyond the main job waiting. Here is the remainder of the log if it's helpful:; ```; [2018-05-02 15:22:58,85] [info] 9fa3ab92-97fd-4bed-a636-6eaf38941141-SubWorkflowActor-SubWorkflow-variantcall:1:1 [[38;5;2m9fa3ab92[0m]: Starting get_parallel_regions; [2018-05-02 15:22:58,85] [info] b0777d55-4f75-47aa-9655-3119936b10a5-SubWorkflowActor-SubWorkflow-variantcall:2:1 [[38;5;2mb0777d55[0m]: Starting get_parallel_regions; [2018-05-02 15:22:58,85] [info] b4328660-38fb-4bd7-8220-cd2f47bb26b2-SubWorkflowActor-SubWorkflow-variantcall:0:1 [[38;5;2mb4328660[0m]: Starting get_parallel_regions; [2018-05-02 15:22:59,95] [[38;5;220mwarn[0m] DispatchedConfigAsyncJobExecutionActor [[38;5;2mb4328660[0mget_parallel_regions:NA:1]: Unrecognized runtime attribute keys: memoryMax, tmpDirMin, cpuMax, cpuMin, tmpDirMax, outDirMin, memoryMin, outDirMax; [2018-05-02 15:22:59,95] [[38;5;220mwarn[0m] DispatchedConfigAsyncJobExecutionActor [[38;5;2m9fa3ab92[0mget_parallel_regions:NA:1]: Unrecognized runtime attribute keys: memoryMax, tmpDirMin, cpuMax, cpuMin, tmpDirMax, outDirMin, memoryMin, outDirMax; [2018-05-02 15:22:59,98] [[38;5;220mwarn[0m] DispatchedConfigAsyncJobExecutionActor [[38;5;2mb0777d55[0mget_parallel_regions:NA:1]: Unrecognized runtime attribute keys: memoryMax, tmpDirMin, cpuMax, cpuMin, tmpDirMax, outDirMin, memoryMin, outDirMax; [2018-05-02 15:23:00,78] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2m9fa3ab92[0mget_parallel_regions:NA:1]: [38;5;5m'bcbio_nextgen.py' 'runfn' 'get_parallel_regions' 'cwl' 'sentinel_runtime=cores,1,ram,3839.9999999999995' 'sentinel_parallel=batch-split' 'sentinel_outputs=region_block' 'sentinel_inputs=batch_rec:record'[0m; [2018-05-02 15:23:00,79] [info] Di",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386387039
https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386387039:3066,Integrability,wrap,wrap,3066,"egions:NA:1]: executing: sbatch -J cromwell_9fa3ab92_get_parallel_regions -D /projects/ngs/oncology/dev/bcbio_validation_workflows/somatic-giab-mix/cromwell_work/cromwell-executions/main-somatic-giab-mix.cwl/bc4644da-87f9-4765-9791-9011a2fae80f/call-variantcall/shard-1/wf-variantcall.cwl/9fa3ab92-97fd-4bed-a636-6eaf38941141/call-get_parallel_regions -o /projects/ngs/oncology/dev/bcbio_validation_workflows/somatic-giab-mix/cromwell_work/cromwell-executions/main-somatic-giab-mix.cwl/bc4644da-87f9-4765-9791-9011a2fae80f/call-variantcall/shard-1/wf-variantcall.cwl/9fa3ab92-97fd-4bed-a636-6eaf38941141/call-get_parallel_regions/execution/stdout -e /projects/ngs/oncology/dev/bcbio_validation_workflows/somatic-giab-mix/cromwell_work/cromwell-executions/main-somatic-giab-mix.cwl/bc4644da-87f9-4765-9791-9011a2fae80f/call-variantcall/shard-1/wf-variantcall.cwl/9fa3ab92-97fd-4bed-a636-6eaf38941141/call-get_parallel_regions/execution/stderr -t 1-00:00 -p core --cpus-per-task=1 --mem=4026 --wrap ""/usr/bin/env bash /projects/ngs/oncology/dev/bcbio_validation_workflows/somatic-giab-mix/cromwell_work/cromwell-executions/main-somatic-giab-mix.cwl/bc4644da-87f9-4765-9791-9011a2fae80f/call-variantcall/shard-1/wf-variantcall.cwl/9fa3ab92-97fd-4bed-a636-6eaf38941141/call-get_parallel_regions/execution/script""; [2018-05-02 15:23:01,69] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mb0777d55[0mget_parallel_regions:NA:1]: [38;5;5m'bcbio_nextgen.py' 'runfn' 'get_parallel_regions' 'cwl' 'sentinel_runtime=cores,1,ram,3839.9999999999995' 'sentinel_parallel=batch-split' 'sentinel_outputs=region_block' 'sentinel_inputs=batch_rec:record'[0m; [2018-05-02 15:23:01,72] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mb0777d55[0mget_parallel_regions:NA:1]: executing: sbatch -J cromwell_b0777d55_get_parallel_regions -D /projects/ngs/oncology/dev/bcbio_validation_workflows/somatic-giab-mix/cromwell_work/cromwell-executions/main-somatic-giab-mix.cwl/bc4644da-87f9-4765-9791-9011a2fae80f",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386387039
https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386387039:4823,Integrability,wrap,wrap,4823,"egions:NA:1]: executing: sbatch -J cromwell_b0777d55_get_parallel_regions -D /projects/ngs/oncology/dev/bcbio_validation_workflows/somatic-giab-mix/cromwell_work/cromwell-executions/main-somatic-giab-mix.cwl/bc4644da-87f9-4765-9791-9011a2fae80f/call-variantcall/shard-2/wf-variantcall.cwl/b0777d55-4f75-47aa-9655-3119936b10a5/call-get_parallel_regions -o /projects/ngs/oncology/dev/bcbio_validation_workflows/somatic-giab-mix/cromwell_work/cromwell-executions/main-somatic-giab-mix.cwl/bc4644da-87f9-4765-9791-9011a2fae80f/call-variantcall/shard-2/wf-variantcall.cwl/b0777d55-4f75-47aa-9655-3119936b10a5/call-get_parallel_regions/execution/stdout -e /projects/ngs/oncology/dev/bcbio_validation_workflows/somatic-giab-mix/cromwell_work/cromwell-executions/main-somatic-giab-mix.cwl/bc4644da-87f9-4765-9791-9011a2fae80f/call-variantcall/shard-2/wf-variantcall.cwl/b0777d55-4f75-47aa-9655-3119936b10a5/call-get_parallel_regions/execution/stderr -t 1-00:00 -p core --cpus-per-task=1 --mem=4026 --wrap ""/usr/bin/env bash /projects/ngs/oncology/dev/bcbio_validation_workflows/somatic-giab-mix/cromwell_work/cromwell-executions/main-somatic-giab-mix.cwl/bc4644da-87f9-4765-9791-9011a2fae80f/call-variantcall/shard-2/wf-variantcall.cwl/b0777d55-4f75-47aa-9655-3119936b10a5/call-get_parallel_regions/execution/script""; [2018-05-02 15:23:01,86] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mb4328660[0mget_parallel_regions:NA:1]: [38;5;5m'bcbio_nextgen.py' 'runfn' 'get_parallel_regions' 'cwl' 'sentinel_runtime=cores,1,ram,3839.9999999999995' 'sentinel_parallel=batch-split' 'sentinel_outputs=region_block' 'sentinel_inputs=batch_rec:record'[0m; [2018-05-02 15:23:01,86] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mb4328660[0mget_parallel_regions:NA:1]: executing: sbatch -J cromwell_b4328660_get_parallel_regions -D /projects/ngs/oncology/dev/bcbio_validation_workflows/somatic-giab-mix/cromwell_work/cromwell-executions/main-somatic-giab-mix.cwl/bc4644da-87f9-4765-9791-9011a2fae80f",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386387039
https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386387039:6580,Integrability,wrap,wrap,6580,"egions:NA:1]: executing: sbatch -J cromwell_b4328660_get_parallel_regions -D /projects/ngs/oncology/dev/bcbio_validation_workflows/somatic-giab-mix/cromwell_work/cromwell-executions/main-somatic-giab-mix.cwl/bc4644da-87f9-4765-9791-9011a2fae80f/call-variantcall/shard-0/wf-variantcall.cwl/b4328660-38fb-4bd7-8220-cd2f47bb26b2/call-get_parallel_regions -o /projects/ngs/oncology/dev/bcbio_validation_workflows/somatic-giab-mix/cromwell_work/cromwell-executions/main-somatic-giab-mix.cwl/bc4644da-87f9-4765-9791-9011a2fae80f/call-variantcall/shard-0/wf-variantcall.cwl/b4328660-38fb-4bd7-8220-cd2f47bb26b2/call-get_parallel_regions/execution/stdout -e /projects/ngs/oncology/dev/bcbio_validation_workflows/somatic-giab-mix/cromwell_work/cromwell-executions/main-somatic-giab-mix.cwl/bc4644da-87f9-4765-9791-9011a2fae80f/call-variantcall/shard-0/wf-variantcall.cwl/b4328660-38fb-4bd7-8220-cd2f47bb26b2/call-get_parallel_regions/execution/stderr -t 1-00:00 -p core --cpus-per-task=1 --mem=4026 --wrap ""/usr/bin/env bash /projects/ngs/oncology/dev/bcbio_validation_workflows/somatic-giab-mix/cromwell_work/cromwell-executions/main-somatic-giab-mix.cwl/bc4644da-87f9-4765-9791-9011a2fae80f/call-variantcall/shard-0/wf-variantcall.cwl/b4328660-38fb-4bd7-8220-cd2f47bb26b2/call-get_parallel_regions/execution/script""; [2018-05-02 15:23:02,64] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2m9fa3ab92[0mget_parallel_regions:NA:1]: job id: 134058; [2018-05-02 15:23:02,64] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mb0777d55[0mget_parallel_regions:NA:1]: job id: 134059; [2018-05-02 15:23:02,64] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mb4328660[0mget_parallel_regions:NA:1]: job id: 134060; [2018-05-02 15:23:02,64] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mb0777d55[0mget_parallel_regions:NA:1]: Status change from - to WaitingForReturnCodeFile; [2018-05-02 15:23:02,65] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mb4328660[0mget_parallel_reg",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386387039
https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386387039:139,Performance,cache,cache,139,"Thanks so much, unfortunately there aren't any other errors. The runner kicks off 3 more jobs (for 3 variant callers on run on this failed cache input). Those all complete and then the main process just stops. There are no more submissions to the cluster or anything beyond the main job waiting. Here is the remainder of the log if it's helpful:; ```; [2018-05-02 15:22:58,85] [info] 9fa3ab92-97fd-4bed-a636-6eaf38941141-SubWorkflowActor-SubWorkflow-variantcall:1:1 [[38;5;2m9fa3ab92[0m]: Starting get_parallel_regions; [2018-05-02 15:22:58,85] [info] b0777d55-4f75-47aa-9655-3119936b10a5-SubWorkflowActor-SubWorkflow-variantcall:2:1 [[38;5;2mb0777d55[0m]: Starting get_parallel_regions; [2018-05-02 15:22:58,85] [info] b4328660-38fb-4bd7-8220-cd2f47bb26b2-SubWorkflowActor-SubWorkflow-variantcall:0:1 [[38;5;2mb4328660[0m]: Starting get_parallel_regions; [2018-05-02 15:22:59,95] [[38;5;220mwarn[0m] DispatchedConfigAsyncJobExecutionActor [[38;5;2mb4328660[0mget_parallel_regions:NA:1]: Unrecognized runtime attribute keys: memoryMax, tmpDirMin, cpuMax, cpuMin, tmpDirMax, outDirMin, memoryMin, outDirMax; [2018-05-02 15:22:59,95] [[38;5;220mwarn[0m] DispatchedConfigAsyncJobExecutionActor [[38;5;2m9fa3ab92[0mget_parallel_regions:NA:1]: Unrecognized runtime attribute keys: memoryMax, tmpDirMin, cpuMax, cpuMin, tmpDirMax, outDirMin, memoryMin, outDirMax; [2018-05-02 15:22:59,98] [[38;5;220mwarn[0m] DispatchedConfigAsyncJobExecutionActor [[38;5;2mb0777d55[0mget_parallel_regions:NA:1]: Unrecognized runtime attribute keys: memoryMax, tmpDirMin, cpuMax, cpuMin, tmpDirMax, outDirMin, memoryMin, outDirMax; [2018-05-02 15:23:00,78] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2m9fa3ab92[0mget_parallel_regions:NA:1]: [38;5;5m'bcbio_nextgen.py' 'runfn' 'get_parallel_regions' 'cwl' 'sentinel_runtime=cores,1,ram,3839.9999999999995' 'sentinel_parallel=batch-split' 'sentinel_outputs=region_block' 'sentinel_inputs=batch_rec:record'[0m; [2018-05-02 15:23:00,79] [info] Di",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386387039
https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386387039:325,Testability,log,log,325,"re aren't any other errors. The runner kicks off 3 more jobs (for 3 variant callers on run on this failed cache input). Those all complete and then the main process just stops. There are no more submissions to the cluster or anything beyond the main job waiting. Here is the remainder of the log if it's helpful:; ```; [2018-05-02 15:22:58,85] [info] 9fa3ab92-97fd-4bed-a636-6eaf38941141-SubWorkflowActor-SubWorkflow-variantcall:1:1 [[38;5;2m9fa3ab92[0m]: Starting get_parallel_regions; [2018-05-02 15:22:58,85] [info] b0777d55-4f75-47aa-9655-3119936b10a5-SubWorkflowActor-SubWorkflow-variantcall:2:1 [[38;5;2mb0777d55[0m]: Starting get_parallel_regions; [2018-05-02 15:22:58,85] [info] b4328660-38fb-4bd7-8220-cd2f47bb26b2-SubWorkflowActor-SubWorkflow-variantcall:0:1 [[38;5;2mb4328660[0m]: Starting get_parallel_regions; [2018-05-02 15:22:59,95] [[38;5;220mwarn[0m] DispatchedConfigAsyncJobExecutionActor [[38;5;2mb4328660[0mget_parallel_regions:NA:1]: Unrecognized runtime attribute keys: memoryMax, tmpDirMin, cpuMax, cpuMin, tmpDirMax, outDirMin, memoryMin, outDirMax; [2018-05-02 15:22:59,95] [[38;5;220mwarn[0m] DispatchedConfigAsyncJobExecutionActor [[38;5;2m9fa3ab92[0mget_parallel_regions:NA:1]: Unrecognized runtime attribute keys: memoryMax, tmpDirMin, cpuMax, cpuMin, tmpDirMax, outDirMin, memoryMin, outDirMax; [2018-05-02 15:22:59,98] [[38;5;220mwarn[0m] DispatchedConfigAsyncJobExecutionActor [[38;5;2mb0777d55[0mget_parallel_regions:NA:1]: Unrecognized runtime attribute keys: memoryMax, tmpDirMin, cpuMax, cpuMin, tmpDirMax, outDirMin, memoryMin, outDirMax; [2018-05-02 15:23:00,78] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2m9fa3ab92[0mget_parallel_regions:NA:1]: [38;5;5m'bcbio_nextgen.py' 'runfn' 'get_parallel_regions' 'cwl' 'sentinel_runtime=cores,1,ram,3839.9999999999995' 'sentinel_parallel=batch-split' 'sentinel_outputs=region_block' 'sentinel_inputs=batch_rec:record'[0m; [2018-05-02 15:23:00,79] [info] DispatchedConfigAsyncJobExecutionAc",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386387039
https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386406902:28,Deployability,configurat,configuration,28,"Could you post the Cromwell configuration you're using ? Are the samples you're using relatively large?; I'm just wild guessing but one option would be that Cromwell is spending a lot of time trying to calculate md5 hashes for input files.; There's a configuration option to use file paths instead of file content to determine file equivalence for call caching purposes.; If you can make the assumptions that files are immutable and you don't go back and change their content manually this can be something to try.; To try that, you can update your Cromwell configuration: in the `backend.providers.SLURM.config` section (or whatever your backend is named instead of `SLURM`), and add this:; `filesystems.local.caching.hashing-strategy=""path""`; and this; `filesystems.local.caching.duplication-strategy=[""soft-link""]`. If possible I'd also recommend using a MySql DB instead of file based HSQL.; There are instructions here on how to do that in a few lines: http://cromwell.readthedocs.io/en/develop/tutorials/PersistentServer/#lets-get-started. Let me know if that makes any difference :)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386406902
https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386406902:251,Deployability,configurat,configuration,251,"Could you post the Cromwell configuration you're using ? Are the samples you're using relatively large?; I'm just wild guessing but one option would be that Cromwell is spending a lot of time trying to calculate md5 hashes for input files.; There's a configuration option to use file paths instead of file content to determine file equivalence for call caching purposes.; If you can make the assumptions that files are immutable and you don't go back and change their content manually this can be something to try.; To try that, you can update your Cromwell configuration: in the `backend.providers.SLURM.config` section (or whatever your backend is named instead of `SLURM`), and add this:; `filesystems.local.caching.hashing-strategy=""path""`; and this; `filesystems.local.caching.duplication-strategy=[""soft-link""]`. If possible I'd also recommend using a MySql DB instead of file based HSQL.; There are instructions here on how to do that in a few lines: http://cromwell.readthedocs.io/en/develop/tutorials/PersistentServer/#lets-get-started. Let me know if that makes any difference :)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386406902
https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386406902:537,Deployability,update,update,537,"Could you post the Cromwell configuration you're using ? Are the samples you're using relatively large?; I'm just wild guessing but one option would be that Cromwell is spending a lot of time trying to calculate md5 hashes for input files.; There's a configuration option to use file paths instead of file content to determine file equivalence for call caching purposes.; If you can make the assumptions that files are immutable and you don't go back and change their content manually this can be something to try.; To try that, you can update your Cromwell configuration: in the `backend.providers.SLURM.config` section (or whatever your backend is named instead of `SLURM`), and add this:; `filesystems.local.caching.hashing-strategy=""path""`; and this; `filesystems.local.caching.duplication-strategy=[""soft-link""]`. If possible I'd also recommend using a MySql DB instead of file based HSQL.; There are instructions here on how to do that in a few lines: http://cromwell.readthedocs.io/en/develop/tutorials/PersistentServer/#lets-get-started. Let me know if that makes any difference :)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386406902
https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386406902:558,Deployability,configurat,configuration,558,"Could you post the Cromwell configuration you're using ? Are the samples you're using relatively large?; I'm just wild guessing but one option would be that Cromwell is spending a lot of time trying to calculate md5 hashes for input files.; There's a configuration option to use file paths instead of file content to determine file equivalence for call caching purposes.; If you can make the assumptions that files are immutable and you don't go back and change their content manually this can be something to try.; To try that, you can update your Cromwell configuration: in the `backend.providers.SLURM.config` section (or whatever your backend is named instead of `SLURM`), and add this:; `filesystems.local.caching.hashing-strategy=""path""`; and this; `filesystems.local.caching.duplication-strategy=[""soft-link""]`. If possible I'd also recommend using a MySql DB instead of file based HSQL.; There are instructions here on how to do that in a few lines: http://cromwell.readthedocs.io/en/develop/tutorials/PersistentServer/#lets-get-started. Let me know if that makes any difference :)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386406902
https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386406902:28,Modifiability,config,configuration,28,"Could you post the Cromwell configuration you're using ? Are the samples you're using relatively large?; I'm just wild guessing but one option would be that Cromwell is spending a lot of time trying to calculate md5 hashes for input files.; There's a configuration option to use file paths instead of file content to determine file equivalence for call caching purposes.; If you can make the assumptions that files are immutable and you don't go back and change their content manually this can be something to try.; To try that, you can update your Cromwell configuration: in the `backend.providers.SLURM.config` section (or whatever your backend is named instead of `SLURM`), and add this:; `filesystems.local.caching.hashing-strategy=""path""`; and this; `filesystems.local.caching.duplication-strategy=[""soft-link""]`. If possible I'd also recommend using a MySql DB instead of file based HSQL.; There are instructions here on how to do that in a few lines: http://cromwell.readthedocs.io/en/develop/tutorials/PersistentServer/#lets-get-started. Let me know if that makes any difference :)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386406902
https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386406902:251,Modifiability,config,configuration,251,"Could you post the Cromwell configuration you're using ? Are the samples you're using relatively large?; I'm just wild guessing but one option would be that Cromwell is spending a lot of time trying to calculate md5 hashes for input files.; There's a configuration option to use file paths instead of file content to determine file equivalence for call caching purposes.; If you can make the assumptions that files are immutable and you don't go back and change their content manually this can be something to try.; To try that, you can update your Cromwell configuration: in the `backend.providers.SLURM.config` section (or whatever your backend is named instead of `SLURM`), and add this:; `filesystems.local.caching.hashing-strategy=""path""`; and this; `filesystems.local.caching.duplication-strategy=[""soft-link""]`. If possible I'd also recommend using a MySql DB instead of file based HSQL.; There are instructions here on how to do that in a few lines: http://cromwell.readthedocs.io/en/develop/tutorials/PersistentServer/#lets-get-started. Let me know if that makes any difference :)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386406902
https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386406902:558,Modifiability,config,configuration,558,"Could you post the Cromwell configuration you're using ? Are the samples you're using relatively large?; I'm just wild guessing but one option would be that Cromwell is spending a lot of time trying to calculate md5 hashes for input files.; There's a configuration option to use file paths instead of file content to determine file equivalence for call caching purposes.; If you can make the assumptions that files are immutable and you don't go back and change their content manually this can be something to try.; To try that, you can update your Cromwell configuration: in the `backend.providers.SLURM.config` section (or whatever your backend is named instead of `SLURM`), and add this:; `filesystems.local.caching.hashing-strategy=""path""`; and this; `filesystems.local.caching.duplication-strategy=[""soft-link""]`. If possible I'd also recommend using a MySql DB instead of file based HSQL.; There are instructions here on how to do that in a few lines: http://cromwell.readthedocs.io/en/develop/tutorials/PersistentServer/#lets-get-started. Let me know if that makes any difference :)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386406902
https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386406902:605,Modifiability,config,config,605,"Could you post the Cromwell configuration you're using ? Are the samples you're using relatively large?; I'm just wild guessing but one option would be that Cromwell is spending a lot of time trying to calculate md5 hashes for input files.; There's a configuration option to use file paths instead of file content to determine file equivalence for call caching purposes.; If you can make the assumptions that files are immutable and you don't go back and change their content manually this can be something to try.; To try that, you can update your Cromwell configuration: in the `backend.providers.SLURM.config` section (or whatever your backend is named instead of `SLURM`), and add this:; `filesystems.local.caching.hashing-strategy=""path""`; and this; `filesystems.local.caching.duplication-strategy=[""soft-link""]`. If possible I'd also recommend using a MySql DB instead of file based HSQL.; There are instructions here on how to do that in a few lines: http://cromwell.readthedocs.io/en/develop/tutorials/PersistentServer/#lets-get-started. Let me know if that makes any difference :)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386406902
https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386406902:216,Security,hash,hashes,216,"Could you post the Cromwell configuration you're using ? Are the samples you're using relatively large?; I'm just wild guessing but one option would be that Cromwell is spending a lot of time trying to calculate md5 hashes for input files.; There's a configuration option to use file paths instead of file content to determine file equivalence for call caching purposes.; If you can make the assumptions that files are immutable and you don't go back and change their content manually this can be something to try.; To try that, you can update your Cromwell configuration: in the `backend.providers.SLURM.config` section (or whatever your backend is named instead of `SLURM`), and add this:; `filesystems.local.caching.hashing-strategy=""path""`; and this; `filesystems.local.caching.duplication-strategy=[""soft-link""]`. If possible I'd also recommend using a MySql DB instead of file based HSQL.; There are instructions here on how to do that in a few lines: http://cromwell.readthedocs.io/en/develop/tutorials/PersistentServer/#lets-get-started. Let me know if that makes any difference :)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386406902
https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386406902:719,Security,hash,hashing-strategy,719,"Could you post the Cromwell configuration you're using ? Are the samples you're using relatively large?; I'm just wild guessing but one option would be that Cromwell is spending a lot of time trying to calculate md5 hashes for input files.; There's a configuration option to use file paths instead of file content to determine file equivalence for call caching purposes.; If you can make the assumptions that files are immutable and you don't go back and change their content manually this can be something to try.; To try that, you can update your Cromwell configuration: in the `backend.providers.SLURM.config` section (or whatever your backend is named instead of `SLURM`), and add this:; `filesystems.local.caching.hashing-strategy=""path""`; and this; `filesystems.local.caching.duplication-strategy=[""soft-link""]`. If possible I'd also recommend using a MySql DB instead of file based HSQL.; There are instructions here on how to do that in a few lines: http://cromwell.readthedocs.io/en/develop/tutorials/PersistentServer/#lets-get-started. Let me know if that makes any difference :)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386406902
https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386666743:145,Availability,error,error,145,"Thanks so much for the pointer to the hashing and details about adjusting that. You're exactly right that was what was happening. I saw the hash error and saw no new jobs launched, thought it had failed, so must have stopped the tasks before they finished the md5 summing and continued. I ran our analysis both with md5 checksumming and path based hashing, and it does save some time. The md5 based one took 6:43 and path based was 5:55. Doing based on paths works great for us so I'll swap to that as the default in bcbio pipelines. For database storage, are their known deficiencies with file based HSQL over MySQL? Do I have ways to mitigate those through different settings? We're planning to use MySQL in some circumstances but for providing something generally for users the file-based database will be the default and I'd like to make that as good and error free as possible. Is leaving this open for the `null` hash issue worthwhile? I also got some other hash errors on a different run that didn't affect completion but might be influencing re-use and storage that I could raise an issue on, but might be due to file based storage. If there are general things I can tweak and test I can do that first prior to opening additional issues. Thank you again for the help.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386666743
https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386666743:859,Availability,error,error,859,"Thanks so much for the pointer to the hashing and details about adjusting that. You're exactly right that was what was happening. I saw the hash error and saw no new jobs launched, thought it had failed, so must have stopped the tasks before they finished the md5 summing and continued. I ran our analysis both with md5 checksumming and path based hashing, and it does save some time. The md5 based one took 6:43 and path based was 5:55. Doing based on paths works great for us so I'll swap to that as the default in bcbio pipelines. For database storage, are their known deficiencies with file based HSQL over MySQL? Do I have ways to mitigate those through different settings? We're planning to use MySQL in some circumstances but for providing something generally for users the file-based database will be the default and I'd like to make that as good and error free as possible. Is leaving this open for the `null` hash issue worthwhile? I also got some other hash errors on a different run that didn't affect completion but might be influencing re-use and storage that I could raise an issue on, but might be due to file based storage. If there are general things I can tweak and test I can do that first prior to opening additional issues. Thank you again for the help.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386666743
https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386666743:969,Availability,error,errors,969,"Thanks so much for the pointer to the hashing and details about adjusting that. You're exactly right that was what was happening. I saw the hash error and saw no new jobs launched, thought it had failed, so must have stopped the tasks before they finished the md5 summing and continued. I ran our analysis both with md5 checksumming and path based hashing, and it does save some time. The md5 based one took 6:43 and path based was 5:55. Doing based on paths works great for us so I'll swap to that as the default in bcbio pipelines. For database storage, are their known deficiencies with file based HSQL over MySQL? Do I have ways to mitigate those through different settings? We're planning to use MySQL in some circumstances but for providing something generally for users the file-based database will be the default and I'd like to make that as good and error free as possible. Is leaving this open for the `null` hash issue worthwhile? I also got some other hash errors on a different run that didn't affect completion but might be influencing re-use and storage that I could raise an issue on, but might be due to file based storage. If there are general things I can tweak and test I can do that first prior to opening additional issues. Thank you again for the help.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386666743
https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386666743:523,Deployability,pipeline,pipelines,523,"Thanks so much for the pointer to the hashing and details about adjusting that. You're exactly right that was what was happening. I saw the hash error and saw no new jobs launched, thought it had failed, so must have stopped the tasks before they finished the md5 summing and continued. I ran our analysis both with md5 checksumming and path based hashing, and it does save some time. The md5 based one took 6:43 and path based was 5:55. Doing based on paths works great for us so I'll swap to that as the default in bcbio pipelines. For database storage, are their known deficiencies with file based HSQL over MySQL? Do I have ways to mitigate those through different settings? We're planning to use MySQL in some circumstances but for providing something generally for users the file-based database will be the default and I'd like to make that as good and error free as possible. Is leaving this open for the `null` hash issue worthwhile? I also got some other hash errors on a different run that didn't affect completion but might be influencing re-use and storage that I could raise an issue on, but might be due to file based storage. If there are general things I can tweak and test I can do that first prior to opening additional issues. Thank you again for the help.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386666743
https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386666743:38,Security,hash,hashing,38,"Thanks so much for the pointer to the hashing and details about adjusting that. You're exactly right that was what was happening. I saw the hash error and saw no new jobs launched, thought it had failed, so must have stopped the tasks before they finished the md5 summing and continued. I ran our analysis both with md5 checksumming and path based hashing, and it does save some time. The md5 based one took 6:43 and path based was 5:55. Doing based on paths works great for us so I'll swap to that as the default in bcbio pipelines. For database storage, are their known deficiencies with file based HSQL over MySQL? Do I have ways to mitigate those through different settings? We're planning to use MySQL in some circumstances but for providing something generally for users the file-based database will be the default and I'd like to make that as good and error free as possible. Is leaving this open for the `null` hash issue worthwhile? I also got some other hash errors on a different run that didn't affect completion but might be influencing re-use and storage that I could raise an issue on, but might be due to file based storage. If there are general things I can tweak and test I can do that first prior to opening additional issues. Thank you again for the help.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386666743
https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386666743:140,Security,hash,hash,140,"Thanks so much for the pointer to the hashing and details about adjusting that. You're exactly right that was what was happening. I saw the hash error and saw no new jobs launched, thought it had failed, so must have stopped the tasks before they finished the md5 summing and continued. I ran our analysis both with md5 checksumming and path based hashing, and it does save some time. The md5 based one took 6:43 and path based was 5:55. Doing based on paths works great for us so I'll swap to that as the default in bcbio pipelines. For database storage, are their known deficiencies with file based HSQL over MySQL? Do I have ways to mitigate those through different settings? We're planning to use MySQL in some circumstances but for providing something generally for users the file-based database will be the default and I'd like to make that as good and error free as possible. Is leaving this open for the `null` hash issue worthwhile? I also got some other hash errors on a different run that didn't affect completion but might be influencing re-use and storage that I could raise an issue on, but might be due to file based storage. If there are general things I can tweak and test I can do that first prior to opening additional issues. Thank you again for the help.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386666743
https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386666743:320,Security,checksum,checksumming,320,"Thanks so much for the pointer to the hashing and details about adjusting that. You're exactly right that was what was happening. I saw the hash error and saw no new jobs launched, thought it had failed, so must have stopped the tasks before they finished the md5 summing and continued. I ran our analysis both with md5 checksumming and path based hashing, and it does save some time. The md5 based one took 6:43 and path based was 5:55. Doing based on paths works great for us so I'll swap to that as the default in bcbio pipelines. For database storage, are their known deficiencies with file based HSQL over MySQL? Do I have ways to mitigate those through different settings? We're planning to use MySQL in some circumstances but for providing something generally for users the file-based database will be the default and I'd like to make that as good and error free as possible. Is leaving this open for the `null` hash issue worthwhile? I also got some other hash errors on a different run that didn't affect completion but might be influencing re-use and storage that I could raise an issue on, but might be due to file based storage. If there are general things I can tweak and test I can do that first prior to opening additional issues. Thank you again for the help.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386666743
https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386666743:348,Security,hash,hashing,348,"Thanks so much for the pointer to the hashing and details about adjusting that. You're exactly right that was what was happening. I saw the hash error and saw no new jobs launched, thought it had failed, so must have stopped the tasks before they finished the md5 summing and continued. I ran our analysis both with md5 checksumming and path based hashing, and it does save some time. The md5 based one took 6:43 and path based was 5:55. Doing based on paths works great for us so I'll swap to that as the default in bcbio pipelines. For database storage, are their known deficiencies with file based HSQL over MySQL? Do I have ways to mitigate those through different settings? We're planning to use MySQL in some circumstances but for providing something generally for users the file-based database will be the default and I'd like to make that as good and error free as possible. Is leaving this open for the `null` hash issue worthwhile? I also got some other hash errors on a different run that didn't affect completion but might be influencing re-use and storage that I could raise an issue on, but might be due to file based storage. If there are general things I can tweak and test I can do that first prior to opening additional issues. Thank you again for the help.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386666743
https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386666743:919,Security,hash,hash,919,"Thanks so much for the pointer to the hashing and details about adjusting that. You're exactly right that was what was happening. I saw the hash error and saw no new jobs launched, thought it had failed, so must have stopped the tasks before they finished the md5 summing and continued. I ran our analysis both with md5 checksumming and path based hashing, and it does save some time. The md5 based one took 6:43 and path based was 5:55. Doing based on paths works great for us so I'll swap to that as the default in bcbio pipelines. For database storage, are their known deficiencies with file based HSQL over MySQL? Do I have ways to mitigate those through different settings? We're planning to use MySQL in some circumstances but for providing something generally for users the file-based database will be the default and I'd like to make that as good and error free as possible. Is leaving this open for the `null` hash issue worthwhile? I also got some other hash errors on a different run that didn't affect completion but might be influencing re-use and storage that I could raise an issue on, but might be due to file based storage. If there are general things I can tweak and test I can do that first prior to opening additional issues. Thank you again for the help.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386666743
https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386666743:964,Security,hash,hash,964,"Thanks so much for the pointer to the hashing and details about adjusting that. You're exactly right that was what was happening. I saw the hash error and saw no new jobs launched, thought it had failed, so must have stopped the tasks before they finished the md5 summing and continued. I ran our analysis both with md5 checksumming and path based hashing, and it does save some time. The md5 based one took 6:43 and path based was 5:55. Doing based on paths works great for us so I'll swap to that as the default in bcbio pipelines. For database storage, are their known deficiencies with file based HSQL over MySQL? Do I have ways to mitigate those through different settings? We're planning to use MySQL in some circumstances but for providing something generally for users the file-based database will be the default and I'd like to make that as good and error free as possible. Is leaving this open for the `null` hash issue worthwhile? I also got some other hash errors on a different run that didn't affect completion but might be influencing re-use and storage that I could raise an issue on, but might be due to file based storage. If there are general things I can tweak and test I can do that first prior to opening additional issues. Thank you again for the help.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386666743
https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386666743:1185,Testability,test,test,1185,"Thanks so much for the pointer to the hashing and details about adjusting that. You're exactly right that was what was happening. I saw the hash error and saw no new jobs launched, thought it had failed, so must have stopped the tasks before they finished the md5 summing and continued. I ran our analysis both with md5 checksumming and path based hashing, and it does save some time. The md5 based one took 6:43 and path based was 5:55. Doing based on paths works great for us so I'll swap to that as the default in bcbio pipelines. For database storage, are their known deficiencies with file based HSQL over MySQL? Do I have ways to mitigate those through different settings? We're planning to use MySQL in some circumstances but for providing something generally for users the file-based database will be the default and I'd like to make that as good and error free as possible. Is leaving this open for the `null` hash issue worthwhile? I also got some other hash errors on a different run that didn't affect completion but might be influencing re-use and storage that I could raise an issue on, but might be due to file based storage. If there are general things I can tweak and test I can do that first prior to opening additional issues. Thank you again for the help.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386666743
https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386700970:185,Performance,perform,performs,185,"Glad that helped !; Regarding HSQL vs MySQL, the main reason is that we've rarely used HSQL and there may be some corner cases that we don't support (and don't know about); It probably performs better too on the long run as your DB grows.; But it's definitely good to have some feedback on how Cromwell behaves with HSQL too.; For the `null` hash, something weird is going on so I'd keep the issue open. If it's not immediately blocking you anymore it might get slightly de-prioritized but we'll definitely look into it.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386700970
https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386700970:342,Security,hash,hash,342,"Glad that helped !; Regarding HSQL vs MySQL, the main reason is that we've rarely used HSQL and there may be some corner cases that we don't support (and don't know about); It probably performs better too on the long run as your DB grows.; But it's definitely good to have some feedback on how Cromwell behaves with HSQL too.; For the `null` hash, something weird is going on so I'd keep the issue open. If it's not immediately blocking you anymore it might get slightly de-prioritized but we'll definitely look into it.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386700970
https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386700970:278,Usability,feedback,feedback,278,"Glad that helped !; Regarding HSQL vs MySQL, the main reason is that we've rarely used HSQL and there may be some corner cases that we don't support (and don't know about); It probably performs better too on the long run as your DB grows.; But it's definitely good to have some feedback on how Cromwell behaves with HSQL too.; For the `null` hash, something weird is going on so I'd keep the issue open. If it's not immediately blocking you anymore it might get slightly de-prioritized but we'll definitely look into it.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386700970
https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-387799021:378,Availability,error,errors,378,Thanks again for looking into the null hash issue. I unfortunately don't have a small reproducible case but have a larger case that seems to always hit this problem if the traceback isn't enough information to debug. It's the `somatic-giab-mix` CWL validation set from here:. https://github.com/bcbio/bcbio_validation_workflows#somatic-genome-in-a-bottle-mixture. and the first errors start to occur ~2hr into the run. Sorry this isn't a minimal case but hope it's useful when you have an opportunity to look into it.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-387799021
https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-387799021:39,Security,hash,hash,39,Thanks again for looking into the null hash issue. I unfortunately don't have a small reproducible case but have a larger case that seems to always hit this problem if the traceback isn't enough information to debug. It's the `somatic-giab-mix` CWL validation set from here:. https://github.com/bcbio/bcbio_validation_workflows#somatic-genome-in-a-bottle-mixture. and the first errors start to occur ~2hr into the run. Sorry this isn't a minimal case but hope it's useful when you have an opportunity to look into it.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-387799021
https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-387799021:249,Security,validat,validation,249,Thanks again for looking into the null hash issue. I unfortunately don't have a small reproducible case but have a larger case that seems to always hit this problem if the traceback isn't enough information to debug. It's the `somatic-giab-mix` CWL validation set from here:. https://github.com/bcbio/bcbio_validation_workflows#somatic-genome-in-a-bottle-mixture. and the first errors start to occur ~2hr into the run. Sorry this isn't a minimal case but hope it's useful when you have an opportunity to look into it.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-387799021
https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-389918760:71,Availability,ERROR,ERROR,71,log from my run includes potentially useful information on the step. `[ERROR] [05/17/2018 15:47:23.959] [cromwell-system-akka.dispatchers.engine-dispatcher-48] [akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor/WorkflowActor-67f5112e-5c3d-4a03-9c78-97725bf0d9cf/WorkflowExecutionActor-67f5112e-5c3d-4a03-9c78-97725bf0d9cf/67f5112e-5c3d-4a03-9c78-97725bf0d9cf-EngineJobExecutionActor-batch_for_variantcall:NA:1/ejha_for_67f5112e-5c3d-4a03-9c78-97725bf0d9cf:BackendJobDescriptorKey_CommandCallNode_batch_for_variantcall:-1:1/CCHashingJobActor-67f5112e-batch_for_variantcall:NA:1] Failed to hash null`,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-389918760
https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-389918760:613,Security,hash,hash,613,log from my run includes potentially useful information on the step. `[ERROR] [05/17/2018 15:47:23.959] [cromwell-system-akka.dispatchers.engine-dispatcher-48] [akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor/WorkflowActor-67f5112e-5c3d-4a03-9c78-97725bf0d9cf/WorkflowExecutionActor-67f5112e-5c3d-4a03-9c78-97725bf0d9cf/67f5112e-5c3d-4a03-9c78-97725bf0d9cf-EngineJobExecutionActor-batch_for_variantcall:NA:1/ejha_for_67f5112e-5c3d-4a03-9c78-97725bf0d9cf:BackendJobDescriptorKey_CommandCallNode_batch_for_variantcall:-1:1/CCHashingJobActor-67f5112e-batch_for_variantcall:NA:1] Failed to hash null`,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-389918760
https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-389918760:0,Testability,log,log,0,log from my run includes potentially useful information on the step. `[ERROR] [05/17/2018 15:47:23.959] [cromwell-system-akka.dispatchers.engine-dispatcher-48] [akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor/WorkflowActor-67f5112e-5c3d-4a03-9c78-97725bf0d9cf/WorkflowExecutionActor-67f5112e-5c3d-4a03-9c78-97725bf0d9cf/67f5112e-5c3d-4a03-9c78-97725bf0d9cf-EngineJobExecutionActor-batch_for_variantcall:NA:1/ejha_for_67f5112e-5c3d-4a03-9c78-97725bf0d9cf:BackendJobDescriptorKey_CommandCallNode_batch_for_variantcall:-1:1/CCHashingJobActor-67f5112e-batch_for_variantcall:NA:1] Failed to hash null`,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-389918760
https://github.com/broadinstitute/cromwell/pull/3601#issuecomment-387452833:63,Deployability,upgrade,upgrade,63,"ToL:. Looking at this, I wonder whether an easier route to the upgrade script is to make another implementation of this `WdlWriter` typeclass for draft 2 `WdlNamespace`. It leaves us further away from funneling draft 2 and draft 3 through the same object mode (and the massive code deletion we'd get from that)l, but it might be a much more expedient (and maybe safer?) way of achieving the upgrade script?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3601#issuecomment-387452833
https://github.com/broadinstitute/cromwell/pull/3601#issuecomment-387452833:391,Deployability,upgrade,upgrade,391,"ToL:. Looking at this, I wonder whether an easier route to the upgrade script is to make another implementation of this `WdlWriter` typeclass for draft 2 `WdlNamespace`. It leaves us further away from funneling draft 2 and draft 3 through the same object mode (and the massive code deletion we'd get from that)l, but it might be a much more expedient (and maybe safer?) way of achieving the upgrade script?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3601#issuecomment-387452833
https://github.com/broadinstitute/cromwell/pull/3601#issuecomment-387452833:50,Integrability,rout,route,50,"ToL:. Looking at this, I wonder whether an easier route to the upgrade script is to make another implementation of this `WdlWriter` typeclass for draft 2 `WdlNamespace`. It leaves us further away from funneling draft 2 and draft 3 through the same object mode (and the massive code deletion we'd get from that)l, but it might be a much more expedient (and maybe safer?) way of achieving the upgrade script?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3601#issuecomment-387452833
https://github.com/broadinstitute/cromwell/pull/3601#issuecomment-387452833:362,Safety,safe,safer,362,"ToL:. Looking at this, I wonder whether an easier route to the upgrade script is to make another implementation of this `WdlWriter` typeclass for draft 2 `WdlNamespace`. It leaves us further away from funneling draft 2 and draft 3 through the same object mode (and the massive code deletion we'd get from that)l, but it might be a much more expedient (and maybe safer?) way of achieving the upgrade script?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3601#issuecomment-387452833
https://github.com/broadinstitute/cromwell/pull/3601#issuecomment-387500001:15,Integrability,message,message,15,"^^ that commit message is a lie, I accidentally accepted the default in IntelliJ. It's just about all of your change requests that hadn't spawned a question/discussion",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3601#issuecomment-387500001
https://github.com/broadinstitute/cromwell/issues/3607#issuecomment-387853025:104,Deployability,configurat,configuration,104,"@chapmanb Also can you explain what the different systems are? It looks like everyone is using the same configuration here, right?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3607#issuecomment-387853025
https://github.com/broadinstitute/cromwell/issues/3607#issuecomment-387853025:104,Modifiability,config,configuration,104,"@chapmanb Also can you explain what the different systems are? It looks like everyone is using the same configuration here, right?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3607#issuecomment-387853025
https://github.com/broadinstitute/cromwell/issues/3607#issuecomment-388827013:966,Availability,error,error,966,"Jeff;; Thanks so much for looking at this. I went back through my runs and realized it is only happening on a single filesystem, the `/n/groups` filesystem on orchestra2 at Harvard Medical School. The folks there were nice enough to let me know the details about the setup:. > /n/groups is NFSv3 being served from an EMC/Isilon fileserver:; > ; > alb15@login03:~$ mount | grep groups; > orchestra2-p05.med.harvard.edu:/ifs/systems/Orchestra/groups on /n/groups type; > nfs (rw,relatime,vers=3,rsize=131072,wsize=524288,namlen=255,hard,proto=; > tcp,timeo=600,retrans=2,sec=sys,mountaddr=10.120.41.64,mountvers=3,mountport=; > 300,mountproto=udp,local_lock=none,addr=10.120.41.64). Does anything in there help provide some clues to dig into it? Apologies, I'm fishing around in the dark with trying to provide useful information since I'm ignorant of both the magic of shared filesystem peculiarities and how that would impact Hsqldb here. All of my searches on this error have to do with database setups and older version of hsqldb so my Google debugging is not helping. Thanks again.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3607#issuecomment-388827013
https://github.com/broadinstitute/cromwell/issues/3607#issuecomment-389261690:332,Security,hash,hashing,332,"Jeff -- thanks for following up and confirming I wasn't missing anything. I realized I was testing on this system with a custom local build so swapped over to the pre-build conda package, and magically, the problem morphed into #3584. I'm very confused but don't think this is reproducible now so will close. Now only the null file hashing issue is causing trouble. Sorry for wasting your time looking at this and thanks again for all the help.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3607#issuecomment-389261690
https://github.com/broadinstitute/cromwell/issues/3607#issuecomment-389261690:91,Testability,test,testing,91,"Jeff -- thanks for following up and confirming I wasn't missing anything. I realized I was testing on this system with a custom local build so swapped over to the pre-build conda package, and magically, the problem morphed into #3584. I'm very confused but don't think this is reproducible now so will close. Now only the null file hashing issue is causing trouble. Sorry for wasting your time looking at this and thanks again for all the help.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3607#issuecomment-389261690
https://github.com/broadinstitute/cromwell/issues/3608#issuecomment-394418950:66,Performance,perform,perform,66,"@aednichols, @ruchim is correct, it's why the JMUI really doesn't perform well (Sometimes crashes) when thousands of workflows with subworkflows are submitted, because we do what you've described for filtering out subworkflows in a paginated way on the front end. This is the issue described in #3240. I appreciate the question though, although we have been making changes to cromwell API to support JMUI, it is worth thinking through each one and which team should be accommodating the use case.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3608#issuecomment-394418950
https://github.com/broadinstitute/cromwell/pull/3609#issuecomment-388126038:55,Availability,repair,repairs,55,This seems to have been broken by a rebase. Closed for repairs.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3609#issuecomment-388126038
https://github.com/broadinstitute/cromwell/issues/3615#issuecomment-390845973:395,Availability,failure,failure,395,"Hey @rexwangcc -- a requirement for any task to be considered a ""success"" is the generation of stdout/stderr log file. From my experience, I've seen in the past that when there's an intermittent docker issues, the ""docker logs"" (which include stdout/stderr) aren't copied out -- so even if some of the outputs produced by your task exist, the fact that stdout/stderr don't exist is considered a failure. I'm not sure we want to change this behavior as not being able to capture docker logs means not all task outputs were created, thus a failure. In cases like this, what will be helpful is an option to retry transient task failures (such as what you describe here), which is work in review [here](https://github.com/broadinstitute/cromwell/pull/3596). Let me know if there's something I'm misunderstanding here!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3615#issuecomment-390845973
https://github.com/broadinstitute/cromwell/issues/3615#issuecomment-390845973:538,Availability,failure,failure,538,"Hey @rexwangcc -- a requirement for any task to be considered a ""success"" is the generation of stdout/stderr log file. From my experience, I've seen in the past that when there's an intermittent docker issues, the ""docker logs"" (which include stdout/stderr) aren't copied out -- so even if some of the outputs produced by your task exist, the fact that stdout/stderr don't exist is considered a failure. I'm not sure we want to change this behavior as not being able to capture docker logs means not all task outputs were created, thus a failure. In cases like this, what will be helpful is an option to retry transient task failures (such as what you describe here), which is work in review [here](https://github.com/broadinstitute/cromwell/pull/3596). Let me know if there's something I'm misunderstanding here!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3615#issuecomment-390845973
https://github.com/broadinstitute/cromwell/issues/3615#issuecomment-390845973:625,Availability,failure,failures,625,"Hey @rexwangcc -- a requirement for any task to be considered a ""success"" is the generation of stdout/stderr log file. From my experience, I've seen in the past that when there's an intermittent docker issues, the ""docker logs"" (which include stdout/stderr) aren't copied out -- so even if some of the outputs produced by your task exist, the fact that stdout/stderr don't exist is considered a failure. I'm not sure we want to change this behavior as not being able to capture docker logs means not all task outputs were created, thus a failure. In cases like this, what will be helpful is an option to retry transient task failures (such as what you describe here), which is work in review [here](https://github.com/broadinstitute/cromwell/pull/3596). Let me know if there's something I'm misunderstanding here!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3615#issuecomment-390845973
https://github.com/broadinstitute/cromwell/issues/3615#issuecomment-390845973:109,Testability,log,log,109,"Hey @rexwangcc -- a requirement for any task to be considered a ""success"" is the generation of stdout/stderr log file. From my experience, I've seen in the past that when there's an intermittent docker issues, the ""docker logs"" (which include stdout/stderr) aren't copied out -- so even if some of the outputs produced by your task exist, the fact that stdout/stderr don't exist is considered a failure. I'm not sure we want to change this behavior as not being able to capture docker logs means not all task outputs were created, thus a failure. In cases like this, what will be helpful is an option to retry transient task failures (such as what you describe here), which is work in review [here](https://github.com/broadinstitute/cromwell/pull/3596). Let me know if there's something I'm misunderstanding here!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3615#issuecomment-390845973
https://github.com/broadinstitute/cromwell/issues/3615#issuecomment-390845973:222,Testability,log,logs,222,"Hey @rexwangcc -- a requirement for any task to be considered a ""success"" is the generation of stdout/stderr log file. From my experience, I've seen in the past that when there's an intermittent docker issues, the ""docker logs"" (which include stdout/stderr) aren't copied out -- so even if some of the outputs produced by your task exist, the fact that stdout/stderr don't exist is considered a failure. I'm not sure we want to change this behavior as not being able to capture docker logs means not all task outputs were created, thus a failure. In cases like this, what will be helpful is an option to retry transient task failures (such as what you describe here), which is work in review [here](https://github.com/broadinstitute/cromwell/pull/3596). Let me know if there's something I'm misunderstanding here!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3615#issuecomment-390845973
https://github.com/broadinstitute/cromwell/issues/3615#issuecomment-390845973:485,Testability,log,logs,485,"Hey @rexwangcc -- a requirement for any task to be considered a ""success"" is the generation of stdout/stderr log file. From my experience, I've seen in the past that when there's an intermittent docker issues, the ""docker logs"" (which include stdout/stderr) aren't copied out -- so even if some of the outputs produced by your task exist, the fact that stdout/stderr don't exist is considered a failure. I'm not sure we want to change this behavior as not being able to capture docker logs means not all task outputs were created, thus a failure. In cases like this, what will be helpful is an option to retry transient task failures (such as what you describe here), which is work in review [here](https://github.com/broadinstitute/cromwell/pull/3596). Let me know if there's something I'm misunderstanding here!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3615#issuecomment-390845973
https://github.com/broadinstitute/cromwell/issues/3615#issuecomment-390846376:127,Availability,failure,failures,127,"@ruchim Thank you very much for the help and explanation here, they look great to me! @jishuxu a follow up for one of your the failures you ran into previously.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3615#issuecomment-390846376
https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388871590:600,Availability,down,downsampled,600,"My JSON file:. {; ""CNVSomaticPairWorkflow.common_sites"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/common_snps_sample-chr20.interval_list"",; ""CNVSomaticPairWorkflow.gatk_docker"": ""8f0ef5140437"",; ""CNVSomaticPairWorkflow.intervals"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/chr20.interval_list"",; ""CNVSomaticPairWorkflow.normal_bam"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143_BL-n1-chr20-downsampled.deduplicated.bam"",; ""CNVSomaticPairWorkflow.normal_bam_idx"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143_BL-n1-chr20-downsampled.deduplicated.bam.bai"",; ""CNVSomaticPairWorkflow.bin_length"": ""10000"",; ""CNVSomaticPairWorkflow.read_count_pon"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/wgs-no-gc.pon.hdf5"",; ""CNVSomaticPairWorkflow.ref_fasta_dict"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/human_g1k_v37.chr-20.truncated.dict"",; ""CNVSomaticPairWorkflow.ref_fasta_fai"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/human_g1k_v37.chr-20.truncated.fasta.fai"",; ""CNVSomaticPairWorkflow.ref_fasta"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/human_g1k_v37.chr-20.truncated.fasta"",; ""CNVSomaticPairWorkflow.tumor_bam"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143-t1-chr20-downsampled.deduplicated.bam"",; ""CNVSomaticPairWorkflow.tumor_bam_idx"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143-t1-chr20-downsample",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388871590
https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388871590:803,Availability,down,downsampled,803,"My JSON file:. {; ""CNVSomaticPairWorkflow.common_sites"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/common_snps_sample-chr20.interval_list"",; ""CNVSomaticPairWorkflow.gatk_docker"": ""8f0ef5140437"",; ""CNVSomaticPairWorkflow.intervals"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/chr20.interval_list"",; ""CNVSomaticPairWorkflow.normal_bam"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143_BL-n1-chr20-downsampled.deduplicated.bam"",; ""CNVSomaticPairWorkflow.normal_bam_idx"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143_BL-n1-chr20-downsampled.deduplicated.bam.bai"",; ""CNVSomaticPairWorkflow.bin_length"": ""10000"",; ""CNVSomaticPairWorkflow.read_count_pon"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/wgs-no-gc.pon.hdf5"",; ""CNVSomaticPairWorkflow.ref_fasta_dict"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/human_g1k_v37.chr-20.truncated.dict"",; ""CNVSomaticPairWorkflow.ref_fasta_fai"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/human_g1k_v37.chr-20.truncated.fasta.fai"",; ""CNVSomaticPairWorkflow.ref_fasta"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/human_g1k_v37.chr-20.truncated.fasta"",; ""CNVSomaticPairWorkflow.tumor_bam"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143-t1-chr20-downsampled.deduplicated.bam"",; ""CNVSomaticPairWorkflow.tumor_bam_idx"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143-t1-chr20-downsample",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388871590
https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388871590:1792,Availability,down,downsampled,1792,"orkflows_test_files/common_snps_sample-chr20.interval_list"",; ""CNVSomaticPairWorkflow.gatk_docker"": ""8f0ef5140437"",; ""CNVSomaticPairWorkflow.intervals"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/chr20.interval_list"",; ""CNVSomaticPairWorkflow.normal_bam"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143_BL-n1-chr20-downsampled.deduplicated.bam"",; ""CNVSomaticPairWorkflow.normal_bam_idx"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143_BL-n1-chr20-downsampled.deduplicated.bam.bai"",; ""CNVSomaticPairWorkflow.bin_length"": ""10000"",; ""CNVSomaticPairWorkflow.read_count_pon"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/wgs-no-gc.pon.hdf5"",; ""CNVSomaticPairWorkflow.ref_fasta_dict"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/human_g1k_v37.chr-20.truncated.dict"",; ""CNVSomaticPairWorkflow.ref_fasta_fai"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/human_g1k_v37.chr-20.truncated.fasta.fai"",; ""CNVSomaticPairWorkflow.ref_fasta"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/human_g1k_v37.chr-20.truncated.fasta"",; ""CNVSomaticPairWorkflow.tumor_bam"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143-t1-chr20-downsampled.deduplicated.bam"",; ""CNVSomaticPairWorkflow.tumor_bam_idx"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143-t1-chr20-downsampled.deduplicated.bam.bai"",; ""CNVSomaticPairWorkflow.gatk4_jar_override"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/build/libs/gatk.jar""; }",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388871590
https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388871590:1991,Availability,down,downsampled,1991,"orkflows_test_files/common_snps_sample-chr20.interval_list"",; ""CNVSomaticPairWorkflow.gatk_docker"": ""8f0ef5140437"",; ""CNVSomaticPairWorkflow.intervals"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/chr20.interval_list"",; ""CNVSomaticPairWorkflow.normal_bam"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143_BL-n1-chr20-downsampled.deduplicated.bam"",; ""CNVSomaticPairWorkflow.normal_bam_idx"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143_BL-n1-chr20-downsampled.deduplicated.bam.bai"",; ""CNVSomaticPairWorkflow.bin_length"": ""10000"",; ""CNVSomaticPairWorkflow.read_count_pon"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/wgs-no-gc.pon.hdf5"",; ""CNVSomaticPairWorkflow.ref_fasta_dict"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/human_g1k_v37.chr-20.truncated.dict"",; ""CNVSomaticPairWorkflow.ref_fasta_fai"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/human_g1k_v37.chr-20.truncated.fasta.fai"",; ""CNVSomaticPairWorkflow.ref_fasta"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/human_g1k_v37.chr-20.truncated.fasta"",; ""CNVSomaticPairWorkflow.tumor_bam"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143-t1-chr20-downsampled.deduplicated.bam"",; ""CNVSomaticPairWorkflow.tumor_bam_idx"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143-t1-chr20-downsampled.deduplicated.bam.bai"",; ""CNVSomaticPairWorkflow.gatk4_jar_override"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/build/libs/gatk.jar""; }",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388871590
https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388871590:113,Testability,test,test,113,"My JSON file:. {; ""CNVSomaticPairWorkflow.common_sites"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/common_snps_sample-chr20.interval_list"",; ""CNVSomaticPairWorkflow.gatk_docker"": ""8f0ef5140437"",; ""CNVSomaticPairWorkflow.intervals"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/chr20.interval_list"",; ""CNVSomaticPairWorkflow.normal_bam"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143_BL-n1-chr20-downsampled.deduplicated.bam"",; ""CNVSomaticPairWorkflow.normal_bam_idx"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143_BL-n1-chr20-downsampled.deduplicated.bam.bai"",; ""CNVSomaticPairWorkflow.bin_length"": ""10000"",; ""CNVSomaticPairWorkflow.read_count_pon"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/wgs-no-gc.pon.hdf5"",; ""CNVSomaticPairWorkflow.ref_fasta_dict"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/human_g1k_v37.chr-20.truncated.dict"",; ""CNVSomaticPairWorkflow.ref_fasta_fai"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/human_g1k_v37.chr-20.truncated.fasta.fai"",; ""CNVSomaticPairWorkflow.ref_fasta"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/human_g1k_v37.chr-20.truncated.fasta"",; ""CNVSomaticPairWorkflow.tumor_bam"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143-t1-chr20-downsampled.deduplicated.bam"",; ""CNVSomaticPairWorkflow.tumor_bam_idx"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143-t1-chr20-downsample",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388871590
https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388871590:356,Testability,test,test,356,"My JSON file:. {; ""CNVSomaticPairWorkflow.common_sites"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/common_snps_sample-chr20.interval_list"",; ""CNVSomaticPairWorkflow.gatk_docker"": ""8f0ef5140437"",; ""CNVSomaticPairWorkflow.intervals"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/chr20.interval_list"",; ""CNVSomaticPairWorkflow.normal_bam"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143_BL-n1-chr20-downsampled.deduplicated.bam"",; ""CNVSomaticPairWorkflow.normal_bam_idx"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143_BL-n1-chr20-downsampled.deduplicated.bam.bai"",; ""CNVSomaticPairWorkflow.bin_length"": ""10000"",; ""CNVSomaticPairWorkflow.read_count_pon"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/wgs-no-gc.pon.hdf5"",; ""CNVSomaticPairWorkflow.ref_fasta_dict"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/human_g1k_v37.chr-20.truncated.dict"",; ""CNVSomaticPairWorkflow.ref_fasta_fai"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/human_g1k_v37.chr-20.truncated.fasta.fai"",; ""CNVSomaticPairWorkflow.ref_fasta"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/human_g1k_v37.chr-20.truncated.fasta"",; ""CNVSomaticPairWorkflow.tumor_bam"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143-t1-chr20-downsampled.deduplicated.bam"",; ""CNVSomaticPairWorkflow.tumor_bam_idx"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143-t1-chr20-downsample",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388871590
https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388871590:526,Testability,test,test,526,"My JSON file:. {; ""CNVSomaticPairWorkflow.common_sites"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/common_snps_sample-chr20.interval_list"",; ""CNVSomaticPairWorkflow.gatk_docker"": ""8f0ef5140437"",; ""CNVSomaticPairWorkflow.intervals"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/chr20.interval_list"",; ""CNVSomaticPairWorkflow.normal_bam"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143_BL-n1-chr20-downsampled.deduplicated.bam"",; ""CNVSomaticPairWorkflow.normal_bam_idx"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143_BL-n1-chr20-downsampled.deduplicated.bam.bai"",; ""CNVSomaticPairWorkflow.bin_length"": ""10000"",; ""CNVSomaticPairWorkflow.read_count_pon"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/wgs-no-gc.pon.hdf5"",; ""CNVSomaticPairWorkflow.ref_fasta_dict"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/human_g1k_v37.chr-20.truncated.dict"",; ""CNVSomaticPairWorkflow.ref_fasta_fai"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/human_g1k_v37.chr-20.truncated.fasta.fai"",; ""CNVSomaticPairWorkflow.ref_fasta"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/human_g1k_v37.chr-20.truncated.fasta"",; ""CNVSomaticPairWorkflow.tumor_bam"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143-t1-chr20-downsampled.deduplicated.bam"",; ""CNVSomaticPairWorkflow.tumor_bam_idx"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143-t1-chr20-downsample",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388871590
https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388871590:729,Testability,test,test,729,"My JSON file:. {; ""CNVSomaticPairWorkflow.common_sites"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/common_snps_sample-chr20.interval_list"",; ""CNVSomaticPairWorkflow.gatk_docker"": ""8f0ef5140437"",; ""CNVSomaticPairWorkflow.intervals"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/chr20.interval_list"",; ""CNVSomaticPairWorkflow.normal_bam"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143_BL-n1-chr20-downsampled.deduplicated.bam"",; ""CNVSomaticPairWorkflow.normal_bam_idx"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143_BL-n1-chr20-downsampled.deduplicated.bam.bai"",; ""CNVSomaticPairWorkflow.bin_length"": ""10000"",; ""CNVSomaticPairWorkflow.read_count_pon"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/wgs-no-gc.pon.hdf5"",; ""CNVSomaticPairWorkflow.ref_fasta_dict"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/human_g1k_v37.chr-20.truncated.dict"",; ""CNVSomaticPairWorkflow.ref_fasta_fai"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/human_g1k_v37.chr-20.truncated.fasta.fai"",; ""CNVSomaticPairWorkflow.ref_fasta"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/human_g1k_v37.chr-20.truncated.fasta"",; ""CNVSomaticPairWorkflow.tumor_bam"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143-t1-chr20-downsampled.deduplicated.bam"",; ""CNVSomaticPairWorkflow.tumor_bam_idx"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143-t1-chr20-downsample",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388871590
https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388871590:983,Testability,test,test,983,"My JSON file:. {; ""CNVSomaticPairWorkflow.common_sites"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/common_snps_sample-chr20.interval_list"",; ""CNVSomaticPairWorkflow.gatk_docker"": ""8f0ef5140437"",; ""CNVSomaticPairWorkflow.intervals"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/chr20.interval_list"",; ""CNVSomaticPairWorkflow.normal_bam"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143_BL-n1-chr20-downsampled.deduplicated.bam"",; ""CNVSomaticPairWorkflow.normal_bam_idx"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143_BL-n1-chr20-downsampled.deduplicated.bam.bai"",; ""CNVSomaticPairWorkflow.bin_length"": ""10000"",; ""CNVSomaticPairWorkflow.read_count_pon"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/wgs-no-gc.pon.hdf5"",; ""CNVSomaticPairWorkflow.ref_fasta_dict"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/human_g1k_v37.chr-20.truncated.dict"",; ""CNVSomaticPairWorkflow.ref_fasta_fai"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/human_g1k_v37.chr-20.truncated.fasta.fai"",; ""CNVSomaticPairWorkflow.ref_fasta"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/human_g1k_v37.chr-20.truncated.fasta"",; ""CNVSomaticPairWorkflow.tumor_bam"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143-t1-chr20-downsampled.deduplicated.bam"",; ""CNVSomaticPairWorkflow.tumor_bam_idx"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143-t1-chr20-downsample",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388871590
https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388871590:1156,Testability,test,test,1156,"orkflows_test_files/common_snps_sample-chr20.interval_list"",; ""CNVSomaticPairWorkflow.gatk_docker"": ""8f0ef5140437"",; ""CNVSomaticPairWorkflow.intervals"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/chr20.interval_list"",; ""CNVSomaticPairWorkflow.normal_bam"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143_BL-n1-chr20-downsampled.deduplicated.bam"",; ""CNVSomaticPairWorkflow.normal_bam_idx"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143_BL-n1-chr20-downsampled.deduplicated.bam.bai"",; ""CNVSomaticPairWorkflow.bin_length"": ""10000"",; ""CNVSomaticPairWorkflow.read_count_pon"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/wgs-no-gc.pon.hdf5"",; ""CNVSomaticPairWorkflow.ref_fasta_dict"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/human_g1k_v37.chr-20.truncated.dict"",; ""CNVSomaticPairWorkflow.ref_fasta_fai"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/human_g1k_v37.chr-20.truncated.fasta.fai"",; ""CNVSomaticPairWorkflow.ref_fasta"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/human_g1k_v37.chr-20.truncated.fasta"",; ""CNVSomaticPairWorkflow.tumor_bam"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143-t1-chr20-downsampled.deduplicated.bam"",; ""CNVSomaticPairWorkflow.tumor_bam_idx"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143-t1-chr20-downsampled.deduplicated.bam.bai"",; ""CNVSomaticPairWorkflow.gatk4_jar_override"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/build/libs/gatk.jar""; }",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388871590
https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388871590:1345,Testability,test,test,1345,"orkflows_test_files/common_snps_sample-chr20.interval_list"",; ""CNVSomaticPairWorkflow.gatk_docker"": ""8f0ef5140437"",; ""CNVSomaticPairWorkflow.intervals"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/chr20.interval_list"",; ""CNVSomaticPairWorkflow.normal_bam"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143_BL-n1-chr20-downsampled.deduplicated.bam"",; ""CNVSomaticPairWorkflow.normal_bam_idx"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143_BL-n1-chr20-downsampled.deduplicated.bam.bai"",; ""CNVSomaticPairWorkflow.bin_length"": ""10000"",; ""CNVSomaticPairWorkflow.read_count_pon"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/wgs-no-gc.pon.hdf5"",; ""CNVSomaticPairWorkflow.ref_fasta_dict"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/human_g1k_v37.chr-20.truncated.dict"",; ""CNVSomaticPairWorkflow.ref_fasta_fai"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/human_g1k_v37.chr-20.truncated.fasta.fai"",; ""CNVSomaticPairWorkflow.ref_fasta"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/human_g1k_v37.chr-20.truncated.fasta"",; ""CNVSomaticPairWorkflow.tumor_bam"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143-t1-chr20-downsampled.deduplicated.bam"",; ""CNVSomaticPairWorkflow.tumor_bam_idx"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143-t1-chr20-downsampled.deduplicated.bam.bai"",; ""CNVSomaticPairWorkflow.gatk4_jar_override"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/build/libs/gatk.jar""; }",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388871590
https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388871590:1535,Testability,test,test,1535,"orkflows_test_files/common_snps_sample-chr20.interval_list"",; ""CNVSomaticPairWorkflow.gatk_docker"": ""8f0ef5140437"",; ""CNVSomaticPairWorkflow.intervals"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/chr20.interval_list"",; ""CNVSomaticPairWorkflow.normal_bam"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143_BL-n1-chr20-downsampled.deduplicated.bam"",; ""CNVSomaticPairWorkflow.normal_bam_idx"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143_BL-n1-chr20-downsampled.deduplicated.bam.bai"",; ""CNVSomaticPairWorkflow.bin_length"": ""10000"",; ""CNVSomaticPairWorkflow.read_count_pon"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/wgs-no-gc.pon.hdf5"",; ""CNVSomaticPairWorkflow.ref_fasta_dict"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/human_g1k_v37.chr-20.truncated.dict"",; ""CNVSomaticPairWorkflow.ref_fasta_fai"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/human_g1k_v37.chr-20.truncated.fasta.fai"",; ""CNVSomaticPairWorkflow.ref_fasta"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/human_g1k_v37.chr-20.truncated.fasta"",; ""CNVSomaticPairWorkflow.tumor_bam"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143-t1-chr20-downsampled.deduplicated.bam"",; ""CNVSomaticPairWorkflow.tumor_bam_idx"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143-t1-chr20-downsampled.deduplicated.bam.bai"",; ""CNVSomaticPairWorkflow.gatk4_jar_override"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/build/libs/gatk.jar""; }",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388871590
https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388871590:1721,Testability,test,test,1721,"orkflows_test_files/common_snps_sample-chr20.interval_list"",; ""CNVSomaticPairWorkflow.gatk_docker"": ""8f0ef5140437"",; ""CNVSomaticPairWorkflow.intervals"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/chr20.interval_list"",; ""CNVSomaticPairWorkflow.normal_bam"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143_BL-n1-chr20-downsampled.deduplicated.bam"",; ""CNVSomaticPairWorkflow.normal_bam_idx"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143_BL-n1-chr20-downsampled.deduplicated.bam.bai"",; ""CNVSomaticPairWorkflow.bin_length"": ""10000"",; ""CNVSomaticPairWorkflow.read_count_pon"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/wgs-no-gc.pon.hdf5"",; ""CNVSomaticPairWorkflow.ref_fasta_dict"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/human_g1k_v37.chr-20.truncated.dict"",; ""CNVSomaticPairWorkflow.ref_fasta_fai"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/human_g1k_v37.chr-20.truncated.fasta.fai"",; ""CNVSomaticPairWorkflow.ref_fasta"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/human_g1k_v37.chr-20.truncated.fasta"",; ""CNVSomaticPairWorkflow.tumor_bam"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143-t1-chr20-downsampled.deduplicated.bam"",; ""CNVSomaticPairWorkflow.tumor_bam_idx"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143-t1-chr20-downsampled.deduplicated.bam.bai"",; ""CNVSomaticPairWorkflow.gatk4_jar_override"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/build/libs/gatk.jar""; }",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388871590
https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388871590:1920,Testability,test,test,1920,"orkflows_test_files/common_snps_sample-chr20.interval_list"",; ""CNVSomaticPairWorkflow.gatk_docker"": ""8f0ef5140437"",; ""CNVSomaticPairWorkflow.intervals"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/chr20.interval_list"",; ""CNVSomaticPairWorkflow.normal_bam"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143_BL-n1-chr20-downsampled.deduplicated.bam"",; ""CNVSomaticPairWorkflow.normal_bam_idx"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143_BL-n1-chr20-downsampled.deduplicated.bam.bai"",; ""CNVSomaticPairWorkflow.bin_length"": ""10000"",; ""CNVSomaticPairWorkflow.read_count_pon"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/wgs-no-gc.pon.hdf5"",; ""CNVSomaticPairWorkflow.ref_fasta_dict"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/human_g1k_v37.chr-20.truncated.dict"",; ""CNVSomaticPairWorkflow.ref_fasta_fai"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/human_g1k_v37.chr-20.truncated.fasta.fai"",; ""CNVSomaticPairWorkflow.ref_fasta"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/human_g1k_v37.chr-20.truncated.fasta"",; ""CNVSomaticPairWorkflow.tumor_bam"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143-t1-chr20-downsampled.deduplicated.bam"",; ""CNVSomaticPairWorkflow.tumor_bam_idx"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/src/test/resources/large/cnv_somatic_workflows_test_files/HCC1143-t1-chr20-downsampled.deduplicated.bam.bai"",; ""CNVSomaticPairWorkflow.gatk4_jar_override"": ""/Users/mkanaszn/Broad_Institute/Code/gatk_ssh/gatk/build/libs/gatk.jar""; }",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388871590
https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388871669:24126,Availability,error,error-rate,24126,"terations; Int? num_smoothing_iterations_per_fit; String? output_dir; File? gatk4_jar_override. # Runtime parameters; String gatk_docker; Int? mem_gb; Int? disk_space_gb; Boolean use_ssd = false; Int? cpu; Int? preemptible_attempts. Int machine_mem_mb = select_first([mem_gb, 13]) * 1000; # ModelSegments seems to need at least 3GB of overhead to run; Int command_mem_mb = machine_mem_mb - 3000. # If optional output_dir not specified, use ""out""; String output_dir_ = select_first([output_dir, ""out/""]) . command <<<; set -e; mkdir ${output_dir_}; export GATK_LOCAL_JAR=${default=""/root/gatk.jar"" gatk4_jar_override}. gatk --java-options ""-Xmx${command_mem_mb}m"" ModelSegments \; --denoised-copy-ratios ${denoised_copy_ratios} \; --allelic-counts ${allelic_counts} \; ${""--normal-allelic-counts "" + normal_allelic_counts} \; --minimum-total-allele-count ${default=""30"" min_total_allele_count} \; --genotyping-homozygous-log-ratio-threshold ${default=""-10.0"" genotyping_homozygous_log_ratio_threshold} \; --genotyping-base-error-rate ${default=""0.05"" genotyping_base_error_rate} \; --maximum-number-of-segments-per-chromosome ${default=""1000"" max_num_segments_per_chromosome} \; --kernel-variance-copy-ratio ${default=""0.0"" kernel_variance_copy_ratio} \; --kernel-variance-allele-fraction ${default=""0.025"" kernel_variance_allele_fraction} \; --kernel-scaling-allele-fraction ${default=""1.0"" kernel_scaling_allele_fraction} \; --kernel-approximation-dimension ${default=""100"" kernel_approximation_dimension} \; --window-size ${sep="" --window-size "" window_sizes} \; --number-of-changepoints-penalty-factor ${default=""1.0"" num_changepoints_penalty_factor} \; --minor-allele-fraction-prior-alpha ${default=""25.0"" minor_allele_fraction_prior_alpha} \; --number-of-samples-copy-ratio ${default=100 num_samples_copy_ratio} \; --number-of-burn-in-samples-copy-ratio ${default=50 num_burn_in_copy_ratio} \; --number-of-samples-allele-fraction ${default=100 num_samples_allele_fraction} \; --number-of-burn-in-",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388871669
https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388871669:9395,Modifiability,variab,variable,9395,"ptible_attempts; }. Int modeled_segments_tumor_disk = ceil(size(DenoiseReadCountsTumor.denoised_copy_ratios, ""GB"")) + ceil(size(ModelSegmentsTumor.modeled_segments, ""GB"")) + disk_pad; call CallModeledSegments as CallModeledSegmentsTumor {; input:; entity_id = CollectCountsTumor.entity_id,; modeled_segments_input_file = ModelSegmentsTumor.modeled_segments,; load_copy_ratio = load_copy_ratio,; load_allele_fraction = load_allele_fraction,; normal_minor_allele_fraction_threshold = normal_minor_allele_fraction_threshold,; copy_ratio_peak_min_weight = copy_ratio_peak_min_weight,; min_fraction_of_points_in_normal_allele_fraction_region = min_fraction_of_points_in_normal_allele_fraction_region,; gatk4_jar_override = gatk4_jar_override,; gatk_docker = gatk_docker,; mem_gb = mem_gb_for_call_modeled_segments,; disk_space_gb = modeled_segments_tumor_disk,; preemptible_attempts = preemptible_attempts; }. # The F=files from other tasks are small enough to just combine into one disk variable and pass to the tumor plotting tasks; Int plot_tumor_disk = ref_size + ceil(size(DenoiseReadCountsTumor.standardized_copy_ratios, ""GB"")) + ceil(size(DenoiseReadCountsTumor.denoised_copy_ratios, ""GB"")) + ceil(size(ModelSegmentsTumor.het_allelic_counts, ""GB"")) + ceil(size(ModelSegmentsTumor.modeled_segments, ""GB"")) + disk_pad; call PlotDenoisedCopyRatios as PlotDenoisedCopyRatiosTumor {; input:; entity_id = CollectCountsTumor.entity_id,; standardized_copy_ratios = DenoiseReadCountsTumor.standardized_copy_ratios,; denoised_copy_ratios = DenoiseReadCountsTumor.denoised_copy_ratios,; ref_fasta_dict = ref_fasta_dict,; minimum_contig_length = minimum_contig_length,; gatk4_jar_override = gatk4_jar_override,; gatk_docker = gatk_docker,; mem_gb = mem_gb_for_plotting,; disk_space_gb = plot_tumor_disk,; preemptible_attempts = preemptible_attempts; }. call PlotModeledSegments as PlotModeledSegmentsTumor {; input:; entity_id = CollectCountsTumor.entity_id,; denoised_copy_ratios = DenoiseReadCountsTumor.deno",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388871669
https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388871669:15357,Modifiability,variab,variable,15357,"_attempts; }. Int modeled_segments_normal_disk = ceil(size(DenoiseReadCountsNormal.denoised_copy_ratios, ""GB"")) + ceil(size(ModelSegmentsNormal.modeled_segments, ""GB"")) + disk_pad; call CallModeledSegments as CallModeledSegmentsNormal {; input:; entity_id = CollectCountsTumor.entity_id,; modeled_segments_input_file = ModelSegmentsNormal.modeled_segments,; load_copy_ratio = load_copy_ratio,; load_allele_fraction = load_allele_fraction,; normal_minor_allele_fraction_threshold = normal_minor_allele_fraction_threshold,; copy_ratio_peak_min_weight = copy_ratio_peak_min_weight,; min_fraction_of_points_in_normal_allele_fraction_region = min_fraction_of_points_in_normal_allele_fraction_region,; gatk4_jar_override = gatk4_jar_override,; gatk_docker = gatk_docker,; mem_gb = mem_gb_for_call_modeled_segments,; disk_space_gb = modeled_segments_normal_disk,; preemptible_attempts = preemptible_attempts; }. # The files from other tasks are small enough to just combine into one disk variable and pass to the normal plotting tasks; Int plot_normal_disk = ref_size + ceil(size(DenoiseReadCountsNormal.standardized_copy_ratios, ""GB"")) + ceil(size(DenoiseReadCountsNormal.denoised_copy_ratios, ""GB"")) + ceil(size(ModelSegmentsNormal.het_allelic_counts, ""GB"")) + ceil(size(ModelSegmentsNormal.modeled_segments, ""GB"")) + disk_pad; call PlotDenoisedCopyRatios as PlotDenoisedCopyRatiosNormal {; input:; entity_id = CollectCountsNormal.entity_id,; standardized_copy_ratios = DenoiseReadCountsNormal.standardized_copy_ratios,; denoised_copy_ratios = DenoiseReadCountsNormal.denoised_copy_ratios,; ref_fasta_dict = ref_fasta_dict,; minimum_contig_length = minimum_contig_length,; gatk4_jar_override = gatk4_jar_override,; gatk_docker = gatk_docker,; mem_gb = mem_gb_for_plotting,; disk_space_gb = plot_normal_disk,; preemptible_attempts = preemptible_attempts; }. call PlotModeledSegments as PlotModeledSegmentsNormal {; input:; entity_id = CollectCountsNormal.entity_id,; denoised_copy_ratios = DenoiseReadCounts",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388871669
https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388871669:27740,Performance,load,load-copy-ratio,27740,"; }. task CallModeledSegments {; String entity_id; File modeled_segments_input_file; Boolean? load_copy_ratio; Boolean? load_allele_fraction; File? output_dir; String? output_prefix; Float? normal_minor_allele_fraction_threshold; Float? copy_ratio_peak_min_weight; Float? min_fraction_of_points_in_normal_allele_fraction_region; File? gatk4_jar_override. # Runtime parameters; String gatk_docker; Int? mem_gb; Int? disk_space_gb; Boolean use_ssd = false; Int? cpu; Int? preemptible_attempts. Int machine_mem_mb = select_first([mem_gb, 7]) * 1000; Int command_mem_mb = machine_mem_mb - 1000. String output_dir_ = select_first([output_dir, ""out/""]); String output_prefix_ = select_first([output_prefix, entity_id]). command <<<; set -e; mkdir ${output_dir_}; export GATK_LOCAL_JAR=${default=""/root/gatk.jar"" gatk4_jar_override}. gatk --java-options ""-Xmx${command_mem_mb}m"" CallModeledSegments \; --input ${modeled_segments_input_file} \; --load-copy-ratio ${default=""true"" load_copy_ratio} \; --load-allele-fraction ${default=""true"" load_allele_fraction} \; --output ${output_dir_} \; --output-prefix ${output_prefix_} \; --normal-minor-allele-fraction-threshold ${default=""0.475"" normal_minor_allele_fraction_threshold} \; --copy-ratio-peak-min-weight ${default=""0.03"" copy_ratio_peak_min_weight} \; --min-fraction-of-points-in-normal-allele-fraction-region ${default=""0.15"" min_fraction_of_points_in_normal_allele_fraction_region}; >>>. runtime {; docker: ""${gatk_docker}""; memory: machine_mem_mb + "" MB""; disks: ""local-disk "" + disk_space_gb + if use_ssd then "" SSD"" else "" HDD""; cpu: select_first([cpu, 1]); preemptible: select_first([preemptible_attempts, 5]); }. output {; File called_modeled_segments_data = ""${output_dir_}${output_prefix_}.called.seg""; }; }. task PlotDenoisedCopyRatios {; String entity_id; File standardized_copy_ratios; File denoised_copy_ratios; File ref_fasta_dict; Int? minimum_contig_length; String? output_dir; File? gatk4_jar_override. # Runtime parameters; String gatk",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388871669
https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388871669:27795,Performance,load,load-allele-fraction,27795,"; }. task CallModeledSegments {; String entity_id; File modeled_segments_input_file; Boolean? load_copy_ratio; Boolean? load_allele_fraction; File? output_dir; String? output_prefix; Float? normal_minor_allele_fraction_threshold; Float? copy_ratio_peak_min_weight; Float? min_fraction_of_points_in_normal_allele_fraction_region; File? gatk4_jar_override. # Runtime parameters; String gatk_docker; Int? mem_gb; Int? disk_space_gb; Boolean use_ssd = false; Int? cpu; Int? preemptible_attempts. Int machine_mem_mb = select_first([mem_gb, 7]) * 1000; Int command_mem_mb = machine_mem_mb - 1000. String output_dir_ = select_first([output_dir, ""out/""]); String output_prefix_ = select_first([output_prefix, entity_id]). command <<<; set -e; mkdir ${output_dir_}; export GATK_LOCAL_JAR=${default=""/root/gatk.jar"" gatk4_jar_override}. gatk --java-options ""-Xmx${command_mem_mb}m"" CallModeledSegments \; --input ${modeled_segments_input_file} \; --load-copy-ratio ${default=""true"" load_copy_ratio} \; --load-allele-fraction ${default=""true"" load_allele_fraction} \; --output ${output_dir_} \; --output-prefix ${output_prefix_} \; --normal-minor-allele-fraction-threshold ${default=""0.475"" normal_minor_allele_fraction_threshold} \; --copy-ratio-peak-min-weight ${default=""0.03"" copy_ratio_peak_min_weight} \; --min-fraction-of-points-in-normal-allele-fraction-region ${default=""0.15"" min_fraction_of_points_in_normal_allele_fraction_region}; >>>. runtime {; docker: ""${gatk_docker}""; memory: machine_mem_mb + "" MB""; disks: ""local-disk "" + disk_space_gb + if use_ssd then "" SSD"" else "" HDD""; cpu: select_first([cpu, 1]); preemptible: select_first([preemptible_attempts, 5]); }. output {; File called_modeled_segments_data = ""${output_dir_}${output_prefix_}.called.seg""; }; }. task PlotDenoisedCopyRatios {; String entity_id; File standardized_copy_ratios; File denoised_copy_ratios; File ref_fasta_dict; Int? minimum_contig_length; String? output_dir; File? gatk4_jar_override. # Runtime parameters; String gatk",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388871669
https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388871669:24024,Testability,log,log-ratio-threshold,24024,"py_ratio; Int? num_burn_in_copy_ratio; Int? num_samples_allele_fraction; Int? num_burn_in_allele_fraction; Float? smoothing_threshold_copy_ratio; Float? smoothing_threshold_allele_fraction; Int? max_num_smoothing_iterations; Int? num_smoothing_iterations_per_fit; String? output_dir; File? gatk4_jar_override. # Runtime parameters; String gatk_docker; Int? mem_gb; Int? disk_space_gb; Boolean use_ssd = false; Int? cpu; Int? preemptible_attempts. Int machine_mem_mb = select_first([mem_gb, 13]) * 1000; # ModelSegments seems to need at least 3GB of overhead to run; Int command_mem_mb = machine_mem_mb - 3000. # If optional output_dir not specified, use ""out""; String output_dir_ = select_first([output_dir, ""out/""]) . command <<<; set -e; mkdir ${output_dir_}; export GATK_LOCAL_JAR=${default=""/root/gatk.jar"" gatk4_jar_override}. gatk --java-options ""-Xmx${command_mem_mb}m"" ModelSegments \; --denoised-copy-ratios ${denoised_copy_ratios} \; --allelic-counts ${allelic_counts} \; ${""--normal-allelic-counts "" + normal_allelic_counts} \; --minimum-total-allele-count ${default=""30"" min_total_allele_count} \; --genotyping-homozygous-log-ratio-threshold ${default=""-10.0"" genotyping_homozygous_log_ratio_threshold} \; --genotyping-base-error-rate ${default=""0.05"" genotyping_base_error_rate} \; --maximum-number-of-segments-per-chromosome ${default=""1000"" max_num_segments_per_chromosome} \; --kernel-variance-copy-ratio ${default=""0.0"" kernel_variance_copy_ratio} \; --kernel-variance-allele-fraction ${default=""0.025"" kernel_variance_allele_fraction} \; --kernel-scaling-allele-fraction ${default=""1.0"" kernel_scaling_allele_fraction} \; --kernel-approximation-dimension ${default=""100"" kernel_approximation_dimension} \; --window-size ${sep="" --window-size "" window_sizes} \; --number-of-changepoints-penalty-factor ${default=""1.0"" num_changepoints_penalty_factor} \; --minor-allele-fraction-prior-alpha ${default=""25.0"" minor_allele_fraction_prior_alpha} \; --number-of-samples-copy-ratio ${defau",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388871669
https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388891613:46,Availability,error,error,46,@MartonKN This is almost certainly not a real error but rather some annoying/alarming yet harmless Cromwell messages. Other than this does it appear that your workflow successfully completed?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388891613
https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388891613:108,Integrability,message,messages,108,@MartonKN This is almost certainly not a real error but rather some annoying/alarming yet harmless Cromwell messages. Other than this does it appear that your workflow successfully completed?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-388891613
https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-402242786:15,Availability,error,error,15,@MartonKN this error should have been addressed in Cromwell v33 -- please reopen this issue if needed. Thanks!,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3618#issuecomment-402242786
https://github.com/broadinstitute/cromwell/pull/3619#issuecomment-389320386:627,Modifiability,refactor,refactoring,627,"@kshakir ; > Does this still mean that all other backend implementations should still look for cwl.output.json as a glob and not a regular file?. I think `cwl.output.json` should be looked at as an ""optional output"". At least for delocalization purposes (since the actual file is never used as is.. I think..). With PAPI V2 we should be able to support optional outputs and so when that happens we should switch from using a glob based approach to an optional approach. For backends that can't support optional outputs for whatever reason, the glob way is still viable IMO.; This is not to say that we don't need a larger glob refactoring, but we've been using glob as a workaround for optional outputs in some cases because of restrictions of V1 that I think we should not impose on V2, or any backend that can deal cleanly with optional outputs. > As the conformance tests are being removed, does that infer that as of this PR is CWL not officially supported on PapiV1?. yes I think there's no official plan to support CWL on V1 (@geoffjentry is that true ?) Since this particular test can only work on V2, instead of duplicating the `papi_conformance_expected_failures.txt` file with a V1/V2 I took the opportunity to nix V1 from travis.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3619#issuecomment-389320386
https://github.com/broadinstitute/cromwell/pull/3619#issuecomment-389320386:869,Testability,test,tests,869,"@kshakir ; > Does this still mean that all other backend implementations should still look for cwl.output.json as a glob and not a regular file?. I think `cwl.output.json` should be looked at as an ""optional output"". At least for delocalization purposes (since the actual file is never used as is.. I think..). With PAPI V2 we should be able to support optional outputs and so when that happens we should switch from using a glob based approach to an optional approach. For backends that can't support optional outputs for whatever reason, the glob way is still viable IMO.; This is not to say that we don't need a larger glob refactoring, but we've been using glob as a workaround for optional outputs in some cases because of restrictions of V1 that I think we should not impose on V2, or any backend that can deal cleanly with optional outputs. > As the conformance tests are being removed, does that infer that as of this PR is CWL not officially supported on PapiV1?. yes I think there's no official plan to support CWL on V1 (@geoffjentry is that true ?) Since this particular test can only work on V2, instead of duplicating the `papi_conformance_expected_failures.txt` file with a V1/V2 I took the opportunity to nix V1 from travis.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3619#issuecomment-389320386
https://github.com/broadinstitute/cromwell/pull/3619#issuecomment-389320386:1083,Testability,test,test,1083,"@kshakir ; > Does this still mean that all other backend implementations should still look for cwl.output.json as a glob and not a regular file?. I think `cwl.output.json` should be looked at as an ""optional output"". At least for delocalization purposes (since the actual file is never used as is.. I think..). With PAPI V2 we should be able to support optional outputs and so when that happens we should switch from using a glob based approach to an optional approach. For backends that can't support optional outputs for whatever reason, the glob way is still viable IMO.; This is not to say that we don't need a larger glob refactoring, but we've been using glob as a workaround for optional outputs in some cases because of restrictions of V1 that I think we should not impose on V2, or any backend that can deal cleanly with optional outputs. > As the conformance tests are being removed, does that infer that as of this PR is CWL not officially supported on PapiV1?. yes I think there's no official plan to support CWL on V1 (@geoffjentry is that true ?) Since this particular test can only work on V2, instead of duplicating the `papi_conformance_expected_failures.txt` file with a V1/V2 I took the opportunity to nix V1 from travis.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3619#issuecomment-389320386
https://github.com/broadinstitute/cromwell/pull/3620#issuecomment-389026162:21,Availability,error,error,21,"Yeah that‚Äôs a sentry error. TBH I thought it was just on my home laptop, apparently not",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3620#issuecomment-389026162
https://github.com/broadinstitute/cromwell/pull/3620#issuecomment-389034690:69,Availability,error,error,69,"Aha. So maybe we can just default in our own Noop DSN to silence the error. ToL: The lack-of-a-DSN-message is also [Logback adjacent](https://docs.sentry.io/clients/java/modules/logback/#usage). Someday I'll figure out how the hell to use logback/Joran. On first glance it looks a lot like HOCON's embedded default `application.conf` that can be overriden via `-Dconfig.file=‚Ä¶` except one is supposed to use [`-Dlogback.configurationFile=‚Ä¶`](https://logback.qos.ch/manual/configuration.html#configFileProperty). But while I ""get"" HOCON's mechanics I do not yet ""get"" best practices for logback [overrides/includes](https://stackoverflow.com/a/23737143/3320205).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3620#issuecomment-389034690
https://github.com/broadinstitute/cromwell/pull/3620#issuecomment-389034690:420,Deployability,configurat,configurationFile,420,"Aha. So maybe we can just default in our own Noop DSN to silence the error. ToL: The lack-of-a-DSN-message is also [Logback adjacent](https://docs.sentry.io/clients/java/modules/logback/#usage). Someday I'll figure out how the hell to use logback/Joran. On first glance it looks a lot like HOCON's embedded default `application.conf` that can be overriden via `-Dconfig.file=‚Ä¶` except one is supposed to use [`-Dlogback.configurationFile=‚Ä¶`](https://logback.qos.ch/manual/configuration.html#configFileProperty). But while I ""get"" HOCON's mechanics I do not yet ""get"" best practices for logback [overrides/includes](https://stackoverflow.com/a/23737143/3320205).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3620#issuecomment-389034690
https://github.com/broadinstitute/cromwell/pull/3620#issuecomment-389034690:472,Deployability,configurat,configuration,472,"Aha. So maybe we can just default in our own Noop DSN to silence the error. ToL: The lack-of-a-DSN-message is also [Logback adjacent](https://docs.sentry.io/clients/java/modules/logback/#usage). Someday I'll figure out how the hell to use logback/Joran. On first glance it looks a lot like HOCON's embedded default `application.conf` that can be overriden via `-Dconfig.file=‚Ä¶` except one is supposed to use [`-Dlogback.configurationFile=‚Ä¶`](https://logback.qos.ch/manual/configuration.html#configFileProperty). But while I ""get"" HOCON's mechanics I do not yet ""get"" best practices for logback [overrides/includes](https://stackoverflow.com/a/23737143/3320205).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3620#issuecomment-389034690
https://github.com/broadinstitute/cromwell/pull/3620#issuecomment-389034690:99,Integrability,message,message,99,"Aha. So maybe we can just default in our own Noop DSN to silence the error. ToL: The lack-of-a-DSN-message is also [Logback adjacent](https://docs.sentry.io/clients/java/modules/logback/#usage). Someday I'll figure out how the hell to use logback/Joran. On first glance it looks a lot like HOCON's embedded default `application.conf` that can be overriden via `-Dconfig.file=‚Ä¶` except one is supposed to use [`-Dlogback.configurationFile=‚Ä¶`](https://logback.qos.ch/manual/configuration.html#configFileProperty). But while I ""get"" HOCON's mechanics I do not yet ""get"" best practices for logback [overrides/includes](https://stackoverflow.com/a/23737143/3320205).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3620#issuecomment-389034690
https://github.com/broadinstitute/cromwell/pull/3620#issuecomment-389034690:420,Modifiability,config,configurationFile,420,"Aha. So maybe we can just default in our own Noop DSN to silence the error. ToL: The lack-of-a-DSN-message is also [Logback adjacent](https://docs.sentry.io/clients/java/modules/logback/#usage). Someday I'll figure out how the hell to use logback/Joran. On first glance it looks a lot like HOCON's embedded default `application.conf` that can be overriden via `-Dconfig.file=‚Ä¶` except one is supposed to use [`-Dlogback.configurationFile=‚Ä¶`](https://logback.qos.ch/manual/configuration.html#configFileProperty). But while I ""get"" HOCON's mechanics I do not yet ""get"" best practices for logback [overrides/includes](https://stackoverflow.com/a/23737143/3320205).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3620#issuecomment-389034690
https://github.com/broadinstitute/cromwell/pull/3620#issuecomment-389034690:472,Modifiability,config,configuration,472,"Aha. So maybe we can just default in our own Noop DSN to silence the error. ToL: The lack-of-a-DSN-message is also [Logback adjacent](https://docs.sentry.io/clients/java/modules/logback/#usage). Someday I'll figure out how the hell to use logback/Joran. On first glance it looks a lot like HOCON's embedded default `application.conf` that can be overriden via `-Dconfig.file=‚Ä¶` except one is supposed to use [`-Dlogback.configurationFile=‚Ä¶`](https://logback.qos.ch/manual/configuration.html#configFileProperty). But while I ""get"" HOCON's mechanics I do not yet ""get"" best practices for logback [overrides/includes](https://stackoverflow.com/a/23737143/3320205).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3620#issuecomment-389034690
https://github.com/broadinstitute/cromwell/pull/3620#issuecomment-389034690:491,Modifiability,config,configFileProperty,491,"Aha. So maybe we can just default in our own Noop DSN to silence the error. ToL: The lack-of-a-DSN-message is also [Logback adjacent](https://docs.sentry.io/clients/java/modules/logback/#usage). Someday I'll figure out how the hell to use logback/Joran. On first glance it looks a lot like HOCON's embedded default `application.conf` that can be overriden via `-Dconfig.file=‚Ä¶` except one is supposed to use [`-Dlogback.configurationFile=‚Ä¶`](https://logback.qos.ch/manual/configuration.html#configFileProperty). But while I ""get"" HOCON's mechanics I do not yet ""get"" best practices for logback [overrides/includes](https://stackoverflow.com/a/23737143/3320205).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3620#issuecomment-389034690
https://github.com/broadinstitute/cromwell/pull/3620#issuecomment-389034690:116,Testability,Log,Logback,116,"Aha. So maybe we can just default in our own Noop DSN to silence the error. ToL: The lack-of-a-DSN-message is also [Logback adjacent](https://docs.sentry.io/clients/java/modules/logback/#usage). Someday I'll figure out how the hell to use logback/Joran. On first glance it looks a lot like HOCON's embedded default `application.conf` that can be overriden via `-Dconfig.file=‚Ä¶` except one is supposed to use [`-Dlogback.configurationFile=‚Ä¶`](https://logback.qos.ch/manual/configuration.html#configFileProperty). But while I ""get"" HOCON's mechanics I do not yet ""get"" best practices for logback [overrides/includes](https://stackoverflow.com/a/23737143/3320205).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3620#issuecomment-389034690
https://github.com/broadinstitute/cromwell/pull/3620#issuecomment-389034690:178,Testability,log,logback,178,"Aha. So maybe we can just default in our own Noop DSN to silence the error. ToL: The lack-of-a-DSN-message is also [Logback adjacent](https://docs.sentry.io/clients/java/modules/logback/#usage). Someday I'll figure out how the hell to use logback/Joran. On first glance it looks a lot like HOCON's embedded default `application.conf` that can be overriden via `-Dconfig.file=‚Ä¶` except one is supposed to use [`-Dlogback.configurationFile=‚Ä¶`](https://logback.qos.ch/manual/configuration.html#configFileProperty). But while I ""get"" HOCON's mechanics I do not yet ""get"" best practices for logback [overrides/includes](https://stackoverflow.com/a/23737143/3320205).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3620#issuecomment-389034690
https://github.com/broadinstitute/cromwell/pull/3620#issuecomment-389034690:239,Testability,log,logback,239,"Aha. So maybe we can just default in our own Noop DSN to silence the error. ToL: The lack-of-a-DSN-message is also [Logback adjacent](https://docs.sentry.io/clients/java/modules/logback/#usage). Someday I'll figure out how the hell to use logback/Joran. On first glance it looks a lot like HOCON's embedded default `application.conf` that can be overriden via `-Dconfig.file=‚Ä¶` except one is supposed to use [`-Dlogback.configurationFile=‚Ä¶`](https://logback.qos.ch/manual/configuration.html#configFileProperty). But while I ""get"" HOCON's mechanics I do not yet ""get"" best practices for logback [overrides/includes](https://stackoverflow.com/a/23737143/3320205).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3620#issuecomment-389034690
https://github.com/broadinstitute/cromwell/pull/3620#issuecomment-389034690:450,Testability,log,logback,450,"Aha. So maybe we can just default in our own Noop DSN to silence the error. ToL: The lack-of-a-DSN-message is also [Logback adjacent](https://docs.sentry.io/clients/java/modules/logback/#usage). Someday I'll figure out how the hell to use logback/Joran. On first glance it looks a lot like HOCON's embedded default `application.conf` that can be overriden via `-Dconfig.file=‚Ä¶` except one is supposed to use [`-Dlogback.configurationFile=‚Ä¶`](https://logback.qos.ch/manual/configuration.html#configFileProperty). But while I ""get"" HOCON's mechanics I do not yet ""get"" best practices for logback [overrides/includes](https://stackoverflow.com/a/23737143/3320205).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3620#issuecomment-389034690
https://github.com/broadinstitute/cromwell/pull/3620#issuecomment-389034690:586,Testability,log,logback,586,"Aha. So maybe we can just default in our own Noop DSN to silence the error. ToL: The lack-of-a-DSN-message is also [Logback adjacent](https://docs.sentry.io/clients/java/modules/logback/#usage). Someday I'll figure out how the hell to use logback/Joran. On first glance it looks a lot like HOCON's embedded default `application.conf` that can be overriden via `-Dconfig.file=‚Ä¶` except one is supposed to use [`-Dlogback.configurationFile=‚Ä¶`](https://logback.qos.ch/manual/configuration.html#configFileProperty). But while I ""get"" HOCON's mechanics I do not yet ""get"" best practices for logback [overrides/includes](https://stackoverflow.com/a/23737143/3320205).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3620#issuecomment-389034690
https://github.com/broadinstitute/cromwell/issues/3624#issuecomment-389207739:101,Availability,error,error,101,Alternate command syntax for those investigating: `sbt 'server/run server'`. ~The original caused an error for me.~ EDIT: The original error may have been an unrelated error that pops up sometimes during `sbt clean compile`. I'm not sure of the default dependencies for `sbt */run` but it does appear that [`*/package`](https://www.scala-sbt.org/1.0/docs/Running.html#Common+commands) is being invoked and zipping up the class files.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3624#issuecomment-389207739
https://github.com/broadinstitute/cromwell/issues/3624#issuecomment-389207739:135,Availability,error,error,135,Alternate command syntax for those investigating: `sbt 'server/run server'`. ~The original caused an error for me.~ EDIT: The original error may have been an unrelated error that pops up sometimes during `sbt clean compile`. I'm not sure of the default dependencies for `sbt */run` but it does appear that [`*/package`](https://www.scala-sbt.org/1.0/docs/Running.html#Common+commands) is being invoked and zipping up the class files.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3624#issuecomment-389207739
https://github.com/broadinstitute/cromwell/issues/3624#issuecomment-389207739:168,Availability,error,error,168,Alternate command syntax for those investigating: `sbt 'server/run server'`. ~The original caused an error for me.~ EDIT: The original error may have been an unrelated error that pops up sometimes during `sbt clean compile`. I'm not sure of the default dependencies for `sbt */run` but it does appear that [`*/package`](https://www.scala-sbt.org/1.0/docs/Running.html#Common+commands) is being invoked and zipping up the class files.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3624#issuecomment-389207739
https://github.com/broadinstitute/cromwell/issues/3624#issuecomment-389207739:253,Integrability,depend,dependencies,253,Alternate command syntax for those investigating: `sbt 'server/run server'`. ~The original caused an error for me.~ EDIT: The original error may have been an unrelated error that pops up sometimes during `sbt clean compile`. I'm not sure of the default dependencies for `sbt */run` but it does appear that [`*/package`](https://www.scala-sbt.org/1.0/docs/Running.html#Common+commands) is being invoked and zipping up the class files.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3624#issuecomment-389207739
https://github.com/broadinstitute/cromwell/pull/3627#issuecomment-389224539:23,Security,hash,hash,23,Tests being fixed with hash bumps I can get behind. üëç . [![Approved with PullApprove](https://img.shields.io/badge/two_reviewers-approved-brightgreen.svg)](https://pullapprove.com/broadinstitute/cromwell/pull-request/3627/?utm_source=github-pr&utm_medium=comment-badge&utm_campaign=broadinstitute/cromwell),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3627#issuecomment-389224539
https://github.com/broadinstitute/cromwell/pull/3627#issuecomment-389224539:0,Testability,Test,Tests,0,Tests being fixed with hash bumps I can get behind. üëç . [![Approved with PullApprove](https://img.shields.io/badge/two_reviewers-approved-brightgreen.svg)](https://pullapprove.com/broadinstitute/cromwell/pull-request/3627/?utm_source=github-pr&utm_medium=comment-badge&utm_campaign=broadinstitute/cromwell),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3627#issuecomment-389224539
https://github.com/broadinstitute/cromwell/pull/3627#issuecomment-389284660:178,Availability,down,down,178,"Just noticed, this PR uses different hashes for conformance tests for Local / PapiV1 / PapiV2. I'm assuming that was not intentional. I have an incoming PR (as soon as PRs quiet down + I get travis to pass for once) that refactors this into reusable includes. That will hopefully help making CI changes in the future.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3627#issuecomment-389284660
https://github.com/broadinstitute/cromwell/pull/3627#issuecomment-389284660:221,Modifiability,refactor,refactors,221,"Just noticed, this PR uses different hashes for conformance tests for Local / PapiV1 / PapiV2. I'm assuming that was not intentional. I have an incoming PR (as soon as PRs quiet down + I get travis to pass for once) that refactors this into reusable includes. That will hopefully help making CI changes in the future.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3627#issuecomment-389284660
https://github.com/broadinstitute/cromwell/pull/3627#issuecomment-389284660:37,Security,hash,hashes,37,"Just noticed, this PR uses different hashes for conformance tests for Local / PapiV1 / PapiV2. I'm assuming that was not intentional. I have an incoming PR (as soon as PRs quiet down + I get travis to pass for once) that refactors this into reusable includes. That will hopefully help making CI changes in the future.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3627#issuecomment-389284660
https://github.com/broadinstitute/cromwell/pull/3627#issuecomment-389284660:60,Testability,test,tests,60,"Just noticed, this PR uses different hashes for conformance tests for Local / PapiV1 / PapiV2. I'm assuming that was not intentional. I have an incoming PR (as soon as PRs quiet down + I get travis to pass for once) that refactors this into reusable includes. That will hopefully help making CI changes in the future.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3627#issuecomment-389284660
https://github.com/broadinstitute/cromwell/pull/3627#issuecomment-389289995:33,Deployability,update,update,33,"@kshakir good point thanks, I'll update local too",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3627#issuecomment-389289995
https://github.com/broadinstitute/cromwell/pull/3627#issuecomment-389337148:447,Integrability,message,messages-to-stderr,447,"Your latest commit _might_ be failing because it's logging to stdout while conformance tests only allow logging to stderr. There are lots of `Extra data: line 1 column 3 - line 18 column 1 (char 2 - 1091)` in the travis logs for Local conformance tests. Someday one of us will get the hang of logback and we can just ""easily"" [switch from stdout to stderr](https://stackoverflow.com/questions/25935326/how-can-i-configure-logback-conf-to-send-all-messages-to-stderr). For now I don't have any quick fixes for logging w/ our existing slf4j framework. `Console.err.println()` would work, but isn't pretty either.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3627#issuecomment-389337148
https://github.com/broadinstitute/cromwell/pull/3627#issuecomment-389337148:412,Modifiability,config,configure-logback-conf-to-send-all-messages-to-stderr,412,"Your latest commit _might_ be failing because it's logging to stdout while conformance tests only allow logging to stderr. There are lots of `Extra data: line 1 column 3 - line 18 column 1 (char 2 - 1091)` in the travis logs for Local conformance tests. Someday one of us will get the hang of logback and we can just ""easily"" [switch from stdout to stderr](https://stackoverflow.com/questions/25935326/how-can-i-configure-logback-conf-to-send-all-messages-to-stderr). For now I don't have any quick fixes for logging w/ our existing slf4j framework. `Console.err.println()` would work, but isn't pretty either.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3627#issuecomment-389337148
https://github.com/broadinstitute/cromwell/pull/3627#issuecomment-389337148:51,Testability,log,logging,51,"Your latest commit _might_ be failing because it's logging to stdout while conformance tests only allow logging to stderr. There are lots of `Extra data: line 1 column 3 - line 18 column 1 (char 2 - 1091)` in the travis logs for Local conformance tests. Someday one of us will get the hang of logback and we can just ""easily"" [switch from stdout to stderr](https://stackoverflow.com/questions/25935326/how-can-i-configure-logback-conf-to-send-all-messages-to-stderr). For now I don't have any quick fixes for logging w/ our existing slf4j framework. `Console.err.println()` would work, but isn't pretty either.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3627#issuecomment-389337148
https://github.com/broadinstitute/cromwell/pull/3627#issuecomment-389337148:87,Testability,test,tests,87,"Your latest commit _might_ be failing because it's logging to stdout while conformance tests only allow logging to stderr. There are lots of `Extra data: line 1 column 3 - line 18 column 1 (char 2 - 1091)` in the travis logs for Local conformance tests. Someday one of us will get the hang of logback and we can just ""easily"" [switch from stdout to stderr](https://stackoverflow.com/questions/25935326/how-can-i-configure-logback-conf-to-send-all-messages-to-stderr). For now I don't have any quick fixes for logging w/ our existing slf4j framework. `Console.err.println()` would work, but isn't pretty either.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3627#issuecomment-389337148
https://github.com/broadinstitute/cromwell/pull/3627#issuecomment-389337148:104,Testability,log,logging,104,"Your latest commit _might_ be failing because it's logging to stdout while conformance tests only allow logging to stderr. There are lots of `Extra data: line 1 column 3 - line 18 column 1 (char 2 - 1091)` in the travis logs for Local conformance tests. Someday one of us will get the hang of logback and we can just ""easily"" [switch from stdout to stderr](https://stackoverflow.com/questions/25935326/how-can-i-configure-logback-conf-to-send-all-messages-to-stderr). For now I don't have any quick fixes for logging w/ our existing slf4j framework. `Console.err.println()` would work, but isn't pretty either.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3627#issuecomment-389337148
https://github.com/broadinstitute/cromwell/pull/3627#issuecomment-389337148:220,Testability,log,logs,220,"Your latest commit _might_ be failing because it's logging to stdout while conformance tests only allow logging to stderr. There are lots of `Extra data: line 1 column 3 - line 18 column 1 (char 2 - 1091)` in the travis logs for Local conformance tests. Someday one of us will get the hang of logback and we can just ""easily"" [switch from stdout to stderr](https://stackoverflow.com/questions/25935326/how-can-i-configure-logback-conf-to-send-all-messages-to-stderr). For now I don't have any quick fixes for logging w/ our existing slf4j framework. `Console.err.println()` would work, but isn't pretty either.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3627#issuecomment-389337148
https://github.com/broadinstitute/cromwell/pull/3627#issuecomment-389337148:247,Testability,test,tests,247,"Your latest commit _might_ be failing because it's logging to stdout while conformance tests only allow logging to stderr. There are lots of `Extra data: line 1 column 3 - line 18 column 1 (char 2 - 1091)` in the travis logs for Local conformance tests. Someday one of us will get the hang of logback and we can just ""easily"" [switch from stdout to stderr](https://stackoverflow.com/questions/25935326/how-can-i-configure-logback-conf-to-send-all-messages-to-stderr). For now I don't have any quick fixes for logging w/ our existing slf4j framework. `Console.err.println()` would work, but isn't pretty either.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3627#issuecomment-389337148
https://github.com/broadinstitute/cromwell/pull/3627#issuecomment-389337148:293,Testability,log,logback,293,"Your latest commit _might_ be failing because it's logging to stdout while conformance tests only allow logging to stderr. There are lots of `Extra data: line 1 column 3 - line 18 column 1 (char 2 - 1091)` in the travis logs for Local conformance tests. Someday one of us will get the hang of logback and we can just ""easily"" [switch from stdout to stderr](https://stackoverflow.com/questions/25935326/how-can-i-configure-logback-conf-to-send-all-messages-to-stderr). For now I don't have any quick fixes for logging w/ our existing slf4j framework. `Console.err.println()` would work, but isn't pretty either.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3627#issuecomment-389337148
https://github.com/broadinstitute/cromwell/pull/3627#issuecomment-389337148:422,Testability,log,logback-conf-to-send-all-messages-to-stderr,422,"Your latest commit _might_ be failing because it's logging to stdout while conformance tests only allow logging to stderr. There are lots of `Extra data: line 1 column 3 - line 18 column 1 (char 2 - 1091)` in the travis logs for Local conformance tests. Someday one of us will get the hang of logback and we can just ""easily"" [switch from stdout to stderr](https://stackoverflow.com/questions/25935326/how-can-i-configure-logback-conf-to-send-all-messages-to-stderr). For now I don't have any quick fixes for logging w/ our existing slf4j framework. `Console.err.println()` would work, but isn't pretty either.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3627#issuecomment-389337148
https://github.com/broadinstitute/cromwell/pull/3627#issuecomment-389337148:509,Testability,log,logging,509,"Your latest commit _might_ be failing because it's logging to stdout while conformance tests only allow logging to stderr. There are lots of `Extra data: line 1 column 3 - line 18 column 1 (char 2 - 1091)` in the travis logs for Local conformance tests. Someday one of us will get the hang of logback and we can just ""easily"" [switch from stdout to stderr](https://stackoverflow.com/questions/25935326/how-can-i-configure-logback-conf-to-send-all-messages-to-stderr). For now I don't have any quick fixes for logging w/ our existing slf4j framework. `Console.err.println()` would work, but isn't pretty either.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3627#issuecomment-389337148
https://github.com/broadinstitute/cromwell/pull/3629#issuecomment-389577205:543,Integrability,depend,depending,543,"> I haven't fully thought it through yet, but I'll keep something sorta like this in mind when we're dealing with tracking the WomFile.value to (cloud, vm, container) path split. I think we could use a mini brainstorm session on this. I'm finding other areas where it would be very nice to clarify this cloud / vm /container separation.; Namely `JobPaths` has become a huge messy melting pot over time and it would be awesome to have a clean `cloudCallRoot`, `vmCallRoot`, `containerCallRoot` for example (some of those that could be the same depending on the backend, w/ docker or not etc..)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3629#issuecomment-389577205
https://github.com/broadinstitute/cromwell/issues/3639#issuecomment-452514774:952,Security,validat,validate,952,"Random google-r checking in, I had some similar confusion with CWL and InitialWorkDirRequirements and although it's not directly related to this issue as I wasn't replicating with docker, I wanted to comment in case anyone else finds themselves here, especially within Cromwell. My confusion can because I had a CommandLineTool that would only generate its files where the inputs are. Basically I needed to localise the file to the execution directory, and then reference it in a glob expression on output. TL;DR, put the InitialWorkDirRequirement file expression in a `Dirent` rather than on the requirement. By _carefully_ re-reading the [`InitialWorkDirRequirement`](https://www.commonwl.org/v1.0/Workflow.html#InitialWorkDirRequirement).[`Dirent`](https://www.commonwl.org/v1.0/Workflow.html#InitialWorkDirRequirement) documentation, we find:. #### InitialWorkDirRequirement.listing; > May be an expression. If so, the expression return value must validate as {type: array, items: [File, Directory]}. This is what I initially did, which looks like:; ```yaml; requirements:; InitialWorkDirRequirement:; listing: $([inputs.inputFile]); ```; but my output expression was never localised to this new directory. Let's look at Dirent:. #### Dirent.entry; > If the value is an expression that evaluates to a File object, this indicates the referenced file should be added to the designated output directory prior to executing the tool. Okay cool, this is basically what I want, and paired with:. #### Dirent.entryname; > The name of the file or subdirectory to create in the output directory. If entry is a File or Directory, the entryname field overrides the value of basename of the File or Directory object. Optional. This is exactly what I want. I need to provide the expression for Dirent.entry, and exclude entryname, and Cromwell successfully localises this. Hence putting this together so that a tabix CommandLineTool can generate the file in the following CommandLineTool:. ```cwl; class: Comman",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3639#issuecomment-452514774
https://github.com/broadinstitute/cromwell/issues/3648#issuecomment-769183176:41,Safety,timeout,timeout-seconds,41,Closing this. It is already fixed with a timeout-seconds options in the SFSBackend,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3648#issuecomment-769183176
https://github.com/broadinstitute/cromwell/issues/3654#issuecomment-402854046:326,Availability,error,error,326,"Thanks @kshakir! . Mint team just noticed a similar issue for a few of our workflows, where the workflow status in Cromwell is ""running"" but the VM instance is no longer running. These specific workflows were ""stuck"" on the first task and did not start any subworkflows. When trying to abort the workflow, I get the following error: . ```; {; ""status"": ""error"",; ""message"": ""Couldn't abort 467b64cc-9aa4-4eaf-85ef-16ed4d540d4c because no workflow with that ID is in progress""; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3654#issuecomment-402854046
https://github.com/broadinstitute/cromwell/issues/3654#issuecomment-402854046:354,Availability,error,error,354,"Thanks @kshakir! . Mint team just noticed a similar issue for a few of our workflows, where the workflow status in Cromwell is ""running"" but the VM instance is no longer running. These specific workflows were ""stuck"" on the first task and did not start any subworkflows. When trying to abort the workflow, I get the following error: . ```; {; ""status"": ""error"",; ""message"": ""Couldn't abort 467b64cc-9aa4-4eaf-85ef-16ed4d540d4c because no workflow with that ID is in progress""; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3654#issuecomment-402854046
https://github.com/broadinstitute/cromwell/issues/3654#issuecomment-402854046:364,Integrability,message,message,364,"Thanks @kshakir! . Mint team just noticed a similar issue for a few of our workflows, where the workflow status in Cromwell is ""running"" but the VM instance is no longer running. These specific workflows were ""stuck"" on the first task and did not start any subworkflows. When trying to abort the workflow, I get the following error: . ```; {; ""status"": ""error"",; ""message"": ""Couldn't abort 467b64cc-9aa4-4eaf-85ef-16ed4d540d4c because no workflow with that ID is in progress""; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3654#issuecomment-402854046
https://github.com/broadinstitute/cromwell/issues/3654#issuecomment-402854046:286,Safety,abort,abort,286,"Thanks @kshakir! . Mint team just noticed a similar issue for a few of our workflows, where the workflow status in Cromwell is ""running"" but the VM instance is no longer running. These specific workflows were ""stuck"" on the first task and did not start any subworkflows. When trying to abort the workflow, I get the following error: . ```; {; ""status"": ""error"",; ""message"": ""Couldn't abort 467b64cc-9aa4-4eaf-85ef-16ed4d540d4c because no workflow with that ID is in progress""; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3654#issuecomment-402854046
https://github.com/broadinstitute/cromwell/issues/3654#issuecomment-402854046:384,Safety,abort,abort,384,"Thanks @kshakir! . Mint team just noticed a similar issue for a few of our workflows, where the workflow status in Cromwell is ""running"" but the VM instance is no longer running. These specific workflows were ""stuck"" on the first task and did not start any subworkflows. When trying to abort the workflow, I get the following error: . ```; {; ""status"": ""error"",; ""message"": ""Couldn't abort 467b64cc-9aa4-4eaf-85ef-16ed4d540d4c because no workflow with that ID is in progress""; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3654#issuecomment-402854046
https://github.com/broadinstitute/cromwell/issues/3656#issuecomment-390433889:272,Deployability,release,release,272,"Yeah that's unfortunate, thanks for reporting it. üôÇ This was [fixed](https://github.com/broadinstitute/cromwell/issues/3421) on the 31_hotfix branch a couple of months ago. There's a corresponding 31-39223b8 image up on Docker Hub but GitHub doesn't seem to have the 31.1 release. For now you could use the Docker image or build from the 31_hotfix branch, I'll try to update GitHub with 31.1 this week.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3656#issuecomment-390433889
https://github.com/broadinstitute/cromwell/issues/3656#issuecomment-390433889:368,Deployability,update,update,368,"Yeah that's unfortunate, thanks for reporting it. üôÇ This was [fixed](https://github.com/broadinstitute/cromwell/issues/3421) on the 31_hotfix branch a couple of months ago. There's a corresponding 31-39223b8 image up on Docker Hub but GitHub doesn't seem to have the 31.1 release. For now you could use the Docker image or build from the 31_hotfix branch, I'll try to update GitHub with 31.1 this week.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3656#issuecomment-390433889
https://github.com/broadinstitute/cromwell/issues/3656#issuecomment-390436881:31,Deployability,release,release,31,I snuck in a quick 31.1 GitHub release that includes the fix for this. Thanks again for reporting it!,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3656#issuecomment-390436881
https://github.com/broadinstitute/cromwell/issues/3658#issuecomment-398533395:98,Availability,failure,failure,98,"If I understand this correctly, this will allow all scalatest tests to try twice - with the first failure being reported to a triage system in case it works the second time and the tests failing as usual if the same test fails twice in a row?. That sounds awesome!. The comments on adding this to the scalacheck tests seem like they could be part of a second pass since (a) there's not many of them and (b) they don't fail very often, so leaving them in the current ""must pass first time"" seems fine to me.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3658#issuecomment-398533395
https://github.com/broadinstitute/cromwell/issues/3658#issuecomment-398533395:62,Testability,test,tests,62,"If I understand this correctly, this will allow all scalatest tests to try twice - with the first failure being reported to a triage system in case it works the second time and the tests failing as usual if the same test fails twice in a row?. That sounds awesome!. The comments on adding this to the scalacheck tests seem like they could be part of a second pass since (a) there's not many of them and (b) they don't fail very often, so leaving them in the current ""must pass first time"" seems fine to me.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3658#issuecomment-398533395
https://github.com/broadinstitute/cromwell/issues/3658#issuecomment-398533395:181,Testability,test,tests,181,"If I understand this correctly, this will allow all scalatest tests to try twice - with the first failure being reported to a triage system in case it works the second time and the tests failing as usual if the same test fails twice in a row?. That sounds awesome!. The comments on adding this to the scalacheck tests seem like they could be part of a second pass since (a) there's not many of them and (b) they don't fail very often, so leaving them in the current ""must pass first time"" seems fine to me.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3658#issuecomment-398533395
https://github.com/broadinstitute/cromwell/issues/3658#issuecomment-398533395:216,Testability,test,test,216,"If I understand this correctly, this will allow all scalatest tests to try twice - with the first failure being reported to a triage system in case it works the second time and the tests failing as usual if the same test fails twice in a row?. That sounds awesome!. The comments on adding this to the scalacheck tests seem like they could be part of a second pass since (a) there's not many of them and (b) they don't fail very often, so leaving them in the current ""must pass first time"" seems fine to me.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3658#issuecomment-398533395
https://github.com/broadinstitute/cromwell/issues/3658#issuecomment-398533395:312,Testability,test,tests,312,"If I understand this correctly, this will allow all scalatest tests to try twice - with the first failure being reported to a triage system in case it works the second time and the tests failing as usual if the same test fails twice in a row?. That sounds awesome!. The comments on adding this to the scalacheck tests seem like they could be part of a second pass since (a) there's not many of them and (b) they don't fail very often, so leaving them in the current ""must pass first time"" seems fine to me.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3658#issuecomment-398533395
https://github.com/broadinstitute/cromwell/pull/3668#issuecomment-391168787:35,Availability,repair,repairs,35,NOT MERGED closing temporarily for repairs as there are at least a couple of legit broken PAPI Centaur tests,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3668#issuecomment-391168787
https://github.com/broadinstitute/cromwell/pull/3668#issuecomment-391168787:103,Testability,test,tests,103,NOT MERGED closing temporarily for repairs as there are at least a couple of legit broken PAPI Centaur tests,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3668#issuecomment-391168787
https://github.com/broadinstitute/cromwell/issues/3673#issuecomment-391771784:228,Availability,down,down,228,"I believe that I am running into this problem with a batch of workflows.; I have a Cromwell instance running on GCE (launched via `docker-compose ... up`). Cromwell had gotten stuck accepting new workflow requests, so I shut it down and it didn't go down cleanly. After restarting Cromwell, I see:. ```; cromwell_1 | 2018-05-24 16:03:29,668 cromwell-system-akka.dispatchers.engine-dispatcher-27 ERROR - Error trying to fetch new workflows; cromwell_1 | common.exception.AggregatedMessageException: Error(s):; cromwell_1 | Workflow a07583dd-f571-44bf-abb7-5bf281dfd249 in state Running and restarted = false cannot be started and should not have been fetched.; ```. with a lengthy list of workflows listed with the same error message. All of these workflows came to a stop. In fact, querying cromwell, I saw:. ```; $ curl http://localhost:8000/engine/v1/stats; {""workflows"":0,""jobs"":0}; ```. I have been able to now restart cromwell and submit new workflows and get them running, but these other workflows were fairly well along. I would like to get them started again. What is the best way to do this?. ```; $ curl http://localhost:8000/engine/v1/version; {""cromwell"":""32-c07d8d9-SNAP""}; ```. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3673#issuecomment-391771784
https://github.com/broadinstitute/cromwell/issues/3673#issuecomment-391771784:250,Availability,down,down,250,"I believe that I am running into this problem with a batch of workflows.; I have a Cromwell instance running on GCE (launched via `docker-compose ... up`). Cromwell had gotten stuck accepting new workflow requests, so I shut it down and it didn't go down cleanly. After restarting Cromwell, I see:. ```; cromwell_1 | 2018-05-24 16:03:29,668 cromwell-system-akka.dispatchers.engine-dispatcher-27 ERROR - Error trying to fetch new workflows; cromwell_1 | common.exception.AggregatedMessageException: Error(s):; cromwell_1 | Workflow a07583dd-f571-44bf-abb7-5bf281dfd249 in state Running and restarted = false cannot be started and should not have been fetched.; ```. with a lengthy list of workflows listed with the same error message. All of these workflows came to a stop. In fact, querying cromwell, I saw:. ```; $ curl http://localhost:8000/engine/v1/stats; {""workflows"":0,""jobs"":0}; ```. I have been able to now restart cromwell and submit new workflows and get them running, but these other workflows were fairly well along. I would like to get them started again. What is the best way to do this?. ```; $ curl http://localhost:8000/engine/v1/version; {""cromwell"":""32-c07d8d9-SNAP""}; ```. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3673#issuecomment-391771784
https://github.com/broadinstitute/cromwell/issues/3673#issuecomment-391771784:395,Availability,ERROR,ERROR,395,"I believe that I am running into this problem with a batch of workflows.; I have a Cromwell instance running on GCE (launched via `docker-compose ... up`). Cromwell had gotten stuck accepting new workflow requests, so I shut it down and it didn't go down cleanly. After restarting Cromwell, I see:. ```; cromwell_1 | 2018-05-24 16:03:29,668 cromwell-system-akka.dispatchers.engine-dispatcher-27 ERROR - Error trying to fetch new workflows; cromwell_1 | common.exception.AggregatedMessageException: Error(s):; cromwell_1 | Workflow a07583dd-f571-44bf-abb7-5bf281dfd249 in state Running and restarted = false cannot be started and should not have been fetched.; ```. with a lengthy list of workflows listed with the same error message. All of these workflows came to a stop. In fact, querying cromwell, I saw:. ```; $ curl http://localhost:8000/engine/v1/stats; {""workflows"":0,""jobs"":0}; ```. I have been able to now restart cromwell and submit new workflows and get them running, but these other workflows were fairly well along. I would like to get them started again. What is the best way to do this?. ```; $ curl http://localhost:8000/engine/v1/version; {""cromwell"":""32-c07d8d9-SNAP""}; ```. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3673#issuecomment-391771784
https://github.com/broadinstitute/cromwell/issues/3673#issuecomment-391771784:403,Availability,Error,Error,403,"I believe that I am running into this problem with a batch of workflows.; I have a Cromwell instance running on GCE (launched via `docker-compose ... up`). Cromwell had gotten stuck accepting new workflow requests, so I shut it down and it didn't go down cleanly. After restarting Cromwell, I see:. ```; cromwell_1 | 2018-05-24 16:03:29,668 cromwell-system-akka.dispatchers.engine-dispatcher-27 ERROR - Error trying to fetch new workflows; cromwell_1 | common.exception.AggregatedMessageException: Error(s):; cromwell_1 | Workflow a07583dd-f571-44bf-abb7-5bf281dfd249 in state Running and restarted = false cannot be started and should not have been fetched.; ```. with a lengthy list of workflows listed with the same error message. All of these workflows came to a stop. In fact, querying cromwell, I saw:. ```; $ curl http://localhost:8000/engine/v1/stats; {""workflows"":0,""jobs"":0}; ```. I have been able to now restart cromwell and submit new workflows and get them running, but these other workflows were fairly well along. I would like to get them started again. What is the best way to do this?. ```; $ curl http://localhost:8000/engine/v1/version; {""cromwell"":""32-c07d8d9-SNAP""}; ```. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3673#issuecomment-391771784
https://github.com/broadinstitute/cromwell/issues/3673#issuecomment-391771784:498,Availability,Error,Error,498,"I believe that I am running into this problem with a batch of workflows.; I have a Cromwell instance running on GCE (launched via `docker-compose ... up`). Cromwell had gotten stuck accepting new workflow requests, so I shut it down and it didn't go down cleanly. After restarting Cromwell, I see:. ```; cromwell_1 | 2018-05-24 16:03:29,668 cromwell-system-akka.dispatchers.engine-dispatcher-27 ERROR - Error trying to fetch new workflows; cromwell_1 | common.exception.AggregatedMessageException: Error(s):; cromwell_1 | Workflow a07583dd-f571-44bf-abb7-5bf281dfd249 in state Running and restarted = false cannot be started and should not have been fetched.; ```. with a lengthy list of workflows listed with the same error message. All of these workflows came to a stop. In fact, querying cromwell, I saw:. ```; $ curl http://localhost:8000/engine/v1/stats; {""workflows"":0,""jobs"":0}; ```. I have been able to now restart cromwell and submit new workflows and get them running, but these other workflows were fairly well along. I would like to get them started again. What is the best way to do this?. ```; $ curl http://localhost:8000/engine/v1/version; {""cromwell"":""32-c07d8d9-SNAP""}; ```. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3673#issuecomment-391771784
https://github.com/broadinstitute/cromwell/issues/3673#issuecomment-391771784:719,Availability,error,error,719,"I believe that I am running into this problem with a batch of workflows.; I have a Cromwell instance running on GCE (launched via `docker-compose ... up`). Cromwell had gotten stuck accepting new workflow requests, so I shut it down and it didn't go down cleanly. After restarting Cromwell, I see:. ```; cromwell_1 | 2018-05-24 16:03:29,668 cromwell-system-akka.dispatchers.engine-dispatcher-27 ERROR - Error trying to fetch new workflows; cromwell_1 | common.exception.AggregatedMessageException: Error(s):; cromwell_1 | Workflow a07583dd-f571-44bf-abb7-5bf281dfd249 in state Running and restarted = false cannot be started and should not have been fetched.; ```. with a lengthy list of workflows listed with the same error message. All of these workflows came to a stop. In fact, querying cromwell, I saw:. ```; $ curl http://localhost:8000/engine/v1/stats; {""workflows"":0,""jobs"":0}; ```. I have been able to now restart cromwell and submit new workflows and get them running, but these other workflows were fairly well along. I would like to get them started again. What is the best way to do this?. ```; $ curl http://localhost:8000/engine/v1/version; {""cromwell"":""32-c07d8d9-SNAP""}; ```. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3673#issuecomment-391771784
https://github.com/broadinstitute/cromwell/issues/3673#issuecomment-391771784:725,Integrability,message,message,725,"I believe that I am running into this problem with a batch of workflows.; I have a Cromwell instance running on GCE (launched via `docker-compose ... up`). Cromwell had gotten stuck accepting new workflow requests, so I shut it down and it didn't go down cleanly. After restarting Cromwell, I see:. ```; cromwell_1 | 2018-05-24 16:03:29,668 cromwell-system-akka.dispatchers.engine-dispatcher-27 ERROR - Error trying to fetch new workflows; cromwell_1 | common.exception.AggregatedMessageException: Error(s):; cromwell_1 | Workflow a07583dd-f571-44bf-abb7-5bf281dfd249 in state Running and restarted = false cannot be started and should not have been fetched.; ```. with a lengthy list of workflows listed with the same error message. All of these workflows came to a stop. In fact, querying cromwell, I saw:. ```; $ curl http://localhost:8000/engine/v1/stats; {""workflows"":0,""jobs"":0}; ```. I have been able to now restart cromwell and submit new workflows and get them running, but these other workflows were fairly well along. I would like to get them started again. What is the best way to do this?. ```; $ curl http://localhost:8000/engine/v1/version; {""cromwell"":""32-c07d8d9-SNAP""}; ```. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3673#issuecomment-391771784
https://github.com/broadinstitute/cromwell/issues/3673#issuecomment-391869122:319,Usability,resume,resumed,319,"Hi Matt. Without looking at your DB I can't be sure exactly what the states of your workflows are, but I don't think it would hurt to try a more recent 32 snapshot with the fixes for this issue to see if that helps. If the workflows are still in the workflow store there's at least a chance they would be picked up and resumed on a Cromwell restart.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3673#issuecomment-391869122
https://github.com/broadinstitute/cromwell/issues/3673#issuecomment-391895624:426,Deployability,update,updated,426,"Is there anything you can suggest with regards to ""looking at your DB""?; Are there queries I could issue myself?. If I understand correctly, when I run `docker-compose ... build`, the Dockerfile is just pulling `broadinstitute/cromwell:develop`. When I look at https://hub.docker.com/r/broadinstitute/cromwell/tags/, I don't see any 32 snapshots explicitly pushed, but I do see that `broadinstitute/cromwell:develop` has been updated. ```; $ docker run --rm -ti broadinstitute/cromwell:develop --version; cromwell 32-d30d9f0-SNAP; ```. I am planning on waiting for my current batch of workflows (that I newly submitted) to complete.; Then I will want to pull the more recent snapshot. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3673#issuecomment-391895624
https://github.com/broadinstitute/cromwell/issues/3680#issuecomment-414894231:85,Modifiability,config,config,85,"@Horneth @geoffjentry For the Dos filesystem, we can control the docker image at the config level. Is the expectation here to do the same for the GCS filesystem?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3680#issuecomment-414894231
https://github.com/broadinstitute/cromwell/issues/3680#issuecomment-415014146:52,Availability,avail,available,52,"Pretty much yes, also like I said we use a publicly available jq image to parse the cwl.output.json on every task, which was meant to be a ""let's get CWL working on PAPIv2 "" but not a permanent solution",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3680#issuecomment-415014146
https://github.com/broadinstitute/cromwell/pull/3682#issuecomment-391699492:46,Deployability,update,updates,46,üëç when above issues are addressed w/ comments/updates. [![Approved with PullApprove](https://img.shields.io/badge/one_reviewer-approved-brightgreen.svg)](https://pullapprove.com/broadinstitute/cromwell/pull-request/3682/?utm_source=github-pr&utm_medium=comment-badge&utm_campaign=broadinstitute/cromwell) [![Approved with PullApprove](https://img.shields.io/badge/two_reviewers-approved-brightgreen.svg)](https://pullapprove.com/broadinstitute/cromwell/pull-request/3682/?utm_source=github-pr&utm_medium=comment-badge&utm_campaign=broadinstitute/cromwell),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3682#issuecomment-391699492
https://github.com/broadinstitute/cromwell/pull/3687#issuecomment-391864246:22,Availability,error,errors,22,"Fixes the false build errors from contributors, such as during https://github.com/broadinstitute/cromwell/pull/3684",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3687#issuecomment-391864246
https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-392038451:134,Deployability,configurat,configuration,134,"Hi, I see you've indeed created a service account and gotten a json file, but I'm not seeing how you're passing it to Cromwell.; Your configuration uses `application_default` as authentication mode, and you are logged in using your personal gmail it seems.; Did you use this json in any way ?. To use the service account in Cromwell you'd want to either; 1 - Recommended) Change your configuration to use the service account instead of application default; You can see how to do that [here](https://cromwell.readthedocs.io/en/develop/backends/Google/); It is slightly outdated, instead of `pem-file` use `json-file` and the path to your json.; 2) You can keep application default and use [`gcloud auth activate-service-account`](https://cloud.google.com/sdk/gcloud/reference/auth/activate-service-account) to authenticate as the service account on your machine. Also could you print the result of `gcloud auth list` ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-392038451
https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-392038451:384,Deployability,configurat,configuration,384,"Hi, I see you've indeed created a service account and gotten a json file, but I'm not seeing how you're passing it to Cromwell.; Your configuration uses `application_default` as authentication mode, and you are logged in using your personal gmail it seems.; Did you use this json in any way ?. To use the service account in Cromwell you'd want to either; 1 - Recommended) Change your configuration to use the service account instead of application default; You can see how to do that [here](https://cromwell.readthedocs.io/en/develop/backends/Google/); It is slightly outdated, instead of `pem-file` use `json-file` and the path to your json.; 2) You can keep application default and use [`gcloud auth activate-service-account`](https://cloud.google.com/sdk/gcloud/reference/auth/activate-service-account) to authenticate as the service account on your machine. Also could you print the result of `gcloud auth list` ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-392038451
https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-392038451:134,Modifiability,config,configuration,134,"Hi, I see you've indeed created a service account and gotten a json file, but I'm not seeing how you're passing it to Cromwell.; Your configuration uses `application_default` as authentication mode, and you are logged in using your personal gmail it seems.; Did you use this json in any way ?. To use the service account in Cromwell you'd want to either; 1 - Recommended) Change your configuration to use the service account instead of application default; You can see how to do that [here](https://cromwell.readthedocs.io/en/develop/backends/Google/); It is slightly outdated, instead of `pem-file` use `json-file` and the path to your json.; 2) You can keep application default and use [`gcloud auth activate-service-account`](https://cloud.google.com/sdk/gcloud/reference/auth/activate-service-account) to authenticate as the service account on your machine. Also could you print the result of `gcloud auth list` ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-392038451
https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-392038451:384,Modifiability,config,configuration,384,"Hi, I see you've indeed created a service account and gotten a json file, but I'm not seeing how you're passing it to Cromwell.; Your configuration uses `application_default` as authentication mode, and you are logged in using your personal gmail it seems.; Did you use this json in any way ?. To use the service account in Cromwell you'd want to either; 1 - Recommended) Change your configuration to use the service account instead of application default; You can see how to do that [here](https://cromwell.readthedocs.io/en/develop/backends/Google/); It is slightly outdated, instead of `pem-file` use `json-file` and the path to your json.; 2) You can keep application default and use [`gcloud auth activate-service-account`](https://cloud.google.com/sdk/gcloud/reference/auth/activate-service-account) to authenticate as the service account on your machine. Also could you print the result of `gcloud auth list` ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-392038451
https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-392038451:178,Security,authenticat,authentication,178,"Hi, I see you've indeed created a service account and gotten a json file, but I'm not seeing how you're passing it to Cromwell.; Your configuration uses `application_default` as authentication mode, and you are logged in using your personal gmail it seems.; Did you use this json in any way ?. To use the service account in Cromwell you'd want to either; 1 - Recommended) Change your configuration to use the service account instead of application default; You can see how to do that [here](https://cromwell.readthedocs.io/en/develop/backends/Google/); It is slightly outdated, instead of `pem-file` use `json-file` and the path to your json.; 2) You can keep application default and use [`gcloud auth activate-service-account`](https://cloud.google.com/sdk/gcloud/reference/auth/activate-service-account) to authenticate as the service account on your machine. Also could you print the result of `gcloud auth list` ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-392038451
https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-392038451:809,Security,authenticat,authenticate,809,"Hi, I see you've indeed created a service account and gotten a json file, but I'm not seeing how you're passing it to Cromwell.; Your configuration uses `application_default` as authentication mode, and you are logged in using your personal gmail it seems.; Did you use this json in any way ?. To use the service account in Cromwell you'd want to either; 1 - Recommended) Change your configuration to use the service account instead of application default; You can see how to do that [here](https://cromwell.readthedocs.io/en/develop/backends/Google/); It is slightly outdated, instead of `pem-file` use `json-file` and the path to your json.; 2) You can keep application default and use [`gcloud auth activate-service-account`](https://cloud.google.com/sdk/gcloud/reference/auth/activate-service-account) to authenticate as the service account on your machine. Also could you print the result of `gcloud auth list` ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-392038451
https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-392038451:211,Testability,log,logged,211,"Hi, I see you've indeed created a service account and gotten a json file, but I'm not seeing how you're passing it to Cromwell.; Your configuration uses `application_default` as authentication mode, and you are logged in using your personal gmail it seems.; Did you use this json in any way ?. To use the service account in Cromwell you'd want to either; 1 - Recommended) Change your configuration to use the service account instead of application default; You can see how to do that [here](https://cromwell.readthedocs.io/en/develop/backends/Google/); It is slightly outdated, instead of `pem-file` use `json-file` and the path to your json.; 2) You can keep application default and use [`gcloud auth activate-service-account`](https://cloud.google.com/sdk/gcloud/reference/auth/activate-service-account) to authenticate as the service account on your machine. Also could you print the result of `gcloud auth list` ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-392038451
https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-392432321:318,Modifiability,variab,variable,318,"I got it working now by setting the service-account in `google.conf`. Excellent, thanks for your help!. I was looking into the wrong place: I didn't realize that Cromwell did not find the account at all, I thought it just had a problem with access rights. ----. To answers to your questions, I had set the environment variable; `export GOOGLE_APPLICATION_CREDENTIALS=/Users/jwilppu/cromwell/project-test1-59b66448c3ab.json`; by following these instructions https://cromwell.readthedocs.io/en/develop/tutorials/PipelinesApi101/ which has a link to this page https://cloud.google.com/docs/authentication/production . The result of command `gcloud auth list` is; ```; Credentialed Accounts; ACTIVE ACCOUNT; * juha.wilppu@gmail.com. To set the active account, run:; $ gcloud config set account `ACCOUNT`; ```. I have now removed the environment variable.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-392432321
https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-392432321:771,Modifiability,config,config,771,"I got it working now by setting the service-account in `google.conf`. Excellent, thanks for your help!. I was looking into the wrong place: I didn't realize that Cromwell did not find the account at all, I thought it just had a problem with access rights. ----. To answers to your questions, I had set the environment variable; `export GOOGLE_APPLICATION_CREDENTIALS=/Users/jwilppu/cromwell/project-test1-59b66448c3ab.json`; by following these instructions https://cromwell.readthedocs.io/en/develop/tutorials/PipelinesApi101/ which has a link to this page https://cloud.google.com/docs/authentication/production . The result of command `gcloud auth list` is; ```; Credentialed Accounts; ACTIVE ACCOUNT; * juha.wilppu@gmail.com. To set the active account, run:; $ gcloud config set account `ACCOUNT`; ```. I have now removed the environment variable.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-392432321
https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-392432321:841,Modifiability,variab,variable,841,"I got it working now by setting the service-account in `google.conf`. Excellent, thanks for your help!. I was looking into the wrong place: I didn't realize that Cromwell did not find the account at all, I thought it just had a problem with access rights. ----. To answers to your questions, I had set the environment variable; `export GOOGLE_APPLICATION_CREDENTIALS=/Users/jwilppu/cromwell/project-test1-59b66448c3ab.json`; by following these instructions https://cromwell.readthedocs.io/en/develop/tutorials/PipelinesApi101/ which has a link to this page https://cloud.google.com/docs/authentication/production . The result of command `gcloud auth list` is; ```; Credentialed Accounts; ACTIVE ACCOUNT; * juha.wilppu@gmail.com. To set the active account, run:; $ gcloud config set account `ACCOUNT`; ```. I have now removed the environment variable.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-392432321
https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-392432321:241,Security,access,access,241,"I got it working now by setting the service-account in `google.conf`. Excellent, thanks for your help!. I was looking into the wrong place: I didn't realize that Cromwell did not find the account at all, I thought it just had a problem with access rights. ----. To answers to your questions, I had set the environment variable; `export GOOGLE_APPLICATION_CREDENTIALS=/Users/jwilppu/cromwell/project-test1-59b66448c3ab.json`; by following these instructions https://cromwell.readthedocs.io/en/develop/tutorials/PipelinesApi101/ which has a link to this page https://cloud.google.com/docs/authentication/production . The result of command `gcloud auth list` is; ```; Credentialed Accounts; ACTIVE ACCOUNT; * juha.wilppu@gmail.com. To set the active account, run:; $ gcloud config set account `ACCOUNT`; ```. I have now removed the environment variable.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-392432321
https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-392432321:587,Security,authenticat,authentication,587,"I got it working now by setting the service-account in `google.conf`. Excellent, thanks for your help!. I was looking into the wrong place: I didn't realize that Cromwell did not find the account at all, I thought it just had a problem with access rights. ----. To answers to your questions, I had set the environment variable; `export GOOGLE_APPLICATION_CREDENTIALS=/Users/jwilppu/cromwell/project-test1-59b66448c3ab.json`; by following these instructions https://cromwell.readthedocs.io/en/develop/tutorials/PipelinesApi101/ which has a link to this page https://cloud.google.com/docs/authentication/production . The result of command `gcloud auth list` is; ```; Credentialed Accounts; ACTIVE ACCOUNT; * juha.wilppu@gmail.com. To set the active account, run:; $ gcloud config set account `ACCOUNT`; ```. I have now removed the environment variable.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-392432321
https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-392807644:56,Deployability,update,update,56,"That's good to know thanks, looks like the docs need an update :); I'm going to close this ticket, don't hesitate to re-open it if you run into the same issue again.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-392807644
https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-432526506:167,Modifiability,variab,variable,167,"Hmm, this seems a bit odd. The `application_default` authentication should still work with a service account, as long as you set the `$GOOGLE_APPLICATION_CREDENTIALS` variable is set, which @juhawilppu seems to have done here. I had this same issue, where my service account only worked once I used a `scheme = ""service_account""`, but that seems like something is implemented wrongly.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-432526506
https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-432526506:53,Security,authenticat,authentication,53,"Hmm, this seems a bit odd. The `application_default` authentication should still work with a service account, as long as you set the `$GOOGLE_APPLICATION_CREDENTIALS` variable is set, which @juhawilppu seems to have done here. I had this same issue, where my service account only worked once I used a `scheme = ""service_account""`, but that seems like something is implemented wrongly.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-432526506
https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906:37,Availability,error,error,37,"I had the same issue. I got the same error message:; ```; [2020-07-27 18:34:00,37] [error] PipelinesApiAsyncBackendJobExecutionActor [3d2d7a27wf_hello.hello:NA:1]: Error attempting to Execute; cromwell.engine.io.IoAttempts$EnhancedCromwellIoException: [Attempted 1 time(s)] - StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; Caused by: com.google.cloud.storage.StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; ```; I had set up my credentials with:; ```; export GOOGLE_APPLICATION_CREDENTIALS=sa.json; ```; and had this configuration in `google.conf` copied from the [tutorial](https://cromwell.readthedocs.io/en/stable/tutorials/PipelinesApi101/):; ```; google {; application-name = ""cromwell""; auths = [; {; name = ""application-default""; scheme = ""application_default""; }; ]; }. engine {; filesystems {; gcs {; auth = ""application-default""; project = ""xxx""; }; }; }; ```; That clearly did not work. I tried to follow the logic in this post. I followed Horneth suggestion to use `service-account`'s authorization and I took the [auths](https://cromwell.readthedocs.io/en/develop/backends/Google/) configuration and changed `pem-file` to `json-file` in `google.conf` as follows:; ```; google {; application-name = ""cromwell""; auths = [; {; name = ""service_account""; scheme = ""service_account""; service-account-id = ""xxx@xxx.iam.gserviceaccount.com""; json-file = ""sa.json""; }; ]; }. engine {; filesystems {; gcs {; auth = ""service_account""; project = ""xxx""; }; }; }; ```; And I have replaced every other instance of `auth = ""application-default""` with `auth = ""service_account""`. Now when I run Cromwell:; ```; java -Dconfig.file=google.conf -jar cromwell-52.jar run hello.wdl -i hello.inputs; ```; I don't get the error anymore. I do get a different error:; ```; [2020-07-27 22:54:56,48] [info] WorkflowManagerActor Workflow 0fb5e69d-7d70-407e-9",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906
https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906:84,Availability,error,error,84,"I had the same issue. I got the same error message:; ```; [2020-07-27 18:34:00,37] [error] PipelinesApiAsyncBackendJobExecutionActor [3d2d7a27wf_hello.hello:NA:1]: Error attempting to Execute; cromwell.engine.io.IoAttempts$EnhancedCromwellIoException: [Attempted 1 time(s)] - StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; Caused by: com.google.cloud.storage.StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; ```; I had set up my credentials with:; ```; export GOOGLE_APPLICATION_CREDENTIALS=sa.json; ```; and had this configuration in `google.conf` copied from the [tutorial](https://cromwell.readthedocs.io/en/stable/tutorials/PipelinesApi101/):; ```; google {; application-name = ""cromwell""; auths = [; {; name = ""application-default""; scheme = ""application_default""; }; ]; }. engine {; filesystems {; gcs {; auth = ""application-default""; project = ""xxx""; }; }; }; ```; That clearly did not work. I tried to follow the logic in this post. I followed Horneth suggestion to use `service-account`'s authorization and I took the [auths](https://cromwell.readthedocs.io/en/develop/backends/Google/) configuration and changed `pem-file` to `json-file` in `google.conf` as follows:; ```; google {; application-name = ""cromwell""; auths = [; {; name = ""service_account""; scheme = ""service_account""; service-account-id = ""xxx@xxx.iam.gserviceaccount.com""; json-file = ""sa.json""; }; ]; }. engine {; filesystems {; gcs {; auth = ""service_account""; project = ""xxx""; }; }; }; ```; And I have replaced every other instance of `auth = ""application-default""` with `auth = ""service_account""`. Now when I run Cromwell:; ```; java -Dconfig.file=google.conf -jar cromwell-52.jar run hello.wdl -i hello.inputs; ```; I don't get the error anymore. I do get a different error:; ```; [2020-07-27 22:54:56,48] [info] WorkflowManagerActor Workflow 0fb5e69d-7d70-407e-9",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906
https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906:164,Availability,Error,Error,164,"I had the same issue. I got the same error message:; ```; [2020-07-27 18:34:00,37] [error] PipelinesApiAsyncBackendJobExecutionActor [3d2d7a27wf_hello.hello:NA:1]: Error attempting to Execute; cromwell.engine.io.IoAttempts$EnhancedCromwellIoException: [Attempted 1 time(s)] - StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; Caused by: com.google.cloud.storage.StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; ```; I had set up my credentials with:; ```; export GOOGLE_APPLICATION_CREDENTIALS=sa.json; ```; and had this configuration in `google.conf` copied from the [tutorial](https://cromwell.readthedocs.io/en/stable/tutorials/PipelinesApi101/):; ```; google {; application-name = ""cromwell""; auths = [; {; name = ""application-default""; scheme = ""application_default""; }; ]; }. engine {; filesystems {; gcs {; auth = ""application-default""; project = ""xxx""; }; }; }; ```; That clearly did not work. I tried to follow the logic in this post. I followed Horneth suggestion to use `service-account`'s authorization and I took the [auths](https://cromwell.readthedocs.io/en/develop/backends/Google/) configuration and changed `pem-file` to `json-file` in `google.conf` as follows:; ```; google {; application-name = ""cromwell""; auths = [; {; name = ""service_account""; scheme = ""service_account""; service-account-id = ""xxx@xxx.iam.gserviceaccount.com""; json-file = ""sa.json""; }; ]; }. engine {; filesystems {; gcs {; auth = ""service_account""; project = ""xxx""; }; }; }; ```; And I have replaced every other instance of `auth = ""application-default""` with `auth = ""service_account""`. Now when I run Cromwell:; ```; java -Dconfig.file=google.conf -jar cromwell-52.jar run hello.wdl -i hello.inputs; ```; I don't get the error anymore. I do get a different error:; ```; [2020-07-27 22:54:56,48] [info] WorkflowManagerActor Workflow 0fb5e69d-7d70-407e-9",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906
https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906:1870,Availability,error,error,1870," {; name = ""application-default""; scheme = ""application_default""; }; ]; }. engine {; filesystems {; gcs {; auth = ""application-default""; project = ""xxx""; }; }; }; ```; That clearly did not work. I tried to follow the logic in this post. I followed Horneth suggestion to use `service-account`'s authorization and I took the [auths](https://cromwell.readthedocs.io/en/develop/backends/Google/) configuration and changed `pem-file` to `json-file` in `google.conf` as follows:; ```; google {; application-name = ""cromwell""; auths = [; {; name = ""service_account""; scheme = ""service_account""; service-account-id = ""xxx@xxx.iam.gserviceaccount.com""; json-file = ""sa.json""; }; ]; }. engine {; filesystems {; gcs {; auth = ""service_account""; project = ""xxx""; }; }; }; ```; And I have replaced every other instance of `auth = ""application-default""` with `auth = ""service_account""`. Now when I run Cromwell:; ```; java -Dconfig.file=google.conf -jar cromwell-52.jar run hello.wdl -i hello.inputs; ```; I don't get the error anymore. I do get a different error:; ```; [2020-07-27 22:54:56,48] [info] WorkflowManagerActor Workflow 0fb5e69d-7d70-407e-9fe2-bf7cb2b2c3e6 failed (during ExecutingWorkflowState): java.lang.Exception: Task wf_hello.hello:NA:1 failed. The job was stopped before the command finished. PAPI error code 7. Required 'compute.zones.list' permission for 'projects/xxx'; ```; I don't know what this means. If I remove `Requester pays` from the bucket I can get the WDL to work using `scheme = ""application_default""`, as long as I do not export `GOOGLE_APPLICATION_CREDENTIALS` first. But if I use `Requester pays` on the bucket, using `scheme = ""application_default""` causes error:; ```; [2020-07-27 23:19:31,90] [info] WorkflowManagerActor Workflow 4c8a642a-19a6-486b-acad-e0adf3168820 failed (during ExecutingWorkflowState): java.lang.Exception: Task wf_hello.hello:NA:1 failed. The job was stopped before the command finished. PAPI error code 10. 15: Gsutil failed: failed to upload logs fo",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906
https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906:1906,Availability,error,error,1906," = ""application-default""; project = ""xxx""; }; }; }; ```; That clearly did not work. I tried to follow the logic in this post. I followed Horneth suggestion to use `service-account`'s authorization and I took the [auths](https://cromwell.readthedocs.io/en/develop/backends/Google/) configuration and changed `pem-file` to `json-file` in `google.conf` as follows:; ```; google {; application-name = ""cromwell""; auths = [; {; name = ""service_account""; scheme = ""service_account""; service-account-id = ""xxx@xxx.iam.gserviceaccount.com""; json-file = ""sa.json""; }; ]; }. engine {; filesystems {; gcs {; auth = ""service_account""; project = ""xxx""; }; }; }; ```; And I have replaced every other instance of `auth = ""application-default""` with `auth = ""service_account""`. Now when I run Cromwell:; ```; java -Dconfig.file=google.conf -jar cromwell-52.jar run hello.wdl -i hello.inputs; ```; I don't get the error anymore. I do get a different error:; ```; [2020-07-27 22:54:56,48] [info] WorkflowManagerActor Workflow 0fb5e69d-7d70-407e-9fe2-bf7cb2b2c3e6 failed (during ExecutingWorkflowState): java.lang.Exception: Task wf_hello.hello:NA:1 failed. The job was stopped before the command finished. PAPI error code 7. Required 'compute.zones.list' permission for 'projects/xxx'; ```; I don't know what this means. If I remove `Requester pays` from the bucket I can get the WDL to work using `scheme = ""application_default""`, as long as I do not export `GOOGLE_APPLICATION_CREDENTIALS` first. But if I use `Requester pays` on the bucket, using `scheme = ""application_default""` causes error:; ```; [2020-07-27 23:19:31,90] [info] WorkflowManagerActor Workflow 4c8a642a-19a6-486b-acad-e0adf3168820 failed (during ExecutingWorkflowState): java.lang.Exception: Task wf_hello.hello:NA:1 failed. The job was stopped before the command finished. PAPI error code 10. 15: Gsutil failed: failed to upload logs for ""gs://xxx/cromwell-execution/wf_hello/4c8a642a-19a6-486b-acad-e0adf3168820/call-hello/"": cp failed: gsutil -h",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906
https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906:2166,Availability,error,error,2166," and I took the [auths](https://cromwell.readthedocs.io/en/develop/backends/Google/) configuration and changed `pem-file` to `json-file` in `google.conf` as follows:; ```; google {; application-name = ""cromwell""; auths = [; {; name = ""service_account""; scheme = ""service_account""; service-account-id = ""xxx@xxx.iam.gserviceaccount.com""; json-file = ""sa.json""; }; ]; }. engine {; filesystems {; gcs {; auth = ""service_account""; project = ""xxx""; }; }; }; ```; And I have replaced every other instance of `auth = ""application-default""` with `auth = ""service_account""`. Now when I run Cromwell:; ```; java -Dconfig.file=google.conf -jar cromwell-52.jar run hello.wdl -i hello.inputs; ```; I don't get the error anymore. I do get a different error:; ```; [2020-07-27 22:54:56,48] [info] WorkflowManagerActor Workflow 0fb5e69d-7d70-407e-9fe2-bf7cb2b2c3e6 failed (during ExecutingWorkflowState): java.lang.Exception: Task wf_hello.hello:NA:1 failed. The job was stopped before the command finished. PAPI error code 7. Required 'compute.zones.list' permission for 'projects/xxx'; ```; I don't know what this means. If I remove `Requester pays` from the bucket I can get the WDL to work using `scheme = ""application_default""`, as long as I do not export `GOOGLE_APPLICATION_CREDENTIALS` first. But if I use `Requester pays` on the bucket, using `scheme = ""application_default""` causes error:; ```; [2020-07-27 23:19:31,90] [info] WorkflowManagerActor Workflow 4c8a642a-19a6-486b-acad-e0adf3168820 failed (during ExecutingWorkflowState): java.lang.Exception: Task wf_hello.hello:NA:1 failed. The job was stopped before the command finished. PAPI error code 10. 15: Gsutil failed: failed to upload logs for ""gs://xxx/cromwell-execution/wf_hello/4c8a642a-19a6-486b-acad-e0adf3168820/call-hello/"": cp failed: gsutil -h Content-type:text/plain -q -m cp /var/log/google-genomics/*.log gs://xxx/cromwell-execution/wf_hello/4c8a642a-19a6-486b-acad-e0adf3168820/call-hello/, command failed: BadRequestException: 400 Buc",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906
https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906:2545,Availability,error,error,2545,"e = ""sa.json""; }; ]; }. engine {; filesystems {; gcs {; auth = ""service_account""; project = ""xxx""; }; }; }; ```; And I have replaced every other instance of `auth = ""application-default""` with `auth = ""service_account""`. Now when I run Cromwell:; ```; java -Dconfig.file=google.conf -jar cromwell-52.jar run hello.wdl -i hello.inputs; ```; I don't get the error anymore. I do get a different error:; ```; [2020-07-27 22:54:56,48] [info] WorkflowManagerActor Workflow 0fb5e69d-7d70-407e-9fe2-bf7cb2b2c3e6 failed (during ExecutingWorkflowState): java.lang.Exception: Task wf_hello.hello:NA:1 failed. The job was stopped before the command finished. PAPI error code 7. Required 'compute.zones.list' permission for 'projects/xxx'; ```; I don't know what this means. If I remove `Requester pays` from the bucket I can get the WDL to work using `scheme = ""application_default""`, as long as I do not export `GOOGLE_APPLICATION_CREDENTIALS` first. But if I use `Requester pays` on the bucket, using `scheme = ""application_default""` causes error:; ```; [2020-07-27 23:19:31,90] [info] WorkflowManagerActor Workflow 4c8a642a-19a6-486b-acad-e0adf3168820 failed (during ExecutingWorkflowState): java.lang.Exception: Task wf_hello.hello:NA:1 failed. The job was stopped before the command finished. PAPI error code 10. 15: Gsutil failed: failed to upload logs for ""gs://xxx/cromwell-execution/wf_hello/4c8a642a-19a6-486b-acad-e0adf3168820/call-hello/"": cp failed: gsutil -h Content-type:text/plain -q -m cp /var/log/google-genomics/*.log gs://xxx/cromwell-execution/wf_hello/4c8a642a-19a6-486b-acad-e0adf3168820/call-hello/, command failed: BadRequestException: 400 Bucket is requester pays bucket but no user project provided.; ```. So I still have not found a way to run the WDL with `Requester pays` on. I wish Cromwell could give errors explaining what steps to take to solve the issue ... I know that with `gsutil` I can specify the user project with `-u xxx` but I have no idea how to do that with Cromwell.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906
https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906:2805,Availability,error,error,2805,"e = ""sa.json""; }; ]; }. engine {; filesystems {; gcs {; auth = ""service_account""; project = ""xxx""; }; }; }; ```; And I have replaced every other instance of `auth = ""application-default""` with `auth = ""service_account""`. Now when I run Cromwell:; ```; java -Dconfig.file=google.conf -jar cromwell-52.jar run hello.wdl -i hello.inputs; ```; I don't get the error anymore. I do get a different error:; ```; [2020-07-27 22:54:56,48] [info] WorkflowManagerActor Workflow 0fb5e69d-7d70-407e-9fe2-bf7cb2b2c3e6 failed (during ExecutingWorkflowState): java.lang.Exception: Task wf_hello.hello:NA:1 failed. The job was stopped before the command finished. PAPI error code 7. Required 'compute.zones.list' permission for 'projects/xxx'; ```; I don't know what this means. If I remove `Requester pays` from the bucket I can get the WDL to work using `scheme = ""application_default""`, as long as I do not export `GOOGLE_APPLICATION_CREDENTIALS` first. But if I use `Requester pays` on the bucket, using `scheme = ""application_default""` causes error:; ```; [2020-07-27 23:19:31,90] [info] WorkflowManagerActor Workflow 4c8a642a-19a6-486b-acad-e0adf3168820 failed (during ExecutingWorkflowState): java.lang.Exception: Task wf_hello.hello:NA:1 failed. The job was stopped before the command finished. PAPI error code 10. 15: Gsutil failed: failed to upload logs for ""gs://xxx/cromwell-execution/wf_hello/4c8a642a-19a6-486b-acad-e0adf3168820/call-hello/"": cp failed: gsutil -h Content-type:text/plain -q -m cp /var/log/google-genomics/*.log gs://xxx/cromwell-execution/wf_hello/4c8a642a-19a6-486b-acad-e0adf3168820/call-hello/, command failed: BadRequestException: 400 Bucket is requester pays bucket but no user project provided.; ```. So I still have not found a way to run the WDL with `Requester pays` on. I wish Cromwell could give errors explaining what steps to take to solve the issue ... I know that with `gsutil` I can specify the user project with `-u xxx` but I have no idea how to do that with Cromwell.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906
https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906:3335,Availability,error,errors,3335,"e = ""sa.json""; }; ]; }. engine {; filesystems {; gcs {; auth = ""service_account""; project = ""xxx""; }; }; }; ```; And I have replaced every other instance of `auth = ""application-default""` with `auth = ""service_account""`. Now when I run Cromwell:; ```; java -Dconfig.file=google.conf -jar cromwell-52.jar run hello.wdl -i hello.inputs; ```; I don't get the error anymore. I do get a different error:; ```; [2020-07-27 22:54:56,48] [info] WorkflowManagerActor Workflow 0fb5e69d-7d70-407e-9fe2-bf7cb2b2c3e6 failed (during ExecutingWorkflowState): java.lang.Exception: Task wf_hello.hello:NA:1 failed. The job was stopped before the command finished. PAPI error code 7. Required 'compute.zones.list' permission for 'projects/xxx'; ```; I don't know what this means. If I remove `Requester pays` from the bucket I can get the WDL to work using `scheme = ""application_default""`, as long as I do not export `GOOGLE_APPLICATION_CREDENTIALS` first. But if I use `Requester pays` on the bucket, using `scheme = ""application_default""` causes error:; ```; [2020-07-27 23:19:31,90] [info] WorkflowManagerActor Workflow 4c8a642a-19a6-486b-acad-e0adf3168820 failed (during ExecutingWorkflowState): java.lang.Exception: Task wf_hello.hello:NA:1 failed. The job was stopped before the command finished. PAPI error code 10. 15: Gsutil failed: failed to upload logs for ""gs://xxx/cromwell-execution/wf_hello/4c8a642a-19a6-486b-acad-e0adf3168820/call-hello/"": cp failed: gsutil -h Content-type:text/plain -q -m cp /var/log/google-genomics/*.log gs://xxx/cromwell-execution/wf_hello/4c8a642a-19a6-486b-acad-e0adf3168820/call-hello/, command failed: BadRequestException: 400 Bucket is requester pays bucket but no user project provided.; ```. So I still have not found a way to run the WDL with `Requester pays` on. I wish Cromwell could give errors explaining what steps to take to solve the issue ... I know that with `gsutil` I can specify the user project with `-u xxx` but I have no idea how to do that with Cromwell.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906
https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906:91,Deployability,Pipeline,PipelinesApiAsyncBackendJobExecutionActor,91,"I had the same issue. I got the same error message:; ```; [2020-07-27 18:34:00,37] [error] PipelinesApiAsyncBackendJobExecutionActor [3d2d7a27wf_hello.hello:NA:1]: Error attempting to Execute; cromwell.engine.io.IoAttempts$EnhancedCromwellIoException: [Attempted 1 time(s)] - StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; Caused by: com.google.cloud.storage.StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; ```; I had set up my credentials with:; ```; export GOOGLE_APPLICATION_CREDENTIALS=sa.json; ```; and had this configuration in `google.conf` copied from the [tutorial](https://cromwell.readthedocs.io/en/stable/tutorials/PipelinesApi101/):; ```; google {; application-name = ""cromwell""; auths = [; {; name = ""application-default""; scheme = ""application_default""; }; ]; }. engine {; filesystems {; gcs {; auth = ""application-default""; project = ""xxx""; }; }; }; ```; That clearly did not work. I tried to follow the logic in this post. I followed Horneth suggestion to use `service-account`'s authorization and I took the [auths](https://cromwell.readthedocs.io/en/develop/backends/Google/) configuration and changed `pem-file` to `json-file` in `google.conf` as follows:; ```; google {; application-name = ""cromwell""; auths = [; {; name = ""service_account""; scheme = ""service_account""; service-account-id = ""xxx@xxx.iam.gserviceaccount.com""; json-file = ""sa.json""; }; ]; }. engine {; filesystems {; gcs {; auth = ""service_account""; project = ""xxx""; }; }; }; ```; And I have replaced every other instance of `auth = ""application-default""` with `auth = ""service_account""`. Now when I run Cromwell:; ```; java -Dconfig.file=google.conf -jar cromwell-52.jar run hello.wdl -i hello.inputs; ```; I don't get the error anymore. I do get a different error:; ```; [2020-07-27 22:54:56,48] [info] WorkflowManagerActor Workflow 0fb5e69d-7d70-407e-9",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906
https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906:676,Deployability,configurat,configuration,676,"I had the same issue. I got the same error message:; ```; [2020-07-27 18:34:00,37] [error] PipelinesApiAsyncBackendJobExecutionActor [3d2d7a27wf_hello.hello:NA:1]: Error attempting to Execute; cromwell.engine.io.IoAttempts$EnhancedCromwellIoException: [Attempted 1 time(s)] - StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; Caused by: com.google.cloud.storage.StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; ```; I had set up my credentials with:; ```; export GOOGLE_APPLICATION_CREDENTIALS=sa.json; ```; and had this configuration in `google.conf` copied from the [tutorial](https://cromwell.readthedocs.io/en/stable/tutorials/PipelinesApi101/):; ```; google {; application-name = ""cromwell""; auths = [; {; name = ""application-default""; scheme = ""application_default""; }; ]; }. engine {; filesystems {; gcs {; auth = ""application-default""; project = ""xxx""; }; }; }; ```; That clearly did not work. I tried to follow the logic in this post. I followed Horneth suggestion to use `service-account`'s authorization and I took the [auths](https://cromwell.readthedocs.io/en/develop/backends/Google/) configuration and changed `pem-file` to `json-file` in `google.conf` as follows:; ```; google {; application-name = ""cromwell""; auths = [; {; name = ""service_account""; scheme = ""service_account""; service-account-id = ""xxx@xxx.iam.gserviceaccount.com""; json-file = ""sa.json""; }; ]; }. engine {; filesystems {; gcs {; auth = ""service_account""; project = ""xxx""; }; }; }; ```; And I have replaced every other instance of `auth = ""application-default""` with `auth = ""service_account""`. Now when I run Cromwell:; ```; java -Dconfig.file=google.conf -jar cromwell-52.jar run hello.wdl -i hello.inputs; ```; I don't get the error anymore. I do get a different error:; ```; [2020-07-27 22:54:56,48] [info] WorkflowManagerActor Workflow 0fb5e69d-7d70-407e-9",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906
https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906:1254,Deployability,configurat,configuration,1254,"(s)] - StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; Caused by: com.google.cloud.storage.StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; ```; I had set up my credentials with:; ```; export GOOGLE_APPLICATION_CREDENTIALS=sa.json; ```; and had this configuration in `google.conf` copied from the [tutorial](https://cromwell.readthedocs.io/en/stable/tutorials/PipelinesApi101/):; ```; google {; application-name = ""cromwell""; auths = [; {; name = ""application-default""; scheme = ""application_default""; }; ]; }. engine {; filesystems {; gcs {; auth = ""application-default""; project = ""xxx""; }; }; }; ```; That clearly did not work. I tried to follow the logic in this post. I followed Horneth suggestion to use `service-account`'s authorization and I took the [auths](https://cromwell.readthedocs.io/en/develop/backends/Google/) configuration and changed `pem-file` to `json-file` in `google.conf` as follows:; ```; google {; application-name = ""cromwell""; auths = [; {; name = ""service_account""; scheme = ""service_account""; service-account-id = ""xxx@xxx.iam.gserviceaccount.com""; json-file = ""sa.json""; }; ]; }. engine {; filesystems {; gcs {; auth = ""service_account""; project = ""xxx""; }; }; }; ```; And I have replaced every other instance of `auth = ""application-default""` with `auth = ""service_account""`. Now when I run Cromwell:; ```; java -Dconfig.file=google.conf -jar cromwell-52.jar run hello.wdl -i hello.inputs; ```; I don't get the error anymore. I do get a different error:; ```; [2020-07-27 22:54:56,48] [info] WorkflowManagerActor Workflow 0fb5e69d-7d70-407e-9fe2-bf7cb2b2c3e6 failed (during ExecutingWorkflowState): java.lang.Exception: Task wf_hello.hello:NA:1 failed. The job was stopped before the command finished. PAPI error code 7. Required 'compute.zones.list' permission for 'projects/xxx'; ```; I don't know what this m",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906
https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906:43,Integrability,message,message,43,"I had the same issue. I got the same error message:; ```; [2020-07-27 18:34:00,37] [error] PipelinesApiAsyncBackendJobExecutionActor [3d2d7a27wf_hello.hello:NA:1]: Error attempting to Execute; cromwell.engine.io.IoAttempts$EnhancedCromwellIoException: [Attempted 1 time(s)] - StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; Caused by: com.google.cloud.storage.StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; ```; I had set up my credentials with:; ```; export GOOGLE_APPLICATION_CREDENTIALS=sa.json; ```; and had this configuration in `google.conf` copied from the [tutorial](https://cromwell.readthedocs.io/en/stable/tutorials/PipelinesApi101/):; ```; google {; application-name = ""cromwell""; auths = [; {; name = ""application-default""; scheme = ""application_default""; }; ]; }. engine {; filesystems {; gcs {; auth = ""application-default""; project = ""xxx""; }; }; }; ```; That clearly did not work. I tried to follow the logic in this post. I followed Horneth suggestion to use `service-account`'s authorization and I took the [auths](https://cromwell.readthedocs.io/en/develop/backends/Google/) configuration and changed `pem-file` to `json-file` in `google.conf` as follows:; ```; google {; application-name = ""cromwell""; auths = [; {; name = ""service_account""; scheme = ""service_account""; service-account-id = ""xxx@xxx.iam.gserviceaccount.com""; json-file = ""sa.json""; }; ]; }. engine {; filesystems {; gcs {; auth = ""service_account""; project = ""xxx""; }; }; }; ```; And I have replaced every other instance of `auth = ""application-default""` with `auth = ""service_account""`. Now when I run Cromwell:; ```; java -Dconfig.file=google.conf -jar cromwell-52.jar run hello.wdl -i hello.inputs; ```; I don't get the error anymore. I do get a different error:; ```; [2020-07-27 22:54:56,48] [info] WorkflowManagerActor Workflow 0fb5e69d-7d70-407e-9",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906
https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906:223,Modifiability,Enhance,EnhancedCromwellIoException,223,"I had the same issue. I got the same error message:; ```; [2020-07-27 18:34:00,37] [error] PipelinesApiAsyncBackendJobExecutionActor [3d2d7a27wf_hello.hello:NA:1]: Error attempting to Execute; cromwell.engine.io.IoAttempts$EnhancedCromwellIoException: [Attempted 1 time(s)] - StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; Caused by: com.google.cloud.storage.StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; ```; I had set up my credentials with:; ```; export GOOGLE_APPLICATION_CREDENTIALS=sa.json; ```; and had this configuration in `google.conf` copied from the [tutorial](https://cromwell.readthedocs.io/en/stable/tutorials/PipelinesApi101/):; ```; google {; application-name = ""cromwell""; auths = [; {; name = ""application-default""; scheme = ""application_default""; }; ]; }. engine {; filesystems {; gcs {; auth = ""application-default""; project = ""xxx""; }; }; }; ```; That clearly did not work. I tried to follow the logic in this post. I followed Horneth suggestion to use `service-account`'s authorization and I took the [auths](https://cromwell.readthedocs.io/en/develop/backends/Google/) configuration and changed `pem-file` to `json-file` in `google.conf` as follows:; ```; google {; application-name = ""cromwell""; auths = [; {; name = ""service_account""; scheme = ""service_account""; service-account-id = ""xxx@xxx.iam.gserviceaccount.com""; json-file = ""sa.json""; }; ]; }. engine {; filesystems {; gcs {; auth = ""service_account""; project = ""xxx""; }; }; }; ```; And I have replaced every other instance of `auth = ""application-default""` with `auth = ""service_account""`. Now when I run Cromwell:; ```; java -Dconfig.file=google.conf -jar cromwell-52.jar run hello.wdl -i hello.inputs; ```; I don't get the error anymore. I do get a different error:; ```; [2020-07-27 22:54:56,48] [info] WorkflowManagerActor Workflow 0fb5e69d-7d70-407e-9",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906
https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906:676,Modifiability,config,configuration,676,"I had the same issue. I got the same error message:; ```; [2020-07-27 18:34:00,37] [error] PipelinesApiAsyncBackendJobExecutionActor [3d2d7a27wf_hello.hello:NA:1]: Error attempting to Execute; cromwell.engine.io.IoAttempts$EnhancedCromwellIoException: [Attempted 1 time(s)] - StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; Caused by: com.google.cloud.storage.StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; ```; I had set up my credentials with:; ```; export GOOGLE_APPLICATION_CREDENTIALS=sa.json; ```; and had this configuration in `google.conf` copied from the [tutorial](https://cromwell.readthedocs.io/en/stable/tutorials/PipelinesApi101/):; ```; google {; application-name = ""cromwell""; auths = [; {; name = ""application-default""; scheme = ""application_default""; }; ]; }. engine {; filesystems {; gcs {; auth = ""application-default""; project = ""xxx""; }; }; }; ```; That clearly did not work. I tried to follow the logic in this post. I followed Horneth suggestion to use `service-account`'s authorization and I took the [auths](https://cromwell.readthedocs.io/en/develop/backends/Google/) configuration and changed `pem-file` to `json-file` in `google.conf` as follows:; ```; google {; application-name = ""cromwell""; auths = [; {; name = ""service_account""; scheme = ""service_account""; service-account-id = ""xxx@xxx.iam.gserviceaccount.com""; json-file = ""sa.json""; }; ]; }. engine {; filesystems {; gcs {; auth = ""service_account""; project = ""xxx""; }; }; }; ```; And I have replaced every other instance of `auth = ""application-default""` with `auth = ""service_account""`. Now when I run Cromwell:; ```; java -Dconfig.file=google.conf -jar cromwell-52.jar run hello.wdl -i hello.inputs; ```; I don't get the error anymore. I do get a different error:; ```; [2020-07-27 22:54:56,48] [info] WorkflowManagerActor Workflow 0fb5e69d-7d70-407e-9",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906
https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906:1254,Modifiability,config,configuration,1254,"(s)] - StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; Caused by: com.google.cloud.storage.StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; ```; I had set up my credentials with:; ```; export GOOGLE_APPLICATION_CREDENTIALS=sa.json; ```; and had this configuration in `google.conf` copied from the [tutorial](https://cromwell.readthedocs.io/en/stable/tutorials/PipelinesApi101/):; ```; google {; application-name = ""cromwell""; auths = [; {; name = ""application-default""; scheme = ""application_default""; }; ]; }. engine {; filesystems {; gcs {; auth = ""application-default""; project = ""xxx""; }; }; }; ```; That clearly did not work. I tried to follow the logic in this post. I followed Horneth suggestion to use `service-account`'s authorization and I took the [auths](https://cromwell.readthedocs.io/en/develop/backends/Google/) configuration and changed `pem-file` to `json-file` in `google.conf` as follows:; ```; google {; application-name = ""cromwell""; auths = [; {; name = ""service_account""; scheme = ""service_account""; service-account-id = ""xxx@xxx.iam.gserviceaccount.com""; json-file = ""sa.json""; }; ]; }. engine {; filesystems {; gcs {; auth = ""service_account""; project = ""xxx""; }; }; }; ```; And I have replaced every other instance of `auth = ""application-default""` with `auth = ""service_account""`. Now when I run Cromwell:; ```; java -Dconfig.file=google.conf -jar cromwell-52.jar run hello.wdl -i hello.inputs; ```; I don't get the error anymore. I do get a different error:; ```; [2020-07-27 22:54:56,48] [info] WorkflowManagerActor Workflow 0fb5e69d-7d70-407e-9fe2-bf7cb2b2c3e6 failed (during ExecutingWorkflowState): java.lang.Exception: Task wf_hello.hello:NA:1 failed. The job was stopped before the command finished. PAPI error code 7. Required 'compute.zones.list' permission for 'projects/xxx'; ```; I don't know what this m",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906
https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906:366,Security,access,access,366,"I had the same issue. I got the same error message:; ```; [2020-07-27 18:34:00,37] [error] PipelinesApiAsyncBackendJobExecutionActor [3d2d7a27wf_hello.hello:NA:1]: Error attempting to Execute; cromwell.engine.io.IoAttempts$EnhancedCromwellIoException: [Attempted 1 time(s)] - StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; Caused by: com.google.cloud.storage.StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; ```; I had set up my credentials with:; ```; export GOOGLE_APPLICATION_CREDENTIALS=sa.json; ```; and had this configuration in `google.conf` copied from the [tutorial](https://cromwell.readthedocs.io/en/stable/tutorials/PipelinesApi101/):; ```; google {; application-name = ""cromwell""; auths = [; {; name = ""application-default""; scheme = ""application_default""; }; ]; }. engine {; filesystems {; gcs {; auth = ""application-default""; project = ""xxx""; }; }; }; ```; That clearly did not work. I tried to follow the logic in this post. I followed Horneth suggestion to use `service-account`'s authorization and I took the [auths](https://cromwell.readthedocs.io/en/develop/backends/Google/) configuration and changed `pem-file` to `json-file` in `google.conf` as follows:; ```; google {; application-name = ""cromwell""; auths = [; {; name = ""service_account""; scheme = ""service_account""; service-account-id = ""xxx@xxx.iam.gserviceaccount.com""; json-file = ""sa.json""; }; ]; }. engine {; filesystems {; gcs {; auth = ""service_account""; project = ""xxx""; }; }; }; ```; And I have replaced every other instance of `auth = ""application-default""` with `auth = ""service_account""`. Now when I run Cromwell:; ```; java -Dconfig.file=google.conf -jar cromwell-52.jar run hello.wdl -i hello.inputs; ```; I don't get the error anymore. I do get a different error:; ```; [2020-07-27 22:54:56,48] [info] WorkflowManagerActor Workflow 0fb5e69d-7d70-407e-9",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906
https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906:529,Security,access,access,529,"I had the same issue. I got the same error message:; ```; [2020-07-27 18:34:00,37] [error] PipelinesApiAsyncBackendJobExecutionActor [3d2d7a27wf_hello.hello:NA:1]: Error attempting to Execute; cromwell.engine.io.IoAttempts$EnhancedCromwellIoException: [Attempted 1 time(s)] - StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; Caused by: com.google.cloud.storage.StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; ```; I had set up my credentials with:; ```; export GOOGLE_APPLICATION_CREDENTIALS=sa.json; ```; and had this configuration in `google.conf` copied from the [tutorial](https://cromwell.readthedocs.io/en/stable/tutorials/PipelinesApi101/):; ```; google {; application-name = ""cromwell""; auths = [; {; name = ""application-default""; scheme = ""application_default""; }; ]; }. engine {; filesystems {; gcs {; auth = ""application-default""; project = ""xxx""; }; }; }; ```; That clearly did not work. I tried to follow the logic in this post. I followed Horneth suggestion to use `service-account`'s authorization and I took the [auths](https://cromwell.readthedocs.io/en/develop/backends/Google/) configuration and changed `pem-file` to `json-file` in `google.conf` as follows:; ```; google {; application-name = ""cromwell""; auths = [; {; name = ""service_account""; scheme = ""service_account""; service-account-id = ""xxx@xxx.iam.gserviceaccount.com""; json-file = ""sa.json""; }; ]; }. engine {; filesystems {; gcs {; auth = ""service_account""; project = ""xxx""; }; }; }; ```; And I have replaced every other instance of `auth = ""application-default""` with `auth = ""service_account""`. Now when I run Cromwell:; ```; java -Dconfig.file=google.conf -jar cromwell-52.jar run hello.wdl -i hello.inputs; ```; I don't get the error anymore. I do get a different error:; ```; [2020-07-27 22:54:56,48] [info] WorkflowManagerActor Workflow 0fb5e69d-7d70-407e-9",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906
https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906:1156,Security,authoriz,authorization,1156,"lo:NA:1]: Error attempting to Execute; cromwell.engine.io.IoAttempts$EnhancedCromwellIoException: [Attempted 1 time(s)] - StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; Caused by: com.google.cloud.storage.StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; ```; I had set up my credentials with:; ```; export GOOGLE_APPLICATION_CREDENTIALS=sa.json; ```; and had this configuration in `google.conf` copied from the [tutorial](https://cromwell.readthedocs.io/en/stable/tutorials/PipelinesApi101/):; ```; google {; application-name = ""cromwell""; auths = [; {; name = ""application-default""; scheme = ""application_default""; }; ]; }. engine {; filesystems {; gcs {; auth = ""application-default""; project = ""xxx""; }; }; }; ```; That clearly did not work. I tried to follow the logic in this post. I followed Horneth suggestion to use `service-account`'s authorization and I took the [auths](https://cromwell.readthedocs.io/en/develop/backends/Google/) configuration and changed `pem-file` to `json-file` in `google.conf` as follows:; ```; google {; application-name = ""cromwell""; auths = [; {; name = ""service_account""; scheme = ""service_account""; service-account-id = ""xxx@xxx.iam.gserviceaccount.com""; json-file = ""sa.json""; }; ]; }. engine {; filesystems {; gcs {; auth = ""service_account""; project = ""xxx""; }; }; }; ```; And I have replaced every other instance of `auth = ""application-default""` with `auth = ""service_account""`. Now when I run Cromwell:; ```; java -Dconfig.file=google.conf -jar cromwell-52.jar run hello.wdl -i hello.inputs; ```; I don't get the error anymore. I do get a different error:; ```; [2020-07-27 22:54:56,48] [info] WorkflowManagerActor Workflow 0fb5e69d-7d70-407e-9fe2-bf7cb2b2c3e6 failed (during ExecutingWorkflowState): java.lang.Exception: Task wf_hello.hello:NA:1 failed. The job was stopped before the command fin",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906
https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906:1079,Testability,log,logic,1079,"0,37] [error] PipelinesApiAsyncBackendJobExecutionActor [3d2d7a27wf_hello.hello:NA:1]: Error attempting to Execute; cromwell.engine.io.IoAttempts$EnhancedCromwellIoException: [Attempted 1 time(s)] - StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; Caused by: com.google.cloud.storage.StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; ```; I had set up my credentials with:; ```; export GOOGLE_APPLICATION_CREDENTIALS=sa.json; ```; and had this configuration in `google.conf` copied from the [tutorial](https://cromwell.readthedocs.io/en/stable/tutorials/PipelinesApi101/):; ```; google {; application-name = ""cromwell""; auths = [; {; name = ""application-default""; scheme = ""application_default""; }; ]; }. engine {; filesystems {; gcs {; auth = ""application-default""; project = ""xxx""; }; }; }; ```; That clearly did not work. I tried to follow the logic in this post. I followed Horneth suggestion to use `service-account`'s authorization and I took the [auths](https://cromwell.readthedocs.io/en/develop/backends/Google/) configuration and changed `pem-file` to `json-file` in `google.conf` as follows:; ```; google {; application-name = ""cromwell""; auths = [; {; name = ""service_account""; scheme = ""service_account""; service-account-id = ""xxx@xxx.iam.gserviceaccount.com""; json-file = ""sa.json""; }; ]; }. engine {; filesystems {; gcs {; auth = ""service_account""; project = ""xxx""; }; }; }; ```; And I have replaced every other instance of `auth = ""application-default""` with `auth = ""service_account""`. Now when I run Cromwell:; ```; java -Dconfig.file=google.conf -jar cromwell-52.jar run hello.wdl -i hello.inputs; ```; I don't get the error anymore. I do get a different error:; ```; [2020-07-27 22:54:56,48] [info] WorkflowManagerActor Workflow 0fb5e69d-7d70-407e-9fe2-bf7cb2b2c3e6 failed (during ExecutingWorkflowState): java.lang.Exception",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906
https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906:2856,Testability,log,logs,2856,"e = ""sa.json""; }; ]; }. engine {; filesystems {; gcs {; auth = ""service_account""; project = ""xxx""; }; }; }; ```; And I have replaced every other instance of `auth = ""application-default""` with `auth = ""service_account""`. Now when I run Cromwell:; ```; java -Dconfig.file=google.conf -jar cromwell-52.jar run hello.wdl -i hello.inputs; ```; I don't get the error anymore. I do get a different error:; ```; [2020-07-27 22:54:56,48] [info] WorkflowManagerActor Workflow 0fb5e69d-7d70-407e-9fe2-bf7cb2b2c3e6 failed (during ExecutingWorkflowState): java.lang.Exception: Task wf_hello.hello:NA:1 failed. The job was stopped before the command finished. PAPI error code 7. Required 'compute.zones.list' permission for 'projects/xxx'; ```; I don't know what this means. If I remove `Requester pays` from the bucket I can get the WDL to work using `scheme = ""application_default""`, as long as I do not export `GOOGLE_APPLICATION_CREDENTIALS` first. But if I use `Requester pays` on the bucket, using `scheme = ""application_default""` causes error:; ```; [2020-07-27 23:19:31,90] [info] WorkflowManagerActor Workflow 4c8a642a-19a6-486b-acad-e0adf3168820 failed (during ExecutingWorkflowState): java.lang.Exception: Task wf_hello.hello:NA:1 failed. The job was stopped before the command finished. PAPI error code 10. 15: Gsutil failed: failed to upload logs for ""gs://xxx/cromwell-execution/wf_hello/4c8a642a-19a6-486b-acad-e0adf3168820/call-hello/"": cp failed: gsutil -h Content-type:text/plain -q -m cp /var/log/google-genomics/*.log gs://xxx/cromwell-execution/wf_hello/4c8a642a-19a6-486b-acad-e0adf3168820/call-hello/, command failed: BadRequestException: 400 Bucket is requester pays bucket but no user project provided.; ```. So I still have not found a way to run the WDL with `Requester pays` on. I wish Cromwell could give errors explaining what steps to take to solve the issue ... I know that with `gsutil` I can specify the user project with `-u xxx` but I have no idea how to do that with Cromwell.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906
https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906:3013,Testability,log,log,3013,"e = ""sa.json""; }; ]; }. engine {; filesystems {; gcs {; auth = ""service_account""; project = ""xxx""; }; }; }; ```; And I have replaced every other instance of `auth = ""application-default""` with `auth = ""service_account""`. Now when I run Cromwell:; ```; java -Dconfig.file=google.conf -jar cromwell-52.jar run hello.wdl -i hello.inputs; ```; I don't get the error anymore. I do get a different error:; ```; [2020-07-27 22:54:56,48] [info] WorkflowManagerActor Workflow 0fb5e69d-7d70-407e-9fe2-bf7cb2b2c3e6 failed (during ExecutingWorkflowState): java.lang.Exception: Task wf_hello.hello:NA:1 failed. The job was stopped before the command finished. PAPI error code 7. Required 'compute.zones.list' permission for 'projects/xxx'; ```; I don't know what this means. If I remove `Requester pays` from the bucket I can get the WDL to work using `scheme = ""application_default""`, as long as I do not export `GOOGLE_APPLICATION_CREDENTIALS` first. But if I use `Requester pays` on the bucket, using `scheme = ""application_default""` causes error:; ```; [2020-07-27 23:19:31,90] [info] WorkflowManagerActor Workflow 4c8a642a-19a6-486b-acad-e0adf3168820 failed (during ExecutingWorkflowState): java.lang.Exception: Task wf_hello.hello:NA:1 failed. The job was stopped before the command finished. PAPI error code 10. 15: Gsutil failed: failed to upload logs for ""gs://xxx/cromwell-execution/wf_hello/4c8a642a-19a6-486b-acad-e0adf3168820/call-hello/"": cp failed: gsutil -h Content-type:text/plain -q -m cp /var/log/google-genomics/*.log gs://xxx/cromwell-execution/wf_hello/4c8a642a-19a6-486b-acad-e0adf3168820/call-hello/, command failed: BadRequestException: 400 Bucket is requester pays bucket but no user project provided.; ```. So I still have not found a way to run the WDL with `Requester pays` on. I wish Cromwell could give errors explaining what steps to take to solve the issue ... I know that with `gsutil` I can specify the user project with `-u xxx` but I have no idea how to do that with Cromwell.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906
https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906:3035,Testability,log,log,3035,"e = ""sa.json""; }; ]; }. engine {; filesystems {; gcs {; auth = ""service_account""; project = ""xxx""; }; }; }; ```; And I have replaced every other instance of `auth = ""application-default""` with `auth = ""service_account""`. Now when I run Cromwell:; ```; java -Dconfig.file=google.conf -jar cromwell-52.jar run hello.wdl -i hello.inputs; ```; I don't get the error anymore. I do get a different error:; ```; [2020-07-27 22:54:56,48] [info] WorkflowManagerActor Workflow 0fb5e69d-7d70-407e-9fe2-bf7cb2b2c3e6 failed (during ExecutingWorkflowState): java.lang.Exception: Task wf_hello.hello:NA:1 failed. The job was stopped before the command finished. PAPI error code 7. Required 'compute.zones.list' permission for 'projects/xxx'; ```; I don't know what this means. If I remove `Requester pays` from the bucket I can get the WDL to work using `scheme = ""application_default""`, as long as I do not export `GOOGLE_APPLICATION_CREDENTIALS` first. But if I use `Requester pays` on the bucket, using `scheme = ""application_default""` causes error:; ```; [2020-07-27 23:19:31,90] [info] WorkflowManagerActor Workflow 4c8a642a-19a6-486b-acad-e0adf3168820 failed (during ExecutingWorkflowState): java.lang.Exception: Task wf_hello.hello:NA:1 failed. The job was stopped before the command finished. PAPI error code 10. 15: Gsutil failed: failed to upload logs for ""gs://xxx/cromwell-execution/wf_hello/4c8a642a-19a6-486b-acad-e0adf3168820/call-hello/"": cp failed: gsutil -h Content-type:text/plain -q -m cp /var/log/google-genomics/*.log gs://xxx/cromwell-execution/wf_hello/4c8a642a-19a6-486b-acad-e0adf3168820/call-hello/, command failed: BadRequestException: 400 Bucket is requester pays bucket but no user project provided.; ```. So I still have not found a way to run the WDL with `Requester pays` on. I wish Cromwell could give errors explaining what steps to take to solve the issue ... I know that with `gsutil` I can specify the user project with `-u xxx` but I have no idea how to do that with Cromwell.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906
https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906:1035,Usability,clear,clearly,1035,"I had the same issue. I got the same error message:; ```; [2020-07-27 18:34:00,37] [error] PipelinesApiAsyncBackendJobExecutionActor [3d2d7a27wf_hello.hello:NA:1]: Error attempting to Execute; cromwell.engine.io.IoAttempts$EnhancedCromwellIoException: [Attempted 1 time(s)] - StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; Caused by: com.google.cloud.storage.StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; ```; I had set up my credentials with:; ```; export GOOGLE_APPLICATION_CREDENTIALS=sa.json; ```; and had this configuration in `google.conf` copied from the [tutorial](https://cromwell.readthedocs.io/en/stable/tutorials/PipelinesApi101/):; ```; google {; application-name = ""cromwell""; auths = [; {; name = ""application-default""; scheme = ""application_default""; }; ]; }. engine {; filesystems {; gcs {; auth = ""application-default""; project = ""xxx""; }; }; }; ```; That clearly did not work. I tried to follow the logic in this post. I followed Horneth suggestion to use `service-account`'s authorization and I took the [auths](https://cromwell.readthedocs.io/en/develop/backends/Google/) configuration and changed `pem-file` to `json-file` in `google.conf` as follows:; ```; google {; application-name = ""cromwell""; auths = [; {; name = ""service_account""; scheme = ""service_account""; service-account-id = ""xxx@xxx.iam.gserviceaccount.com""; json-file = ""sa.json""; }; ]; }. engine {; filesystems {; gcs {; auth = ""service_account""; project = ""xxx""; }; }; }; ```; And I have replaced every other instance of `auth = ""application-default""` with `auth = ""service_account""`. Now when I run Cromwell:; ```; java -Dconfig.file=google.conf -jar cromwell-52.jar run hello.wdl -i hello.inputs; ```; I don't get the error anymore. I do get a different error:; ```; [2020-07-27 22:54:56,48] [info] WorkflowManagerActor Workflow 0fb5e69d-7d70-407e-9",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906
https://github.com/broadinstitute/cromwell/pull/3691#issuecomment-392093770:96,Availability,avail,available,96,> not sure why this was showing all green with only one review ü§î. PullApprove audits are always available via the `code-review/pullapprove` [Details](https://pullapprove.com/broadinstitute/cromwell/pull-request/3691/) links. In this case the change fell into `groups.one_reviewer` because of `groups.two_reviewers.conditions.files.exclude: centaur/*`,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3691#issuecomment-392093770
https://github.com/broadinstitute/cromwell/pull/3691#issuecomment-392093770:36,Energy Efficiency,green,green,36,> not sure why this was showing all green with only one review ü§î. PullApprove audits are always available via the `code-review/pullapprove` [Details](https://pullapprove.com/broadinstitute/cromwell/pull-request/3691/) links. In this case the change fell into `groups.one_reviewer` because of `groups.two_reviewers.conditions.files.exclude: centaur/*`,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3691#issuecomment-392093770
https://github.com/broadinstitute/cromwell/pull/3691#issuecomment-392093770:78,Security,audit,audits,78,> not sure why this was showing all green with only one review ü§î. PullApprove audits are always available via the `code-review/pullapprove` [Details](https://pullapprove.com/broadinstitute/cromwell/pull-request/3691/) links. In this case the change fell into `groups.one_reviewer` because of `groups.two_reviewers.conditions.files.exclude: centaur/*`,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3691#issuecomment-392093770
https://github.com/broadinstitute/cromwell/pull/3691#issuecomment-392157369:48,Modifiability,config,config,48,Thanks. Pretty sure the one-reviewer-on-Centaur config was really intended for our arboreal friends to not require a Cromwellian thumb if they were only touching Centaur files. From a brief scan of the PullApprove docs I'm not readily seeing a way to require two thumbs for a Cromwellian-initiated PR.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3691#issuecomment-392157369
https://github.com/broadinstitute/cromwell/pull/3691#issuecomment-392192566:77,Deployability,update,update,77,One option: we're currently using conditions by `files`. We could replace-or-update those conditions using `labels`: http://docs.pullapprove.com/groups/conditions/#labels,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3691#issuecomment-392192566
https://github.com/broadinstitute/cromwell/pull/3697#issuecomment-392623498:98,Testability,test,tests,98,"You don't really *need* to worry about 117 here, but just FYI it's expected that the Centaur PAPI tests would require `/bin/bash` while the PAPI conformance tests should be able to get by with `/bin/sh`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3697#issuecomment-392623498
https://github.com/broadinstitute/cromwell/pull/3697#issuecomment-392623498:157,Testability,test,tests,157,"You don't really *need* to worry about 117 here, but just FYI it's expected that the Centaur PAPI tests would require `/bin/bash` while the PAPI conformance tests should be able to get by with `/bin/sh`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3697#issuecomment-392623498
https://github.com/broadinstitute/cromwell/pull/3697#issuecomment-392637741:38,Testability,test,tests,38,> it's expected that the Centaur PAPI tests would require /bin/bash while the PAPI conformance tests should be able to get by with /bin/sh. @mcovarr Oh I didn't realize that. I'd be curious to know why. Maybe we can tech talk this tomorrow too,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3697#issuecomment-392637741
https://github.com/broadinstitute/cromwell/pull/3697#issuecomment-392637741:95,Testability,test,tests,95,> it's expected that the Centaur PAPI tests would require /bin/bash while the PAPI conformance tests should be able to get by with /bin/sh. @mcovarr Oh I didn't realize that. I'd be curious to know why. Maybe we can tech talk this tomorrow too,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3697#issuecomment-392637741
https://github.com/broadinstitute/cromwell/pull/3697#issuecomment-392810761:149,Deployability,release,releases,149,I think the PAPI Centaur `/bin/bash` dependency is purely an artifact of having a job shell effectively hardcoded to `/bin/bash` for the previous 31 releases of Cromwell so that unintentionally `/bin/bash` dependent WDLs were written into the test suite. üôÇ,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3697#issuecomment-392810761
https://github.com/broadinstitute/cromwell/pull/3697#issuecomment-392810761:37,Integrability,depend,dependency,37,I think the PAPI Centaur `/bin/bash` dependency is purely an artifact of having a job shell effectively hardcoded to `/bin/bash` for the previous 31 releases of Cromwell so that unintentionally `/bin/bash` dependent WDLs were written into the test suite. üôÇ,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3697#issuecomment-392810761
https://github.com/broadinstitute/cromwell/pull/3697#issuecomment-392810761:206,Integrability,depend,dependent,206,I think the PAPI Centaur `/bin/bash` dependency is purely an artifact of having a job shell effectively hardcoded to `/bin/bash` for the previous 31 releases of Cromwell so that unintentionally `/bin/bash` dependent WDLs were written into the test suite. üôÇ,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3697#issuecomment-392810761
https://github.com/broadinstitute/cromwell/pull/3697#issuecomment-392810761:243,Testability,test,test,243,I think the PAPI Centaur `/bin/bash` dependency is purely an artifact of having a job shell effectively hardcoded to `/bin/bash` for the previous 31 releases of Cromwell so that unintentionally `/bin/bash` dependent WDLs were written into the test suite. üôÇ,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3697#issuecomment-392810761
https://github.com/broadinstitute/cromwell/pull/3697#issuecomment-392814191:44,Availability,failure,failures,44,"@mcovarr oh I see thanks. Well I only saw 4 failures IIRC, so it's not that bad. In the meantime we could always keep `/bin/bash` as the default and set it to`/bin/sh` for CWL conf tests which would make 117 pass",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3697#issuecomment-392814191
https://github.com/broadinstitute/cromwell/pull/3697#issuecomment-392814191:181,Testability,test,tests,181,"@mcovarr oh I see thanks. Well I only saw 4 failures IIRC, so it's not that bad. In the meantime we could always keep `/bin/bash` as the default and set it to`/bin/sh` for CWL conf tests which would make 117 pass",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3697#issuecomment-392814191
https://github.com/broadinstitute/cromwell/pull/3700#issuecomment-395052458:97,Deployability,update,updated,97,"> Is it a huge overhead/burden to also turn on the draft-3 versions?. Whenever the originals get updated, these should (in theory) be kept in sync. The point of the CRON tests is to run as close as possible what the real world workflows are running. As many of the originals run in FC, I believe they should be draft-2 for now. If one wanted to additionally clone draft-3/1.0 versions I think that would be fine. ToL: A better version of the CRON tests would just point-to/reference the originals from the source with smaller inputs, instead of having clones in this git repo. EDIT: More specifically re: burden-- this PR is just trying to get the tests green and then move on. I personally don't know enough about ""what's an input, what's an input-with-defaults, what's a non-input-but-calculated-from-an-input"" to go through the hundreds of lines for a ""quick"" convert.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3700#issuecomment-395052458
https://github.com/broadinstitute/cromwell/pull/3700#issuecomment-395052458:654,Energy Efficiency,green,green,654,"> Is it a huge overhead/burden to also turn on the draft-3 versions?. Whenever the originals get updated, these should (in theory) be kept in sync. The point of the CRON tests is to run as close as possible what the real world workflows are running. As many of the originals run in FC, I believe they should be draft-2 for now. If one wanted to additionally clone draft-3/1.0 versions I think that would be fine. ToL: A better version of the CRON tests would just point-to/reference the originals from the source with smaller inputs, instead of having clones in this git repo. EDIT: More specifically re: burden-- this PR is just trying to get the tests green and then move on. I personally don't know enough about ""what's an input, what's an input-with-defaults, what's a non-input-but-calculated-from-an-input"" to go through the hundreds of lines for a ""quick"" convert.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3700#issuecomment-395052458
https://github.com/broadinstitute/cromwell/pull/3700#issuecomment-395052458:170,Testability,test,tests,170,"> Is it a huge overhead/burden to also turn on the draft-3 versions?. Whenever the originals get updated, these should (in theory) be kept in sync. The point of the CRON tests is to run as close as possible what the real world workflows are running. As many of the originals run in FC, I believe they should be draft-2 for now. If one wanted to additionally clone draft-3/1.0 versions I think that would be fine. ToL: A better version of the CRON tests would just point-to/reference the originals from the source with smaller inputs, instead of having clones in this git repo. EDIT: More specifically re: burden-- this PR is just trying to get the tests green and then move on. I personally don't know enough about ""what's an input, what's an input-with-defaults, what's a non-input-but-calculated-from-an-input"" to go through the hundreds of lines for a ""quick"" convert.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3700#issuecomment-395052458
https://github.com/broadinstitute/cromwell/pull/3700#issuecomment-395052458:447,Testability,test,tests,447,"> Is it a huge overhead/burden to also turn on the draft-3 versions?. Whenever the originals get updated, these should (in theory) be kept in sync. The point of the CRON tests is to run as close as possible what the real world workflows are running. As many of the originals run in FC, I believe they should be draft-2 for now. If one wanted to additionally clone draft-3/1.0 versions I think that would be fine. ToL: A better version of the CRON tests would just point-to/reference the originals from the source with smaller inputs, instead of having clones in this git repo. EDIT: More specifically re: burden-- this PR is just trying to get the tests green and then move on. I personally don't know enough about ""what's an input, what's an input-with-defaults, what's a non-input-but-calculated-from-an-input"" to go through the hundreds of lines for a ""quick"" convert.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3700#issuecomment-395052458
https://github.com/broadinstitute/cromwell/pull/3700#issuecomment-395052458:648,Testability,test,tests,648,"> Is it a huge overhead/burden to also turn on the draft-3 versions?. Whenever the originals get updated, these should (in theory) be kept in sync. The point of the CRON tests is to run as close as possible what the real world workflows are running. As many of the originals run in FC, I believe they should be draft-2 for now. If one wanted to additionally clone draft-3/1.0 versions I think that would be fine. ToL: A better version of the CRON tests would just point-to/reference the originals from the source with smaller inputs, instead of having clones in this git repo. EDIT: More specifically re: burden-- this PR is just trying to get the tests green and then move on. I personally don't know enough about ""what's an input, what's an input-with-defaults, what's a non-input-but-calculated-from-an-input"" to go through the hundreds of lines for a ""quick"" convert.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3700#issuecomment-395052458
https://github.com/broadinstitute/cromwell/issues/3705#issuecomment-393064752:240,Availability,error,error,240,"I have confirmed and worked-around by changing the configuration -o and -e parameters to ; ```; -o ${out}.cromwell; -e ${err}.cromwell; ```; identical duplicated files are now written to the work directory. (Identical except in the case of error, which is when I need these files anyway). My request is to remove the >(tee) lines, but I understand they probably exist to serve some other backend. The ability to turn them off would be appreciated.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3705#issuecomment-393064752
https://github.com/broadinstitute/cromwell/issues/3705#issuecomment-393064752:51,Deployability,configurat,configuration,51,"I have confirmed and worked-around by changing the configuration -o and -e parameters to ; ```; -o ${out}.cromwell; -e ${err}.cromwell; ```; identical duplicated files are now written to the work directory. (Identical except in the case of error, which is when I need these files anyway). My request is to remove the >(tee) lines, but I understand they probably exist to serve some other backend. The ability to turn them off would be appreciated.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3705#issuecomment-393064752
https://github.com/broadinstitute/cromwell/issues/3705#issuecomment-393064752:51,Modifiability,config,configuration,51,"I have confirmed and worked-around by changing the configuration -o and -e parameters to ; ```; -o ${out}.cromwell; -e ${err}.cromwell; ```; identical duplicated files are now written to the work directory. (Identical except in the case of error, which is when I need these files anyway). My request is to remove the >(tee) lines, but I understand they probably exist to serve some other backend. The ability to turn them off would be appreciated.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3705#issuecomment-393064752
https://github.com/broadinstitute/cromwell/issues/3705#issuecomment-393103059:331,Integrability,message,messages,331,"Thanks for reporting this, you're right that those files should not have the same name. The files within the script are meant to capture the stdout and stderr of the user command only and are required for both WDL and CWL support. The files on the `qsub` command line are meant to capture all stdout and stderr including those log messages. The structure of the script has changed somewhat with Cromwell 32 but I suspect this problem still exists so we'll look at making a fix.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3705#issuecomment-393103059
https://github.com/broadinstitute/cromwell/issues/3705#issuecomment-393103059:327,Testability,log,log,327,"Thanks for reporting this, you're right that those files should not have the same name. The files within the script are meant to capture the stdout and stderr of the user command only and are required for both WDL and CWL support. The files on the `qsub` command line are meant to capture all stdout and stderr including those log messages. The structure of the script has changed somewhat with Cromwell 32 but I suspect this problem still exists so we'll look at making a fix.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3705#issuecomment-393103059
https://github.com/broadinstitute/cromwell/issues/3705#issuecomment-393106416:118,Deployability,configurat,configuration,118,"If it is intended that the `qsub` files also capture the `command` output, then I think the only 'bug' is the default configuration and docs.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3705#issuecomment-393106416
https://github.com/broadinstitute/cromwell/issues/3705#issuecomment-393106416:118,Modifiability,config,configuration,118,"If it is intended that the `qsub` files also capture the `command` output, then I think the only 'bug' is the default configuration and docs.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3705#issuecomment-393106416
https://github.com/broadinstitute/cromwell/issues/3705#issuecomment-393154909:32,Modifiability,config,config,32,"There's certainly an issue with config and docs, and now that I'm thinking about this more it's possible that with a recent bug fix we might be able to do away with the tee and keep the command stdout/err out of the qsub stdout/err. I'll look into this further.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3705#issuecomment-393154909
https://github.com/broadinstitute/cromwell/issues/3708#issuecomment-394475430:0,Integrability,depend,depends,0,depends on #3726,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3708#issuecomment-394475430
https://github.com/broadinstitute/cromwell/issues/3709#issuecomment-394767306:119,Integrability,protocol,protocol,119,"It is turned on in Dev, evidence: https://sentry.io/broad-institute/firecloud-dev/issues/572001494/. Not sure what the protocol is to migrate these settings to Staging/Prod/Perf? @davidbernick ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3709#issuecomment-394767306
https://github.com/broadinstitute/cromwell/issues/3709#issuecomment-394768106:197,Deployability,release,release,197,"Looks like it's here ""https://github.com/broadinstitute/firecloud-develop/blob/dev/run-context/live/configs/cromwell/docker-compose.yaml.ctmpl"" so it means it'll get promoted automatically on next release.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3709#issuecomment-394768106
https://github.com/broadinstitute/cromwell/issues/3709#issuecomment-394768106:100,Modifiability,config,configs,100,"Looks like it's here ""https://github.com/broadinstitute/firecloud-develop/blob/dev/run-context/live/configs/cromwell/docker-compose.yaml.ctmpl"" so it means it'll get promoted automatically on next release.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3709#issuecomment-394768106
https://github.com/broadinstitute/cromwell/issues/3710#issuecomment-393459918:248,Testability,test,tested,248,"For completeness sake, the same issue occurs with `arguments: [ '{""inputs"":$(inputs)}' ]`. Interestingly `argument: [ '{""self"":$(self)}' ]` works, but only because `null` is represented the same way in YAML and JSON. I would guess that if this was tested in a context where `self` wasn't null then it could have the same issue.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3710#issuecomment-393459918
https://github.com/broadinstitute/cromwell/issues/3712#issuecomment-393634397:8,Availability,ping,pinging,8,@andy7i pinging you as this is also a great perfomance test,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3712#issuecomment-393634397
https://github.com/broadinstitute/cromwell/issues/3712#issuecomment-393634397:55,Testability,test,test,55,@andy7i pinging you as this is also a great perfomance test,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3712#issuecomment-393634397
https://github.com/broadinstitute/cromwell/issues/3713#issuecomment-393635892:18,Modifiability,config,configure,18,@hjfbynara Can we configure apache to disable this endpoint in production as a stopgap?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3713#issuecomment-393635892
https://github.com/broadinstitute/cromwell/issues/3713#issuecomment-393918710:13,Energy Efficiency,green,green,13,@ktibbett is green team using /stats for anything meaningful?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3713#issuecomment-393918710
https://github.com/broadinstitute/cromwell/issues/3713#issuecomment-395755673:497,Modifiability,config,config,497,"From a technical perspective - sure likely possible. My question is what do you want requests to that URL to return? 400,404, 50X? . The biggest challenge is how to make the change such that it does not break everything else, the current proxy setup is pretty simple ( / (slash - which is where /engine falls under) does one thing, /api does another). This will require adding a 3rd option around /engine/v1/stats - likely something with mod_rewrite. Will take me a bit to work through a workable config",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3713#issuecomment-395755673
https://github.com/broadinstitute/cromwell/issues/3713#issuecomment-395755673:260,Usability,simpl,simple,260,"From a technical perspective - sure likely possible. My question is what do you want requests to that URL to return? 400,404, 50X? . The biggest challenge is how to make the change such that it does not break everything else, the current proxy setup is pretty simple ( / (slash - which is where /engine falls under) does one thing, /api does another). This will require adding a 3rd option around /engine/v1/stats - likely something with mod_rewrite. Will take me a bit to work through a workable config",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3713#issuecomment-395755673
https://github.com/broadinstitute/cromwell/issues/3713#issuecomment-395762351:137,Deployability,pipeline,pipelines,137,fwiw - green team currently run their own cromwell instances - so they are not currently impacted by anything we do on WB prod for their pipelines. Plus they generally are not as aggressive at taking newer cromwell versions - so even if you disable (remove) that endpoint they would likely not see the results for quite a bit.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3713#issuecomment-395762351
https://github.com/broadinstitute/cromwell/issues/3713#issuecomment-395762351:7,Energy Efficiency,green,green,7,fwiw - green team currently run their own cromwell instances - so they are not currently impacted by anything we do on WB prod for their pipelines. Plus they generally are not as aggressive at taking newer cromwell versions - so even if you disable (remove) that endpoint they would likely not see the results for quite a bit.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3713#issuecomment-395762351
https://github.com/broadinstitute/cromwell/pull/3715#issuecomment-393910783:55,Deployability,hotfix,hotfix,55,"@ruchim @kshakir Yes, @Horneth could you please add to hotfix branch? They are getting 32 ready for FC, would like to get this in there.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3715#issuecomment-393910783
https://github.com/broadinstitute/cromwell/issues/3716#issuecomment-395378463:62,Modifiability,config,config,62,Kristian saw this again last night. I believe Henry made some config adjustments to up the limit in the Cromwell container and restarted.; ![image](https://user-images.githubusercontent.com/10790523/41095375-3a47e138-6a1f-11e8-8f14-19a3cb1b7d81.png),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3716#issuecomment-395378463
https://github.com/broadinstitute/cromwell/issues/3716#issuecomment-396592770:580,Integrability,protocol,protocol,580,"Some information that may assist in debugging what is going on. I logged onto production to see what the current openfile count is and it is over 90K. Since we now have sufficient headroom to further investigate (ie java is not running out of open file handles) - I ran lsof on the java proc to see what it tells me. . First I looked at the beginning part of the ""path/name"" for the open file to see if there was some common part. awk ' { print $9 } ' < /tmp/lsof.out | cut -d '/' -f2 | sort | uniq -c | sort -nr; 50277 pipe; 25137 [eventpoll]; 14242 cromwell-workflow-logs; 1094 protocol:; 69 (stat:; 17 usr; 12 tmp; 6 dev; 2 etc; 2; 1 var; 1 app; 1 NAME. Obviously ""pipe"" and ""eventpoll"" are important areas to investigate to see if this is normal behavior or something odd. The third largest consumer ""cromwell-workflow-logs"" seemed interesting and if you look more closely I noticed that of the 14k over 11k are files that no longer exist (were deleted) but cromwell is maintaining an open file handle to it. . egrep cromwell-workflow-logs /tmp/lsof.out | awk ' { print $NF } ' | sort | uniq -c | head -4; 11541 (deleted); 1 /cromwell-workflow-logs/workflow.0005b906-d7be-4214-9943-0647a92c2c8e.log; 1 /cromwell-workflow-logs/workflow.000c5b14-0da4-4c2c-9a3b-f50377471820.log; 1 /cromwell-workflow-logs/workflow.001655a7-2c75-4a0f-b7cc-ba8ec96781ec.log. I also ran ls on the directory inside the container to see how many files exist. Of course the exact numbers don't line up because all these commands were run at different times (lsof was a snapshot ran at a specific time and my ls command is current time). docker exec -it cromwell_app_1 ls /cromwell-workflow-logs | wc -l; 2699. So at least one place that warrants further investigation is the code that reads/writes the cromwell-workflow-logs - something in there is not closing their file handle.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3716#issuecomment-396592770
https://github.com/broadinstitute/cromwell/issues/3716#issuecomment-396592770:66,Testability,log,logged,66,"Some information that may assist in debugging what is going on. I logged onto production to see what the current openfile count is and it is over 90K. Since we now have sufficient headroom to further investigate (ie java is not running out of open file handles) - I ran lsof on the java proc to see what it tells me. . First I looked at the beginning part of the ""path/name"" for the open file to see if there was some common part. awk ' { print $9 } ' < /tmp/lsof.out | cut -d '/' -f2 | sort | uniq -c | sort -nr; 50277 pipe; 25137 [eventpoll]; 14242 cromwell-workflow-logs; 1094 protocol:; 69 (stat:; 17 usr; 12 tmp; 6 dev; 2 etc; 2; 1 var; 1 app; 1 NAME. Obviously ""pipe"" and ""eventpoll"" are important areas to investigate to see if this is normal behavior or something odd. The third largest consumer ""cromwell-workflow-logs"" seemed interesting and if you look more closely I noticed that of the 14k over 11k are files that no longer exist (were deleted) but cromwell is maintaining an open file handle to it. . egrep cromwell-workflow-logs /tmp/lsof.out | awk ' { print $NF } ' | sort | uniq -c | head -4; 11541 (deleted); 1 /cromwell-workflow-logs/workflow.0005b906-d7be-4214-9943-0647a92c2c8e.log; 1 /cromwell-workflow-logs/workflow.000c5b14-0da4-4c2c-9a3b-f50377471820.log; 1 /cromwell-workflow-logs/workflow.001655a7-2c75-4a0f-b7cc-ba8ec96781ec.log. I also ran ls on the directory inside the container to see how many files exist. Of course the exact numbers don't line up because all these commands were run at different times (lsof was a snapshot ran at a specific time and my ls command is current time). docker exec -it cromwell_app_1 ls /cromwell-workflow-logs | wc -l; 2699. So at least one place that warrants further investigation is the code that reads/writes the cromwell-workflow-logs - something in there is not closing their file handle.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3716#issuecomment-396592770
https://github.com/broadinstitute/cromwell/issues/3716#issuecomment-396592770:569,Testability,log,logs,569,"Some information that may assist in debugging what is going on. I logged onto production to see what the current openfile count is and it is over 90K. Since we now have sufficient headroom to further investigate (ie java is not running out of open file handles) - I ran lsof on the java proc to see what it tells me. . First I looked at the beginning part of the ""path/name"" for the open file to see if there was some common part. awk ' { print $9 } ' < /tmp/lsof.out | cut -d '/' -f2 | sort | uniq -c | sort -nr; 50277 pipe; 25137 [eventpoll]; 14242 cromwell-workflow-logs; 1094 protocol:; 69 (stat:; 17 usr; 12 tmp; 6 dev; 2 etc; 2; 1 var; 1 app; 1 NAME. Obviously ""pipe"" and ""eventpoll"" are important areas to investigate to see if this is normal behavior or something odd. The third largest consumer ""cromwell-workflow-logs"" seemed interesting and if you look more closely I noticed that of the 14k over 11k are files that no longer exist (were deleted) but cromwell is maintaining an open file handle to it. . egrep cromwell-workflow-logs /tmp/lsof.out | awk ' { print $NF } ' | sort | uniq -c | head -4; 11541 (deleted); 1 /cromwell-workflow-logs/workflow.0005b906-d7be-4214-9943-0647a92c2c8e.log; 1 /cromwell-workflow-logs/workflow.000c5b14-0da4-4c2c-9a3b-f50377471820.log; 1 /cromwell-workflow-logs/workflow.001655a7-2c75-4a0f-b7cc-ba8ec96781ec.log. I also ran ls on the directory inside the container to see how many files exist. Of course the exact numbers don't line up because all these commands were run at different times (lsof was a snapshot ran at a specific time and my ls command is current time). docker exec -it cromwell_app_1 ls /cromwell-workflow-logs | wc -l; 2699. So at least one place that warrants further investigation is the code that reads/writes the cromwell-workflow-logs - something in there is not closing their file handle.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3716#issuecomment-396592770
https://github.com/broadinstitute/cromwell/issues/3716#issuecomment-396592770:823,Testability,log,logs,823,"Some information that may assist in debugging what is going on. I logged onto production to see what the current openfile count is and it is over 90K. Since we now have sufficient headroom to further investigate (ie java is not running out of open file handles) - I ran lsof on the java proc to see what it tells me. . First I looked at the beginning part of the ""path/name"" for the open file to see if there was some common part. awk ' { print $9 } ' < /tmp/lsof.out | cut -d '/' -f2 | sort | uniq -c | sort -nr; 50277 pipe; 25137 [eventpoll]; 14242 cromwell-workflow-logs; 1094 protocol:; 69 (stat:; 17 usr; 12 tmp; 6 dev; 2 etc; 2; 1 var; 1 app; 1 NAME. Obviously ""pipe"" and ""eventpoll"" are important areas to investigate to see if this is normal behavior or something odd. The third largest consumer ""cromwell-workflow-logs"" seemed interesting and if you look more closely I noticed that of the 14k over 11k are files that no longer exist (were deleted) but cromwell is maintaining an open file handle to it. . egrep cromwell-workflow-logs /tmp/lsof.out | awk ' { print $NF } ' | sort | uniq -c | head -4; 11541 (deleted); 1 /cromwell-workflow-logs/workflow.0005b906-d7be-4214-9943-0647a92c2c8e.log; 1 /cromwell-workflow-logs/workflow.000c5b14-0da4-4c2c-9a3b-f50377471820.log; 1 /cromwell-workflow-logs/workflow.001655a7-2c75-4a0f-b7cc-ba8ec96781ec.log. I also ran ls on the directory inside the container to see how many files exist. Of course the exact numbers don't line up because all these commands were run at different times (lsof was a snapshot ran at a specific time and my ls command is current time). docker exec -it cromwell_app_1 ls /cromwell-workflow-logs | wc -l; 2699. So at least one place that warrants further investigation is the code that reads/writes the cromwell-workflow-logs - something in there is not closing their file handle.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3716#issuecomment-396592770
https://github.com/broadinstitute/cromwell/issues/3716#issuecomment-396592770:1039,Testability,log,logs,1039,"Some information that may assist in debugging what is going on. I logged onto production to see what the current openfile count is and it is over 90K. Since we now have sufficient headroom to further investigate (ie java is not running out of open file handles) - I ran lsof on the java proc to see what it tells me. . First I looked at the beginning part of the ""path/name"" for the open file to see if there was some common part. awk ' { print $9 } ' < /tmp/lsof.out | cut -d '/' -f2 | sort | uniq -c | sort -nr; 50277 pipe; 25137 [eventpoll]; 14242 cromwell-workflow-logs; 1094 protocol:; 69 (stat:; 17 usr; 12 tmp; 6 dev; 2 etc; 2; 1 var; 1 app; 1 NAME. Obviously ""pipe"" and ""eventpoll"" are important areas to investigate to see if this is normal behavior or something odd. The third largest consumer ""cromwell-workflow-logs"" seemed interesting and if you look more closely I noticed that of the 14k over 11k are files that no longer exist (were deleted) but cromwell is maintaining an open file handle to it. . egrep cromwell-workflow-logs /tmp/lsof.out | awk ' { print $NF } ' | sort | uniq -c | head -4; 11541 (deleted); 1 /cromwell-workflow-logs/workflow.0005b906-d7be-4214-9943-0647a92c2c8e.log; 1 /cromwell-workflow-logs/workflow.000c5b14-0da4-4c2c-9a3b-f50377471820.log; 1 /cromwell-workflow-logs/workflow.001655a7-2c75-4a0f-b7cc-ba8ec96781ec.log. I also ran ls on the directory inside the container to see how many files exist. Of course the exact numbers don't line up because all these commands were run at different times (lsof was a snapshot ran at a specific time and my ls command is current time). docker exec -it cromwell_app_1 ls /cromwell-workflow-logs | wc -l; 2699. So at least one place that warrants further investigation is the code that reads/writes the cromwell-workflow-logs - something in there is not closing their file handle.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3716#issuecomment-396592770
https://github.com/broadinstitute/cromwell/issues/3716#issuecomment-396592770:1148,Testability,log,logs,1148,"Some information that may assist in debugging what is going on. I logged onto production to see what the current openfile count is and it is over 90K. Since we now have sufficient headroom to further investigate (ie java is not running out of open file handles) - I ran lsof on the java proc to see what it tells me. . First I looked at the beginning part of the ""path/name"" for the open file to see if there was some common part. awk ' { print $9 } ' < /tmp/lsof.out | cut -d '/' -f2 | sort | uniq -c | sort -nr; 50277 pipe; 25137 [eventpoll]; 14242 cromwell-workflow-logs; 1094 protocol:; 69 (stat:; 17 usr; 12 tmp; 6 dev; 2 etc; 2; 1 var; 1 app; 1 NAME. Obviously ""pipe"" and ""eventpoll"" are important areas to investigate to see if this is normal behavior or something odd. The third largest consumer ""cromwell-workflow-logs"" seemed interesting and if you look more closely I noticed that of the 14k over 11k are files that no longer exist (were deleted) but cromwell is maintaining an open file handle to it. . egrep cromwell-workflow-logs /tmp/lsof.out | awk ' { print $NF } ' | sort | uniq -c | head -4; 11541 (deleted); 1 /cromwell-workflow-logs/workflow.0005b906-d7be-4214-9943-0647a92c2c8e.log; 1 /cromwell-workflow-logs/workflow.000c5b14-0da4-4c2c-9a3b-f50377471820.log; 1 /cromwell-workflow-logs/workflow.001655a7-2c75-4a0f-b7cc-ba8ec96781ec.log. I also ran ls on the directory inside the container to see how many files exist. Of course the exact numbers don't line up because all these commands were run at different times (lsof was a snapshot ran at a specific time and my ls command is current time). docker exec -it cromwell_app_1 ls /cromwell-workflow-logs | wc -l; 2699. So at least one place that warrants further investigation is the code that reads/writes the cromwell-workflow-logs - something in there is not closing their file handle.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3716#issuecomment-396592770
https://github.com/broadinstitute/cromwell/issues/3716#issuecomment-396592770:1199,Testability,log,log,1199,"Some information that may assist in debugging what is going on. I logged onto production to see what the current openfile count is and it is over 90K. Since we now have sufficient headroom to further investigate (ie java is not running out of open file handles) - I ran lsof on the java proc to see what it tells me. . First I looked at the beginning part of the ""path/name"" for the open file to see if there was some common part. awk ' { print $9 } ' < /tmp/lsof.out | cut -d '/' -f2 | sort | uniq -c | sort -nr; 50277 pipe; 25137 [eventpoll]; 14242 cromwell-workflow-logs; 1094 protocol:; 69 (stat:; 17 usr; 12 tmp; 6 dev; 2 etc; 2; 1 var; 1 app; 1 NAME. Obviously ""pipe"" and ""eventpoll"" are important areas to investigate to see if this is normal behavior or something odd. The third largest consumer ""cromwell-workflow-logs"" seemed interesting and if you look more closely I noticed that of the 14k over 11k are files that no longer exist (were deleted) but cromwell is maintaining an open file handle to it. . egrep cromwell-workflow-logs /tmp/lsof.out | awk ' { print $NF } ' | sort | uniq -c | head -4; 11541 (deleted); 1 /cromwell-workflow-logs/workflow.0005b906-d7be-4214-9943-0647a92c2c8e.log; 1 /cromwell-workflow-logs/workflow.000c5b14-0da4-4c2c-9a3b-f50377471820.log; 1 /cromwell-workflow-logs/workflow.001655a7-2c75-4a0f-b7cc-ba8ec96781ec.log. I also ran ls on the directory inside the container to see how many files exist. Of course the exact numbers don't line up because all these commands were run at different times (lsof was a snapshot ran at a specific time and my ls command is current time). docker exec -it cromwell_app_1 ls /cromwell-workflow-logs | wc -l; 2699. So at least one place that warrants further investigation is the code that reads/writes the cromwell-workflow-logs - something in there is not closing their file handle.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3716#issuecomment-396592770
https://github.com/broadinstitute/cromwell/issues/3716#issuecomment-396592770:1225,Testability,log,logs,1225,"Some information that may assist in debugging what is going on. I logged onto production to see what the current openfile count is and it is over 90K. Since we now have sufficient headroom to further investigate (ie java is not running out of open file handles) - I ran lsof on the java proc to see what it tells me. . First I looked at the beginning part of the ""path/name"" for the open file to see if there was some common part. awk ' { print $9 } ' < /tmp/lsof.out | cut -d '/' -f2 | sort | uniq -c | sort -nr; 50277 pipe; 25137 [eventpoll]; 14242 cromwell-workflow-logs; 1094 protocol:; 69 (stat:; 17 usr; 12 tmp; 6 dev; 2 etc; 2; 1 var; 1 app; 1 NAME. Obviously ""pipe"" and ""eventpoll"" are important areas to investigate to see if this is normal behavior or something odd. The third largest consumer ""cromwell-workflow-logs"" seemed interesting and if you look more closely I noticed that of the 14k over 11k are files that no longer exist (were deleted) but cromwell is maintaining an open file handle to it. . egrep cromwell-workflow-logs /tmp/lsof.out | awk ' { print $NF } ' | sort | uniq -c | head -4; 11541 (deleted); 1 /cromwell-workflow-logs/workflow.0005b906-d7be-4214-9943-0647a92c2c8e.log; 1 /cromwell-workflow-logs/workflow.000c5b14-0da4-4c2c-9a3b-f50377471820.log; 1 /cromwell-workflow-logs/workflow.001655a7-2c75-4a0f-b7cc-ba8ec96781ec.log. I also ran ls on the directory inside the container to see how many files exist. Of course the exact numbers don't line up because all these commands were run at different times (lsof was a snapshot ran at a specific time and my ls command is current time). docker exec -it cromwell_app_1 ls /cromwell-workflow-logs | wc -l; 2699. So at least one place that warrants further investigation is the code that reads/writes the cromwell-workflow-logs - something in there is not closing their file handle.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3716#issuecomment-396592770
https://github.com/broadinstitute/cromwell/issues/3716#issuecomment-396592770:1276,Testability,log,log,1276,"Some information that may assist in debugging what is going on. I logged onto production to see what the current openfile count is and it is over 90K. Since we now have sufficient headroom to further investigate (ie java is not running out of open file handles) - I ran lsof on the java proc to see what it tells me. . First I looked at the beginning part of the ""path/name"" for the open file to see if there was some common part. awk ' { print $9 } ' < /tmp/lsof.out | cut -d '/' -f2 | sort | uniq -c | sort -nr; 50277 pipe; 25137 [eventpoll]; 14242 cromwell-workflow-logs; 1094 protocol:; 69 (stat:; 17 usr; 12 tmp; 6 dev; 2 etc; 2; 1 var; 1 app; 1 NAME. Obviously ""pipe"" and ""eventpoll"" are important areas to investigate to see if this is normal behavior or something odd. The third largest consumer ""cromwell-workflow-logs"" seemed interesting and if you look more closely I noticed that of the 14k over 11k are files that no longer exist (were deleted) but cromwell is maintaining an open file handle to it. . egrep cromwell-workflow-logs /tmp/lsof.out | awk ' { print $NF } ' | sort | uniq -c | head -4; 11541 (deleted); 1 /cromwell-workflow-logs/workflow.0005b906-d7be-4214-9943-0647a92c2c8e.log; 1 /cromwell-workflow-logs/workflow.000c5b14-0da4-4c2c-9a3b-f50377471820.log; 1 /cromwell-workflow-logs/workflow.001655a7-2c75-4a0f-b7cc-ba8ec96781ec.log. I also ran ls on the directory inside the container to see how many files exist. Of course the exact numbers don't line up because all these commands were run at different times (lsof was a snapshot ran at a specific time and my ls command is current time). docker exec -it cromwell_app_1 ls /cromwell-workflow-logs | wc -l; 2699. So at least one place that warrants further investigation is the code that reads/writes the cromwell-workflow-logs - something in there is not closing their file handle.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3716#issuecomment-396592770
https://github.com/broadinstitute/cromwell/issues/3716#issuecomment-396592770:1302,Testability,log,logs,1302,"Some information that may assist in debugging what is going on. I logged onto production to see what the current openfile count is and it is over 90K. Since we now have sufficient headroom to further investigate (ie java is not running out of open file handles) - I ran lsof on the java proc to see what it tells me. . First I looked at the beginning part of the ""path/name"" for the open file to see if there was some common part. awk ' { print $9 } ' < /tmp/lsof.out | cut -d '/' -f2 | sort | uniq -c | sort -nr; 50277 pipe; 25137 [eventpoll]; 14242 cromwell-workflow-logs; 1094 protocol:; 69 (stat:; 17 usr; 12 tmp; 6 dev; 2 etc; 2; 1 var; 1 app; 1 NAME. Obviously ""pipe"" and ""eventpoll"" are important areas to investigate to see if this is normal behavior or something odd. The third largest consumer ""cromwell-workflow-logs"" seemed interesting and if you look more closely I noticed that of the 14k over 11k are files that no longer exist (were deleted) but cromwell is maintaining an open file handle to it. . egrep cromwell-workflow-logs /tmp/lsof.out | awk ' { print $NF } ' | sort | uniq -c | head -4; 11541 (deleted); 1 /cromwell-workflow-logs/workflow.0005b906-d7be-4214-9943-0647a92c2c8e.log; 1 /cromwell-workflow-logs/workflow.000c5b14-0da4-4c2c-9a3b-f50377471820.log; 1 /cromwell-workflow-logs/workflow.001655a7-2c75-4a0f-b7cc-ba8ec96781ec.log. I also ran ls on the directory inside the container to see how many files exist. Of course the exact numbers don't line up because all these commands were run at different times (lsof was a snapshot ran at a specific time and my ls command is current time). docker exec -it cromwell_app_1 ls /cromwell-workflow-logs | wc -l; 2699. So at least one place that warrants further investigation is the code that reads/writes the cromwell-workflow-logs - something in there is not closing their file handle.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3716#issuecomment-396592770
https://github.com/broadinstitute/cromwell/issues/3716#issuecomment-396592770:1353,Testability,log,log,1353,"Some information that may assist in debugging what is going on. I logged onto production to see what the current openfile count is and it is over 90K. Since we now have sufficient headroom to further investigate (ie java is not running out of open file handles) - I ran lsof on the java proc to see what it tells me. . First I looked at the beginning part of the ""path/name"" for the open file to see if there was some common part. awk ' { print $9 } ' < /tmp/lsof.out | cut -d '/' -f2 | sort | uniq -c | sort -nr; 50277 pipe; 25137 [eventpoll]; 14242 cromwell-workflow-logs; 1094 protocol:; 69 (stat:; 17 usr; 12 tmp; 6 dev; 2 etc; 2; 1 var; 1 app; 1 NAME. Obviously ""pipe"" and ""eventpoll"" are important areas to investigate to see if this is normal behavior or something odd. The third largest consumer ""cromwell-workflow-logs"" seemed interesting and if you look more closely I noticed that of the 14k over 11k are files that no longer exist (were deleted) but cromwell is maintaining an open file handle to it. . egrep cromwell-workflow-logs /tmp/lsof.out | awk ' { print $NF } ' | sort | uniq -c | head -4; 11541 (deleted); 1 /cromwell-workflow-logs/workflow.0005b906-d7be-4214-9943-0647a92c2c8e.log; 1 /cromwell-workflow-logs/workflow.000c5b14-0da4-4c2c-9a3b-f50377471820.log; 1 /cromwell-workflow-logs/workflow.001655a7-2c75-4a0f-b7cc-ba8ec96781ec.log. I also ran ls on the directory inside the container to see how many files exist. Of course the exact numbers don't line up because all these commands were run at different times (lsof was a snapshot ran at a specific time and my ls command is current time). docker exec -it cromwell_app_1 ls /cromwell-workflow-logs | wc -l; 2699. So at least one place that warrants further investigation is the code that reads/writes the cromwell-workflow-logs - something in there is not closing their file handle.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3716#issuecomment-396592770
https://github.com/broadinstitute/cromwell/issues/3716#issuecomment-396592770:1669,Testability,log,logs,1669,"Some information that may assist in debugging what is going on. I logged onto production to see what the current openfile count is and it is over 90K. Since we now have sufficient headroom to further investigate (ie java is not running out of open file handles) - I ran lsof on the java proc to see what it tells me. . First I looked at the beginning part of the ""path/name"" for the open file to see if there was some common part. awk ' { print $9 } ' < /tmp/lsof.out | cut -d '/' -f2 | sort | uniq -c | sort -nr; 50277 pipe; 25137 [eventpoll]; 14242 cromwell-workflow-logs; 1094 protocol:; 69 (stat:; 17 usr; 12 tmp; 6 dev; 2 etc; 2; 1 var; 1 app; 1 NAME. Obviously ""pipe"" and ""eventpoll"" are important areas to investigate to see if this is normal behavior or something odd. The third largest consumer ""cromwell-workflow-logs"" seemed interesting and if you look more closely I noticed that of the 14k over 11k are files that no longer exist (were deleted) but cromwell is maintaining an open file handle to it. . egrep cromwell-workflow-logs /tmp/lsof.out | awk ' { print $NF } ' | sort | uniq -c | head -4; 11541 (deleted); 1 /cromwell-workflow-logs/workflow.0005b906-d7be-4214-9943-0647a92c2c8e.log; 1 /cromwell-workflow-logs/workflow.000c5b14-0da4-4c2c-9a3b-f50377471820.log; 1 /cromwell-workflow-logs/workflow.001655a7-2c75-4a0f-b7cc-ba8ec96781ec.log. I also ran ls on the directory inside the container to see how many files exist. Of course the exact numbers don't line up because all these commands were run at different times (lsof was a snapshot ran at a specific time and my ls command is current time). docker exec -it cromwell_app_1 ls /cromwell-workflow-logs | wc -l; 2699. So at least one place that warrants further investigation is the code that reads/writes the cromwell-workflow-logs - something in there is not closing their file handle.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3716#issuecomment-396592770
https://github.com/broadinstitute/cromwell/issues/3716#issuecomment-396592770:1799,Testability,log,logs,1799,"Some information that may assist in debugging what is going on. I logged onto production to see what the current openfile count is and it is over 90K. Since we now have sufficient headroom to further investigate (ie java is not running out of open file handles) - I ran lsof on the java proc to see what it tells me. . First I looked at the beginning part of the ""path/name"" for the open file to see if there was some common part. awk ' { print $9 } ' < /tmp/lsof.out | cut -d '/' -f2 | sort | uniq -c | sort -nr; 50277 pipe; 25137 [eventpoll]; 14242 cromwell-workflow-logs; 1094 protocol:; 69 (stat:; 17 usr; 12 tmp; 6 dev; 2 etc; 2; 1 var; 1 app; 1 NAME. Obviously ""pipe"" and ""eventpoll"" are important areas to investigate to see if this is normal behavior or something odd. The third largest consumer ""cromwell-workflow-logs"" seemed interesting and if you look more closely I noticed that of the 14k over 11k are files that no longer exist (were deleted) but cromwell is maintaining an open file handle to it. . egrep cromwell-workflow-logs /tmp/lsof.out | awk ' { print $NF } ' | sort | uniq -c | head -4; 11541 (deleted); 1 /cromwell-workflow-logs/workflow.0005b906-d7be-4214-9943-0647a92c2c8e.log; 1 /cromwell-workflow-logs/workflow.000c5b14-0da4-4c2c-9a3b-f50377471820.log; 1 /cromwell-workflow-logs/workflow.001655a7-2c75-4a0f-b7cc-ba8ec96781ec.log. I also ran ls on the directory inside the container to see how many files exist. Of course the exact numbers don't line up because all these commands were run at different times (lsof was a snapshot ran at a specific time and my ls command is current time). docker exec -it cromwell_app_1 ls /cromwell-workflow-logs | wc -l; 2699. So at least one place that warrants further investigation is the code that reads/writes the cromwell-workflow-logs - something in there is not closing their file handle.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3716#issuecomment-396592770
https://github.com/broadinstitute/cromwell/issues/3716#issuecomment-396621684:71,Testability,log,log,71,"Thanks Henry, I'm currently on rotation so I'll look into the workflow log issue. Is there any way to get more detail on the `pipe` or `[eventpoll]` categories?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3716#issuecomment-396621684
https://github.com/broadinstitute/cromwell/issues/3716#issuecomment-396673480:13,Deployability,update,update,13,Unsurprising update: Cromwell is definitely leaking workflow log file handles.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3716#issuecomment-396673480
https://github.com/broadinstitute/cromwell/issues/3716#issuecomment-396673480:61,Testability,log,log,61,Unsurprising update: Cromwell is definitely leaking workflow log file handles.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3716#issuecomment-396673480
https://github.com/broadinstitute/cromwell/issues/3717#issuecomment-393883431:65,Deployability,configurat,configuration,65,"Hi thanks for reporting this issue, could you post your Cromwell configuration ? Specifically the [call caching part of the backend configuration](https://github.com/broadinstitute/cromwell/blob/cea07d69919a609362d2e374888f9ed8c4220564/cromwell.examples.conf#L332) (if any)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3717#issuecomment-393883431
https://github.com/broadinstitute/cromwell/issues/3717#issuecomment-393883431:132,Deployability,configurat,configuration,132,"Hi thanks for reporting this issue, could you post your Cromwell configuration ? Specifically the [call caching part of the backend configuration](https://github.com/broadinstitute/cromwell/blob/cea07d69919a609362d2e374888f9ed8c4220564/cromwell.examples.conf#L332) (if any)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3717#issuecomment-393883431
https://github.com/broadinstitute/cromwell/issues/3717#issuecomment-393883431:65,Modifiability,config,configuration,65,"Hi thanks for reporting this issue, could you post your Cromwell configuration ? Specifically the [call caching part of the backend configuration](https://github.com/broadinstitute/cromwell/blob/cea07d69919a609362d2e374888f9ed8c4220564/cromwell.examples.conf#L332) (if any)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3717#issuecomment-393883431
https://github.com/broadinstitute/cromwell/issues/3717#issuecomment-393883431:132,Modifiability,config,configuration,132,"Hi thanks for reporting this issue, could you post your Cromwell configuration ? Specifically the [call caching part of the backend configuration](https://github.com/broadinstitute/cromwell/blob/cea07d69919a609362d2e374888f9ed8c4220564/cromwell.examples.conf#L332) (if any)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3717#issuecomment-393883431
https://github.com/broadinstitute/cromwell/issues/3717#issuecomment-393886848:39,Deployability,configurat,configuration,39,"I have to note that I didn't make this configuration (@rhpvorderman will know more about this); This is in the backend section:; ```; caching {; duplication-strategy: [ ""soft-link"", ""copy"", ""hard-link"" ]; hashing-strategy: ""file""; }; ```; This is on the top level:; ```; call-caching {; enabled = true; invalidate-bad-cache-results = true; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3717#issuecomment-393886848
https://github.com/broadinstitute/cromwell/issues/3717#issuecomment-393886848:39,Modifiability,config,configuration,39,"I have to note that I didn't make this configuration (@rhpvorderman will know more about this); This is in the backend section:; ```; caching {; duplication-strategy: [ ""soft-link"", ""copy"", ""hard-link"" ]; hashing-strategy: ""file""; }; ```; This is on the top level:; ```; call-caching {; enabled = true; invalidate-bad-cache-results = true; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3717#issuecomment-393886848
https://github.com/broadinstitute/cromwell/issues/3717#issuecomment-393886848:318,Performance,cache,cache-results,318,"I have to note that I didn't make this configuration (@rhpvorderman will know more about this); This is in the backend section:; ```; caching {; duplication-strategy: [ ""soft-link"", ""copy"", ""hard-link"" ]; hashing-strategy: ""file""; }; ```; This is on the top level:; ```; call-caching {; enabled = true; invalidate-bad-cache-results = true; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3717#issuecomment-393886848
https://github.com/broadinstitute/cromwell/issues/3717#issuecomment-393886848:205,Security,hash,hashing-strategy,205,"I have to note that I didn't make this configuration (@rhpvorderman will know more about this); This is in the backend section:; ```; caching {; duplication-strategy: [ ""soft-link"", ""copy"", ""hard-link"" ]; hashing-strategy: ""file""; }; ```; This is on the top level:; ```; call-caching {; enabled = true; invalidate-bad-cache-results = true; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3717#issuecomment-393886848
https://github.com/broadinstitute/cromwell/issues/3717#issuecomment-394625591:11,Deployability,configurat,configuration,11,The entire configuration here.; https://gist.github.com/rhpvorderman/cd91d3356e3fb460df09b0953c31eadb,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3717#issuecomment-394625591
https://github.com/broadinstitute/cromwell/issues/3717#issuecomment-394625591:11,Modifiability,config,configuration,11,The entire configuration here.; https://gist.github.com/rhpvorderman/cd91d3356e3fb460df09b0953c31eadb,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3717#issuecomment-394625591
https://github.com/broadinstitute/cromwell/issues/3717#issuecomment-395070381:48,Performance,cache,cache,48,@rhpvorderman @DavyCats -- did `mergeLibraries` cache? Would you mind posting the outputs of that task from the first/second run?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3717#issuecomment-395070381
https://github.com/broadinstitute/cromwell/issues/3717#issuecomment-395080386:88,Performance,cache,cached,88,"@ruchim `mergeLibraries` would be run after the indexing step which is not getting call-cached, so no it would not get cached (or at least it will get rerun). I assume you're asking about this call because its output is given to the `mergedIndex` call. This is a different indexing step from the one I was referring to (`samtoolsIndex` in https://github.com/biowdl/aligning/tree/BIOWDL-25). Actually, `mergeLibraries` doesn't get run at all, because there is only one bam file (notice the if statement surrounding the call). `linkBam` is called instead at this point. If you're wondering about the input for the `samtoolsIndex` call, yes that call (`star`) gets cached.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3717#issuecomment-395080386
https://github.com/broadinstitute/cromwell/issues/3717#issuecomment-395080386:119,Performance,cache,cached,119,"@ruchim `mergeLibraries` would be run after the indexing step which is not getting call-cached, so no it would not get cached (or at least it will get rerun). I assume you're asking about this call because its output is given to the `mergedIndex` call. This is a different indexing step from the one I was referring to (`samtoolsIndex` in https://github.com/biowdl/aligning/tree/BIOWDL-25). Actually, `mergeLibraries` doesn't get run at all, because there is only one bam file (notice the if statement surrounding the call). `linkBam` is called instead at this point. If you're wondering about the input for the `samtoolsIndex` call, yes that call (`star`) gets cached.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3717#issuecomment-395080386
https://github.com/broadinstitute/cromwell/issues/3717#issuecomment-395080386:662,Performance,cache,cached,662,"@ruchim `mergeLibraries` would be run after the indexing step which is not getting call-cached, so no it would not get cached (or at least it will get rerun). I assume you're asking about this call because its output is given to the `mergedIndex` call. This is a different indexing step from the one I was referring to (`samtoolsIndex` in https://github.com/biowdl/aligning/tree/BIOWDL-25). Actually, `mergeLibraries` doesn't get run at all, because there is only one bam file (notice the if statement surrounding the call). `linkBam` is called instead at this point. If you're wondering about the input for the `samtoolsIndex` call, yes that call (`star`) gets cached.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3717#issuecomment-395080386
https://github.com/broadinstitute/cromwell/issues/3717#issuecomment-395373551:182,Integrability,depend,depending,182,The problem might be that `bamIndexPath` is an [optional String](https://github.com/biowdl/tasks/blob/d8fd75696ef2c04d0cc2876e77b38e80e0c37e6d/samtools.wdl#L4) whose value will vary depending on the path to the index file rather than its content. I think this should be a File type instead.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3717#issuecomment-395373551
https://github.com/broadinstitute/cromwell/issues/3717#issuecomment-395677185:375,Deployability,pipeline,pipeline,375,"The output which is produced by STAR might be named differently depending on the settings used. Currently this isn't supported yet in this task, but it might be in the future. Because of this I didn't want to make any assumptions on the naming of these files, in order to maintain flexibility in the use of these settings. After some consideration, though, for this specific pipeline I suppose these settings won't (or shouldn't) be changed. So, for now: Yes, the path to the BAI can be calculated in a more stable way. It still seems a bit awkward, though, that a rerun might try to produce a different file from the original run, but I'll close this for now.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3717#issuecomment-395677185
https://github.com/broadinstitute/cromwell/issues/3717#issuecomment-395677185:64,Integrability,depend,depending,64,"The output which is produced by STAR might be named differently depending on the settings used. Currently this isn't supported yet in this task, but it might be in the future. Because of this I didn't want to make any assumptions on the naming of these files, in order to maintain flexibility in the use of these settings. After some consideration, though, for this specific pipeline I suppose these settings won't (or shouldn't) be changed. So, for now: Yes, the path to the BAI can be calculated in a more stable way. It still seems a bit awkward, though, that a rerun might try to produce a different file from the original run, but I'll close this for now.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3717#issuecomment-395677185
https://github.com/broadinstitute/cromwell/pull/3720#issuecomment-394412402:77,Safety,avoid,avoid,77,"PR redo. This on moves the docs to google and increses sbt jvm stack size to avoid ""(cwl / Compile / compileIncremental) java.lang.StackOverflowError"".",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3720#issuecomment-394412402
https://github.com/broadinstitute/cromwell/pull/3721#issuecomment-394391389:144,Security,access,access,144,"Hi @cpavanrun , thanks for the contribution!. Are you using docker? Not having write permission would mean files could only be removed via root access, as docker is executing these services as root. As such, I think this should be `733`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3721#issuecomment-394391389
https://github.com/broadinstitute/cromwell/pull/3721#issuecomment-394394286:315,Availability,down,down,315,"Right. When these issues come up they're part of a tension between people using docker and people using HPC on shared filesystems (who almost always are **not** using docker). . What we've done in the past has been to detect if the context is docker - if so, stick with something more permissive and if not lock it down. YMMV and all of that",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3721#issuecomment-394394286
https://github.com/broadinstitute/cromwell/pull/3721#issuecomment-394394286:218,Safety,detect,detect,218,"Right. When these issues come up they're part of a tension between people using docker and people using HPC on shared filesystems (who almost always are **not** using docker). . What we've done in the past has been to detect if the context is docker - if so, stick with something more permissive and if not lock it down. YMMV and all of that",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3721#issuecomment-394394286
https://github.com/broadinstitute/cromwell/pull/3721#issuecomment-394406690:80,Deployability,Patch,Patch,80,If it's a recurring issue whould it not make sense to have it configurable?; 1. Patch it on every cromwell release; 1. Hard-code a chmod reset in every WDL command,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3721#issuecomment-394406690
https://github.com/broadinstitute/cromwell/pull/3721#issuecomment-394406690:107,Deployability,release,release,107,If it's a recurring issue whould it not make sense to have it configurable?; 1. Patch it on every cromwell release; 1. Hard-code a chmod reset in every WDL command,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3721#issuecomment-394406690
https://github.com/broadinstitute/cromwell/pull/3721#issuecomment-394406690:62,Modifiability,config,configurable,62,If it's a recurring issue whould it not make sense to have it configurable?; 1. Patch it on every cromwell release; 1. Hard-code a chmod reset in every WDL command,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3721#issuecomment-394406690
https://github.com/broadinstitute/cromwell/pull/3721#issuecomment-394428973:23,Modifiability,config,configurable,23,The same way we have a configurable `SCRIPT_EPILOGUE` we could introduce a configurable `SCRIPT_PREFACE` üìñ that would execute before the script. If we export the `TMPDIR` variable before `SCRIPT_PREFACE` is run then backend authors could set whatever permissions they want (or none) on the `TMPDIR`.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3721#issuecomment-394428973
https://github.com/broadinstitute/cromwell/pull/3721#issuecomment-394428973:75,Modifiability,config,configurable,75,The same way we have a configurable `SCRIPT_EPILOGUE` we could introduce a configurable `SCRIPT_PREFACE` üìñ that would execute before the script. If we export the `TMPDIR` variable before `SCRIPT_PREFACE` is run then backend authors could set whatever permissions they want (or none) on the `TMPDIR`.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3721#issuecomment-394428973
https://github.com/broadinstitute/cromwell/pull/3721#issuecomment-394428973:171,Modifiability,variab,variable,171,The same way we have a configurable `SCRIPT_EPILOGUE` we could introduce a configurable `SCRIPT_PREFACE` üìñ that would execute before the script. If we export the `TMPDIR` variable before `SCRIPT_PREFACE` is run then backend authors could set whatever permissions they want (or none) on the `TMPDIR`.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3721#issuecomment-394428973
https://github.com/broadinstitute/cromwell/pull/3721#issuecomment-394686544:84,Modifiability,config,configurable,84,"@cpavanrun That's a good point, although it looks like the `SCRIPT_PREAMBLE` is not configurable, only overridable in code by backend implementations.; We could make it configurable too (while making sure that backend implementations still get to add their bit), or create a different one for just that purpose",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3721#issuecomment-394686544
https://github.com/broadinstitute/cromwell/pull/3721#issuecomment-394686544:169,Modifiability,config,configurable,169,"@cpavanrun That's a good point, although it looks like the `SCRIPT_PREAMBLE` is not configurable, only overridable in code by backend implementations.; We could make it configurable too (while making sure that backend implementations still get to add their bit), or create a different one for just that purpose",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3721#issuecomment-394686544
https://github.com/broadinstitute/cromwell/pull/3721#issuecomment-395221774:103,Modifiability,flexible,flexible,103,I've merged #3735 that only `chmod`s the tmpdir when running on Docker. If it turns out we need a more flexible solution we can revisit the suggestions here.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3721#issuecomment-395221774
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-425209964:197,Availability,avail,available,197,"Specifically looking at the following: `gvcf_joint`, `prealign`, `rnaseq`, `somatic`, `svcall` from https://github.com/bcbio/test_bcbio_cwl. Note that there's a version of `somatic` with GS inputs available in the `gcp` subdir which might make testing smoother for that one. I've seen `prealign` work ok on PAPI2 but haven't had luck on anything else.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-425209964
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-425209964:244,Testability,test,testing,244,"Specifically looking at the following: `gvcf_joint`, `prealign`, `rnaseq`, `somatic`, `svcall` from https://github.com/bcbio/test_bcbio_cwl. Note that there's a version of `somatic` with GS inputs available in the `gcp` subdir which might make testing smoother for that one. I've seen `prealign` work ok on PAPI2 but haven't had luck on anything else.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-425209964
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856:71,Availability,error,error,71,"I'm seeing the `detect_sv` tool in the somatic workflow fail with this error (from stderr):. ```; [2018-11-04T19:02:19.372170Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Failed to complete master workflow, error code: 1; [2018-11-04T19:02:19.372320Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] errorMessage:; [2018-11-04T19:02:19.373700Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Unhandled Exception in TaskRunner-Thread-masterWorkflow; [2018-11-04T19:02:19.373750Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Traceback (most recent call last):; [2018-11-04T19:02:19.373786Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 1069, in run; [2018-11-04T19:02:19.373812Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] (retval, retmsg) = self._run(); [2018-11-04T19:02:19.373833Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 1121, in _run; [2018-11-04T19:02:19.373871Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] self.workflow.workflow(); [2018-11-04T19:02:19.373894Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 895, in workflow; [2018-11-04T19:02:19.373930Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] graphTasks = runLocusGraph(self,dependencies=graphTaskDependencies); [2018-11-04T19:02:19.373954Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 296, in runLocusGraph; [2018-11-04T19:02:19.373978Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] mergeTask = self.addTask(preJoin(taskPrefix,""mergeLocusGraph""),mergeCmd,dependencies=tmpGraphFileListTask,memMb=self.params.mergeMemMb); [2018-11-04T19:02:19.374002Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856:168,Availability,ERROR,ERROR,168,"I'm seeing the `detect_sv` tool in the somatic workflow fail with this error (from stderr):. ```; [2018-11-04T19:02:19.372170Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Failed to complete master workflow, error code: 1; [2018-11-04T19:02:19.372320Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] errorMessage:; [2018-11-04T19:02:19.373700Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Unhandled Exception in TaskRunner-Thread-masterWorkflow; [2018-11-04T19:02:19.373750Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Traceback (most recent call last):; [2018-11-04T19:02:19.373786Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 1069, in run; [2018-11-04T19:02:19.373812Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] (retval, retmsg) = self._run(); [2018-11-04T19:02:19.373833Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 1121, in _run; [2018-11-04T19:02:19.373871Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] self.workflow.workflow(); [2018-11-04T19:02:19.373894Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 895, in workflow; [2018-11-04T19:02:19.373930Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] graphTasks = runLocusGraph(self,dependencies=graphTaskDependencies); [2018-11-04T19:02:19.373954Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 296, in runLocusGraph; [2018-11-04T19:02:19.373978Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] mergeTask = self.addTask(preJoin(taskPrefix,""mergeLocusGraph""),mergeCmd,dependencies=tmpGraphFileListTask,memMb=self.params.mergeMemMb); [2018-11-04T19:02:19.374002Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856:211,Availability,error,error,211,"I'm seeing the `detect_sv` tool in the somatic workflow fail with this error (from stderr):. ```; [2018-11-04T19:02:19.372170Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Failed to complete master workflow, error code: 1; [2018-11-04T19:02:19.372320Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] errorMessage:; [2018-11-04T19:02:19.373700Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Unhandled Exception in TaskRunner-Thread-masterWorkflow; [2018-11-04T19:02:19.373750Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Traceback (most recent call last):; [2018-11-04T19:02:19.373786Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 1069, in run; [2018-11-04T19:02:19.373812Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] (retval, retmsg) = self._run(); [2018-11-04T19:02:19.373833Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 1121, in _run; [2018-11-04T19:02:19.373871Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] self.workflow.workflow(); [2018-11-04T19:02:19.373894Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 895, in workflow; [2018-11-04T19:02:19.373930Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] graphTasks = runLocusGraph(self,dependencies=graphTaskDependencies); [2018-11-04T19:02:19.373954Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 296, in runLocusGraph; [2018-11-04T19:02:19.373978Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] mergeTask = self.addTask(preJoin(taskPrefix,""mergeLocusGraph""),mergeCmd,dependencies=tmpGraphFileListTask,memMb=self.params.mergeMemMb); [2018-11-04T19:02:19.374002Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856:296,Availability,ERROR,ERROR,296,"I'm seeing the `detect_sv` tool in the somatic workflow fail with this error (from stderr):. ```; [2018-11-04T19:02:19.372170Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Failed to complete master workflow, error code: 1; [2018-11-04T19:02:19.372320Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] errorMessage:; [2018-11-04T19:02:19.373700Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Unhandled Exception in TaskRunner-Thread-masterWorkflow; [2018-11-04T19:02:19.373750Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Traceback (most recent call last):; [2018-11-04T19:02:19.373786Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 1069, in run; [2018-11-04T19:02:19.373812Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] (retval, retmsg) = self._run(); [2018-11-04T19:02:19.373833Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 1121, in _run; [2018-11-04T19:02:19.373871Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] self.workflow.workflow(); [2018-11-04T19:02:19.373894Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 895, in workflow; [2018-11-04T19:02:19.373930Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] graphTasks = runLocusGraph(self,dependencies=graphTaskDependencies); [2018-11-04T19:02:19.373954Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 296, in runLocusGraph; [2018-11-04T19:02:19.373978Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] mergeTask = self.addTask(preJoin(taskPrefix,""mergeLocusGraph""),mergeCmd,dependencies=tmpGraphFileListTask,memMb=self.params.mergeMemMb); [2018-11-04T19:02:19.374002Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856:303,Availability,error,errorMessage,303,"I'm seeing the `detect_sv` tool in the somatic workflow fail with this error (from stderr):. ```; [2018-11-04T19:02:19.372170Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Failed to complete master workflow, error code: 1; [2018-11-04T19:02:19.372320Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] errorMessage:; [2018-11-04T19:02:19.373700Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Unhandled Exception in TaskRunner-Thread-masterWorkflow; [2018-11-04T19:02:19.373750Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Traceback (most recent call last):; [2018-11-04T19:02:19.373786Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 1069, in run; [2018-11-04T19:02:19.373812Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] (retval, retmsg) = self._run(); [2018-11-04T19:02:19.373833Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 1121, in _run; [2018-11-04T19:02:19.373871Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] self.workflow.workflow(); [2018-11-04T19:02:19.373894Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 895, in workflow; [2018-11-04T19:02:19.373930Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] graphTasks = runLocusGraph(self,dependencies=graphTaskDependencies); [2018-11-04T19:02:19.373954Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 296, in runLocusGraph; [2018-11-04T19:02:19.373978Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] mergeTask = self.addTask(preJoin(taskPrefix,""mergeLocusGraph""),mergeCmd,dependencies=tmpGraphFileListTask,memMb=self.params.mergeMemMb); [2018-11-04T19:02:19.374002Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856:388,Availability,ERROR,ERROR,388,"I'm seeing the `detect_sv` tool in the somatic workflow fail with this error (from stderr):. ```; [2018-11-04T19:02:19.372170Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Failed to complete master workflow, error code: 1; [2018-11-04T19:02:19.372320Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] errorMessage:; [2018-11-04T19:02:19.373700Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Unhandled Exception in TaskRunner-Thread-masterWorkflow; [2018-11-04T19:02:19.373750Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Traceback (most recent call last):; [2018-11-04T19:02:19.373786Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 1069, in run; [2018-11-04T19:02:19.373812Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] (retval, retmsg) = self._run(); [2018-11-04T19:02:19.373833Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 1121, in _run; [2018-11-04T19:02:19.373871Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] self.workflow.workflow(); [2018-11-04T19:02:19.373894Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 895, in workflow; [2018-11-04T19:02:19.373930Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] graphTasks = runLocusGraph(self,dependencies=graphTaskDependencies); [2018-11-04T19:02:19.373954Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 296, in runLocusGraph; [2018-11-04T19:02:19.373978Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] mergeTask = self.addTask(preJoin(taskPrefix,""mergeLocusGraph""),mergeCmd,dependencies=tmpGraphFileListTask,memMb=self.params.mergeMemMb); [2018-11-04T19:02:19.374002Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856:522,Availability,ERROR,ERROR,522,"I'm seeing the `detect_sv` tool in the somatic workflow fail with this error (from stderr):. ```; [2018-11-04T19:02:19.372170Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Failed to complete master workflow, error code: 1; [2018-11-04T19:02:19.372320Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] errorMessage:; [2018-11-04T19:02:19.373700Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Unhandled Exception in TaskRunner-Thread-masterWorkflow; [2018-11-04T19:02:19.373750Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Traceback (most recent call last):; [2018-11-04T19:02:19.373786Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 1069, in run; [2018-11-04T19:02:19.373812Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] (retval, retmsg) = self._run(); [2018-11-04T19:02:19.373833Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 1121, in _run; [2018-11-04T19:02:19.373871Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] self.workflow.workflow(); [2018-11-04T19:02:19.373894Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 895, in workflow; [2018-11-04T19:02:19.373930Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] graphTasks = runLocusGraph(self,dependencies=graphTaskDependencies); [2018-11-04T19:02:19.373954Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 296, in runLocusGraph; [2018-11-04T19:02:19.373978Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] mergeTask = self.addTask(preJoin(taskPrefix,""mergeLocusGraph""),mergeCmd,dependencies=tmpGraphFileListTask,memMb=self.params.mergeMemMb); [2018-11-04T19:02:19.374002Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856:635,Availability,ERROR,ERROR,635,"I'm seeing the `detect_sv` tool in the somatic workflow fail with this error (from stderr):. ```; [2018-11-04T19:02:19.372170Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Failed to complete master workflow, error code: 1; [2018-11-04T19:02:19.372320Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] errorMessage:; [2018-11-04T19:02:19.373700Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Unhandled Exception in TaskRunner-Thread-masterWorkflow; [2018-11-04T19:02:19.373750Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Traceback (most recent call last):; [2018-11-04T19:02:19.373786Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 1069, in run; [2018-11-04T19:02:19.373812Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] (retval, retmsg) = self._run(); [2018-11-04T19:02:19.373833Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 1121, in _run; [2018-11-04T19:02:19.373871Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] self.workflow.workflow(); [2018-11-04T19:02:19.373894Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 895, in workflow; [2018-11-04T19:02:19.373930Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] graphTasks = runLocusGraph(self,dependencies=graphTaskDependencies); [2018-11-04T19:02:19.373954Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 296, in runLocusGraph; [2018-11-04T19:02:19.373978Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] mergeTask = self.addTask(preJoin(taskPrefix,""mergeLocusGraph""),mergeCmd,dependencies=tmpGraphFileListTask,memMb=self.params.mergeMemMb); [2018-11-04T19:02:19.374002Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856:827,Availability,ERROR,ERROR,827,"I'm seeing the `detect_sv` tool in the somatic workflow fail with this error (from stderr):. ```; [2018-11-04T19:02:19.372170Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Failed to complete master workflow, error code: 1; [2018-11-04T19:02:19.372320Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] errorMessage:; [2018-11-04T19:02:19.373700Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Unhandled Exception in TaskRunner-Thread-masterWorkflow; [2018-11-04T19:02:19.373750Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Traceback (most recent call last):; [2018-11-04T19:02:19.373786Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 1069, in run; [2018-11-04T19:02:19.373812Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] (retval, retmsg) = self._run(); [2018-11-04T19:02:19.373833Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 1121, in _run; [2018-11-04T19:02:19.373871Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] self.workflow.workflow(); [2018-11-04T19:02:19.373894Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 895, in workflow; [2018-11-04T19:02:19.373930Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] graphTasks = runLocusGraph(self,dependencies=graphTaskDependencies); [2018-11-04T19:02:19.373954Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 296, in runLocusGraph; [2018-11-04T19:02:19.373978Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] mergeTask = self.addTask(preJoin(taskPrefix,""mergeLocusGraph""),mergeCmd,dependencies=tmpGraphFileListTask,memMb=self.params.mergeMemMb); [2018-11-04T19:02:19.374002Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856:936,Availability,ERROR,ERROR,936,"I'm seeing the `detect_sv` tool in the somatic workflow fail with this error (from stderr):. ```; [2018-11-04T19:02:19.372170Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Failed to complete master workflow, error code: 1; [2018-11-04T19:02:19.372320Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] errorMessage:; [2018-11-04T19:02:19.373700Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Unhandled Exception in TaskRunner-Thread-masterWorkflow; [2018-11-04T19:02:19.373750Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Traceback (most recent call last):; [2018-11-04T19:02:19.373786Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 1069, in run; [2018-11-04T19:02:19.373812Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] (retval, retmsg) = self._run(); [2018-11-04T19:02:19.373833Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 1121, in _run; [2018-11-04T19:02:19.373871Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] self.workflow.workflow(); [2018-11-04T19:02:19.373894Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 895, in workflow; [2018-11-04T19:02:19.373930Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] graphTasks = runLocusGraph(self,dependencies=graphTaskDependencies); [2018-11-04T19:02:19.373954Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 296, in runLocusGraph; [2018-11-04T19:02:19.373978Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] mergeTask = self.addTask(preJoin(taskPrefix,""mergeLocusGraph""),mergeCmd,dependencies=tmpGraphFileListTask,memMb=self.params.mergeMemMb); [2018-11-04T19:02:19.374002Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856:1129,Availability,ERROR,ERROR,1129,"19:02:19.372170Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Failed to complete master workflow, error code: 1; [2018-11-04T19:02:19.372320Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] errorMessage:; [2018-11-04T19:02:19.373700Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Unhandled Exception in TaskRunner-Thread-masterWorkflow; [2018-11-04T19:02:19.373750Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Traceback (most recent call last):; [2018-11-04T19:02:19.373786Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 1069, in run; [2018-11-04T19:02:19.373812Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] (retval, retmsg) = self._run(); [2018-11-04T19:02:19.373833Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 1121, in _run; [2018-11-04T19:02:19.373871Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] self.workflow.workflow(); [2018-11-04T19:02:19.373894Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 895, in workflow; [2018-11-04T19:02:19.373930Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] graphTasks = runLocusGraph(self,dependencies=graphTaskDependencies); [2018-11-04T19:02:19.373954Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 296, in runLocusGraph; [2018-11-04T19:02:19.373978Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] mergeTask = self.addTask(preJoin(taskPrefix,""mergeLocusGraph""),mergeCmd,dependencies=tmpGraphFileListTask,memMb=self.params.mergeMemMb); [2018-11-04T19:02:19.374002Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 3689, in addTa",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856:1232,Availability,ERROR,ERROR,1232,"02:19.372320Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] errorMessage:; [2018-11-04T19:02:19.373700Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Unhandled Exception in TaskRunner-Thread-masterWorkflow; [2018-11-04T19:02:19.373750Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Traceback (most recent call last):; [2018-11-04T19:02:19.373786Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 1069, in run; [2018-11-04T19:02:19.373812Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] (retval, retmsg) = self._run(); [2018-11-04T19:02:19.373833Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 1121, in _run; [2018-11-04T19:02:19.373871Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] self.workflow.workflow(); [2018-11-04T19:02:19.373894Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 895, in workflow; [2018-11-04T19:02:19.373930Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] graphTasks = runLocusGraph(self,dependencies=graphTaskDependencies); [2018-11-04T19:02:19.373954Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 296, in runLocusGraph; [2018-11-04T19:02:19.373978Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] mergeTask = self.addTask(preJoin(taskPrefix,""mergeLocusGraph""),mergeCmd,dependencies=tmpGraphFileListTask,memMb=self.params.mergeMemMb); [2018-11-04T19:02:19.374002Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 3689, in addTask; [2018-11-04T19:02:19.374023Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] raise Exception(""Task memory requirement exceeds ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856:1428,Availability,ERROR,ERROR,1428,"[2018-11-04T19:02:19.373750Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Traceback (most recent call last):; [2018-11-04T19:02:19.373786Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 1069, in run; [2018-11-04T19:02:19.373812Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] (retval, retmsg) = self._run(); [2018-11-04T19:02:19.373833Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 1121, in _run; [2018-11-04T19:02:19.373871Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] self.workflow.workflow(); [2018-11-04T19:02:19.373894Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 895, in workflow; [2018-11-04T19:02:19.373930Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] graphTasks = runLocusGraph(self,dependencies=graphTaskDependencies); [2018-11-04T19:02:19.373954Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 296, in runLocusGraph; [2018-11-04T19:02:19.373978Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] mergeTask = self.addTask(preJoin(taskPrefix,""mergeLocusGraph""),mergeCmd,dependencies=tmpGraphFileListTask,memMb=self.params.mergeMemMb); [2018-11-04T19:02:19.374002Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 3689, in addTask; [2018-11-04T19:02:19.374023Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] raise Exception(""Task memory requirement exceeds full available resources""); [2018-11-04T19:02:19.374046Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Exception: Task memory requirement exceeds full available resources; ```. The cwl [requests 4GB](https://g",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856:1574,Availability,ERROR,ERROR,1574,"19.373786Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 1069, in run; [2018-11-04T19:02:19.373812Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] (retval, retmsg) = self._run(); [2018-11-04T19:02:19.373833Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 1121, in _run; [2018-11-04T19:02:19.373871Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] self.workflow.workflow(); [2018-11-04T19:02:19.373894Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 895, in workflow; [2018-11-04T19:02:19.373930Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] graphTasks = runLocusGraph(self,dependencies=graphTaskDependencies); [2018-11-04T19:02:19.373954Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 296, in runLocusGraph; [2018-11-04T19:02:19.373978Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] mergeTask = self.addTask(preJoin(taskPrefix,""mergeLocusGraph""),mergeCmd,dependencies=tmpGraphFileListTask,memMb=self.params.mergeMemMb); [2018-11-04T19:02:19.374002Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 3689, in addTask; [2018-11-04T19:02:19.374023Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] raise Exception(""Task memory requirement exceeds full available resources""); [2018-11-04T19:02:19.374046Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Exception: Task memory requirement exceeds full available resources; ```. The cwl [requests 4GB](https://github.com/bcbio/test_bcbio_cwl/blob/48ca2661644e01e2d4b7f8ad8f2588a31cf87537/gcp/somatic-workflow/steps/detect_sv.cwl#L25) of memor",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856:1775,Availability,ERROR,ERROR,1775,"-11-04T19:02:19.373812Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] (retval, retmsg) = self._run(); [2018-11-04T19:02:19.373833Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 1121, in _run; [2018-11-04T19:02:19.373871Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] self.workflow.workflow(); [2018-11-04T19:02:19.373894Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 895, in workflow; [2018-11-04T19:02:19.373930Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] graphTasks = runLocusGraph(self,dependencies=graphTaskDependencies); [2018-11-04T19:02:19.373954Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 296, in runLocusGraph; [2018-11-04T19:02:19.373978Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] mergeTask = self.addTask(preJoin(taskPrefix,""mergeLocusGraph""),mergeCmd,dependencies=tmpGraphFileListTask,memMb=self.params.mergeMemMb); [2018-11-04T19:02:19.374002Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 3689, in addTask; [2018-11-04T19:02:19.374023Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] raise Exception(""Task memory requirement exceeds full available resources""); [2018-11-04T19:02:19.374046Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Exception: Task memory requirement exceeds full available resources; ```. The cwl [requests 4GB](https://github.com/bcbio/test_bcbio_cwl/blob/48ca2661644e01e2d4b7f8ad8f2588a31cf87537/gcp/somatic-workflow/steps/detect_sv.cwl#L25) of memory for this task, which I verified Cromwell did request from PAPI as well:; <pre>; resources:; projectId: broad-dsde-cromwell-perf; regions: []; virtualMachine:; accelerators: []; b",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856:1989,Availability,ERROR,ERROR,1989,"ta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 1121, in _run; [2018-11-04T19:02:19.373871Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] self.workflow.workflow(); [2018-11-04T19:02:19.373894Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 895, in workflow; [2018-11-04T19:02:19.373930Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] graphTasks = runLocusGraph(self,dependencies=graphTaskDependencies); [2018-11-04T19:02:19.373954Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 296, in runLocusGraph; [2018-11-04T19:02:19.373978Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] mergeTask = self.addTask(preJoin(taskPrefix,""mergeLocusGraph""),mergeCmd,dependencies=tmpGraphFileListTask,memMb=self.params.mergeMemMb); [2018-11-04T19:02:19.374002Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 3689, in addTask; [2018-11-04T19:02:19.374023Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] raise Exception(""Task memory requirement exceeds full available resources""); [2018-11-04T19:02:19.374046Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Exception: Task memory requirement exceeds full available resources; ```. The cwl [requests 4GB](https://github.com/bcbio/test_bcbio_cwl/blob/48ca2661644e01e2d4b7f8ad8f2588a31cf87537/gcp/somatic-workflow/steps/detect_sv.cwl#L25) of memory for this task, which I verified Cromwell did request from PAPI as well:; <pre>; resources:; projectId: broad-dsde-cromwell-perf; regions: []; virtualMachine:; accelerators: []; bootDiskSizeGb: 21; bootImage: projects/cos-cloud/global/images/family/cos-stable; cpuPlatform: ''; disks:; - name: local-disk; sizeGb: 10; sourceImage: ''; type: pd-ssd; labels:; cromwell-sub-workflow-name: wf-svcall-cwl; cromwell-work",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856:2185,Availability,ERROR,ERROR,2185," [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 895, in workflow; [2018-11-04T19:02:19.373930Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] graphTasks = runLocusGraph(self,dependencies=graphTaskDependencies); [2018-11-04T19:02:19.373954Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 296, in runLocusGraph; [2018-11-04T19:02:19.373978Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] mergeTask = self.addTask(preJoin(taskPrefix,""mergeLocusGraph""),mergeCmd,dependencies=tmpGraphFileListTask,memMb=self.params.mergeMemMb); [2018-11-04T19:02:19.374002Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 3689, in addTask; [2018-11-04T19:02:19.374023Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] raise Exception(""Task memory requirement exceeds full available resources""); [2018-11-04T19:02:19.374046Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Exception: Task memory requirement exceeds full available resources; ```. The cwl [requests 4GB](https://github.com/bcbio/test_bcbio_cwl/blob/48ca2661644e01e2d4b7f8ad8f2588a31cf87537/gcp/somatic-workflow/steps/detect_sv.cwl#L25) of memory for this task, which I verified Cromwell did request from PAPI as well:; <pre>; resources:; projectId: broad-dsde-cromwell-perf; regions: []; virtualMachine:; accelerators: []; bootDiskSizeGb: 21; bootImage: projects/cos-cloud/global/images/family/cos-stable; cpuPlatform: ''; disks:; - name: local-disk; sizeGb: 10; sourceImage: ''; type: pd-ssd; labels:; cromwell-sub-workflow-name: wf-svcall-cwl; cromwell-workflow-id: cromwell-0344f62e-809d-48d4-8e9a-ede11fe5dd5c; wdl-call-alias: detect-sv; wdl-task-name: detect-sv-cwl; <b>machineType: custom-2-4096</b>; </pre>. @chapmanb I was curious if you've seen this before ? I'm mo",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856:2246,Availability,avail,available,2246," [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 895, in workflow; [2018-11-04T19:02:19.373930Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] graphTasks = runLocusGraph(self,dependencies=graphTaskDependencies); [2018-11-04T19:02:19.373954Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 296, in runLocusGraph; [2018-11-04T19:02:19.373978Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] mergeTask = self.addTask(preJoin(taskPrefix,""mergeLocusGraph""),mergeCmd,dependencies=tmpGraphFileListTask,memMb=self.params.mergeMemMb); [2018-11-04T19:02:19.374002Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 3689, in addTask; [2018-11-04T19:02:19.374023Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] raise Exception(""Task memory requirement exceeds full available resources""); [2018-11-04T19:02:19.374046Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Exception: Task memory requirement exceeds full available resources; ```. The cwl [requests 4GB](https://github.com/bcbio/test_bcbio_cwl/blob/48ca2661644e01e2d4b7f8ad8f2588a31cf87537/gcp/somatic-workflow/steps/detect_sv.cwl#L25) of memory for this task, which I verified Cromwell did request from PAPI as well:; <pre>; resources:; projectId: broad-dsde-cromwell-perf; regions: []; virtualMachine:; accelerators: []; bootDiskSizeGb: 21; bootImage: projects/cos-cloud/global/images/family/cos-stable; cpuPlatform: ''; disks:; - name: local-disk; sizeGb: 10; sourceImage: ''; type: pd-ssd; labels:; cromwell-sub-workflow-name: wf-svcall-cwl; cromwell-workflow-id: cromwell-0344f62e-809d-48d4-8e9a-ede11fe5dd5c; wdl-call-alias: detect-sv; wdl-task-name: detect-sv-cwl; <b>machineType: custom-2-4096</b>; </pre>. @chapmanb I was curious if you've seen this before ? I'm mo",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856:2339,Availability,ERROR,ERROR,2339," line 895, in workflow; [2018-11-04T19:02:19.373930Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] graphTasks = runLocusGraph(self,dependencies=graphTaskDependencies); [2018-11-04T19:02:19.373954Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 296, in runLocusGraph; [2018-11-04T19:02:19.373978Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] mergeTask = self.addTask(preJoin(taskPrefix,""mergeLocusGraph""),mergeCmd,dependencies=tmpGraphFileListTask,memMb=self.params.mergeMemMb); [2018-11-04T19:02:19.374002Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 3689, in addTask; [2018-11-04T19:02:19.374023Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] raise Exception(""Task memory requirement exceeds full available resources""); [2018-11-04T19:02:19.374046Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Exception: Task memory requirement exceeds full available resources; ```. The cwl [requests 4GB](https://github.com/bcbio/test_bcbio_cwl/blob/48ca2661644e01e2d4b7f8ad8f2588a31cf87537/gcp/somatic-workflow/steps/detect_sv.cwl#L25) of memory for this task, which I verified Cromwell did request from PAPI as well:; <pre>; resources:; projectId: broad-dsde-cromwell-perf; regions: []; virtualMachine:; accelerators: []; bootDiskSizeGb: 21; bootImage: projects/cos-cloud/global/images/family/cos-stable; cpuPlatform: ''; disks:; - name: local-disk; sizeGb: 10; sourceImage: ''; type: pd-ssd; labels:; cromwell-sub-workflow-name: wf-svcall-cwl; cromwell-workflow-id: cromwell-0344f62e-809d-48d4-8e9a-ede11fe5dd5c; wdl-call-alias: detect-sv; wdl-task-name: detect-sv-cwl; <b>machineType: custom-2-4096</b>; </pre>. @chapmanb I was curious if you've seen this before ? I'm modifying the CWL to ask for a bit more memory but I'm wondering if there's something else that Cromwell is not doing right",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856:2394,Availability,avail,available,2394," line 895, in workflow; [2018-11-04T19:02:19.373930Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] graphTasks = runLocusGraph(self,dependencies=graphTaskDependencies); [2018-11-04T19:02:19.373954Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 296, in runLocusGraph; [2018-11-04T19:02:19.373978Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] mergeTask = self.addTask(preJoin(taskPrefix,""mergeLocusGraph""),mergeCmd,dependencies=tmpGraphFileListTask,memMb=self.params.mergeMemMb); [2018-11-04T19:02:19.374002Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 3689, in addTask; [2018-11-04T19:02:19.374023Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] raise Exception(""Task memory requirement exceeds full available resources""); [2018-11-04T19:02:19.374046Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Exception: Task memory requirement exceeds full available resources; ```. The cwl [requests 4GB](https://github.com/bcbio/test_bcbio_cwl/blob/48ca2661644e01e2d4b7f8ad8f2588a31cf87537/gcp/somatic-workflow/steps/detect_sv.cwl#L25) of memory for this task, which I verified Cromwell did request from PAPI as well:; <pre>; resources:; projectId: broad-dsde-cromwell-perf; regions: []; virtualMachine:; accelerators: []; bootDiskSizeGb: 21; bootImage: projects/cos-cloud/global/images/family/cos-stable; cpuPlatform: ''; disks:; - name: local-disk; sizeGb: 10; sourceImage: ''; type: pd-ssd; labels:; cromwell-sub-workflow-name: wf-svcall-cwl; cromwell-workflow-id: cromwell-0344f62e-809d-48d4-8e9a-ede11fe5dd5c; wdl-call-alias: detect-sv; wdl-task-name: detect-sv-cwl; <b>machineType: custom-2-4096</b>; </pre>. @chapmanb I was curious if you've seen this before ? I'm modifying the CWL to ask for a bit more memory but I'm wondering if there's something else that Cromwell is not doing right",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856:1467,Integrability,depend,dependencies,1467,"[2018-11-04T19:02:19.373750Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Traceback (most recent call last):; [2018-11-04T19:02:19.373786Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 1069, in run; [2018-11-04T19:02:19.373812Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] (retval, retmsg) = self._run(); [2018-11-04T19:02:19.373833Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 1121, in _run; [2018-11-04T19:02:19.373871Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] self.workflow.workflow(); [2018-11-04T19:02:19.373894Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 895, in workflow; [2018-11-04T19:02:19.373930Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] graphTasks = runLocusGraph(self,dependencies=graphTaskDependencies); [2018-11-04T19:02:19.373954Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 296, in runLocusGraph; [2018-11-04T19:02:19.373978Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] mergeTask = self.addTask(preJoin(taskPrefix,""mergeLocusGraph""),mergeCmd,dependencies=tmpGraphFileListTask,memMb=self.params.mergeMemMb); [2018-11-04T19:02:19.374002Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 3689, in addTask; [2018-11-04T19:02:19.374023Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] raise Exception(""Task memory requirement exceeds full available resources""); [2018-11-04T19:02:19.374046Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Exception: Task memory requirement exceeds full available resources; ```. The cwl [requests 4GB](https://g",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856:1854,Integrability,depend,dependencies,1854,") = self._run(); [2018-11-04T19:02:19.373833Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 1121, in _run; [2018-11-04T19:02:19.373871Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] self.workflow.workflow(); [2018-11-04T19:02:19.373894Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 895, in workflow; [2018-11-04T19:02:19.373930Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] graphTasks = runLocusGraph(self,dependencies=graphTaskDependencies); [2018-11-04T19:02:19.373954Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 296, in runLocusGraph; [2018-11-04T19:02:19.373978Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] mergeTask = self.addTask(preJoin(taskPrefix,""mergeLocusGraph""),mergeCmd,dependencies=tmpGraphFileListTask,memMb=self.params.mergeMemMb); [2018-11-04T19:02:19.374002Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 3689, in addTask; [2018-11-04T19:02:19.374023Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] raise Exception(""Task memory requirement exceeds full available resources""); [2018-11-04T19:02:19.374046Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Exception: Task memory requirement exceeds full available resources; ```. The cwl [requests 4GB](https://github.com/bcbio/test_bcbio_cwl/blob/48ca2661644e01e2d4b7f8ad8f2588a31cf87537/gcp/somatic-workflow/steps/detect_sv.cwl#L25) of memory for this task, which I verified Cromwell did request from PAPI as well:; <pre>; resources:; projectId: broad-dsde-cromwell-perf; regions: []; virtualMachine:; accelerators: []; bootDiskSizeGb: 21; bootImage: projects/cos-cloud/global/images/family/cos-stable; cpuP",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856:3070,Safety,detect,detect-sv,3070," line 895, in workflow; [2018-11-04T19:02:19.373930Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] graphTasks = runLocusGraph(self,dependencies=graphTaskDependencies); [2018-11-04T19:02:19.373954Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 296, in runLocusGraph; [2018-11-04T19:02:19.373978Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] mergeTask = self.addTask(preJoin(taskPrefix,""mergeLocusGraph""),mergeCmd,dependencies=tmpGraphFileListTask,memMb=self.params.mergeMemMb); [2018-11-04T19:02:19.374002Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 3689, in addTask; [2018-11-04T19:02:19.374023Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] raise Exception(""Task memory requirement exceeds full available resources""); [2018-11-04T19:02:19.374046Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Exception: Task memory requirement exceeds full available resources; ```. The cwl [requests 4GB](https://github.com/bcbio/test_bcbio_cwl/blob/48ca2661644e01e2d4b7f8ad8f2588a31cf87537/gcp/somatic-workflow/steps/detect_sv.cwl#L25) of memory for this task, which I verified Cromwell did request from PAPI as well:; <pre>; resources:; projectId: broad-dsde-cromwell-perf; regions: []; virtualMachine:; accelerators: []; bootDiskSizeGb: 21; bootImage: projects/cos-cloud/global/images/family/cos-stable; cpuPlatform: ''; disks:; - name: local-disk; sizeGb: 10; sourceImage: ''; type: pd-ssd; labels:; cromwell-sub-workflow-name: wf-svcall-cwl; cromwell-workflow-id: cromwell-0344f62e-809d-48d4-8e9a-ede11fe5dd5c; wdl-call-alias: detect-sv; wdl-task-name: detect-sv-cwl; <b>machineType: custom-2-4096</b>; </pre>. @chapmanb I was curious if you've seen this before ? I'm modifying the CWL to ask for a bit more memory but I'm wondering if there's something else that Cromwell is not doing right",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856:3096,Safety,detect,detect-sv-cwl,3096," line 895, in workflow; [2018-11-04T19:02:19.373930Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] graphTasks = runLocusGraph(self,dependencies=graphTaskDependencies); [2018-11-04T19:02:19.373954Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/mantaWorkflow.py"", line 296, in runLocusGraph; [2018-11-04T19:02:19.373978Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] mergeTask = self.addTask(preJoin(taskPrefix,""mergeLocusGraph""),mergeCmd,dependencies=tmpGraphFileListTask,memMb=self.params.mergeMemMb); [2018-11-04T19:02:19.374002Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] File ""/usr/local/share/bcbio-nextgen/anaconda/share/manta-1.4.0-1/lib/python/pyflow/pyflow.py"", line 3689, in addTask; [2018-11-04T19:02:19.374023Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] raise Exception(""Task memory requirement exceeds full available resources""); [2018-11-04T19:02:19.374046Z] [2a8fea138cb7] [72_1] [WorkflowRunner] [ERROR] Exception: Task memory requirement exceeds full available resources; ```. The cwl [requests 4GB](https://github.com/bcbio/test_bcbio_cwl/blob/48ca2661644e01e2d4b7f8ad8f2588a31cf87537/gcp/somatic-workflow/steps/detect_sv.cwl#L25) of memory for this task, which I verified Cromwell did request from PAPI as well:; <pre>; resources:; projectId: broad-dsde-cromwell-perf; regions: []; virtualMachine:; accelerators: []; bootDiskSizeGb: 21; bootImage: projects/cos-cloud/global/images/family/cos-stable; cpuPlatform: ''; disks:; - name: local-disk; sizeGb: 10; sourceImage: ''; type: pd-ssd; labels:; cromwell-sub-workflow-name: wf-svcall-cwl; cromwell-workflow-id: cromwell-0344f62e-809d-48d4-8e9a-ede11fe5dd5c; wdl-call-alias: detect-sv; wdl-task-name: detect-sv-cwl; <b>machineType: custom-2-4096</b>; </pre>. @chapmanb I was curious if you've seen this before ? I'm modifying the CWL to ask for a bit more memory but I'm wondering if there's something else that Cromwell is not doing right",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435937856
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435950771:286,Availability,error,error,286,"Thanks much for testing this out. I'm happy to help with whatever I can for supporting this. I haven't seen this previously and am kind of surprised that it hits memory issues. This is a tiny test dataset so I'm not sure why it hits a 4Gb limit. It shouldn't use much memory at all.The error comes from within pyflow, which is an internal workflow system manta uses for running:. https://github.com/Illumina/pyflow/blob/aac143d6b95ddfdc1dad7b2a7226b03a41379b58/pyflow/src/pyflow.py#L3660. I wish it told us the memory it thought the system had and what it wants so we'd have more idea of what is happening. I don't think Cromwell is doing anything wrong here and asking for more memory would be the first thing I'd try as well. Let me know if this doesn't fix and we can try to explore more. Thanks again.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435950771
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435950771:16,Testability,test,testing,16,"Thanks much for testing this out. I'm happy to help with whatever I can for supporting this. I haven't seen this previously and am kind of surprised that it hits memory issues. This is a tiny test dataset so I'm not sure why it hits a 4Gb limit. It shouldn't use much memory at all.The error comes from within pyflow, which is an internal workflow system manta uses for running:. https://github.com/Illumina/pyflow/blob/aac143d6b95ddfdc1dad7b2a7226b03a41379b58/pyflow/src/pyflow.py#L3660. I wish it told us the memory it thought the system had and what it wants so we'd have more idea of what is happening. I don't think Cromwell is doing anything wrong here and asking for more memory would be the first thing I'd try as well. Let me know if this doesn't fix and we can try to explore more. Thanks again.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435950771
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435950771:192,Testability,test,test,192,"Thanks much for testing this out. I'm happy to help with whatever I can for supporting this. I haven't seen this previously and am kind of surprised that it hits memory issues. This is a tiny test dataset so I'm not sure why it hits a 4Gb limit. It shouldn't use much memory at all.The error comes from within pyflow, which is an internal workflow system manta uses for running:. https://github.com/Illumina/pyflow/blob/aac143d6b95ddfdc1dad7b2a7226b03a41379b58/pyflow/src/pyflow.py#L3660. I wish it told us the memory it thought the system had and what it wants so we'd have more idea of what is happening. I don't think Cromwell is doing anything wrong here and asking for more memory would be the first thing I'd try as well. Let me know if this doesn't fix and we can try to explore more. Thanks again.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435950771
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435958655:26,Deployability,update,update,26,Sounds good thanks ! I'll update here once I have more info.; In similar news I was able to run [gvcf_joint](https://github.com/bcbio/test_bcbio_cwl/tree/master/gvcf_joint/gvcf-joint-workflow) to completion using the same inputs as in the gcp/somatic workflow (in the `gs://bcbiodata/test_bcbio_cwl` bucket),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435958655
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435984778:124,Usability,simpl,simpler,124,"Nice one, glad you're having success with the gvcf_joint workflow. That has more parts and the svcaller one was meant to be simpler, so having that going is a good indication you've got most of the Cromwell parts in place. Really nice, I'm excited about having this going on GCP. Thanks again for all the work.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-435984778
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277:176,Availability,error,error,176,"@chapmanb Somatic completed successfully by bumping the memory (I doubled it to 8GB) :); I have another question about the rnaseq pipeline if you don't mind.; I'm hitting this error on the `pipeline_summary` task:. ```; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/cyvcf2/__init__.py:1: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from .cyvcf2 import (VCF, Variant, Writer, r_ as r_unphased, par_relatedness,; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/_libs/__init__.py:4: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from .tslib import iNaT, NaT, Timestamp, Timedelta, OutOfBoundsDatetime; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/__init__.py:26: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from pandas._libs import (hashtable as _hashtable,; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/core/dtypes/common.py:6: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from pandas._libs import algos, lib; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/core/util/hashing.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from pandas._libs import hashing, tslib; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/core/indexes/base.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from pandas._libs import (lib, index as libindex, tslib as libts,; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/tseries/offsets.py:21: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; import pandas._libs.tslibs.offsets as liboffsets; /usr/loca",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277:130,Deployability,pipeline,pipeline,130,"@chapmanb Somatic completed successfully by bumping the memory (I doubled it to 8GB) :); I have another question about the rnaseq pipeline if you don't mind.; I'm hitting this error on the `pipeline_summary` task:. ```; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/cyvcf2/__init__.py:1: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from .cyvcf2 import (VCF, Variant, Writer, r_ as r_unphased, par_relatedness,; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/_libs/__init__.py:4: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from .tslib import iNaT, NaT, Timestamp, Timedelta, OutOfBoundsDatetime; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/__init__.py:26: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from pandas._libs import (hashtable as _hashtable,; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/core/dtypes/common.py:6: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from pandas._libs import algos, lib; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/core/util/hashing.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from pandas._libs import hashing, tslib; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/core/indexes/base.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from pandas._libs import (lib, index as libindex, tslib as libts,; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/tseries/offsets.py:21: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; import pandas._libs.tslibs.offsets as liboffsets; /usr/loca",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277:5325,Deployability,pipeline,pipeline,5325,"t this database has not had the ANALYZE sqlite3 command run on it. Doing so can dramatically speed up queries, and is done by default for databases created with gffutils >0.8.7.1 (this database was created with version 0.8.2) Consider calling the analyze() method of this object.; ""method of this object."" % self.version); Traceback (most recent call last):; File ""/usr/local/bin/bcbio_nextgen.py"", line 223, in <module>; runfn.process(kwargs[""args""]); File ""/usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/bcbio/distributed/runfn.py"", line 58, in process; out = fn(fnargs); File ""/usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/bcbio/utils.py"", line 52, in wrapper; return apply(f, *args, **kwargs); File ""/usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/bcbio/distributed/multitasks.py"", line 208, in pipeline_summary; return qcsummary.pipeline_summary(*args); File ""/usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/bcbio/pipeline/qcsummary.py"", line 70, in pipeline_summary; data[""summary""] = _run_qc_tools(work_bam, work_data); File ""/usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/bcbio/pipeline/qcsummary.py"", line 162, in _run_qc_tools; out = qc_fn(bam_file, data, cur_qc_dir); File ""/usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/bcbio/qc/qualimap.py"", line 347, in run_rnaseq; metrics = _parse_metrics(metrics); File ""/usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/bcbio/qc/qualimap.py"", line 210, in _parse_metrics; out.update({name: float(metrics[name])}); TypeError: float() argument must be a string or a number; ```. This is what the command Cromwell generated looks like:. ```; 'bcbio_nextgen.py' 'runfn' 'pipeline_summary' 'cwl' 'sentinel_runtime=cores,2,ram,4096' 'sentinel_parallel=multi-parallel' 'sentinel_outputs=qcout_rec:summary__qc;summary__metrics;resources;description;reference__fasta__base;config__algorithm__coverage_interval;genome",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277:5513,Deployability,pipeline,pipeline,5513,"abase was created with version 0.8.2) Consider calling the analyze() method of this object.; ""method of this object."" % self.version); Traceback (most recent call last):; File ""/usr/local/bin/bcbio_nextgen.py"", line 223, in <module>; runfn.process(kwargs[""args""]); File ""/usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/bcbio/distributed/runfn.py"", line 58, in process; out = fn(fnargs); File ""/usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/bcbio/utils.py"", line 52, in wrapper; return apply(f, *args, **kwargs); File ""/usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/bcbio/distributed/multitasks.py"", line 208, in pipeline_summary; return qcsummary.pipeline_summary(*args); File ""/usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/bcbio/pipeline/qcsummary.py"", line 70, in pipeline_summary; data[""summary""] = _run_qc_tools(work_bam, work_data); File ""/usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/bcbio/pipeline/qcsummary.py"", line 162, in _run_qc_tools; out = qc_fn(bam_file, data, cur_qc_dir); File ""/usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/bcbio/qc/qualimap.py"", line 347, in run_rnaseq; metrics = _parse_metrics(metrics); File ""/usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/bcbio/qc/qualimap.py"", line 210, in _parse_metrics; out.update({name: float(metrics[name])}); TypeError: float() argument must be a string or a number; ```. This is what the command Cromwell generated looks like:. ```; 'bcbio_nextgen.py' 'runfn' 'pipeline_summary' 'cwl' 'sentinel_runtime=cores,2,ram,4096' 'sentinel_parallel=multi-parallel' 'sentinel_outputs=qcout_rec:summary__qc;summary__metrics;resources;description;reference__fasta__base;config__algorithm__coverage_interval;genome_build;genome_resources__rnaseq__transcripts;config__algorithm__tools_off;config__algorithm__qc;analysis;config__algorithm__tools_on;align_bam' 'sentinel_inputs=qc_rec:record' 'run_number=",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277:5893,Deployability,update,update,5893,"bio-nextgen/anaconda/lib/python2.7/site-packages/bcbio/utils.py"", line 52, in wrapper; return apply(f, *args, **kwargs); File ""/usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/bcbio/distributed/multitasks.py"", line 208, in pipeline_summary; return qcsummary.pipeline_summary(*args); File ""/usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/bcbio/pipeline/qcsummary.py"", line 70, in pipeline_summary; data[""summary""] = _run_qc_tools(work_bam, work_data); File ""/usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/bcbio/pipeline/qcsummary.py"", line 162, in _run_qc_tools; out = qc_fn(bam_file, data, cur_qc_dir); File ""/usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/bcbio/qc/qualimap.py"", line 347, in run_rnaseq; metrics = _parse_metrics(metrics); File ""/usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/bcbio/qc/qualimap.py"", line 210, in _parse_metrics; out.update({name: float(metrics[name])}); TypeError: float() argument must be a string or a number; ```. This is what the command Cromwell generated looks like:. ```; 'bcbio_nextgen.py' 'runfn' 'pipeline_summary' 'cwl' 'sentinel_runtime=cores,2,ram,4096' 'sentinel_parallel=multi-parallel' 'sentinel_outputs=qcout_rec:summary__qc;summary__metrics;resources;description;reference__fasta__base;config__algorithm__coverage_interval;genome_build;genome_resources__rnaseq__transcripts;config__algorithm__tools_off;config__algorithm__qc;analysis;config__algorithm__tools_on;align_bam' 'sentinel_inputs=qc_rec:record' 'run_number=0'; ```. And the `cwl.inputs.json`:. ```; {; ""qc_rec"": {; ""genome_build"": ""hg19"",; ""config__algorithm__tools_on"": [],; ""align_bam"": {; ""nameext"": "".bam"",; ""location"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/call-process_alignment/shard-0/align/Test1/Test1-sort.bam"",; ""path"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277:4278,Integrability,interface,interface,4278,"pandas/core/groupby/groupby.py:68: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from pandas._libs import (lib, reduction,; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/core/reshape/reshape.py:30: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from pandas._libs import algos as _algos, reshape as _reshape; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/io/parsers.py:45: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; import pandas._libs.parsers as parsers; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/io/pytables.py:50: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from pandas._libs import algos, lib, writers as libwriters; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/gffutils/interface.py:161: UserWarning: It appears that this database has not had the ANALYZE sqlite3 command run on it. Doing so can dramatically speed up queries, and is done by default for databases created with gffutils >0.8.7.1 (this database was created with version 0.8.2) Consider calling the analyze() method of this object.; ""method of this object."" % self.version); Traceback (most recent call last):; File ""/usr/local/bin/bcbio_nextgen.py"", line 223, in <module>; runfn.process(kwargs[""args""]); File ""/usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/bcbio/distributed/runfn.py"", line 58, in process; out = fn(fnargs); File ""/usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/bcbio/utils.py"", line 52, in wrapper; return apply(f, *args, **kwargs); File ""/usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/bcbio/distributed/multitasks.py"", line 208, in pipeline_summary; return qcsummary.pipeline_summary(*args); File ""/usr/local/share/bcb",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277:5021,Integrability,wrap,wrapper,5021,"dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from pandas._libs import algos, lib, writers as libwriters; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/gffutils/interface.py:161: UserWarning: It appears that this database has not had the ANALYZE sqlite3 command run on it. Doing so can dramatically speed up queries, and is done by default for databases created with gffutils >0.8.7.1 (this database was created with version 0.8.2) Consider calling the analyze() method of this object.; ""method of this object."" % self.version); Traceback (most recent call last):; File ""/usr/local/bin/bcbio_nextgen.py"", line 223, in <module>; runfn.process(kwargs[""args""]); File ""/usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/bcbio/distributed/runfn.py"", line 58, in process; out = fn(fnargs); File ""/usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/bcbio/utils.py"", line 52, in wrapper; return apply(f, *args, **kwargs); File ""/usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/bcbio/distributed/multitasks.py"", line 208, in pipeline_summary; return qcsummary.pipeline_summary(*args); File ""/usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/bcbio/pipeline/qcsummary.py"", line 70, in pipeline_summary; data[""summary""] = _run_qc_tools(work_bam, work_data); File ""/usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/bcbio/pipeline/qcsummary.py"", line 162, in _run_qc_tools; out = qc_fn(bam_file, data, cur_qc_dir); File ""/usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/bcbio/qc/qualimap.py"", line 347, in run_rnaseq; metrics = _parse_metrics(metrics); File ""/usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/bcbio/qc/qualimap.py"", line 210, in _parse_metrics; out.update({name: float(metrics[name])}); TypeError: float() argument must be a string or a number; ```. This is what the command Cromwell generated looks like:. ```; 'bcbio_",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277:975,Security,hash,hashtable,975,"nb Somatic completed successfully by bumping the memory (I doubled it to 8GB) :); I have another question about the rnaseq pipeline if you don't mind.; I'm hitting this error on the `pipeline_summary` task:. ```; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/cyvcf2/__init__.py:1: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from .cyvcf2 import (VCF, Variant, Writer, r_ as r_unphased, par_relatedness,; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/_libs/__init__.py:4: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from .tslib import iNaT, NaT, Timestamp, Timedelta, OutOfBoundsDatetime; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/__init__.py:26: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from pandas._libs import (hashtable as _hashtable,; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/core/dtypes/common.py:6: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from pandas._libs import algos, lib; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/core/util/hashing.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from pandas._libs import hashing, tslib; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/core/indexes/base.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from pandas._libs import (lib, index as libindex, tslib as libts,; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/tseries/offsets.py:21: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; import pandas._libs.tslibs.offsets as liboffsets; /usr/local/shar",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277:1323,Security,hash,hashing,1323,"RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from .cyvcf2 import (VCF, Variant, Writer, r_ as r_unphased, par_relatedness,; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/_libs/__init__.py:4: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from .tslib import iNaT, NaT, Timestamp, Timedelta, OutOfBoundsDatetime; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/__init__.py:26: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from pandas._libs import (hashtable as _hashtable,; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/core/dtypes/common.py:6: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from pandas._libs import algos, lib; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/core/util/hashing.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from pandas._libs import hashing, tslib; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/core/indexes/base.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from pandas._libs import (lib, index as libindex, tslib as libts,; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/tseries/offsets.py:21: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; import pandas._libs.tslibs.offsets as liboffsets; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/core/ops.py:16: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from pandas._libs import algos as libalgos, ops as libops; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/p",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277:1462,Security,hash,hashing,1462,"/usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/_libs/__init__.py:4: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from .tslib import iNaT, NaT, Timestamp, Timedelta, OutOfBoundsDatetime; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/__init__.py:26: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from pandas._libs import (hashtable as _hashtable,; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/core/dtypes/common.py:6: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from pandas._libs import algos, lib; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/core/util/hashing.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from pandas._libs import hashing, tslib; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/core/indexes/base.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from pandas._libs import (lib, index as libindex, tslib as libts,; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/tseries/offsets.py:21: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; import pandas._libs.tslibs.offsets as liboffsets; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/core/ops.py:16: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from pandas._libs import algos as libalgos, ops as libops; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/core/indexes/interval.py:32: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from pandas._libs.interval import (; /usr/lo",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277:8176,Testability,test,testdata,8176,"rd-0/align/Test1"",; ""secondaryFiles"": [; {; ""nameext"": "".bai"",; ""location"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/call-process_alignment/shard-0/align/Test1/Test1-sort.bam.bai"",; ""path"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/call-process_alignment/shard-0/align/Test1/Test1-sort.bam.bai"",; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/call-process_alignment/shard-0/align/Test1"",; ""secondaryFiles"": [],; ""basename"": ""Test1-sort.bam.bai"",; ""class"": ""File"",; ""nameroot"": ""Test1-sort.bam""; }; ],; ""basename"": ""Test1-sort.bam"",; ""class"": ""File"",; ""nameroot"": ""Test1-sort""; },; ""description"": ""Test1"",; ""config__algorithm__tools_off"": [],; ""genome_resources__rnaseq__transcripts"": {; ""nameext"": "".gtf"",; ""location"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq/ref-transcripts.gtf"",; ""path"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq/ref-transcripts.gtf"",; ""size"": 15149,; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq"",; ""secondaryFiles"": [; {; ""nameext"": "".db"",; ""location"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq/ref-transcripts.gtf.db"",; ""path"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq/ref-transcripts.gtf.db"",; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/gen",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277:8359,Testability,test,testdata,8359,"ess_alignment/shard-0/align/Test1/Test1-sort.bam.bai"",; ""path"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/call-process_alignment/shard-0/align/Test1/Test1-sort.bam.bai"",; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/call-process_alignment/shard-0/align/Test1"",; ""secondaryFiles"": [],; ""basename"": ""Test1-sort.bam.bai"",; ""class"": ""File"",; ""nameroot"": ""Test1-sort.bam""; }; ],; ""basename"": ""Test1-sort.bam"",; ""class"": ""File"",; ""nameroot"": ""Test1-sort""; },; ""description"": ""Test1"",; ""config__algorithm__tools_off"": [],; ""genome_resources__rnaseq__transcripts"": {; ""nameext"": "".gtf"",; ""location"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq/ref-transcripts.gtf"",; ""path"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq/ref-transcripts.gtf"",; ""size"": 15149,; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq"",; ""secondaryFiles"": [; {; ""nameext"": "".db"",; ""location"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq/ref-transcripts.gtf.db"",; ""path"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq/ref-transcripts.gtf.db"",; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq"",; ""secondaryFiles"": [],; ""basename"": ""ref-transcripts.gtf.db"",; ""class"": ""File"",; ""nameroot"": ""ref-transcripts.gtf""; }; ],; ""basename"": ""ref-transcripts.gtf"",; ""clas",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277:8561,Testability,test,testdata,8561,"t.bam.bai"",; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/call-process_alignment/shard-0/align/Test1"",; ""secondaryFiles"": [],; ""basename"": ""Test1-sort.bam.bai"",; ""class"": ""File"",; ""nameroot"": ""Test1-sort.bam""; }; ],; ""basename"": ""Test1-sort.bam"",; ""class"": ""File"",; ""nameroot"": ""Test1-sort""; },; ""description"": ""Test1"",; ""config__algorithm__tools_off"": [],; ""genome_resources__rnaseq__transcripts"": {; ""nameext"": "".gtf"",; ""location"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq/ref-transcripts.gtf"",; ""path"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq/ref-transcripts.gtf"",; ""size"": 15149,; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq"",; ""secondaryFiles"": [; {; ""nameext"": "".db"",; ""location"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq/ref-transcripts.gtf.db"",; ""path"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq/ref-transcripts.gtf.db"",; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq"",; ""secondaryFiles"": [],; ""basename"": ""ref-transcripts.gtf.db"",; ""class"": ""File"",; ""nameroot"": ""ref-transcripts.gtf""; }; ],; ""basename"": ""ref-transcripts.gtf"",; ""class"": ""File"",; ""nameroot"": ""ref-transcripts""; },; ""reference__fasta__base"": {; ""nameext"": "".fa"",; ""location"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodat",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277:8771,Testability,test,testdata,8771,"me"": ""Test1-sort.bam.bai"",; ""class"": ""File"",; ""nameroot"": ""Test1-sort.bam""; }; ],; ""basename"": ""Test1-sort.bam"",; ""class"": ""File"",; ""nameroot"": ""Test1-sort""; },; ""description"": ""Test1"",; ""config__algorithm__tools_off"": [],; ""genome_resources__rnaseq__transcripts"": {; ""nameext"": "".gtf"",; ""location"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq/ref-transcripts.gtf"",; ""path"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq/ref-transcripts.gtf"",; ""size"": 15149,; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq"",; ""secondaryFiles"": [; {; ""nameext"": "".db"",; ""location"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq/ref-transcripts.gtf.db"",; ""path"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq/ref-transcripts.gtf.db"",; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq"",; ""secondaryFiles"": [],; ""basename"": ""ref-transcripts.gtf.db"",; ""class"": ""File"",; ""nameroot"": ""ref-transcripts.gtf""; }; ],; ""basename"": ""ref-transcripts.gtf"",; ""class"": ""File"",; ""nameroot"": ""ref-transcripts""; },; ""reference__fasta__base"": {; ""nameext"": "".fa"",; ""location"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.fa"",; ""path"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/geno",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277:8957,Testability,test,testdata,8957," ""config__algorithm__tools_off"": [],; ""genome_resources__rnaseq__transcripts"": {; ""nameext"": "".gtf"",; ""location"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq/ref-transcripts.gtf"",; ""path"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq/ref-transcripts.gtf"",; ""size"": 15149,; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq"",; ""secondaryFiles"": [; {; ""nameext"": "".db"",; ""location"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq/ref-transcripts.gtf.db"",; ""path"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq/ref-transcripts.gtf.db"",; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq"",; ""secondaryFiles"": [],; ""basename"": ""ref-transcripts.gtf.db"",; ""class"": ""File"",; ""nameroot"": ""ref-transcripts.gtf""; }; ],; ""basename"": ""ref-transcripts.gtf"",; ""class"": ""File"",; ""nameroot"": ""ref-transcripts""; },; ""reference__fasta__base"": {; ""nameext"": "".fa"",; ""location"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.fa"",; ""path"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.fa"",; ""size"": 37196,; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/gen",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277:9146,Testability,test,testdata,9146,"rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq/ref-transcripts.gtf"",; ""path"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq/ref-transcripts.gtf"",; ""size"": 15149,; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq"",; ""secondaryFiles"": [; {; ""nameext"": "".db"",; ""location"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq/ref-transcripts.gtf.db"",; ""path"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq/ref-transcripts.gtf.db"",; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq"",; ""secondaryFiles"": [],; ""basename"": ""ref-transcripts.gtf.db"",; ""class"": ""File"",; ""nameroot"": ""ref-transcripts.gtf""; }; ],; ""basename"": ""ref-transcripts.gtf"",; ""class"": ""File"",; ""nameroot"": ""ref-transcripts""; },; ""reference__fasta__base"": {; ""nameext"": "".fa"",; ""location"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.fa"",; ""path"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.fa"",; ""size"": 37196,; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq"",; ""secondaryFiles"": [; {; ""nameext"": "".fai"",; ""location"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/geno",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277:9572,Testability,test,testdata,9572,"est_bcbio_cwl/testdata/genomes/hg19/rnaseq"",; ""secondaryFiles"": [; {; ""nameext"": "".db"",; ""location"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq/ref-transcripts.gtf.db"",; ""path"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq/ref-transcripts.gtf.db"",; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq"",; ""secondaryFiles"": [],; ""basename"": ""ref-transcripts.gtf.db"",; ""class"": ""File"",; ""nameroot"": ""ref-transcripts.gtf""; }; ],; ""basename"": ""ref-transcripts.gtf"",; ""class"": ""File"",; ""nameroot"": ""ref-transcripts""; },; ""reference__fasta__base"": {; ""nameext"": "".fa"",; ""location"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.fa"",; ""path"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.fa"",; ""size"": 37196,; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq"",; ""secondaryFiles"": [; {; ""nameext"": "".fai"",; ""location"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.fa.fai"",; ""path"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.fa.fai"",; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq"",; ""secondaryFiles"": [],; ""basename"": """,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277:9740,Testability,test,testdata,9740,"5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq/ref-transcripts.gtf.db"",; ""path"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq/ref-transcripts.gtf.db"",; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq"",; ""secondaryFiles"": [],; ""basename"": ""ref-transcripts.gtf.db"",; ""class"": ""File"",; ""nameroot"": ""ref-transcripts.gtf""; }; ],; ""basename"": ""ref-transcripts.gtf"",; ""class"": ""File"",; ""nameroot"": ""ref-transcripts""; },; ""reference__fasta__base"": {; ""nameext"": "".fa"",; ""location"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.fa"",; ""path"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.fa"",; ""size"": 37196,; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq"",; ""secondaryFiles"": [; {; ""nameext"": "".fai"",; ""location"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.fa.fai"",; ""path"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.fa.fai"",; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq"",; ""secondaryFiles"": [],; ""basename"": ""hg19.fa.fai"",; ""class"": ""File"",; ""nameroot"": ""hg19.fa""; },; {; ""nameext"": "".dict"",; ""location"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277:9927,Testability,test,testdata,9927,"ll-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq/ref-transcripts.gtf.db"",; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq"",; ""secondaryFiles"": [],; ""basename"": ""ref-transcripts.gtf.db"",; ""class"": ""File"",; ""nameroot"": ""ref-transcripts.gtf""; }; ],; ""basename"": ""ref-transcripts.gtf"",; ""class"": ""File"",; ""nameroot"": ""ref-transcripts""; },; ""reference__fasta__base"": {; ""nameext"": "".fa"",; ""location"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.fa"",; ""path"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.fa"",; ""size"": 37196,; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq"",; ""secondaryFiles"": [; {; ""nameext"": "".fai"",; ""location"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.fa.fai"",; ""path"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.fa.fai"",; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq"",; ""secondaryFiles"": [],; ""basename"": ""hg19.fa.fai"",; ""class"": ""File"",; ""nameroot"": ""hg19.fa""; },; {; ""nameext"": "".dict"",; ""location"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.dict"",; ""path"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277:10135,Testability,test,testdata,10135,"-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/rnaseq"",; ""secondaryFiles"": [],; ""basename"": ""ref-transcripts.gtf.db"",; ""class"": ""File"",; ""nameroot"": ""ref-transcripts.gtf""; }; ],; ""basename"": ""ref-transcripts.gtf"",; ""class"": ""File"",; ""nameroot"": ""ref-transcripts""; },; ""reference__fasta__base"": {; ""nameext"": "".fa"",; ""location"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.fa"",; ""path"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.fa"",; ""size"": 37196,; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq"",; ""secondaryFiles"": [; {; ""nameext"": "".fai"",; ""location"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.fa.fai"",; ""path"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.fa.fai"",; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq"",; ""secondaryFiles"": [],; ""basename"": ""hg19.fa.fai"",; ""class"": ""File"",; ""nameroot"": ""hg19.fa""; },; {; ""nameext"": "".dict"",; ""location"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.dict"",; ""path"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.dict"",; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/t",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277:10307,Testability,test,testdata,10307,"ipts.gtf""; }; ],; ""basename"": ""ref-transcripts.gtf"",; ""class"": ""File"",; ""nameroot"": ""ref-transcripts""; },; ""reference__fasta__base"": {; ""nameext"": "".fa"",; ""location"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.fa"",; ""path"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.fa"",; ""size"": 37196,; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq"",; ""secondaryFiles"": [; {; ""nameext"": "".fai"",; ""location"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.fa.fai"",; ""path"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.fa.fai"",; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq"",; ""secondaryFiles"": [],; ""basename"": ""hg19.fa.fai"",; ""class"": ""File"",; ""nameroot"": ""hg19.fa""; },; {; ""nameext"": "".dict"",; ""location"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.dict"",; ""path"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.dict"",; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq"",; ""secondaryFiles"": [],; ""basename"": ""hg19.dict"",; ""class"": ""File"",; ""nameroot"": ""hg19""; }; ],; ""basename"": ""hg19.fa"",; ""class"": ""File"",; ""nameroo",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277:10482,Testability,test,testdata,10482,"pi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.fa"",; ""path"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.fa"",; ""size"": 37196,; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq"",; ""secondaryFiles"": [; {; ""nameext"": "".fai"",; ""location"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.fa.fai"",; ""path"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.fa.fai"",; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq"",; ""secondaryFiles"": [],; ""basename"": ""hg19.fa.fai"",; ""class"": ""File"",; ""nameroot"": ""hg19.fa""; },; {; ""nameext"": "".dict"",; ""location"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.dict"",; ""path"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.dict"",; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq"",; ""secondaryFiles"": [],; ""basename"": ""hg19.dict"",; ""class"": ""File"",; ""nameroot"": ""hg19""; }; ],; ""basename"": ""hg19.fa"",; ""class"": ""File"",; ""nameroot"": ""hg19""; },; ""analysis"": ""RNA-seq"",; ""resources"": ""{\""default\"":{\""cores\"":1,\""jvm_opts\"":[\""-Xms1000m\"",\""-Xmx2048m\""],\""memory\"":\""2048M\""}}"",; ""config__algorithm__qc"": [; ""qualimap_rnaseq"";",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277:10766,Testability,test,testdata,10766,"estdata/genomes/hg19/seq/hg19.fa"",; ""size"": 37196,; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq"",; ""secondaryFiles"": [; {; ""nameext"": "".fai"",; ""location"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.fa.fai"",; ""path"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.fa.fai"",; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq"",; ""secondaryFiles"": [],; ""basename"": ""hg19.fa.fai"",; ""class"": ""File"",; ""nameroot"": ""hg19.fa""; },; {; ""nameext"": "".dict"",; ""location"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.dict"",; ""path"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.dict"",; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq"",; ""secondaryFiles"": [],; ""basename"": ""hg19.dict"",; ""class"": ""File"",; ""nameroot"": ""hg19""; }; ],; ""basename"": ""hg19.fa"",; ""class"": ""File"",; ""nameroot"": ""hg19""; },; ""analysis"": ""RNA-seq"",; ""resources"": ""{\""default\"":{\""cores\"":1,\""jvm_opts\"":[\""-Xms1000m\"",\""-Xmx2048m\""],\""memory\"":\""2048M\""}}"",; ""config__algorithm__qc"": [; ""qualimap_rnaseq""; ],; ""config__algorithm__coverage_interval"": null; }; }; ```. The only thing maybe off that I see is the `config__algorithm__coverage_interval` (at the bottom of the json) being `null` ? Is this something that you'd expect not to be `null` and could throw off the ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277:10936,Testability,test,testdata,10936,"a/genomes/hg19/seq/hg19.fa"",; ""size"": 37196,; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq"",; ""secondaryFiles"": [; {; ""nameext"": "".fai"",; ""location"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.fa.fai"",; ""path"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.fa.fai"",; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq"",; ""secondaryFiles"": [],; ""basename"": ""hg19.fa.fai"",; ""class"": ""File"",; ""nameroot"": ""hg19.fa""; },; {; ""nameext"": "".dict"",; ""location"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.dict"",; ""path"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.dict"",; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq"",; ""secondaryFiles"": [],; ""basename"": ""hg19.dict"",; ""class"": ""File"",; ""nameroot"": ""hg19""; }; ],; ""basename"": ""hg19.fa"",; ""class"": ""File"",; ""nameroot"": ""hg19""; },; ""analysis"": ""RNA-seq"",; ""resources"": ""{\""default\"":{\""cores\"":1,\""jvm_opts\"":[\""-Xms1000m\"",\""-Xmx2048m\""],\""memory\"":\""2048M\""}}"",; ""config__algorithm__qc"": [; ""qualimap_rnaseq""; ],; ""config__algorithm__coverage_interval"": null; }; }; ```. The only thing maybe off that I see is the `config__algorithm__coverage_interval` (at the bottom of the json) being `null` ? Is this something that you'd expect not to be `null` and could throw off the tool ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277:11109,Testability,test,testdata,11109,"a/genomes/hg19/seq/hg19.fa"",; ""size"": 37196,; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq"",; ""secondaryFiles"": [; {; ""nameext"": "".fai"",; ""location"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.fa.fai"",; ""path"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.fa.fai"",; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq"",; ""secondaryFiles"": [],; ""basename"": ""hg19.fa.fai"",; ""class"": ""File"",; ""nameroot"": ""hg19.fa""; },; {; ""nameext"": "".dict"",; ""location"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.dict"",; ""path"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.dict"",; ""dirname"": ""/cromwell_root/tj-bcbio-papi/main-rnaseq.cwl/6c75cc7c-5515-45e0-9e5b-9a1b9e6fd2e1/call-qc_to_rec/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq"",; ""secondaryFiles"": [],; ""basename"": ""hg19.dict"",; ""class"": ""File"",; ""nameroot"": ""hg19""; }; ],; ""basename"": ""hg19.fa"",; ""class"": ""File"",; ""nameroot"": ""hg19""; },; ""analysis"": ""RNA-seq"",; ""resources"": ""{\""default\"":{\""cores\"":1,\""jvm_opts\"":[\""-Xms1000m\"",\""-Xmx2048m\""],\""memory\"":\""2048M\""}}"",; ""config__algorithm__qc"": [; ""qualimap_rnaseq""; ],; ""config__algorithm__coverage_interval"": null; }; }; ```. The only thing maybe off that I see is the `config__algorithm__coverage_interval` (at the bottom of the json) being `null` ? Is this something that you'd expect not to be `null` and could throw off the tool ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436101342:241,Deployability,release,release,241,Sorry about this. That's a bug in the qualimap parsing in bcbio that we've fixed (https://github.com/bcbio/bcbio-nextgen/commit/e15f787f984da3e5d727733f2a1d7c58c50c6be0) but hasn't yet been rolled into the Docker container. We're planning a release tomorrow so I can push a new Docker container as well which should fix the problem. So I don't think this is a Cromwell issue but a bug on the bcbio side and if other workflows are good I'd skip it for now. Thanks again for all this testing.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436101342
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436101342:482,Testability,test,testing,482,Sorry about this. That's a bug in the qualimap parsing in bcbio that we've fixed (https://github.com/bcbio/bcbio-nextgen/commit/e15f787f984da3e5d727733f2a1d7c58c50c6be0) but hasn't yet been rolled into the Docker container. We're planning a release tomorrow so I can push a new Docker container as well which should fix the problem. So I don't think this is a Cromwell issue but a bug on the bcbio side and if other workflows are good I'd skip it for now. Thanks again for all this testing.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436101342
https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436234476:27,Deployability,update,update,27,"No worries, thanks for the update, I'll skip this workflow for now then :)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436234476
https://github.com/broadinstitute/cromwell/pull/3725#issuecomment-394447827:202,Availability,down,down,202,"Ah, that sounds really nice, but I don't think it's possible: the `actual` is of type `Terminal`, which does not include type information (which makes sense, because once parsing the grammar has broken down you can't make any guarantees that a symbol you find will fit into a defined universe of types)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3725#issuecomment-394447827
https://github.com/broadinstitute/cromwell/pull/3725#issuecomment-394841642:26,Energy Efficiency,green,green,26,"Tests are in, waiting for green!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3725#issuecomment-394841642
https://github.com/broadinstitute/cromwell/pull/3725#issuecomment-394841642:0,Testability,Test,Tests,0,"Tests are in, waiting for green!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3725#issuecomment-394841642
https://github.com/broadinstitute/cromwell/pull/3729#issuecomment-394766552:23,Availability,error,errors,23,"there are still config errors in this space, might want to hold off starting reviews until those are sorted out",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3729#issuecomment-394766552
https://github.com/broadinstitute/cromwell/pull/3729#issuecomment-394766552:16,Modifiability,config,config,16,"there are still config errors in this space, might want to hold off starting reviews until those are sorted out",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3729#issuecomment-394766552
https://github.com/broadinstitute/cromwell/issues/3732#issuecomment-395066256:31,Availability,error,error,31,This looks like the preemption error codes are different in PAPI v2. I don't think we expected this,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3732#issuecomment-395066256
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395193978:62,Modifiability,config,config,62,"Hi Tom, if you could please share any redacted WDL, inputs or config that would be helpful. Thanks",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395193978
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395392027:266,Availability,Error,Error,266,"Latest on aws_backend branch. ________________________________; From: mcovarr <notifications@github.com>; Sent: Thursday, June 7, 2018 6:47:04 AM; To: broadinstitute/cromwell; Cc: Thomas Dyar (EXTERNAL); Author; Subject: Re: [broadinstitute/cromwell] Strange ""Boxed Error"", probably authorization / config (#3736). Also what version of Cromwell is this?. ‚Äî; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_broadinstitute_cromwell_issues_3736-23issuecomment-2D395377185&d=DwMCaQ&c=n7UHtw8cUfEZZQ61ciL2BA&r=Wpxr3yZIgJUDc4CsPhUpuiAtTKDn_lya4DWla3Q21iI&m=vxqjxBUg7eYY0Pzk0lUj-fru5Fu_Xj93aim9v5CyjEk&s=U0Ofhj4NWKhfebpsRfeTCvMxBZRUhJ44bevIpm6SR-E&e=>, or mute the thread<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_AIfLudmaJuhICx-5FxkNqusXZWh8pJ14zvks5t6QSogaJpZM4UdPeJ&d=DwMCaQ&c=n7UHtw8cUfEZZQ61ciL2BA&r=Wpxr3yZIgJUDc4CsPhUpuiAtTKDn_lya4DWla3Q21iI&m=vxqjxBUg7eYY0Pzk0lUj-fru5Fu_Xj93aim9v5CyjEk&s=qPDfKyTsVifxuNzZbVjE9HCwrHl6ANQrTo9wh-9YTJE&e=>.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395392027
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395392027:299,Modifiability,config,config,299,"Latest on aws_backend branch. ________________________________; From: mcovarr <notifications@github.com>; Sent: Thursday, June 7, 2018 6:47:04 AM; To: broadinstitute/cromwell; Cc: Thomas Dyar (EXTERNAL); Author; Subject: Re: [broadinstitute/cromwell] Strange ""Boxed Error"", probably authorization / config (#3736). Also what version of Cromwell is this?. ‚Äî; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_broadinstitute_cromwell_issues_3736-23issuecomment-2D395377185&d=DwMCaQ&c=n7UHtw8cUfEZZQ61ciL2BA&r=Wpxr3yZIgJUDc4CsPhUpuiAtTKDn_lya4DWla3Q21iI&m=vxqjxBUg7eYY0Pzk0lUj-fru5Fu_Xj93aim9v5CyjEk&s=U0Ofhj4NWKhfebpsRfeTCvMxBZRUhJ44bevIpm6SR-E&e=>, or mute the thread<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_AIfLudmaJuhICx-5FxkNqusXZWh8pJ14zvks5t6QSogaJpZM4UdPeJ&d=DwMCaQ&c=n7UHtw8cUfEZZQ61ciL2BA&r=Wpxr3yZIgJUDc4CsPhUpuiAtTKDn_lya4DWla3Q21iI&m=vxqjxBUg7eYY0Pzk0lUj-fru5Fu_Xj93aim9v5CyjEk&s=qPDfKyTsVifxuNzZbVjE9HCwrHl6ANQrTo9wh-9YTJE&e=>.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395392027
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395392027:283,Security,authoriz,authorization,283,"Latest on aws_backend branch. ________________________________; From: mcovarr <notifications@github.com>; Sent: Thursday, June 7, 2018 6:47:04 AM; To: broadinstitute/cromwell; Cc: Thomas Dyar (EXTERNAL); Author; Subject: Re: [broadinstitute/cromwell] Strange ""Boxed Error"", probably authorization / config (#3736). Also what version of Cromwell is this?. ‚Äî; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_broadinstitute_cromwell_issues_3736-23issuecomment-2D395377185&d=DwMCaQ&c=n7UHtw8cUfEZZQ61ciL2BA&r=Wpxr3yZIgJUDc4CsPhUpuiAtTKDn_lya4DWla3Q21iI&m=vxqjxBUg7eYY0Pzk0lUj-fru5Fu_Xj93aim9v5CyjEk&s=U0Ofhj4NWKhfebpsRfeTCvMxBZRUhJ44bevIpm6SR-E&e=>, or mute the thread<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_AIfLudmaJuhICx-5FxkNqusXZWh8pJ14zvks5t6QSogaJpZM4UdPeJ&d=DwMCaQ&c=n7UHtw8cUfEZZQ61ciL2BA&r=Wpxr3yZIgJUDc4CsPhUpuiAtTKDn_lya4DWla3Q21iI&m=vxqjxBUg7eYY0Pzk0lUj-fru5Fu_Xj93aim9v5CyjEk&s=qPDfKyTsVifxuNzZbVjE9HCwrHl6ANQrTo9wh-9YTJE&e=>.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395392027
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395472255:79,Availability,error,error,79,"Strangely, this non-input workflow and non-AWS configuration, lead to the same error, so seems to be something about my build, not likely the AWS Batch specific part:. [my-cromwell.conf.txt](https://github.com/broadinstitute/cromwell/files/2081156/my-cromwell.conf.txt); [myWorkflow.wdl.txt](https://github.com/broadinstitute/cromwell/files/2081161/myWorkflow.wdl.txt)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395472255
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395472255:47,Deployability,configurat,configuration,47,"Strangely, this non-input workflow and non-AWS configuration, lead to the same error, so seems to be something about my build, not likely the AWS Batch specific part:. [my-cromwell.conf.txt](https://github.com/broadinstitute/cromwell/files/2081156/my-cromwell.conf.txt); [myWorkflow.wdl.txt](https://github.com/broadinstitute/cromwell/files/2081161/myWorkflow.wdl.txt)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395472255
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395472255:47,Modifiability,config,configuration,47,"Strangely, this non-input workflow and non-AWS configuration, lead to the same error, so seems to be something about my build, not likely the AWS Batch specific part:. [my-cromwell.conf.txt](https://github.com/broadinstitute/cromwell/files/2081156/my-cromwell.conf.txt); [myWorkflow.wdl.txt](https://github.com/broadinstitute/cromwell/files/2081161/myWorkflow.wdl.txt)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395472255
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:5,Availability,error,error,5,"Same error, maybe you will see something in this full output from start of server:. ```; [info] SHA-1: dceb5f4f7fdf8646b3aa9ed1257ceb7f1b35f3c7; [info] Packaging /Users/tdyar/workspace/cromwell/server/target/scala-2.12/cromwell-33-7a41a75-SNAP.jar ...; [info] Done packaging.; [info] Done packaging.; [info] Done packaging.; [success] Total time: 189 s, completed Jun 7, 2018 12:13:55 PM; US-M094110:cromwell tdyar$ nano ~/workspace/cromwell-31/my-cromwell.conf; US-M094110:cromwell tdyar$ java -Dconfig.file=/Users/tdyar/workspace/cromwell-31/my-cromwell_test_develop.conf -jar /Users/tdyar/workspace/cromwell/server/target/scala-2.12/cromwell-33-7a41a75-SNAP.jar server; Picked up _JAVA_OPTIONS: -Dswing.systemlaf=com.sun.javax.swing.plaf.metal.CrossPlatformLookAndFeel; 2018-06-07 12:16:03,575 INFO - Running with database db.url = jdbc:hsqldb:mem:3922af96-263f-4846-9018-fb0a4968d4ab;shutdown=false;hsqldb.tx=mvcc; 2018-06-07 12:16:09,027 INFO - Successfully acquired change log lock; 2018-06-07 12:16:10,243 INFO - Creating database history table with name: PUBLIC.DATABASECHANGELOG; 2018-06-07 12:16:10,246 INFO - Reading from PUBLIC.DATABASECHANGELOG; 2018-06-07 12:16:10,417 INFO - changelog.xml: changesets/db_schema.xml::db_schema_other_table_alldb::scottfrazer: Table WORKFLOW_EXECUTION created; 2018-06-07 12:16:10,419 INFO - changelog.xml: changesets/db_schema.xml::db_schema_other_table_alldb::scottfrazer: Table EXECUTION created; 2018-06-07 12:16:10,420 INFO - changelog.xml: changesets/db_schema.xml::db_schema_other_table_alldb::scottfrazer: Table JES_JOB created; 2018-06-07 12:16:10,421 INFO - changelog.xml: changesets/db_schema.xml::db_schema_other_table_alldb::scottfrazer: Table LOCAL_JOB created; 2018-06-07 12:16:10,422 INFO - changelog.xml: changesets/db_schema.xml::db_schema_other_table_alldb::scottfrazer: ChangeSet changesets/db_schema.xml::db_schema_other_table_alldb::scottfrazer ran successfully in 6ms; 2018-06-07 12:16:10,431 INFO - changelog.xml: changesets/db_sch",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:43916,Availability,failure,failure,43916,".xml::call_job_identifiers::rmunshi: Column METADATA_JOURNAL.METADATA_CALL_INDEX renamed to JOB_SCATTER_INDEX; 2018-06-07 12:16:10,762 INFO - changelog.xml: changesets/standardize_column_names.xml::call_job_identifiers::rmunshi: Column METADATA_JOURNAL.METADATA_CALL_ATTEMPT renamed to JOB_RETRY_ATTEMPT; 2018-06-07 12:16:10,762 INFO - changelog.xml: changesets/standardize_column_names.xml::call_job_identifiers::rmunshi: ChangeSet changesets/standardize_column_names.xml::call_job_identifiers::rmunshi ran successfully in 1ms; 2018-06-07 12:16:10,778 INFO - changelog.xml: changesets/embiggen_metadata_value.xml::entry_or_journal_existence_xor::mcovarr: ChangeSet changesets/embiggen_metadata_value.xml::entry_or_journal_existence_xor::mcovarr ran successfully in 15ms; 2018-06-07 12:16:10,789 INFO - changelog.xml: changesets/embiggen_metadata_value.xml::embiggen_metadata_entry::mcovarr: Marking ChangeSet: changesets/embiggen_metadata_value.xml::embiggen_metadata_entry::mcovarr ran despite precondition failure due to onFail='MARK_RAN':; changelog.xml : Table PUBLIC.METADATA_ENTRY does not exist. 2018-06-07 12:16:10,792 INFO - changelog.xml: changesets/embiggen_metadata_value.xml::embiggen_metadata_journal::mcovarr: METADATA_JOURNAL.METADATA_VALUE datatype was changed to LONGTEXT; 2018-06-07 12:16:10,793 INFO - changelog.xml: changesets/embiggen_metadata_value.xml::embiggen_metadata_journal::mcovarr: ChangeSet changesets/embiggen_metadata_value.xml::embiggen_metadata_journal::mcovarr ran successfully in 3ms; 2018-06-07 12:16:10,795 INFO - changelog.xml: changesets/call_caching_job_detritus.xml::call_caching_job_detritus::rmunshi: Table CALL_CACHING_JOB_DETRITUS created; 2018-06-07 12:16:10,795 INFO - changelog.xml: changesets/call_caching_job_detritus.xml::call_caching_job_detritus::rmunshi: ChangeSet changesets/call_caching_job_detritus.xml::call_caching_job_detritus::rmunshi ran successfully in 1ms; 2018-06-07 12:16:10,797 INFO - changelog.xml: changesets/call_caching_job_d",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:96248,Availability,heartbeat,heartbeat,96248,"ete_duplicate_custom_labels.xml::delete_duplicate_custom_labels::kshakir: Unique constraint UC_CUSTOM_LABEL_ENTRY_CLK_CLV_WEU dropped from CUSTOM_LABEL_ENTRY; 2018-06-07 12:16:11,094 INFO - sql_metadata_changelog.xml: metadata_changesets/delete_duplicate_custom_labels.xml::delete_duplicate_custom_labels::kshakir: Unique constraint added to CUSTOM_LABEL_ENTRY(CUSTOM_LABEL_KEY, WORKFLOW_EXECUTION_UUID); 2018-06-07 12:16:11,094 INFO - sql_metadata_changelog.xml: metadata_changesets/delete_duplicate_custom_labels.xml::delete_duplicate_custom_labels::kshakir: ChangeSet metadata_changesets/delete_duplicate_custom_labels.xml::delete_duplicate_custom_labels::kshakir ran successfully in 2ms; 2018-06-07 12:16:11,095 INFO - Successfully released change log lock; 2018-06-07 12:16:11,332 INFO - Slf4jLogger started; 2018-06-07 12:16:11,499 cromwell-system-akka.dispatchers.engine-dispatcher-4 INFO - Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-6c9b8d4"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; 2018-06-07 12:16:11,540 cromwell-system-akka.dispatchers.service-dispatcher-10 INFO - Metadata summary refreshing every 2 seconds.; 2018-06-07 12:16:11,574 cromwell-system-akka.dispatchers.service-dispatcher-8 INFO - WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; 2018-06-07 12:16:11,575 cromwell-system-akka.actor.default-dispatcher-2 INFO - KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; 2018-06-07 12:16:11,575 cromwell-system-akka.dispatchers.engine-dispatcher-32 INFO - JobStoreWriterActor configured to flush with batch size 1000 and process rate 1 second.; 2018-06-07 12:16:11,576 cromwell-system-akka.dispatchers.engine-dispatcher-49 INFO - CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; 2018-06-07 12:16:12,232 cromwell-system-akka.dispatchers.engine-dispatcher-49 INFO - JobExecutionToken",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:96312,Availability,heartbeat,heartbeatInterval,96312,"ete_duplicate_custom_labels.xml::delete_duplicate_custom_labels::kshakir: Unique constraint UC_CUSTOM_LABEL_ENTRY_CLK_CLV_WEU dropped from CUSTOM_LABEL_ENTRY; 2018-06-07 12:16:11,094 INFO - sql_metadata_changelog.xml: metadata_changesets/delete_duplicate_custom_labels.xml::delete_duplicate_custom_labels::kshakir: Unique constraint added to CUSTOM_LABEL_ENTRY(CUSTOM_LABEL_KEY, WORKFLOW_EXECUTION_UUID); 2018-06-07 12:16:11,094 INFO - sql_metadata_changelog.xml: metadata_changesets/delete_duplicate_custom_labels.xml::delete_duplicate_custom_labels::kshakir: ChangeSet metadata_changesets/delete_duplicate_custom_labels.xml::delete_duplicate_custom_labels::kshakir ran successfully in 2ms; 2018-06-07 12:16:11,095 INFO - Successfully released change log lock; 2018-06-07 12:16:11,332 INFO - Slf4jLogger started; 2018-06-07 12:16:11,499 cromwell-system-akka.dispatchers.engine-dispatcher-4 INFO - Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-6c9b8d4"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; 2018-06-07 12:16:11,540 cromwell-system-akka.dispatchers.service-dispatcher-10 INFO - Metadata summary refreshing every 2 seconds.; 2018-06-07 12:16:11,574 cromwell-system-akka.dispatchers.service-dispatcher-8 INFO - WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; 2018-06-07 12:16:11,575 cromwell-system-akka.actor.default-dispatcher-2 INFO - KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; 2018-06-07 12:16:11,575 cromwell-system-akka.dispatchers.engine-dispatcher-32 INFO - JobStoreWriterActor configured to flush with batch size 1000 and process rate 1 second.; 2018-06-07 12:16:11,576 cromwell-system-akka.dispatchers.engine-dispatcher-49 INFO - CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; 2018-06-07 12:16:12,232 cromwell-system-akka.dispatchers.engine-dispatcher-49 INFO - JobExecutionToken",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:98715,Availability,ERROR,ERROR,98715,"w workflows fetched; 2018-06-07 12:16:52,349 cromwell-system-akka.dispatchers.engine-dispatcher-49 INFO - WorkflowManagerActor Starting workflow UUID(dd0b1399-ebb6-4d9b-89ea-7da193994220); 2018-06-07 12:16:52,353 cromwell-system-akka.dispatchers.engine-dispatcher-49 INFO - WorkflowManagerActor Successfully started WorkflowActor-dd0b1399-ebb6-4d9b-89ea-7da193994220; 2018-06-07 12:16:52,353 cromwell-system-akka.dispatchers.engine-dispatcher-49 INFO - Retrieved 1 workflows from the WorkflowStoreActor; 2018-06-07 12:16:52,362 cromwell-system-akka.dispatchers.engine-dispatcher-47 INFO - WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.; 2018-06-07 12:16:52,443 cromwell-system-akka.dispatchers.engine-dispatcher-47 INFO - MaterializeWorkflowDescriptorActor [UUID(dd0b1399)]: Parsing workflow as WDL draft-2; 2018-06-07 12:16:52,498 cromwell-system-akka.dispatchers.engine-dispatcher-47 ERROR - WorkflowManagerActor Workflow dd0b1399-ebb6-4d9b-89ea-7da193994220 failed (during MaterializingWorkflowDescriptorState): cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; Boxed Error; scala.concurrent.impl.Promise$.resolver(Promise.scala:83); scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:280); scala.concurrent.Promise.complete(Promise.scala:49); scala.concurrent.Promise.complete$(Promise.scala:48); scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:183); scala.concurrent.Promise.failure(Promise.scala:100); scala.concurrent.Promise.failure$(Promise.scala:100); scala.concurrent.impl.Promise$DefaultPromise.failure(Promise.scala:183); cats.effect.IO.$anonfun$unsafeToFuture$2(IO.scala:328); scala.util.Either.fold(Either.scala:189); cats.effect.IO.$anonfun$unsafeToFuture$1(IO.scala:328); cats.effect.IO.$anonfun$unsafeToFuture$1$ada",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:98980,Availability,Error,Error,98980,"ea-7da193994220); 2018-06-07 12:16:52,353 cromwell-system-akka.dispatchers.engine-dispatcher-49 INFO - WorkflowManagerActor Successfully started WorkflowActor-dd0b1399-ebb6-4d9b-89ea-7da193994220; 2018-06-07 12:16:52,353 cromwell-system-akka.dispatchers.engine-dispatcher-49 INFO - Retrieved 1 workflows from the WorkflowStoreActor; 2018-06-07 12:16:52,362 cromwell-system-akka.dispatchers.engine-dispatcher-47 INFO - WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.; 2018-06-07 12:16:52,443 cromwell-system-akka.dispatchers.engine-dispatcher-47 INFO - MaterializeWorkflowDescriptorActor [UUID(dd0b1399)]: Parsing workflow as WDL draft-2; 2018-06-07 12:16:52,498 cromwell-system-akka.dispatchers.engine-dispatcher-47 ERROR - WorkflowManagerActor Workflow dd0b1399-ebb6-4d9b-89ea-7da193994220 failed (during MaterializingWorkflowDescriptorState): cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; Boxed Error; scala.concurrent.impl.Promise$.resolver(Promise.scala:83); scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:280); scala.concurrent.Promise.complete(Promise.scala:49); scala.concurrent.Promise.complete$(Promise.scala:48); scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:183); scala.concurrent.Promise.failure(Promise.scala:100); scala.concurrent.Promise.failure$(Promise.scala:100); scala.concurrent.impl.Promise$DefaultPromise.failure(Promise.scala:183); cats.effect.IO.$anonfun$unsafeToFuture$2(IO.scala:328); scala.util.Either.fold(Either.scala:189); cats.effect.IO.$anonfun$unsafeToFuture$1(IO.scala:328); cats.effect.IO.$anonfun$unsafeToFuture$1$adapted(IO.scala:328); cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:98); cats.effect.internals.IORunLoop$.start(IORunLoop.scala:35)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:99421,Availability,failure,failure,99421,"e 10000 and process rate 2 minutes.; 2018-06-07 12:16:52,443 cromwell-system-akka.dispatchers.engine-dispatcher-47 INFO - MaterializeWorkflowDescriptorActor [UUID(dd0b1399)]: Parsing workflow as WDL draft-2; 2018-06-07 12:16:52,498 cromwell-system-akka.dispatchers.engine-dispatcher-47 ERROR - WorkflowManagerActor Workflow dd0b1399-ebb6-4d9b-89ea-7da193994220 failed (during MaterializingWorkflowDescriptorState): cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; Boxed Error; scala.concurrent.impl.Promise$.resolver(Promise.scala:83); scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:280); scala.concurrent.Promise.complete(Promise.scala:49); scala.concurrent.Promise.complete$(Promise.scala:48); scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:183); scala.concurrent.Promise.failure(Promise.scala:100); scala.concurrent.Promise.failure$(Promise.scala:100); scala.concurrent.impl.Promise$DefaultPromise.failure(Promise.scala:183); cats.effect.IO.$anonfun$unsafeToFuture$2(IO.scala:328); scala.util.Either.fold(Either.scala:189); cats.effect.IO.$anonfun$unsafeToFuture$1(IO.scala:328); cats.effect.IO.$anonfun$unsafeToFuture$1$adapted(IO.scala:328); cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:98); cats.effect.internals.IORunLoop$.start(IORunLoop.scala:35); cats.effect.IO.unsafeRunAsync(IO.scala:257); cats.effect.IO.unsafeToFuture(IO.scala:328); cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.$anonfun$applyOrElse$1(MaterializeWorkflowDescriptorActor.scala:146); scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:303); scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); akka.dispatch.BatchingExecut",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:99474,Availability,failure,failure,99474,":52,443 cromwell-system-akka.dispatchers.engine-dispatcher-47 INFO - MaterializeWorkflowDescriptorActor [UUID(dd0b1399)]: Parsing workflow as WDL draft-2; 2018-06-07 12:16:52,498 cromwell-system-akka.dispatchers.engine-dispatcher-47 ERROR - WorkflowManagerActor Workflow dd0b1399-ebb6-4d9b-89ea-7da193994220 failed (during MaterializingWorkflowDescriptorState): cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; Boxed Error; scala.concurrent.impl.Promise$.resolver(Promise.scala:83); scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:280); scala.concurrent.Promise.complete(Promise.scala:49); scala.concurrent.Promise.complete$(Promise.scala:48); scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:183); scala.concurrent.Promise.failure(Promise.scala:100); scala.concurrent.Promise.failure$(Promise.scala:100); scala.concurrent.impl.Promise$DefaultPromise.failure(Promise.scala:183); cats.effect.IO.$anonfun$unsafeToFuture$2(IO.scala:328); scala.util.Either.fold(Either.scala:189); cats.effect.IO.$anonfun$unsafeToFuture$1(IO.scala:328); cats.effect.IO.$anonfun$unsafeToFuture$1$adapted(IO.scala:328); cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:98); cats.effect.internals.IORunLoop$.start(IORunLoop.scala:35); cats.effect.IO.unsafeRunAsync(IO.scala:257); cats.effect.IO.unsafeToFuture(IO.scala:328); cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.$anonfun$applyOrElse$1(MaterializeWorkflowDescriptorActor.scala:146); scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:303); scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:5",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:99548,Availability,failure,failure,99548,"ializeWorkflowDescriptorActor [UUID(dd0b1399)]: Parsing workflow as WDL draft-2; 2018-06-07 12:16:52,498 cromwell-system-akka.dispatchers.engine-dispatcher-47 ERROR - WorkflowManagerActor Workflow dd0b1399-ebb6-4d9b-89ea-7da193994220 failed (during MaterializingWorkflowDescriptorState): cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; Boxed Error; scala.concurrent.impl.Promise$.resolver(Promise.scala:83); scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:280); scala.concurrent.Promise.complete(Promise.scala:49); scala.concurrent.Promise.complete$(Promise.scala:48); scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:183); scala.concurrent.Promise.failure(Promise.scala:100); scala.concurrent.Promise.failure$(Promise.scala:100); scala.concurrent.impl.Promise$DefaultPromise.failure(Promise.scala:183); cats.effect.IO.$anonfun$unsafeToFuture$2(IO.scala:328); scala.util.Either.fold(Either.scala:189); cats.effect.IO.$anonfun$unsafeToFuture$1(IO.scala:328); cats.effect.IO.$anonfun$unsafeToFuture$1$adapted(IO.scala:328); cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:98); cats.effect.internals.IORunLoop$.start(IORunLoop.scala:35); cats.effect.IO.unsafeRunAsync(IO.scala:257); cats.effect.IO.unsafeToFuture(IO.scala:328); cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.$anonfun$applyOrElse$1(MaterializeWorkflowDescriptorActor.scala:146); scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:303); scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(Batching",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:68611,Deployability,update,updated,68611,"s_again.xml::standardize_column_names_again::kshakir: Unique constraint added to WORKFLOW_STORE_ENTRY(WORKFLOW_EXECUTION_UUID); 2018-06-07 12:16:10,858 INFO - changelog.xml: changesets/standardize_column_names_again.xml::standardize_column_names_again::kshakir: Index IX_JOB_STORE_ENTRY_WEU created; 2018-06-07 12:16:10,858 INFO - changelog.xml: changesets/standardize_column_names_again.xml::standardize_column_names_again::kshakir: Index IX_WORKFLOW_METADATA_SUMMARY_ENTRY_WN created; 2018-06-07 12:16:10,859 INFO - changelog.xml: changesets/standardize_column_names_again.xml::standardize_column_names_again::kshakir: Index IX_WORKFLOW_METADATA_SUMMARY_ENTRY_WS created; 2018-06-07 12:16:10,859 INFO - changelog.xml: changesets/standardize_column_names_again.xml::standardize_column_names_again::kshakir: Index IX_WORKFLOW_STORE_ENTRY_WS created; 2018-06-07 12:16:10,859 INFO - changelog.xml: changesets/standardize_column_names_again.xml::standardize_column_names_again::kshakir: Data updated in SUMMARY_STATUS_ENTRY; 2018-06-07 12:16:10,859 INFO - changelog.xml: changesets/standardize_column_names_again.xml::standardize_column_names_again::kshakir: Data updated in SUMMARY_STATUS_ENTRY; 2018-06-07 12:16:10,860 INFO - changelog.xml: changesets/standardize_column_names_again.xml::standardize_column_names_again::kshakir: ChangeSet changesets/standardize_column_names_again.xml::standardize_column_names_again::kshakir ran successfully in 54ms; 2018-06-07 12:16:10,880 INFO - Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; 2018-06-07 12:16:10,896 INFO - [RenameWorkflowOptionsInMetadata] 100%; 2018-06-07 12:16:10,896 INFO - changelog.xml: changesets/rename_workflow_options_in_metadata.xml::rename_workflow_options_in_metadata::tjeandet: RenameWorkflowOptionsInMetadata complete.; 2018-06-07 12:16:10,896 INFO - changelog.xml: changesets/rename_workflow_options_in_metadata.xml::rename_workflow_options_in_metadata::tjeandet",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:68783,Deployability,update,updated,68783,": changesets/standardize_column_names_again.xml::standardize_column_names_again::kshakir: Index IX_JOB_STORE_ENTRY_WEU created; 2018-06-07 12:16:10,858 INFO - changelog.xml: changesets/standardize_column_names_again.xml::standardize_column_names_again::kshakir: Index IX_WORKFLOW_METADATA_SUMMARY_ENTRY_WN created; 2018-06-07 12:16:10,859 INFO - changelog.xml: changesets/standardize_column_names_again.xml::standardize_column_names_again::kshakir: Index IX_WORKFLOW_METADATA_SUMMARY_ENTRY_WS created; 2018-06-07 12:16:10,859 INFO - changelog.xml: changesets/standardize_column_names_again.xml::standardize_column_names_again::kshakir: Index IX_WORKFLOW_STORE_ENTRY_WS created; 2018-06-07 12:16:10,859 INFO - changelog.xml: changesets/standardize_column_names_again.xml::standardize_column_names_again::kshakir: Data updated in SUMMARY_STATUS_ENTRY; 2018-06-07 12:16:10,859 INFO - changelog.xml: changesets/standardize_column_names_again.xml::standardize_column_names_again::kshakir: Data updated in SUMMARY_STATUS_ENTRY; 2018-06-07 12:16:10,860 INFO - changelog.xml: changesets/standardize_column_names_again.xml::standardize_column_names_again::kshakir: ChangeSet changesets/standardize_column_names_again.xml::standardize_column_names_again::kshakir ran successfully in 54ms; 2018-06-07 12:16:10,880 INFO - Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; 2018-06-07 12:16:10,896 INFO - [RenameWorkflowOptionsInMetadata] 100%; 2018-06-07 12:16:10,896 INFO - changelog.xml: changesets/rename_workflow_options_in_metadata.xml::rename_workflow_options_in_metadata::tjeandet: RenameWorkflowOptionsInMetadata complete.; 2018-06-07 12:16:10,896 INFO - changelog.xml: changesets/rename_workflow_options_in_metadata.xml::rename_workflow_options_in_metadata::tjeandet: ChangeSet changesets/rename_workflow_options_in_metadata.xml::rename_workflow_options_in_metadata::tjeandet ran successfully in 17ms; 2018-06-07 12:16:10,898 INFO - chang",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:89002,Deployability,update,update-restartable,89002,"ow_store_state_widening.xml::workflow-store-state-widening::tjeandet: WORKFLOW_STORE_ENTRY.WORKFLOW_STATE datatype was changed to varchar(20); 2018-06-07 12:16:10,983 INFO - changelog.xml: changesets/workflow_store_state_widening.xml::workflow-store-state-widening::tjeandet: ChangeSet changesets/workflow_store_state_widening.xml::workflow-store-state-widening::tjeandet ran successfully in 0ms; 2018-06-07 12:16:10,985 INFO - changelog.xml: changesets/workflow_store_restarted_column.xml::workflow-store-restarted-column::tjeandet: Columns RESTARTED(BOOLEAN) added to WORKFLOW_STORE_ENTRY; 2018-06-07 12:16:10,985 INFO - changelog.xml: changesets/workflow_store_restarted_column.xml::workflow-store-restarted-column::tjeandet: ChangeSet changesets/workflow_store_restarted_column.xml::workflow-store-restarted-column::tjeandet ran successfully in 1ms; 2018-06-07 12:16:10,987 INFO - changelog.xml: changesets/workflow_store_restarted_column.xml::update-restartable::tjeandet: Data updated in WORKFLOW_STORE_ENTRY; 2018-06-07 12:16:10,987 INFO - changelog.xml: changesets/workflow_store_restarted_column.xml::update-restartable::tjeandet: Data updated in WORKFLOW_STORE_ENTRY; 2018-06-07 12:16:10,987 INFO - changelog.xml: changesets/workflow_store_restarted_column.xml::update-restartable::tjeandet: ChangeSet changesets/workflow_store_restarted_column.xml::update-restartable::tjeandet ran successfully in 1ms; 2018-06-07 12:16:10,989 INFO - changelog.xml: changesets/workflow_store_workflow_root_column.xml::workflow-store-workflow-root-column::tjeandet: Columns WORKFLOW_ROOT(VARCHAR(100)) added to WORKFLOW_STORE_ENTRY; 2018-06-07 12:16:10,989 INFO - changelog.xml: changesets/workflow_store_workflow_root_column.xml::workflow-store-workflow-root-column::tjeandet: ChangeSet changesets/workflow_store_workflow_root_column.xml::workflow-store-workflow-root-column::tjeandet ran successfully in 0ms; 2018-06-07 12:16:10,992 INFO - changelog.xml: changesets/workflow_store_horizontal_db.xml::workf",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:89037,Deployability,update,updated,89037,"ow_store_state_widening.xml::workflow-store-state-widening::tjeandet: WORKFLOW_STORE_ENTRY.WORKFLOW_STATE datatype was changed to varchar(20); 2018-06-07 12:16:10,983 INFO - changelog.xml: changesets/workflow_store_state_widening.xml::workflow-store-state-widening::tjeandet: ChangeSet changesets/workflow_store_state_widening.xml::workflow-store-state-widening::tjeandet ran successfully in 0ms; 2018-06-07 12:16:10,985 INFO - changelog.xml: changesets/workflow_store_restarted_column.xml::workflow-store-restarted-column::tjeandet: Columns RESTARTED(BOOLEAN) added to WORKFLOW_STORE_ENTRY; 2018-06-07 12:16:10,985 INFO - changelog.xml: changesets/workflow_store_restarted_column.xml::workflow-store-restarted-column::tjeandet: ChangeSet changesets/workflow_store_restarted_column.xml::workflow-store-restarted-column::tjeandet ran successfully in 1ms; 2018-06-07 12:16:10,987 INFO - changelog.xml: changesets/workflow_store_restarted_column.xml::update-restartable::tjeandet: Data updated in WORKFLOW_STORE_ENTRY; 2018-06-07 12:16:10,987 INFO - changelog.xml: changesets/workflow_store_restarted_column.xml::update-restartable::tjeandet: Data updated in WORKFLOW_STORE_ENTRY; 2018-06-07 12:16:10,987 INFO - changelog.xml: changesets/workflow_store_restarted_column.xml::update-restartable::tjeandet: ChangeSet changesets/workflow_store_restarted_column.xml::update-restartable::tjeandet ran successfully in 1ms; 2018-06-07 12:16:10,989 INFO - changelog.xml: changesets/workflow_store_workflow_root_column.xml::workflow-store-workflow-root-column::tjeandet: Columns WORKFLOW_ROOT(VARCHAR(100)) added to WORKFLOW_STORE_ENTRY; 2018-06-07 12:16:10,989 INFO - changelog.xml: changesets/workflow_store_workflow_root_column.xml::workflow-store-workflow-root-column::tjeandet: ChangeSet changesets/workflow_store_workflow_root_column.xml::workflow-store-workflow-root-column::tjeandet ran successfully in 0ms; 2018-06-07 12:16:10,992 INFO - changelog.xml: changesets/workflow_store_horizontal_db.xml::workf",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:89164,Deployability,update,update-restartable,89164,",983 INFO - changelog.xml: changesets/workflow_store_state_widening.xml::workflow-store-state-widening::tjeandet: ChangeSet changesets/workflow_store_state_widening.xml::workflow-store-state-widening::tjeandet ran successfully in 0ms; 2018-06-07 12:16:10,985 INFO - changelog.xml: changesets/workflow_store_restarted_column.xml::workflow-store-restarted-column::tjeandet: Columns RESTARTED(BOOLEAN) added to WORKFLOW_STORE_ENTRY; 2018-06-07 12:16:10,985 INFO - changelog.xml: changesets/workflow_store_restarted_column.xml::workflow-store-restarted-column::tjeandet: ChangeSet changesets/workflow_store_restarted_column.xml::workflow-store-restarted-column::tjeandet ran successfully in 1ms; 2018-06-07 12:16:10,987 INFO - changelog.xml: changesets/workflow_store_restarted_column.xml::update-restartable::tjeandet: Data updated in WORKFLOW_STORE_ENTRY; 2018-06-07 12:16:10,987 INFO - changelog.xml: changesets/workflow_store_restarted_column.xml::update-restartable::tjeandet: Data updated in WORKFLOW_STORE_ENTRY; 2018-06-07 12:16:10,987 INFO - changelog.xml: changesets/workflow_store_restarted_column.xml::update-restartable::tjeandet: ChangeSet changesets/workflow_store_restarted_column.xml::update-restartable::tjeandet ran successfully in 1ms; 2018-06-07 12:16:10,989 INFO - changelog.xml: changesets/workflow_store_workflow_root_column.xml::workflow-store-workflow-root-column::tjeandet: Columns WORKFLOW_ROOT(VARCHAR(100)) added to WORKFLOW_STORE_ENTRY; 2018-06-07 12:16:10,989 INFO - changelog.xml: changesets/workflow_store_workflow_root_column.xml::workflow-store-workflow-root-column::tjeandet: ChangeSet changesets/workflow_store_workflow_root_column.xml::workflow-store-workflow-root-column::tjeandet ran successfully in 0ms; 2018-06-07 12:16:10,992 INFO - changelog.xml: changesets/workflow_store_horizontal_db.xml::workflow-store-horizontal-db::mcovarr: Column WORKFLOW_STORE_ENTRY.RESTARTED dropped; 2018-06-07 12:16:10,992 INFO - changelog.xml: changesets/workflow_store_horizonta",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:89199,Deployability,update,updated,89199,",983 INFO - changelog.xml: changesets/workflow_store_state_widening.xml::workflow-store-state-widening::tjeandet: ChangeSet changesets/workflow_store_state_widening.xml::workflow-store-state-widening::tjeandet ran successfully in 0ms; 2018-06-07 12:16:10,985 INFO - changelog.xml: changesets/workflow_store_restarted_column.xml::workflow-store-restarted-column::tjeandet: Columns RESTARTED(BOOLEAN) added to WORKFLOW_STORE_ENTRY; 2018-06-07 12:16:10,985 INFO - changelog.xml: changesets/workflow_store_restarted_column.xml::workflow-store-restarted-column::tjeandet: ChangeSet changesets/workflow_store_restarted_column.xml::workflow-store-restarted-column::tjeandet ran successfully in 1ms; 2018-06-07 12:16:10,987 INFO - changelog.xml: changesets/workflow_store_restarted_column.xml::update-restartable::tjeandet: Data updated in WORKFLOW_STORE_ENTRY; 2018-06-07 12:16:10,987 INFO - changelog.xml: changesets/workflow_store_restarted_column.xml::update-restartable::tjeandet: Data updated in WORKFLOW_STORE_ENTRY; 2018-06-07 12:16:10,987 INFO - changelog.xml: changesets/workflow_store_restarted_column.xml::update-restartable::tjeandet: ChangeSet changesets/workflow_store_restarted_column.xml::update-restartable::tjeandet ran successfully in 1ms; 2018-06-07 12:16:10,989 INFO - changelog.xml: changesets/workflow_store_workflow_root_column.xml::workflow-store-workflow-root-column::tjeandet: Columns WORKFLOW_ROOT(VARCHAR(100)) added to WORKFLOW_STORE_ENTRY; 2018-06-07 12:16:10,989 INFO - changelog.xml: changesets/workflow_store_workflow_root_column.xml::workflow-store-workflow-root-column::tjeandet: ChangeSet changesets/workflow_store_workflow_root_column.xml::workflow-store-workflow-root-column::tjeandet ran successfully in 0ms; 2018-06-07 12:16:10,992 INFO - changelog.xml: changesets/workflow_store_horizontal_db.xml::workflow-store-horizontal-db::mcovarr: Column WORKFLOW_STORE_ENTRY.RESTARTED dropped; 2018-06-07 12:16:10,992 INFO - changelog.xml: changesets/workflow_store_horizonta",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:89326,Deployability,update,update-restartable,89326,"_state_widening.xml::workflow-store-state-widening::tjeandet ran successfully in 0ms; 2018-06-07 12:16:10,985 INFO - changelog.xml: changesets/workflow_store_restarted_column.xml::workflow-store-restarted-column::tjeandet: Columns RESTARTED(BOOLEAN) added to WORKFLOW_STORE_ENTRY; 2018-06-07 12:16:10,985 INFO - changelog.xml: changesets/workflow_store_restarted_column.xml::workflow-store-restarted-column::tjeandet: ChangeSet changesets/workflow_store_restarted_column.xml::workflow-store-restarted-column::tjeandet ran successfully in 1ms; 2018-06-07 12:16:10,987 INFO - changelog.xml: changesets/workflow_store_restarted_column.xml::update-restartable::tjeandet: Data updated in WORKFLOW_STORE_ENTRY; 2018-06-07 12:16:10,987 INFO - changelog.xml: changesets/workflow_store_restarted_column.xml::update-restartable::tjeandet: Data updated in WORKFLOW_STORE_ENTRY; 2018-06-07 12:16:10,987 INFO - changelog.xml: changesets/workflow_store_restarted_column.xml::update-restartable::tjeandet: ChangeSet changesets/workflow_store_restarted_column.xml::update-restartable::tjeandet ran successfully in 1ms; 2018-06-07 12:16:10,989 INFO - changelog.xml: changesets/workflow_store_workflow_root_column.xml::workflow-store-workflow-root-column::tjeandet: Columns WORKFLOW_ROOT(VARCHAR(100)) added to WORKFLOW_STORE_ENTRY; 2018-06-07 12:16:10,989 INFO - changelog.xml: changesets/workflow_store_workflow_root_column.xml::workflow-store-workflow-root-column::tjeandet: ChangeSet changesets/workflow_store_workflow_root_column.xml::workflow-store-workflow-root-column::tjeandet ran successfully in 0ms; 2018-06-07 12:16:10,992 INFO - changelog.xml: changesets/workflow_store_horizontal_db.xml::workflow-store-horizontal-db::mcovarr: Column WORKFLOW_STORE_ENTRY.RESTARTED dropped; 2018-06-07 12:16:10,992 INFO - changelog.xml: changesets/workflow_store_horizontal_db.xml::workflow-store-horizontal-db::mcovarr: Columns CROMWELL_ID(VARCHAR(100)) added to WORKFLOW_STORE_ENTRY; 2018-06-07 12:16:10,993 INFO - chan",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:89414,Deployability,update,update-restartable,89414,"07 12:16:10,985 INFO - changelog.xml: changesets/workflow_store_restarted_column.xml::workflow-store-restarted-column::tjeandet: Columns RESTARTED(BOOLEAN) added to WORKFLOW_STORE_ENTRY; 2018-06-07 12:16:10,985 INFO - changelog.xml: changesets/workflow_store_restarted_column.xml::workflow-store-restarted-column::tjeandet: ChangeSet changesets/workflow_store_restarted_column.xml::workflow-store-restarted-column::tjeandet ran successfully in 1ms; 2018-06-07 12:16:10,987 INFO - changelog.xml: changesets/workflow_store_restarted_column.xml::update-restartable::tjeandet: Data updated in WORKFLOW_STORE_ENTRY; 2018-06-07 12:16:10,987 INFO - changelog.xml: changesets/workflow_store_restarted_column.xml::update-restartable::tjeandet: Data updated in WORKFLOW_STORE_ENTRY; 2018-06-07 12:16:10,987 INFO - changelog.xml: changesets/workflow_store_restarted_column.xml::update-restartable::tjeandet: ChangeSet changesets/workflow_store_restarted_column.xml::update-restartable::tjeandet ran successfully in 1ms; 2018-06-07 12:16:10,989 INFO - changelog.xml: changesets/workflow_store_workflow_root_column.xml::workflow-store-workflow-root-column::tjeandet: Columns WORKFLOW_ROOT(VARCHAR(100)) added to WORKFLOW_STORE_ENTRY; 2018-06-07 12:16:10,989 INFO - changelog.xml: changesets/workflow_store_workflow_root_column.xml::workflow-store-workflow-root-column::tjeandet: ChangeSet changesets/workflow_store_workflow_root_column.xml::workflow-store-workflow-root-column::tjeandet ran successfully in 0ms; 2018-06-07 12:16:10,992 INFO - changelog.xml: changesets/workflow_store_horizontal_db.xml::workflow-store-horizontal-db::mcovarr: Column WORKFLOW_STORE_ENTRY.RESTARTED dropped; 2018-06-07 12:16:10,992 INFO - changelog.xml: changesets/workflow_store_horizontal_db.xml::workflow-store-horizontal-db::mcovarr: Columns CROMWELL_ID(VARCHAR(100)) added to WORKFLOW_STORE_ENTRY; 2018-06-07 12:16:10,993 INFO - changelog.xml: changesets/workflow_store_horizontal_db.xml::workflow-store-horizontal-db::mcovarr:",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:90822,Deployability,release,released,90822,"column::tjeandet: ChangeSet changesets/workflow_store_workflow_root_column.xml::workflow-store-workflow-root-column::tjeandet ran successfully in 0ms; 2018-06-07 12:16:10,992 INFO - changelog.xml: changesets/workflow_store_horizontal_db.xml::workflow-store-horizontal-db::mcovarr: Column WORKFLOW_STORE_ENTRY.RESTARTED dropped; 2018-06-07 12:16:10,992 INFO - changelog.xml: changesets/workflow_store_horizontal_db.xml::workflow-store-horizontal-db::mcovarr: Columns CROMWELL_ID(VARCHAR(100)) added to WORKFLOW_STORE_ENTRY; 2018-06-07 12:16:10,993 INFO - changelog.xml: changesets/workflow_store_horizontal_db.xml::workflow-store-horizontal-db::mcovarr: Columns HEARTBEAT_TIMESTAMP(TIMESTAMP) added to WORKFLOW_STORE_ENTRY; 2018-06-07 12:16:10,994 INFO - changelog.xml: changesets/workflow_store_horizontal_db.xml::workflow-store-horizontal-db::mcovarr: ChangeSet changesets/workflow_store_horizontal_db.xml::workflow-store-horizontal-db::mcovarr ran successfully in 3ms; 2018-06-07 12:16:10,997 INFO - Successfully released change log lock; 2018-06-07 12:16:11,007 INFO - Running with database db.url = jdbc:hsqldb:mem:78e2c868-f948-49e1-b7ba-840a9b54f3aa;shutdown=false;hsqldb.tx=mvcc; 2018-06-07 12:16:11,051 INFO - Successfully acquired change log lock; 2018-06-07 12:16:11,069 INFO - Creating database history table with name: PUBLIC.SQLMETADATADATABASECHANGELOG; 2018-06-07 12:16:11,071 INFO - Reading from PUBLIC.SQLMETADATADATABASECHANGELOG; 2018-06-07 12:16:11,080 INFO - sql_metadata_changelog.xml: metadata_changesets/move_sql_metadata_changelog.xml::move_metadata_changelog::kshakir: Table CUSTOM_LABEL_ENTRY created; 2018-06-07 12:16:11,081 INFO - sql_metadata_changelog.xml: metadata_changesets/move_sql_metadata_changelog.xml::move_metadata_changelog::kshakir: Table METADATA_ENTRY created; 2018-06-07 12:16:11,081 INFO - sql_metadata_changelog.xml: metadata_changesets/move_sql_metadata_changelog.xml::move_metadata_changelog::kshakir: Table SUMMARY_STATUS_ENTRY created; 2018-06-07 12",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:96077,Deployability,release,released,96077,":11,093 INFO - sql_metadata_changelog.xml: metadata_changesets/delete_duplicate_custom_labels.xml::delete_duplicate_custom_labels::kshakir: Data deleted from CUSTOM_LABEL_ENTRY; 2018-06-07 12:16:11,093 INFO - sql_metadata_changelog.xml: metadata_changesets/delete_duplicate_custom_labels.xml::delete_duplicate_custom_labels::kshakir: Unique constraint UC_CUSTOM_LABEL_ENTRY_CLK_CLV_WEU dropped from CUSTOM_LABEL_ENTRY; 2018-06-07 12:16:11,094 INFO - sql_metadata_changelog.xml: metadata_changesets/delete_duplicate_custom_labels.xml::delete_duplicate_custom_labels::kshakir: Unique constraint added to CUSTOM_LABEL_ENTRY(CUSTOM_LABEL_KEY, WORKFLOW_EXECUTION_UUID); 2018-06-07 12:16:11,094 INFO - sql_metadata_changelog.xml: metadata_changesets/delete_duplicate_custom_labels.xml::delete_duplicate_custom_labels::kshakir: ChangeSet metadata_changesets/delete_duplicate_custom_labels.xml::delete_duplicate_custom_labels::kshakir ran successfully in 2ms; 2018-06-07 12:16:11,095 INFO - Successfully released change log lock; 2018-06-07 12:16:11,332 INFO - Slf4jLogger started; 2018-06-07 12:16:11,499 cromwell-system-akka.dispatchers.engine-dispatcher-4 INFO - Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-6c9b8d4"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; 2018-06-07 12:16:11,540 cromwell-system-akka.dispatchers.service-dispatcher-10 INFO - Metadata summary refreshing every 2 seconds.; 2018-06-07 12:16:11,574 cromwell-system-akka.dispatchers.service-dispatcher-8 INFO - WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; 2018-06-07 12:16:11,575 cromwell-system-akka.actor.default-dispatcher-2 INFO - KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; 2018-06-07 12:16:11,575 cromwell-system-akka.dispatchers.engine-dispatcher-32 INFO - JobStoreWriterActor configured to flush with batch size 1000 and process rate 1 second.; 2018-06-07 12:16",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:96258,Deployability,configurat,configuration,96258,"ete_duplicate_custom_labels.xml::delete_duplicate_custom_labels::kshakir: Unique constraint UC_CUSTOM_LABEL_ENTRY_CLK_CLV_WEU dropped from CUSTOM_LABEL_ENTRY; 2018-06-07 12:16:11,094 INFO - sql_metadata_changelog.xml: metadata_changesets/delete_duplicate_custom_labels.xml::delete_duplicate_custom_labels::kshakir: Unique constraint added to CUSTOM_LABEL_ENTRY(CUSTOM_LABEL_KEY, WORKFLOW_EXECUTION_UUID); 2018-06-07 12:16:11,094 INFO - sql_metadata_changelog.xml: metadata_changesets/delete_duplicate_custom_labels.xml::delete_duplicate_custom_labels::kshakir: ChangeSet metadata_changesets/delete_duplicate_custom_labels.xml::delete_duplicate_custom_labels::kshakir ran successfully in 2ms; 2018-06-07 12:16:11,095 INFO - Successfully released change log lock; 2018-06-07 12:16:11,332 INFO - Slf4jLogger started; 2018-06-07 12:16:11,499 cromwell-system-akka.dispatchers.engine-dispatcher-4 INFO - Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-6c9b8d4"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; 2018-06-07 12:16:11,540 cromwell-system-akka.dispatchers.service-dispatcher-10 INFO - Metadata summary refreshing every 2 seconds.; 2018-06-07 12:16:11,574 cromwell-system-akka.dispatchers.service-dispatcher-8 INFO - WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; 2018-06-07 12:16:11,575 cromwell-system-akka.actor.default-dispatcher-2 INFO - KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; 2018-06-07 12:16:11,575 cromwell-system-akka.dispatchers.engine-dispatcher-32 INFO - JobStoreWriterActor configured to flush with batch size 1000 and process rate 1 second.; 2018-06-07 12:16:11,576 cromwell-system-akka.dispatchers.engine-dispatcher-49 INFO - CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; 2018-06-07 12:16:12,232 cromwell-system-akka.dispatchers.engine-dispatcher-49 INFO - JobExecutionToken",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:99771,Energy Efficiency,adapt,adapted,99771,bb6-4d9b-89ea-7da193994220 failed (during MaterializingWorkflowDescriptorState): cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; Boxed Error; scala.concurrent.impl.Promise$.resolver(Promise.scala:83); scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:280); scala.concurrent.Promise.complete(Promise.scala:49); scala.concurrent.Promise.complete$(Promise.scala:48); scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:183); scala.concurrent.Promise.failure(Promise.scala:100); scala.concurrent.Promise.failure$(Promise.scala:100); scala.concurrent.impl.Promise$DefaultPromise.failure(Promise.scala:183); cats.effect.IO.$anonfun$unsafeToFuture$2(IO.scala:328); scala.util.Either.fold(Either.scala:189); cats.effect.IO.$anonfun$unsafeToFuture$1(IO.scala:328); cats.effect.IO.$anonfun$unsafeToFuture$1$adapted(IO.scala:328); cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:98); cats.effect.internals.IORunLoop$.start(IORunLoop.scala:35); cats.effect.IO.unsafeRunAsync(IO.scala:257); cats.effect.IO.unsafeToFuture(IO.scala:328); cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.$anonfun$applyOrElse$1(MaterializeWorkflowDescriptorActor.scala:146); scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:303); scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); akka.dispatch.BatchingExecutor$BlockableBatc,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:96258,Modifiability,config,configuration,96258,"ete_duplicate_custom_labels.xml::delete_duplicate_custom_labels::kshakir: Unique constraint UC_CUSTOM_LABEL_ENTRY_CLK_CLV_WEU dropped from CUSTOM_LABEL_ENTRY; 2018-06-07 12:16:11,094 INFO - sql_metadata_changelog.xml: metadata_changesets/delete_duplicate_custom_labels.xml::delete_duplicate_custom_labels::kshakir: Unique constraint added to CUSTOM_LABEL_ENTRY(CUSTOM_LABEL_KEY, WORKFLOW_EXECUTION_UUID); 2018-06-07 12:16:11,094 INFO - sql_metadata_changelog.xml: metadata_changesets/delete_duplicate_custom_labels.xml::delete_duplicate_custom_labels::kshakir: ChangeSet metadata_changesets/delete_duplicate_custom_labels.xml::delete_duplicate_custom_labels::kshakir ran successfully in 2ms; 2018-06-07 12:16:11,095 INFO - Successfully released change log lock; 2018-06-07 12:16:11,332 INFO - Slf4jLogger started; 2018-06-07 12:16:11,499 cromwell-system-akka.dispatchers.engine-dispatcher-4 INFO - Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-6c9b8d4"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; 2018-06-07 12:16:11,540 cromwell-system-akka.dispatchers.service-dispatcher-10 INFO - Metadata summary refreshing every 2 seconds.; 2018-06-07 12:16:11,574 cromwell-system-akka.dispatchers.service-dispatcher-8 INFO - WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; 2018-06-07 12:16:11,575 cromwell-system-akka.actor.default-dispatcher-2 INFO - KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; 2018-06-07 12:16:11,575 cromwell-system-akka.dispatchers.engine-dispatcher-32 INFO - JobStoreWriterActor configured to flush with batch size 1000 and process rate 1 second.; 2018-06-07 12:16:11,576 cromwell-system-akka.dispatchers.engine-dispatcher-49 INFO - CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; 2018-06-07 12:16:12,232 cromwell-system-akka.dispatchers.engine-dispatcher-49 INFO - JobExecutionToken",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:96662,Modifiability,config,configured,96662,"t added to CUSTOM_LABEL_ENTRY(CUSTOM_LABEL_KEY, WORKFLOW_EXECUTION_UUID); 2018-06-07 12:16:11,094 INFO - sql_metadata_changelog.xml: metadata_changesets/delete_duplicate_custom_labels.xml::delete_duplicate_custom_labels::kshakir: ChangeSet metadata_changesets/delete_duplicate_custom_labels.xml::delete_duplicate_custom_labels::kshakir ran successfully in 2ms; 2018-06-07 12:16:11,095 INFO - Successfully released change log lock; 2018-06-07 12:16:11,332 INFO - Slf4jLogger started; 2018-06-07 12:16:11,499 cromwell-system-akka.dispatchers.engine-dispatcher-4 INFO - Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-6c9b8d4"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; 2018-06-07 12:16:11,540 cromwell-system-akka.dispatchers.service-dispatcher-10 INFO - Metadata summary refreshing every 2 seconds.; 2018-06-07 12:16:11,574 cromwell-system-akka.dispatchers.service-dispatcher-8 INFO - WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; 2018-06-07 12:16:11,575 cromwell-system-akka.actor.default-dispatcher-2 INFO - KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; 2018-06-07 12:16:11,575 cromwell-system-akka.dispatchers.engine-dispatcher-32 INFO - JobStoreWriterActor configured to flush with batch size 1000 and process rate 1 second.; 2018-06-07 12:16:11,576 cromwell-system-akka.dispatchers.engine-dispatcher-49 INFO - CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; 2018-06-07 12:16:12,232 cromwell-system-akka.dispatchers.engine-dispatcher-49 INFO - JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; 2018-06-07 12:16:12,406 cromwell-system-akka.dispatchers.engine-dispatcher-4 INFO - Cromwell service started...; 2018-06-07 12:16:40,751 cromwell-system-akka.dispatchers.api-dispatcher-116 INFO - Unspecified type (Unspecified version) workflow dd0b1399-ebb6-4d9b-89ea-7da193994220",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:96823,Modifiability,config,configured,96823,"icate_custom_labels.xml::delete_duplicate_custom_labels::kshakir: ChangeSet metadata_changesets/delete_duplicate_custom_labels.xml::delete_duplicate_custom_labels::kshakir ran successfully in 2ms; 2018-06-07 12:16:11,095 INFO - Successfully released change log lock; 2018-06-07 12:16:11,332 INFO - Slf4jLogger started; 2018-06-07 12:16:11,499 cromwell-system-akka.dispatchers.engine-dispatcher-4 INFO - Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-6c9b8d4"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; 2018-06-07 12:16:11,540 cromwell-system-akka.dispatchers.service-dispatcher-10 INFO - Metadata summary refreshing every 2 seconds.; 2018-06-07 12:16:11,574 cromwell-system-akka.dispatchers.service-dispatcher-8 INFO - WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; 2018-06-07 12:16:11,575 cromwell-system-akka.actor.default-dispatcher-2 INFO - KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; 2018-06-07 12:16:11,575 cromwell-system-akka.dispatchers.engine-dispatcher-32 INFO - JobStoreWriterActor configured to flush with batch size 1000 and process rate 1 second.; 2018-06-07 12:16:11,576 cromwell-system-akka.dispatchers.engine-dispatcher-49 INFO - CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; 2018-06-07 12:16:12,232 cromwell-system-akka.dispatchers.engine-dispatcher-49 INFO - JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; 2018-06-07 12:16:12,406 cromwell-system-akka.dispatchers.engine-dispatcher-4 INFO - Cromwell service started...; 2018-06-07 12:16:40,751 cromwell-system-akka.dispatchers.api-dispatcher-116 INFO - Unspecified type (Unspecified version) workflow dd0b1399-ebb6-4d9b-89ea-7da193994220 submitted; 2018-06-07 12:16:52,348 cromwell-system-akka.dispatchers.engine-dispatcher-49 INFO - 1 new workflows fetched; 2018-06-07 12:16:52,349 cromwell-system-ak",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:96997,Modifiability,config,configured,96997,"r ran successfully in 2ms; 2018-06-07 12:16:11,095 INFO - Successfully released change log lock; 2018-06-07 12:16:11,332 INFO - Slf4jLogger started; 2018-06-07 12:16:11,499 cromwell-system-akka.dispatchers.engine-dispatcher-4 INFO - Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-6c9b8d4"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; 2018-06-07 12:16:11,540 cromwell-system-akka.dispatchers.service-dispatcher-10 INFO - Metadata summary refreshing every 2 seconds.; 2018-06-07 12:16:11,574 cromwell-system-akka.dispatchers.service-dispatcher-8 INFO - WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; 2018-06-07 12:16:11,575 cromwell-system-akka.actor.default-dispatcher-2 INFO - KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; 2018-06-07 12:16:11,575 cromwell-system-akka.dispatchers.engine-dispatcher-32 INFO - JobStoreWriterActor configured to flush with batch size 1000 and process rate 1 second.; 2018-06-07 12:16:11,576 cromwell-system-akka.dispatchers.engine-dispatcher-49 INFO - CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; 2018-06-07 12:16:12,232 cromwell-system-akka.dispatchers.engine-dispatcher-49 INFO - JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; 2018-06-07 12:16:12,406 cromwell-system-akka.dispatchers.engine-dispatcher-4 INFO - Cromwell service started...; 2018-06-07 12:16:40,751 cromwell-system-akka.dispatchers.api-dispatcher-116 INFO - Unspecified type (Unspecified version) workflow dd0b1399-ebb6-4d9b-89ea-7da193994220 submitted; 2018-06-07 12:16:52,348 cromwell-system-akka.dispatchers.engine-dispatcher-49 INFO - 1 new workflows fetched; 2018-06-07 12:16:52,349 cromwell-system-akka.dispatchers.engine-dispatcher-49 INFO - WorkflowManagerActor Starting workflow UUID(dd0b1399-ebb6-4d9b-89ea-7da193994220); 2018-06-07 12:16:52,353 cromwell-system-akka.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:97171,Modifiability,config,configured,97171,"romwell-system-akka.dispatchers.engine-dispatcher-4 INFO - Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-6c9b8d4"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; 2018-06-07 12:16:11,540 cromwell-system-akka.dispatchers.service-dispatcher-10 INFO - Metadata summary refreshing every 2 seconds.; 2018-06-07 12:16:11,574 cromwell-system-akka.dispatchers.service-dispatcher-8 INFO - WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; 2018-06-07 12:16:11,575 cromwell-system-akka.actor.default-dispatcher-2 INFO - KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; 2018-06-07 12:16:11,575 cromwell-system-akka.dispatchers.engine-dispatcher-32 INFO - JobStoreWriterActor configured to flush with batch size 1000 and process rate 1 second.; 2018-06-07 12:16:11,576 cromwell-system-akka.dispatchers.engine-dispatcher-49 INFO - CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; 2018-06-07 12:16:12,232 cromwell-system-akka.dispatchers.engine-dispatcher-49 INFO - JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; 2018-06-07 12:16:12,406 cromwell-system-akka.dispatchers.engine-dispatcher-4 INFO - Cromwell service started...; 2018-06-07 12:16:40,751 cromwell-system-akka.dispatchers.api-dispatcher-116 INFO - Unspecified type (Unspecified version) workflow dd0b1399-ebb6-4d9b-89ea-7da193994220 submitted; 2018-06-07 12:16:52,348 cromwell-system-akka.dispatchers.engine-dispatcher-49 INFO - 1 new workflows fetched; 2018-06-07 12:16:52,349 cromwell-system-akka.dispatchers.engine-dispatcher-49 INFO - WorkflowManagerActor Starting workflow UUID(dd0b1399-ebb6-4d9b-89ea-7da193994220); 2018-06-07 12:16:52,353 cromwell-system-akka.dispatchers.engine-dispatcher-49 INFO - WorkflowManagerActor Successfully started WorkflowActor-dd0b1399-ebb6-4d9b-89ea-7da193994220; 2018-06-07 12:16:52,353 cromwell-system-",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:98395,Modifiability,config,configured,98395,"-07 12:16:12,406 cromwell-system-akka.dispatchers.engine-dispatcher-4 INFO - Cromwell service started...; 2018-06-07 12:16:40,751 cromwell-system-akka.dispatchers.api-dispatcher-116 INFO - Unspecified type (Unspecified version) workflow dd0b1399-ebb6-4d9b-89ea-7da193994220 submitted; 2018-06-07 12:16:52,348 cromwell-system-akka.dispatchers.engine-dispatcher-49 INFO - 1 new workflows fetched; 2018-06-07 12:16:52,349 cromwell-system-akka.dispatchers.engine-dispatcher-49 INFO - WorkflowManagerActor Starting workflow UUID(dd0b1399-ebb6-4d9b-89ea-7da193994220); 2018-06-07 12:16:52,353 cromwell-system-akka.dispatchers.engine-dispatcher-49 INFO - WorkflowManagerActor Successfully started WorkflowActor-dd0b1399-ebb6-4d9b-89ea-7da193994220; 2018-06-07 12:16:52,353 cromwell-system-akka.dispatchers.engine-dispatcher-49 INFO - Retrieved 1 workflows from the WorkflowStoreActor; 2018-06-07 12:16:52,362 cromwell-system-akka.dispatchers.engine-dispatcher-47 INFO - WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.; 2018-06-07 12:16:52,443 cromwell-system-akka.dispatchers.engine-dispatcher-47 INFO - MaterializeWorkflowDescriptorActor [UUID(dd0b1399)]: Parsing workflow as WDL draft-2; 2018-06-07 12:16:52,498 cromwell-system-akka.dispatchers.engine-dispatcher-47 ERROR - WorkflowManagerActor Workflow dd0b1399-ebb6-4d9b-89ea-7da193994220 failed (during MaterializingWorkflowDescriptorState): cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; Boxed Error; scala.concurrent.impl.Promise$.resolver(Promise.scala:83); scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:280); scala.concurrent.Promise.complete(Promise.scala:49); scala.concurrent.Promise.complete$(Promise.scala:48); scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:183); sca",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:99771,Modifiability,adapt,adapted,99771,bb6-4d9b-89ea-7da193994220 failed (during MaterializingWorkflowDescriptorState): cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; Boxed Error; scala.concurrent.impl.Promise$.resolver(Promise.scala:83); scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:280); scala.concurrent.Promise.complete(Promise.scala:49); scala.concurrent.Promise.complete$(Promise.scala:48); scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:183); scala.concurrent.Promise.failure(Promise.scala:100); scala.concurrent.Promise.failure$(Promise.scala:100); scala.concurrent.impl.Promise$DefaultPromise.failure(Promise.scala:183); cats.effect.IO.$anonfun$unsafeToFuture$2(IO.scala:328); scala.util.Either.fold(Either.scala:189); cats.effect.IO.$anonfun$unsafeToFuture$1(IO.scala:328); cats.effect.IO.$anonfun$unsafeToFuture$1$adapted(IO.scala:328); cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:98); cats.effect.internals.IORunLoop$.start(IORunLoop.scala:35); cats.effect.IO.unsafeRunAsync(IO.scala:257); cats.effect.IO.unsafeToFuture(IO.scala:328); cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.$anonfun$applyOrElse$1(MaterializeWorkflowDescriptorActor.scala:146); scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:303); scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); akka.dispatch.BatchingExecutor$BlockableBatc,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:98993,Performance,concurren,concurrent,98993,"tem-akka.dispatchers.engine-dispatcher-49 INFO - WorkflowManagerActor Successfully started WorkflowActor-dd0b1399-ebb6-4d9b-89ea-7da193994220; 2018-06-07 12:16:52,353 cromwell-system-akka.dispatchers.engine-dispatcher-49 INFO - Retrieved 1 workflows from the WorkflowStoreActor; 2018-06-07 12:16:52,362 cromwell-system-akka.dispatchers.engine-dispatcher-47 INFO - WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.; 2018-06-07 12:16:52,443 cromwell-system-akka.dispatchers.engine-dispatcher-47 INFO - MaterializeWorkflowDescriptorActor [UUID(dd0b1399)]: Parsing workflow as WDL draft-2; 2018-06-07 12:16:52,498 cromwell-system-akka.dispatchers.engine-dispatcher-47 ERROR - WorkflowManagerActor Workflow dd0b1399-ebb6-4d9b-89ea-7da193994220 failed (during MaterializingWorkflowDescriptorState): cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; Boxed Error; scala.concurrent.impl.Promise$.resolver(Promise.scala:83); scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:280); scala.concurrent.Promise.complete(Promise.scala:49); scala.concurrent.Promise.complete$(Promise.scala:48); scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:183); scala.concurrent.Promise.failure(Promise.scala:100); scala.concurrent.Promise.failure$(Promise.scala:100); scala.concurrent.impl.Promise$DefaultPromise.failure(Promise.scala:183); cats.effect.IO.$anonfun$unsafeToFuture$2(IO.scala:328); scala.util.Either.fold(Either.scala:189); cats.effect.IO.$anonfun$unsafeToFuture$1(IO.scala:328); cats.effect.IO.$anonfun$unsafeToFuture$1$adapted(IO.scala:328); cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:98); cats.effect.internals.IORunLoop$.start(IORunLoop.scala:35); cats.effect.IO.unsafeRunAsync(IO.scala:257); cats.eff",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:99052,Performance,concurren,concurrent,99052,"nagerActor Successfully started WorkflowActor-dd0b1399-ebb6-4d9b-89ea-7da193994220; 2018-06-07 12:16:52,353 cromwell-system-akka.dispatchers.engine-dispatcher-49 INFO - Retrieved 1 workflows from the WorkflowStoreActor; 2018-06-07 12:16:52,362 cromwell-system-akka.dispatchers.engine-dispatcher-47 INFO - WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.; 2018-06-07 12:16:52,443 cromwell-system-akka.dispatchers.engine-dispatcher-47 INFO - MaterializeWorkflowDescriptorActor [UUID(dd0b1399)]: Parsing workflow as WDL draft-2; 2018-06-07 12:16:52,498 cromwell-system-akka.dispatchers.engine-dispatcher-47 ERROR - WorkflowManagerActor Workflow dd0b1399-ebb6-4d9b-89ea-7da193994220 failed (during MaterializingWorkflowDescriptorState): cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; Boxed Error; scala.concurrent.impl.Promise$.resolver(Promise.scala:83); scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:280); scala.concurrent.Promise.complete(Promise.scala:49); scala.concurrent.Promise.complete$(Promise.scala:48); scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:183); scala.concurrent.Promise.failure(Promise.scala:100); scala.concurrent.Promise.failure$(Promise.scala:100); scala.concurrent.impl.Promise$DefaultPromise.failure(Promise.scala:183); cats.effect.IO.$anonfun$unsafeToFuture$2(IO.scala:328); scala.util.Either.fold(Either.scala:189); cats.effect.IO.$anonfun$unsafeToFuture$1(IO.scala:328); cats.effect.IO.$anonfun$unsafeToFuture$1$adapted(IO.scala:328); cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:98); cats.effect.internals.IORunLoop$.start(IORunLoop.scala:35); cats.effect.IO.unsafeRunAsync(IO.scala:257); cats.effect.IO.unsafeToFuture(IO.scala:328); cromwell.engine.workfl",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:99083,Performance,concurren,concurrent,99083,"-dd0b1399-ebb6-4d9b-89ea-7da193994220; 2018-06-07 12:16:52,353 cromwell-system-akka.dispatchers.engine-dispatcher-49 INFO - Retrieved 1 workflows from the WorkflowStoreActor; 2018-06-07 12:16:52,362 cromwell-system-akka.dispatchers.engine-dispatcher-47 INFO - WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.; 2018-06-07 12:16:52,443 cromwell-system-akka.dispatchers.engine-dispatcher-47 INFO - MaterializeWorkflowDescriptorActor [UUID(dd0b1399)]: Parsing workflow as WDL draft-2; 2018-06-07 12:16:52,498 cromwell-system-akka.dispatchers.engine-dispatcher-47 ERROR - WorkflowManagerActor Workflow dd0b1399-ebb6-4d9b-89ea-7da193994220 failed (during MaterializingWorkflowDescriptorState): cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; Boxed Error; scala.concurrent.impl.Promise$.resolver(Promise.scala:83); scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:280); scala.concurrent.Promise.complete(Promise.scala:49); scala.concurrent.Promise.complete$(Promise.scala:48); scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:183); scala.concurrent.Promise.failure(Promise.scala:100); scala.concurrent.Promise.failure$(Promise.scala:100); scala.concurrent.impl.Promise$DefaultPromise.failure(Promise.scala:183); cats.effect.IO.$anonfun$unsafeToFuture$2(IO.scala:328); scala.util.Either.fold(Either.scala:189); cats.effect.IO.$anonfun$unsafeToFuture$1(IO.scala:328); cats.effect.IO.$anonfun$unsafeToFuture$1$adapted(IO.scala:328); cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:98); cats.effect.internals.IORunLoop$.start(IORunLoop.scala:35); cats.effect.IO.unsafeRunAsync(IO.scala:257); cats.effect.IO.unsafeToFuture(IO.scala:328); cromwell.engine.workflow.lifecycle.materialization.MaterializeWork",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:99144,Performance,concurren,concurrent,99144,"07 12:16:52,353 cromwell-system-akka.dispatchers.engine-dispatcher-49 INFO - Retrieved 1 workflows from the WorkflowStoreActor; 2018-06-07 12:16:52,362 cromwell-system-akka.dispatchers.engine-dispatcher-47 INFO - WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.; 2018-06-07 12:16:52,443 cromwell-system-akka.dispatchers.engine-dispatcher-47 INFO - MaterializeWorkflowDescriptorActor [UUID(dd0b1399)]: Parsing workflow as WDL draft-2; 2018-06-07 12:16:52,498 cromwell-system-akka.dispatchers.engine-dispatcher-47 ERROR - WorkflowManagerActor Workflow dd0b1399-ebb6-4d9b-89ea-7da193994220 failed (during MaterializingWorkflowDescriptorState): cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; Boxed Error; scala.concurrent.impl.Promise$.resolver(Promise.scala:83); scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:280); scala.concurrent.Promise.complete(Promise.scala:49); scala.concurrent.Promise.complete$(Promise.scala:48); scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:183); scala.concurrent.Promise.failure(Promise.scala:100); scala.concurrent.Promise.failure$(Promise.scala:100); scala.concurrent.impl.Promise$DefaultPromise.failure(Promise.scala:183); cats.effect.IO.$anonfun$unsafeToFuture$2(IO.scala:328); scala.util.Either.fold(Either.scala:189); cats.effect.IO.$anonfun$unsafeToFuture$1(IO.scala:328); cats.effect.IO.$anonfun$unsafeToFuture$1$adapted(IO.scala:328); cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:98); cats.effect.internals.IORunLoop$.start(IORunLoop.scala:35); cats.effect.IO.unsafeRunAsync(IO.scala:257); cats.effect.IO.unsafeToFuture(IO.scala:328); cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.$anonfun$applyOrE",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:99221,Performance,concurren,concurrent,99221,"Retrieved 1 workflows from the WorkflowStoreActor; 2018-06-07 12:16:52,362 cromwell-system-akka.dispatchers.engine-dispatcher-47 INFO - WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.; 2018-06-07 12:16:52,443 cromwell-system-akka.dispatchers.engine-dispatcher-47 INFO - MaterializeWorkflowDescriptorActor [UUID(dd0b1399)]: Parsing workflow as WDL draft-2; 2018-06-07 12:16:52,498 cromwell-system-akka.dispatchers.engine-dispatcher-47 ERROR - WorkflowManagerActor Workflow dd0b1399-ebb6-4d9b-89ea-7da193994220 failed (during MaterializingWorkflowDescriptorState): cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; Boxed Error; scala.concurrent.impl.Promise$.resolver(Promise.scala:83); scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:280); scala.concurrent.Promise.complete(Promise.scala:49); scala.concurrent.Promise.complete$(Promise.scala:48); scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:183); scala.concurrent.Promise.failure(Promise.scala:100); scala.concurrent.Promise.failure$(Promise.scala:100); scala.concurrent.impl.Promise$DefaultPromise.failure(Promise.scala:183); cats.effect.IO.$anonfun$unsafeToFuture$2(IO.scala:328); scala.util.Either.fold(Either.scala:189); cats.effect.IO.$anonfun$unsafeToFuture$1(IO.scala:328); cats.effect.IO.$anonfun$unsafeToFuture$1$adapted(IO.scala:328); cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:98); cats.effect.internals.IORunLoop$.start(IORunLoop.scala:35); cats.effect.IO.unsafeRunAsync(IO.scala:257); cats.effect.IO.unsafeToFuture(IO.scala:328); cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.$anonfun$applyOrElse$1(MaterializeWorkflowDescriptorActor.scala:146); scala.concurrent.Future.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:99274,Performance,concurren,concurrent,99274,"18-06-07 12:16:52,362 cromwell-system-akka.dispatchers.engine-dispatcher-47 INFO - WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.; 2018-06-07 12:16:52,443 cromwell-system-akka.dispatchers.engine-dispatcher-47 INFO - MaterializeWorkflowDescriptorActor [UUID(dd0b1399)]: Parsing workflow as WDL draft-2; 2018-06-07 12:16:52,498 cromwell-system-akka.dispatchers.engine-dispatcher-47 ERROR - WorkflowManagerActor Workflow dd0b1399-ebb6-4d9b-89ea-7da193994220 failed (during MaterializingWorkflowDescriptorState): cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; Boxed Error; scala.concurrent.impl.Promise$.resolver(Promise.scala:83); scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:280); scala.concurrent.Promise.complete(Promise.scala:49); scala.concurrent.Promise.complete$(Promise.scala:48); scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:183); scala.concurrent.Promise.failure(Promise.scala:100); scala.concurrent.Promise.failure$(Promise.scala:100); scala.concurrent.impl.Promise$DefaultPromise.failure(Promise.scala:183); cats.effect.IO.$anonfun$unsafeToFuture$2(IO.scala:328); scala.util.Either.fold(Either.scala:189); cats.effect.IO.$anonfun$unsafeToFuture$1(IO.scala:328); cats.effect.IO.$anonfun$unsafeToFuture$1$adapted(IO.scala:328); cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:98); cats.effect.internals.IORunLoop$.start(IORunLoop.scala:35); cats.effect.IO.unsafeRunAsync(IO.scala:257); cats.effect.IO.unsafeToFuture(IO.scala:328); cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.$anonfun$applyOrElse$1(MaterializeWorkflowDescriptorActor.scala:146); scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:303); scala.concurren",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:99328,Performance,concurren,concurrent,99328,".engine-dispatcher-47 INFO - WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.; 2018-06-07 12:16:52,443 cromwell-system-akka.dispatchers.engine-dispatcher-47 INFO - MaterializeWorkflowDescriptorActor [UUID(dd0b1399)]: Parsing workflow as WDL draft-2; 2018-06-07 12:16:52,498 cromwell-system-akka.dispatchers.engine-dispatcher-47 ERROR - WorkflowManagerActor Workflow dd0b1399-ebb6-4d9b-89ea-7da193994220 failed (during MaterializingWorkflowDescriptorState): cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; Boxed Error; scala.concurrent.impl.Promise$.resolver(Promise.scala:83); scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:280); scala.concurrent.Promise.complete(Promise.scala:49); scala.concurrent.Promise.complete$(Promise.scala:48); scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:183); scala.concurrent.Promise.failure(Promise.scala:100); scala.concurrent.Promise.failure$(Promise.scala:100); scala.concurrent.impl.Promise$DefaultPromise.failure(Promise.scala:183); cats.effect.IO.$anonfun$unsafeToFuture$2(IO.scala:328); scala.util.Either.fold(Either.scala:189); cats.effect.IO.$anonfun$unsafeToFuture$1(IO.scala:328); cats.effect.IO.$anonfun$unsafeToFuture$1$adapted(IO.scala:328); cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:98); cats.effect.internals.IORunLoop$.start(IORunLoop.scala:35); cats.effect.IO.unsafeRunAsync(IO.scala:257); cats.effect.IO.unsafeToFuture(IO.scala:328); cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.$anonfun$applyOrElse$1(MaterializeWorkflowDescriptorActor.scala:146); scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:303); scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:99402,Performance,concurren,concurrent,99402,"o flush with batch size 10000 and process rate 2 minutes.; 2018-06-07 12:16:52,443 cromwell-system-akka.dispatchers.engine-dispatcher-47 INFO - MaterializeWorkflowDescriptorActor [UUID(dd0b1399)]: Parsing workflow as WDL draft-2; 2018-06-07 12:16:52,498 cromwell-system-akka.dispatchers.engine-dispatcher-47 ERROR - WorkflowManagerActor Workflow dd0b1399-ebb6-4d9b-89ea-7da193994220 failed (during MaterializingWorkflowDescriptorState): cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; Boxed Error; scala.concurrent.impl.Promise$.resolver(Promise.scala:83); scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:280); scala.concurrent.Promise.complete(Promise.scala:49); scala.concurrent.Promise.complete$(Promise.scala:48); scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:183); scala.concurrent.Promise.failure(Promise.scala:100); scala.concurrent.Promise.failure$(Promise.scala:100); scala.concurrent.impl.Promise$DefaultPromise.failure(Promise.scala:183); cats.effect.IO.$anonfun$unsafeToFuture$2(IO.scala:328); scala.util.Either.fold(Either.scala:189); cats.effect.IO.$anonfun$unsafeToFuture$1(IO.scala:328); cats.effect.IO.$anonfun$unsafeToFuture$1$adapted(IO.scala:328); cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:98); cats.effect.internals.IORunLoop$.start(IORunLoop.scala:35); cats.effect.IO.unsafeRunAsync(IO.scala:257); cats.effect.IO.unsafeToFuture(IO.scala:328); cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.$anonfun$applyOrElse$1(MaterializeWorkflowDescriptorActor.scala:146); scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:303); scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); akka.di",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:99455,Performance,concurren,concurrent,99455,"tes.; 2018-06-07 12:16:52,443 cromwell-system-akka.dispatchers.engine-dispatcher-47 INFO - MaterializeWorkflowDescriptorActor [UUID(dd0b1399)]: Parsing workflow as WDL draft-2; 2018-06-07 12:16:52,498 cromwell-system-akka.dispatchers.engine-dispatcher-47 ERROR - WorkflowManagerActor Workflow dd0b1399-ebb6-4d9b-89ea-7da193994220 failed (during MaterializingWorkflowDescriptorState): cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; Boxed Error; scala.concurrent.impl.Promise$.resolver(Promise.scala:83); scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:280); scala.concurrent.Promise.complete(Promise.scala:49); scala.concurrent.Promise.complete$(Promise.scala:48); scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:183); scala.concurrent.Promise.failure(Promise.scala:100); scala.concurrent.Promise.failure$(Promise.scala:100); scala.concurrent.impl.Promise$DefaultPromise.failure(Promise.scala:183); cats.effect.IO.$anonfun$unsafeToFuture$2(IO.scala:328); scala.util.Either.fold(Either.scala:189); cats.effect.IO.$anonfun$unsafeToFuture$1(IO.scala:328); cats.effect.IO.$anonfun$unsafeToFuture$1$adapted(IO.scala:328); cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:98); cats.effect.internals.IORunLoop$.start(IORunLoop.scala:35); cats.effect.IO.unsafeRunAsync(IO.scala:257); cats.effect.IO.unsafeToFuture(IO.scala:328); cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.$anonfun$applyOrElse$1(MaterializeWorkflowDescriptorActor.scala:146); scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:303); scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(Ba",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:99509,Performance,concurren,concurrent,99509,"patchers.engine-dispatcher-47 INFO - MaterializeWorkflowDescriptorActor [UUID(dd0b1399)]: Parsing workflow as WDL draft-2; 2018-06-07 12:16:52,498 cromwell-system-akka.dispatchers.engine-dispatcher-47 ERROR - WorkflowManagerActor Workflow dd0b1399-ebb6-4d9b-89ea-7da193994220 failed (during MaterializingWorkflowDescriptorState): cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; Boxed Error; scala.concurrent.impl.Promise$.resolver(Promise.scala:83); scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:280); scala.concurrent.Promise.complete(Promise.scala:49); scala.concurrent.Promise.complete$(Promise.scala:48); scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:183); scala.concurrent.Promise.failure(Promise.scala:100); scala.concurrent.Promise.failure$(Promise.scala:100); scala.concurrent.impl.Promise$DefaultPromise.failure(Promise.scala:183); cats.effect.IO.$anonfun$unsafeToFuture$2(IO.scala:328); scala.util.Either.fold(Either.scala:189); cats.effect.IO.$anonfun$unsafeToFuture$1(IO.scala:328); cats.effect.IO.$anonfun$unsafeToFuture$1$adapted(IO.scala:328); cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:98); cats.effect.internals.IORunLoop$.start(IORunLoop.scala:35); cats.effect.IO.unsafeRunAsync(IO.scala:257); cats.effect.IO.unsafeToFuture(IO.scala:328); cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.$anonfun$applyOrElse$1(MaterializeWorkflowDescriptorActor.scala:146); scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:303); scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); akka.dispatch.BatchingExecut",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:100209,Performance,concurren,concurrent,100209, scala.concurrent.Promise.complete(Promise.scala:49); scala.concurrent.Promise.complete$(Promise.scala:48); scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:183); scala.concurrent.Promise.failure(Promise.scala:100); scala.concurrent.Promise.failure$(Promise.scala:100); scala.concurrent.impl.Promise$DefaultPromise.failure(Promise.scala:183); cats.effect.IO.$anonfun$unsafeToFuture$2(IO.scala:328); scala.util.Either.fold(Either.scala:189); cats.effect.IO.$anonfun$unsafeToFuture$1(IO.scala:328); cats.effect.IO.$anonfun$unsafeToFuture$1$adapted(IO.scala:328); cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:98); cats.effect.internals.IORunLoop$.start(IORunLoop.scala:35); cats.effect.IO.unsafeRunAsync(IO.scala:257); cats.effect.IO.unsafeToFuture(IO.scala:328); cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.$anonfun$applyOrElse$1(MaterializeWorkflowDescriptorActor.scala:146); scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:303); scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91); akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:43); akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); akka.dispatch.forkjoin.ForkJoinW,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:100271,Performance,concurren,concurrent,100271,ncurrent.Promise.complete$(Promise.scala:48); scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:183); scala.concurrent.Promise.failure(Promise.scala:100); scala.concurrent.Promise.failure$(Promise.scala:100); scala.concurrent.impl.Promise$DefaultPromise.failure(Promise.scala:183); cats.effect.IO.$anonfun$unsafeToFuture$2(IO.scala:328); scala.util.Either.fold(Either.scala:189); cats.effect.IO.$anonfun$unsafeToFuture$1(IO.scala:328); cats.effect.IO.$anonfun$unsafeToFuture$1$adapted(IO.scala:328); cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:98); cats.effect.internals.IORunLoop$.start(IORunLoop.scala:35); cats.effect.IO.unsafeRunAsync(IO.scala:257); cats.effect.IO.unsafeToFuture(IO.scala:328); cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.$anonfun$applyOrElse$1(MaterializeWorkflowDescriptorActor.scala:146); scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:303); scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91); akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:43); akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); 	at cromwell.e,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:100345,Performance,concurren,concurrent,100345,e$DefaultPromise.complete(Promise.scala:183); scala.concurrent.Promise.failure(Promise.scala:100); scala.concurrent.Promise.failure$(Promise.scala:100); scala.concurrent.impl.Promise$DefaultPromise.failure(Promise.scala:183); cats.effect.IO.$anonfun$unsafeToFuture$2(IO.scala:328); scala.util.Either.fold(Either.scala:189); cats.effect.IO.$anonfun$unsafeToFuture$1(IO.scala:328); cats.effect.IO.$anonfun$unsafeToFuture$1$adapted(IO.scala:328); cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:98); cats.effect.internals.IORunLoop$.start(IORunLoop.scala:35); cats.effect.IO.unsafeRunAsync(IO.scala:257); cats.effect.IO.unsafeToFuture(IO.scala:328); cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.$anonfun$applyOrElse$1(MaterializeWorkflowDescriptorActor.scala:146); scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:303); scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91); akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:43); akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActo,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:100654,Performance,concurren,concurrent,100654,er.scala:189); cats.effect.IO.$anonfun$unsafeToFuture$1(IO.scala:328); cats.effect.IO.$anonfun$unsafeToFuture$1$adapted(IO.scala:328); cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:98); cats.effect.internals.IORunLoop$.start(IORunLoop.scala:35); cats.effect.IO.unsafeRunAsync(IO.scala:257); cats.effect.IO.unsafeToFuture(IO.scala:328); cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.$anonfun$applyOrElse$1(MaterializeWorkflowDescriptorActor.scala:146); scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:303); scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91); akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:43); akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$workflowInitializationFailed(MaterializeWorkflowDescriptorActor.scala:200); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorAc,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:99600,Safety,unsafe,unsafeToFuture,99600,"arsing workflow as WDL draft-2; 2018-06-07 12:16:52,498 cromwell-system-akka.dispatchers.engine-dispatcher-47 ERROR - WorkflowManagerActor Workflow dd0b1399-ebb6-4d9b-89ea-7da193994220 failed (during MaterializingWorkflowDescriptorState): cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; Boxed Error; scala.concurrent.impl.Promise$.resolver(Promise.scala:83); scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:280); scala.concurrent.Promise.complete(Promise.scala:49); scala.concurrent.Promise.complete$(Promise.scala:48); scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:183); scala.concurrent.Promise.failure(Promise.scala:100); scala.concurrent.Promise.failure$(Promise.scala:100); scala.concurrent.impl.Promise$DefaultPromise.failure(Promise.scala:183); cats.effect.IO.$anonfun$unsafeToFuture$2(IO.scala:328); scala.util.Either.fold(Either.scala:189); cats.effect.IO.$anonfun$unsafeToFuture$1(IO.scala:328); cats.effect.IO.$anonfun$unsafeToFuture$1$adapted(IO.scala:328); cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:98); cats.effect.internals.IORunLoop$.start(IORunLoop.scala:35); cats.effect.IO.unsafeRunAsync(IO.scala:257); cats.effect.IO.unsafeToFuture(IO.scala:328); cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.$anonfun$applyOrElse$1(MaterializeWorkflowDescriptorActor.scala:146); scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:303); scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); scala.runtime.java8.JFunction0",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:99698,Safety,unsafe,unsafeToFuture,99698,spatcher-47 ERROR - WorkflowManagerActor Workflow dd0b1399-ebb6-4d9b-89ea-7da193994220 failed (during MaterializingWorkflowDescriptorState): cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; Boxed Error; scala.concurrent.impl.Promise$.resolver(Promise.scala:83); scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:280); scala.concurrent.Promise.complete(Promise.scala:49); scala.concurrent.Promise.complete$(Promise.scala:48); scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:183); scala.concurrent.Promise.failure(Promise.scala:100); scala.concurrent.Promise.failure$(Promise.scala:100); scala.concurrent.impl.Promise$DefaultPromise.failure(Promise.scala:183); cats.effect.IO.$anonfun$unsafeToFuture$2(IO.scala:328); scala.util.Either.fold(Either.scala:189); cats.effect.IO.$anonfun$unsafeToFuture$1(IO.scala:328); cats.effect.IO.$anonfun$unsafeToFuture$1$adapted(IO.scala:328); cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:98); cats.effect.internals.IORunLoop$.start(IORunLoop.scala:35); cats.effect.IO.unsafeRunAsync(IO.scala:257); cats.effect.IO.unsafeToFuture(IO.scala:328); cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.$anonfun$applyOrElse$1(MaterializeWorkflowDescriptorActor.scala:146); scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:303); scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); scala.concurrent.BlockContext$.withBlockContext(BlockCon,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:99754,Safety,unsafe,unsafeToFuture,99754,bb6-4d9b-89ea-7da193994220 failed (during MaterializingWorkflowDescriptorState): cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; Boxed Error; scala.concurrent.impl.Promise$.resolver(Promise.scala:83); scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:280); scala.concurrent.Promise.complete(Promise.scala:49); scala.concurrent.Promise.complete$(Promise.scala:48); scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:183); scala.concurrent.Promise.failure(Promise.scala:100); scala.concurrent.Promise.failure$(Promise.scala:100); scala.concurrent.impl.Promise$DefaultPromise.failure(Promise.scala:183); cats.effect.IO.$anonfun$unsafeToFuture$2(IO.scala:328); scala.util.Either.fold(Either.scala:189); cats.effect.IO.$anonfun$unsafeToFuture$1(IO.scala:328); cats.effect.IO.$anonfun$unsafeToFuture$1$adapted(IO.scala:328); cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:98); cats.effect.internals.IORunLoop$.start(IORunLoop.scala:35); cats.effect.IO.unsafeRunAsync(IO.scala:257); cats.effect.IO.unsafeToFuture(IO.scala:328); cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.$anonfun$applyOrElse$1(MaterializeWorkflowDescriptorActor.scala:146); scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:303); scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); akka.dispatch.BatchingExecutor$BlockableBatc,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:99961,Safety,unsafe,unsafeRunAsync,99961,d:; Boxed Error; scala.concurrent.impl.Promise$.resolver(Promise.scala:83); scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:280); scala.concurrent.Promise.complete(Promise.scala:49); scala.concurrent.Promise.complete$(Promise.scala:48); scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:183); scala.concurrent.Promise.failure(Promise.scala:100); scala.concurrent.Promise.failure$(Promise.scala:100); scala.concurrent.impl.Promise$DefaultPromise.failure(Promise.scala:183); cats.effect.IO.$anonfun$unsafeToFuture$2(IO.scala:328); scala.util.Either.fold(Either.scala:189); cats.effect.IO.$anonfun$unsafeToFuture$1(IO.scala:328); cats.effect.IO.$anonfun$unsafeToFuture$1$adapted(IO.scala:328); cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:98); cats.effect.internals.IORunLoop$.start(IORunLoop.scala:35); cats.effect.IO.unsafeRunAsync(IO.scala:257); cats.effect.IO.unsafeToFuture(IO.scala:328); cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.$anonfun$applyOrElse$1(MaterializeWorkflowDescriptorActor.scala:146); scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:303); scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91); akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:43); akka,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:100006,Safety,unsafe,unsafeToFuture,100006,e$.resolver(Promise.scala:83); scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:280); scala.concurrent.Promise.complete(Promise.scala:49); scala.concurrent.Promise.complete$(Promise.scala:48); scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:183); scala.concurrent.Promise.failure(Promise.scala:100); scala.concurrent.Promise.failure$(Promise.scala:100); scala.concurrent.impl.Promise$DefaultPromise.failure(Promise.scala:183); cats.effect.IO.$anonfun$unsafeToFuture$2(IO.scala:328); scala.util.Either.fold(Either.scala:189); cats.effect.IO.$anonfun$unsafeToFuture$1(IO.scala:328); cats.effect.IO.$anonfun$unsafeToFuture$1$adapted(IO.scala:328); cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:98); cats.effect.internals.IORunLoop$.start(IORunLoop.scala:35); cats.effect.IO.unsafeRunAsync(IO.scala:257); cats.effect.IO.unsafeToFuture(IO.scala:328); cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.$anonfun$applyOrElse$1(MaterializeWorkflowDescriptorActor.scala:146); scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:303); scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91); akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:43); akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJo,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:15516,Security,HASH,HASH,15516,"018-06-07 12:16:10,556 INFO - changelog.xml: changesets/workflow_execution_aux_not_null.xml::workflow_execution_aux_not_null::tjeandet: Null constraint has been added to WORKFLOW_EXECUTION_AUX.WORKFLOW_OPTIONS; 2018-06-07 12:16:10,556 INFO - changelog.xml: changesets/workflow_execution_aux_not_null.xml::workflow_execution_aux_not_null::tjeandet: ChangeSet changesets/workflow_execution_aux_not_null.xml::workflow_execution_aux_not_null::tjeandet ran successfully in 2ms; 2018-06-07 12:16:10,561 INFO - changelog.xml: changesets/call_result_caching.xml::call_result_caching::chrisl: Columns ALLOWS_RESULT_REUSE(BOOLEAN),DOCKER_IMAGE_HASH(VARCHAR(100)),RESULTS_CLONED_FROM(INT),EXECUTION_HASH(VARCHAR(100)) added to EXECUTION; 2018-06-07 12:16:10,562 INFO - changelog.xml: changesets/call_result_caching.xml::call_result_caching::chrisl: Index HASH_INDEX created; 2018-06-07 12:16:10,563 INFO - changelog.xml: changesets/call_result_caching.xml::call_result_caching::chrisl: Columns HASH(VARCHAR(100)) added to SYMBOL; 2018-06-07 12:16:10,564 INFO - changelog.xml: changesets/call_result_caching.xml::call_result_caching::chrisl: Foreign key constraint added to EXECUTION (RESULTS_CLONED_FROM); 2018-06-07 12:16:10,564 INFO - changelog.xml: changesets/call_result_caching.xml::call_result_caching::chrisl: ChangeSet changesets/call_result_caching.xml::call_result_caching::chrisl ran successfully in 5ms; 2018-06-07 12:16:10,569 INFO - changelog.xml: changesets/events_table.xml::execution_event_table::chrisl: Table EXECUTION_EVENT created; 2018-06-07 12:16:10,570 INFO - changelog.xml: changesets/events_table.xml::execution_event_table::chrisl: Foreign key constraint added to EXECUTION_EVENT (EXECUTION_ID); 2018-06-07 12:16:10,571 INFO - changelog.xml: changesets/events_table.xml::execution_event_table::chrisl: Unique constraint added to EXECUTION_EVENT(EXECUTION_ID, DESCRIPTION); 2018-06-07 12:16:10,571 INFO - changelog.xml: changesets/events_table.xml::execution_event_table::chrisl: Change",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:69912,Security,Encrypt,EncryptWorkflowStoreEntryWorkflowOptions,69912,"l::standardize_column_names_again::kshakir: ChangeSet changesets/standardize_column_names_again.xml::standardize_column_names_again::kshakir ran successfully in 54ms; 2018-06-07 12:16:10,880 INFO - Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; 2018-06-07 12:16:10,896 INFO - [RenameWorkflowOptionsInMetadata] 100%; 2018-06-07 12:16:10,896 INFO - changelog.xml: changesets/rename_workflow_options_in_metadata.xml::rename_workflow_options_in_metadata::tjeandet: RenameWorkflowOptionsInMetadata complete.; 2018-06-07 12:16:10,896 INFO - changelog.xml: changesets/rename_workflow_options_in_metadata.xml::rename_workflow_options_in_metadata::tjeandet: ChangeSet changesets/rename_workflow_options_in_metadata.xml::rename_workflow_options_in_metadata::tjeandet ran successfully in 17ms; 2018-06-07 12:16:10,898 INFO - changelog.xml: changesets/encrypt_and_clear_workflow_options.xml::encrypt_workflow_store_entry_workflow_options::kshakir: EncryptWorkflowStoreEntryWorkflowOptions complete.; 2018-06-07 12:16:10,899 INFO - changelog.xml: changesets/encrypt_and_clear_workflow_options.xml::encrypt_workflow_store_entry_workflow_options::kshakir: ChangeSet changesets/encrypt_and_clear_workflow_options.xml::encrypt_workflow_store_entry_workflow_options::kshakir ran successfully in 1ms; 2018-06-07 12:16:10,900 INFO - changelog.xml: changesets/encrypt_and_clear_workflow_options.xml::clear_metadata_entry_workflow_options::kshakir: ClearMetadataEntryWorkflowOptions complete.; 2018-06-07 12:16:10,900 INFO - changelog.xml: changesets/encrypt_and_clear_workflow_options.xml::clear_metadata_entry_workflow_options::kshakir: ChangeSet changesets/encrypt_and_clear_workflow_options.xml::clear_metadata_entry_workflow_options::kshakir ran successfully in 0ms; 2018-06-07 12:16:10,902 INFO - changelog.xml: changesets/sub_workflow_store.xml::SUB_WORKFLOW_STORE_ENTRY::tjeandet: Table SUB_WORKFLOW_STORE_ENTRY created; 2018-06-07 12:16:10,902 ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:979,Testability,log,log,979,"Same error, maybe you will see something in this full output from start of server:. ```; [info] SHA-1: dceb5f4f7fdf8646b3aa9ed1257ceb7f1b35f3c7; [info] Packaging /Users/tdyar/workspace/cromwell/server/target/scala-2.12/cromwell-33-7a41a75-SNAP.jar ...; [info] Done packaging.; [info] Done packaging.; [info] Done packaging.; [success] Total time: 189 s, completed Jun 7, 2018 12:13:55 PM; US-M094110:cromwell tdyar$ nano ~/workspace/cromwell-31/my-cromwell.conf; US-M094110:cromwell tdyar$ java -Dconfig.file=/Users/tdyar/workspace/cromwell-31/my-cromwell_test_develop.conf -jar /Users/tdyar/workspace/cromwell/server/target/scala-2.12/cromwell-33-7a41a75-SNAP.jar server; Picked up _JAVA_OPTIONS: -Dswing.systemlaf=com.sun.javax.swing.plaf.metal.CrossPlatformLookAndFeel; 2018-06-07 12:16:03,575 INFO - Running with database db.url = jdbc:hsqldb:mem:3922af96-263f-4846-9018-fb0a4968d4ab;shutdown=false;hsqldb.tx=mvcc; 2018-06-07 12:16:09,027 INFO - Successfully acquired change log lock; 2018-06-07 12:16:10,243 INFO - Creating database history table with name: PUBLIC.DATABASECHANGELOG; 2018-06-07 12:16:10,246 INFO - Reading from PUBLIC.DATABASECHANGELOG; 2018-06-07 12:16:10,417 INFO - changelog.xml: changesets/db_schema.xml::db_schema_other_table_alldb::scottfrazer: Table WORKFLOW_EXECUTION created; 2018-06-07 12:16:10,419 INFO - changelog.xml: changesets/db_schema.xml::db_schema_other_table_alldb::scottfrazer: Table EXECUTION created; 2018-06-07 12:16:10,420 INFO - changelog.xml: changesets/db_schema.xml::db_schema_other_table_alldb::scottfrazer: Table JES_JOB created; 2018-06-07 12:16:10,421 INFO - changelog.xml: changesets/db_schema.xml::db_schema_other_table_alldb::scottfrazer: Table LOCAL_JOB created; 2018-06-07 12:16:10,422 INFO - changelog.xml: changesets/db_schema.xml::db_schema_other_table_alldb::scottfrazer: ChangeSet changesets/db_schema.xml::db_schema_other_table_alldb::scottfrazer ran successfully in 6ms; 2018-06-07 12:16:10,431 INFO - changelog.xml: changesets/db_sch",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:90838,Testability,log,log,90838,"column::tjeandet: ChangeSet changesets/workflow_store_workflow_root_column.xml::workflow-store-workflow-root-column::tjeandet ran successfully in 0ms; 2018-06-07 12:16:10,992 INFO - changelog.xml: changesets/workflow_store_horizontal_db.xml::workflow-store-horizontal-db::mcovarr: Column WORKFLOW_STORE_ENTRY.RESTARTED dropped; 2018-06-07 12:16:10,992 INFO - changelog.xml: changesets/workflow_store_horizontal_db.xml::workflow-store-horizontal-db::mcovarr: Columns CROMWELL_ID(VARCHAR(100)) added to WORKFLOW_STORE_ENTRY; 2018-06-07 12:16:10,993 INFO - changelog.xml: changesets/workflow_store_horizontal_db.xml::workflow-store-horizontal-db::mcovarr: Columns HEARTBEAT_TIMESTAMP(TIMESTAMP) added to WORKFLOW_STORE_ENTRY; 2018-06-07 12:16:10,994 INFO - changelog.xml: changesets/workflow_store_horizontal_db.xml::workflow-store-horizontal-db::mcovarr: ChangeSet changesets/workflow_store_horizontal_db.xml::workflow-store-horizontal-db::mcovarr ran successfully in 3ms; 2018-06-07 12:16:10,997 INFO - Successfully released change log lock; 2018-06-07 12:16:11,007 INFO - Running with database db.url = jdbc:hsqldb:mem:78e2c868-f948-49e1-b7ba-840a9b54f3aa;shutdown=false;hsqldb.tx=mvcc; 2018-06-07 12:16:11,051 INFO - Successfully acquired change log lock; 2018-06-07 12:16:11,069 INFO - Creating database history table with name: PUBLIC.SQLMETADATADATABASECHANGELOG; 2018-06-07 12:16:11,071 INFO - Reading from PUBLIC.SQLMETADATADATABASECHANGELOG; 2018-06-07 12:16:11,080 INFO - sql_metadata_changelog.xml: metadata_changesets/move_sql_metadata_changelog.xml::move_metadata_changelog::kshakir: Table CUSTOM_LABEL_ENTRY created; 2018-06-07 12:16:11,081 INFO - sql_metadata_changelog.xml: metadata_changesets/move_sql_metadata_changelog.xml::move_metadata_changelog::kshakir: Table METADATA_ENTRY created; 2018-06-07 12:16:11,081 INFO - sql_metadata_changelog.xml: metadata_changesets/move_sql_metadata_changelog.xml::move_metadata_changelog::kshakir: Table SUMMARY_STATUS_ENTRY created; 2018-06-07 12",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:91054,Testability,log,log,91054,"orizontal-db::mcovarr: Column WORKFLOW_STORE_ENTRY.RESTARTED dropped; 2018-06-07 12:16:10,992 INFO - changelog.xml: changesets/workflow_store_horizontal_db.xml::workflow-store-horizontal-db::mcovarr: Columns CROMWELL_ID(VARCHAR(100)) added to WORKFLOW_STORE_ENTRY; 2018-06-07 12:16:10,993 INFO - changelog.xml: changesets/workflow_store_horizontal_db.xml::workflow-store-horizontal-db::mcovarr: Columns HEARTBEAT_TIMESTAMP(TIMESTAMP) added to WORKFLOW_STORE_ENTRY; 2018-06-07 12:16:10,994 INFO - changelog.xml: changesets/workflow_store_horizontal_db.xml::workflow-store-horizontal-db::mcovarr: ChangeSet changesets/workflow_store_horizontal_db.xml::workflow-store-horizontal-db::mcovarr ran successfully in 3ms; 2018-06-07 12:16:10,997 INFO - Successfully released change log lock; 2018-06-07 12:16:11,007 INFO - Running with database db.url = jdbc:hsqldb:mem:78e2c868-f948-49e1-b7ba-840a9b54f3aa;shutdown=false;hsqldb.tx=mvcc; 2018-06-07 12:16:11,051 INFO - Successfully acquired change log lock; 2018-06-07 12:16:11,069 INFO - Creating database history table with name: PUBLIC.SQLMETADATADATABASECHANGELOG; 2018-06-07 12:16:11,071 INFO - Reading from PUBLIC.SQLMETADATADATABASECHANGELOG; 2018-06-07 12:16:11,080 INFO - sql_metadata_changelog.xml: metadata_changesets/move_sql_metadata_changelog.xml::move_metadata_changelog::kshakir: Table CUSTOM_LABEL_ENTRY created; 2018-06-07 12:16:11,081 INFO - sql_metadata_changelog.xml: metadata_changesets/move_sql_metadata_changelog.xml::move_metadata_changelog::kshakir: Table METADATA_ENTRY created; 2018-06-07 12:16:11,081 INFO - sql_metadata_changelog.xml: metadata_changesets/move_sql_metadata_changelog.xml::move_metadata_changelog::kshakir: Table SUMMARY_STATUS_ENTRY created; 2018-06-07 12:16:11,082 INFO - sql_metadata_changelog.xml: metadata_changesets/move_sql_metadata_changelog.xml::move_metadata_changelog::kshakir: Table WORKFLOW_METADATA_SUMMARY_ENTRY created; 2018-06-07 12:16:11,082 INFO - sql_metadata_changelog.xml: metadata_changesets",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:96093,Testability,log,log,96093,":11,093 INFO - sql_metadata_changelog.xml: metadata_changesets/delete_duplicate_custom_labels.xml::delete_duplicate_custom_labels::kshakir: Data deleted from CUSTOM_LABEL_ENTRY; 2018-06-07 12:16:11,093 INFO - sql_metadata_changelog.xml: metadata_changesets/delete_duplicate_custom_labels.xml::delete_duplicate_custom_labels::kshakir: Unique constraint UC_CUSTOM_LABEL_ENTRY_CLK_CLV_WEU dropped from CUSTOM_LABEL_ENTRY; 2018-06-07 12:16:11,094 INFO - sql_metadata_changelog.xml: metadata_changesets/delete_duplicate_custom_labels.xml::delete_duplicate_custom_labels::kshakir: Unique constraint added to CUSTOM_LABEL_ENTRY(CUSTOM_LABEL_KEY, WORKFLOW_EXECUTION_UUID); 2018-06-07 12:16:11,094 INFO - sql_metadata_changelog.xml: metadata_changesets/delete_duplicate_custom_labels.xml::delete_duplicate_custom_labels::kshakir: ChangeSet metadata_changesets/delete_duplicate_custom_labels.xml::delete_duplicate_custom_labels::kshakir ran successfully in 2ms; 2018-06-07 12:16:11,095 INFO - Successfully released change log lock; 2018-06-07 12:16:11,332 INFO - Slf4jLogger started; 2018-06-07 12:16:11,499 cromwell-system-akka.dispatchers.engine-dispatcher-4 INFO - Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-6c9b8d4"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; 2018-06-07 12:16:11,540 cromwell-system-akka.dispatchers.service-dispatcher-10 INFO - Metadata summary refreshing every 2 seconds.; 2018-06-07 12:16:11,574 cromwell-system-akka.dispatchers.service-dispatcher-8 INFO - WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; 2018-06-07 12:16:11,575 cromwell-system-akka.actor.default-dispatcher-2 INFO - KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; 2018-06-07 12:16:11,575 cromwell-system-akka.dispatchers.engine-dispatcher-32 INFO - JobStoreWriterActor configured to flush with batch size 1000 and process rate 1 second.; 2018-06-07 12:16",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:102117,Testability,Log,LoggingFSM,102117,ool.runWorker(ForkJoinPool.java:1979); akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$workflowInitializationFailed(MaterializeWorkflowDescriptorActor.scala:200); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:173); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:165); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); 	at akka.actor.FSM.processEvent(FSM.scala:665); 	at akka.actor.FSM.processEvent$(FSM.scala:662); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:123); 	at akka.actor.LoggingFSM.processEvent(FSM.scala:801); 	at akka.actor.LoggingFSM.processEvent$(FSM.scala:783); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.processEvent(MaterializeWorkflowDescriptorActor.scala:123); 	at akka.actor.FSM.akka$actor$FSM$$processMsg(FSM.scala:659); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:653); 	at akka.actor.Actor.aroundReceive(Actor.scala:514); 	at akka.actor.Actor.aroundReceive$(Actor.scala:512); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:123); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); 	at akka.actor.ActorCell.invoke(ActorCell.scala:496); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at akka.dispatch.forkjoi,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:102210,Testability,Log,LoggingFSM,102210,orkerThread.run(ForkJoinWorkerThread.java:107); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$workflowInitializationFailed(MaterializeWorkflowDescriptorActor.scala:200); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:173); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:165); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); 	at akka.actor.FSM.processEvent(FSM.scala:665); 	at akka.actor.FSM.processEvent$(FSM.scala:662); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:123); 	at akka.actor.LoggingFSM.processEvent(FSM.scala:801); 	at akka.actor.LoggingFSM.processEvent$(FSM.scala:783); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.processEvent(MaterializeWorkflowDescriptorActor.scala:123); 	at akka.actor.FSM.akka$actor$FSM$$processMsg(FSM.scala:659); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:653); 	at akka.actor.Actor.aroundReceive(Actor.scala:514); 	at akka.actor.Actor.aroundReceive$(Actor.scala:512); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:123); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); 	at akka.actor.ActorCell.invoke(ActorCell.scala:496); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoi,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:102265,Testability,Log,LoggingFSM,102265,mwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$workflowInitializationFailed(MaterializeWorkflowDescriptorActor.scala:200); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:173); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:165); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); 	at akka.actor.FSM.processEvent(FSM.scala:665); 	at akka.actor.FSM.processEvent$(FSM.scala:662); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:123); 	at akka.actor.LoggingFSM.processEvent(FSM.scala:801); 	at akka.actor.LoggingFSM.processEvent$(FSM.scala:783); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.processEvent(MaterializeWorkflowDescriptorActor.scala:123); 	at akka.actor.FSM.akka$actor$FSM$$processMsg(FSM.scala:659); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:653); 	at akka.actor.Actor.aroundReceive(Actor.scala:514); 	at akka.actor.Actor.aroundReceive$(Actor.scala:512); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:123); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); 	at akka.actor.ActorCell.invoke(ActorCell.scala:496); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:70403,Usability,Clear,ClearMetadataEntryWorkflowOptions,70403,"orkflow_options_in_metadata::tjeandet: RenameWorkflowOptionsInMetadata complete.; 2018-06-07 12:16:10,896 INFO - changelog.xml: changesets/rename_workflow_options_in_metadata.xml::rename_workflow_options_in_metadata::tjeandet: ChangeSet changesets/rename_workflow_options_in_metadata.xml::rename_workflow_options_in_metadata::tjeandet ran successfully in 17ms; 2018-06-07 12:16:10,898 INFO - changelog.xml: changesets/encrypt_and_clear_workflow_options.xml::encrypt_workflow_store_entry_workflow_options::kshakir: EncryptWorkflowStoreEntryWorkflowOptions complete.; 2018-06-07 12:16:10,899 INFO - changelog.xml: changesets/encrypt_and_clear_workflow_options.xml::encrypt_workflow_store_entry_workflow_options::kshakir: ChangeSet changesets/encrypt_and_clear_workflow_options.xml::encrypt_workflow_store_entry_workflow_options::kshakir ran successfully in 1ms; 2018-06-07 12:16:10,900 INFO - changelog.xml: changesets/encrypt_and_clear_workflow_options.xml::clear_metadata_entry_workflow_options::kshakir: ClearMetadataEntryWorkflowOptions complete.; 2018-06-07 12:16:10,900 INFO - changelog.xml: changesets/encrypt_and_clear_workflow_options.xml::clear_metadata_entry_workflow_options::kshakir: ChangeSet changesets/encrypt_and_clear_workflow_options.xml::clear_metadata_entry_workflow_options::kshakir ran successfully in 0ms; 2018-06-07 12:16:10,902 INFO - changelog.xml: changesets/sub_workflow_store.xml::SUB_WORKFLOW_STORE_ENTRY::tjeandet: Table SUB_WORKFLOW_STORE_ENTRY created; 2018-06-07 12:16:10,902 INFO - changelog.xml: changesets/sub_workflow_store.xml::SUB_WORKFLOW_STORE_ENTRY::tjeandet: ChangeSet changesets/sub_workflow_store.xml::SUB_WORKFLOW_STORE_ENTRY::tjeandet ran successfully in 1ms; 2018-06-07 12:16:10,904 INFO - changelog.xml: changesets/sub_workflow_store.xml::sub_workflow_store_uuid_index::tjeandet: Index IX_SUB_WORKFLOW_STORE_ENTRY_PWEU created; 2018-06-07 12:16:10,904 INFO - changelog.xml: changesets/sub_workflow_store.xml::sub_workflow_store_uuid_index::tjeandet: C",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395489025:52,Availability,error,error,52,Scratch that. Fresh git clone and build cleared the error for the non-AWS config. I must have screwed up the switch to develop from aws_backend branch. So my error **does** seem to be related to AWS code somehow! Sorry for the whipsaw...,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395489025
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395489025:158,Availability,error,error,158,Scratch that. Fresh git clone and build cleared the error for the non-AWS config. I must have screwed up the switch to develop from aws_backend branch. So my error **does** seem to be related to AWS code somehow! Sorry for the whipsaw...,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395489025
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395489025:74,Modifiability,config,config,74,Scratch that. Fresh git clone and build cleared the error for the non-AWS config. I must have screwed up the switch to develop from aws_backend branch. So my error **does** seem to be related to AWS code somehow! Sorry for the whipsaw...,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395489025
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395489025:40,Usability,clear,cleared,40,Scratch that. Fresh git clone and build cleared the error for the non-AWS config. I must have screwed up the switch to develop from aws_backend branch. So my error **does** seem to be related to AWS code somehow! Sorry for the whipsaw...,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395489025
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395499661:119,Deployability,pipeline,pipeline,119,"@tom-dyar Can you try again with latest? I fixed a ton of stuff in the last 24 hours, including a whole new processing pipeline for stdout/stderr and rc.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395499661
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395510754:51,Performance,queue,queue,51,"Fixed! Question: I have a compute-environment, job-queue, and job-definition already set up, and it appears they were used. What would happen if I didn't have any of that set up in AWS Batch already? I don't feel like re-creating right now to test, but just wondering... Also, I see you opened an issue to add volume support. You could check out the work done by the Funnel team and [https://github.com/adamstruck/ebsmount/tree/master/resources/funnel](url)...",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395510754
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395510754:243,Testability,test,test,243,"Fixed! Question: I have a compute-environment, job-queue, and job-definition already set up, and it appears they were used. What would happen if I didn't have any of that set up in AWS Batch already? I don't feel like re-creating right now to test, but just wondering... Also, I see you opened an issue to add volume support. You could check out the work done by the Funnel team and [https://github.com/adamstruck/ebsmount/tree/master/resources/funnel](url)...",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395510754
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395554332:73,Performance,queue,queue,73,"Excellent! Thanks for the pointer. As far as compute environment and job queue, they need to be setup in advance. @delagoya is creating a CloudFormation template that will make this relatively simple, and I believe we're planning on putting that in the 101 docs at that time.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395554332
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395554332:193,Usability,simpl,simple,193,"Excellent! Thanks for the pointer. As far as compute environment and job queue, they need to be setup in advance. @delagoya is creating a CloudFormation template that will make this relatively simple, and I believe we're planning on putting that in the 101 docs at that time.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395554332
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395557543:74,Performance,Queue,Queue,74,"@tom-dyar @elerch Current assumption is that you have valid AWS Batch Job Queue with a Compute Environment, and a AWS S3 bucket for results. Associated with these are IAM instance and task roles, VPC, etc. We will be providing tutorials on this pre-Cromwell requirements soon (weeks). . The AWS conf file just needs the job queue ARN. And the S3 bucket.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395557543
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395557543:324,Performance,queue,queue,324,"@tom-dyar @elerch Current assumption is that you have valid AWS Batch Job Queue with a Compute Environment, and a AWS S3 bucket for results. Associated with these are IAM instance and task roles, VPC, etc. We will be providing tutorials on this pre-Cromwell requirements soon (weeks). . The AWS conf file just needs the job queue ARN. And the S3 bucket.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395557543
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395590745:134,Deployability,release,release,134,AWS Batch works in a different way than current platforms and we are taking that into account for something we think will be great on release. Stay tuned to #3744 for more details and progress on this item,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395590745
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395590745:148,Performance,tune,tuned,148,AWS Batch works in a different way than current platforms and we are taking that into account for something we think will be great on release. Stay tuned to #3744 for more details and progress on this item,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395590745
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-400859982:38,Availability,error,error,38,@tom-dyar fyi - I received this boxed error today as well. It eventually cleared when I did an sbt clean and rebuilt the source.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-400859982
https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-400859982:73,Usability,clear,cleared,73,@tom-dyar fyi - I received this boxed error today as well. It eventually cleared when I did an sbt clean and rebuilt the source.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-400859982
https://github.com/broadinstitute/cromwell/pull/3738#issuecomment-395469732:119,Testability,test,tests,119,"@cjllanwarne It'd be helpful if you could add a description of how this is intended to work, I can kinda see it in the tests but want to make sure I'm not interpreting things incorrectly",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3738#issuecomment-395469732
https://github.com/broadinstitute/cromwell/pull/3738#issuecomment-395518160:133,Performance,optimiz,optimizations,133,@geoffjentry and @aednichols regarding documentation I added this: https://github.com/broadinstitute/cromwell/blob/cjl_nio_meta/docs/optimizations/FileLocalization.md. Is that sufficient of is there more to be said?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3738#issuecomment-395518160
https://github.com/broadinstitute/cromwell/issues/3740#issuecomment-395410031:70,Deployability,configurat,configuration,70,"Hi. Call caching is turned off by default, did you turn it on in your configuration? Also call caching will require the use of a MySQL-like database to preserve caching information between runs. Thanks",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3740#issuecomment-395410031
https://github.com/broadinstitute/cromwell/issues/3740#issuecomment-395410031:70,Modifiability,config,configuration,70,"Hi. Call caching is turned off by default, did you turn it on in your configuration? Also call caching will require the use of a MySQL-like database to preserve caching information between runs. Thanks",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3740#issuecomment-395410031
https://github.com/broadinstitute/cromwell/issues/3740#issuecomment-395418531:1346,Availability,error,error,1346,"In my FireCloud workflow, call caching is turned on by default. ; <img width=""1153"" alt=""screen shot 2018-06-07 at 8 57 27 am"" src=""https://user-images.githubusercontent.com/10040800/41101026-f1183d66-6a30-11e8-9fc0-75486f87e18f.png"">. and I also just realized that within the same workflow, some early tasks have the cache results recognized (Hit), for example:; <img width=""509"" alt=""screen shot 2018-06-07 at 9 03 24 am"" src=""https://user-images.githubusercontent.com/10040800/41101331-debd6938-6a31-11e8-903a-c6bf9c6e85e6.png"">; However, once it reaches to one task (M2), which splits the job based on scatter count (in my case, it is 50, basically, each subjob will only take care of a fraction of genome), I think the fraction of genome each job takes care of in different runs should be the same because no parameter has changed. But quite unexpectedly, the subjob cant recognize previous run (Miss). for example:; <img width=""905"" alt=""screen shot 2018-06-07 at 9 19 38 am"" src=""https://user-images.githubusercontent.com/10040800/41102077-f3d8fde4-6a33-11e8-8e24-0c13ada5865a.png"">. If I can't copy whatever successfully finished in previous subjobs, i have to start the whole 50 subjobs every time, it will dramatically increase my cost and time and there is no guarantee that new job will finish successfully because of those transient error. . Maybe there is something I am missing to set up call caching correctly, but as a newbie, I can't figure out myself. . Thanks all in advance",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3740#issuecomment-395418531
https://github.com/broadinstitute/cromwell/issues/3740#issuecomment-395418531:318,Performance,cache,cache,318,"In my FireCloud workflow, call caching is turned on by default. ; <img width=""1153"" alt=""screen shot 2018-06-07 at 8 57 27 am"" src=""https://user-images.githubusercontent.com/10040800/41101026-f1183d66-6a30-11e8-9fc0-75486f87e18f.png"">. and I also just realized that within the same workflow, some early tasks have the cache results recognized (Hit), for example:; <img width=""509"" alt=""screen shot 2018-06-07 at 9 03 24 am"" src=""https://user-images.githubusercontent.com/10040800/41101331-debd6938-6a31-11e8-903a-c6bf9c6e85e6.png"">; However, once it reaches to one task (M2), which splits the job based on scatter count (in my case, it is 50, basically, each subjob will only take care of a fraction of genome), I think the fraction of genome each job takes care of in different runs should be the same because no parameter has changed. But quite unexpectedly, the subjob cant recognize previous run (Miss). for example:; <img width=""905"" alt=""screen shot 2018-06-07 at 9 19 38 am"" src=""https://user-images.githubusercontent.com/10040800/41102077-f3d8fde4-6a33-11e8-8e24-0c13ada5865a.png"">. If I can't copy whatever successfully finished in previous subjobs, i have to start the whole 50 subjobs every time, it will dramatically increase my cost and time and there is no guarantee that new job will finish successfully because of those transient error. . Maybe there is something I am missing to set up call caching correctly, but as a newbie, I can't figure out myself. . Thanks all in advance",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3740#issuecomment-395418531
https://github.com/broadinstitute/cromwell/pull/3741#issuecomment-395449356:24,Modifiability,plugin,plugin,24,IntelliJ has a Markdown plugin that gives you a preview FWIW,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3741#issuecomment-395449356
https://github.com/broadinstitute/cromwell/issues/3742#issuecomment-395994748:15,Deployability,Pipeline,Pipelines,15,Reached out to Pipelines API for a potential retry on their end.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3742#issuecomment-395994748
https://github.com/broadinstitute/cromwell/issues/3742#issuecomment-401892591:188,Availability,failure,failures,188,This [PR](https://github.com/broadinstitute/cromwell/pull/3813) added _some_ retries around (de)localization. Definitely might not be enough but it's worth looking if it helped with those failures.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3742#issuecomment-401892591
https://github.com/broadinstitute/cromwell/issues/3743#issuecomment-395529303:23,Testability,log,log,23,"Though looking at this log there's definitely something wrong with the way Cromwell is setting the TMPDIR to use a non-containerized path. This appears to be a TES-specific bug as I can't reproduce it on Local or PAPI, but definitely a bug.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3743#issuecomment-395529303
https://github.com/broadinstitute/cromwell/issues/3743#issuecomment-395539408:0,Deployability,Update,Updated,0,Updated the file in the issue description. Thanks!,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3743#issuecomment-395539408
https://github.com/broadinstitute/cromwell/issues/3743#issuecomment-395576505:485,Integrability,message,message,485,@tom-dyar Based on the logs it appears cromwell is expecting to find the outputs locally. Since Funnel is running against AWS Batch those files are either being moved around on the AWS VM or being uploaded to S3. I think to get this working you would need to setup cromwell's `root` storage in the config to point to an S3 bucket. . @mcovarr I am not quite sure how cromwell can protect against this sort of config issue. One idea would be to inspect the OutputFileLog in the TES Task message and check the URL's of all of the output files.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3743#issuecomment-395576505
https://github.com/broadinstitute/cromwell/issues/3743#issuecomment-395576505:298,Modifiability,config,config,298,@tom-dyar Based on the logs it appears cromwell is expecting to find the outputs locally. Since Funnel is running against AWS Batch those files are either being moved around on the AWS VM or being uploaded to S3. I think to get this working you would need to setup cromwell's `root` storage in the config to point to an S3 bucket. . @mcovarr I am not quite sure how cromwell can protect against this sort of config issue. One idea would be to inspect the OutputFileLog in the TES Task message and check the URL's of all of the output files.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3743#issuecomment-395576505
https://github.com/broadinstitute/cromwell/issues/3743#issuecomment-395576505:408,Modifiability,config,config,408,@tom-dyar Based on the logs it appears cromwell is expecting to find the outputs locally. Since Funnel is running against AWS Batch those files are either being moved around on the AWS VM or being uploaded to S3. I think to get this working you would need to setup cromwell's `root` storage in the config to point to an S3 bucket. . @mcovarr I am not quite sure how cromwell can protect against this sort of config issue. One idea would be to inspect the OutputFileLog in the TES Task message and check the URL's of all of the output files.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3743#issuecomment-395576505
https://github.com/broadinstitute/cromwell/issues/3743#issuecomment-395576505:23,Testability,log,logs,23,@tom-dyar Based on the logs it appears cromwell is expecting to find the outputs locally. Since Funnel is running against AWS Batch those files are either being moved around on the AWS VM or being uploaded to S3. I think to get this working you would need to setup cromwell's `root` storage in the config to point to an S3 bucket. . @mcovarr I am not quite sure how cromwell can protect against this sort of config issue. One idea would be to inspect the OutputFileLog in the TES Task message and check the URL's of all of the output files.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3743#issuecomment-395576505
https://github.com/broadinstitute/cromwell/issues/3743#issuecomment-395613110:23,Availability,error,error,23,"I can't reproduce this error with hash 437d1b592ca606cdd96276a1cf85bf84594c31eb on develop, though I do still see the TMPDIR bug. I'll work on fixing that.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3743#issuecomment-395613110
https://github.com/broadinstitute/cromwell/issues/3743#issuecomment-395613110:34,Security,hash,hash,34,"I can't reproduce this error with hash 437d1b592ca606cdd96276a1cf85bf84594c31eb on develop, though I do still see the TMPDIR bug. I'll work on fixing that.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3743#issuecomment-395613110
https://github.com/broadinstitute/cromwell/issues/3744#issuecomment-398854923:625,Deployability,deploy,deployment,625,"Current proposal is to support the [`disks` runtime attribute](http://cromwell.readthedocs.io/en/develop/RuntimeAttributes/#disks) using the following rules:. 1. For all tasks, provide a predictable bind mount for `local-disk`. Specifications for disk size and disk type will be ignored, as they are not needed or configurable at runtime for AWS Batch. ; 2. Other mount points that are defined (e.g. `disks: ""/mnt/my_mnt 3 SSD, /mnt/my_mnt2 500 HDD""`) will result in additional bind mounts from the host container to the running docker container for the task. The disk size and disk type are ignored. The AWS Batch reference deployment for Cromwell will provide a mount point for each task which the `disks` will be structured under. As an example, assume the following runtime attribute definition:. ```; runtime {; disks: ""local-disk 100 SSD, /mnt/my_mnt 3 SSD, /mnt/my_mnt2 500 HDD""; }; ```. Will result in a filesystem tree structure on the host:. ```; /mnt/cromwell_io_mountpoint/; ‚îú‚îÄ‚îÄ $CROMWELL_TASK_ID; ‚îú‚îÄ‚îÄ /cromwell_root; ‚îî‚îÄ‚îÄ /mnt/; ‚îú‚îÄ‚îÄ /my_mnt; ‚îî‚îÄ‚îÄ /my_mnt2; ```. And the running container will see the `/cromwell_root`, `/mnt/my_mnt` and `/mnt/my_mnt2` directories.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3744#issuecomment-398854923
https://github.com/broadinstitute/cromwell/issues/3744#issuecomment-398854923:314,Modifiability,config,configurable,314,"Current proposal is to support the [`disks` runtime attribute](http://cromwell.readthedocs.io/en/develop/RuntimeAttributes/#disks) using the following rules:. 1. For all tasks, provide a predictable bind mount for `local-disk`. Specifications for disk size and disk type will be ignored, as they are not needed or configurable at runtime for AWS Batch. ; 2. Other mount points that are defined (e.g. `disks: ""/mnt/my_mnt 3 SSD, /mnt/my_mnt2 500 HDD""`) will result in additional bind mounts from the host container to the running docker container for the task. The disk size and disk type are ignored. The AWS Batch reference deployment for Cromwell will provide a mount point for each task which the `disks` will be structured under. As an example, assume the following runtime attribute definition:. ```; runtime {; disks: ""local-disk 100 SSD, /mnt/my_mnt 3 SSD, /mnt/my_mnt2 500 HDD""; }; ```. Will result in a filesystem tree structure on the host:. ```; /mnt/cromwell_io_mountpoint/; ‚îú‚îÄ‚îÄ $CROMWELL_TASK_ID; ‚îú‚îÄ‚îÄ /cromwell_root; ‚îî‚îÄ‚îÄ /mnt/; ‚îú‚îÄ‚îÄ /my_mnt; ‚îî‚îÄ‚îÄ /my_mnt2; ```. And the running container will see the `/cromwell_root`, `/mnt/my_mnt` and `/mnt/my_mnt2` directories.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3744#issuecomment-398854923
https://github.com/broadinstitute/cromwell/issues/3744#issuecomment-398854923:187,Safety,predict,predictable,187,"Current proposal is to support the [`disks` runtime attribute](http://cromwell.readthedocs.io/en/develop/RuntimeAttributes/#disks) using the following rules:. 1. For all tasks, provide a predictable bind mount for `local-disk`. Specifications for disk size and disk type will be ignored, as they are not needed or configurable at runtime for AWS Batch. ; 2. Other mount points that are defined (e.g. `disks: ""/mnt/my_mnt 3 SSD, /mnt/my_mnt2 500 HDD""`) will result in additional bind mounts from the host container to the running docker container for the task. The disk size and disk type are ignored. The AWS Batch reference deployment for Cromwell will provide a mount point for each task which the `disks` will be structured under. As an example, assume the following runtime attribute definition:. ```; runtime {; disks: ""local-disk 100 SSD, /mnt/my_mnt 3 SSD, /mnt/my_mnt2 500 HDD""; }; ```. Will result in a filesystem tree structure on the host:. ```; /mnt/cromwell_io_mountpoint/; ‚îú‚îÄ‚îÄ $CROMWELL_TASK_ID; ‚îú‚îÄ‚îÄ /cromwell_root; ‚îî‚îÄ‚îÄ /mnt/; ‚îú‚îÄ‚îÄ /my_mnt; ‚îî‚îÄ‚îÄ /my_mnt2; ```. And the running container will see the `/cromwell_root`, `/mnt/my_mnt` and `/mnt/my_mnt2` directories.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3744#issuecomment-398854923
https://github.com/broadinstitute/cromwell/issues/3744#issuecomment-399127437:100,Modifiability,config,configurable,100,"Also worth noting that `/mnt/cromwell_io_mountpoint` is not to be taken literally. . It should be a configurable option to Cromwell server, but not a runtime attribute. . Proposed name ""CROMWELL_HOST_ROOT"" but open to better suggestion.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3744#issuecomment-399127437
https://github.com/broadinstitute/cromwell/issues/3744#issuecomment-403851615:61,Availability,echo,echo,61,"Reopening this issue. . For the following WDL:; ```wdl; task echo {. command {; echo ""Hello World!""; }. runtime {; docker: ""ubuntu:latest""; disks: ""local-disk 100 HDD, /test1 10 SSD""; }; }. workflow wf_echo {; call echo; }; ```. I get an error that the specification expects the form of `disks: ""local-disk, /test1""`. If we are going to change the syntax of the value of `disks` runtime attribute, then we should change the label as well. `host_mount_point` or `docker_volumes` would be more appropriate for the way Batch works. . But in the interest of test, I change the WDL to match expectations:; ```wdl; task echo {. command {; echo ""Hello World!""; }. runtime {; docker: ""ubuntu:latest""; disks: ""local-disk, /test1""; }; }. workflow wf_echo {; call echo; }; ```. And the following `volumes` & `mountPoints` were created in the AWS Batch JobDefinition:. ```json; ""volumes"": [; {; ""host"": {; ""sourcePath"": ""/cromwell_root/wf_echo.echo-None-1""; },; ""name"": ""local-disk""; },; {; ""host"": {; ""sourcePath"": ""/test1/wf_echo.echo-None-1""; },; ""name"": ""d-c919a18cd1e1254f560bb64acc581574""; }; ],; ""mountPoints"": [; {; ""containerPath"": ""/cromwell_root"",; ""sourceVolume"": ""local-disk""; },; {; ""containerPath"": ""/test1"",; ""sourceVolume"": ""d-c919a18cd1e1254f560bb64acc581574""; }; ]; ```. The `volumes[].host.sourcePath` should instead be `/container_host_root/wf_echo.echo-None-1/cromwell_root` and `/container_host_root/wf_echo.echo-None-1/test1`. The defined `mountPoints` are correct.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3744#issuecomment-403851615
https://github.com/broadinstitute/cromwell/issues/3744#issuecomment-403851615:80,Availability,echo,echo,80,"Reopening this issue. . For the following WDL:; ```wdl; task echo {. command {; echo ""Hello World!""; }. runtime {; docker: ""ubuntu:latest""; disks: ""local-disk 100 HDD, /test1 10 SSD""; }; }. workflow wf_echo {; call echo; }; ```. I get an error that the specification expects the form of `disks: ""local-disk, /test1""`. If we are going to change the syntax of the value of `disks` runtime attribute, then we should change the label as well. `host_mount_point` or `docker_volumes` would be more appropriate for the way Batch works. . But in the interest of test, I change the WDL to match expectations:; ```wdl; task echo {. command {; echo ""Hello World!""; }. runtime {; docker: ""ubuntu:latest""; disks: ""local-disk, /test1""; }; }. workflow wf_echo {; call echo; }; ```. And the following `volumes` & `mountPoints` were created in the AWS Batch JobDefinition:. ```json; ""volumes"": [; {; ""host"": {; ""sourcePath"": ""/cromwell_root/wf_echo.echo-None-1""; },; ""name"": ""local-disk""; },; {; ""host"": {; ""sourcePath"": ""/test1/wf_echo.echo-None-1""; },; ""name"": ""d-c919a18cd1e1254f560bb64acc581574""; }; ],; ""mountPoints"": [; {; ""containerPath"": ""/cromwell_root"",; ""sourceVolume"": ""local-disk""; },; {; ""containerPath"": ""/test1"",; ""sourceVolume"": ""d-c919a18cd1e1254f560bb64acc581574""; }; ]; ```. The `volumes[].host.sourcePath` should instead be `/container_host_root/wf_echo.echo-None-1/cromwell_root` and `/container_host_root/wf_echo.echo-None-1/test1`. The defined `mountPoints` are correct.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3744#issuecomment-403851615
https://github.com/broadinstitute/cromwell/issues/3744#issuecomment-403851615:215,Availability,echo,echo,215,"Reopening this issue. . For the following WDL:; ```wdl; task echo {. command {; echo ""Hello World!""; }. runtime {; docker: ""ubuntu:latest""; disks: ""local-disk 100 HDD, /test1 10 SSD""; }; }. workflow wf_echo {; call echo; }; ```. I get an error that the specification expects the form of `disks: ""local-disk, /test1""`. If we are going to change the syntax of the value of `disks` runtime attribute, then we should change the label as well. `host_mount_point` or `docker_volumes` would be more appropriate for the way Batch works. . But in the interest of test, I change the WDL to match expectations:; ```wdl; task echo {. command {; echo ""Hello World!""; }. runtime {; docker: ""ubuntu:latest""; disks: ""local-disk, /test1""; }; }. workflow wf_echo {; call echo; }; ```. And the following `volumes` & `mountPoints` were created in the AWS Batch JobDefinition:. ```json; ""volumes"": [; {; ""host"": {; ""sourcePath"": ""/cromwell_root/wf_echo.echo-None-1""; },; ""name"": ""local-disk""; },; {; ""host"": {; ""sourcePath"": ""/test1/wf_echo.echo-None-1""; },; ""name"": ""d-c919a18cd1e1254f560bb64acc581574""; }; ],; ""mountPoints"": [; {; ""containerPath"": ""/cromwell_root"",; ""sourceVolume"": ""local-disk""; },; {; ""containerPath"": ""/test1"",; ""sourceVolume"": ""d-c919a18cd1e1254f560bb64acc581574""; }; ]; ```. The `volumes[].host.sourcePath` should instead be `/container_host_root/wf_echo.echo-None-1/cromwell_root` and `/container_host_root/wf_echo.echo-None-1/test1`. The defined `mountPoints` are correct.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3744#issuecomment-403851615
https://github.com/broadinstitute/cromwell/issues/3744#issuecomment-403851615:238,Availability,error,error,238,"Reopening this issue. . For the following WDL:; ```wdl; task echo {. command {; echo ""Hello World!""; }. runtime {; docker: ""ubuntu:latest""; disks: ""local-disk 100 HDD, /test1 10 SSD""; }; }. workflow wf_echo {; call echo; }; ```. I get an error that the specification expects the form of `disks: ""local-disk, /test1""`. If we are going to change the syntax of the value of `disks` runtime attribute, then we should change the label as well. `host_mount_point` or `docker_volumes` would be more appropriate for the way Batch works. . But in the interest of test, I change the WDL to match expectations:; ```wdl; task echo {. command {; echo ""Hello World!""; }. runtime {; docker: ""ubuntu:latest""; disks: ""local-disk, /test1""; }; }. workflow wf_echo {; call echo; }; ```. And the following `volumes` & `mountPoints` were created in the AWS Batch JobDefinition:. ```json; ""volumes"": [; {; ""host"": {; ""sourcePath"": ""/cromwell_root/wf_echo.echo-None-1""; },; ""name"": ""local-disk""; },; {; ""host"": {; ""sourcePath"": ""/test1/wf_echo.echo-None-1""; },; ""name"": ""d-c919a18cd1e1254f560bb64acc581574""; }; ],; ""mountPoints"": [; {; ""containerPath"": ""/cromwell_root"",; ""sourceVolume"": ""local-disk""; },; {; ""containerPath"": ""/test1"",; ""sourceVolume"": ""d-c919a18cd1e1254f560bb64acc581574""; }; ]; ```. The `volumes[].host.sourcePath` should instead be `/container_host_root/wf_echo.echo-None-1/cromwell_root` and `/container_host_root/wf_echo.echo-None-1/test1`. The defined `mountPoints` are correct.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3744#issuecomment-403851615
https://github.com/broadinstitute/cromwell/issues/3744#issuecomment-403851615:614,Availability,echo,echo,614,"Reopening this issue. . For the following WDL:; ```wdl; task echo {. command {; echo ""Hello World!""; }. runtime {; docker: ""ubuntu:latest""; disks: ""local-disk 100 HDD, /test1 10 SSD""; }; }. workflow wf_echo {; call echo; }; ```. I get an error that the specification expects the form of `disks: ""local-disk, /test1""`. If we are going to change the syntax of the value of `disks` runtime attribute, then we should change the label as well. `host_mount_point` or `docker_volumes` would be more appropriate for the way Batch works. . But in the interest of test, I change the WDL to match expectations:; ```wdl; task echo {. command {; echo ""Hello World!""; }. runtime {; docker: ""ubuntu:latest""; disks: ""local-disk, /test1""; }; }. workflow wf_echo {; call echo; }; ```. And the following `volumes` & `mountPoints` were created in the AWS Batch JobDefinition:. ```json; ""volumes"": [; {; ""host"": {; ""sourcePath"": ""/cromwell_root/wf_echo.echo-None-1""; },; ""name"": ""local-disk""; },; {; ""host"": {; ""sourcePath"": ""/test1/wf_echo.echo-None-1""; },; ""name"": ""d-c919a18cd1e1254f560bb64acc581574""; }; ],; ""mountPoints"": [; {; ""containerPath"": ""/cromwell_root"",; ""sourceVolume"": ""local-disk""; },; {; ""containerPath"": ""/test1"",; ""sourceVolume"": ""d-c919a18cd1e1254f560bb64acc581574""; }; ]; ```. The `volumes[].host.sourcePath` should instead be `/container_host_root/wf_echo.echo-None-1/cromwell_root` and `/container_host_root/wf_echo.echo-None-1/test1`. The defined `mountPoints` are correct.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3744#issuecomment-403851615
https://github.com/broadinstitute/cromwell/issues/3744#issuecomment-403851615:633,Availability,echo,echo,633,"Reopening this issue. . For the following WDL:; ```wdl; task echo {. command {; echo ""Hello World!""; }. runtime {; docker: ""ubuntu:latest""; disks: ""local-disk 100 HDD, /test1 10 SSD""; }; }. workflow wf_echo {; call echo; }; ```. I get an error that the specification expects the form of `disks: ""local-disk, /test1""`. If we are going to change the syntax of the value of `disks` runtime attribute, then we should change the label as well. `host_mount_point` or `docker_volumes` would be more appropriate for the way Batch works. . But in the interest of test, I change the WDL to match expectations:; ```wdl; task echo {. command {; echo ""Hello World!""; }. runtime {; docker: ""ubuntu:latest""; disks: ""local-disk, /test1""; }; }. workflow wf_echo {; call echo; }; ```. And the following `volumes` & `mountPoints` were created in the AWS Batch JobDefinition:. ```json; ""volumes"": [; {; ""host"": {; ""sourcePath"": ""/cromwell_root/wf_echo.echo-None-1""; },; ""name"": ""local-disk""; },; {; ""host"": {; ""sourcePath"": ""/test1/wf_echo.echo-None-1""; },; ""name"": ""d-c919a18cd1e1254f560bb64acc581574""; }; ],; ""mountPoints"": [; {; ""containerPath"": ""/cromwell_root"",; ""sourceVolume"": ""local-disk""; },; {; ""containerPath"": ""/test1"",; ""sourceVolume"": ""d-c919a18cd1e1254f560bb64acc581574""; }; ]; ```. The `volumes[].host.sourcePath` should instead be `/container_host_root/wf_echo.echo-None-1/cromwell_root` and `/container_host_root/wf_echo.echo-None-1/test1`. The defined `mountPoints` are correct.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3744#issuecomment-403851615
https://github.com/broadinstitute/cromwell/issues/3744#issuecomment-403851615:753,Availability,echo,echo,753,"Reopening this issue. . For the following WDL:; ```wdl; task echo {. command {; echo ""Hello World!""; }. runtime {; docker: ""ubuntu:latest""; disks: ""local-disk 100 HDD, /test1 10 SSD""; }; }. workflow wf_echo {; call echo; }; ```. I get an error that the specification expects the form of `disks: ""local-disk, /test1""`. If we are going to change the syntax of the value of `disks` runtime attribute, then we should change the label as well. `host_mount_point` or `docker_volumes` would be more appropriate for the way Batch works. . But in the interest of test, I change the WDL to match expectations:; ```wdl; task echo {. command {; echo ""Hello World!""; }. runtime {; docker: ""ubuntu:latest""; disks: ""local-disk, /test1""; }; }. workflow wf_echo {; call echo; }; ```. And the following `volumes` & `mountPoints` were created in the AWS Batch JobDefinition:. ```json; ""volumes"": [; {; ""host"": {; ""sourcePath"": ""/cromwell_root/wf_echo.echo-None-1""; },; ""name"": ""local-disk""; },; {; ""host"": {; ""sourcePath"": ""/test1/wf_echo.echo-None-1""; },; ""name"": ""d-c919a18cd1e1254f560bb64acc581574""; }; ],; ""mountPoints"": [; {; ""containerPath"": ""/cromwell_root"",; ""sourceVolume"": ""local-disk""; },; {; ""containerPath"": ""/test1"",; ""sourceVolume"": ""d-c919a18cd1e1254f560bb64acc581574""; }; ]; ```. The `volumes[].host.sourcePath` should instead be `/container_host_root/wf_echo.echo-None-1/cromwell_root` and `/container_host_root/wf_echo.echo-None-1/test1`. The defined `mountPoints` are correct.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3744#issuecomment-403851615
https://github.com/broadinstitute/cromwell/issues/3744#issuecomment-403851615:932,Availability,echo,echo-None-,932,"Reopening this issue. . For the following WDL:; ```wdl; task echo {. command {; echo ""Hello World!""; }. runtime {; docker: ""ubuntu:latest""; disks: ""local-disk 100 HDD, /test1 10 SSD""; }; }. workflow wf_echo {; call echo; }; ```. I get an error that the specification expects the form of `disks: ""local-disk, /test1""`. If we are going to change the syntax of the value of `disks` runtime attribute, then we should change the label as well. `host_mount_point` or `docker_volumes` would be more appropriate for the way Batch works. . But in the interest of test, I change the WDL to match expectations:; ```wdl; task echo {. command {; echo ""Hello World!""; }. runtime {; docker: ""ubuntu:latest""; disks: ""local-disk, /test1""; }; }. workflow wf_echo {; call echo; }; ```. And the following `volumes` & `mountPoints` were created in the AWS Batch JobDefinition:. ```json; ""volumes"": [; {; ""host"": {; ""sourcePath"": ""/cromwell_root/wf_echo.echo-None-1""; },; ""name"": ""local-disk""; },; {; ""host"": {; ""sourcePath"": ""/test1/wf_echo.echo-None-1""; },; ""name"": ""d-c919a18cd1e1254f560bb64acc581574""; }; ],; ""mountPoints"": [; {; ""containerPath"": ""/cromwell_root"",; ""sourceVolume"": ""local-disk""; },; {; ""containerPath"": ""/test1"",; ""sourceVolume"": ""d-c919a18cd1e1254f560bb64acc581574""; }; ]; ```. The `volumes[].host.sourcePath` should instead be `/container_host_root/wf_echo.echo-None-1/cromwell_root` and `/container_host_root/wf_echo.echo-None-1/test1`. The defined `mountPoints` are correct.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3744#issuecomment-403851615
https://github.com/broadinstitute/cromwell/issues/3744#issuecomment-403851615:1020,Availability,echo,echo-None-,1020,"Reopening this issue. . For the following WDL:; ```wdl; task echo {. command {; echo ""Hello World!""; }. runtime {; docker: ""ubuntu:latest""; disks: ""local-disk 100 HDD, /test1 10 SSD""; }; }. workflow wf_echo {; call echo; }; ```. I get an error that the specification expects the form of `disks: ""local-disk, /test1""`. If we are going to change the syntax of the value of `disks` runtime attribute, then we should change the label as well. `host_mount_point` or `docker_volumes` would be more appropriate for the way Batch works. . But in the interest of test, I change the WDL to match expectations:; ```wdl; task echo {. command {; echo ""Hello World!""; }. runtime {; docker: ""ubuntu:latest""; disks: ""local-disk, /test1""; }; }. workflow wf_echo {; call echo; }; ```. And the following `volumes` & `mountPoints` were created in the AWS Batch JobDefinition:. ```json; ""volumes"": [; {; ""host"": {; ""sourcePath"": ""/cromwell_root/wf_echo.echo-None-1""; },; ""name"": ""local-disk""; },; {; ""host"": {; ""sourcePath"": ""/test1/wf_echo.echo-None-1""; },; ""name"": ""d-c919a18cd1e1254f560bb64acc581574""; }; ],; ""mountPoints"": [; {; ""containerPath"": ""/cromwell_root"",; ""sourceVolume"": ""local-disk""; },; {; ""containerPath"": ""/test1"",; ""sourceVolume"": ""d-c919a18cd1e1254f560bb64acc581574""; }; ]; ```. The `volumes[].host.sourcePath` should instead be `/container_host_root/wf_echo.echo-None-1/cromwell_root` and `/container_host_root/wf_echo.echo-None-1/test1`. The defined `mountPoints` are correct.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3744#issuecomment-403851615
https://github.com/broadinstitute/cromwell/issues/3744#issuecomment-403851615:1358,Availability,echo,echo-None-,1358,"Reopening this issue. . For the following WDL:; ```wdl; task echo {. command {; echo ""Hello World!""; }. runtime {; docker: ""ubuntu:latest""; disks: ""local-disk 100 HDD, /test1 10 SSD""; }; }. workflow wf_echo {; call echo; }; ```. I get an error that the specification expects the form of `disks: ""local-disk, /test1""`. If we are going to change the syntax of the value of `disks` runtime attribute, then we should change the label as well. `host_mount_point` or `docker_volumes` would be more appropriate for the way Batch works. . But in the interest of test, I change the WDL to match expectations:; ```wdl; task echo {. command {; echo ""Hello World!""; }. runtime {; docker: ""ubuntu:latest""; disks: ""local-disk, /test1""; }; }. workflow wf_echo {; call echo; }; ```. And the following `volumes` & `mountPoints` were created in the AWS Batch JobDefinition:. ```json; ""volumes"": [; {; ""host"": {; ""sourcePath"": ""/cromwell_root/wf_echo.echo-None-1""; },; ""name"": ""local-disk""; },; {; ""host"": {; ""sourcePath"": ""/test1/wf_echo.echo-None-1""; },; ""name"": ""d-c919a18cd1e1254f560bb64acc581574""; }; ],; ""mountPoints"": [; {; ""containerPath"": ""/cromwell_root"",; ""sourceVolume"": ""local-disk""; },; {; ""containerPath"": ""/test1"",; ""sourceVolume"": ""d-c919a18cd1e1254f560bb64acc581574""; }; ]; ```. The `volumes[].host.sourcePath` should instead be `/container_host_root/wf_echo.echo-None-1/cromwell_root` and `/container_host_root/wf_echo.echo-None-1/test1`. The defined `mountPoints` are correct.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3744#issuecomment-403851615
https://github.com/broadinstitute/cromwell/issues/3744#issuecomment-403851615:1419,Availability,echo,echo-None-,1419,"Reopening this issue. . For the following WDL:; ```wdl; task echo {. command {; echo ""Hello World!""; }. runtime {; docker: ""ubuntu:latest""; disks: ""local-disk 100 HDD, /test1 10 SSD""; }; }. workflow wf_echo {; call echo; }; ```. I get an error that the specification expects the form of `disks: ""local-disk, /test1""`. If we are going to change the syntax of the value of `disks` runtime attribute, then we should change the label as well. `host_mount_point` or `docker_volumes` would be more appropriate for the way Batch works. . But in the interest of test, I change the WDL to match expectations:; ```wdl; task echo {. command {; echo ""Hello World!""; }. runtime {; docker: ""ubuntu:latest""; disks: ""local-disk, /test1""; }; }. workflow wf_echo {; call echo; }; ```. And the following `volumes` & `mountPoints` were created in the AWS Batch JobDefinition:. ```json; ""volumes"": [; {; ""host"": {; ""sourcePath"": ""/cromwell_root/wf_echo.echo-None-1""; },; ""name"": ""local-disk""; },; {; ""host"": {; ""sourcePath"": ""/test1/wf_echo.echo-None-1""; },; ""name"": ""d-c919a18cd1e1254f560bb64acc581574""; }; ],; ""mountPoints"": [; {; ""containerPath"": ""/cromwell_root"",; ""sourceVolume"": ""local-disk""; },; {; ""containerPath"": ""/test1"",; ""sourceVolume"": ""d-c919a18cd1e1254f560bb64acc581574""; }; ]; ```. The `volumes[].host.sourcePath` should instead be `/container_host_root/wf_echo.echo-None-1/cromwell_root` and `/container_host_root/wf_echo.echo-None-1/test1`. The defined `mountPoints` are correct.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3744#issuecomment-403851615
https://github.com/broadinstitute/cromwell/issues/3744#issuecomment-403851615:554,Testability,test,test,554,"Reopening this issue. . For the following WDL:; ```wdl; task echo {. command {; echo ""Hello World!""; }. runtime {; docker: ""ubuntu:latest""; disks: ""local-disk 100 HDD, /test1 10 SSD""; }; }. workflow wf_echo {; call echo; }; ```. I get an error that the specification expects the form of `disks: ""local-disk, /test1""`. If we are going to change the syntax of the value of `disks` runtime attribute, then we should change the label as well. `host_mount_point` or `docker_volumes` would be more appropriate for the way Batch works. . But in the interest of test, I change the WDL to match expectations:; ```wdl; task echo {. command {; echo ""Hello World!""; }. runtime {; docker: ""ubuntu:latest""; disks: ""local-disk, /test1""; }; }. workflow wf_echo {; call echo; }; ```. And the following `volumes` & `mountPoints` were created in the AWS Batch JobDefinition:. ```json; ""volumes"": [; {; ""host"": {; ""sourcePath"": ""/cromwell_root/wf_echo.echo-None-1""; },; ""name"": ""local-disk""; },; {; ""host"": {; ""sourcePath"": ""/test1/wf_echo.echo-None-1""; },; ""name"": ""d-c919a18cd1e1254f560bb64acc581574""; }; ],; ""mountPoints"": [; {; ""containerPath"": ""/cromwell_root"",; ""sourceVolume"": ""local-disk""; },; {; ""containerPath"": ""/test1"",; ""sourceVolume"": ""d-c919a18cd1e1254f560bb64acc581574""; }; ]; ```. The `volumes[].host.sourcePath` should instead be `/container_host_root/wf_echo.echo-None-1/cromwell_root` and `/container_host_root/wf_echo.echo-None-1/test1`. The defined `mountPoints` are correct.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3744#issuecomment-403851615
https://github.com/broadinstitute/cromwell/issues/3744#issuecomment-405687348:382,Deployability,configurat,configuration,382,"@delagoya I can't seem to find the thread, but the pathing reversal from @kshakir's notes above was purposeful. By using /test1/... rather than .../test1, we get the advantage of a more useful host path when traversing manually for debugging purposes for example, or by being able to segment what we know are large tasks to different filesystems. I'm comfortable changing the disks configuration name but this should probably be tracked in a separate issue.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3744#issuecomment-405687348
https://github.com/broadinstitute/cromwell/issues/3744#issuecomment-405687348:382,Modifiability,config,configuration,382,"@delagoya I can't seem to find the thread, but the pathing reversal from @kshakir's notes above was purposeful. By using /test1/... rather than .../test1, we get the advantage of a more useful host path when traversing manually for debugging purposes for example, or by being able to segment what we know are large tasks to different filesystems. I'm comfortable changing the disks configuration name but this should probably be tracked in a separate issue.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3744#issuecomment-405687348
https://github.com/broadinstitute/cromwell/issues/3751#issuecomment-395825435:25,Integrability,wrap,wrapping,25,Appears to be related to wrapping it up into the implicit sub-workflow for the inner scatter (`ScatterElementToGraphNode:103`),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3751#issuecomment-395825435
https://github.com/broadinstitute/cromwell/issues/3753#issuecomment-396287044:8,Security,access,access,8,Batched access to the workflow store will likely touch on #3757,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3753#issuecomment-396287044
https://github.com/broadinstitute/cromwell/issues/3755#issuecomment-451759631:395,Availability,error,errors,395,"Recently for an operation task that updating labels for ~2500 workflows, we have to write a loop to end ~2500 PATCH /label requests to the Cromwell, which took more than 3 hrs. (In Cromwell IAM, this is even worse since a single token will expire in 60mins, so you have to also deal with the token refreshment) . We tried to use multi-threading to speed it up but ended up getting transient 500 errors when using a thread pool with a size of >=4 threads. . So having this batch feature will make a lot of things much easier!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3755#issuecomment-451759631
https://github.com/broadinstitute/cromwell/issues/3755#issuecomment-451759631:110,Deployability,PATCH,PATCH,110,"Recently for an operation task that updating labels for ~2500 workflows, we have to write a loop to end ~2500 PATCH /label requests to the Cromwell, which took more than 3 hrs. (In Cromwell IAM, this is even worse since a single token will expire in 60mins, so you have to also deal with the token refreshment) . We tried to use multi-threading to speed it up but ended up getting transient 500 errors when using a thread pool with a size of >=4 threads. . So having this batch feature will make a lot of things much easier!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3755#issuecomment-451759631
https://github.com/broadinstitute/cromwell/issues/3755#issuecomment-451759631:329,Performance,multi-thread,multi-threading,329,"Recently for an operation task that updating labels for ~2500 workflows, we have to write a loop to end ~2500 PATCH /label requests to the Cromwell, which took more than 3 hrs. (In Cromwell IAM, this is even worse since a single token will expire in 60mins, so you have to also deal with the token refreshment) . We tried to use multi-threading to speed it up but ended up getting transient 500 errors when using a thread pool with a size of >=4 threads. . So having this batch feature will make a lot of things much easier!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3755#issuecomment-451759631
https://github.com/broadinstitute/cromwell/issues/3758#issuecomment-395992525:148,Safety,abort,abort,148,Hey @patmagee -- a few questions:. 1. What version of Cromwell are you using? Is this behavior you're seeing as of recently? ; 2. Are you using the abort endpoint or killing operations from the Google Cloud console?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3758#issuecomment-395992525
https://github.com/broadinstitute/cromwell/issues/3758#issuecomment-395998956:37,Safety,abort,aborted,37,Hey @ruchim . I am using 31.1. And i aborted them with the rest endpoint first. But a day later vms were still running. Manually killing these caused the above behaviour,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3758#issuecomment-395998956
https://github.com/broadinstitute/cromwell/issues/3758#issuecomment-396002673:416,Availability,error,errors,416,"Hey Patrick, I just ran a tiny test and was able to confirm jobs getting aborted. ; - How many jobs were started from your workflow, and did any of the jobs from your workflow abort?; - Do you have a general sense at the stage your jobs were on when they were aborted? Were they all mostly executing the command when you aborted them? ; - Did Cromwell ever report the workflow to have been successfully Aborted? Any errors thrown in the server logs?. Would you mind posting the operation metadata from one of the jobs that you tried aborting using the rest endpoint? Or simply the events reported for that operation?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3758#issuecomment-396002673
https://github.com/broadinstitute/cromwell/issues/3758#issuecomment-396002673:73,Safety,abort,aborted,73,"Hey Patrick, I just ran a tiny test and was able to confirm jobs getting aborted. ; - How many jobs were started from your workflow, and did any of the jobs from your workflow abort?; - Do you have a general sense at the stage your jobs were on when they were aborted? Were they all mostly executing the command when you aborted them? ; - Did Cromwell ever report the workflow to have been successfully Aborted? Any errors thrown in the server logs?. Would you mind posting the operation metadata from one of the jobs that you tried aborting using the rest endpoint? Or simply the events reported for that operation?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3758#issuecomment-396002673
https://github.com/broadinstitute/cromwell/issues/3758#issuecomment-396002673:176,Safety,abort,abort,176,"Hey Patrick, I just ran a tiny test and was able to confirm jobs getting aborted. ; - How many jobs were started from your workflow, and did any of the jobs from your workflow abort?; - Do you have a general sense at the stage your jobs were on when they were aborted? Were they all mostly executing the command when you aborted them? ; - Did Cromwell ever report the workflow to have been successfully Aborted? Any errors thrown in the server logs?. Would you mind posting the operation metadata from one of the jobs that you tried aborting using the rest endpoint? Or simply the events reported for that operation?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3758#issuecomment-396002673
https://github.com/broadinstitute/cromwell/issues/3758#issuecomment-396002673:260,Safety,abort,aborted,260,"Hey Patrick, I just ran a tiny test and was able to confirm jobs getting aborted. ; - How many jobs were started from your workflow, and did any of the jobs from your workflow abort?; - Do you have a general sense at the stage your jobs were on when they were aborted? Were they all mostly executing the command when you aborted them? ; - Did Cromwell ever report the workflow to have been successfully Aborted? Any errors thrown in the server logs?. Would you mind posting the operation metadata from one of the jobs that you tried aborting using the rest endpoint? Or simply the events reported for that operation?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3758#issuecomment-396002673
https://github.com/broadinstitute/cromwell/issues/3758#issuecomment-396002673:321,Safety,abort,aborted,321,"Hey Patrick, I just ran a tiny test and was able to confirm jobs getting aborted. ; - How many jobs were started from your workflow, and did any of the jobs from your workflow abort?; - Do you have a general sense at the stage your jobs were on when they were aborted? Were they all mostly executing the command when you aborted them? ; - Did Cromwell ever report the workflow to have been successfully Aborted? Any errors thrown in the server logs?. Would you mind posting the operation metadata from one of the jobs that you tried aborting using the rest endpoint? Or simply the events reported for that operation?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3758#issuecomment-396002673
https://github.com/broadinstitute/cromwell/issues/3758#issuecomment-396002673:403,Safety,Abort,Aborted,403,"Hey Patrick, I just ran a tiny test and was able to confirm jobs getting aborted. ; - How many jobs were started from your workflow, and did any of the jobs from your workflow abort?; - Do you have a general sense at the stage your jobs were on when they were aborted? Were they all mostly executing the command when you aborted them? ; - Did Cromwell ever report the workflow to have been successfully Aborted? Any errors thrown in the server logs?. Would you mind posting the operation metadata from one of the jobs that you tried aborting using the rest endpoint? Or simply the events reported for that operation?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3758#issuecomment-396002673
https://github.com/broadinstitute/cromwell/issues/3758#issuecomment-396002673:533,Safety,abort,aborting,533,"Hey Patrick, I just ran a tiny test and was able to confirm jobs getting aborted. ; - How many jobs were started from your workflow, and did any of the jobs from your workflow abort?; - Do you have a general sense at the stage your jobs were on when they were aborted? Were they all mostly executing the command when you aborted them? ; - Did Cromwell ever report the workflow to have been successfully Aborted? Any errors thrown in the server logs?. Would you mind posting the operation metadata from one of the jobs that you tried aborting using the rest endpoint? Or simply the events reported for that operation?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3758#issuecomment-396002673
https://github.com/broadinstitute/cromwell/issues/3758#issuecomment-396002673:31,Testability,test,test,31,"Hey Patrick, I just ran a tiny test and was able to confirm jobs getting aborted. ; - How many jobs were started from your workflow, and did any of the jobs from your workflow abort?; - Do you have a general sense at the stage your jobs were on when they were aborted? Were they all mostly executing the command when you aborted them? ; - Did Cromwell ever report the workflow to have been successfully Aborted? Any errors thrown in the server logs?. Would you mind posting the operation metadata from one of the jobs that you tried aborting using the rest endpoint? Or simply the events reported for that operation?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3758#issuecomment-396002673
https://github.com/broadinstitute/cromwell/issues/3758#issuecomment-396002673:444,Testability,log,logs,444,"Hey Patrick, I just ran a tiny test and was able to confirm jobs getting aborted. ; - How many jobs were started from your workflow, and did any of the jobs from your workflow abort?; - Do you have a general sense at the stage your jobs were on when they were aborted? Were they all mostly executing the command when you aborted them? ; - Did Cromwell ever report the workflow to have been successfully Aborted? Any errors thrown in the server logs?. Would you mind posting the operation metadata from one of the jobs that you tried aborting using the rest endpoint? Or simply the events reported for that operation?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3758#issuecomment-396002673
https://github.com/broadinstitute/cromwell/issues/3758#issuecomment-396002673:570,Usability,simpl,simply,570,"Hey Patrick, I just ran a tiny test and was able to confirm jobs getting aborted. ; - How many jobs were started from your workflow, and did any of the jobs from your workflow abort?; - Do you have a general sense at the stage your jobs were on when they were aborted? Were they all mostly executing the command when you aborted them? ; - Did Cromwell ever report the workflow to have been successfully Aborted? Any errors thrown in the server logs?. Would you mind posting the operation metadata from one of the jobs that you tried aborting using the rest endpoint? Or simply the events reported for that operation?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3758#issuecomment-396002673
https://github.com/broadinstitute/cromwell/issues/3758#issuecomment-397628025:158,Safety,abort,abort,158,"Hey @patmagee I'm able to reproduce this behavior today. We will look into why this is happening, there's a definitely some path that's not killing jobs upon abort.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3758#issuecomment-397628025
https://github.com/broadinstitute/cromwell/issues/3758#issuecomment-397628329:186,Safety,Abort,Aborted,186,"<img width=""795"" alt=""screen shot 2018-06-15 at 9 44 14 am"" src=""https://user-images.githubusercontent.com/14941133/41471529-e9b665be-7081-11e8-86e3-1a4804d71adf.png"">. Workflow status `Aborted`, executionStatus/backendStatus `Running`, PAPI Operation status `done:false`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3758#issuecomment-397628329
https://github.com/broadinstitute/cromwell/issues/3758#issuecomment-397628552:98,Testability,log,logs,98,"@ruchim Thanks alot for looking into this, I have not really had bandwidth to get those Operation logs yet, I can look into it later today hopefully",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3758#issuecomment-397628552
https://github.com/broadinstitute/cromwell/issues/3758#issuecomment-400468311:119,Availability,failure,failures,119,@patmagee It turned out it was a different issue entirely in our production environment that had the symptoms of abort failures. We've not had success recreating this -- but let us know what you end up observing!,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3758#issuecomment-400468311
https://github.com/broadinstitute/cromwell/issues/3758#issuecomment-400468311:113,Safety,abort,abort,113,@patmagee It turned out it was a different issue entirely in our production environment that had the symptoms of abort failures. We've not had success recreating this -- but let us know what you end up observing!,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3758#issuecomment-400468311
https://github.com/broadinstitute/cromwell/issues/3759#issuecomment-395994554:34,Security,hash,hash,34,@geoffjentry is it appropriate to hash the url itself for caching purposes for this stage?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3759#issuecomment-395994554
https://github.com/broadinstitute/cromwell/issues/3759#issuecomment-396064853:56,Security,access,access,56,"IMO yes as that's the stated purpose of DOS, to provide access to the **same** file in **different** locations. . Since this level of work is really for the blue box stuff and that's not **quite** the same as DOS yet I'd check with the relevant folks on our side and in particular try to have them to circulate that question among their larger group.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3759#issuecomment-396064853
https://github.com/broadinstitute/cromwell/issues/3759#issuecomment-396066752:40,Security,hash,hash,40,@dvoet Is it acceptable for Cromwell to hash the dos url string itself for the purposes of call caching? Would this ever be different in the future?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3759#issuecomment-396066752
https://github.com/broadinstitute/cromwell/issues/3759#issuecomment-396092432:204,Security,hash,hash,204,"I think it is acceptable for the now. There is still discussion over the; final format of the uri so the future, as usual, is a little murky. If you; want to be fancy you can resolve the uri and grab the hash. On Sun, Jun 10, 2018 at 1:32 PM Ruchi <notifications@github.com> wrote:. > @dvoet <https://github.com/dvoet> Is it acceptable for Cromwell to hash; > the dos url string itself for the purposes of call caching? Would this ever; > be different in the future?; >; > ‚Äî; > You are receiving this because you were mentioned.; >; >; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/3759#issuecomment-396066752>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABc2tWw3C-27jEOgivVBPa3jQYyBxm4sks5t7VgegaJpZM4UhdvM>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3759#issuecomment-396092432
https://github.com/broadinstitute/cromwell/issues/3759#issuecomment-396092432:352,Security,hash,hash,352,"I think it is acceptable for the now. There is still discussion over the; final format of the uri so the future, as usual, is a little murky. If you; want to be fancy you can resolve the uri and grab the hash. On Sun, Jun 10, 2018 at 1:32 PM Ruchi <notifications@github.com> wrote:. > @dvoet <https://github.com/dvoet> Is it acceptable for Cromwell to hash; > the dos url string itself for the purposes of call caching? Would this ever; > be different in the future?; >; > ‚Äî; > You are receiving this because you were mentioned.; >; >; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/3759#issuecomment-396066752>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABc2tWw3C-27jEOgivVBPa3jQYyBxm4sks5t7VgegaJpZM4UhdvM>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3759#issuecomment-396092432
https://github.com/broadinstitute/cromwell/issues/3760#issuecomment-398846677:97,Availability,echo,echo,97,"Staging input/output files from/to S3 is not yet implemented. If the command from the task is an echo that redirects STDOUT to a file (e.g. `echo 'hello world' > output`) this will fail when Cromwell tries to retrieve the file from S3. . If the command is a simple echo (e.g. `echo ""hello world"") the STDOUT is retrieved from CloudWatch Logs and the process should succeed.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3760#issuecomment-398846677
https://github.com/broadinstitute/cromwell/issues/3760#issuecomment-398846677:141,Availability,echo,echo,141,"Staging input/output files from/to S3 is not yet implemented. If the command from the task is an echo that redirects STDOUT to a file (e.g. `echo 'hello world' > output`) this will fail when Cromwell tries to retrieve the file from S3. . If the command is a simple echo (e.g. `echo ""hello world"") the STDOUT is retrieved from CloudWatch Logs and the process should succeed.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3760#issuecomment-398846677
https://github.com/broadinstitute/cromwell/issues/3760#issuecomment-398846677:265,Availability,echo,echo,265,"Staging input/output files from/to S3 is not yet implemented. If the command from the task is an echo that redirects STDOUT to a file (e.g. `echo 'hello world' > output`) this will fail when Cromwell tries to retrieve the file from S3. . If the command is a simple echo (e.g. `echo ""hello world"") the STDOUT is retrieved from CloudWatch Logs and the process should succeed.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3760#issuecomment-398846677
https://github.com/broadinstitute/cromwell/issues/3760#issuecomment-398846677:277,Availability,echo,echo,277,"Staging input/output files from/to S3 is not yet implemented. If the command from the task is an echo that redirects STDOUT to a file (e.g. `echo 'hello world' > output`) this will fail when Cromwell tries to retrieve the file from S3. . If the command is a simple echo (e.g. `echo ""hello world"") the STDOUT is retrieved from CloudWatch Logs and the process should succeed.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3760#issuecomment-398846677
https://github.com/broadinstitute/cromwell/issues/3760#issuecomment-398846677:337,Testability,Log,Logs,337,"Staging input/output files from/to S3 is not yet implemented. If the command from the task is an echo that redirects STDOUT to a file (e.g. `echo 'hello world' > output`) this will fail when Cromwell tries to retrieve the file from S3. . If the command is a simple echo (e.g. `echo ""hello world"") the STDOUT is retrieved from CloudWatch Logs and the process should succeed.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3760#issuecomment-398846677
https://github.com/broadinstitute/cromwell/issues/3760#issuecomment-398846677:258,Usability,simpl,simple,258,"Staging input/output files from/to S3 is not yet implemented. If the command from the task is an echo that redirects STDOUT to a file (e.g. `echo 'hello world' > output`) this will fail when Cromwell tries to retrieve the file from S3. . If the command is a simple echo (e.g. `echo ""hello world"") the STDOUT is retrieved from CloudWatch Logs and the process should succeed.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3760#issuecomment-398846677
https://github.com/broadinstitute/cromwell/issues/3760#issuecomment-452039660:70,Deployability,update,update,70,Is it still the case that call caching is not implemented for S3? Any update on this issue @delagoya?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3760#issuecomment-452039660
https://github.com/broadinstitute/cromwell/pull/3761#issuecomment-397602143:187,Availability,Fault,FaultHandling,187,After a little research it seems the default Akka supervision decider and strategy looks [pretty reasonable](https://github.com/akka/akka/blob/master/akka-actor/src/main/scala/akka/actor/FaultHandling.scala#L156) for this.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3761#issuecomment-397602143
https://github.com/broadinstitute/cromwell/issues/3762#issuecomment-396605877:120,Security,validat,validating,120,"It's not required by the spec per se, but it is required in order to be runnable so presumably what womtool is doing is validating ""can this be run"" instead of ""is this correct syntax"". @cjllanwarne Something to consider, those two things aren't **quite** the same.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3762#issuecomment-396605877
https://github.com/broadinstitute/cromwell/issues/3762#issuecomment-396950006:216,Deployability,release,release,216,"Interesting - I thought it would only push as far as ""can I execute it"" if an inputs file is provided, but that appears to not be true. Thanks for raising this - we should be able to get a fix in for the Cromwell 33 release which should be sometime next week.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3762#issuecomment-396950006
https://github.com/broadinstitute/cromwell/issues/3762#issuecomment-396973479:149,Deployability,upgrade,upgrade,149,"PR now in for review #3772 - I can add another workaround in the meantime, since apparently this was only affecting the draft-2 language factory:. * upgrade to WDL 1.0. However, since an upgrade script is also coming in as part of Cromwell 33, maybe one of your other workarounds is less effort in the short term?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3762#issuecomment-396973479
https://github.com/broadinstitute/cromwell/issues/3762#issuecomment-396973479:187,Deployability,upgrade,upgrade,187,"PR now in for review #3772 - I can add another workaround in the meantime, since apparently this was only affecting the draft-2 language factory:. * upgrade to WDL 1.0. However, since an upgrade script is also coming in as part of Cromwell 33, maybe one of your other workarounds is less effort in the short term?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3762#issuecomment-396973479
https://github.com/broadinstitute/cromwell/issues/3762#issuecomment-398279541:118,Deployability,upgrade,upgrade,118,"@cjllanwarne Thanks for fixing this so fast. For validation I just skip version 32 ;) When is 33 planned?. We want to upgrade to wdl 1.0 anyway but first need to complete our testing framework around wdl, see also https://github.com/biopet/biowdl-test-utils (library) and https://github.com/biowdl/QC (real pipeline with testing)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3762#issuecomment-398279541
https://github.com/broadinstitute/cromwell/issues/3762#issuecomment-398279541:307,Deployability,pipeline,pipeline,307,"@cjllanwarne Thanks for fixing this so fast. For validation I just skip version 32 ;) When is 33 planned?. We want to upgrade to wdl 1.0 anyway but first need to complete our testing framework around wdl, see also https://github.com/biopet/biowdl-test-utils (library) and https://github.com/biowdl/QC (real pipeline with testing)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3762#issuecomment-398279541
https://github.com/broadinstitute/cromwell/issues/3762#issuecomment-398279541:49,Security,validat,validation,49,"@cjllanwarne Thanks for fixing this so fast. For validation I just skip version 32 ;) When is 33 planned?. We want to upgrade to wdl 1.0 anyway but first need to complete our testing framework around wdl, see also https://github.com/biopet/biowdl-test-utils (library) and https://github.com/biowdl/QC (real pipeline with testing)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3762#issuecomment-398279541
https://github.com/broadinstitute/cromwell/issues/3762#issuecomment-398279541:175,Testability,test,testing,175,"@cjllanwarne Thanks for fixing this so fast. For validation I just skip version 32 ;) When is 33 planned?. We want to upgrade to wdl 1.0 anyway but first need to complete our testing framework around wdl, see also https://github.com/biopet/biowdl-test-utils (library) and https://github.com/biowdl/QC (real pipeline with testing)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3762#issuecomment-398279541
https://github.com/broadinstitute/cromwell/issues/3762#issuecomment-398279541:247,Testability,test,test-utils,247,"@cjllanwarne Thanks for fixing this so fast. For validation I just skip version 32 ;) When is 33 planned?. We want to upgrade to wdl 1.0 anyway but first need to complete our testing framework around wdl, see also https://github.com/biopet/biowdl-test-utils (library) and https://github.com/biowdl/QC (real pipeline with testing)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3762#issuecomment-398279541
https://github.com/broadinstitute/cromwell/issues/3762#issuecomment-398279541:321,Testability,test,testing,321,"@cjllanwarne Thanks for fixing this so fast. For validation I just skip version 32 ;) When is 33 planned?. We want to upgrade to wdl 1.0 anyway but first need to complete our testing framework around wdl, see also https://github.com/biopet/biowdl-test-utils (library) and https://github.com/biowdl/QC (real pipeline with testing)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3762#issuecomment-398279541
https://github.com/broadinstitute/cromwell/issues/3762#issuecomment-399565111:108,Availability,avail,available,108,"@cjllanwarne: I also encountered this issue. Until the mentioned upgrade script is released, is information available that highlights the changes necessary to migrate from draft 2 (or 3/1) to WDL 1.0? My files are in draft-2 format. Any sort of guidance about what's different between the versions would be helpful. Doing a visual diff of the `SPEC.md` files isn't ideal... Somewhat related: Is there an estimate of when womtool will have `-imports` exposed as a parameter?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3762#issuecomment-399565111
https://github.com/broadinstitute/cromwell/issues/3762#issuecomment-399565111:65,Deployability,upgrade,upgrade,65,"@cjllanwarne: I also encountered this issue. Until the mentioned upgrade script is released, is information available that highlights the changes necessary to migrate from draft 2 (or 3/1) to WDL 1.0? My files are in draft-2 format. Any sort of guidance about what's different between the versions would be helpful. Doing a visual diff of the `SPEC.md` files isn't ideal... Somewhat related: Is there an estimate of when womtool will have `-imports` exposed as a parameter?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3762#issuecomment-399565111
https://github.com/broadinstitute/cromwell/issues/3762#issuecomment-399565111:83,Deployability,release,released,83,"@cjllanwarne: I also encountered this issue. Until the mentioned upgrade script is released, is information available that highlights the changes necessary to migrate from draft 2 (or 3/1) to WDL 1.0? My files are in draft-2 format. Any sort of guidance about what's different between the versions would be helpful. Doing a visual diff of the `SPEC.md` files isn't ideal... Somewhat related: Is there an estimate of when womtool will have `-imports` exposed as a parameter?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3762#issuecomment-399565111
https://github.com/broadinstitute/cromwell/issues/3762#issuecomment-399565111:450,Security,expose,exposed,450,"@cjllanwarne: I also encountered this issue. Until the mentioned upgrade script is released, is information available that highlights the changes necessary to migrate from draft 2 (or 3/1) to WDL 1.0? My files are in draft-2 format. Any sort of guidance about what's different between the versions would be helpful. Doing a visual diff of the `SPEC.md` files isn't ideal... Somewhat related: Is there an estimate of when womtool will have `-imports` exposed as a parameter?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3762#issuecomment-399565111
https://github.com/broadinstitute/cromwell/issues/3762#issuecomment-399565111:245,Usability,guid,guidance,245,"@cjllanwarne: I also encountered this issue. Until the mentioned upgrade script is released, is information available that highlights the changes necessary to migrate from draft 2 (or 3/1) to WDL 1.0? My files are in draft-2 format. Any sort of guidance about what's different between the versions would be helpful. Doing a visual diff of the `SPEC.md` files isn't ideal... Somewhat related: Is there an estimate of when womtool will have `-imports` exposed as a parameter?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3762#issuecomment-399565111
https://github.com/broadinstitute/cromwell/pull/3772#issuecomment-397102286:19,Availability,failure,failures,19,Ignoring the PAPI2 failures resulting from their API change,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3772#issuecomment-397102286
https://github.com/broadinstitute/cromwell/issues/3774#issuecomment-397402360:78,Availability,down,down,78,@elerch -- I got IntelliJ fired up and can step through to see if I can track down what is happening...,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3774#issuecomment-397402360
https://github.com/broadinstitute/cromwell/issues/3774#issuecomment-399490552:90,Usability,clear,clear,90,"This is a duplicate of #3804. I'll keep both open for the time being - that issue is more clear about what is going on at a high level, but this has good technical detail.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3774#issuecomment-399490552
https://github.com/broadinstitute/cromwell/pull/3780#issuecomment-397458758:56,Testability,log,logic,56,"regarding:; > Will it then make sense to change similar logic inside ... ... yes, I think it does",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3780#issuecomment-397458758
https://github.com/broadinstitute/cromwell/issues/3784#issuecomment-397676775:170,Modifiability,config,config,170,"Hi Evan thanks for reporting this. That change in the way `tmpDir` is calculated actually wasn't actually intentional, let me see if I can move things around so your old config value still works. Also `tmpDir` chmoding will be [turned off](https://github.com/broadinstitute/cromwell/pull/3735) in Dockerless environments with Cromwell 33.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3784#issuecomment-397676775
https://github.com/broadinstitute/cromwell/issues/3785#issuecomment-402780568:448,Modifiability,portab,portable,448,"@EvanTheB Yeah, `File` in WDL is **not** supposed to reference a directory (as you noted in your followup, that's a whole separate topic). It manages to work-ish by happenstance on shared filesystem backends, as you discovered - we came across that a little while back. . I'd call it one of those things where if it Works For You then knock yourself out but keep in mind that it's not supported behavior and if your WDL relies on it they'll not be portable in cloud environments.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3785#issuecomment-402780568
https://github.com/broadinstitute/cromwell/issues/3786#issuecomment-398204194:2743,Deployability,update,update,2743,"of having multiple processes access the same embedded DB, is to research spinning up a background daemon db process, which do support multiple connections. Links to consider when defining acceptance criteria are below. . Re: our existing/proposed HSQLDB usage; - Cromwell's `database.metadata` and `database.engine` when absent both [fall back to the root `database` stanza.](https://github.com/broadinstitute/cromwell/blob/088e12d97dd18f463e6a387a6ffb002d9725cbe4/services/src/main/scala/cromwell/services/ServicesStore.scala#L12); - [""This allows each instance of a database object to use a clean, and different, in memory database.""](https://github.com/broadinstitute/cromwell/blob/a8a605ed1f2f2d2de2db9b05c395a2c87ebfc295/database/sql/src/main/scala/cromwell/database/sql/SqlDatabase.scala#L17-L39); - [""only one Java process at a time can make in-process connections to a given _file:_ database""](http://hsqldb.org/doc/guide/running-chapt.html#rgc_inprocess); - [""Several different programs can connect to the server and retrieve or update information.""](http://hsqldb.org/doc/2.0/guide/running-chapt.html#rgc_server_modes). Re: SQLite; - [""You can't add a constraint to existing table in SQLite""](https://stackoverflow.com/a/15498225); - [""use caution: this locking mechanism might not work correctly if the database file is kept on an NFS filesystem""](https://www.sqlite.org/faq.html#q5); - We often change our table uniqueness using [Liquibase](https://github.com/broadinstitute/cromwell/pull/3553/files#diff-76feec217bb5aaed111d4c3c11ead546). HSQLDB stopped supporting [unique indexes years ago](http://www.hsqldb.org/doc/1.8/guide/ch09.html#create_index-section), so Cromwell only uses their cousin the [unique constraint](https://community.oracle.com/thread/1033157). Meanwhile SQLite does not allow adding/dropping a unique constraint without [copying the whole table](https://stackoverflow.com/a/42013422) but does support [adding/dropping a unique index](https://www.sqlite.org/lang_crea",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3786#issuecomment-398204194
https://github.com/broadinstitute/cromwell/issues/3786#issuecomment-398204194:125,Integrability,depend,depending,125,"Something like this will be great for users who just want something simple. We may need to add warnings to the Cromwell docs depending on how this ticket is implemented. The specific behavior this ticket aims to emulate / implement should be further refined with respect to HSQLDB. Plugging in `file:` will absolutely work for ""hello world"". But if one runs cromwell(s) the wrong way the db may become corrupted/deadlocked negating the ability to call-cache. Many databases have minimal to no support for sharing an embedded instance between concurrent procs. SQLite has the most ""support"" afaik but a) would require _a lot_ of custom Cromwell code, and b) still has other issues such as in NFS environments. Depending on whomever this ticket is aimed at, if they're using an HPC environment like our methods users do we'd have to be careful not to store a multiprocess embedded DB on NFS. Today with HSQLDB `mem:` cromwell uses a pair of ephemeral database connection pools. I'm not sure the behavior if both pools are pointed at the same HSQLDB `file:`, but I think it might work as the docs only warn of connecting from multi-process not multi-pool. The default config mentioned in this ticket may still consider using separate `file:` instances just in case. All issues above have workarounds with varying degrees of difficulty and/or documentation warnings. For example one could clarify the documentation with ""Cromwell only supports one instance connecting to the pair of default _file:_ databases at a time."" Or: ""Cromwell only supports call caching when running a workflow with the same name"" because we did something like generate the db file based on the workflow name. Another option, instead of having multiple processes access the same embedded DB, is to research spinning up a background daemon db process, which do support multiple connections. Links to consider when defining acceptance criteria are below. . Re: our existing/proposed HSQLDB usage; - Cromwell's `database.metadata` an",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3786#issuecomment-398204194
https://github.com/broadinstitute/cromwell/issues/3786#issuecomment-398204194:709,Integrability,Depend,Depending,709,"Something like this will be great for users who just want something simple. We may need to add warnings to the Cromwell docs depending on how this ticket is implemented. The specific behavior this ticket aims to emulate / implement should be further refined with respect to HSQLDB. Plugging in `file:` will absolutely work for ""hello world"". But if one runs cromwell(s) the wrong way the db may become corrupted/deadlocked negating the ability to call-cache. Many databases have minimal to no support for sharing an embedded instance between concurrent procs. SQLite has the most ""support"" afaik but a) would require _a lot_ of custom Cromwell code, and b) still has other issues such as in NFS environments. Depending on whomever this ticket is aimed at, if they're using an HPC environment like our methods users do we'd have to be careful not to store a multiprocess embedded DB on NFS. Today with HSQLDB `mem:` cromwell uses a pair of ephemeral database connection pools. I'm not sure the behavior if both pools are pointed at the same HSQLDB `file:`, but I think it might work as the docs only warn of connecting from multi-process not multi-pool. The default config mentioned in this ticket may still consider using separate `file:` instances just in case. All issues above have workarounds with varying degrees of difficulty and/or documentation warnings. For example one could clarify the documentation with ""Cromwell only supports one instance connecting to the pair of default _file:_ databases at a time."" Or: ""Cromwell only supports call caching when running a workflow with the same name"" because we did something like generate the db file based on the workflow name. Another option, instead of having multiple processes access the same embedded DB, is to research spinning up a background daemon db process, which do support multiple connections. Links to consider when defining acceptance criteria are below. . Re: our existing/proposed HSQLDB usage; - Cromwell's `database.metadata` an",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3786#issuecomment-398204194
https://github.com/broadinstitute/cromwell/issues/3786#issuecomment-398204194:1165,Modifiability,config,config,1165,"s to emulate / implement should be further refined with respect to HSQLDB. Plugging in `file:` will absolutely work for ""hello world"". But if one runs cromwell(s) the wrong way the db may become corrupted/deadlocked negating the ability to call-cache. Many databases have minimal to no support for sharing an embedded instance between concurrent procs. SQLite has the most ""support"" afaik but a) would require _a lot_ of custom Cromwell code, and b) still has other issues such as in NFS environments. Depending on whomever this ticket is aimed at, if they're using an HPC environment like our methods users do we'd have to be careful not to store a multiprocess embedded DB on NFS. Today with HSQLDB `mem:` cromwell uses a pair of ephemeral database connection pools. I'm not sure the behavior if both pools are pointed at the same HSQLDB `file:`, but I think it might work as the docs only warn of connecting from multi-process not multi-pool. The default config mentioned in this ticket may still consider using separate `file:` instances just in case. All issues above have workarounds with varying degrees of difficulty and/or documentation warnings. For example one could clarify the documentation with ""Cromwell only supports one instance connecting to the pair of default _file:_ databases at a time."" Or: ""Cromwell only supports call caching when running a workflow with the same name"" because we did something like generate the db file based on the workflow name. Another option, instead of having multiple processes access the same embedded DB, is to research spinning up a background daemon db process, which do support multiple connections. Links to consider when defining acceptance criteria are below. . Re: our existing/proposed HSQLDB usage; - Cromwell's `database.metadata` and `database.engine` when absent both [fall back to the root `database` stanza.](https://github.com/broadinstitute/cromwell/blob/088e12d97dd18f463e6a387a6ffb002d9725cbe4/services/src/main/scala/cromwell/serv",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3786#issuecomment-398204194
https://github.com/broadinstitute/cromwell/issues/3786#issuecomment-398204194:452,Performance,cache,cache,452,"Something like this will be great for users who just want something simple. We may need to add warnings to the Cromwell docs depending on how this ticket is implemented. The specific behavior this ticket aims to emulate / implement should be further refined with respect to HSQLDB. Plugging in `file:` will absolutely work for ""hello world"". But if one runs cromwell(s) the wrong way the db may become corrupted/deadlocked negating the ability to call-cache. Many databases have minimal to no support for sharing an embedded instance between concurrent procs. SQLite has the most ""support"" afaik but a) would require _a lot_ of custom Cromwell code, and b) still has other issues such as in NFS environments. Depending on whomever this ticket is aimed at, if they're using an HPC environment like our methods users do we'd have to be careful not to store a multiprocess embedded DB on NFS. Today with HSQLDB `mem:` cromwell uses a pair of ephemeral database connection pools. I'm not sure the behavior if both pools are pointed at the same HSQLDB `file:`, but I think it might work as the docs only warn of connecting from multi-process not multi-pool. The default config mentioned in this ticket may still consider using separate `file:` instances just in case. All issues above have workarounds with varying degrees of difficulty and/or documentation warnings. For example one could clarify the documentation with ""Cromwell only supports one instance connecting to the pair of default _file:_ databases at a time."" Or: ""Cromwell only supports call caching when running a workflow with the same name"" because we did something like generate the db file based on the workflow name. Another option, instead of having multiple processes access the same embedded DB, is to research spinning up a background daemon db process, which do support multiple connections. Links to consider when defining acceptance criteria are below. . Re: our existing/proposed HSQLDB usage; - Cromwell's `database.metadata` an",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3786#issuecomment-398204194
https://github.com/broadinstitute/cromwell/issues/3786#issuecomment-398204194:542,Performance,concurren,concurrent,542,"Something like this will be great for users who just want something simple. We may need to add warnings to the Cromwell docs depending on how this ticket is implemented. The specific behavior this ticket aims to emulate / implement should be further refined with respect to HSQLDB. Plugging in `file:` will absolutely work for ""hello world"". But if one runs cromwell(s) the wrong way the db may become corrupted/deadlocked negating the ability to call-cache. Many databases have minimal to no support for sharing an embedded instance between concurrent procs. SQLite has the most ""support"" afaik but a) would require _a lot_ of custom Cromwell code, and b) still has other issues such as in NFS environments. Depending on whomever this ticket is aimed at, if they're using an HPC environment like our methods users do we'd have to be careful not to store a multiprocess embedded DB on NFS. Today with HSQLDB `mem:` cromwell uses a pair of ephemeral database connection pools. I'm not sure the behavior if both pools are pointed at the same HSQLDB `file:`, but I think it might work as the docs only warn of connecting from multi-process not multi-pool. The default config mentioned in this ticket may still consider using separate `file:` instances just in case. All issues above have workarounds with varying degrees of difficulty and/or documentation warnings. For example one could clarify the documentation with ""Cromwell only supports one instance connecting to the pair of default _file:_ databases at a time."" Or: ""Cromwell only supports call caching when running a workflow with the same name"" because we did something like generate the db file based on the workflow name. Another option, instead of having multiple processes access the same embedded DB, is to research spinning up a background daemon db process, which do support multiple connections. Links to consider when defining acceptance criteria are below. . Re: our existing/proposed HSQLDB usage; - Cromwell's `database.metadata` an",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3786#issuecomment-398204194
https://github.com/broadinstitute/cromwell/issues/3786#issuecomment-398204194:1734,Security,access,access,1734,"ng an HPC environment like our methods users do we'd have to be careful not to store a multiprocess embedded DB on NFS. Today with HSQLDB `mem:` cromwell uses a pair of ephemeral database connection pools. I'm not sure the behavior if both pools are pointed at the same HSQLDB `file:`, but I think it might work as the docs only warn of connecting from multi-process not multi-pool. The default config mentioned in this ticket may still consider using separate `file:` instances just in case. All issues above have workarounds with varying degrees of difficulty and/or documentation warnings. For example one could clarify the documentation with ""Cromwell only supports one instance connecting to the pair of default _file:_ databases at a time."" Or: ""Cromwell only supports call caching when running a workflow with the same name"" because we did something like generate the db file based on the workflow name. Another option, instead of having multiple processes access the same embedded DB, is to research spinning up a background daemon db process, which do support multiple connections. Links to consider when defining acceptance criteria are below. . Re: our existing/proposed HSQLDB usage; - Cromwell's `database.metadata` and `database.engine` when absent both [fall back to the root `database` stanza.](https://github.com/broadinstitute/cromwell/blob/088e12d97dd18f463e6a387a6ffb002d9725cbe4/services/src/main/scala/cromwell/services/ServicesStore.scala#L12); - [""This allows each instance of a database object to use a clean, and different, in memory database.""](https://github.com/broadinstitute/cromwell/blob/a8a605ed1f2f2d2de2db9b05c395a2c87ebfc295/database/sql/src/main/scala/cromwell/database/sql/SqlDatabase.scala#L17-L39); - [""only one Java process at a time can make in-process connections to a given _file:_ database""](http://hsqldb.org/doc/guide/running-chapt.html#rgc_inprocess); - [""Several different programs can connect to the server and retrieve or update information.""](http:",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3786#issuecomment-398204194
https://github.com/broadinstitute/cromwell/issues/3786#issuecomment-398204194:68,Usability,simpl,simple,68,"Something like this will be great for users who just want something simple. We may need to add warnings to the Cromwell docs depending on how this ticket is implemented. The specific behavior this ticket aims to emulate / implement should be further refined with respect to HSQLDB. Plugging in `file:` will absolutely work for ""hello world"". But if one runs cromwell(s) the wrong way the db may become corrupted/deadlocked negating the ability to call-cache. Many databases have minimal to no support for sharing an embedded instance between concurrent procs. SQLite has the most ""support"" afaik but a) would require _a lot_ of custom Cromwell code, and b) still has other issues such as in NFS environments. Depending on whomever this ticket is aimed at, if they're using an HPC environment like our methods users do we'd have to be careful not to store a multiprocess embedded DB on NFS. Today with HSQLDB `mem:` cromwell uses a pair of ephemeral database connection pools. I'm not sure the behavior if both pools are pointed at the same HSQLDB `file:`, but I think it might work as the docs only warn of connecting from multi-process not multi-pool. The default config mentioned in this ticket may still consider using separate `file:` instances just in case. All issues above have workarounds with varying degrees of difficulty and/or documentation warnings. For example one could clarify the documentation with ""Cromwell only supports one instance connecting to the pair of default _file:_ databases at a time."" Or: ""Cromwell only supports call caching when running a workflow with the same name"" because we did something like generate the db file based on the workflow name. Another option, instead of having multiple processes access the same embedded DB, is to research spinning up a background daemon db process, which do support multiple connections. Links to consider when defining acceptance criteria are below. . Re: our existing/proposed HSQLDB usage; - Cromwell's `database.metadata` an",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3786#issuecomment-398204194
https://github.com/broadinstitute/cromwell/issues/3786#issuecomment-398204194:2629,Usability,guid,guide,2629,"erate the db file based on the workflow name. Another option, instead of having multiple processes access the same embedded DB, is to research spinning up a background daemon db process, which do support multiple connections. Links to consider when defining acceptance criteria are below. . Re: our existing/proposed HSQLDB usage; - Cromwell's `database.metadata` and `database.engine` when absent both [fall back to the root `database` stanza.](https://github.com/broadinstitute/cromwell/blob/088e12d97dd18f463e6a387a6ffb002d9725cbe4/services/src/main/scala/cromwell/services/ServicesStore.scala#L12); - [""This allows each instance of a database object to use a clean, and different, in memory database.""](https://github.com/broadinstitute/cromwell/blob/a8a605ed1f2f2d2de2db9b05c395a2c87ebfc295/database/sql/src/main/scala/cromwell/database/sql/SqlDatabase.scala#L17-L39); - [""only one Java process at a time can make in-process connections to a given _file:_ database""](http://hsqldb.org/doc/guide/running-chapt.html#rgc_inprocess); - [""Several different programs can connect to the server and retrieve or update information.""](http://hsqldb.org/doc/2.0/guide/running-chapt.html#rgc_server_modes). Re: SQLite; - [""You can't add a constraint to existing table in SQLite""](https://stackoverflow.com/a/15498225); - [""use caution: this locking mechanism might not work correctly if the database file is kept on an NFS filesystem""](https://www.sqlite.org/faq.html#q5); - We often change our table uniqueness using [Liquibase](https://github.com/broadinstitute/cromwell/pull/3553/files#diff-76feec217bb5aaed111d4c3c11ead546). HSQLDB stopped supporting [unique indexes years ago](http://www.hsqldb.org/doc/1.8/guide/ch09.html#create_index-section), so Cromwell only uses their cousin the [unique constraint](https://community.oracle.com/thread/1033157). Meanwhile SQLite does not allow adding/dropping a unique constraint without [copying the whole table](https://stackoverflow.com/a/42013422) but does su",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3786#issuecomment-398204194
https://github.com/broadinstitute/cromwell/issues/3786#issuecomment-398204194:2791,Usability,guid,guide,2791,"nd daemon db process, which do support multiple connections. Links to consider when defining acceptance criteria are below. . Re: our existing/proposed HSQLDB usage; - Cromwell's `database.metadata` and `database.engine` when absent both [fall back to the root `database` stanza.](https://github.com/broadinstitute/cromwell/blob/088e12d97dd18f463e6a387a6ffb002d9725cbe4/services/src/main/scala/cromwell/services/ServicesStore.scala#L12); - [""This allows each instance of a database object to use a clean, and different, in memory database.""](https://github.com/broadinstitute/cromwell/blob/a8a605ed1f2f2d2de2db9b05c395a2c87ebfc295/database/sql/src/main/scala/cromwell/database/sql/SqlDatabase.scala#L17-L39); - [""only one Java process at a time can make in-process connections to a given _file:_ database""](http://hsqldb.org/doc/guide/running-chapt.html#rgc_inprocess); - [""Several different programs can connect to the server and retrieve or update information.""](http://hsqldb.org/doc/2.0/guide/running-chapt.html#rgc_server_modes). Re: SQLite; - [""You can't add a constraint to existing table in SQLite""](https://stackoverflow.com/a/15498225); - [""use caution: this locking mechanism might not work correctly if the database file is kept on an NFS filesystem""](https://www.sqlite.org/faq.html#q5); - We often change our table uniqueness using [Liquibase](https://github.com/broadinstitute/cromwell/pull/3553/files#diff-76feec217bb5aaed111d4c3c11ead546). HSQLDB stopped supporting [unique indexes years ago](http://www.hsqldb.org/doc/1.8/guide/ch09.html#create_index-section), so Cromwell only uses their cousin the [unique constraint](https://community.oracle.com/thread/1033157). Meanwhile SQLite does not allow adding/dropping a unique constraint without [copying the whole table](https://stackoverflow.com/a/42013422) but does support [adding/dropping a unique index](https://www.sqlite.org/lang_createindex.html).; - Additionally, SQLite will need a bunch of custom code for its [JDBC-lite imp",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3786#issuecomment-398204194
https://github.com/broadinstitute/cromwell/issues/3786#issuecomment-398204194:3340,Usability,guid,guide,3340,".metadata` and `database.engine` when absent both [fall back to the root `database` stanza.](https://github.com/broadinstitute/cromwell/blob/088e12d97dd18f463e6a387a6ffb002d9725cbe4/services/src/main/scala/cromwell/services/ServicesStore.scala#L12); - [""This allows each instance of a database object to use a clean, and different, in memory database.""](https://github.com/broadinstitute/cromwell/blob/a8a605ed1f2f2d2de2db9b05c395a2c87ebfc295/database/sql/src/main/scala/cromwell/database/sql/SqlDatabase.scala#L17-L39); - [""only one Java process at a time can make in-process connections to a given _file:_ database""](http://hsqldb.org/doc/guide/running-chapt.html#rgc_inprocess); - [""Several different programs can connect to the server and retrieve or update information.""](http://hsqldb.org/doc/2.0/guide/running-chapt.html#rgc_server_modes). Re: SQLite; - [""You can't add a constraint to existing table in SQLite""](https://stackoverflow.com/a/15498225); - [""use caution: this locking mechanism might not work correctly if the database file is kept on an NFS filesystem""](https://www.sqlite.org/faq.html#q5); - We often change our table uniqueness using [Liquibase](https://github.com/broadinstitute/cromwell/pull/3553/files#diff-76feec217bb5aaed111d4c3c11ead546). HSQLDB stopped supporting [unique indexes years ago](http://www.hsqldb.org/doc/1.8/guide/ch09.html#create_index-section), so Cromwell only uses their cousin the [unique constraint](https://community.oracle.com/thread/1033157). Meanwhile SQLite does not allow adding/dropping a unique constraint without [copying the whole table](https://stackoverflow.com/a/42013422) but does support [adding/dropping a unique index](https://www.sqlite.org/lang_createindex.html).; - Additionally, SQLite will need a bunch of custom code for its [JDBC-lite implementation](https://stackoverflow.com/a/48643377). **TL;DR Be sure of the use case before verifying that ""hello world"" passes, and consider labeling any implementation as ""experimental""**",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3786#issuecomment-398204194
https://github.com/broadinstitute/cromwell/pull/3789#issuecomment-397692617:42,Deployability,hotfix,hotfix,42,I'd also like to cherry pick this onto 32 hotfix if the shorebirds allow.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3789#issuecomment-397692617
https://github.com/broadinstitute/cromwell/issues/3792#issuecomment-398081689:787,Integrability,protocol,protocols,787,"From SLACK:. ```; 1. Can you make sure CaaS conforms to this loose list ‚Äî ask questions about what any of this means ‚Äî https://broadinstitute.atlassian.net/wiki/spaces/DSDE/pages/229212218/New+Service+Checklist. 2. This is an example of the ‚Äúpaperwork‚Äù required ‚Äî https://docs.google.com/document/d/1vv0thxw1ESyO6k9pP1R0qqo1atEiMn4f-ynx6ns972Y ‚Äî we‚Äôll need one of these for CaaS; ```; ```; 1. System diagram ‚Äî shows the different components and how they connect to each other. 2. Data flow diagram ‚Äî slightly different ‚Äî shows how the data moves through the system. This should have a paragraph or so description walking through the different steps the data takes. . 3. Network Diagram ‚Äî Actual network connectivity between components and how they connect to each other (inlcuding ports/protocols). Yes, I know they all sound the same. They‚Äôre really really similar. They‚Äôre not the same.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3792#issuecomment-398081689
https://github.com/broadinstitute/cromwell/issues/3799#issuecomment-401347492:26,Deployability,pipeline,pipelines,26,"from Aaron Kemp of Google pipelines, emphasis mine:. ""In the short term, I think the original option we discussed is the best: try without, if it fails, try with. **You will not be billed for the failed request**.""",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3799#issuecomment-401347492
https://github.com/broadinstitute/cromwell/issues/3799#issuecomment-401347618:46,Performance,cache,cached,46,understanding that we are going to proceed w/ cached API calls approach. Just noting that we are not billed for the failed request.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3799#issuecomment-401347618
https://github.com/broadinstitute/cromwell/issues/3799#issuecomment-401420929:125,Availability,robust,robust,125,"@danbills I think I'm actually changing my mind and leaning towards doing the try/retry instead:; 1) It seems generally more robust to be able to fallback to that (compared to caching where if we can't get the info or we get it wrong we'd fail workflows); 2) Talking to @kshakir, things seem to be moving towards more generic implementations of filesystems. The retry logic could be lifted up to the generic implementation whenever it happens (which might be harder to do with a caching logic); 3) We can always add caching later if we see Cromwell struggling too much; 4) Unlike what I was thinking first, it actually simplifies the code a little and even more testing (testing that things get cached properly and for the right amount of time is a pain). Thoughts ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3799#issuecomment-401420929
https://github.com/broadinstitute/cromwell/issues/3799#issuecomment-401420929:695,Performance,cache,cached,695,"@danbills I think I'm actually changing my mind and leaning towards doing the try/retry instead:; 1) It seems generally more robust to be able to fallback to that (compared to caching where if we can't get the info or we get it wrong we'd fail workflows); 2) Talking to @kshakir, things seem to be moving towards more generic implementations of filesystems. The retry logic could be lifted up to the generic implementation whenever it happens (which might be harder to do with a caching logic); 3) We can always add caching later if we see Cromwell struggling too much; 4) Unlike what I was thinking first, it actually simplifies the code a little and even more testing (testing that things get cached properly and for the right amount of time is a pain). Thoughts ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3799#issuecomment-401420929
https://github.com/broadinstitute/cromwell/issues/3799#issuecomment-401420929:368,Testability,log,logic,368,"@danbills I think I'm actually changing my mind and leaning towards doing the try/retry instead:; 1) It seems generally more robust to be able to fallback to that (compared to caching where if we can't get the info or we get it wrong we'd fail workflows); 2) Talking to @kshakir, things seem to be moving towards more generic implementations of filesystems. The retry logic could be lifted up to the generic implementation whenever it happens (which might be harder to do with a caching logic); 3) We can always add caching later if we see Cromwell struggling too much; 4) Unlike what I was thinking first, it actually simplifies the code a little and even more testing (testing that things get cached properly and for the right amount of time is a pain). Thoughts ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3799#issuecomment-401420929
https://github.com/broadinstitute/cromwell/issues/3799#issuecomment-401420929:487,Testability,log,logic,487,"@danbills I think I'm actually changing my mind and leaning towards doing the try/retry instead:; 1) It seems generally more robust to be able to fallback to that (compared to caching where if we can't get the info or we get it wrong we'd fail workflows); 2) Talking to @kshakir, things seem to be moving towards more generic implementations of filesystems. The retry logic could be lifted up to the generic implementation whenever it happens (which might be harder to do with a caching logic); 3) We can always add caching later if we see Cromwell struggling too much; 4) Unlike what I was thinking first, it actually simplifies the code a little and even more testing (testing that things get cached properly and for the right amount of time is a pain). Thoughts ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3799#issuecomment-401420929
https://github.com/broadinstitute/cromwell/issues/3799#issuecomment-401420929:662,Testability,test,testing,662,"@danbills I think I'm actually changing my mind and leaning towards doing the try/retry instead:; 1) It seems generally more robust to be able to fallback to that (compared to caching where if we can't get the info or we get it wrong we'd fail workflows); 2) Talking to @kshakir, things seem to be moving towards more generic implementations of filesystems. The retry logic could be lifted up to the generic implementation whenever it happens (which might be harder to do with a caching logic); 3) We can always add caching later if we see Cromwell struggling too much; 4) Unlike what I was thinking first, it actually simplifies the code a little and even more testing (testing that things get cached properly and for the right amount of time is a pain). Thoughts ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3799#issuecomment-401420929
https://github.com/broadinstitute/cromwell/issues/3799#issuecomment-401420929:671,Testability,test,testing,671,"@danbills I think I'm actually changing my mind and leaning towards doing the try/retry instead:; 1) It seems generally more robust to be able to fallback to that (compared to caching where if we can't get the info or we get it wrong we'd fail workflows); 2) Talking to @kshakir, things seem to be moving towards more generic implementations of filesystems. The retry logic could be lifted up to the generic implementation whenever it happens (which might be harder to do with a caching logic); 3) We can always add caching later if we see Cromwell struggling too much; 4) Unlike what I was thinking first, it actually simplifies the code a little and even more testing (testing that things get cached properly and for the right amount of time is a pain). Thoughts ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3799#issuecomment-401420929
https://github.com/broadinstitute/cromwell/issues/3799#issuecomment-401420929:619,Usability,simpl,simplifies,619,"@danbills I think I'm actually changing my mind and leaning towards doing the try/retry instead:; 1) It seems generally more robust to be able to fallback to that (compared to caching where if we can't get the info or we get it wrong we'd fail workflows); 2) Talking to @kshakir, things seem to be moving towards more generic implementations of filesystems. The retry logic could be lifted up to the generic implementation whenever it happens (which might be harder to do with a caching logic); 3) We can always add caching later if we see Cromwell struggling too much; 4) Unlike what I was thinking first, it actually simplifies the code a little and even more testing (testing that things get cached properly and for the right amount of time is a pain). Thoughts ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3799#issuecomment-401420929
https://github.com/broadinstitute/cromwell/issues/3799#issuecomment-401425590:15,Usability,simpl,simpler,15,* It does seem simpler; * not 100% sure how it plays into generic impl; * I think gsutil is getting smarter soon per the hint we got,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3799#issuecomment-401425590
https://github.com/broadinstitute/cromwell/pull/3800#issuecomment-398948843:271,Safety,risk,risk,271,"ToL: (sorry for the seagulling...) I did find the names and semantics of these new filters a tiny bit confusing and it started me wondering whether these combinations of various label filters are likely to get harder to manage as more filter types get dreamed up. At the risk of ""if you have a hammer every problem starts to look like a nail"", I wonder whether a basic expression style syntax will be a good idea at some point, something like e.g.:. (""Label1"" && ""Label2"" && !""Label3"") || ""Label4"". If that ever does sound worth pursuing, there's a cool looking (previously core Scala) library which might be able to help: https://github.com/scala/scala-parser-combinators",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3800#issuecomment-398948843
https://github.com/broadinstitute/cromwell/pull/3801#issuecomment-399141015:73,Modifiability,config,configured,73,"Well nevermind, this does not seem to help, still seeing ; ```; Exceeded configured max-open-requests value of [128]. This means that the request queue of this pool (HostConnectionPoolSetup(localhost,...; ```. We might want to increase the `max-open-requests` conf setting instead ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3801#issuecomment-399141015
https://github.com/broadinstitute/cromwell/pull/3801#issuecomment-399141015:146,Performance,queue,queue,146,"Well nevermind, this does not seem to help, still seeing ; ```; Exceeded configured max-open-requests value of [128]. This means that the request queue of this pool (HostConnectionPoolSetup(localhost,...; ```. We might want to increase the `max-open-requests` conf setting instead ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3801#issuecomment-399141015
https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-400025987:753,Deployability,install,installed,753,"@danbills The Orchestrator pattern as described above is what we discussed. . Per your other questions, the answer is that AWS Batch does not take a array of arbitrary scripts as an option, nor can you override a Docker container's `ENTRY_POINT` to supply your own script if the entry point of the container has been changed from the default shell. You can only specify an array to pass into Docker daemon's `CMD`. Speaking of default shells, the other arguments against a set of shell scripts is that it limits the set of containers that can be called from a WDL. For example, the current Cromwell scripts that are injected into the container assume Bash support, but by default Alpine Linux (and many containers that build off of it) do not have Bash installed. . Most of the time the above two items are safe assumptions, but not always, hence the current plan to implement data staging via a sibling container approach similar to how CI systems are deployed today. For inspiration, I refer to [Dave Hein's excellent article on running sibling containers in lieu of docker-in-docker](https://www.develves.net/blogs/asd/2016-05-27-alternative-to-docker-in-docker/)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-400025987
https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-400025987:953,Deployability,deploy,deployed,953,"@danbills The Orchestrator pattern as described above is what we discussed. . Per your other questions, the answer is that AWS Batch does not take a array of arbitrary scripts as an option, nor can you override a Docker container's `ENTRY_POINT` to supply your own script if the entry point of the container has been changed from the default shell. You can only specify an array to pass into Docker daemon's `CMD`. Speaking of default shells, the other arguments against a set of shell scripts is that it limits the set of containers that can be called from a WDL. For example, the current Cromwell scripts that are injected into the container assume Bash support, but by default Alpine Linux (and many containers that build off of it) do not have Bash installed. . Most of the time the above two items are safe assumptions, but not always, hence the current plan to implement data staging via a sibling container approach similar to how CI systems are deployed today. For inspiration, I refer to [Dave Hein's excellent article on running sibling containers in lieu of docker-in-docker](https://www.develves.net/blogs/asd/2016-05-27-alternative-to-docker-in-docker/)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-400025987
https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-400025987:616,Integrability,inject,injected,616,"@danbills The Orchestrator pattern as described above is what we discussed. . Per your other questions, the answer is that AWS Batch does not take a array of arbitrary scripts as an option, nor can you override a Docker container's `ENTRY_POINT` to supply your own script if the entry point of the container has been changed from the default shell. You can only specify an array to pass into Docker daemon's `CMD`. Speaking of default shells, the other arguments against a set of shell scripts is that it limits the set of containers that can be called from a WDL. For example, the current Cromwell scripts that are injected into the container assume Bash support, but by default Alpine Linux (and many containers that build off of it) do not have Bash installed. . Most of the time the above two items are safe assumptions, but not always, hence the current plan to implement data staging via a sibling container approach similar to how CI systems are deployed today. For inspiration, I refer to [Dave Hein's excellent article on running sibling containers in lieu of docker-in-docker](https://www.develves.net/blogs/asd/2016-05-27-alternative-to-docker-in-docker/)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-400025987
https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-400025987:807,Safety,safe,safe,807,"@danbills The Orchestrator pattern as described above is what we discussed. . Per your other questions, the answer is that AWS Batch does not take a array of arbitrary scripts as an option, nor can you override a Docker container's `ENTRY_POINT` to supply your own script if the entry point of the container has been changed from the default shell. You can only specify an array to pass into Docker daemon's `CMD`. Speaking of default shells, the other arguments against a set of shell scripts is that it limits the set of containers that can be called from a WDL. For example, the current Cromwell scripts that are injected into the container assume Bash support, but by default Alpine Linux (and many containers that build off of it) do not have Bash installed. . Most of the time the above two items are safe assumptions, but not always, hence the current plan to implement data staging via a sibling container approach similar to how CI systems are deployed today. For inspiration, I refer to [Dave Hein's excellent article on running sibling containers in lieu of docker-in-docker](https://www.develves.net/blogs/asd/2016-05-27-alternative-to-docker-in-docker/)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-400025987
https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-400025987:616,Security,inject,injected,616,"@danbills The Orchestrator pattern as described above is what we discussed. . Per your other questions, the answer is that AWS Batch does not take a array of arbitrary scripts as an option, nor can you override a Docker container's `ENTRY_POINT` to supply your own script if the entry point of the container has been changed from the default shell. You can only specify an array to pass into Docker daemon's `CMD`. Speaking of default shells, the other arguments against a set of shell scripts is that it limits the set of containers that can be called from a WDL. For example, the current Cromwell scripts that are injected into the container assume Bash support, but by default Alpine Linux (and many containers that build off of it) do not have Bash installed. . Most of the time the above two items are safe assumptions, but not always, hence the current plan to implement data staging via a sibling container approach similar to how CI systems are deployed today. For inspiration, I refer to [Dave Hein's excellent article on running sibling containers in lieu of docker-in-docker](https://www.develves.net/blogs/asd/2016-05-27-alternative-to-docker-in-docker/)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-400025987
https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-401398435:363,Energy Efficiency,monitor,monitor,363,"So, quick thoughts on this. +1 on @delagoya's sidecar container concept (with some concerns I'll mention below). When implementing #3835 I had this issue in mind as well, along with some thoughts on implementation. My thought was to have a sidecar always running, using the [system events](https://docs.docker.com/engine/api/v1.37/#operation/SystemEvents) api to monitor for containers that have exited. At that time, it can [inspect the container](https://docs.docker.com/engine/api/v1.37/#operation/ContainerInspect), make sure it's a cromwell container, and use the volume information (in conjunction with the TASK_ID environment variable I'm setting) to find the local files and copy them out to s3. Something to consider that I don't see discussed yet on this thread: A sidecar approach requires the sidecar to have fairly permissive access to S3. On the positive side, this does alleviate the need for S3 permissions on the container running the task.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-401398435
https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-401398435:633,Modifiability,variab,variable,633,"So, quick thoughts on this. +1 on @delagoya's sidecar container concept (with some concerns I'll mention below). When implementing #3835 I had this issue in mind as well, along with some thoughts on implementation. My thought was to have a sidecar always running, using the [system events](https://docs.docker.com/engine/api/v1.37/#operation/SystemEvents) api to monitor for containers that have exited. At that time, it can [inspect the container](https://docs.docker.com/engine/api/v1.37/#operation/ContainerInspect), make sure it's a cromwell container, and use the volume information (in conjunction with the TASK_ID environment variable I'm setting) to find the local files and copy them out to s3. Something to consider that I don't see discussed yet on this thread: A sidecar approach requires the sidecar to have fairly permissive access to S3. On the positive side, this does alleviate the need for S3 permissions on the container running the task.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-401398435
https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-401398435:839,Security,access,access,839,"So, quick thoughts on this. +1 on @delagoya's sidecar container concept (with some concerns I'll mention below). When implementing #3835 I had this issue in mind as well, along with some thoughts on implementation. My thought was to have a sidecar always running, using the [system events](https://docs.docker.com/engine/api/v1.37/#operation/SystemEvents) api to monitor for containers that have exited. At that time, it can [inspect the container](https://docs.docker.com/engine/api/v1.37/#operation/ContainerInspect), make sure it's a cromwell container, and use the volume information (in conjunction with the TASK_ID environment variable I'm setting) to find the local files and copy them out to s3. Something to consider that I don't see discussed yet on this thread: A sidecar approach requires the sidecar to have fairly permissive access to S3. On the positive side, this does alleviate the need for S3 permissions on the container running the task.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-401398435
https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-405738068:577,Deployability,configurat,configuration,577,"So I think I'm now clear regarding the options on this thread. One option, and the original one discussed, is a container entrypoint (""Orchestrator"" as @danbills put it). Another option, which is what I originally thought was being discussed, is an always-running sidecar. That entrypoint container would then launch our target container, similar to something like https://ohsu-comp-bio.github.io/funnel/ or https://github.com/delagoya/batch-task-runner. IMHO, the entrypoint/Orchestrator introduces some unnecessary complexity. It works for a simple case, but leaves a lot of configuration as TBD. To implement this properly we'd need to implement a standard task definition for the entrypoint (or Orchestrator) container (simple), but also pass to that container all the necessary docker parameters necessary for implementing the target container (much more difficult). There is also the question of supervision for the target container as the entrypoint/Orchestrator is hiding from batch and Cromwell the actual task's status. Also, the permissions issues I brought up in my comment above apply. I also have some concerns about the implementation of this approach within Cromwell, as I believe (but I'm not certain), this scheme would require some non-trivial changes to the StandardAsyncExecutionActor class as well as the AwsBatchAsyncExecutionActor logic (likely moreso on the later). I haven't investigated, but I also have some concerns over whether this mechanism would require significant rework of the process input/output and return code. It looks like @delagoya may have considered this in the batch-task-runner repo, but I'm not clear on this after the limited time I've had reviewing the repo. So, with that in mind, I spent a bit of time researching the ""always on sidecar"" approach, which I'll reference as ""cromwell agent"" moving forward for clarity. I took a look at the limitations of the permissions issue I mentioned above, and I believe I have a workable solution. The high leve",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-405738068
https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-405738068:3113,Deployability,configurat,configuration,3113,"aven't investigated, but I also have some concerns over whether this mechanism would require significant rework of the process input/output and return code. It looks like @delagoya may have considered this in the batch-task-runner repo, but I'm not clear on this after the limited time I've had reviewing the repo. So, with that in mind, I spent a bit of time researching the ""always on sidecar"" approach, which I'll reference as ""cromwell agent"" moving forward for clarity. I took a look at the limitations of the permissions issue I mentioned above, and I believe I have a workable solution. The high level process would work like this:. 0. Each host runs the cromwell agent container similar to the way the ecs-agent operates today; 1. The cromwell agent container listens to the system events as described above; 2. When a cromwell task is started, the cromwell agent container will pause the target container (cromwell task) immediately; 3. It can then inspect the container and use the ECS ""AWS_CONTAINER_CREDENTIALS_RELATIVE_URI"" in conjunction with the ecs-agent container credentials endpoint at 169.254.170.2 to fetch the **target container credentials**; 4. Using the target container credentials, we can localize inputs, then unpause the target container; 5. Upon completion of the task (we should see this from the system events stream), we can then delocalize outputs. This process feels workable with the following advantages:. * Minimal changes to the Cromwell code base/the agent can be developed and maintained separately; * Per-task IAM roles; * No changes needed to Cromwell task definitions or containers; * Cromwell task supervision stays within AWS Batch and Cromwell; * AWS Batch Job Definition configuration does not have to pass through an intermediary. Right now I have a POC to accomplish through step 3. Unless there are objections I'm going to continue to prototype to ensure 4 and 5 work as expected, then we can make a final call either on this thread or in a meeting.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-405738068
https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-405738068:577,Modifiability,config,configuration,577,"So I think I'm now clear regarding the options on this thread. One option, and the original one discussed, is a container entrypoint (""Orchestrator"" as @danbills put it). Another option, which is what I originally thought was being discussed, is an always-running sidecar. That entrypoint container would then launch our target container, similar to something like https://ohsu-comp-bio.github.io/funnel/ or https://github.com/delagoya/batch-task-runner. IMHO, the entrypoint/Orchestrator introduces some unnecessary complexity. It works for a simple case, but leaves a lot of configuration as TBD. To implement this properly we'd need to implement a standard task definition for the entrypoint (or Orchestrator) container (simple), but also pass to that container all the necessary docker parameters necessary for implementing the target container (much more difficult). There is also the question of supervision for the target container as the entrypoint/Orchestrator is hiding from batch and Cromwell the actual task's status. Also, the permissions issues I brought up in my comment above apply. I also have some concerns about the implementation of this approach within Cromwell, as I believe (but I'm not certain), this scheme would require some non-trivial changes to the StandardAsyncExecutionActor class as well as the AwsBatchAsyncExecutionActor logic (likely moreso on the later). I haven't investigated, but I also have some concerns over whether this mechanism would require significant rework of the process input/output and return code. It looks like @delagoya may have considered this in the batch-task-runner repo, but I'm not clear on this after the limited time I've had reviewing the repo. So, with that in mind, I spent a bit of time researching the ""always on sidecar"" approach, which I'll reference as ""cromwell agent"" moving forward for clarity. I took a look at the limitations of the permissions issue I mentioned above, and I believe I have a workable solution. The high leve",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-405738068
https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-405738068:3113,Modifiability,config,configuration,3113,"aven't investigated, but I also have some concerns over whether this mechanism would require significant rework of the process input/output and return code. It looks like @delagoya may have considered this in the batch-task-runner repo, but I'm not clear on this after the limited time I've had reviewing the repo. So, with that in mind, I spent a bit of time researching the ""always on sidecar"" approach, which I'll reference as ""cromwell agent"" moving forward for clarity. I took a look at the limitations of the permissions issue I mentioned above, and I believe I have a workable solution. The high level process would work like this:. 0. Each host runs the cromwell agent container similar to the way the ecs-agent operates today; 1. The cromwell agent container listens to the system events as described above; 2. When a cromwell task is started, the cromwell agent container will pause the target container (cromwell task) immediately; 3. It can then inspect the container and use the ECS ""AWS_CONTAINER_CREDENTIALS_RELATIVE_URI"" in conjunction with the ecs-agent container credentials endpoint at 169.254.170.2 to fetch the **target container credentials**; 4. Using the target container credentials, we can localize inputs, then unpause the target container; 5. Upon completion of the task (we should see this from the system events stream), we can then delocalize outputs. This process feels workable with the following advantages:. * Minimal changes to the Cromwell code base/the agent can be developed and maintained separately; * Per-task IAM roles; * No changes needed to Cromwell task definitions or containers; * Cromwell task supervision stays within AWS Batch and Cromwell; * AWS Batch Job Definition configuration does not have to pass through an intermediary. Right now I have a POC to accomplish through step 3. Unless there are objections I'm going to continue to prototype to ensure 4 and 5 work as expected, then we can make a final call either on this thread or in a meeting.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-405738068
https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-405738068:1355,Testability,log,logic,1355,"s an always-running sidecar. That entrypoint container would then launch our target container, similar to something like https://ohsu-comp-bio.github.io/funnel/ or https://github.com/delagoya/batch-task-runner. IMHO, the entrypoint/Orchestrator introduces some unnecessary complexity. It works for a simple case, but leaves a lot of configuration as TBD. To implement this properly we'd need to implement a standard task definition for the entrypoint (or Orchestrator) container (simple), but also pass to that container all the necessary docker parameters necessary for implementing the target container (much more difficult). There is also the question of supervision for the target container as the entrypoint/Orchestrator is hiding from batch and Cromwell the actual task's status. Also, the permissions issues I brought up in my comment above apply. I also have some concerns about the implementation of this approach within Cromwell, as I believe (but I'm not certain), this scheme would require some non-trivial changes to the StandardAsyncExecutionActor class as well as the AwsBatchAsyncExecutionActor logic (likely moreso on the later). I haven't investigated, but I also have some concerns over whether this mechanism would require significant rework of the process input/output and return code. It looks like @delagoya may have considered this in the batch-task-runner repo, but I'm not clear on this after the limited time I've had reviewing the repo. So, with that in mind, I spent a bit of time researching the ""always on sidecar"" approach, which I'll reference as ""cromwell agent"" moving forward for clarity. I took a look at the limitations of the permissions issue I mentioned above, and I believe I have a workable solution. The high level process would work like this:. 0. Each host runs the cromwell agent container similar to the way the ecs-agent operates today; 1. The cromwell agent container listens to the system events as described above; 2. When a cromwell task is starte",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-405738068
https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-405738068:19,Usability,clear,clear,19,"So I think I'm now clear regarding the options on this thread. One option, and the original one discussed, is a container entrypoint (""Orchestrator"" as @danbills put it). Another option, which is what I originally thought was being discussed, is an always-running sidecar. That entrypoint container would then launch our target container, similar to something like https://ohsu-comp-bio.github.io/funnel/ or https://github.com/delagoya/batch-task-runner. IMHO, the entrypoint/Orchestrator introduces some unnecessary complexity. It works for a simple case, but leaves a lot of configuration as TBD. To implement this properly we'd need to implement a standard task definition for the entrypoint (or Orchestrator) container (simple), but also pass to that container all the necessary docker parameters necessary for implementing the target container (much more difficult). There is also the question of supervision for the target container as the entrypoint/Orchestrator is hiding from batch and Cromwell the actual task's status. Also, the permissions issues I brought up in my comment above apply. I also have some concerns about the implementation of this approach within Cromwell, as I believe (but I'm not certain), this scheme would require some non-trivial changes to the StandardAsyncExecutionActor class as well as the AwsBatchAsyncExecutionActor logic (likely moreso on the later). I haven't investigated, but I also have some concerns over whether this mechanism would require significant rework of the process input/output and return code. It looks like @delagoya may have considered this in the batch-task-runner repo, but I'm not clear on this after the limited time I've had reviewing the repo. So, with that in mind, I spent a bit of time researching the ""always on sidecar"" approach, which I'll reference as ""cromwell agent"" moving forward for clarity. I took a look at the limitations of the permissions issue I mentioned above, and I believe I have a workable solution. The high leve",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-405738068
https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-405738068:544,Usability,simpl,simple,544,"So I think I'm now clear regarding the options on this thread. One option, and the original one discussed, is a container entrypoint (""Orchestrator"" as @danbills put it). Another option, which is what I originally thought was being discussed, is an always-running sidecar. That entrypoint container would then launch our target container, similar to something like https://ohsu-comp-bio.github.io/funnel/ or https://github.com/delagoya/batch-task-runner. IMHO, the entrypoint/Orchestrator introduces some unnecessary complexity. It works for a simple case, but leaves a lot of configuration as TBD. To implement this properly we'd need to implement a standard task definition for the entrypoint (or Orchestrator) container (simple), but also pass to that container all the necessary docker parameters necessary for implementing the target container (much more difficult). There is also the question of supervision for the target container as the entrypoint/Orchestrator is hiding from batch and Cromwell the actual task's status. Also, the permissions issues I brought up in my comment above apply. I also have some concerns about the implementation of this approach within Cromwell, as I believe (but I'm not certain), this scheme would require some non-trivial changes to the StandardAsyncExecutionActor class as well as the AwsBatchAsyncExecutionActor logic (likely moreso on the later). I haven't investigated, but I also have some concerns over whether this mechanism would require significant rework of the process input/output and return code. It looks like @delagoya may have considered this in the batch-task-runner repo, but I'm not clear on this after the limited time I've had reviewing the repo. So, with that in mind, I spent a bit of time researching the ""always on sidecar"" approach, which I'll reference as ""cromwell agent"" moving forward for clarity. I took a look at the limitations of the permissions issue I mentioned above, and I believe I have a workable solution. The high leve",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-405738068
https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-405738068:724,Usability,simpl,simple,724,"So I think I'm now clear regarding the options on this thread. One option, and the original one discussed, is a container entrypoint (""Orchestrator"" as @danbills put it). Another option, which is what I originally thought was being discussed, is an always-running sidecar. That entrypoint container would then launch our target container, similar to something like https://ohsu-comp-bio.github.io/funnel/ or https://github.com/delagoya/batch-task-runner. IMHO, the entrypoint/Orchestrator introduces some unnecessary complexity. It works for a simple case, but leaves a lot of configuration as TBD. To implement this properly we'd need to implement a standard task definition for the entrypoint (or Orchestrator) container (simple), but also pass to that container all the necessary docker parameters necessary for implementing the target container (much more difficult). There is also the question of supervision for the target container as the entrypoint/Orchestrator is hiding from batch and Cromwell the actual task's status. Also, the permissions issues I brought up in my comment above apply. I also have some concerns about the implementation of this approach within Cromwell, as I believe (but I'm not certain), this scheme would require some non-trivial changes to the StandardAsyncExecutionActor class as well as the AwsBatchAsyncExecutionActor logic (likely moreso on the later). I haven't investigated, but I also have some concerns over whether this mechanism would require significant rework of the process input/output and return code. It looks like @delagoya may have considered this in the batch-task-runner repo, but I'm not clear on this after the limited time I've had reviewing the repo. So, with that in mind, I spent a bit of time researching the ""always on sidecar"" approach, which I'll reference as ""cromwell agent"" moving forward for clarity. I took a look at the limitations of the permissions issue I mentioned above, and I believe I have a workable solution. The high leve",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-405738068
https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-405738068:1643,Usability,clear,clear,1643,"d need to implement a standard task definition for the entrypoint (or Orchestrator) container (simple), but also pass to that container all the necessary docker parameters necessary for implementing the target container (much more difficult). There is also the question of supervision for the target container as the entrypoint/Orchestrator is hiding from batch and Cromwell the actual task's status. Also, the permissions issues I brought up in my comment above apply. I also have some concerns about the implementation of this approach within Cromwell, as I believe (but I'm not certain), this scheme would require some non-trivial changes to the StandardAsyncExecutionActor class as well as the AwsBatchAsyncExecutionActor logic (likely moreso on the later). I haven't investigated, but I also have some concerns over whether this mechanism would require significant rework of the process input/output and return code. It looks like @delagoya may have considered this in the batch-task-runner repo, but I'm not clear on this after the limited time I've had reviewing the repo. So, with that in mind, I spent a bit of time researching the ""always on sidecar"" approach, which I'll reference as ""cromwell agent"" moving forward for clarity. I took a look at the limitations of the permissions issue I mentioned above, and I believe I have a workable solution. The high level process would work like this:. 0. Each host runs the cromwell agent container similar to the way the ecs-agent operates today; 1. The cromwell agent container listens to the system events as described above; 2. When a cromwell task is started, the cromwell agent container will pause the target container (cromwell task) immediately; 3. It can then inspect the container and use the ECS ""AWS_CONTAINER_CREDENTIALS_RELATIVE_URI"" in conjunction with the ecs-agent container credentials endpoint at 169.254.170.2 to fetch the **target container credentials**; 4. Using the target container credentials, we can localize inputs, th",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-405738068
https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-405738068:2281,Usability,pause,pause,2281,"e StandardAsyncExecutionActor class as well as the AwsBatchAsyncExecutionActor logic (likely moreso on the later). I haven't investigated, but I also have some concerns over whether this mechanism would require significant rework of the process input/output and return code. It looks like @delagoya may have considered this in the batch-task-runner repo, but I'm not clear on this after the limited time I've had reviewing the repo. So, with that in mind, I spent a bit of time researching the ""always on sidecar"" approach, which I'll reference as ""cromwell agent"" moving forward for clarity. I took a look at the limitations of the permissions issue I mentioned above, and I believe I have a workable solution. The high level process would work like this:. 0. Each host runs the cromwell agent container similar to the way the ecs-agent operates today; 1. The cromwell agent container listens to the system events as described above; 2. When a cromwell task is started, the cromwell agent container will pause the target container (cromwell task) immediately; 3. It can then inspect the container and use the ECS ""AWS_CONTAINER_CREDENTIALS_RELATIVE_URI"" in conjunction with the ecs-agent container credentials endpoint at 169.254.170.2 to fetch the **target container credentials**; 4. Using the target container credentials, we can localize inputs, then unpause the target container; 5. Upon completion of the task (we should see this from the system events stream), we can then delocalize outputs. This process feels workable with the following advantages:. * Minimal changes to the Cromwell code base/the agent can be developed and maintained separately; * Per-task IAM roles; * No changes needed to Cromwell task definitions or containers; * Cromwell task supervision stays within AWS Batch and Cromwell; * AWS Batch Job Definition configuration does not have to pass through an intermediary. Right now I have a POC to accomplish through step 3. Unless there are objections I'm going to continue",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-405738068
https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-405795490:15,Energy Efficiency,monitor,monitoring,15,"A system event monitoring and interrupt system seems way complex to me than implementing some conventions that leverage a standard task definition. At the point of submitting a process to Batch, you should already have all of the information needed to run a task, and can pass this along in a standard way to the standard task definition. This is the same information that is used to create the current job wrapping script. . FYI - the Funnel worker that is wrapped in `batch-task-runner` is modified to run stand-alone from a input JSON file, as opposed to communicating back to a Funnel server for task scheduling and distribution. The modified worker consumes the return codes passes the result back through it's own process and back to Batch. In this way, the sibling process is not hidden from Batch (or Cromwell).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-405795490
https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-405795490:605,Energy Efficiency,schedul,scheduling,605,"A system event monitoring and interrupt system seems way complex to me than implementing some conventions that leverage a standard task definition. At the point of submitting a process to Batch, you should already have all of the information needed to run a task, and can pass this along in a standard way to the standard task definition. This is the same information that is used to create the current job wrapping script. . FYI - the Funnel worker that is wrapped in `batch-task-runner` is modified to run stand-alone from a input JSON file, as opposed to communicating back to a Funnel server for task scheduling and distribution. The modified worker consumes the return codes passes the result back through it's own process and back to Batch. In this way, the sibling process is not hidden from Batch (or Cromwell).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-405795490
https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-405795490:407,Integrability,wrap,wrapping,407,"A system event monitoring and interrupt system seems way complex to me than implementing some conventions that leverage a standard task definition. At the point of submitting a process to Batch, you should already have all of the information needed to run a task, and can pass this along in a standard way to the standard task definition. This is the same information that is used to create the current job wrapping script. . FYI - the Funnel worker that is wrapped in `batch-task-runner` is modified to run stand-alone from a input JSON file, as opposed to communicating back to a Funnel server for task scheduling and distribution. The modified worker consumes the return codes passes the result back through it's own process and back to Batch. In this way, the sibling process is not hidden from Batch (or Cromwell).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-405795490
https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-405795490:458,Integrability,wrap,wrapped,458,"A system event monitoring and interrupt system seems way complex to me than implementing some conventions that leverage a standard task definition. At the point of submitting a process to Batch, you should already have all of the information needed to run a task, and can pass this along in a standard way to the standard task definition. This is the same information that is used to create the current job wrapping script. . FYI - the Funnel worker that is wrapped in `batch-task-runner` is modified to run stand-alone from a input JSON file, as opposed to communicating back to a Funnel server for task scheduling and distribution. The modified worker consumes the return codes passes the result back through it's own process and back to Batch. In this way, the sibling process is not hidden from Batch (or Cromwell).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-405795490
https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-410858494:79,Deployability,install,installed,79,@delagoya The plan is to bake this into an AMI similar to the way ecs agent is installed. It will be a container with a always-on restart policy. https://docs.docker.com/config/containers/start-containers-automatically/,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-410858494
https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-410858494:170,Modifiability,config,config,170,@delagoya The plan is to bake this into an AMI similar to the way ecs agent is installed. It will be a container with a always-on restart policy. https://docs.docker.com/config/containers/start-containers-automatically/,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-410858494
https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-413092230:329,Deployability,deploy,deploy,329,"@elerch Careful with that `always-on` restart policy from docker. In my experience, it did not re-read `env-files` (in my case those env vars are sitting on the host's `/etc/defaults/ecs`). I expected SIGHUP-like behavior when changing ecs-agent attributes like `ECS_CLUSTER`, i.e:. https://github.com/umccr/umccrise/blob/master/deploy/roles/brainstorm.umccrise-docker/files/bootstrap_instance.sh#L39. Instead, I had to resort to a systemd service that re-runs the ecs-agent docker container on boot:. https://github.com/umccr/umccrise/blob/master/deploy/roles/brainstorm.ecs-agent/tasks/main.yml#L75",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-413092230
https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-413092230:548,Deployability,deploy,deploy,548,"@elerch Careful with that `always-on` restart policy from docker. In my experience, it did not re-read `env-files` (in my case those env vars are sitting on the host's `/etc/defaults/ecs`). I expected SIGHUP-like behavior when changing ecs-agent attributes like `ECS_CLUSTER`, i.e:. https://github.com/umccr/umccrise/blob/master/deploy/roles/brainstorm.umccrise-docker/files/bootstrap_instance.sh#L39. Instead, I had to resort to a systemd service that re-runs the ecs-agent docker container on boot:. https://github.com/umccr/umccrise/blob/master/deploy/roles/brainstorm.ecs-agent/tasks/main.yml#L75",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-413092230
https://github.com/broadinstitute/cromwell/pull/3806#issuecomment-399991936:58,Testability,test,test,58,"Thanks @kshakir, squashed and rebased. I added an invalid test case too.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3806#issuecomment-399991936
https://github.com/broadinstitute/cromwell/pull/3806#issuecomment-400031053:92,Testability,test,tests,92,@cjllanwarne @kshakir could either of you merge this if your reviews have been resolved and tests pass?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3806#issuecomment-400031053
https://github.com/broadinstitute/cromwell/issues/3811#issuecomment-418892826:261,Availability,echo,echo,261,"Some sloppy experimental procedure is to blame for incorrect conclusions in the previous (deleted) comment. It's enough for the input and task name to be the same:; ```; workflow x {; call cram; call y { input:; cram = cram.scram; }; }. task cram {; command {; echo "".""; }; output {; String scram = "".""; }; }. task y {; String cram; command {; echo "".""; }; }; ```; ```; ERROR: Bad target for member access 'cram.scram': 'cram' was a String (line 4, col 21):. cram = cram.scram; ^; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3811#issuecomment-418892826
https://github.com/broadinstitute/cromwell/issues/3811#issuecomment-418892826:344,Availability,echo,echo,344,"Some sloppy experimental procedure is to blame for incorrect conclusions in the previous (deleted) comment. It's enough for the input and task name to be the same:; ```; workflow x {; call cram; call y { input:; cram = cram.scram; }; }. task cram {; command {; echo "".""; }; output {; String scram = "".""; }; }. task y {; String cram; command {; echo "".""; }; }; ```; ```; ERROR: Bad target for member access 'cram.scram': 'cram' was a String (line 4, col 21):. cram = cram.scram; ^; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3811#issuecomment-418892826
https://github.com/broadinstitute/cromwell/issues/3811#issuecomment-418892826:370,Availability,ERROR,ERROR,370,"Some sloppy experimental procedure is to blame for incorrect conclusions in the previous (deleted) comment. It's enough for the input and task name to be the same:; ```; workflow x {; call cram; call y { input:; cram = cram.scram; }; }. task cram {; command {; echo "".""; }; output {; String scram = "".""; }; }. task y {; String cram; command {; echo "".""; }; }; ```; ```; ERROR: Bad target for member access 'cram.scram': 'cram' was a String (line 4, col 21):. cram = cram.scram; ^; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3811#issuecomment-418892826
https://github.com/broadinstitute/cromwell/issues/3811#issuecomment-418892826:399,Security,access,access,399,"Some sloppy experimental procedure is to blame for incorrect conclusions in the previous (deleted) comment. It's enough for the input and task name to be the same:; ```; workflow x {; call cram; call y { input:; cram = cram.scram; }; }. task cram {; command {; echo "".""; }; output {; String scram = "".""; }; }. task y {; String cram; command {; echo "".""; }; }; ```; ```; ERROR: Bad target for member access 'cram.scram': 'cram' was a String (line 4, col 21):. cram = cram.scram; ^; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3811#issuecomment-418892826
https://github.com/broadinstitute/cromwell/issues/3811#issuecomment-419132650:132,Safety,detect,detect,132,Created branch [`aen_3811`](https://github.com/broadinstitute/cromwell/compare/aen_3811?expand=1) that concisely illustrates how to detect the problem before it happens; fix TBD,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3811#issuecomment-419132650
https://github.com/broadinstitute/cromwell/issues/3811#issuecomment-422889488:67,Deployability,release,release,67,"@orodeh thanks for reporting, the fix will be included in the next release of Cromwell.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3811#issuecomment-422889488
https://github.com/broadinstitute/cromwell/pull/3812#issuecomment-400002150:27,Deployability,release,release,27,"Since this is blocking the release and comments are ToL I'm going to merge as is and address the comments in a later PR.; @mcovarr Yeah we could also do that, I just never know how much coercion logic from third-party libraries to jam into WOM (e.g now we coerce from spray.json but not circe.json)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3812#issuecomment-400002150
https://github.com/broadinstitute/cromwell/pull/3812#issuecomment-400002150:195,Testability,log,logic,195,"Since this is blocking the release and comments are ToL I'm going to merge as is and address the comments in a later PR.; @mcovarr Yeah we could also do that, I just never know how much coercion logic from third-party libraries to jam into WOM (e.g now we coerce from spray.json but not circe.json)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3812#issuecomment-400002150
https://github.com/broadinstitute/cromwell/issues/3814#issuecomment-400446797:186,Availability,down,downstream,186,I believe this might be the intended behavior. Since we treat subworkflow calls the same as a task call -- the outputs of a call can't be used until the call completes and only then can downstream calls continue. I can see the advantages of doing things differently for a subworkflow call -- @geoffjentry @danbills thoughts?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3814#issuecomment-400446797
https://github.com/broadinstitute/cromwell/issues/3814#issuecomment-400468499:157,Availability,down,downstream,157,"The pros / cons sort of mirror each other.; One pro of changing it is what @ffinfo suggested where you don't have to wait for the whole subworkflow to start downstream tasks.; However if your subworkflow is a coherent unit in the sense that it only really is successful if all of its calls complete successfully it might not be the desired behavior.; For example in the WDLs above, if task `Cat` is an expensive operation and the sleep task ends up failing, you could potentially have wasted time running `Cat` unnecessarily.; Of course this can be mitigated by having `Cat` depend on `Sleep`, but it's some sort of ""fake"" dependency. To be fair this behavior already exists with scatters so it might not be that much of a deal, but I remember it was brought up at the time. I think people could be surprised either way. Another not-quite-similar-but-related example is streaming of files from one task to the other, which [CWL lets you specify explicitly](https://www.commonwl.org/v1.0/CommandLineTool.html#CommandInputParameter) (see `streamable` field).; You could imagine a scenario like this (if WDL had a similar streamable concept):. ```wdl. task A {; command {; ./my_script_generating_data.sh > streamable_out; echo ""hello"" > out; }; output {; File streamable_out = ""streamable_out""; File out = ""out""; }; parameter_meta {; streamable_out: {; ""streamable"": true; }; }; }. task B {; File in; command {; cat in | my_script_reading_data.sh; }; }. workflow w {; call A; call B { input: in = A.streamable_out }; call B as B2 { input: in = A.out }; }; ```. Where A and B would actually run simultaneously but B2 would have to wait for A to complete.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3814#issuecomment-400468499
https://github.com/broadinstitute/cromwell/issues/3814#issuecomment-400468499:1219,Availability,echo,echo,1219,"The pros / cons sort of mirror each other.; One pro of changing it is what @ffinfo suggested where you don't have to wait for the whole subworkflow to start downstream tasks.; However if your subworkflow is a coherent unit in the sense that it only really is successful if all of its calls complete successfully it might not be the desired behavior.; For example in the WDLs above, if task `Cat` is an expensive operation and the sleep task ends up failing, you could potentially have wasted time running `Cat` unnecessarily.; Of course this can be mitigated by having `Cat` depend on `Sleep`, but it's some sort of ""fake"" dependency. To be fair this behavior already exists with scatters so it might not be that much of a deal, but I remember it was brought up at the time. I think people could be surprised either way. Another not-quite-similar-but-related example is streaming of files from one task to the other, which [CWL lets you specify explicitly](https://www.commonwl.org/v1.0/CommandLineTool.html#CommandInputParameter) (see `streamable` field).; You could imagine a scenario like this (if WDL had a similar streamable concept):. ```wdl. task A {; command {; ./my_script_generating_data.sh > streamable_out; echo ""hello"" > out; }; output {; File streamable_out = ""streamable_out""; File out = ""out""; }; parameter_meta {; streamable_out: {; ""streamable"": true; }; }; }. task B {; File in; command {; cat in | my_script_reading_data.sh; }; }. workflow w {; call A; call B { input: in = A.streamable_out }; call B as B2 { input: in = A.out }; }; ```. Where A and B would actually run simultaneously but B2 would have to wait for A to complete.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3814#issuecomment-400468499
https://github.com/broadinstitute/cromwell/issues/3814#issuecomment-400468499:575,Integrability,depend,depend,575,"The pros / cons sort of mirror each other.; One pro of changing it is what @ffinfo suggested where you don't have to wait for the whole subworkflow to start downstream tasks.; However if your subworkflow is a coherent unit in the sense that it only really is successful if all of its calls complete successfully it might not be the desired behavior.; For example in the WDLs above, if task `Cat` is an expensive operation and the sleep task ends up failing, you could potentially have wasted time running `Cat` unnecessarily.; Of course this can be mitigated by having `Cat` depend on `Sleep`, but it's some sort of ""fake"" dependency. To be fair this behavior already exists with scatters so it might not be that much of a deal, but I remember it was brought up at the time. I think people could be surprised either way. Another not-quite-similar-but-related example is streaming of files from one task to the other, which [CWL lets you specify explicitly](https://www.commonwl.org/v1.0/CommandLineTool.html#CommandInputParameter) (see `streamable` field).; You could imagine a scenario like this (if WDL had a similar streamable concept):. ```wdl. task A {; command {; ./my_script_generating_data.sh > streamable_out; echo ""hello"" > out; }; output {; File streamable_out = ""streamable_out""; File out = ""out""; }; parameter_meta {; streamable_out: {; ""streamable"": true; }; }; }. task B {; File in; command {; cat in | my_script_reading_data.sh; }; }. workflow w {; call A; call B { input: in = A.streamable_out }; call B as B2 { input: in = A.out }; }; ```. Where A and B would actually run simultaneously but B2 would have to wait for A to complete.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3814#issuecomment-400468499
https://github.com/broadinstitute/cromwell/issues/3814#issuecomment-400468499:623,Integrability,depend,dependency,623,"The pros / cons sort of mirror each other.; One pro of changing it is what @ffinfo suggested where you don't have to wait for the whole subworkflow to start downstream tasks.; However if your subworkflow is a coherent unit in the sense that it only really is successful if all of its calls complete successfully it might not be the desired behavior.; For example in the WDLs above, if task `Cat` is an expensive operation and the sleep task ends up failing, you could potentially have wasted time running `Cat` unnecessarily.; Of course this can be mitigated by having `Cat` depend on `Sleep`, but it's some sort of ""fake"" dependency. To be fair this behavior already exists with scatters so it might not be that much of a deal, but I remember it was brought up at the time. I think people could be surprised either way. Another not-quite-similar-but-related example is streaming of files from one task to the other, which [CWL lets you specify explicitly](https://www.commonwl.org/v1.0/CommandLineTool.html#CommandInputParameter) (see `streamable` field).; You could imagine a scenario like this (if WDL had a similar streamable concept):. ```wdl. task A {; command {; ./my_script_generating_data.sh > streamable_out; echo ""hello"" > out; }; output {; File streamable_out = ""streamable_out""; File out = ""out""; }; parameter_meta {; streamable_out: {; ""streamable"": true; }; }; }. task B {; File in; command {; cat in | my_script_reading_data.sh; }; }. workflow w {; call A; call B { input: in = A.streamable_out }; call B as B2 { input: in = A.out }; }; ```. Where A and B would actually run simultaneously but B2 would have to wait for A to complete.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3814#issuecomment-400468499
https://github.com/broadinstitute/cromwell/issues/3814#issuecomment-400586197:126,Integrability,depend,depending,126,That's also a nice option indeed but streams only work if they can really run next to each other. If there are multiple tasks depending on the same file this become more difficult I think. Maybe a config value where the user can define if a subworkflow need to be completed or not to continue?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3814#issuecomment-400586197
https://github.com/broadinstitute/cromwell/issues/3814#issuecomment-400586197:197,Modifiability,config,config,197,That's also a nice option indeed but streams only work if they can really run next to each other. If there are multiple tasks depending on the same file this become more difficult I think. Maybe a config value where the user can define if a subworkflow need to be completed or not to continue?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3814#issuecomment-400586197
https://github.com/broadinstitute/cromwell/issues/3817#issuecomment-400828579:13,Security,access,access,13,"re `5: Write access:` we have to stage stuff in CWL too - maybe even more so than we do in WDL. Regardless, my comment would be that we don't necessarily need to write to the same FS that inputs are coming from - eg if we're running on PAPI would could ""write"" to `gs://...` even if most inputs are coming from `https://...`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3817#issuecomment-400828579
https://github.com/broadinstitute/cromwell/issues/3817#issuecomment-400829241:81,Performance,cache,cache,81,re `6: hashes beside CRC32` - yes we *can* use anything. Only if we want to call cache between tasks from different FS's do we need to standardize. That's not been a problem for now between local (`md5`) and GCS (`CRC32C`) because we'd never call cache between local and PAPI anyway,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3817#issuecomment-400829241
https://github.com/broadinstitute/cromwell/issues/3817#issuecomment-400829241:247,Performance,cache,cache,247,re `6: hashes beside CRC32` - yes we *can* use anything. Only if we want to call cache between tasks from different FS's do we need to standardize. That's not been a problem for now between local (`md5`) and GCS (`CRC32C`) because we'd never call cache between local and PAPI anyway,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3817#issuecomment-400829241
https://github.com/broadinstitute/cromwell/issues/3817#issuecomment-400829241:7,Security,hash,hashes,7,re `6: hashes beside CRC32` - yes we *can* use anything. Only if we want to call cache between tasks from different FS's do we need to standardize. That's not been a problem for now between local (`md5`) and GCS (`CRC32C`) because we'd never call cache between local and PAPI anyway,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3817#issuecomment-400829241
https://github.com/broadinstitute/cromwell/issues/3817#issuecomment-401390686:38,Performance,cache,cache,38,"3: call caching: in order to make the cache hit, we only need to obtain the MD5 from the input and match it to something run before. If we can get this from the supplied psURL then we have the md5 and can match internally. . As long as we are not using psURLs as destinations (e.g. we are still writing task outputs to the cromwell execution bucket) performing the ""hit"" (e.g. doing the copy/reference) shouldn't be affected by psURLs.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3817#issuecomment-401390686
https://github.com/broadinstitute/cromwell/issues/3817#issuecomment-401390686:350,Performance,perform,performing,350,"3: call caching: in order to make the cache hit, we only need to obtain the MD5 from the input and match it to something run before. If we can get this from the supplied psURL then we have the md5 and can match internally. . As long as we are not using psURLs as destinations (e.g. we are still writing task outputs to the cromwell execution bucket) performing the ""hit"" (e.g. doing the copy/reference) shouldn't be affected by psURLs.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3817#issuecomment-401390686
https://github.com/broadinstitute/cromwell/issues/3817#issuecomment-401397990:333,Performance,cache,cache-control,333,"1: on google, generating a psURL and calling HEAD on it (which you can also do with a GET and only as for the 1st byte). HTTP/2 200 ; x-guploader-uploadid: AEnB2Uo10d8ECr7tR5601R8roi8MIXlzvg1rjyMui9wavFC7KO2Pv2QBk94Qv22mgAz5Ih0nnayc2kXj5XBFgRUqkNTJNtAo7Q; expires: Fri, 29 Jun 2018 15:56:42 GMT; date: Fri, 29 Jun 2018 15:56:42 GMT; cache-control: private, max-age=0; last-modified: Fri, 29 Jun 2018 15:53:49 GMT; etag: ""09f7e02f1290be211da707a266f153b3""; x-goog-generation: 1530287629024005; x-goog-metageneration: 1; x-goog-stored-content-encoding: identity; x-goog-stored-content-length: 6; content-type: text/plain; content-language: en; x-goog-hash: crc32c=sMnOMw==; x-goog-hash: md5=CffgLxKQviEdpweiZvFTsw==; x-goog-storage-class: STANDARD; accept-ranges: bytes; content-length: 6; server: UploadServer; alt-svc: quic="":443""; ma=2592000; v=""43,42,41,39,35""",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3817#issuecomment-401397990
https://github.com/broadinstitute/cromwell/issues/3817#issuecomment-401397990:649,Security,hash,hash,649,"1: on google, generating a psURL and calling HEAD on it (which you can also do with a GET and only as for the 1st byte). HTTP/2 200 ; x-guploader-uploadid: AEnB2Uo10d8ECr7tR5601R8roi8MIXlzvg1rjyMui9wavFC7KO2Pv2QBk94Qv22mgAz5Ih0nnayc2kXj5XBFgRUqkNTJNtAo7Q; expires: Fri, 29 Jun 2018 15:56:42 GMT; date: Fri, 29 Jun 2018 15:56:42 GMT; cache-control: private, max-age=0; last-modified: Fri, 29 Jun 2018 15:53:49 GMT; etag: ""09f7e02f1290be211da707a266f153b3""; x-goog-generation: 1530287629024005; x-goog-metageneration: 1; x-goog-stored-content-encoding: identity; x-goog-stored-content-length: 6; content-type: text/plain; content-language: en; x-goog-hash: crc32c=sMnOMw==; x-goog-hash: md5=CffgLxKQviEdpweiZvFTsw==; x-goog-storage-class: STANDARD; accept-ranges: bytes; content-length: 6; server: UploadServer; alt-svc: quic="":443""; ma=2592000; v=""43,42,41,39,35""",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3817#issuecomment-401397990
https://github.com/broadinstitute/cromwell/issues/3817#issuecomment-401397990:679,Security,hash,hash,679,"1: on google, generating a psURL and calling HEAD on it (which you can also do with a GET and only as for the 1st byte). HTTP/2 200 ; x-guploader-uploadid: AEnB2Uo10d8ECr7tR5601R8roi8MIXlzvg1rjyMui9wavFC7KO2Pv2QBk94Qv22mgAz5Ih0nnayc2kXj5XBFgRUqkNTJNtAo7Q; expires: Fri, 29 Jun 2018 15:56:42 GMT; date: Fri, 29 Jun 2018 15:56:42 GMT; cache-control: private, max-age=0; last-modified: Fri, 29 Jun 2018 15:53:49 GMT; etag: ""09f7e02f1290be211da707a266f153b3""; x-goog-generation: 1530287629024005; x-goog-metageneration: 1; x-goog-stored-content-encoding: identity; x-goog-stored-content-length: 6; content-type: text/plain; content-language: en; x-goog-hash: crc32c=sMnOMw==; x-goog-hash: md5=CffgLxKQviEdpweiZvFTsw==; x-goog-storage-class: STANDARD; accept-ranges: bytes; content-length: 6; server: UploadServer; alt-svc: quic="":443""; ma=2592000; v=""43,42,41,39,35""",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3817#issuecomment-401397990
https://github.com/broadinstitute/cromwell/issues/3819#issuecomment-421435288:298,Availability,echo,echo,298,"With inputs; ```; {; ""wf.input_to_wf"": null; }; ```; and WDL; ```; version 1.0. workflow wf {; input {; String? input_to_wf = ""Neither should this""; }. call hello { input:; input_to_hello = input_to_wf; }; }. task hello {; input {; String? input_to_hello = ""This should not be here""; }. command {; echo ""Should be blank: ${input_to_hello}""; }; output {; String result = read_string(stdout()); }; }; ```; the result is; ```; ""Should be blank: This should not be here""; ```; ...so it would seem that Cromwell understands not to overwrite null with a default value _sometimes_, just not on calls.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3819#issuecomment-421435288
https://github.com/broadinstitute/cromwell/issues/3825#issuecomment-401217803:135,Availability,error,error,135,"I think the cache is unrelated, this is purely input localisation. I re-ran the job with caching disabled in the config file. The same error occurs. From this directory: /share/ScratchGeneral/evaben/cromwell/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/37e4e046-b256-4f81-95c6-9f0c915810bf/call-SamToFastqAndBwaMem/inputs/-21323395 . There is a file 'cromwell.tmp' which seems to be a partial copy of my cromwell process' CWD. All of the logs are copied in, (cromwell.tmp/cromwell-workflow-logs/) and a single seemingly unrelated job (cromwell.tmp/cromwell-executions/HaplotypeCallerGvcf_GATK4/f18cded7-24ae-470d-b58d-d87ce97f21cb/call-HaplotypeCaller/shard-6/). All of that jobs 'execution' folder, and some of its 'inputs' are copied. It is not clear if more would have been copied in or if the process was ended by the soft link error mentioned above.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3825#issuecomment-401217803
https://github.com/broadinstitute/cromwell/issues/3825#issuecomment-401217803:846,Availability,error,error,846,"I think the cache is unrelated, this is purely input localisation. I re-ran the job with caching disabled in the config file. The same error occurs. From this directory: /share/ScratchGeneral/evaben/cromwell/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/37e4e046-b256-4f81-95c6-9f0c915810bf/call-SamToFastqAndBwaMem/inputs/-21323395 . There is a file 'cromwell.tmp' which seems to be a partial copy of my cromwell process' CWD. All of the logs are copied in, (cromwell.tmp/cromwell-workflow-logs/) and a single seemingly unrelated job (cromwell.tmp/cromwell-executions/HaplotypeCallerGvcf_GATK4/f18cded7-24ae-470d-b58d-d87ce97f21cb/call-HaplotypeCaller/shard-6/). All of that jobs 'execution' folder, and some of its 'inputs' are copied. It is not clear if more would have been copied in or if the process was ended by the soft link error mentioned above.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3825#issuecomment-401217803
https://github.com/broadinstitute/cromwell/issues/3825#issuecomment-401217803:113,Modifiability,config,config,113,"I think the cache is unrelated, this is purely input localisation. I re-ran the job with caching disabled in the config file. The same error occurs. From this directory: /share/ScratchGeneral/evaben/cromwell/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/37e4e046-b256-4f81-95c6-9f0c915810bf/call-SamToFastqAndBwaMem/inputs/-21323395 . There is a file 'cromwell.tmp' which seems to be a partial copy of my cromwell process' CWD. All of the logs are copied in, (cromwell.tmp/cromwell-workflow-logs/) and a single seemingly unrelated job (cromwell.tmp/cromwell-executions/HaplotypeCallerGvcf_GATK4/f18cded7-24ae-470d-b58d-d87ce97f21cb/call-HaplotypeCaller/shard-6/). All of that jobs 'execution' folder, and some of its 'inputs' are copied. It is not clear if more would have been copied in or if the process was ended by the soft link error mentioned above.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3825#issuecomment-401217803
https://github.com/broadinstitute/cromwell/issues/3825#issuecomment-401217803:12,Performance,cache,cache,12,"I think the cache is unrelated, this is purely input localisation. I re-ran the job with caching disabled in the config file. The same error occurs. From this directory: /share/ScratchGeneral/evaben/cromwell/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/37e4e046-b256-4f81-95c6-9f0c915810bf/call-SamToFastqAndBwaMem/inputs/-21323395 . There is a file 'cromwell.tmp' which seems to be a partial copy of my cromwell process' CWD. All of the logs are copied in, (cromwell.tmp/cromwell-workflow-logs/) and a single seemingly unrelated job (cromwell.tmp/cromwell-executions/HaplotypeCallerGvcf_GATK4/f18cded7-24ae-470d-b58d-d87ce97f21cb/call-HaplotypeCaller/shard-6/). All of that jobs 'execution' folder, and some of its 'inputs' are copied. It is not clear if more would have been copied in or if the process was ended by the soft link error mentioned above.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3825#issuecomment-401217803
https://github.com/broadinstitute/cromwell/issues/3825#issuecomment-401217803:452,Testability,log,logs,452,"I think the cache is unrelated, this is purely input localisation. I re-ran the job with caching disabled in the config file. The same error occurs. From this directory: /share/ScratchGeneral/evaben/cromwell/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/37e4e046-b256-4f81-95c6-9f0c915810bf/call-SamToFastqAndBwaMem/inputs/-21323395 . There is a file 'cromwell.tmp' which seems to be a partial copy of my cromwell process' CWD. All of the logs are copied in, (cromwell.tmp/cromwell-workflow-logs/) and a single seemingly unrelated job (cromwell.tmp/cromwell-executions/HaplotypeCallerGvcf_GATK4/f18cded7-24ae-470d-b58d-d87ce97f21cb/call-HaplotypeCaller/shard-6/). All of that jobs 'execution' folder, and some of its 'inputs' are copied. It is not clear if more would have been copied in or if the process was ended by the soft link error mentioned above.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3825#issuecomment-401217803
https://github.com/broadinstitute/cromwell/issues/3825#issuecomment-401217803:504,Testability,log,logs,504,"I think the cache is unrelated, this is purely input localisation. I re-ran the job with caching disabled in the config file. The same error occurs. From this directory: /share/ScratchGeneral/evaben/cromwell/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/37e4e046-b256-4f81-95c6-9f0c915810bf/call-SamToFastqAndBwaMem/inputs/-21323395 . There is a file 'cromwell.tmp' which seems to be a partial copy of my cromwell process' CWD. All of the logs are copied in, (cromwell.tmp/cromwell-workflow-logs/) and a single seemingly unrelated job (cromwell.tmp/cromwell-executions/HaplotypeCallerGvcf_GATK4/f18cded7-24ae-470d-b58d-d87ce97f21cb/call-HaplotypeCaller/shard-6/). All of that jobs 'execution' folder, and some of its 'inputs' are copied. It is not clear if more would have been copied in or if the process was ended by the soft link error mentioned above.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3825#issuecomment-401217803
https://github.com/broadinstitute/cromwell/issues/3825#issuecomment-401217803:761,Usability,clear,clear,761,"I think the cache is unrelated, this is purely input localisation. I re-ran the job with caching disabled in the config file. The same error occurs. From this directory: /share/ScratchGeneral/evaben/cromwell/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/37e4e046-b256-4f81-95c6-9f0c915810bf/call-SamToFastqAndBwaMem/inputs/-21323395 . There is a file 'cromwell.tmp' which seems to be a partial copy of my cromwell process' CWD. All of the logs are copied in, (cromwell.tmp/cromwell-workflow-logs/) and a single seemingly unrelated job (cromwell.tmp/cromwell-executions/HaplotypeCallerGvcf_GATK4/f18cded7-24ae-470d-b58d-d87ce97f21cb/call-HaplotypeCaller/shard-6/). All of that jobs 'execution' folder, and some of its 'inputs' are copied. It is not clear if more would have been copied in or if the process was ended by the soft link error mentioned above.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3825#issuecomment-401217803
https://github.com/broadinstitute/cromwell/issues/3825#issuecomment-401233074:163,Availability,error,error,163,"[meta.txt](https://github.com/broadinstitute/cromwell/files/2147609/meta.txt); Checking the metadata, none of the 'inputs' are folders, or anything related to the error that I can tell.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3825#issuecomment-401233074
https://github.com/broadinstitute/cromwell/pull/3828#issuecomment-401064686:0,Deployability,Hotfix,Hotfix,0,Hotfix version,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3828#issuecomment-401064686
https://github.com/broadinstitute/cromwell/pull/3828#issuecomment-401099308:61,Deployability,Release,Release,61,"Maybe add an entry in the changelog, even just; ```; ## 33.1 Release Notes. ### Bug fixes; ```. So that something shows up in the release in github (if you do make a release)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3828#issuecomment-401099308
https://github.com/broadinstitute/cromwell/pull/3828#issuecomment-401099308:130,Deployability,release,release,130,"Maybe add an entry in the changelog, even just; ```; ## 33.1 Release Notes. ### Bug fixes; ```. So that something shows up in the release in github (if you do make a release)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3828#issuecomment-401099308
https://github.com/broadinstitute/cromwell/pull/3828#issuecomment-401099308:166,Deployability,release,release,166,"Maybe add an entry in the changelog, even just; ```; ## 33.1 Release Notes. ### Bug fixes; ```. So that something shows up in the release in github (if you do make a release)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3828#issuecomment-401099308
https://github.com/broadinstitute/cromwell/pull/3832#issuecomment-401169672:179,Security,validat,validate,179,Thanks for fixing this!. Would you be willing to also add a test case for draft-2 and/or 1.0 to https://github.com/broadinstitute/cromwell/tree/develop/womtool/src/test/resources/validate to make sure this doesn't regress again?. You shouldn't need to do any wiring other than dropping a new test case into an appropriate `valid/testname` directory.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3832#issuecomment-401169672
https://github.com/broadinstitute/cromwell/pull/3832#issuecomment-401169672:60,Testability,test,test,60,Thanks for fixing this!. Would you be willing to also add a test case for draft-2 and/or 1.0 to https://github.com/broadinstitute/cromwell/tree/develop/womtool/src/test/resources/validate to make sure this doesn't regress again?. You shouldn't need to do any wiring other than dropping a new test case into an appropriate `valid/testname` directory.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3832#issuecomment-401169672
https://github.com/broadinstitute/cromwell/pull/3832#issuecomment-401169672:164,Testability,test,test,164,Thanks for fixing this!. Would you be willing to also add a test case for draft-2 and/or 1.0 to https://github.com/broadinstitute/cromwell/tree/develop/womtool/src/test/resources/validate to make sure this doesn't regress again?. You shouldn't need to do any wiring other than dropping a new test case into an appropriate `valid/testname` directory.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3832#issuecomment-401169672
https://github.com/broadinstitute/cromwell/pull/3832#issuecomment-401169672:292,Testability,test,test,292,Thanks for fixing this!. Would you be willing to also add a test case for draft-2 and/or 1.0 to https://github.com/broadinstitute/cromwell/tree/develop/womtool/src/test/resources/validate to make sure this doesn't regress again?. You shouldn't need to do any wiring other than dropping a new test case into an appropriate `valid/testname` directory.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3832#issuecomment-401169672
https://github.com/broadinstitute/cromwell/pull/3832#issuecomment-401169672:329,Testability,test,testname,329,Thanks for fixing this!. Would you be willing to also add a test case for draft-2 and/or 1.0 to https://github.com/broadinstitute/cromwell/tree/develop/womtool/src/test/resources/validate to make sure this doesn't regress again?. You shouldn't need to do any wiring other than dropping a new test case into an appropriate `valid/testname` directory.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3832#issuecomment-401169672
https://github.com/broadinstitute/cromwell/pull/3832#issuecomment-401426922:78,Testability,test,tests,78,"I've made it so WOMtool will resolve files relative to the main WDL file. The tests now test that instead. However, this is a new behaviour and I'm not sure if its what you guys want.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3832#issuecomment-401426922
https://github.com/broadinstitute/cromwell/pull/3832#issuecomment-401426922:88,Testability,test,test,88,"I've made it so WOMtool will resolve files relative to the main WDL file. The tests now test that instead. However, this is a new behaviour and I'm not sure if its what you guys want.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3832#issuecomment-401426922
https://github.com/broadinstitute/cromwell/pull/3832#issuecomment-401428709:292,Security,validat,validation,292,"@tlangs I think the best answer may be to change the [directoryResolver](https://github.com/broadinstitute/cromwell/blob/develop/languageFactories/language-factory-core/src/main/scala/cromwell/languages/util/ImportResolver.scala#L33) to allow us to customize the ""don't escape the directory"" validation when womtool calls it only, ie:; ```scala; def directoryResolver(directory: Path, allowEscapingDirectory: Boolean = false) = { ; ...; if (absolutePathToFile.startsWith(absolutePathToImports) || allowEscapingDirectory) {; ...; } else {; ...; }; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3832#issuecomment-401428709
https://github.com/broadinstitute/cromwell/issues/3846#issuecomment-409588696:163,Deployability,integrat,integration-test,163,"No longer blocked. It appears that the service account used by centaur tests for requester-pays testing is not compatible with the bucket used in `arrays` centaur-integration-test. Options:; - Use a workflow option to override-the-override, the service account back to the ""original"" service account specified in the JSON; - Reconfigure the centaur-integration-tests to not use an override of the requester-pays service account",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3846#issuecomment-409588696
https://github.com/broadinstitute/cromwell/issues/3846#issuecomment-409588696:349,Deployability,integrat,integration-tests,349,"No longer blocked. It appears that the service account used by centaur tests for requester-pays testing is not compatible with the bucket used in `arrays` centaur-integration-test. Options:; - Use a workflow option to override-the-override, the service account back to the ""original"" service account specified in the JSON; - Reconfigure the centaur-integration-tests to not use an override of the requester-pays service account",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3846#issuecomment-409588696
https://github.com/broadinstitute/cromwell/issues/3846#issuecomment-409588696:163,Integrability,integrat,integration-test,163,"No longer blocked. It appears that the service account used by centaur tests for requester-pays testing is not compatible with the bucket used in `arrays` centaur-integration-test. Options:; - Use a workflow option to override-the-override, the service account back to the ""original"" service account specified in the JSON; - Reconfigure the centaur-integration-tests to not use an override of the requester-pays service account",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3846#issuecomment-409588696
https://github.com/broadinstitute/cromwell/issues/3846#issuecomment-409588696:349,Integrability,integrat,integration-tests,349,"No longer blocked. It appears that the service account used by centaur tests for requester-pays testing is not compatible with the bucket used in `arrays` centaur-integration-test. Options:; - Use a workflow option to override-the-override, the service account back to the ""original"" service account specified in the JSON; - Reconfigure the centaur-integration-tests to not use an override of the requester-pays service account",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3846#issuecomment-409588696
https://github.com/broadinstitute/cromwell/issues/3846#issuecomment-409588696:71,Testability,test,tests,71,"No longer blocked. It appears that the service account used by centaur tests for requester-pays testing is not compatible with the bucket used in `arrays` centaur-integration-test. Options:; - Use a workflow option to override-the-override, the service account back to the ""original"" service account specified in the JSON; - Reconfigure the centaur-integration-tests to not use an override of the requester-pays service account",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3846#issuecomment-409588696
https://github.com/broadinstitute/cromwell/issues/3846#issuecomment-409588696:96,Testability,test,testing,96,"No longer blocked. It appears that the service account used by centaur tests for requester-pays testing is not compatible with the bucket used in `arrays` centaur-integration-test. Options:; - Use a workflow option to override-the-override, the service account back to the ""original"" service account specified in the JSON; - Reconfigure the centaur-integration-tests to not use an override of the requester-pays service account",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3846#issuecomment-409588696
https://github.com/broadinstitute/cromwell/issues/3846#issuecomment-409588696:175,Testability,test,test,175,"No longer blocked. It appears that the service account used by centaur tests for requester-pays testing is not compatible with the bucket used in `arrays` centaur-integration-test. Options:; - Use a workflow option to override-the-override, the service account back to the ""original"" service account specified in the JSON; - Reconfigure the centaur-integration-tests to not use an override of the requester-pays service account",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3846#issuecomment-409588696
https://github.com/broadinstitute/cromwell/issues/3846#issuecomment-409588696:361,Testability,test,tests,361,"No longer blocked. It appears that the service account used by centaur tests for requester-pays testing is not compatible with the bucket used in `arrays` centaur-integration-test. Options:; - Use a workflow option to override-the-override, the service account back to the ""original"" service account specified in the JSON; - Reconfigure the centaur-integration-tests to not use an override of the requester-pays service account",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3846#issuecomment-409588696
https://github.com/broadinstitute/cromwell/issues/3849#issuecomment-403963315:144,Integrability,depend,dependencies,144,"* The ""no zip bundle"" set of import resolvers is probably the right one to use when trying to ""resolve"" the original file from String (unless a dependencies zip is *also* supplied?).; * Side comment: should we therefore make the set of import resolvers to use *Cromwell's* responsibility? (right now every language factory comes up with its own set üò±); * We should try end up as similar to the WES equivalent as possible when adding this; * To find out: is this just `submit` with `workflowRoot` + no `workflowSource`, or is it a separate endpoint?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3849#issuecomment-403963315
https://github.com/broadinstitute/cromwell/pull/3852#issuecomment-402194081:210,Integrability,inject,inject,210,"@cjllanwarne Do you need a red review on this ? If so could you elaborate just a little on what ; > Allows reading of WDL 1.0 and 1.1 Asts through a shared set of CheckedAtoB functions, with the flexibility to inject different transform behavior into each usage of the instantiations of the transforms. means for me poor mortal and / or point to relevant code that I should look at ? üòÑ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3852#issuecomment-402194081
https://github.com/broadinstitute/cromwell/pull/3852#issuecomment-402194081:210,Security,inject,inject,210,"@cjllanwarne Do you need a red review on this ? If so could you elaborate just a little on what ; > Allows reading of WDL 1.0 and 1.1 Asts through a shared set of CheckedAtoB functions, with the flexibility to inject different transform behavior into each usage of the instantiations of the transforms. means for me poor mortal and / or point to relevant code that I should look at ? üòÑ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3852#issuecomment-402194081
https://github.com/broadinstitute/cromwell/pull/3853#issuecomment-402268184:112,Testability,test,test,112,"> All of these changes look great but I'm a bit uncertain how they've enabled Jenkins CRON. The 279 changes in `test.inc.sh`, especially those near `${CROMWELL_BUILD_PROVIDER_JENKINS}`,; are the heart of Jenkins support. As of v33 that file contains all of the the local/Travis/Jenkins (and later CircleCI) business logic. It was consolidated from code copy/pasted around the various `test*.sh` scripts in the past. > 279 src/bin/ci/test.inc.sh ‚Üí src/ci/bin/test.inc.sh; > Large diffs are not rendered by default. If you haven't already click to expand the diff and scroll through the changes/cleanup. Also happy to review IRL. Many of the changes in other files are just ripples.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3853#issuecomment-402268184
https://github.com/broadinstitute/cromwell/pull/3853#issuecomment-402268184:316,Testability,log,logic,316,"> All of these changes look great but I'm a bit uncertain how they've enabled Jenkins CRON. The 279 changes in `test.inc.sh`, especially those near `${CROMWELL_BUILD_PROVIDER_JENKINS}`,; are the heart of Jenkins support. As of v33 that file contains all of the the local/Travis/Jenkins (and later CircleCI) business logic. It was consolidated from code copy/pasted around the various `test*.sh` scripts in the past. > 279 src/bin/ci/test.inc.sh ‚Üí src/ci/bin/test.inc.sh; > Large diffs are not rendered by default. If you haven't already click to expand the diff and scroll through the changes/cleanup. Also happy to review IRL. Many of the changes in other files are just ripples.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3853#issuecomment-402268184
https://github.com/broadinstitute/cromwell/pull/3853#issuecomment-402268184:385,Testability,test,test,385,"> All of these changes look great but I'm a bit uncertain how they've enabled Jenkins CRON. The 279 changes in `test.inc.sh`, especially those near `${CROMWELL_BUILD_PROVIDER_JENKINS}`,; are the heart of Jenkins support. As of v33 that file contains all of the the local/Travis/Jenkins (and later CircleCI) business logic. It was consolidated from code copy/pasted around the various `test*.sh` scripts in the past. > 279 src/bin/ci/test.inc.sh ‚Üí src/ci/bin/test.inc.sh; > Large diffs are not rendered by default. If you haven't already click to expand the diff and scroll through the changes/cleanup. Also happy to review IRL. Many of the changes in other files are just ripples.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3853#issuecomment-402268184
https://github.com/broadinstitute/cromwell/pull/3853#issuecomment-402268184:433,Testability,test,test,433,"> All of these changes look great but I'm a bit uncertain how they've enabled Jenkins CRON. The 279 changes in `test.inc.sh`, especially those near `${CROMWELL_BUILD_PROVIDER_JENKINS}`,; are the heart of Jenkins support. As of v33 that file contains all of the the local/Travis/Jenkins (and later CircleCI) business logic. It was consolidated from code copy/pasted around the various `test*.sh` scripts in the past. > 279 src/bin/ci/test.inc.sh ‚Üí src/ci/bin/test.inc.sh; > Large diffs are not rendered by default. If you haven't already click to expand the diff and scroll through the changes/cleanup. Also happy to review IRL. Many of the changes in other files are just ripples.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3853#issuecomment-402268184
https://github.com/broadinstitute/cromwell/pull/3853#issuecomment-402268184:458,Testability,test,test,458,"> All of these changes look great but I'm a bit uncertain how they've enabled Jenkins CRON. The 279 changes in `test.inc.sh`, especially those near `${CROMWELL_BUILD_PROVIDER_JENKINS}`,; are the heart of Jenkins support. As of v33 that file contains all of the the local/Travis/Jenkins (and later CircleCI) business logic. It was consolidated from code copy/pasted around the various `test*.sh` scripts in the past. > 279 src/bin/ci/test.inc.sh ‚Üí src/ci/bin/test.inc.sh; > Large diffs are not rendered by default. If you haven't already click to expand the diff and scroll through the changes/cleanup. Also happy to review IRL. Many of the changes in other files are just ripples.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3853#issuecomment-402268184
https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985:204,Availability,Error,Error,204,"I also saw this problem. The VM is not a preemptible and I'm using Cromwell v32. There's a lot of shards spending 10 minutes in ""Waiting for quota"" when this problem happens. The instance that gives PAPI Error Code 10 was able to get a virtual machine, though. Maybe there is a timeout for ""Waiting for quota"" which causes all other shards to fail with Error Code 10 even though there was nothing wrong with this particular shard?. ```; Task to_bam_workflow.BaseRecalibrator:3:1 failed. The job was stopped before the command finished. PAPI error code 10. Message: 14: VM ggp-8822042418103915125 stopped unexpectedly.; java.lang.Exception: Task to_bam_workflow.BaseRecalibrator:3:1 failed. The job was stopped before the command finished. PAPI error code 10. Message: 14: VM ggp-8822042418103915125 stopped unexpectedly.; 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:73); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:520); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:527); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:77); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1019); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1015); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.Batching",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985
https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985:353,Availability,Error,Error,353,"I also saw this problem. The VM is not a preemptible and I'm using Cromwell v32. There's a lot of shards spending 10 minutes in ""Waiting for quota"" when this problem happens. The instance that gives PAPI Error Code 10 was able to get a virtual machine, though. Maybe there is a timeout for ""Waiting for quota"" which causes all other shards to fail with Error Code 10 even though there was nothing wrong with this particular shard?. ```; Task to_bam_workflow.BaseRecalibrator:3:1 failed. The job was stopped before the command finished. PAPI error code 10. Message: 14: VM ggp-8822042418103915125 stopped unexpectedly.; java.lang.Exception: Task to_bam_workflow.BaseRecalibrator:3:1 failed. The job was stopped before the command finished. PAPI error code 10. Message: 14: VM ggp-8822042418103915125 stopped unexpectedly.; 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:73); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:520); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:527); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:77); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1019); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1015); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.Batching",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985
https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985:541,Availability,error,error,541,"I also saw this problem. The VM is not a preemptible and I'm using Cromwell v32. There's a lot of shards spending 10 minutes in ""Waiting for quota"" when this problem happens. The instance that gives PAPI Error Code 10 was able to get a virtual machine, though. Maybe there is a timeout for ""Waiting for quota"" which causes all other shards to fail with Error Code 10 even though there was nothing wrong with this particular shard?. ```; Task to_bam_workflow.BaseRecalibrator:3:1 failed. The job was stopped before the command finished. PAPI error code 10. Message: 14: VM ggp-8822042418103915125 stopped unexpectedly.; java.lang.Exception: Task to_bam_workflow.BaseRecalibrator:3:1 failed. The job was stopped before the command finished. PAPI error code 10. Message: 14: VM ggp-8822042418103915125 stopped unexpectedly.; 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:73); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:520); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:527); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:77); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1019); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1015); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.Batching",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985
https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985:744,Availability,error,error,744,"I also saw this problem. The VM is not a preemptible and I'm using Cromwell v32. There's a lot of shards spending 10 minutes in ""Waiting for quota"" when this problem happens. The instance that gives PAPI Error Code 10 was able to get a virtual machine, though. Maybe there is a timeout for ""Waiting for quota"" which causes all other shards to fail with Error Code 10 even though there was nothing wrong with this particular shard?. ```; Task to_bam_workflow.BaseRecalibrator:3:1 failed. The job was stopped before the command finished. PAPI error code 10. Message: 14: VM ggp-8822042418103915125 stopped unexpectedly.; java.lang.Exception: Task to_bam_workflow.BaseRecalibrator:3:1 failed. The job was stopped before the command finished. PAPI error code 10. Message: 14: VM ggp-8822042418103915125 stopped unexpectedly.; 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:73); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:520); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:527); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:77); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1019); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1015); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.Batching",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985
https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985:1798,Availability,recover,recoverWith,1798,ed unexpectedly.; 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:73); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:520); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:527); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:77); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1019); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1015); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); 	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:43); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akk,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985
https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985:850,Deployability,pipeline,pipelines,850,"I also saw this problem. The VM is not a preemptible and I'm using Cromwell v32. There's a lot of shards spending 10 minutes in ""Waiting for quota"" when this problem happens. The instance that gives PAPI Error Code 10 was able to get a virtual machine, though. Maybe there is a timeout for ""Waiting for quota"" which causes all other shards to fail with Error Code 10 even though there was nothing wrong with this particular shard?. ```; Task to_bam_workflow.BaseRecalibrator:3:1 failed. The job was stopped before the command finished. PAPI error code 10. Message: 14: VM ggp-8822042418103915125 stopped unexpectedly.; java.lang.Exception: Task to_bam_workflow.BaseRecalibrator:3:1 failed. The job was stopped before the command finished. PAPI error code 10. Message: 14: VM ggp-8822042418103915125 stopped unexpectedly.; 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:73); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:520); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:527); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:77); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1019); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1015); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.Batching",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985
https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985:867,Deployability,Pipeline,PipelinesApiAsyncBackendJobExecutionActor,867,"I also saw this problem. The VM is not a preemptible and I'm using Cromwell v32. There's a lot of shards spending 10 minutes in ""Waiting for quota"" when this problem happens. The instance that gives PAPI Error Code 10 was able to get a virtual machine, though. Maybe there is a timeout for ""Waiting for quota"" which causes all other shards to fail with Error Code 10 even though there was nothing wrong with this particular shard?. ```; Task to_bam_workflow.BaseRecalibrator:3:1 failed. The job was stopped before the command finished. PAPI error code 10. Message: 14: VM ggp-8822042418103915125 stopped unexpectedly.; java.lang.Exception: Task to_bam_workflow.BaseRecalibrator:3:1 failed. The job was stopped before the command finished. PAPI error code 10. Message: 14: VM ggp-8822042418103915125 stopped unexpectedly.; 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:73); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:520); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:527); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:77); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1019); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1015); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.Batching",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985
https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985:928,Deployability,Pipeline,PipelinesApiAsyncBackendJobExecutionActor,928,"I also saw this problem. The VM is not a preemptible and I'm using Cromwell v32. There's a lot of shards spending 10 minutes in ""Waiting for quota"" when this problem happens. The instance that gives PAPI Error Code 10 was able to get a virtual machine, though. Maybe there is a timeout for ""Waiting for quota"" which causes all other shards to fail with Error Code 10 even though there was nothing wrong with this particular shard?. ```; Task to_bam_workflow.BaseRecalibrator:3:1 failed. The job was stopped before the command finished. PAPI error code 10. Message: 14: VM ggp-8822042418103915125 stopped unexpectedly.; java.lang.Exception: Task to_bam_workflow.BaseRecalibrator:3:1 failed. The job was stopped before the command finished. PAPI error code 10. Message: 14: VM ggp-8822042418103915125 stopped unexpectedly.; 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:73); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:520); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:527); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:77); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1019); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1015); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.Batching",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985
https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985:1009,Deployability,pipeline,pipelines,1009,"s problem. The VM is not a preemptible and I'm using Cromwell v32. There's a lot of shards spending 10 minutes in ""Waiting for quota"" when this problem happens. The instance that gives PAPI Error Code 10 was able to get a virtual machine, though. Maybe there is a timeout for ""Waiting for quota"" which causes all other shards to fail with Error Code 10 even though there was nothing wrong with this particular shard?. ```; Task to_bam_workflow.BaseRecalibrator:3:1 failed. The job was stopped before the command finished. PAPI error code 10. Message: 14: VM ggp-8822042418103915125 stopped unexpectedly.; java.lang.Exception: Task to_bam_workflow.BaseRecalibrator:3:1 failed. The job was stopped before the command finished. PAPI error code 10. Message: 14: VM ggp-8822042418103915125 stopped unexpectedly.; 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:73); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:520); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:527); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:77); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1019); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1015); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.BatchingExecutor$Abst",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985
https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985:1026,Deployability,Pipeline,PipelinesApiAsyncBackendJobExecutionActor,1026,"tible and I'm using Cromwell v32. There's a lot of shards spending 10 minutes in ""Waiting for quota"" when this problem happens. The instance that gives PAPI Error Code 10 was able to get a virtual machine, though. Maybe there is a timeout for ""Waiting for quota"" which causes all other shards to fail with Error Code 10 even though there was nothing wrong with this particular shard?. ```; Task to_bam_workflow.BaseRecalibrator:3:1 failed. The job was stopped before the command finished. PAPI error code 10. Message: 14: VM ggp-8822042418103915125 stopped unexpectedly.; java.lang.Exception: Task to_bam_workflow.BaseRecalibrator:3:1 failed. The job was stopped before the command finished. PAPI error code 10. Message: 14: VM ggp-8822042418103915125 stopped unexpectedly.; 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:73); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:520); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:527); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:77); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1019); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1015); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingEx",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985
https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985:1092,Deployability,Pipeline,PipelinesApiAsyncBackendJobExecutionActor,1092,"rds spending 10 minutes in ""Waiting for quota"" when this problem happens. The instance that gives PAPI Error Code 10 was able to get a virtual machine, though. Maybe there is a timeout for ""Waiting for quota"" which causes all other shards to fail with Error Code 10 even though there was nothing wrong with this particular shard?. ```; Task to_bam_workflow.BaseRecalibrator:3:1 failed. The job was stopped before the command finished. PAPI error code 10. Message: 14: VM ggp-8822042418103915125 stopped unexpectedly.; java.lang.Exception: Task to_bam_workflow.BaseRecalibrator:3:1 failed. The job was stopped before the command finished. PAPI error code 10. Message: 14: VM ggp-8822042418103915125 stopped unexpectedly.; 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:73); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:520); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:527); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:77); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1019); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1015); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$B",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985
https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985:1174,Deployability,pipeline,pipelines,1174,"instance that gives PAPI Error Code 10 was able to get a virtual machine, though. Maybe there is a timeout for ""Waiting for quota"" which causes all other shards to fail with Error Code 10 even though there was nothing wrong with this particular shard?. ```; Task to_bam_workflow.BaseRecalibrator:3:1 failed. The job was stopped before the command finished. PAPI error code 10. Message: 14: VM ggp-8822042418103915125 stopped unexpectedly.; java.lang.Exception: Task to_bam_workflow.BaseRecalibrator:3:1 failed. The job was stopped before the command finished. PAPI error code 10. Message: 14: VM ggp-8822042418103915125 stopped unexpectedly.; 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:73); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:520); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:527); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:77); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1019); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1015); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); 	at scala.runtime.jav",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985
https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985:1191,Deployability,Pipeline,PipelinesApiAsyncBackendJobExecutionActor,1191,"de 10 was able to get a virtual machine, though. Maybe there is a timeout for ""Waiting for quota"" which causes all other shards to fail with Error Code 10 even though there was nothing wrong with this particular shard?. ```; Task to_bam_workflow.BaseRecalibrator:3:1 failed. The job was stopped before the command finished. PAPI error code 10. Message: 14: VM ggp-8822042418103915125 stopped unexpectedly.; java.lang.Exception: Task to_bam_workflow.BaseRecalibrator:3:1 failed. The job was stopped before the command finished. PAPI error code 10. Message: 14: VM ggp-8822042418103915125 stopped unexpectedly.; 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:73); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:520); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:527); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:77); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1019); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1015); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunct",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985
https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985:1256,Deployability,Pipeline,PipelinesApiAsyncBackendJobExecutionActor,1256,"e there is a timeout for ""Waiting for quota"" which causes all other shards to fail with Error Code 10 even though there was nothing wrong with this particular shard?. ```; Task to_bam_workflow.BaseRecalibrator:3:1 failed. The job was stopped before the command finished. PAPI error code 10. Message: 14: VM ggp-8822042418103915125 stopped unexpectedly.; java.lang.Exception: Task to_bam_workflow.BaseRecalibrator:3:1 failed. The job was stopped before the command finished. PAPI error code 10. Message: 14: VM ggp-8822042418103915125 stopped unexpectedly.; 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:73); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:520); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:527); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:77); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1019); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1015); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); 	at scala.concurrent.BlockContex",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985
https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985:1338,Deployability,pipeline,pipelines,1338,fail with Error Code 10 even though there was nothing wrong with this particular shard?. ```; Task to_bam_workflow.BaseRecalibrator:3:1 failed. The job was stopped before the command finished. PAPI error code 10. Message: 14: VM ggp-8822042418103915125 stopped unexpectedly.; java.lang.Exception: Task to_bam_workflow.BaseRecalibrator:3:1 failed. The job was stopped before the command finished. PAPI error code 10. Message: 14: VM ggp-8822042418103915125 stopped unexpectedly.; 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:73); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:520); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:527); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:77); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1019); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1015); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); 	at akka.dispatch.BatchingExecuto,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985
https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985:1355,Deployability,Pipeline,PipelinesApiAsyncBackendJobExecutionActor,1355,gh there was nothing wrong with this particular shard?. ```; Task to_bam_workflow.BaseRecalibrator:3:1 failed. The job was stopped before the command finished. PAPI error code 10. Message: 14: VM ggp-8822042418103915125 stopped unexpectedly.; java.lang.Exception: Task to_bam_workflow.BaseRecalibrator:3:1 failed. The job was stopped before the command finished. PAPI error code 10. Message: 14: VM ggp-8822042418103915125 stopped unexpectedly.; 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:73); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:520); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:527); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:77); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1019); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1015); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); 	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExec,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985
https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985:1420,Deployability,Pipeline,PipelinesApiAsyncBackendJobExecutionActor,1420,?. ```; Task to_bam_workflow.BaseRecalibrator:3:1 failed. The job was stopped before the command finished. PAPI error code 10. Message: 14: VM ggp-8822042418103915125 stopped unexpectedly.; java.lang.Exception: Task to_bam_workflow.BaseRecalibrator:3:1 failed. The job was stopped before the command finished. PAPI error code 10. Message: 14: VM ggp-8822042418103915125 stopped unexpectedly.; 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:73); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:520); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:527); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:77); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1019); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1015); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); 	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91); 	at akka.dispatch.TaskInvocation.run(A,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985
https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985:556,Integrability,Message,Message,556,"I also saw this problem. The VM is not a preemptible and I'm using Cromwell v32. There's a lot of shards spending 10 minutes in ""Waiting for quota"" when this problem happens. The instance that gives PAPI Error Code 10 was able to get a virtual machine, though. Maybe there is a timeout for ""Waiting for quota"" which causes all other shards to fail with Error Code 10 even though there was nothing wrong with this particular shard?. ```; Task to_bam_workflow.BaseRecalibrator:3:1 failed. The job was stopped before the command finished. PAPI error code 10. Message: 14: VM ggp-8822042418103915125 stopped unexpectedly.; java.lang.Exception: Task to_bam_workflow.BaseRecalibrator:3:1 failed. The job was stopped before the command finished. PAPI error code 10. Message: 14: VM ggp-8822042418103915125 stopped unexpectedly.; 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:73); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:520); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:527); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:77); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1019); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1015); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.Batching",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985
https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985:759,Integrability,Message,Message,759,"I also saw this problem. The VM is not a preemptible and I'm using Cromwell v32. There's a lot of shards spending 10 minutes in ""Waiting for quota"" when this problem happens. The instance that gives PAPI Error Code 10 was able to get a virtual machine, though. Maybe there is a timeout for ""Waiting for quota"" which causes all other shards to fail with Error Code 10 even though there was nothing wrong with this particular shard?. ```; Task to_bam_workflow.BaseRecalibrator:3:1 failed. The job was stopped before the command finished. PAPI error code 10. Message: 14: VM ggp-8822042418103915125 stopped unexpectedly.; java.lang.Exception: Task to_bam_workflow.BaseRecalibrator:3:1 failed. The job was stopped before the command finished. PAPI error code 10. Message: 14: VM ggp-8822042418103915125 stopped unexpectedly.; 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:73); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:520); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:527); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:77); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1019); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1015); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.Batching",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985
https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985:1771,Performance,concurren,concurrent,1771,gp-8822042418103915125 stopped unexpectedly.; 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:73); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:520); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:527); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:77); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1019); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1015); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); 	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:43); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJ,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985
https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985:1841,Performance,concurren,concurrent,1841,gle.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:73); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:520); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:527); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:77); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1019); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1015); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); 	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:43); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.ru,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985
https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985:1919,Performance,concurren,concurrent,1919,BackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:73); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:520); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:527); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:77); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1019); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1015); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); 	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:43); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985
https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985:2244,Performance,concurren,concurrent,2244,BackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:73); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:520); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:527); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:77); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1019); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1015); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); 	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:43); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985
https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985:278,Safety,timeout,timeout,278,"I also saw this problem. The VM is not a preemptible and I'm using Cromwell v32. There's a lot of shards spending 10 minutes in ""Waiting for quota"" when this problem happens. The instance that gives PAPI Error Code 10 was able to get a virtual machine, though. Maybe there is a timeout for ""Waiting for quota"" which causes all other shards to fail with Error Code 10 even though there was nothing wrong with this particular shard?. ```; Task to_bam_workflow.BaseRecalibrator:3:1 failed. The job was stopped before the command finished. PAPI error code 10. Message: 14: VM ggp-8822042418103915125 stopped unexpectedly.; java.lang.Exception: Task to_bam_workflow.BaseRecalibrator:3:1 failed. The job was stopped before the command finished. PAPI error code 10. Message: 14: VM ggp-8822042418103915125 stopped unexpectedly.; 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:73); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:520); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:527); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:77); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1019); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1015); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.Batching",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985
https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985:1798,Safety,recover,recoverWith,1798,ed unexpectedly.; 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:73); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:520); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:527); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:77); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1019); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1015); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); 	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:43); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akk,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-414289985
https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-424963752:86,Availability,error,error-code-,86,https://gatkforums.broadinstitute.org/firecloud/discussion/12490/getting-lots-of-papi-error-code-10-message-14-errors,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-424963752
https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-424963752:111,Availability,error,errors,111,https://gatkforums.broadinstitute.org/firecloud/discussion/12490/getting-lots-of-papi-error-code-10-message-14-errors,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-424963752
https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-424963752:100,Integrability,message,message-,100,https://gatkforums.broadinstitute.org/firecloud/discussion/12490/getting-lots-of-papi-error-code-10-message-14-errors,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3855#issuecomment-424963752
https://github.com/broadinstitute/cromwell/issues/3860#issuecomment-422481001:108,Modifiability,config,configurable,108,"Hi @DaveRidic - if you're in a server mode absolutely they can run in parallel. However note that there are configurable limits, e.g. https://github.com/broadinstitute/cromwell/blob/develop/cromwell.examples.conf#L31. What backend are you using?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3860#issuecomment-422481001
https://github.com/broadinstitute/cromwell/issues/3860#issuecomment-1728318541:50,Deployability,update,update,50,"HI, having the same issue. Are there plans for an update? Happy to put in a MR to fix the type here! let me know ! Thanks",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3860#issuecomment-1728318541
https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495:325,Availability,error,error,325,"I'm experiencing the issue, running the Broad ""gatk4-data-processing"" pipeline on their sample data, on Google Cloud. Repository with their code: https://github.com/gatk-workflows/gatk4-data-processing. The only change I made to the .wdl was setting Pre-emption to 0, although previous runs with ""3"" resulted in the the same error. I also doubled the size of the ""agg_large_disk"" to 800 GB, because I thought I was running out of space during merging, although the error seems consistent. Relevant log:. `PipelinesApiAsyncBackendJobExecutionActor [UUID(dba9b85f)PreProcessingForVariantDiscovery_GATK4.SamToFastqAndBwaMem:11:1]: Status change from Running to Success; 2019-01-18 18:43:32,761 cromwell-system-akka.dispatchers.backend-dispatcher-362 INFO - PipelinesApiAsyncBackendJobExecutionActor [UUID(dba9b85f)PreProcessingForVariantDiscovery_GATK4.SamToFastqAndBwaMem:6:1]: Status change from Running to Success; 2019-01-18 18:43:33,255 cromwell-system-akka.dispatchers.engine-dispatcher-5 ERROR - WorkflowManagerActor Workflow dba9b85f-e9ea-4e78-9a04-ed1babbb9ebc failed (during ExecutingWorkflowState): java.lang.Exception: Task PreProcessingForVariantDiscovery_GATK4.MergeBamAlignment:23:1 failed. The job was stopped before the command finished. PAPI error code 2. Execution failed: pulling image: docker pull: running [""docker"" ""pull"" ""broadinstitute/gatk@sha256:1532dec11e05c471f827f59efdd9ff978e63ebe8f7292adf56c406374c131f71""]: exit status 1 (standard error: ""failed to register layer: Error processing tar file(exit status 1): write /opt/miniconda/envs/gatk/lib/python3.6/site-packages/sklearn/datasets/__pycache__/olivetti_faces.cpython-36.pyc: no space left on device\n""); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:79); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.sca",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495
https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495:465,Availability,error,error,465,"I'm experiencing the issue, running the Broad ""gatk4-data-processing"" pipeline on their sample data, on Google Cloud. Repository with their code: https://github.com/gatk-workflows/gatk4-data-processing. The only change I made to the .wdl was setting Pre-emption to 0, although previous runs with ""3"" resulted in the the same error. I also doubled the size of the ""agg_large_disk"" to 800 GB, because I thought I was running out of space during merging, although the error seems consistent. Relevant log:. `PipelinesApiAsyncBackendJobExecutionActor [UUID(dba9b85f)PreProcessingForVariantDiscovery_GATK4.SamToFastqAndBwaMem:11:1]: Status change from Running to Success; 2019-01-18 18:43:32,761 cromwell-system-akka.dispatchers.backend-dispatcher-362 INFO - PipelinesApiAsyncBackendJobExecutionActor [UUID(dba9b85f)PreProcessingForVariantDiscovery_GATK4.SamToFastqAndBwaMem:6:1]: Status change from Running to Success; 2019-01-18 18:43:33,255 cromwell-system-akka.dispatchers.engine-dispatcher-5 ERROR - WorkflowManagerActor Workflow dba9b85f-e9ea-4e78-9a04-ed1babbb9ebc failed (during ExecutingWorkflowState): java.lang.Exception: Task PreProcessingForVariantDiscovery_GATK4.MergeBamAlignment:23:1 failed. The job was stopped before the command finished. PAPI error code 2. Execution failed: pulling image: docker pull: running [""docker"" ""pull"" ""broadinstitute/gatk@sha256:1532dec11e05c471f827f59efdd9ff978e63ebe8f7292adf56c406374c131f71""]: exit status 1 (standard error: ""failed to register layer: Error processing tar file(exit status 1): write /opt/miniconda/envs/gatk/lib/python3.6/site-packages/sklearn/datasets/__pycache__/olivetti_faces.cpython-36.pyc: no space left on device\n""); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:79); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.sca",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495
https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495:992,Availability,ERROR,ERROR,992,"oad ""gatk4-data-processing"" pipeline on their sample data, on Google Cloud. Repository with their code: https://github.com/gatk-workflows/gatk4-data-processing. The only change I made to the .wdl was setting Pre-emption to 0, although previous runs with ""3"" resulted in the the same error. I also doubled the size of the ""agg_large_disk"" to 800 GB, because I thought I was running out of space during merging, although the error seems consistent. Relevant log:. `PipelinesApiAsyncBackendJobExecutionActor [UUID(dba9b85f)PreProcessingForVariantDiscovery_GATK4.SamToFastqAndBwaMem:11:1]: Status change from Running to Success; 2019-01-18 18:43:32,761 cromwell-system-akka.dispatchers.backend-dispatcher-362 INFO - PipelinesApiAsyncBackendJobExecutionActor [UUID(dba9b85f)PreProcessingForVariantDiscovery_GATK4.SamToFastqAndBwaMem:6:1]: Status change from Running to Success; 2019-01-18 18:43:33,255 cromwell-system-akka.dispatchers.engine-dispatcher-5 ERROR - WorkflowManagerActor Workflow dba9b85f-e9ea-4e78-9a04-ed1babbb9ebc failed (during ExecutingWorkflowState): java.lang.Exception: Task PreProcessingForVariantDiscovery_GATK4.MergeBamAlignment:23:1 failed. The job was stopped before the command finished. PAPI error code 2. Execution failed: pulling image: docker pull: running [""docker"" ""pull"" ""broadinstitute/gatk@sha256:1532dec11e05c471f827f59efdd9ff978e63ebe8f7292adf56c406374c131f71""]: exit status 1 (standard error: ""failed to register layer: Error processing tar file(exit status 1): write /opt/miniconda/envs/gatk/lib/python3.6/site-packages/sklearn/datasets/__pycache__/olivetti_faces.cpython-36.pyc: no space left on device\n""); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:79); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:585); 	at ; cromwell.backend.google.pi",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495
https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495:1257,Availability,error,error,1257,"n to 0, although previous runs with ""3"" resulted in the the same error. I also doubled the size of the ""agg_large_disk"" to 800 GB, because I thought I was running out of space during merging, although the error seems consistent. Relevant log:. `PipelinesApiAsyncBackendJobExecutionActor [UUID(dba9b85f)PreProcessingForVariantDiscovery_GATK4.SamToFastqAndBwaMem:11:1]: Status change from Running to Success; 2019-01-18 18:43:32,761 cromwell-system-akka.dispatchers.backend-dispatcher-362 INFO - PipelinesApiAsyncBackendJobExecutionActor [UUID(dba9b85f)PreProcessingForVariantDiscovery_GATK4.SamToFastqAndBwaMem:6:1]: Status change from Running to Success; 2019-01-18 18:43:33,255 cromwell-system-akka.dispatchers.engine-dispatcher-5 ERROR - WorkflowManagerActor Workflow dba9b85f-e9ea-4e78-9a04-ed1babbb9ebc failed (during ExecutingWorkflowState): java.lang.Exception: Task PreProcessingForVariantDiscovery_GATK4.MergeBamAlignment:23:1 failed. The job was stopped before the command finished. PAPI error code 2. Execution failed: pulling image: docker pull: running [""docker"" ""pull"" ""broadinstitute/gatk@sha256:1532dec11e05c471f827f59efdd9ff978e63ebe8f7292adf56c406374c131f71""]: exit status 1 (standard error: ""failed to register layer: Error processing tar file(exit status 1): write /opt/miniconda/envs/gatk/lib/python3.6/site-packages/sklearn/datasets/__pycache__/olivetti_faces.cpython-36.pyc: no space left on device\n""); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:79); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:585); 	at ; cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:592); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActo",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495
https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495:1462,Availability,error,error,1462,"t of space during merging, although the error seems consistent. Relevant log:. `PipelinesApiAsyncBackendJobExecutionActor [UUID(dba9b85f)PreProcessingForVariantDiscovery_GATK4.SamToFastqAndBwaMem:11:1]: Status change from Running to Success; 2019-01-18 18:43:32,761 cromwell-system-akka.dispatchers.backend-dispatcher-362 INFO - PipelinesApiAsyncBackendJobExecutionActor [UUID(dba9b85f)PreProcessingForVariantDiscovery_GATK4.SamToFastqAndBwaMem:6:1]: Status change from Running to Success; 2019-01-18 18:43:33,255 cromwell-system-akka.dispatchers.engine-dispatcher-5 ERROR - WorkflowManagerActor Workflow dba9b85f-e9ea-4e78-9a04-ed1babbb9ebc failed (during ExecutingWorkflowState): java.lang.Exception: Task PreProcessingForVariantDiscovery_GATK4.MergeBamAlignment:23:1 failed. The job was stopped before the command finished. PAPI error code 2. Execution failed: pulling image: docker pull: running [""docker"" ""pull"" ""broadinstitute/gatk@sha256:1532dec11e05c471f827f59efdd9ff978e63ebe8f7292adf56c406374c131f71""]: exit status 1 (standard error: ""failed to register layer: Error processing tar file(exit status 1): write /opt/miniconda/envs/gatk/lib/python3.6/site-packages/sklearn/datasets/__pycache__/olivetti_faces.cpython-36.pyc: no space left on device\n""); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:79); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:585); 	at ; cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:592); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:83); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResul",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495
https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495:1496,Availability,Error,Error,1496,"t of space during merging, although the error seems consistent. Relevant log:. `PipelinesApiAsyncBackendJobExecutionActor [UUID(dba9b85f)PreProcessingForVariantDiscovery_GATK4.SamToFastqAndBwaMem:11:1]: Status change from Running to Success; 2019-01-18 18:43:32,761 cromwell-system-akka.dispatchers.backend-dispatcher-362 INFO - PipelinesApiAsyncBackendJobExecutionActor [UUID(dba9b85f)PreProcessingForVariantDiscovery_GATK4.SamToFastqAndBwaMem:6:1]: Status change from Running to Success; 2019-01-18 18:43:33,255 cromwell-system-akka.dispatchers.engine-dispatcher-5 ERROR - WorkflowManagerActor Workflow dba9b85f-e9ea-4e78-9a04-ed1babbb9ebc failed (during ExecutingWorkflowState): java.lang.Exception: Task PreProcessingForVariantDiscovery_GATK4.MergeBamAlignment:23:1 failed. The job was stopped before the command finished. PAPI error code 2. Execution failed: pulling image: docker pull: running [""docker"" ""pull"" ""broadinstitute/gatk@sha256:1532dec11e05c471f827f59efdd9ff978e63ebe8f7292adf56c406374c131f71""]: exit status 1 (standard error: ""failed to register layer: Error processing tar file(exit status 1): write /opt/miniconda/envs/gatk/lib/python3.6/site-packages/sklearn/datasets/__pycache__/olivetti_faces.cpython-36.pyc: no space left on device\n""); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:79); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:585); 	at ; cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:592); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:83); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResul",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495
https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495:2664,Availability,recover,recoverWith,2664," on device\n""); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:79); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:585); 	at ; cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:592); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:83); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1099); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1095); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); 	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akk",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495
https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495:70,Deployability,pipeline,pipeline,70,"I'm experiencing the issue, running the Broad ""gatk4-data-processing"" pipeline on their sample data, on Google Cloud. Repository with their code: https://github.com/gatk-workflows/gatk4-data-processing. The only change I made to the .wdl was setting Pre-emption to 0, although previous runs with ""3"" resulted in the the same error. I also doubled the size of the ""agg_large_disk"" to 800 GB, because I thought I was running out of space during merging, although the error seems consistent. Relevant log:. `PipelinesApiAsyncBackendJobExecutionActor [UUID(dba9b85f)PreProcessingForVariantDiscovery_GATK4.SamToFastqAndBwaMem:11:1]: Status change from Running to Success; 2019-01-18 18:43:32,761 cromwell-system-akka.dispatchers.backend-dispatcher-362 INFO - PipelinesApiAsyncBackendJobExecutionActor [UUID(dba9b85f)PreProcessingForVariantDiscovery_GATK4.SamToFastqAndBwaMem:6:1]: Status change from Running to Success; 2019-01-18 18:43:33,255 cromwell-system-akka.dispatchers.engine-dispatcher-5 ERROR - WorkflowManagerActor Workflow dba9b85f-e9ea-4e78-9a04-ed1babbb9ebc failed (during ExecutingWorkflowState): java.lang.Exception: Task PreProcessingForVariantDiscovery_GATK4.MergeBamAlignment:23:1 failed. The job was stopped before the command finished. PAPI error code 2. Execution failed: pulling image: docker pull: running [""docker"" ""pull"" ""broadinstitute/gatk@sha256:1532dec11e05c471f827f59efdd9ff978e63ebe8f7292adf56c406374c131f71""]: exit status 1 (standard error: ""failed to register layer: Error processing tar file(exit status 1): write /opt/miniconda/envs/gatk/lib/python3.6/site-packages/sklearn/datasets/__pycache__/olivetti_faces.cpython-36.pyc: no space left on device\n""); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:79); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.sca",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495
https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495:505,Deployability,Pipeline,PipelinesApiAsyncBackendJobExecutionActor,505,"I'm experiencing the issue, running the Broad ""gatk4-data-processing"" pipeline on their sample data, on Google Cloud. Repository with their code: https://github.com/gatk-workflows/gatk4-data-processing. The only change I made to the .wdl was setting Pre-emption to 0, although previous runs with ""3"" resulted in the the same error. I also doubled the size of the ""agg_large_disk"" to 800 GB, because I thought I was running out of space during merging, although the error seems consistent. Relevant log:. `PipelinesApiAsyncBackendJobExecutionActor [UUID(dba9b85f)PreProcessingForVariantDiscovery_GATK4.SamToFastqAndBwaMem:11:1]: Status change from Running to Success; 2019-01-18 18:43:32,761 cromwell-system-akka.dispatchers.backend-dispatcher-362 INFO - PipelinesApiAsyncBackendJobExecutionActor [UUID(dba9b85f)PreProcessingForVariantDiscovery_GATK4.SamToFastqAndBwaMem:6:1]: Status change from Running to Success; 2019-01-18 18:43:33,255 cromwell-system-akka.dispatchers.engine-dispatcher-5 ERROR - WorkflowManagerActor Workflow dba9b85f-e9ea-4e78-9a04-ed1babbb9ebc failed (during ExecutingWorkflowState): java.lang.Exception: Task PreProcessingForVariantDiscovery_GATK4.MergeBamAlignment:23:1 failed. The job was stopped before the command finished. PAPI error code 2. Execution failed: pulling image: docker pull: running [""docker"" ""pull"" ""broadinstitute/gatk@sha256:1532dec11e05c471f827f59efdd9ff978e63ebe8f7292adf56c406374c131f71""]: exit status 1 (standard error: ""failed to register layer: Error processing tar file(exit status 1): write /opt/miniconda/envs/gatk/lib/python3.6/site-packages/sklearn/datasets/__pycache__/olivetti_faces.cpython-36.pyc: no space left on device\n""); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:79); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.sca",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495
https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495:754,Deployability,Pipeline,PipelinesApiAsyncBackendJobExecutionActor,754,"I'm experiencing the issue, running the Broad ""gatk4-data-processing"" pipeline on their sample data, on Google Cloud. Repository with their code: https://github.com/gatk-workflows/gatk4-data-processing. The only change I made to the .wdl was setting Pre-emption to 0, although previous runs with ""3"" resulted in the the same error. I also doubled the size of the ""agg_large_disk"" to 800 GB, because I thought I was running out of space during merging, although the error seems consistent. Relevant log:. `PipelinesApiAsyncBackendJobExecutionActor [UUID(dba9b85f)PreProcessingForVariantDiscovery_GATK4.SamToFastqAndBwaMem:11:1]: Status change from Running to Success; 2019-01-18 18:43:32,761 cromwell-system-akka.dispatchers.backend-dispatcher-362 INFO - PipelinesApiAsyncBackendJobExecutionActor [UUID(dba9b85f)PreProcessingForVariantDiscovery_GATK4.SamToFastqAndBwaMem:6:1]: Status change from Running to Success; 2019-01-18 18:43:33,255 cromwell-system-akka.dispatchers.engine-dispatcher-5 ERROR - WorkflowManagerActor Workflow dba9b85f-e9ea-4e78-9a04-ed1babbb9ebc failed (during ExecutingWorkflowState): java.lang.Exception: Task PreProcessingForVariantDiscovery_GATK4.MergeBamAlignment:23:1 failed. The job was stopped before the command finished. PAPI error code 2. Execution failed: pulling image: docker pull: running [""docker"" ""pull"" ""broadinstitute/gatk@sha256:1532dec11e05c471f827f59efdd9ff978e63ebe8f7292adf56c406374c131f71""]: exit status 1 (standard error: ""failed to register layer: Error processing tar file(exit status 1): write /opt/miniconda/envs/gatk/lib/python3.6/site-packages/sklearn/datasets/__pycache__/olivetti_faces.cpython-36.pyc: no space left on device\n""); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:79); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.sca",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495
https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495:1714,Deployability,pipeline,pipelines,1714,"hers.backend-dispatcher-362 INFO - PipelinesApiAsyncBackendJobExecutionActor [UUID(dba9b85f)PreProcessingForVariantDiscovery_GATK4.SamToFastqAndBwaMem:6:1]: Status change from Running to Success; 2019-01-18 18:43:33,255 cromwell-system-akka.dispatchers.engine-dispatcher-5 ERROR - WorkflowManagerActor Workflow dba9b85f-e9ea-4e78-9a04-ed1babbb9ebc failed (during ExecutingWorkflowState): java.lang.Exception: Task PreProcessingForVariantDiscovery_GATK4.MergeBamAlignment:23:1 failed. The job was stopped before the command finished. PAPI error code 2. Execution failed: pulling image: docker pull: running [""docker"" ""pull"" ""broadinstitute/gatk@sha256:1532dec11e05c471f827f59efdd9ff978e63ebe8f7292adf56c406374c131f71""]: exit status 1 (standard error: ""failed to register layer: Error processing tar file(exit status 1): write /opt/miniconda/envs/gatk/lib/python3.6/site-packages/sklearn/datasets/__pycache__/olivetti_faces.cpython-36.pyc: no space left on device\n""); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:79); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:585); 	at ; cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:592); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:83); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1099); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1095); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.i",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495
https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495:1731,Deployability,Pipeline,PipelinesApiAsyncBackendJobExecutionActor,1731,"- PipelinesApiAsyncBackendJobExecutionActor [UUID(dba9b85f)PreProcessingForVariantDiscovery_GATK4.SamToFastqAndBwaMem:6:1]: Status change from Running to Success; 2019-01-18 18:43:33,255 cromwell-system-akka.dispatchers.engine-dispatcher-5 ERROR - WorkflowManagerActor Workflow dba9b85f-e9ea-4e78-9a04-ed1babbb9ebc failed (during ExecutingWorkflowState): java.lang.Exception: Task PreProcessingForVariantDiscovery_GATK4.MergeBamAlignment:23:1 failed. The job was stopped before the command finished. PAPI error code 2. Execution failed: pulling image: docker pull: running [""docker"" ""pull"" ""broadinstitute/gatk@sha256:1532dec11e05c471f827f59efdd9ff978e63ebe8f7292adf56c406374c131f71""]: exit status 1 (standard error: ""failed to register layer: Error processing tar file(exit status 1): write /opt/miniconda/envs/gatk/lib/python3.6/site-packages/sklearn/datasets/__pycache__/olivetti_faces.cpython-36.pyc: no space left on device\n""); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:79); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:585); 	at ; cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:592); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:83); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1099); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1095); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.impl.Promise.$anonfun$transformWith",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495
https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495:1792,Deployability,Pipeline,PipelinesApiAsyncBackendJobExecutionActor,1792,"a9b85f)PreProcessingForVariantDiscovery_GATK4.SamToFastqAndBwaMem:6:1]: Status change from Running to Success; 2019-01-18 18:43:33,255 cromwell-system-akka.dispatchers.engine-dispatcher-5 ERROR - WorkflowManagerActor Workflow dba9b85f-e9ea-4e78-9a04-ed1babbb9ebc failed (during ExecutingWorkflowState): java.lang.Exception: Task PreProcessingForVariantDiscovery_GATK4.MergeBamAlignment:23:1 failed. The job was stopped before the command finished. PAPI error code 2. Execution failed: pulling image: docker pull: running [""docker"" ""pull"" ""broadinstitute/gatk@sha256:1532dec11e05c471f827f59efdd9ff978e63ebe8f7292adf56c406374c131f71""]: exit status 1 (standard error: ""failed to register layer: Error processing tar file(exit status 1): write /opt/miniconda/envs/gatk/lib/python3.6/site-packages/sklearn/datasets/__pycache__/olivetti_faces.cpython-36.pyc: no space left on device\n""); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:79); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:585); 	at ; cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:592); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:83); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1099); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1095); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.Cal",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495
https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495:1873,Deployability,pipeline,pipelines,1873,"atus change from Running to Success; 2019-01-18 18:43:33,255 cromwell-system-akka.dispatchers.engine-dispatcher-5 ERROR - WorkflowManagerActor Workflow dba9b85f-e9ea-4e78-9a04-ed1babbb9ebc failed (during ExecutingWorkflowState): java.lang.Exception: Task PreProcessingForVariantDiscovery_GATK4.MergeBamAlignment:23:1 failed. The job was stopped before the command finished. PAPI error code 2. Execution failed: pulling image: docker pull: running [""docker"" ""pull"" ""broadinstitute/gatk@sha256:1532dec11e05c471f827f59efdd9ff978e63ebe8f7292adf56c406374c131f71""]: exit status 1 (standard error: ""failed to register layer: Error processing tar file(exit status 1): write /opt/miniconda/envs/gatk/lib/python3.6/site-packages/sklearn/datasets/__pycache__/olivetti_faces.cpython-36.pyc: no space left on device\n""); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:79); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:585); 	at ; cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:592); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:83); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1099); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1095); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.BatchingExecutor$Ab",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495
https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495:1890,Deployability,Pipeline,PipelinesApiAsyncBackendJobExecutionActor,1890,"ss; 2019-01-18 18:43:33,255 cromwell-system-akka.dispatchers.engine-dispatcher-5 ERROR - WorkflowManagerActor Workflow dba9b85f-e9ea-4e78-9a04-ed1babbb9ebc failed (during ExecutingWorkflowState): java.lang.Exception: Task PreProcessingForVariantDiscovery_GATK4.MergeBamAlignment:23:1 failed. The job was stopped before the command finished. PAPI error code 2. Execution failed: pulling image: docker pull: running [""docker"" ""pull"" ""broadinstitute/gatk@sha256:1532dec11e05c471f827f59efdd9ff978e63ebe8f7292adf56c406374c131f71""]: exit status 1 (standard error: ""failed to register layer: Error processing tar file(exit status 1): write /opt/miniconda/envs/gatk/lib/python3.6/site-packages/sklearn/datasets/__pycache__/olivetti_faces.cpython-36.pyc: no space left on device\n""); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:79); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:585); 	at ; cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:592); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:83); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1099); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1095); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(Batching",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495
https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495:1956,Deployability,Pipeline,PipelinesApiAsyncBackendJobExecutionActor,1956,"tchers.engine-dispatcher-5 ERROR - WorkflowManagerActor Workflow dba9b85f-e9ea-4e78-9a04-ed1babbb9ebc failed (during ExecutingWorkflowState): java.lang.Exception: Task PreProcessingForVariantDiscovery_GATK4.MergeBamAlignment:23:1 failed. The job was stopped before the command finished. PAPI error code 2. Execution failed: pulling image: docker pull: running [""docker"" ""pull"" ""broadinstitute/gatk@sha256:1532dec11e05c471f827f59efdd9ff978e63ebe8f7292adf56c406374c131f71""]: exit status 1 (standard error: ""failed to register layer: Error processing tar file(exit status 1): write /opt/miniconda/envs/gatk/lib/python3.6/site-packages/sklearn/datasets/__pycache__/olivetti_faces.cpython-36.pyc: no space left on device\n""); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:79); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:585); 	at ; cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:592); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:83); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1099); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1095); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495
https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495:2040,Deployability,pipeline,pipelines,2040,"e78-9a04-ed1babbb9ebc failed (during ExecutingWorkflowState): java.lang.Exception: Task PreProcessingForVariantDiscovery_GATK4.MergeBamAlignment:23:1 failed. The job was stopped before the command finished. PAPI error code 2. Execution failed: pulling image: docker pull: running [""docker"" ""pull"" ""broadinstitute/gatk@sha256:1532dec11e05c471f827f59efdd9ff978e63ebe8f7292adf56c406374c131f71""]: exit status 1 (standard error: ""failed to register layer: Error processing tar file(exit status 1): write /opt/miniconda/envs/gatk/lib/python3.6/site-packages/sklearn/datasets/__pycache__/olivetti_faces.cpython-36.pyc: no space left on device\n""); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:79); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:585); 	at ; cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:592); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:83); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1099); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1095); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); 	at scala.runtime.jav",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495
https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495:2057,Deployability,Pipeline,PipelinesApiAsyncBackendJobExecutionActor,2057,"ing ExecutingWorkflowState): java.lang.Exception: Task PreProcessingForVariantDiscovery_GATK4.MergeBamAlignment:23:1 failed. The job was stopped before the command finished. PAPI error code 2. Execution failed: pulling image: docker pull: running [""docker"" ""pull"" ""broadinstitute/gatk@sha256:1532dec11e05c471f827f59efdd9ff978e63ebe8f7292adf56c406374c131f71""]: exit status 1 (standard error: ""failed to register layer: Error processing tar file(exit status 1): write /opt/miniconda/envs/gatk/lib/python3.6/site-packages/sklearn/datasets/__pycache__/olivetti_faces.cpython-36.pyc: no space left on device\n""); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:79); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:585); 	at ; cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:592); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:83); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1099); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1095); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunct",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495
https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495:2122,Deployability,Pipeline,PipelinesApiAsyncBackendJobExecutionActor,2122,"k PreProcessingForVariantDiscovery_GATK4.MergeBamAlignment:23:1 failed. The job was stopped before the command finished. PAPI error code 2. Execution failed: pulling image: docker pull: running [""docker"" ""pull"" ""broadinstitute/gatk@sha256:1532dec11e05c471f827f59efdd9ff978e63ebe8f7292adf56c406374c131f71""]: exit status 1 (standard error: ""failed to register layer: Error processing tar file(exit status 1): write /opt/miniconda/envs/gatk/lib/python3.6/site-packages/sklearn/datasets/__pycache__/olivetti_faces.cpython-36.pyc: no space left on device\n""); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:79); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:585); 	at ; cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:592); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:83); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1099); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1095); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); 	at scala.concurrent.BlockContex",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495
https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495:2204,Deployability,pipeline,pipelines,2204,"b was stopped before the command finished. PAPI error code 2. Execution failed: pulling image: docker pull: running [""docker"" ""pull"" ""broadinstitute/gatk@sha256:1532dec11e05c471f827f59efdd9ff978e63ebe8f7292adf56c406374c131f71""]: exit status 1 (standard error: ""failed to register layer: Error processing tar file(exit status 1): write /opt/miniconda/envs/gatk/lib/python3.6/site-packages/sklearn/datasets/__pycache__/olivetti_faces.cpython-36.pyc: no space left on device\n""); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:79); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:585); 	at ; cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:592); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:83); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1099); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1095); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); 	at akka.dispatch.BatchingExecuto",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495
https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495:2221,Deployability,Pipeline,PipelinesApiAsyncBackendJobExecutionActor,2221,"finished. PAPI error code 2. Execution failed: pulling image: docker pull: running [""docker"" ""pull"" ""broadinstitute/gatk@sha256:1532dec11e05c471f827f59efdd9ff978e63ebe8f7292adf56c406374c131f71""]: exit status 1 (standard error: ""failed to register layer: Error processing tar file(exit status 1): write /opt/miniconda/envs/gatk/lib/python3.6/site-packages/sklearn/datasets/__pycache__/olivetti_faces.cpython-36.pyc: no space left on device\n""); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:79); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:585); 	at ; cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:592); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:83); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1099); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1095); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); 	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExec",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495
https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495:2286,Deployability,Pipeline,PipelinesApiAsyncBackendJobExecutionActor,2286,"g image: docker pull: running [""docker"" ""pull"" ""broadinstitute/gatk@sha256:1532dec11e05c471f827f59efdd9ff978e63ebe8f7292adf56c406374c131f71""]: exit status 1 (standard error: ""failed to register layer: Error processing tar file(exit status 1): write /opt/miniconda/envs/gatk/lib/python3.6/site-packages/sklearn/datasets/__pycache__/olivetti_faces.cpython-36.pyc: no space left on device\n""); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:79); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:585); 	at ; cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:592); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:83); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1099); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1095); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); 	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91); 	at akka.dispatch.TaskInvocation.run(A",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495
https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495:2637,Performance,concurren,concurrent,2637,"python-36.pyc: no space left on device\n""); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:79); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:585); 	at ; cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:592); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:83); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1099); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1095); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); 	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495
https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495:2707,Performance,concurren,concurrent,2707,e.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:79); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:585); 	at ; cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:592); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:83); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1099); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1095); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); 	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.ru,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495
https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495:2785,Performance,concurren,concurrent,2785,n(PipelinesApiAsyncBackendJobExecutionActor.scala:79); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:585); 	at ; cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:592); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:83); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1099); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1095); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); 	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); `; [sampleData_gatk-sample-out_logging_outpu,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495
https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495:3110,Performance,concurren,concurrent,3110,BackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:585); 	at ; cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:592); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:83); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1099); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1095); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); 	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); `; [sampleData_gatk-sample-out_logging_output (3).txt](https://github.com/broadinstitute/cromwell/files/2774220/sampleData_gatk-sample-out_logging_output.3.txt),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495
https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495:2664,Safety,recover,recoverWith,2664," on device\n""); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:79); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:585); 	at ; cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:592); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:83); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1099); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1095); 	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); 	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akk",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495
https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495:498,Testability,log,log,498,"I'm experiencing the issue, running the Broad ""gatk4-data-processing"" pipeline on their sample data, on Google Cloud. Repository with their code: https://github.com/gatk-workflows/gatk4-data-processing. The only change I made to the .wdl was setting Pre-emption to 0, although previous runs with ""3"" resulted in the the same error. I also doubled the size of the ""agg_large_disk"" to 800 GB, because I thought I was running out of space during merging, although the error seems consistent. Relevant log:. `PipelinesApiAsyncBackendJobExecutionActor [UUID(dba9b85f)PreProcessingForVariantDiscovery_GATK4.SamToFastqAndBwaMem:11:1]: Status change from Running to Success; 2019-01-18 18:43:32,761 cromwell-system-akka.dispatchers.backend-dispatcher-362 INFO - PipelinesApiAsyncBackendJobExecutionActor [UUID(dba9b85f)PreProcessingForVariantDiscovery_GATK4.SamToFastqAndBwaMem:6:1]: Status change from Running to Success; 2019-01-18 18:43:33,255 cromwell-system-akka.dispatchers.engine-dispatcher-5 ERROR - WorkflowManagerActor Workflow dba9b85f-e9ea-4e78-9a04-ed1babbb9ebc failed (during ExecutingWorkflowState): java.lang.Exception: Task PreProcessingForVariantDiscovery_GATK4.MergeBamAlignment:23:1 failed. The job was stopped before the command finished. PAPI error code 2. Execution failed: pulling image: docker pull: running [""docker"" ""pull"" ""broadinstitute/gatk@sha256:1532dec11e05c471f827f59efdd9ff978e63ebe8f7292adf56c406374c131f71""]: exit status 1 (standard error: ""failed to register layer: Error processing tar file(exit status 1): write /opt/miniconda/envs/gatk/lib/python3.6/site-packages/sklearn/datasets/__pycache__/olivetti_faces.cpython-36.pyc: no space left on device\n""); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:79); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.sca",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3861#issuecomment-455657495
https://github.com/broadinstitute/cromwell/issues/3862#issuecomment-402788985:160,Deployability,release,release,160,"@vsoch Just a heads up, @katevoss did point out that her fix will be on the `/develop` version of RTD shortly but won't be on `/stable` until the next Cromwell release",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3862#issuecomment-402788985
https://github.com/broadinstitute/cromwell/issues/3862#issuecomment-402804431:80,Availability,error,errors,80,"okay awesome, thanks muchly! I have seen readthedocs have (rather silent) build errors, so it's very good to have a develop --> stable branch flow. It will be much appreciated as I read about cromwell",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3862#issuecomment-402804431
https://github.com/broadinstitute/cromwell/issues/3863#issuecomment-402838047:88,Security,validat,validation,88,"Thanks! I think that the `""Report this Bug""` is *probably* a typo as long as the static validation in `womtool validate` *does* fail for this workflow. I this workflow started, ran a few jobs and **then** this happened, we should fix that ASAP.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3863#issuecomment-402838047
https://github.com/broadinstitute/cromwell/issues/3863#issuecomment-402838047:111,Security,validat,validate,111,"Thanks! I think that the `""Report this Bug""` is *probably* a typo as long as the static validation in `womtool validate` *does* fail for this workflow. I this workflow started, ran a few jobs and **then** this happened, we should fix that ASAP.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3863#issuecomment-402838047
https://github.com/broadinstitute/cromwell/issues/3863#issuecomment-402842188:183,Availability,error,error,183,"@EvanTheB thanks for this report! . I've [added a test](https://github.com/broadinstitute/cromwell/pull/3867) to make sure this check happens during static validation and amended the error message. I'll link this issue so that it gets closed when the PR merges, are you all set with how to fix the problem in your expression?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3863#issuecomment-402842188
https://github.com/broadinstitute/cromwell/issues/3863#issuecomment-402842188:189,Integrability,message,message,189,"@EvanTheB thanks for this report! . I've [added a test](https://github.com/broadinstitute/cromwell/pull/3867) to make sure this check happens during static validation and amended the error message. I'll link this issue so that it gets closed when the PR merges, are you all set with how to fix the problem in your expression?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3863#issuecomment-402842188
https://github.com/broadinstitute/cromwell/issues/3863#issuecomment-402842188:156,Security,validat,validation,156,"@EvanTheB thanks for this report! . I've [added a test](https://github.com/broadinstitute/cromwell/pull/3867) to make sure this check happens during static validation and amended the error message. I'll link this issue so that it gets closed when the PR merges, are you all set with how to fix the problem in your expression?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3863#issuecomment-402842188
https://github.com/broadinstitute/cromwell/issues/3863#issuecomment-402842188:50,Testability,test,test,50,"@EvanTheB thanks for this report! . I've [added a test](https://github.com/broadinstitute/cromwell/pull/3867) to make sure this check happens during static validation and amended the error message. I'll link this issue so that it gets closed when the PR merges, are you all set with how to fix the problem in your expression?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3863#issuecomment-402842188
https://github.com/broadinstitute/cromwell/issues/3863#issuecomment-402886702:151,Availability,error,error,151,"Hello, I posted this bug because the validator does NOT do a check. IE I run the validator on every WDL I submit, but the validator did not catch this error. The error happens, as you said, after many tasks have run already.; [wot.wdl.txt](https://github.com/broadinstitute/cromwell/files/2168605/wot.wdl.txt)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3863#issuecomment-402886702
https://github.com/broadinstitute/cromwell/issues/3863#issuecomment-402886702:162,Availability,error,error,162,"Hello, I posted this bug because the validator does NOT do a check. IE I run the validator on every WDL I submit, but the validator did not catch this error. The error happens, as you said, after many tasks have run already.; [wot.wdl.txt](https://github.com/broadinstitute/cromwell/files/2168605/wot.wdl.txt)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3863#issuecomment-402886702
https://github.com/broadinstitute/cromwell/issues/3863#issuecomment-402886702:37,Security,validat,validator,37,"Hello, I posted this bug because the validator does NOT do a check. IE I run the validator on every WDL I submit, but the validator did not catch this error. The error happens, as you said, after many tasks have run already.; [wot.wdl.txt](https://github.com/broadinstitute/cromwell/files/2168605/wot.wdl.txt)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3863#issuecomment-402886702
https://github.com/broadinstitute/cromwell/issues/3863#issuecomment-402886702:81,Security,validat,validator,81,"Hello, I posted this bug because the validator does NOT do a check. IE I run the validator on every WDL I submit, but the validator did not catch this error. The error happens, as you said, after many tasks have run already.; [wot.wdl.txt](https://github.com/broadinstitute/cromwell/files/2168605/wot.wdl.txt)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3863#issuecomment-402886702
https://github.com/broadinstitute/cromwell/issues/3863#issuecomment-402886702:122,Security,validat,validator,122,"Hello, I posted this bug because the validator does NOT do a check. IE I run the validator on every WDL I submit, but the validator did not catch this error. The error happens, as you said, after many tasks have run already.; [wot.wdl.txt](https://github.com/broadinstitute/cromwell/files/2168605/wot.wdl.txt)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3863#issuecomment-402886702
https://github.com/broadinstitute/cromwell/issues/3863#issuecomment-403042558:62,Testability,test,test,62,@EvanTheB aha!. There must be something different between our test cases - the most obvious thing I can see is that your expression is in the task definition vs mine in the workflow definition. I'll investigate this now.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3863#issuecomment-403042558
https://github.com/broadinstitute/cromwell/issues/3863#issuecomment-403059207:15,Deployability,update,updated,15,@EvanTheB I've updated my PR with a fix and a new test for this problem in task outputs. Thanks again for the bug report!,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3863#issuecomment-403059207
https://github.com/broadinstitute/cromwell/issues/3863#issuecomment-403059207:50,Testability,test,test,50,@EvanTheB I've updated my PR with a fix and a new test for this problem in task outputs. Thanks again for the bug report!,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3863#issuecomment-403059207
https://github.com/broadinstitute/cromwell/pull/3864#issuecomment-402756505:431,Deployability,update,update,431,"I've been seeing the configurable epilogue more as a ""hey user, here's a place for you to add stuff for your specific setup"" rather than ""you absolutely need your epilogue config to have this if you want your backend to work"", but maybe they're not that far apart after all.; I'd be ok with making it a ""required"" epilogue for cloud backends as long as we make it pretty clear in the changelog that it's required and that a config update is necessary. Also I'm not too worried that anyone has been relying on this anyway since it's a hack to support empty directories which hopefully is not wildly used.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3864#issuecomment-402756505
https://github.com/broadinstitute/cromwell/pull/3864#issuecomment-402756505:21,Modifiability,config,configurable,21,"I've been seeing the configurable epilogue more as a ""hey user, here's a place for you to add stuff for your specific setup"" rather than ""you absolutely need your epilogue config to have this if you want your backend to work"", but maybe they're not that far apart after all.; I'd be ok with making it a ""required"" epilogue for cloud backends as long as we make it pretty clear in the changelog that it's required and that a config update is necessary. Also I'm not too worried that anyone has been relying on this anyway since it's a hack to support empty directories which hopefully is not wildly used.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3864#issuecomment-402756505
https://github.com/broadinstitute/cromwell/pull/3864#issuecomment-402756505:172,Modifiability,config,config,172,"I've been seeing the configurable epilogue more as a ""hey user, here's a place for you to add stuff for your specific setup"" rather than ""you absolutely need your epilogue config to have this if you want your backend to work"", but maybe they're not that far apart after all.; I'd be ok with making it a ""required"" epilogue for cloud backends as long as we make it pretty clear in the changelog that it's required and that a config update is necessary. Also I'm not too worried that anyone has been relying on this anyway since it's a hack to support empty directories which hopefully is not wildly used.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3864#issuecomment-402756505
https://github.com/broadinstitute/cromwell/pull/3864#issuecomment-402756505:424,Modifiability,config,config,424,"I've been seeing the configurable epilogue more as a ""hey user, here's a place for you to add stuff for your specific setup"" rather than ""you absolutely need your epilogue config to have this if you want your backend to work"", but maybe they're not that far apart after all.; I'd be ok with making it a ""required"" epilogue for cloud backends as long as we make it pretty clear in the changelog that it's required and that a config update is necessary. Also I'm not too worried that anyone has been relying on this anyway since it's a hack to support empty directories which hopefully is not wildly used.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3864#issuecomment-402756505
https://github.com/broadinstitute/cromwell/pull/3864#issuecomment-402756505:371,Usability,clear,clear,371,"I've been seeing the configurable epilogue more as a ""hey user, here's a place for you to add stuff for your specific setup"" rather than ""you absolutely need your epilogue config to have this if you want your backend to work"", but maybe they're not that far apart after all.; I'd be ok with making it a ""required"" epilogue for cloud backends as long as we make it pretty clear in the changelog that it's required and that a config update is necessary. Also I'm not too worried that anyone has been relying on this anyway since it's a hack to support empty directories which hopefully is not wildly used.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3864#issuecomment-402756505
https://github.com/broadinstitute/cromwell/issues/3869#issuecomment-403045308:218,Availability,down,downloaded,218,Hi @geoffjentry Thanks for your response. I was trying to walk throught `[Server Mode](http://cromwell.readthedocs.io/en/develop/tutorials/ServerMode/)`. On the `Start the job` section I wasn't able to choose files. I downloaded 33.1 from [(https://github.com/broadinstitute/cromwell/releases)]. Here is the system version:; ```; $ lsb_release -a; No LSB modules are available.; Distributor ID:	Ubuntu; Description:	Ubuntu 16.04.4 LTS; Release:	16.04; Codename:	xenial; ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3869#issuecomment-403045308
https://github.com/broadinstitute/cromwell/issues/3869#issuecomment-403045308:367,Availability,avail,available,367,Hi @geoffjentry Thanks for your response. I was trying to walk throught `[Server Mode](http://cromwell.readthedocs.io/en/develop/tutorials/ServerMode/)`. On the `Start the job` section I wasn't able to choose files. I downloaded 33.1 from [(https://github.com/broadinstitute/cromwell/releases)]. Here is the system version:; ```; $ lsb_release -a; No LSB modules are available.; Distributor ID:	Ubuntu; Description:	Ubuntu 16.04.4 LTS; Release:	16.04; Codename:	xenial; ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3869#issuecomment-403045308
https://github.com/broadinstitute/cromwell/issues/3869#issuecomment-403045308:284,Deployability,release,releases,284,Hi @geoffjentry Thanks for your response. I was trying to walk throught `[Server Mode](http://cromwell.readthedocs.io/en/develop/tutorials/ServerMode/)`. On the `Start the job` section I wasn't able to choose files. I downloaded 33.1 from [(https://github.com/broadinstitute/cromwell/releases)]. Here is the system version:; ```; $ lsb_release -a; No LSB modules are available.; Distributor ID:	Ubuntu; Description:	Ubuntu 16.04.4 LTS; Release:	16.04; Codename:	xenial; ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3869#issuecomment-403045308
https://github.com/broadinstitute/cromwell/issues/3869#issuecomment-403045308:436,Deployability,Release,Release,436,Hi @geoffjentry Thanks for your response. I was trying to walk throught `[Server Mode](http://cromwell.readthedocs.io/en/develop/tutorials/ServerMode/)`. On the `Start the job` section I wasn't able to choose files. I downloaded 33.1 from [(https://github.com/broadinstitute/cromwell/releases)]. Here is the system version:; ```; $ lsb_release -a; No LSB modules are available.; Distributor ID:	Ubuntu; Description:	Ubuntu 16.04.4 LTS; Release:	16.04; Codename:	xenial; ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3869#issuecomment-403045308
https://github.com/broadinstitute/cromwell/issues/3869#issuecomment-403133874:85,Availability,down,downloaded,85,Hi @DadongZ - I can't replicate this. . I run: `java -jar cromwell-33.1.jar server` (downloaded from ; In my browser I go to `http://localhost:8000/swagger/index.html?url=/swagger/cromwell.yaml` and it works fine. Are you doing something differently than this?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3869#issuecomment-403133874
https://github.com/broadinstitute/cromwell/issues/3869#issuecomment-403295623:28,Availability,error,error,28,"Thanks for the report. The ""error"" is reproducible and should be cleaned up, along with the docs. Your original issue would be better discussed over in the [WDL forums](https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team). If the hint below doesn't help, please make a forum post and drop a link here so that others may follow it back. I can post screen shots in the forum plus other users can follow what's going on. 1. To find the button you're probably looking for click on the first ""POST"" and then ""Try it out"". Again happy to post screenshots over in the forum.; 2. The ""error"" seen is a swagger-online error, not a swagger-ui error.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3869#issuecomment-403295623
https://github.com/broadinstitute/cromwell/issues/3869#issuecomment-403295623:595,Availability,error,error,595,"Thanks for the report. The ""error"" is reproducible and should be cleaned up, along with the docs. Your original issue would be better discussed over in the [WDL forums](https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team). If the hint below doesn't help, please make a forum post and drop a link here so that others may follow it back. I can post screen shots in the forum plus other users can follow what's going on. 1. To find the button you're probably looking for click on the first ""POST"" and then ""Try it out"". Again happy to post screenshots over in the forum.; 2. The ""error"" seen is a swagger-online error, not a swagger-ui error.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3869#issuecomment-403295623
https://github.com/broadinstitute/cromwell/issues/3869#issuecomment-403295623:627,Availability,error,error,627,"Thanks for the report. The ""error"" is reproducible and should be cleaned up, along with the docs. Your original issue would be better discussed over in the [WDL forums](https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team). If the hint below doesn't help, please make a forum post and drop a link here so that others may follow it back. I can post screen shots in the forum plus other users can follow what's going on. 1. To find the button you're probably looking for click on the first ""POST"" and then ""Try it out"". Again happy to post screenshots over in the forum.; 2. The ""error"" seen is a swagger-online error, not a swagger-ui error.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3869#issuecomment-403295623
https://github.com/broadinstitute/cromwell/issues/3869#issuecomment-403295623:651,Availability,error,error,651,"Thanks for the report. The ""error"" is reproducible and should be cleaned up, along with the docs. Your original issue would be better discussed over in the [WDL forums](https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team). If the hint below doesn't help, please make a forum post and drop a link here so that others may follow it back. I can post screen shots in the forum plus other users can follow what's going on. 1. To find the button you're probably looking for click on the first ""POST"" and then ""Try it out"". Again happy to post screenshots over in the forum.; 2. The ""error"" seen is a swagger-online error, not a swagger-ui error.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3869#issuecomment-403295623
https://github.com/broadinstitute/cromwell/issues/3873#issuecomment-455261953:241,Integrability,message,message,241,"Sorry @cjllanwarne , I just tested with:; ```; [; {; ""includeSubworkflows"": ""false""; }; ]; ``` ; on https://cromwell.caas-prod.broadinstitute.org which has version `36-fde91e6`, the problem appeared to me again:. ```; {; ""status"": ""fail"",; ""message"": ""Task slick.basic.BasicBackend$DatabaseDef$$anon$2@23304acb rejected from slick.util.AsyncExecutor$$anon$2$$anon$1@233013e3[Running, pool size = 200, active threads = 200, queued tasks = 1000, completed tasks = 2178366]""; }; ```; Maybe the query is too ambitious? I should use pagination or more restrictive query instead?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3873#issuecomment-455261953
https://github.com/broadinstitute/cromwell/issues/3873#issuecomment-455261953:423,Performance,queue,queued,423,"Sorry @cjllanwarne , I just tested with:; ```; [; {; ""includeSubworkflows"": ""false""; }; ]; ``` ; on https://cromwell.caas-prod.broadinstitute.org which has version `36-fde91e6`, the problem appeared to me again:. ```; {; ""status"": ""fail"",; ""message"": ""Task slick.basic.BasicBackend$DatabaseDef$$anon$2@23304acb rejected from slick.util.AsyncExecutor$$anon$2$$anon$1@233013e3[Running, pool size = 200, active threads = 200, queued tasks = 1000, completed tasks = 2178366]""; }; ```; Maybe the query is too ambitious? I should use pagination or more restrictive query instead?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3873#issuecomment-455261953
https://github.com/broadinstitute/cromwell/issues/3873#issuecomment-455261953:28,Testability,test,tested,28,"Sorry @cjllanwarne , I just tested with:; ```; [; {; ""includeSubworkflows"": ""false""; }; ]; ``` ; on https://cromwell.caas-prod.broadinstitute.org which has version `36-fde91e6`, the problem appeared to me again:. ```; {; ""status"": ""fail"",; ""message"": ""Task slick.basic.BasicBackend$DatabaseDef$$anon$2@23304acb rejected from slick.util.AsyncExecutor$$anon$2$$anon$1@233013e3[Running, pool size = 200, active threads = 200, queued tasks = 1000, completed tasks = 2178366]""; }; ```; Maybe the query is too ambitious? I should use pagination or more restrictive query instead?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3873#issuecomment-455261953
https://github.com/broadinstitute/cromwell/issues/3876#issuecomment-403974995:176,Modifiability,config,config,176,"The hard-coded linking you found is part of the ""glob result capturing"" logic, which is a slightly different case from localizing files before job execution (which is why that config option isn't doing anything for you here). I'm not sure I'd want to merge the two concepts since a lot of people need to localize by copying but wouldn't necessarily want to have copies made of every glob output. I don't see any reason why we couldn't also have a `glob-evaluation-method` option with the same sort of priority ordering (except for the yet-another-config-option problem).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3876#issuecomment-403974995
https://github.com/broadinstitute/cromwell/issues/3876#issuecomment-403974995:547,Modifiability,config,config-option,547,"The hard-coded linking you found is part of the ""glob result capturing"" logic, which is a slightly different case from localizing files before job execution (which is why that config option isn't doing anything for you here). I'm not sure I'd want to merge the two concepts since a lot of people need to localize by copying but wouldn't necessarily want to have copies made of every glob output. I don't see any reason why we couldn't also have a `glob-evaluation-method` option with the same sort of priority ordering (except for the yet-another-config-option problem).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3876#issuecomment-403974995
https://github.com/broadinstitute/cromwell/issues/3876#issuecomment-403974995:72,Testability,log,logic,72,"The hard-coded linking you found is part of the ""glob result capturing"" logic, which is a slightly different case from localizing files before job execution (which is why that config option isn't doing anything for you here). I'm not sure I'd want to merge the two concepts since a lot of people need to localize by copying but wouldn't necessarily want to have copies made of every glob output. I don't see any reason why we couldn't also have a `glob-evaluation-method` option with the same sort of priority ordering (except for the yet-another-config-option problem).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3876#issuecomment-403974995
https://github.com/broadinstitute/cromwell/issues/3878#issuecomment-407144286:52,Deployability,release,releases,52,fixed in https://github.com/broadinstitute/cromwell/releases/tag/34,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3878#issuecomment-407144286
https://github.com/broadinstitute/cromwell/issues/3881#issuecomment-620049532:77,Deployability,pipeline,pipelines,77,"Hi,. I am wondering if there was progress made on that issue? . Running GATK pipelines uses a lot of disk space for intermediate (bam) files, which is problematic for large cohorts. It seems that removing those files before the pipeline complete would break the Cromwell cache.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3881#issuecomment-620049532
https://github.com/broadinstitute/cromwell/issues/3881#issuecomment-620049532:228,Deployability,pipeline,pipeline,228,"Hi,. I am wondering if there was progress made on that issue? . Running GATK pipelines uses a lot of disk space for intermediate (bam) files, which is problematic for large cohorts. It seems that removing those files before the pipeline complete would break the Cromwell cache.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3881#issuecomment-620049532
https://github.com/broadinstitute/cromwell/issues/3881#issuecomment-620049532:271,Performance,cache,cache,271,"Hi,. I am wondering if there was progress made on that issue? . Running GATK pipelines uses a lot of disk space for intermediate (bam) files, which is problematic for large cohorts. It seems that removing those files before the pipeline complete would break the Cromwell cache.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3881#issuecomment-620049532
https://github.com/broadinstitute/cromwell/issues/3881#issuecomment-620053705:176,Deployability,Pipeline,Pipelines,176,"Hi @gn5 , please see `delete_intermediate_output_files` on this page: https://cromwell.readthedocs.io/en/stable/wf_options/Google/. Note that this feature only works on Google Pipelines API v2 at the moment. This is because PAPIv2 is the primary use case for Cromwell within the Broad Institute. When the option is enabled, Cromwell is smart enough to remove the files automatically from being considered in call caching.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3881#issuecomment-620053705
https://github.com/broadinstitute/cromwell/issues/3885#issuecomment-404899951:10,Deployability,upgrade,upgraded,10,"Note: the upgraded 1.0 version of this workflow passed validation, so it's something specific to the draft-2 WDL implementation",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3885#issuecomment-404899951
https://github.com/broadinstitute/cromwell/issues/3885#issuecomment-404899951:55,Security,validat,validation,55,"Note: the upgraded 1.0 version of this workflow passed validation, so it's something specific to the draft-2 WDL implementation",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3885#issuecomment-404899951
https://github.com/broadinstitute/cromwell/pull/3886#issuecomment-404051207:1,Deployability,Update,Updated,1,(Updated) Brain dump on how this PR would be used:; https://drive.google.com/open?id=1MBsgFHhMtSZPK1Egfr4NCkH3C4zN5NDW,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3886#issuecomment-404051207
https://github.com/broadinstitute/cromwell/issues/3889#issuecomment-437590471:55,Modifiability,config,config,55,"When use the server mode, set ""backend.providers.Local.config.root"" in options.json is unusefule. ; It's a question.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3889#issuecomment-437590471
https://github.com/broadinstitute/cromwell/issues/3894#issuecomment-417332578:70,Testability,log,logs,70,I have had 2 issues in the past month or so where at least 30 days of logs would have been enormously useful,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3894#issuecomment-417332578
https://github.com/broadinstitute/cromwell/pull/3895#issuecomment-405639335:61,Testability,test,test,61,"Suggestions for review:. - Start by looking at the (centaur) test cases. These show you what I'm trying to enable; - All of the changed typeclasses now get a new parameter to recurse with. Otherwise the base would need to import a `Typeclass[ExpressionElement]` from somewhere which breaks when sharing them between versions.; - If you're cool with that, skip over any lines which are adding a new `Typeclass[ExpressionElement]` parameter to the typeclass methods.; - If you're not, comment away!; - A lot of the `AstToXyzWom` conversions now take in various typeclass implementations to execute where before they relied on importing the 1.0 version of that typeclass.; - If you're cool with that, you can skip over any lines which are adding a new `Typeclass[ExpressionElement]` parameter to the `AstToXyzWom` conversions.; - If you're not, comment away!; - The code in `wdl/transforms/biscayne/linking/expression/...` is new and should be reviewed. Specifically, it's the typeclass listings for the new version and new typeclass implementations for the new expression types, `as_map`, `as_pairs` and `collect_by_key`.; - The additions in `wdl/draft-3/transforms/linking/expression/...` and removals from `wdl/transforms/base/linking/expression/...` is mostly cut/paste from base to draft-3 (a side effect from #3852 when *everything* was shared). These changes can be skipped over.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3895#issuecomment-405639335
https://github.com/broadinstitute/cromwell/issues/3900#issuecomment-404939788:63,Usability,simpl,simply,63,"Hi @agraubert - one thing we discussed when we did that was to simply provide another concept altogether (because cromwell labels and google labels were 2 concepts shoehorned together) and then removed them completely as the only known users didn't need them. If we bring them back as they were before but **not** as standard cromwell labels, would this still work for you?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3900#issuecomment-404939788
https://github.com/broadinstitute/cromwell/issues/3900#issuecomment-453221742:13,Deployability,update,update,13,Is there any update to this?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3900#issuecomment-453221742
https://github.com/broadinstitute/cromwell/issues/3900#issuecomment-478161147:81,Deployability,pipeline,pipeline,81,"Hey @agraubert, the best way to know that a ticket will be worked on is when the pipeline for it changes to backlog bucket. . Just as an FYI, we are focused on scale improvements and small bug fixes for the near future. Out of curiosity, are you interested in contributing this feature yourself, especially with the guidance of a Cromwell developer? Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3900#issuecomment-478161147
https://github.com/broadinstitute/cromwell/issues/3900#issuecomment-478161147:316,Usability,guid,guidance,316,"Hey @agraubert, the best way to know that a ticket will be worked on is when the pipeline for it changes to backlog bucket. . Just as an FYI, we are focused on scale improvements and small bug fixes for the near future. Out of curiosity, are you interested in contributing this feature yourself, especially with the guidance of a Cromwell developer? Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3900#issuecomment-478161147
https://github.com/broadinstitute/cromwell/issues/3900#issuecomment-478681472:145,Deployability,update,update,145,"Scala is very much not in my wheelhouse, so unfortunately this is not a task I'd be comfortable taking on. But I really do appreciate the status update",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3900#issuecomment-478681472
https://github.com/broadinstitute/cromwell/issues/3909#issuecomment-412242086:784,Availability,down,down,784,The AWS dependencies needs to be pruned. The entire known universe of AWS libraries [were pulled in](https://github.com/broadinstitute/cromwell/blob/9bee537c5f6a9ff4e8597f75b6844c0eaee721cc/project/Dependencies.scala#L230) during the work-in-progress towards a new backend for cromwell. The image below was produced using [GrandPerspective](http://grandperspectiv.sourceforge.net/) on the expanded cromwell 33 jar. It shows the amount of AWS libraries that have been assembled transitively by that one `aws-sdk-java` [blanket](https://mvnrepository.com/artifact/software.amazon.awssdk/aws-sdk-java/2.0.0-preview-9) dependency. ![cromwell_expanded](https://user-images.githubusercontent.com/791985/43986825-3ccde314-9ce5-11e8-8260-c9bbb66d3623.png). The dependencies should be slimmed down to only the required libs.; We don't need to have AWS [Route53](https://aws.amazon.com/route53/) etc. zipped in the jar to run workflows on the upcoming backend.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3909#issuecomment-412242086
https://github.com/broadinstitute/cromwell/issues/3909#issuecomment-412242086:8,Integrability,depend,dependencies,8,The AWS dependencies needs to be pruned. The entire known universe of AWS libraries [were pulled in](https://github.com/broadinstitute/cromwell/blob/9bee537c5f6a9ff4e8597f75b6844c0eaee721cc/project/Dependencies.scala#L230) during the work-in-progress towards a new backend for cromwell. The image below was produced using [GrandPerspective](http://grandperspectiv.sourceforge.net/) on the expanded cromwell 33 jar. It shows the amount of AWS libraries that have been assembled transitively by that one `aws-sdk-java` [blanket](https://mvnrepository.com/artifact/software.amazon.awssdk/aws-sdk-java/2.0.0-preview-9) dependency. ![cromwell_expanded](https://user-images.githubusercontent.com/791985/43986825-3ccde314-9ce5-11e8-8260-c9bbb66d3623.png). The dependencies should be slimmed down to only the required libs.; We don't need to have AWS [Route53](https://aws.amazon.com/route53/) etc. zipped in the jar to run workflows on the upcoming backend.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3909#issuecomment-412242086
https://github.com/broadinstitute/cromwell/issues/3909#issuecomment-412242086:198,Integrability,Depend,Dependencies,198,The AWS dependencies needs to be pruned. The entire known universe of AWS libraries [were pulled in](https://github.com/broadinstitute/cromwell/blob/9bee537c5f6a9ff4e8597f75b6844c0eaee721cc/project/Dependencies.scala#L230) during the work-in-progress towards a new backend for cromwell. The image below was produced using [GrandPerspective](http://grandperspectiv.sourceforge.net/) on the expanded cromwell 33 jar. It shows the amount of AWS libraries that have been assembled transitively by that one `aws-sdk-java` [blanket](https://mvnrepository.com/artifact/software.amazon.awssdk/aws-sdk-java/2.0.0-preview-9) dependency. ![cromwell_expanded](https://user-images.githubusercontent.com/791985/43986825-3ccde314-9ce5-11e8-8260-c9bbb66d3623.png). The dependencies should be slimmed down to only the required libs.; We don't need to have AWS [Route53](https://aws.amazon.com/route53/) etc. zipped in the jar to run workflows on the upcoming backend.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3909#issuecomment-412242086
https://github.com/broadinstitute/cromwell/issues/3909#issuecomment-412242086:615,Integrability,depend,dependency,615,The AWS dependencies needs to be pruned. The entire known universe of AWS libraries [were pulled in](https://github.com/broadinstitute/cromwell/blob/9bee537c5f6a9ff4e8597f75b6844c0eaee721cc/project/Dependencies.scala#L230) during the work-in-progress towards a new backend for cromwell. The image below was produced using [GrandPerspective](http://grandperspectiv.sourceforge.net/) on the expanded cromwell 33 jar. It shows the amount of AWS libraries that have been assembled transitively by that one `aws-sdk-java` [blanket](https://mvnrepository.com/artifact/software.amazon.awssdk/aws-sdk-java/2.0.0-preview-9) dependency. ![cromwell_expanded](https://user-images.githubusercontent.com/791985/43986825-3ccde314-9ce5-11e8-8260-c9bbb66d3623.png). The dependencies should be slimmed down to only the required libs.; We don't need to have AWS [Route53](https://aws.amazon.com/route53/) etc. zipped in the jar to run workflows on the upcoming backend.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3909#issuecomment-412242086
https://github.com/broadinstitute/cromwell/issues/3909#issuecomment-412242086:753,Integrability,depend,dependencies,753,The AWS dependencies needs to be pruned. The entire known universe of AWS libraries [were pulled in](https://github.com/broadinstitute/cromwell/blob/9bee537c5f6a9ff4e8597f75b6844c0eaee721cc/project/Dependencies.scala#L230) during the work-in-progress towards a new backend for cromwell. The image below was produced using [GrandPerspective](http://grandperspectiv.sourceforge.net/) on the expanded cromwell 33 jar. It shows the amount of AWS libraries that have been assembled transitively by that one `aws-sdk-java` [blanket](https://mvnrepository.com/artifact/software.amazon.awssdk/aws-sdk-java/2.0.0-preview-9) dependency. ![cromwell_expanded](https://user-images.githubusercontent.com/791985/43986825-3ccde314-9ce5-11e8-8260-c9bbb66d3623.png). The dependencies should be slimmed down to only the required libs.; We don't need to have AWS [Route53](https://aws.amazon.com/route53/) etc. zipped in the jar to run workflows on the upcoming backend.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3909#issuecomment-412242086
https://github.com/broadinstitute/cromwell/issues/3909#issuecomment-473106092:65,Integrability,depend,dependencies,65,"The jar size isn't viewed to be an issue. We can definitely trim dependencies going forward, but closing this for now",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3909#issuecomment-473106092
https://github.com/broadinstitute/cromwell/issues/3911#issuecomment-406642863:117,Deployability,release,releaseHold,117,"I think the ""CaaS"" comment at the end should be put into the headline (ie something like `CaaS wraps 404 into 500 on releaseHold requests`). And we should probably check this works in other cases where 404s might be returned, not just `releaseHold`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3911#issuecomment-406642863
https://github.com/broadinstitute/cromwell/issues/3911#issuecomment-406642863:236,Deployability,release,releaseHold,236,"I think the ""CaaS"" comment at the end should be put into the headline (ie something like `CaaS wraps 404 into 500 on releaseHold requests`). And we should probably check this works in other cases where 404s might be returned, not just `releaseHold`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3911#issuecomment-406642863
https://github.com/broadinstitute/cromwell/issues/3911#issuecomment-406642863:95,Integrability,wrap,wraps,95,"I think the ""CaaS"" comment at the end should be put into the headline (ie something like `CaaS wraps 404 into 500 on releaseHold requests`). And we should probably check this works in other cases where 404s might be returned, not just `releaseHold`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3911#issuecomment-406642863
https://github.com/broadinstitute/cromwell/issues/3911#issuecomment-406643905:192,Availability,error,errors,192,"Looked at this quickly w/ @salonishah11 and I suspect the problem is due to our ""artisanal"" friend, `cromwell.api.CromwellClient`, which as we discovered earlier this week just gleefully eats errors from Cromwell and returns them in an insane way",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3911#issuecomment-406643905
https://github.com/broadinstitute/cromwell/pull/3915#issuecomment-407929014:108,Modifiability,variab,variable,108,Rebased on develop (fixed merge now that the other PRs are in) and cleaned up the environment vars (DRYer + variable name change).,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3915#issuecomment-407929014
https://github.com/broadinstitute/cromwell/pull/3916#issuecomment-406769307:21,Testability,test,test,21,> thoughts on how to test HTTP relative imports in centaur. No need to use fakes. Use an http link to a public object in GCS. Ex: https://storage.googleapis.com/gcp-public-data-landsat/index.csv.gz,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3916#issuecomment-406769307
https://github.com/broadinstitute/cromwell/pull/3916#issuecomment-407170726:106,Availability,down,downloading,106,Also requesting a review by @salonishah11 because I think these resolvers might potentially be useful for downloading content from the `workflowUrl` as well,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3916#issuecomment-407170726
https://github.com/broadinstitute/cromwell/issues/3919#issuecomment-407124690:28,Energy Efficiency,reduce,reduce,28,Any suggestions or plans to reduce the verbosity?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3919#issuecomment-407124690
https://github.com/broadinstitute/cromwell/issues/3919#issuecomment-1092107938:250,Availability,error,errors,250,"It looks like the link OP posted is now a 404, but I'd also like to voice an interest in this option. I have written a few workflows by now and have found that the output of Cromwell is very difficult to navigate through. It's tricky to quickly find errors, especially if the output is piped through a file with no color coding or any situation involving automated tests.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3919#issuecomment-1092107938
https://github.com/broadinstitute/cromwell/issues/3919#issuecomment-1092107938:365,Testability,test,tests,365,"It looks like the link OP posted is now a 404, but I'd also like to voice an interest in this option. I have written a few workflows by now and have found that the output of Cromwell is very difficult to navigate through. It's tricky to quickly find errors, especially if the output is piped through a file with no color coding or any situation involving automated tests.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3919#issuecomment-1092107938
https://github.com/broadinstitute/cromwell/pull/3925#issuecomment-408117654:12,Deployability,upgrade,upgrade,12,"The Centaur upgrade test uses a WDL temp file as the input of `womtool upgrade`, and imports do not work in this scenario. Attempting to re-engineer this now...",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3925#issuecomment-408117654
https://github.com/broadinstitute/cromwell/pull/3925#issuecomment-408117654:71,Deployability,upgrade,upgrade,71,"The Centaur upgrade test uses a WDL temp file as the input of `womtool upgrade`, and imports do not work in this scenario. Attempting to re-engineer this now...",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3925#issuecomment-408117654
https://github.com/broadinstitute/cromwell/pull/3925#issuecomment-408117654:20,Testability,test,test,20,"The Centaur upgrade test uses a WDL temp file as the input of `womtool upgrade`, and imports do not work in this scenario. Attempting to re-engineer this now...",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3925#issuecomment-408117654
https://github.com/broadinstitute/cromwell/issues/3927#issuecomment-407519270:99,Availability,error,error,99,"@DavyCats thank you for the report. Would you mind posting the WDL that you're using to induce the error? (Or if it contains sensitive information, a minimal repro case.)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3927#issuecomment-407519270
https://github.com/broadinstitute/cromwell/issues/3928#issuecomment-654851201:126,Availability,echo,echo,126,"Hey,. I am trying to use TESK as a backend for a cromwell server (version 51) just running a simple task to test if it works (echo ""Hello World"" using an alpine image) and it does not work. TESK receives the input from the server with the correct syntax, however, the script files and all other files generated by cromwell are pointing to a local directory which TESK does not have (TESK is running in a kubernetes cluster). Maybe I am missing something but I this behaviour with creating local files does not work with a kubernetes cluster. Can I change it by setting the config differently or what is a possible solution? Is there anyone who is experiences with Cromwell-TESK?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3928#issuecomment-654851201
https://github.com/broadinstitute/cromwell/issues/3928#issuecomment-654851201:573,Modifiability,config,config,573,"Hey,. I am trying to use TESK as a backend for a cromwell server (version 51) just running a simple task to test if it works (echo ""Hello World"" using an alpine image) and it does not work. TESK receives the input from the server with the correct syntax, however, the script files and all other files generated by cromwell are pointing to a local directory which TESK does not have (TESK is running in a kubernetes cluster). Maybe I am missing something but I this behaviour with creating local files does not work with a kubernetes cluster. Can I change it by setting the config differently or what is a possible solution? Is there anyone who is experiences with Cromwell-TESK?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3928#issuecomment-654851201
https://github.com/broadinstitute/cromwell/issues/3928#issuecomment-654851201:108,Testability,test,test,108,"Hey,. I am trying to use TESK as a backend for a cromwell server (version 51) just running a simple task to test if it works (echo ""Hello World"" using an alpine image) and it does not work. TESK receives the input from the server with the correct syntax, however, the script files and all other files generated by cromwell are pointing to a local directory which TESK does not have (TESK is running in a kubernetes cluster). Maybe I am missing something but I this behaviour with creating local files does not work with a kubernetes cluster. Can I change it by setting the config differently or what is a possible solution? Is there anyone who is experiences with Cromwell-TESK?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3928#issuecomment-654851201
https://github.com/broadinstitute/cromwell/issues/3928#issuecomment-654851201:93,Usability,simpl,simple,93,"Hey,. I am trying to use TESK as a backend for a cromwell server (version 51) just running a simple task to test if it works (echo ""Hello World"" using an alpine image) and it does not work. TESK receives the input from the server with the correct syntax, however, the script files and all other files generated by cromwell are pointing to a local directory which TESK does not have (TESK is running in a kubernetes cluster). Maybe I am missing something but I this behaviour with creating local files does not work with a kubernetes cluster. Can I change it by setting the config differently or what is a possible solution? Is there anyone who is experiences with Cromwell-TESK?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3928#issuecomment-654851201
https://github.com/broadinstitute/cromwell/issues/3929#issuecomment-407444944:24,Testability,log,log,24,"Is it possible that the log location is not a lie, but rather that the attempt 1 log was never written?. The log statement that specifies the log location is for `""attempt"": 1`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3929#issuecomment-407444944
https://github.com/broadinstitute/cromwell/issues/3929#issuecomment-407444944:81,Testability,log,log,81,"Is it possible that the log location is not a lie, but rather that the attempt 1 log was never written?. The log statement that specifies the log location is for `""attempt"": 1`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3929#issuecomment-407444944
https://github.com/broadinstitute/cromwell/issues/3929#issuecomment-407444944:109,Testability,log,log,109,"Is it possible that the log location is not a lie, but rather that the attempt 1 log was never written?. The log statement that specifies the log location is for `""attempt"": 1`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3929#issuecomment-407444944
https://github.com/broadinstitute/cromwell/issues/3929#issuecomment-407444944:142,Testability,log,log,142,"Is it possible that the log location is not a lie, but rather that the attempt 1 log was never written?. The log statement that specifies the log location is for `""attempt"": 1`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3929#issuecomment-407444944
https://github.com/broadinstitute/cromwell/issues/3929#issuecomment-407468142:16,Testability,log,log,16,"Yes, but if the log was never written, then I would think that cromwell would show no log. Isn't it cromwell that manages the stdout and stderr logs?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3929#issuecomment-407468142
https://github.com/broadinstitute/cromwell/issues/3929#issuecomment-407468142:86,Testability,log,log,86,"Yes, but if the log was never written, then I would think that cromwell would show no log. Isn't it cromwell that manages the stdout and stderr logs?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3929#issuecomment-407468142
https://github.com/broadinstitute/cromwell/issues/3929#issuecomment-407468142:144,Testability,log,logs,144,"Yes, but if the log was never written, then I would think that cromwell would show no log. Isn't it cromwell that manages the stdout and stderr logs?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3929#issuecomment-407468142
https://github.com/broadinstitute/cromwell/issues/3929#issuecomment-407471320:21,Testability,log,log,21,"I‚Äôve definitely seen log links in FireCloud that turn out to be 404s. > On Jul 24, 2018, at 12:26, Trevyn Langsford <notifications@github.com> wrote:; > ; > Yes, but if the log was never written, then I would think that cromwell would show no log. Isn't it cromwell that manages the stdout and stderr logs?; > ; > ‚Äî; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3929#issuecomment-407471320
https://github.com/broadinstitute/cromwell/issues/3929#issuecomment-407471320:173,Testability,log,log,173,"I‚Äôve definitely seen log links in FireCloud that turn out to be 404s. > On Jul 24, 2018, at 12:26, Trevyn Langsford <notifications@github.com> wrote:; > ; > Yes, but if the log was never written, then I would think that cromwell would show no log. Isn't it cromwell that manages the stdout and stderr logs?; > ; > ‚Äî; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3929#issuecomment-407471320
https://github.com/broadinstitute/cromwell/issues/3929#issuecomment-407471320:243,Testability,log,log,243,"I‚Äôve definitely seen log links in FireCloud that turn out to be 404s. > On Jul 24, 2018, at 12:26, Trevyn Langsford <notifications@github.com> wrote:; > ; > Yes, but if the log was never written, then I would think that cromwell would show no log. Isn't it cromwell that manages the stdout and stderr logs?; > ; > ‚Äî; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3929#issuecomment-407471320
https://github.com/broadinstitute/cromwell/issues/3929#issuecomment-407471320:301,Testability,log,logs,301,"I‚Äôve definitely seen log links in FireCloud that turn out to be 404s. > On Jul 24, 2018, at 12:26, Trevyn Langsford <notifications@github.com> wrote:; > ; > Yes, but if the log was never written, then I would think that cromwell would show no log. Isn't it cromwell that manages the stdout and stderr logs?; > ; > ‚Äî; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3929#issuecomment-407471320
https://github.com/broadinstitute/cromwell/issues/3929#issuecomment-408142138:250,Testability,log,logs,250,"Summary: Based on investigation -- it seems like the stdout/stderr files were never delocalized to the task root directory, and I suspect it has to do with something gone slightly wrong with preemption as the stdout/stderr is squished inside the JES logs. Either way -- regardless of what caused the stdout/stderr files to be missing, it seems Cromwell publishes the expected location of both files to metadata without confirming the files were actually produced. . AC: Cromwell doesn't push stdout/stderr paths to metadata until verifying the outputs exist (just like it behaves with non-detritus output files)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3929#issuecomment-408142138
https://github.com/broadinstitute/cromwell/pull/3933#issuecomment-408934534:35,Availability,checkpoint,checkpoint,35,"@mcovarr does ""needs docs if not a checkpoint"" still apply?. EDIT: I see some docs do exist - is that sufficient to satisfy the PR description comment?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3933#issuecomment-408934534
https://github.com/broadinstitute/cromwell/pull/3938#issuecomment-409374762:55,Safety,safe,safe,55,@cjllanwarne provided you're fully satisfied that it's safe and is well tested I'm good,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3938#issuecomment-409374762
https://github.com/broadinstitute/cromwell/pull/3938#issuecomment-409374762:72,Testability,test,tested,72,@cjllanwarne provided you're fully satisfied that it's safe and is well tested I'm good,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3938#issuecomment-409374762
https://github.com/broadinstitute/cromwell/issues/3942#issuecomment-409375834:287,Availability,error,error,287,"When you make a call from an imported WDL, the call is automatically aliased to the simple task name, so in your case:. ```wdl; import ""a.wdl"" as a. workflow b {. # This task is 'a.t', but the callis given the alias 't'; call a.t {}. String x = t.s; }; ```. Similarly, this should be an error:; ```wdl; import ""a.wdl"" as a; import ""z.wdl"" as z. workflow b {. # Cannot do this because the calls would have the same alias:; call a.t {}; call z.t {}. # Which t?; String x = t.s; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3942#issuecomment-409375834
https://github.com/broadinstitute/cromwell/issues/3942#issuecomment-409375834:84,Usability,simpl,simple,84,"When you make a call from an imported WDL, the call is automatically aliased to the simple task name, so in your case:. ```wdl; import ""a.wdl"" as a. workflow b {. # This task is 'a.t', but the callis given the alias 't'; call a.t {}. String x = t.s; }; ```. Similarly, this should be an error:; ```wdl; import ""a.wdl"" as a; import ""z.wdl"" as z. workflow b {. # Cannot do this because the calls would have the same alias:; call a.t {}; call z.t {}. # Which t?; String x = t.s; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3942#issuecomment-409375834
https://github.com/broadinstitute/cromwell/pull/3945#issuecomment-409299130:16,Deployability,update,update,16,Don't forget to update `cromiam.yaml`,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3945#issuecomment-409299130
https://github.com/broadinstitute/cromwell/issues/3947#issuecomment-410034522:670,Availability,reliab,reliably,670,"To add some more context, not having this ability makes it difficult for us to use the On Hold status for queuing in Mint without a lot of overhead. In more detail:. We have a new service called Falcon that periodically queries our workflow collection in CaaS and starts the oldest On Hold workflow. Right now we have no choice but to query for *all* on hold workflows in each cycle, which for scale testing and production will be thousands of workflows -- even though we just want the oldest one or a few of the oldest ones. We could try to paginate and use multiple requests to skip to the last page, but when several workflows per second are being submitted we can't reliably find the oldest on hold workflow that way. It would be much more efficient if we could ask Cromwell to reverse the order and get just the first page of say the 10 oldest On Hold workflows.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3947#issuecomment-410034522
https://github.com/broadinstitute/cromwell/issues/3947#issuecomment-410034522:744,Energy Efficiency,efficient,efficient,744,"To add some more context, not having this ability makes it difficult for us to use the On Hold status for queuing in Mint without a lot of overhead. In more detail:. We have a new service called Falcon that periodically queries our workflow collection in CaaS and starts the oldest On Hold workflow. Right now we have no choice but to query for *all* on hold workflows in each cycle, which for scale testing and production will be thousands of workflows -- even though we just want the oldest one or a few of the oldest ones. We could try to paginate and use multiple requests to skip to the last page, but when several workflows per second are being submitted we can't reliably find the oldest on hold workflow that way. It would be much more efficient if we could ask Cromwell to reverse the order and get just the first page of say the 10 oldest On Hold workflows.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3947#issuecomment-410034522
https://github.com/broadinstitute/cromwell/issues/3947#issuecomment-410034522:400,Testability,test,testing,400,"To add some more context, not having this ability makes it difficult for us to use the On Hold status for queuing in Mint without a lot of overhead. In more detail:. We have a new service called Falcon that periodically queries our workflow collection in CaaS and starts the oldest On Hold workflow. Right now we have no choice but to query for *all* on hold workflows in each cycle, which for scale testing and production will be thousands of workflows -- even though we just want the oldest one or a few of the oldest ones. We could try to paginate and use multiple requests to skip to the last page, but when several workflows per second are being submitted we can't reliably find the oldest on hold workflow that way. It would be much more efficient if we could ask Cromwell to reverse the order and get just the first page of say the 10 oldest On Hold workflows.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3947#issuecomment-410034522
https://github.com/broadinstitute/cromwell/issues/3947#issuecomment-417326254:214,Availability,reliab,reliably,214,"@dshiga -- can you help me understand one piece of your request:; ``` We could try to paginate and use multiple requests to skip to the last page, but when several workflows per second are being submitted we can't reliably find the oldest on hold workflow that way.```. Why exactly does pagination make it unreliable to find the last from a list?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3947#issuecomment-417326254
https://github.com/broadinstitute/cromwell/issues/3947#issuecomment-417346160:57,Performance,perform,performant,57,"We would like to use small page sizes to make this query performant, say 10 workflows per page. We will also be submitting ~10 workflows per second sometimes, so the number of pages could easily change between the first and second request, and we'd end up getting the next to last page instead of the last one.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3947#issuecomment-417346160
https://github.com/broadinstitute/cromwell/pull/3950#issuecomment-410024401:46,Modifiability,refactor,refactored,46,"Added a section to the `Google.md` docs. Also refactored the config handling a little to allow for a default value for the docker-image, and to allow for running without an NGC.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3950#issuecomment-410024401
https://github.com/broadinstitute/cromwell/pull/3950#issuecomment-410024401:61,Modifiability,config,config,61,"Added a section to the `Google.md` docs. Also refactored the config handling a little to allow for a default value for the docker-image, and to allow for running without an NGC.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3950#issuecomment-410024401
https://github.com/broadinstitute/cromwell/issues/3955#issuecomment-409700884:92,Usability,clear,clear,92,Not sure I agree with he first poinT. I was thinking about it earlier and the answer is not clear to me.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3955#issuecomment-409700884
https://github.com/broadinstitute/cromwell/issues/3958#issuecomment-409941435:152,Usability,clear,clear,152,"Interesting. To me, `valueFrom` with a non-expression only makes sense for within the `arguments` section, but I agree that the CWl specification isn't clear on this. As a workaround I suggest using the `default` field one level up, as that appears to be the user intent here:. ``` cwl; class: CommandLineTool; cwlVersion: v1.0; id: 13CNMR; baseCommand: batchprocessNMR.py; inputs:; inputFiles:; type: File[]; inputBinding:; position: 0; frequency:; type: float?; default: 150819500.0; inputBinding:; position: 1; outputs:; output:; type: File[]; outputBinding:; glob: '*.h5'; label: 13C-NMR",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3958#issuecomment-409941435
https://github.com/broadinstitute/cromwell/pull/3960#issuecomment-409901418:5,Testability,test,test,5,Cron test result https://gotc-jenkins.dsp-techops.broadinstitute.org/job/cromwell-cron-papiv2/30/,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3960#issuecomment-409901418
https://github.com/broadinstitute/cromwell/issues/3962#issuecomment-424957788:85,Availability,failure,failures,85,@mcovarr what do you believe is the impact of this change toward managing production failures?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3962#issuecomment-424957788
