id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216:484,Integrability,interface,interface,484,"Hi Yi,. Thanks for your work and the comments. I've been discussing some with Jonathon, and I think if you could do the below, that will clarify all the scaling factor and testing aspects of the PR, so we can move on to the I/O optimization and routing logic parts. Please let me know of any concerns. * accept the various GH suggestions clarifying the scaling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; ```; #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms. DHF = -0.01189736 #TEST; Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; ""SAPT EXCH ENERGY"": 0.36545706, #TEST; ""SAPT IND ENERGY"": -0.00840483, #TEST; ""SAPT DISP ENERGY"": -0.24398704, #TEST; ""CURRENT ENERGY"": 0.01122234} #TEST. Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26658499, #TEST; ""CURRENT ENERGY"": -0.01126250} #TEST. Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26605283, #TEST; ""CURRENT ENERGY"": -0.01073034} #TEST. molecule dimer {; Ne; --; Ar 1 6.5; units bohr; }. set {; basis aug-cc-pvdz; scf_type df; sapt_dft_grac_shift_a 0.203293; sapt_dft_grac_shift_b 0.138264; }. # No hybrid kernel & no exch-disp scaling & no deltaHF; set SAPT_DFT_DO_DHF False; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216
https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216:812,Integrability,rout,routing,812,"Hi Yi,. Thanks for your work and the comments. I've been discussing some with Jonathon, and I think if you could do the below, that will clarify all the scaling factor and testing aspects of the PR, so we can move on to the I/O optimization and routing logic parts. Please let me know of any concerns. * accept the various GH suggestions clarifying the scaling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; ```; #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms. DHF = -0.01189736 #TEST; Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; ""SAPT EXCH ENERGY"": 0.36545706, #TEST; ""SAPT IND ENERGY"": -0.00840483, #TEST; ""SAPT DISP ENERGY"": -0.24398704, #TEST; ""CURRENT ENERGY"": 0.01122234} #TEST. Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26658499, #TEST; ""CURRENT ENERGY"": -0.01126250} #TEST. Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26605283, #TEST; ""CURRENT ENERGY"": -0.01073034} #TEST. molecule dimer {; Ne; --; Ar 1 6.5; units bohr; }. set {; basis aug-cc-pvdz; scf_type df; sapt_dft_grac_shift_a 0.203293; sapt_dft_grac_shift_b 0.138264; }. # No hybrid kernel & no exch-disp scaling & no deltaHF; set SAPT_DFT_DO_DHF False; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216
https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216:2156,Modifiability,variab,variable,2156,"TEST; ""CURRENT ENERGY"": 0.01122234} #TEST. Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26658499, #TEST; ""CURRENT ENERGY"": -0.01126250} #TEST. Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26605283, #TEST; ""CURRENT ENERGY"": -0.01073034} #TEST. molecule dimer {; Ne; --; Ar 1 6.5; units bohr; }. set {; basis aug-cc-pvdz; scf_type df; sapt_dft_grac_shift_a 0.203293; sapt_dft_grac_shift_b 0.138264; }. # No hybrid kernel & no exch-disp scaling & no deltaHF; set SAPT_DFT_DO_DHF False; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; ref = (v - DHF) / 1000.0; else:; ref = v / 1000.0; compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST. # No hybrid kernel & no exch-disp scaling; set SAPT_DFT_DO_DHF True; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""!hyb, xd=none, dHF: "" + k) #TEST. # Hybrid kernel & exch-disp scaling (DISP); set SAPT_DFT_DO_HYBRID True; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME disp; energy('sapt(dft)', molecule=dimer); for k, v in Eref_h_disp.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=disp, dHF: "" + k) #TEST. # Hybrid kernel & exch-disp scaling (FIXED); set SAPT_DFT_DO_HYBRID True; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME fixed ; set SAPT_DFT_EXCH_DISP_FIXED_SCALE 0.770; energy('sapt(dft)', molecule=dimer); for k, v in Eref_h_fixed.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=fixed, dHF: "" + k) #TEST. ```; * I think it should be clear from the output file what exch-disp scheme/scale",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216
https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216:2454,Modifiability,variab,variable,2454,"193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26605283, #TEST; ""CURRENT ENERGY"": -0.01073034} #TEST. molecule dimer {; Ne; --; Ar 1 6.5; units bohr; }. set {; basis aug-cc-pvdz; scf_type df; sapt_dft_grac_shift_a 0.203293; sapt_dft_grac_shift_b 0.138264; }. # No hybrid kernel & no exch-disp scaling & no deltaHF; set SAPT_DFT_DO_DHF False; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; ref = (v - DHF) / 1000.0; else:; ref = v / 1000.0; compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST. # No hybrid kernel & no exch-disp scaling; set SAPT_DFT_DO_DHF True; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""!hyb, xd=none, dHF: "" + k) #TEST. # Hybrid kernel & exch-disp scaling (DISP); set SAPT_DFT_DO_HYBRID True; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME disp; energy('sapt(dft)', molecule=dimer); for k, v in Eref_h_disp.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=disp, dHF: "" + k) #TEST. # Hybrid kernel & exch-disp scaling (FIXED); set SAPT_DFT_DO_HYBRID True; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME fixed ; set SAPT_DFT_EXCH_DISP_FIXED_SCALE 0.770; energy('sapt(dft)', molecule=dimer); for k, v in Eref_h_fixed.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=fixed, dHF: "" + k) #TEST. ```; * I think it should be clear from the output file what exch-disp scheme/scale is applied. So perhaps add a couple lines to the printout like below. This should also satisfy Jonathon's request that the output file show the change in scaling defaults. ```; ==> E20 Dispersion (MP2) <==. Disp20 (MP2) -0.37881730 [mEh]; Exch-Disp20,u 0.02037338 [mEh]; Scaling Scheme: Disp; Sca",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216
https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216:2729,Modifiability,variab,variable,2729,"ift_a 0.203293; sapt_dft_grac_shift_b 0.138264; }. # No hybrid kernel & no exch-disp scaling & no deltaHF; set SAPT_DFT_DO_DHF False; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; ref = (v - DHF) / 1000.0; else:; ref = v / 1000.0; compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST. # No hybrid kernel & no exch-disp scaling; set SAPT_DFT_DO_DHF True; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""!hyb, xd=none, dHF: "" + k) #TEST. # Hybrid kernel & exch-disp scaling (DISP); set SAPT_DFT_DO_HYBRID True; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME disp; energy('sapt(dft)', molecule=dimer); for k, v in Eref_h_disp.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=disp, dHF: "" + k) #TEST. # Hybrid kernel & exch-disp scaling (FIXED); set SAPT_DFT_DO_HYBRID True; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME fixed ; set SAPT_DFT_EXCH_DISP_FIXED_SCALE 0.770; energy('sapt(dft)', molecule=dimer); for k, v in Eref_h_fixed.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=fixed, dHF: "" + k) #TEST. ```; * I think it should be clear from the output file what exch-disp scheme/scale is applied. So perhaps add a couple lines to the printout like below. This should also satisfy Jonathon's request that the output file show the change in scaling defaults. ```; ==> E20 Dispersion (MP2) <==. Disp20 (MP2) -0.37881730 [mEh]; Exch-Disp20,u 0.02037338 [mEh]; Scaling Scheme: Disp; Scaling Factor: 0.707. SAPT(DFT) Results; ---------------------------------------------------------------------------------------------------------; Electrostatics -0.10197192 [mEh] -0.06398835 [kcal/mol] -0.26772724 [kJ/mol]; Elst1,r -0.10197192 [mEh] -0.06398835 [kcal/mol] -0",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216
https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216:3049,Modifiability,variab,variable,3049,"_grac_shift_b 0.138264; }. # No hybrid kernel & no exch-disp scaling & no deltaHF; set SAPT_DFT_DO_DHF False; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; ref = (v - DHF) / 1000.0; else:; ref = v / 1000.0; compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST. # No hybrid kernel & no exch-disp scaling; set SAPT_DFT_DO_DHF True; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""!hyb, xd=none, dHF: "" + k) #TEST. # Hybrid kernel & exch-disp scaling (DISP); set SAPT_DFT_DO_HYBRID True; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME disp; energy('sapt(dft)', molecule=dimer); for k, v in Eref_h_disp.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=disp, dHF: "" + k) #TEST. # Hybrid kernel & exch-disp scaling (FIXED); set SAPT_DFT_DO_HYBRID True; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME fixed ; set SAPT_DFT_EXCH_DISP_FIXED_SCALE 0.770; energy('sapt(dft)', molecule=dimer); for k, v in Eref_h_fixed.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=fixed, dHF: "" + k) #TEST. ```; * I think it should be clear from the output file what exch-disp scheme/scale is applied. So perhaps add a couple lines to the printout like below. This should also satisfy Jonathon's request that the output file show the change in scaling defaults. ```; ==> E20 Dispersion (MP2) <==. Disp20 (MP2) -0.37881730 [mEh]; Exch-Disp20,u 0.02037338 [mEh]; Scaling Scheme: Disp; Scaling Factor: 0.707. SAPT(DFT) Results; ---------------------------------------------------------------------------------------------------------; Electrostatics -0.10197192 [mEh] -0.06398835 [kcal/mol] -0.26772724 [kJ/mol]; Elst1,r -0.10197192 [mEh] -0.06398835 [kcal/mol] -0.26772724 [kJ/mol]; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216
https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216:228,Performance,optimiz,optimization,228,"Hi Yi,. Thanks for your work and the comments. I've been discussing some with Jonathon, and I think if you could do the below, that will clarify all the scaling factor and testing aspects of the PR, so we can move on to the I/O optimization and routing logic parts. Please let me know of any concerns. * accept the various GH suggestions clarifying the scaling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; ```; #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms. DHF = -0.01189736 #TEST; Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; ""SAPT EXCH ENERGY"": 0.36545706, #TEST; ""SAPT IND ENERGY"": -0.00840483, #TEST; ""SAPT DISP ENERGY"": -0.24398704, #TEST; ""CURRENT ENERGY"": 0.01122234} #TEST. Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26658499, #TEST; ""CURRENT ENERGY"": -0.01126250} #TEST. Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26605283, #TEST; ""CURRENT ENERGY"": -0.01073034} #TEST. molecule dimer {; Ne; --; Ar 1 6.5; units bohr; }. set {; basis aug-cc-pvdz; scf_type df; sapt_dft_grac_shift_a 0.203293; sapt_dft_grac_shift_b 0.138264; }. # No hybrid kernel & no exch-disp scaling & no deltaHF; set SAPT_DFT_DO_DHF False; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216
https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216:172,Testability,test,testing,172,"Hi Yi,. Thanks for your work and the comments. I've been discussing some with Jonathon, and I think if you could do the below, that will clarify all the scaling factor and testing aspects of the PR, so we can move on to the I/O optimization and routing logic parts. Please let me know of any concerns. * accept the various GH suggestions clarifying the scaling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; ```; #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms. DHF = -0.01189736 #TEST; Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; ""SAPT EXCH ENERGY"": 0.36545706, #TEST; ""SAPT IND ENERGY"": -0.00840483, #TEST; ""SAPT DISP ENERGY"": -0.24398704, #TEST; ""CURRENT ENERGY"": 0.01122234} #TEST. Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26658499, #TEST; ""CURRENT ENERGY"": -0.01126250} #TEST. Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26605283, #TEST; ""CURRENT ENERGY"": -0.01073034} #TEST. molecule dimer {; Ne; --; Ar 1 6.5; units bohr; }. set {; basis aug-cc-pvdz; scf_type df; sapt_dft_grac_shift_a 0.203293; sapt_dft_grac_shift_b 0.138264; }. # No hybrid kernel & no exch-disp scaling & no deltaHF; set SAPT_DFT_DO_DHF False; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216
https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216:253,Testability,log,logic,253,"Hi Yi,. Thanks for your work and the comments. I've been discussing some with Jonathon, and I think if you could do the below, that will clarify all the scaling factor and testing aspects of the PR, so we can move on to the I/O optimization and routing logic parts. Please let me know of any concerns. * accept the various GH suggestions clarifying the scaling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; ```; #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms. DHF = -0.01189736 #TEST; Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; ""SAPT EXCH ENERGY"": 0.36545706, #TEST; ""SAPT IND ENERGY"": -0.00840483, #TEST; ""SAPT DISP ENERGY"": -0.24398704, #TEST; ""CURRENT ENERGY"": 0.01122234} #TEST. Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26658499, #TEST; ""CURRENT ENERGY"": -0.01126250} #TEST. Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26605283, #TEST; ""CURRENT ENERGY"": -0.01073034} #TEST. molecule dimer {; Ne; --; Ar 1 6.5; units bohr; }. set {; basis aug-cc-pvdz; scf_type df; sapt_dft_grac_shift_a 0.203293; sapt_dft_grac_shift_b 0.138264; }. # No hybrid kernel & no exch-disp scaling & no deltaHF; set SAPT_DFT_DO_DHF False; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216
https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216:554,Testability,test,test,554,"Hi Yi,. Thanks for your work and the comments. I've been discussing some with Jonathon, and I think if you could do the below, that will clarify all the scaling factor and testing aspects of the PR, so we can move on to the I/O optimization and routing logic parts. Please let me know of any concerns. * accept the various GH suggestions clarifying the scaling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; ```; #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms. DHF = -0.01189736 #TEST; Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; ""SAPT EXCH ENERGY"": 0.36545706, #TEST; ""SAPT IND ENERGY"": -0.00840483, #TEST; ""SAPT DISP ENERGY"": -0.24398704, #TEST; ""CURRENT ENERGY"": 0.01122234} #TEST. Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26658499, #TEST; ""CURRENT ENERGY"": -0.01126250} #TEST. Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26605283, #TEST; ""CURRENT ENERGY"": -0.01073034} #TEST. molecule dimer {; Ne; --; Ar 1 6.5; units bohr; }. set {; basis aug-cc-pvdz; scf_type df; sapt_dft_grac_shift_a 0.203293; sapt_dft_grac_shift_b 0.138264; }. # No hybrid kernel & no exch-disp scaling & no deltaHF; set SAPT_DFT_DO_DHF False; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216
https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216:673,Testability,test,test,673,"Hi Yi,. Thanks for your work and the comments. I've been discussing some with Jonathon, and I think if you could do the below, that will clarify all the scaling factor and testing aspects of the PR, so we can move on to the I/O optimization and routing logic parts. Please let me know of any concerns. * accept the various GH suggestions clarifying the scaling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; ```; #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms. DHF = -0.01189736 #TEST; Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; ""SAPT EXCH ENERGY"": 0.36545706, #TEST; ""SAPT IND ENERGY"": -0.00840483, #TEST; ""SAPT DISP ENERGY"": -0.24398704, #TEST; ""CURRENT ENERGY"": 0.01122234} #TEST. Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26658499, #TEST; ""CURRENT ENERGY"": -0.01126250} #TEST. Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26605283, #TEST; ""CURRENT ENERGY"": -0.01073034} #TEST. molecule dimer {; Ne; --; Ar 1 6.5; units bohr; }. set {; basis aug-cc-pvdz; scf_type df; sapt_dft_grac_shift_a 0.203293; sapt_dft_grac_shift_b 0.138264; }. # No hybrid kernel & no exch-disp scaling & no deltaHF; set SAPT_DFT_DO_DHF False; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216
https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216:820,Testability,log,logic,820,"Hi Yi,. Thanks for your work and the comments. I've been discussing some with Jonathon, and I think if you could do the below, that will clarify all the scaling factor and testing aspects of the PR, so we can move on to the I/O optimization and routing logic parts. Please let me know of any concerns. * accept the various GH suggestions clarifying the scaling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; ```; #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms. DHF = -0.01189736 #TEST; Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; ""SAPT EXCH ENERGY"": 0.36545706, #TEST; ""SAPT IND ENERGY"": -0.00840483, #TEST; ""SAPT DISP ENERGY"": -0.24398704, #TEST; ""CURRENT ENERGY"": 0.01122234} #TEST. Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26658499, #TEST; ""CURRENT ENERGY"": -0.01126250} #TEST. Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26605283, #TEST; ""CURRENT ENERGY"": -0.01073034} #TEST. molecule dimer {; Ne; --; Ar 1 6.5; units bohr; }. set {; basis aug-cc-pvdz; scf_type df; sapt_dft_grac_shift_a 0.203293; sapt_dft_grac_shift_b 0.138264; }. # No hybrid kernel & no exch-disp scaling & no deltaHF; set SAPT_DFT_DO_DHF False; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216
https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216:895,Testability,test,tests,895,"Hi Yi,. Thanks for your work and the comments. I've been discussing some with Jonathon, and I think if you could do the below, that will clarify all the scaling factor and testing aspects of the PR, so we can move on to the I/O optimization and routing logic parts. Please let me know of any concerns. * accept the various GH suggestions clarifying the scaling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; ```; #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms. DHF = -0.01189736 #TEST; Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; ""SAPT EXCH ENERGY"": 0.36545706, #TEST; ""SAPT IND ENERGY"": -0.00840483, #TEST; ""SAPT DISP ENERGY"": -0.24398704, #TEST; ""CURRENT ENERGY"": 0.01122234} #TEST. Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26658499, #TEST; ""CURRENT ENERGY"": -0.01126250} #TEST. Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26605283, #TEST; ""CURRENT ENERGY"": -0.01073034} #TEST. molecule dimer {; Ne; --; Ar 1 6.5; units bohr; }. set {; basis aug-cc-pvdz; scf_type df; sapt_dft_grac_shift_a 0.203293; sapt_dft_grac_shift_b 0.138264; }. # No hybrid kernel & no exch-disp scaling & no deltaHF; set SAPT_DFT_DO_DHF False; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216
https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216:1012,Testability,TEST,TEST,1012,"k and the comments. I've been discussing some with Jonathon, and I think if you could do the below, that will clarify all the scaling factor and testing aspects of the PR, so we can move on to the I/O optimization and routing logic parts. Please let me know of any concerns. * accept the various GH suggestions clarifying the scaling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; ```; #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms. DHF = -0.01189736 #TEST; Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; ""SAPT EXCH ENERGY"": 0.36545706, #TEST; ""SAPT IND ENERGY"": -0.00840483, #TEST; ""SAPT DISP ENERGY"": -0.24398704, #TEST; ""CURRENT ENERGY"": 0.01122234} #TEST. Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26658499, #TEST; ""CURRENT ENERGY"": -0.01126250} #TEST. Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26605283, #TEST; ""CURRENT ENERGY"": -0.01073034} #TEST. molecule dimer {; Ne; --; Ar 1 6.5; units bohr; }. set {; basis aug-cc-pvdz; scf_type df; sapt_dft_grac_shift_a 0.203293; sapt_dft_grac_shift_b 0.138264; }. # No hybrid kernel & no exch-disp scaling & no deltaHF; set SAPT_DFT_DO_DHF False; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #T",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216
https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216:1063,Testability,TEST,TEST,1063,"e with Jonathon, and I think if you could do the below, that will clarify all the scaling factor and testing aspects of the PR, so we can move on to the I/O optimization and routing logic parts. Please let me know of any concerns. * accept the various GH suggestions clarifying the scaling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; ```; #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms. DHF = -0.01189736 #TEST; Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; ""SAPT EXCH ENERGY"": 0.36545706, #TEST; ""SAPT IND ENERGY"": -0.00840483, #TEST; ""SAPT DISP ENERGY"": -0.24398704, #TEST; ""CURRENT ENERGY"": 0.01122234} #TEST. Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26658499, #TEST; ""CURRENT ENERGY"": -0.01126250} #TEST. Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26605283, #TEST; ""CURRENT ENERGY"": -0.01073034} #TEST. molecule dimer {; Ne; --; Ar 1 6.5; units bohr; }. set {; basis aug-cc-pvdz; scf_type df; sapt_dft_grac_shift_a 0.203293; sapt_dft_grac_shift_b 0.138264; }. # No hybrid kernel & no exch-disp scaling & no deltaHF; set SAPT_DFT_DO_DHF False; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; if k in [""SAPT IND ENERGY"", ""CURRENT ENE",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216
https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216:1102,Testability,TEST,TEST,1102,"ld do the below, that will clarify all the scaling factor and testing aspects of the PR, so we can move on to the I/O optimization and routing logic parts. Please let me know of any concerns. * accept the various GH suggestions clarifying the scaling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; ```; #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms. DHF = -0.01189736 #TEST; Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; ""SAPT EXCH ENERGY"": 0.36545706, #TEST; ""SAPT IND ENERGY"": -0.00840483, #TEST; ""SAPT DISP ENERGY"": -0.24398704, #TEST; ""CURRENT ENERGY"": 0.01122234} #TEST. Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26658499, #TEST; ""CURRENT ENERGY"": -0.01126250} #TEST. Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26605283, #TEST; ""CURRENT ENERGY"": -0.01073034} #TEST. molecule dimer {; Ne; --; Ar 1 6.5; units bohr; }. set {; basis aug-cc-pvdz; scf_type df; sapt_dft_grac_shift_a 0.203293; sapt_dft_grac_shift_b 0.138264; }. # No hybrid kernel & no exch-disp scaling & no deltaHF; set SAPT_DFT_DO_DHF False; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; ref = (v - DHF) / 1000.0; else:",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216
https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216:1141,Testability,TEST,TEST,1141,"he scaling factor and testing aspects of the PR, so we can move on to the I/O optimization and routing logic parts. Please let me know of any concerns. * accept the various GH suggestions clarifying the scaling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; ```; #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms. DHF = -0.01189736 #TEST; Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; ""SAPT EXCH ENERGY"": 0.36545706, #TEST; ""SAPT IND ENERGY"": -0.00840483, #TEST; ""SAPT DISP ENERGY"": -0.24398704, #TEST; ""CURRENT ENERGY"": 0.01122234} #TEST. Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26658499, #TEST; ""CURRENT ENERGY"": -0.01126250} #TEST. Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26605283, #TEST; ""CURRENT ENERGY"": -0.01073034} #TEST. molecule dimer {; Ne; --; Ar 1 6.5; units bohr; }. set {; basis aug-cc-pvdz; scf_type df; sapt_dft_grac_shift_a 0.203293; sapt_dft_grac_shift_b 0.138264; }. # No hybrid kernel & no exch-disp scaling & no deltaHF; set SAPT_DFT_DO_DHF False; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; ref = (v - DHF) / 1000.0; else:; ref = v / 1000.0; compare_values(ref,",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216
https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216:1181,Testability,TEST,TEST,1181,"of the PR, so we can move on to the I/O optimization and routing logic parts. Please let me know of any concerns. * accept the various GH suggestions clarifying the scaling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; ```; #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms. DHF = -0.01189736 #TEST; Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; ""SAPT EXCH ENERGY"": 0.36545706, #TEST; ""SAPT IND ENERGY"": -0.00840483, #TEST; ""SAPT DISP ENERGY"": -0.24398704, #TEST; ""CURRENT ENERGY"": 0.01122234} #TEST. Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26658499, #TEST; ""CURRENT ENERGY"": -0.01126250} #TEST. Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26605283, #TEST; ""CURRENT ENERGY"": -0.01073034} #TEST. molecule dimer {; Ne; --; Ar 1 6.5; units bohr; }. set {; basis aug-cc-pvdz; scf_type df; sapt_dft_grac_shift_a 0.203293; sapt_dft_grac_shift_b 0.138264; }. # No hybrid kernel & no exch-disp scaling & no deltaHF; set SAPT_DFT_DO_DHF False; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; ref = (v - DHF) / 1000.0; else:; ref = v / 1000.0; compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216
https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216:1218,Testability,TEST,TEST,1218,"n to the I/O optimization and routing logic parts. Please let me know of any concerns. * accept the various GH suggestions clarifying the scaling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; ```; #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms. DHF = -0.01189736 #TEST; Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; ""SAPT EXCH ENERGY"": 0.36545706, #TEST; ""SAPT IND ENERGY"": -0.00840483, #TEST; ""SAPT DISP ENERGY"": -0.24398704, #TEST; ""CURRENT ENERGY"": 0.01122234} #TEST. Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26658499, #TEST; ""CURRENT ENERGY"": -0.01126250} #TEST. Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26605283, #TEST; ""CURRENT ENERGY"": -0.01073034} #TEST. molecule dimer {; Ne; --; Ar 1 6.5; units bohr; }. set {; basis aug-cc-pvdz; scf_type df; sapt_dft_grac_shift_a 0.203293; sapt_dft_grac_shift_b 0.138264; }. # No hybrid kernel & no exch-disp scaling & no deltaHF; set SAPT_DFT_DO_DHF False; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; ref = (v - DHF) / 1000.0; else:; ref = v / 1000.0; compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST. # No hy",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216
https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216:1273,Testability,TEST,TEST,1273,"now of any concerns. * accept the various GH suggestions clarifying the scaling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; ```; #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms. DHF = -0.01189736 #TEST; Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; ""SAPT EXCH ENERGY"": 0.36545706, #TEST; ""SAPT IND ENERGY"": -0.00840483, #TEST; ""SAPT DISP ENERGY"": -0.24398704, #TEST; ""CURRENT ENERGY"": 0.01122234} #TEST. Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26658499, #TEST; ""CURRENT ENERGY"": -0.01126250} #TEST. Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26605283, #TEST; ""CURRENT ENERGY"": -0.01073034} #TEST. molecule dimer {; Ne; --; Ar 1 6.5; units bohr; }. set {; basis aug-cc-pvdz; scf_type df; sapt_dft_grac_shift_a 0.203293; sapt_dft_grac_shift_b 0.138264; }. # No hybrid kernel & no exch-disp scaling & no deltaHF; set SAPT_DFT_DO_DHF False; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; ref = (v - DHF) / 1000.0; else:; ref = v / 1000.0; compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST. # No hybrid kernel & no exch-disp scaling; set SAPT_DFT_DO_DHF True; set S",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216
https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216:1312,Testability,TEST,TEST,1312,"us GH suggestions clarifying the scaling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; ```; #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms. DHF = -0.01189736 #TEST; Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; ""SAPT EXCH ENERGY"": 0.36545706, #TEST; ""SAPT IND ENERGY"": -0.00840483, #TEST; ""SAPT DISP ENERGY"": -0.24398704, #TEST; ""CURRENT ENERGY"": 0.01122234} #TEST. Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26658499, #TEST; ""CURRENT ENERGY"": -0.01126250} #TEST. Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26605283, #TEST; ""CURRENT ENERGY"": -0.01073034} #TEST. molecule dimer {; Ne; --; Ar 1 6.5; units bohr; }. set {; basis aug-cc-pvdz; scf_type df; sapt_dft_grac_shift_a 0.203293; sapt_dft_grac_shift_b 0.138264; }. # No hybrid kernel & no exch-disp scaling & no deltaHF; set SAPT_DFT_DO_DHF False; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; ref = (v - DHF) / 1000.0; else:; ref = v / 1000.0; compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST. # No hybrid kernel & no exch-disp scaling; set SAPT_DFT_DO_DHF True; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_E",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216
https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216:1351,Testability,TEST,TEST,1351," scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; ```; #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms. DHF = -0.01189736 #TEST; Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; ""SAPT EXCH ENERGY"": 0.36545706, #TEST; ""SAPT IND ENERGY"": -0.00840483, #TEST; ""SAPT DISP ENERGY"": -0.24398704, #TEST; ""CURRENT ENERGY"": 0.01122234} #TEST. Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26658499, #TEST; ""CURRENT ENERGY"": -0.01126250} #TEST. Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26605283, #TEST; ""CURRENT ENERGY"": -0.01073034} #TEST. molecule dimer {; Ne; --; Ar 1 6.5; units bohr; }. set {; basis aug-cc-pvdz; scf_type df; sapt_dft_grac_shift_a 0.203293; sapt_dft_grac_shift_b 0.138264; }. # No hybrid kernel & no exch-disp scaling & no deltaHF; set SAPT_DFT_DO_DHF False; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; ref = (v - DHF) / 1000.0; else:; ref = v / 1000.0; compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST. # No hybrid kernel & no exch-disp scaling; set SAPT_DFT_DO_DHF True; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sap",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216
https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216:1391,Testability,TEST,TEST,1391," them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; ```; #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms. DHF = -0.01189736 #TEST; Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; ""SAPT EXCH ENERGY"": 0.36545706, #TEST; ""SAPT IND ENERGY"": -0.00840483, #TEST; ""SAPT DISP ENERGY"": -0.24398704, #TEST; ""CURRENT ENERGY"": 0.01122234} #TEST. Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26658499, #TEST; ""CURRENT ENERGY"": -0.01126250} #TEST. Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26605283, #TEST; ""CURRENT ENERGY"": -0.01073034} #TEST. molecule dimer {; Ne; --; Ar 1 6.5; units bohr; }. set {; basis aug-cc-pvdz; scf_type df; sapt_dft_grac_shift_a 0.203293; sapt_dft_grac_shift_b 0.138264; }. # No hybrid kernel & no exch-disp scaling & no deltaHF; set SAPT_DFT_DO_DHF False; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; ref = (v - DHF) / 1000.0; else:; ref = v / 1000.0; compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST. # No hybrid kernel & no exch-disp scaling; set SAPT_DFT_DO_DHF True; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in E",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216
https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216:1429,Testability,TEST,TEST,1429,"e to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; ```; #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms. DHF = -0.01189736 #TEST; Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; ""SAPT EXCH ENERGY"": 0.36545706, #TEST; ""SAPT IND ENERGY"": -0.00840483, #TEST; ""SAPT DISP ENERGY"": -0.24398704, #TEST; ""CURRENT ENERGY"": 0.01122234} #TEST. Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26658499, #TEST; ""CURRENT ENERGY"": -0.01126250} #TEST. Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26605283, #TEST; ""CURRENT ENERGY"": -0.01073034} #TEST. molecule dimer {; Ne; --; Ar 1 6.5; units bohr; }. set {; basis aug-cc-pvdz; scf_type df; sapt_dft_grac_shift_a 0.203293; sapt_dft_grac_shift_b 0.138264; }. # No hybrid kernel & no exch-disp scaling & no deltaHF; set SAPT_DFT_DO_DHF False; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; ref = (v - DHF) / 1000.0; else:; ref = v / 1000.0; compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST. # No hybrid kernel & no exch-disp scaling; set SAPT_DFT_DO_DHF True; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; comp",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216
https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216:1485,Testability,TEST,TEST,1485,", if that makes the git operations easier.; * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; ```; #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms. DHF = -0.01189736 #TEST; Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; ""SAPT EXCH ENERGY"": 0.36545706, #TEST; ""SAPT IND ENERGY"": -0.00840483, #TEST; ""SAPT DISP ENERGY"": -0.24398704, #TEST; ""CURRENT ENERGY"": 0.01122234} #TEST. Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26658499, #TEST; ""CURRENT ENERGY"": -0.01126250} #TEST. Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26605283, #TEST; ""CURRENT ENERGY"": -0.01073034} #TEST. molecule dimer {; Ne; --; Ar 1 6.5; units bohr; }. set {; basis aug-cc-pvdz; scf_type df; sapt_dft_grac_shift_a 0.203293; sapt_dft_grac_shift_b 0.138264; }. # No hybrid kernel & no exch-disp scaling & no deltaHF; set SAPT_DFT_DO_DHF False; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; ref = (v - DHF) / 1000.0; else:; ref = v / 1000.0; compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST. # No hybrid kernel & no exch-disp scaling; set SAPT_DFT_DO_DHF True; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""!hyb, xd=none, dHF: "" +",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216
https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216:1524,Testability,TEST,TEST,1524,"er.; * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; ```; #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms. DHF = -0.01189736 #TEST; Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; ""SAPT EXCH ENERGY"": 0.36545706, #TEST; ""SAPT IND ENERGY"": -0.00840483, #TEST; ""SAPT DISP ENERGY"": -0.24398704, #TEST; ""CURRENT ENERGY"": 0.01122234} #TEST. Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26658499, #TEST; ""CURRENT ENERGY"": -0.01126250} #TEST. Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26605283, #TEST; ""CURRENT ENERGY"": -0.01073034} #TEST. molecule dimer {; Ne; --; Ar 1 6.5; units bohr; }. set {; basis aug-cc-pvdz; scf_type df; sapt_dft_grac_shift_a 0.203293; sapt_dft_grac_shift_b 0.138264; }. # No hybrid kernel & no exch-disp scaling & no deltaHF; set SAPT_DFT_DO_DHF False; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; ref = (v - DHF) / 1000.0; else:; ref = v / 1000.0; compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST. # No hybrid kernel & no exch-disp scaling; set SAPT_DFT_DO_DHF True; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""!hyb, xd=none, dHF: "" + k) #TEST. # Hybrid kernel & exch-disp ",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216
https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216:1563,Testability,TEST,TEST,1563,"ng like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; ```; #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms. DHF = -0.01189736 #TEST; Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; ""SAPT EXCH ENERGY"": 0.36545706, #TEST; ""SAPT IND ENERGY"": -0.00840483, #TEST; ""SAPT DISP ENERGY"": -0.24398704, #TEST; ""CURRENT ENERGY"": 0.01122234} #TEST. Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26658499, #TEST; ""CURRENT ENERGY"": -0.01126250} #TEST. Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26605283, #TEST; ""CURRENT ENERGY"": -0.01073034} #TEST. molecule dimer {; Ne; --; Ar 1 6.5; units bohr; }. set {; basis aug-cc-pvdz; scf_type df; sapt_dft_grac_shift_a 0.203293; sapt_dft_grac_shift_b 0.138264; }. # No hybrid kernel & no exch-disp scaling & no deltaHF; set SAPT_DFT_DO_DHF False; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; ref = (v - DHF) / 1000.0; else:; ref = v / 1000.0; compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST. # No hybrid kernel & no exch-disp scaling; set SAPT_DFT_DO_DHF True; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""!hyb, xd=none, dHF: "" + k) #TEST. # Hybrid kernel & exch-disp scaling (DISP); set SAPT_DFT_DO_HYBRID ",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216
https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216:1603,Testability,TEST,TEST,1603,"ection without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; ```; #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms. DHF = -0.01189736 #TEST; Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; ""SAPT EXCH ENERGY"": 0.36545706, #TEST; ""SAPT IND ENERGY"": -0.00840483, #TEST; ""SAPT DISP ENERGY"": -0.24398704, #TEST; ""CURRENT ENERGY"": 0.01122234} #TEST. Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26658499, #TEST; ""CURRENT ENERGY"": -0.01126250} #TEST. Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26605283, #TEST; ""CURRENT ENERGY"": -0.01073034} #TEST. molecule dimer {; Ne; --; Ar 1 6.5; units bohr; }. set {; basis aug-cc-pvdz; scf_type df; sapt_dft_grac_shift_a 0.203293; sapt_dft_grac_shift_b 0.138264; }. # No hybrid kernel & no exch-disp scaling & no deltaHF; set SAPT_DFT_DO_DHF False; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; ref = (v - DHF) / 1000.0; else:; ref = v / 1000.0; compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST. # No hybrid kernel & no exch-disp scaling; set SAPT_DFT_DO_DHF True; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""!hyb, xd=none, dHF: "" + k) #TEST. # Hybrid kernel & exch-disp scaling (DISP); set SAPT_DFT_DO_HYBRID True; set SAPT_DFT_EXCH_DISP_SCALE_SCHE",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216
https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216:1641,Testability,TEST,TEST,1641,"correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; ```; #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms. DHF = -0.01189736 #TEST; Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; ""SAPT EXCH ENERGY"": 0.36545706, #TEST; ""SAPT IND ENERGY"": -0.00840483, #TEST; ""SAPT DISP ENERGY"": -0.24398704, #TEST; ""CURRENT ENERGY"": 0.01122234} #TEST. Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26658499, #TEST; ""CURRENT ENERGY"": -0.01126250} #TEST. Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26605283, #TEST; ""CURRENT ENERGY"": -0.01073034} #TEST. molecule dimer {; Ne; --; Ar 1 6.5; units bohr; }. set {; basis aug-cc-pvdz; scf_type df; sapt_dft_grac_shift_a 0.203293; sapt_dft_grac_shift_b 0.138264; }. # No hybrid kernel & no exch-disp scaling & no deltaHF; set SAPT_DFT_DO_DHF False; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; ref = (v - DHF) / 1000.0; else:; ref = v / 1000.0; compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST. # No hybrid kernel & no exch-disp scaling; set SAPT_DFT_DO_DHF True; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""!hyb, xd=none, dHF: "" + k) #TEST. # Hybrid kernel & exch-disp scaling (DISP); set SAPT_DFT_DO_HYBRID True; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME disp; energy('sapt(dft)'",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216
https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216:2026,Testability,TEST,TEST,2026,"9, #TEST; ""SAPT EXCH ENERGY"": 0.36545706, #TEST; ""SAPT IND ENERGY"": -0.00840483, #TEST; ""SAPT DISP ENERGY"": -0.24398704, #TEST; ""CURRENT ENERGY"": 0.01122234} #TEST. Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26658499, #TEST; ""CURRENT ENERGY"": -0.01126250} #TEST. Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26605283, #TEST; ""CURRENT ENERGY"": -0.01073034} #TEST. molecule dimer {; Ne; --; Ar 1 6.5; units bohr; }. set {; basis aug-cc-pvdz; scf_type df; sapt_dft_grac_shift_a 0.203293; sapt_dft_grac_shift_b 0.138264; }. # No hybrid kernel & no exch-disp scaling & no deltaHF; set SAPT_DFT_DO_DHF False; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; ref = (v - DHF) / 1000.0; else:; ref = v / 1000.0; compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST. # No hybrid kernel & no exch-disp scaling; set SAPT_DFT_DO_DHF True; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""!hyb, xd=none, dHF: "" + k) #TEST. # Hybrid kernel & exch-disp scaling (DISP); set SAPT_DFT_DO_HYBRID True; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME disp; energy('sapt(dft)', molecule=dimer); for k, v in Eref_h_disp.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=disp, dHF: "" + k) #TEST. # Hybrid kernel & exch-disp scaling (FIXED); set SAPT_DFT_DO_HYBRID True; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME fixed ; set SAPT_DFT_EXCH_DISP_FIXED_SCALE 0.770; energy('sapt(dft)', molecule=dimer); for k, v in Eref_h_fixed.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k)",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216
https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216:2202,Testability,TEST,TEST,2202,"TEST; ""CURRENT ENERGY"": 0.01122234} #TEST. Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26658499, #TEST; ""CURRENT ENERGY"": -0.01126250} #TEST. Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26605283, #TEST; ""CURRENT ENERGY"": -0.01073034} #TEST. molecule dimer {; Ne; --; Ar 1 6.5; units bohr; }. set {; basis aug-cc-pvdz; scf_type df; sapt_dft_grac_shift_a 0.203293; sapt_dft_grac_shift_b 0.138264; }. # No hybrid kernel & no exch-disp scaling & no deltaHF; set SAPT_DFT_DO_DHF False; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; ref = (v - DHF) / 1000.0; else:; ref = v / 1000.0; compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST. # No hybrid kernel & no exch-disp scaling; set SAPT_DFT_DO_DHF True; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""!hyb, xd=none, dHF: "" + k) #TEST. # Hybrid kernel & exch-disp scaling (DISP); set SAPT_DFT_DO_HYBRID True; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME disp; energy('sapt(dft)', molecule=dimer); for k, v in Eref_h_disp.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=disp, dHF: "" + k) #TEST. # Hybrid kernel & exch-disp scaling (FIXED); set SAPT_DFT_DO_HYBRID True; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME fixed ; set SAPT_DFT_EXCH_DISP_FIXED_SCALE 0.770; energy('sapt(dft)', molecule=dimer); for k, v in Eref_h_fixed.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=fixed, dHF: "" + k) #TEST. ```; * I think it should be clear from the output file what exch-disp scheme/scale",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216
https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216:2416,Testability,TEST,TEST,2416,"} #TEST. Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26605283, #TEST; ""CURRENT ENERGY"": -0.01073034} #TEST. molecule dimer {; Ne; --; Ar 1 6.5; units bohr; }. set {; basis aug-cc-pvdz; scf_type df; sapt_dft_grac_shift_a 0.203293; sapt_dft_grac_shift_b 0.138264; }. # No hybrid kernel & no exch-disp scaling & no deltaHF; set SAPT_DFT_DO_DHF False; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; ref = (v - DHF) / 1000.0; else:; ref = v / 1000.0; compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST. # No hybrid kernel & no exch-disp scaling; set SAPT_DFT_DO_DHF True; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""!hyb, xd=none, dHF: "" + k) #TEST. # Hybrid kernel & exch-disp scaling (DISP); set SAPT_DFT_DO_HYBRID True; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME disp; energy('sapt(dft)', molecule=dimer); for k, v in Eref_h_disp.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=disp, dHF: "" + k) #TEST. # Hybrid kernel & exch-disp scaling (FIXED); set SAPT_DFT_DO_HYBRID True; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME fixed ; set SAPT_DFT_EXCH_DISP_FIXED_SCALE 0.770; energy('sapt(dft)', molecule=dimer); for k, v in Eref_h_fixed.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=fixed, dHF: "" + k) #TEST. ```; * I think it should be clear from the output file what exch-disp scheme/scale is applied. So perhaps add a couple lines to the printout like below. This should also satisfy Jonathon's request that the output file show the change in scaling defaults. ```; ==> E20 Dispersion (MP2) <==. Disp20 (MP2) -0.37881730 [mEh]; Exch",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216
https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216:2499,Testability,TEST,TEST,2499,"193, #TEST; ""SAPT EXCH ENERGY"": 0.36569812, #TEST; ""SAPT IND ENERGY"": -0.00840370, #TEST; ""SAPT DISP ENERGY"": -0.26605283, #TEST; ""CURRENT ENERGY"": -0.01073034} #TEST. molecule dimer {; Ne; --; Ar 1 6.5; units bohr; }. set {; basis aug-cc-pvdz; scf_type df; sapt_dft_grac_shift_a 0.203293; sapt_dft_grac_shift_b 0.138264; }. # No hybrid kernel & no exch-disp scaling & no deltaHF; set SAPT_DFT_DO_DHF False; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; ref = (v - DHF) / 1000.0; else:; ref = v / 1000.0; compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST. # No hybrid kernel & no exch-disp scaling; set SAPT_DFT_DO_DHF True; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""!hyb, xd=none, dHF: "" + k) #TEST. # Hybrid kernel & exch-disp scaling (DISP); set SAPT_DFT_DO_HYBRID True; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME disp; energy('sapt(dft)', molecule=dimer); for k, v in Eref_h_disp.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=disp, dHF: "" + k) #TEST. # Hybrid kernel & exch-disp scaling (FIXED); set SAPT_DFT_DO_HYBRID True; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME fixed ; set SAPT_DFT_EXCH_DISP_FIXED_SCALE 0.770; energy('sapt(dft)', molecule=dimer); for k, v in Eref_h_fixed.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=fixed, dHF: "" + k) #TEST. ```; * I think it should be clear from the output file what exch-disp scheme/scale is applied. So perhaps add a couple lines to the printout like below. This should also satisfy Jonathon's request that the output file show the change in scaling defaults. ```; ==> E20 Dispersion (MP2) <==. Disp20 (MP2) -0.37881730 [mEh]; Exch-Disp20,u 0.02037338 [mEh]; Scaling Scheme: Disp; Sca",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216
https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216:2691,Testability,TEST,TEST,2691," {; basis aug-cc-pvdz; scf_type df; sapt_dft_grac_shift_a 0.203293; sapt_dft_grac_shift_b 0.138264; }. # No hybrid kernel & no exch-disp scaling & no deltaHF; set SAPT_DFT_DO_DHF False; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; ref = (v - DHF) / 1000.0; else:; ref = v / 1000.0; compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST. # No hybrid kernel & no exch-disp scaling; set SAPT_DFT_DO_DHF True; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""!hyb, xd=none, dHF: "" + k) #TEST. # Hybrid kernel & exch-disp scaling (DISP); set SAPT_DFT_DO_HYBRID True; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME disp; energy('sapt(dft)', molecule=dimer); for k, v in Eref_h_disp.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=disp, dHF: "" + k) #TEST. # Hybrid kernel & exch-disp scaling (FIXED); set SAPT_DFT_DO_HYBRID True; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME fixed ; set SAPT_DFT_EXCH_DISP_FIXED_SCALE 0.770; energy('sapt(dft)', molecule=dimer); for k, v in Eref_h_fixed.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=fixed, dHF: "" + k) #TEST. ```; * I think it should be clear from the output file what exch-disp scheme/scale is applied. So perhaps add a couple lines to the printout like below. This should also satisfy Jonathon's request that the output file show the change in scaling defaults. ```; ==> E20 Dispersion (MP2) <==. Disp20 (MP2) -0.37881730 [mEh]; Exch-Disp20,u 0.02037338 [mEh]; Scaling Scheme: Disp; Scaling Factor: 0.707. SAPT(DFT) Results; ---------------------------------------------------------------------------------------------------------; Electrostatics -0.10197192 [mEh] -0.06398835 [kcal/mol] -0.26772724 [kJ/mol]",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216
https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216:2773,Testability,TEST,TEST,2773,"ift_a 0.203293; sapt_dft_grac_shift_b 0.138264; }. # No hybrid kernel & no exch-disp scaling & no deltaHF; set SAPT_DFT_DO_DHF False; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; ref = (v - DHF) / 1000.0; else:; ref = v / 1000.0; compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST. # No hybrid kernel & no exch-disp scaling; set SAPT_DFT_DO_DHF True; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""!hyb, xd=none, dHF: "" + k) #TEST. # Hybrid kernel & exch-disp scaling (DISP); set SAPT_DFT_DO_HYBRID True; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME disp; energy('sapt(dft)', molecule=dimer); for k, v in Eref_h_disp.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=disp, dHF: "" + k) #TEST. # Hybrid kernel & exch-disp scaling (FIXED); set SAPT_DFT_DO_HYBRID True; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME fixed ; set SAPT_DFT_EXCH_DISP_FIXED_SCALE 0.770; energy('sapt(dft)', molecule=dimer); for k, v in Eref_h_fixed.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=fixed, dHF: "" + k) #TEST. ```; * I think it should be clear from the output file what exch-disp scheme/scale is applied. So perhaps add a couple lines to the printout like below. This should also satisfy Jonathon's request that the output file show the change in scaling defaults. ```; ==> E20 Dispersion (MP2) <==. Disp20 (MP2) -0.37881730 [mEh]; Exch-Disp20,u 0.02037338 [mEh]; Scaling Scheme: Disp; Scaling Factor: 0.707. SAPT(DFT) Results; ---------------------------------------------------------------------------------------------------------; Electrostatics -0.10197192 [mEh] -0.06398835 [kcal/mol] -0.26772724 [kJ/mol]; Elst1,r -0.10197192 [mEh] -0.06398835 [kcal/mol] -0",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216
https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216:3011,Testability,TEST,TEST,3011,"_grac_shift_b 0.138264; }. # No hybrid kernel & no exch-disp scaling & no deltaHF; set SAPT_DFT_DO_DHF False; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; ref = (v - DHF) / 1000.0; else:; ref = v / 1000.0; compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST. # No hybrid kernel & no exch-disp scaling; set SAPT_DFT_DO_DHF True; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""!hyb, xd=none, dHF: "" + k) #TEST. # Hybrid kernel & exch-disp scaling (DISP); set SAPT_DFT_DO_HYBRID True; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME disp; energy('sapt(dft)', molecule=dimer); for k, v in Eref_h_disp.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=disp, dHF: "" + k) #TEST. # Hybrid kernel & exch-disp scaling (FIXED); set SAPT_DFT_DO_HYBRID True; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME fixed ; set SAPT_DFT_EXCH_DISP_FIXED_SCALE 0.770; energy('sapt(dft)', molecule=dimer); for k, v in Eref_h_fixed.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=fixed, dHF: "" + k) #TEST. ```; * I think it should be clear from the output file what exch-disp scheme/scale is applied. So perhaps add a couple lines to the printout like below. This should also satisfy Jonathon's request that the output file show the change in scaling defaults. ```; ==> E20 Dispersion (MP2) <==. Disp20 (MP2) -0.37881730 [mEh]; Exch-Disp20,u 0.02037338 [mEh]; Scaling Scheme: Disp; Scaling Factor: 0.707. SAPT(DFT) Results; ---------------------------------------------------------------------------------------------------------; Electrostatics -0.10197192 [mEh] -0.06398835 [kcal/mol] -0.26772724 [kJ/mol]; Elst1,r -0.10197192 [mEh] -0.06398835 [kcal/mol] -0.26772724 [kJ/mol]; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216
https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216:3094,Testability,TEST,TEST,3094,"_grac_shift_b 0.138264; }. # No hybrid kernel & no exch-disp scaling & no deltaHF; set SAPT_DFT_DO_DHF False; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; ref = (v - DHF) / 1000.0; else:; ref = v / 1000.0; compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST. # No hybrid kernel & no exch-disp scaling; set SAPT_DFT_DO_DHF True; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""!hyb, xd=none, dHF: "" + k) #TEST. # Hybrid kernel & exch-disp scaling (DISP); set SAPT_DFT_DO_HYBRID True; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME disp; energy('sapt(dft)', molecule=dimer); for k, v in Eref_h_disp.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=disp, dHF: "" + k) #TEST. # Hybrid kernel & exch-disp scaling (FIXED); set SAPT_DFT_DO_HYBRID True; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME fixed ; set SAPT_DFT_EXCH_DISP_FIXED_SCALE 0.770; energy('sapt(dft)', molecule=dimer); for k, v in Eref_h_fixed.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=fixed, dHF: "" + k) #TEST. ```; * I think it should be clear from the output file what exch-disp scheme/scale is applied. So perhaps add a couple lines to the printout like below. This should also satisfy Jonathon's request that the output file show the change in scaling defaults. ```; ==> E20 Dispersion (MP2) <==. Disp20 (MP2) -0.37881730 [mEh]; Exch-Disp20,u 0.02037338 [mEh]; Scaling Scheme: Disp; Scaling Factor: 0.707. SAPT(DFT) Results; ---------------------------------------------------------------------------------------------------------; Electrostatics -0.10197192 [mEh] -0.06398835 [kcal/mol] -0.26772724 [kJ/mol]; Elst1,r -0.10197192 [mEh] -0.06398835 [kcal/mol] -0.26772724 [kJ/mol]; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216
https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216:3128,Usability,clear,clear,3128,"_grac_shift_b 0.138264; }. # No hybrid kernel & no exch-disp scaling & no deltaHF; set SAPT_DFT_DO_DHF False; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; ref = (v - DHF) / 1000.0; else:; ref = v / 1000.0; compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST. # No hybrid kernel & no exch-disp scaling; set SAPT_DFT_DO_DHF True; set SAPT_DFT_DO_HYBRID False; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; energy('sapt(dft)', molecule=dimer); for k, v in Eref_nh.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""!hyb, xd=none, dHF: "" + k) #TEST. # Hybrid kernel & exch-disp scaling (DISP); set SAPT_DFT_DO_HYBRID True; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME disp; energy('sapt(dft)', molecule=dimer); for k, v in Eref_h_disp.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=disp, dHF: "" + k) #TEST. # Hybrid kernel & exch-disp scaling (FIXED); set SAPT_DFT_DO_HYBRID True; set SAPT_DFT_EXCH_DISP_SCALE_SCHEME fixed ; set SAPT_DFT_EXCH_DISP_FIXED_SCALE 0.770; energy('sapt(dft)', molecule=dimer); for k, v in Eref_h_fixed.items(): #TEST; compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=fixed, dHF: "" + k) #TEST. ```; * I think it should be clear from the output file what exch-disp scheme/scale is applied. So perhaps add a couple lines to the printout like below. This should also satisfy Jonathon's request that the output file show the change in scaling defaults. ```; ==> E20 Dispersion (MP2) <==. Disp20 (MP2) -0.37881730 [mEh]; Exch-Disp20,u 0.02037338 [mEh]; Scaling Scheme: Disp; Scaling Factor: 0.707. SAPT(DFT) Results; ---------------------------------------------------------------------------------------------------------; Electrostatics -0.10197192 [mEh] -0.06398835 [kcal/mol] -0.26772724 [kJ/mol]; Elst1,r -0.10197192 [mEh] -0.06398835 [kcal/mol] -0.26772724 [kJ/mol]; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1283510216
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:986,Energy Efficiency,energy,energy,986,"> Hi Yi,; > ; > Thanks for your work and the comments. I've been discussing some with Jonathon, and I think if you could do the below, that will clarify all the scaling factor and testing aspects of the PR, so we can move on to the I/O optimization and routing logic parts. Please let me know of any concerns.; > ; > * accept the various GH suggestions clarifying the scaling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; > * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; > ; > ```; > #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > se",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:1074,Energy Efficiency,ENERGY,ENERGY,1074,"been discussing some with Jonathon, and I think if you could do the below, that will clarify all the scaling factor and testing aspects of the PR, so we can move on to the I/O optimization and routing logic parts. Please let me know of any concerns.; > ; > * accept the various GH suggestions clarifying the scaling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; > * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; > ; > ```; > #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:1116,Energy Efficiency,ENERGY,ENERGY,1116,"k if you could do the below, that will clarify all the scaling factor and testing aspects of the PR, so we can move on to the I/O optimization and routing logic parts. Please let me know of any concerns.; > ; > * accept the various GH suggestions clarifying the scaling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; > * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; > ; > ```; > #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dim",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:1156,Energy Efficiency,ENERGY,ENERGY,1156,"arify all the scaling factor and testing aspects of the PR, so we can move on to the I/O optimization and routing logic parts. Please let me know of any concerns.; > ; > * accept the various GH suggestions clarifying the scaling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; > * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; > ; > ```; > #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:1198,Energy Efficiency,ENERGY,ENERGY,1198,"spects of the PR, so we can move on to the I/O optimization and routing logic parts. Please let me know of any concerns.; > ; > * accept the various GH suggestions clarifying the scaling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; > * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; > ; > ```; > #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > if k in [""SAPT IND ENERGY"", ""CURRENT ",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:1238,Energy Efficiency,ENERGY,ENERGY,1238,"he I/O optimization and routing logic parts. Please let me know of any concerns.; > ; > * accept the various GH suggestions clarifying the scaling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; > * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; > ; > ```; > #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; > ref = (v - DHF) / 1000.0; > ",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:1298,Energy Efficiency,ENERGY,ENERGY,1298,"e let me know of any concerns.; > ; > * accept the various GH suggestions clarifying the scaling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; > * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; > ; > ```; > #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; > ref = (v - DHF) / 1000.0; > else:; > ref = v / 1000.0; > compare_values(ref, p",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:1340,Energy Efficiency,ENERGY,ENERGY,1340,"various GH suggestions clarifying the scaling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; > * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; > ; > ```; > #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; > ref = (v - DHF) / 1000.0; > else:; > ref = v / 1000.0; > compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #T",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:1380,Energy Efficiency,ENERGY,ENERGY,1380,"ling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; > * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; > ; > ```; > #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; > ref = (v - DHF) / 1000.0; > else:; > ref = v / 1000.0; > compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST; > ; > # No hybrid kernel & no exch-d",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:1422,Energy Efficiency,ENERGY,ENERGY,1422,"h them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; > * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; > ; > ```; > #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; > ref = (v - DHF) / 1000.0; > else:; > ref = v / 1000.0; > compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST; > ; > # No hybrid kernel & no exch-disp scaling; > set SAPT_DFT_DO_DHF True; ",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:1462,Energy Efficiency,ENERGY,ENERGY,1462," changes locally, rather than through the GH interface, if that makes the git operations easier.; > * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; > ; > ```; > #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; > ref = (v - DHF) / 1000.0; > else:; > ref = v / 1000.0; > compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST; > ; > # No hybrid kernel & no exch-disp scaling; > set SAPT_DFT_DO_DHF True; > set SAPT_DFT_DO_HYBRID False; > set SAP",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:1524,Energy Efficiency,ENERGY,ENERGY,1524,"ace, if that makes the git operations easier.; > * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; > ; > ```; > #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; > ref = (v - DHF) / 1000.0; > else:; > ref = v / 1000.0; > compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST; > ; > # No hybrid kernel & no exch-disp scaling; > set SAPT_DFT_DO_DHF True; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(d",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:1566,Energy Efficiency,ENERGY,ENERGY,1566,"edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; > ; > ```; > #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; > ref = (v - DHF) / 1000.0; > else:; > ref = v / 1000.0; > compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST; > ; > # No hybrid kernel & no exch-disp scaling; > set SAPT_DFT_DO_DHF True; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items()",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:1606,Energy Efficiency,ENERGY,ENERGY,1606,"the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; > ; > ```; > #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; > ref = (v - DHF) / 1000.0; > else:; > ref = v / 1000.0; > compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST; > ; > # No hybrid kernel & no exch-disp scaling; > set SAPT_DFT_DO_DHF True; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > compare_values(v / 1000.0, psi",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:1648,Energy Efficiency,ENERGY,ENERGY,1648,"out the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; > ; > ```; > #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; > ref = (v - DHF) / 1000.0; > else:; > ref = v / 1000.0; > compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST; > ; > # No hybrid kernel & no exch-disp scaling; > set SAPT_DFT_DO_DHF True; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""!hyb, xd=none, dHF: "" ",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:1688,Energy Efficiency,ENERGY,ENERGY,1688," value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; > ; > ```; > #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; > ref = (v - DHF) / 1000.0; > else:; > ref = v / 1000.0; > compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST; > ; > # No hybrid kernel & no exch-disp scaling; > set SAPT_DFT_DO_DHF True; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""!hyb, xd=none, dHF: "" + k) #TEST; > ; > # Hybrid kernel & exch-",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:2075,Energy Efficiency,energy,energy,2075,"oms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; > ref = (v - DHF) / 1000.0; > else:; > ref = v / 1000.0; > compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST; > ; > # No hybrid kernel & no exch-disp scaling; > set SAPT_DFT_DO_DHF True; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""!hyb, xd=none, dHF: "" + k) #TEST; > ; > # Hybrid kernel & exch-disp scaling (DISP); > set SAPT_DFT_DO_HYBRID True; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME disp; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_h_disp.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=disp, dHF: "" + k) #TEST; > ; > # Hybrid kernel & exch-disp scaling (FIXED); > set SAPT_DFT_DO_HYBR",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:2171,Energy Efficiency,ENERGY,ENERGY,2171,"TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; > ref = (v - DHF) / 1000.0; > else:; > ref = v / 1000.0; > compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST; > ; > # No hybrid kernel & no exch-disp scaling; > set SAPT_DFT_DO_DHF True; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""!hyb, xd=none, dHF: "" + k) #TEST; > ; > # Hybrid kernel & exch-disp scaling (DISP); > set SAPT_DFT_DO_HYBRID True; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME disp; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_h_disp.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=disp, dHF: "" + k) #TEST; > ; > # Hybrid kernel & exch-disp scaling (FIXED); > set SAPT_DFT_DO_HYBRID True; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME fixed ; > set SAPT_DFT_EXCH_DISP_FIXED_SCALE 0.770; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_h_fixed.i",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:2189,Energy Efficiency,ENERGY,ENERGY,2189,"TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; > ref = (v - DHF) / 1000.0; > else:; > ref = v / 1000.0; > compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST; > ; > # No hybrid kernel & no exch-disp scaling; > set SAPT_DFT_DO_DHF True; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""!hyb, xd=none, dHF: "" + k) #TEST; > ; > # Hybrid kernel & exch-disp scaling (DISP); > set SAPT_DFT_DO_HYBRID True; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME disp; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_h_disp.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=disp, dHF: "" + k) #TEST; > ; > # Hybrid kernel & exch-disp scaling (FIXED); > set SAPT_DFT_DO_HYBRID True; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME fixed ; > set SAPT_DFT_EXCH_DISP_FIXED_SCALE 0.770; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_h_fixed.i",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:2491,Energy Efficiency,energy,energy,2491,"DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; > ref = (v - DHF) / 1000.0; > else:; > ref = v / 1000.0; > compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST; > ; > # No hybrid kernel & no exch-disp scaling; > set SAPT_DFT_DO_DHF True; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""!hyb, xd=none, dHF: "" + k) #TEST; > ; > # Hybrid kernel & exch-disp scaling (DISP); > set SAPT_DFT_DO_HYBRID True; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME disp; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_h_disp.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=disp, dHF: "" + k) #TEST; > ; > # Hybrid kernel & exch-disp scaling (FIXED); > set SAPT_DFT_DO_HYBRID True; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME fixed ; > set SAPT_DFT_EXCH_DISP_FIXED_SCALE 0.770; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_h_fixed.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=fixed, dHF: "" + k) #TEST; > ```; > ; > * I think it should be clear from the output file what exch-disp scheme/scale is applied. So perhaps add a couple lines to t",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:2778,Energy Efficiency,energy,energy,2778," > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; > ref = (v - DHF) / 1000.0; > else:; > ref = v / 1000.0; > compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST; > ; > # No hybrid kernel & no exch-disp scaling; > set SAPT_DFT_DO_DHF True; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""!hyb, xd=none, dHF: "" + k) #TEST; > ; > # Hybrid kernel & exch-disp scaling (DISP); > set SAPT_DFT_DO_HYBRID True; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME disp; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_h_disp.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=disp, dHF: "" + k) #TEST; > ; > # Hybrid kernel & exch-disp scaling (FIXED); > set SAPT_DFT_DO_HYBRID True; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME fixed ; > set SAPT_DFT_EXCH_DISP_FIXED_SCALE 0.770; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_h_fixed.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=fixed, dHF: "" + k) #TEST; > ```; > ; > * I think it should be clear from the output file what exch-disp scheme/scale is applied. So perhaps add a couple lines to the printout like below. This should also satisfy Jonathon's request that the output file show the change in scaling defaults.; > ; > ```; > ==> E20 Dispersion (MP2) <==; > ; > ; > Disp20 (MP2) -0.37881730 [mEh]; > Exch-Disp20,u 0.02037338 [mEh]; > Scaling Scheme: Disp; > Scaling Factor: 0.707; > ; > SAP",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:3115,Energy Efficiency,energy,energy,3115,"#TEST; > if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; > ref = (v - DHF) / 1000.0; > else:; > ref = v / 1000.0; > compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST; > ; > # No hybrid kernel & no exch-disp scaling; > set SAPT_DFT_DO_DHF True; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""!hyb, xd=none, dHF: "" + k) #TEST; > ; > # Hybrid kernel & exch-disp scaling (DISP); > set SAPT_DFT_DO_HYBRID True; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME disp; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_h_disp.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=disp, dHF: "" + k) #TEST; > ; > # Hybrid kernel & exch-disp scaling (FIXED); > set SAPT_DFT_DO_HYBRID True; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME fixed ; > set SAPT_DFT_EXCH_DISP_FIXED_SCALE 0.770; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_h_fixed.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=fixed, dHF: "" + k) #TEST; > ```; > ; > * I think it should be clear from the output file what exch-disp scheme/scale is applied. So perhaps add a couple lines to the printout like below. This should also satisfy Jonathon's request that the output file show the change in scaling defaults.; > ; > ```; > ==> E20 Dispersion (MP2) <==; > ; > ; > Disp20 (MP2) -0.37881730 [mEh]; > Exch-Disp20,u 0.02037338 [mEh]; > Scaling Scheme: Disp; > Scaling Factor: 0.707; > ; > SAPT(DFT) Results; > ---------------------------------------------------------------------------------------------------------; > Electrostatics -0.10197192 [mEh] -0.06398835 [kcal/mol] -0.26772724 [kJ/mol]; > Elst1,r -0.10197192 [mEh] -0.06398835 [kcal/mol] -0.26772724 [kJ/mol]; > ```. Added the !dHF cases in `sapt-dft1` and `sapt-dft2`. For `sapt-dft-api`, the dHF feature is intrinsically unsupported, because the dHF cal",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:253,Integrability,rout,routing,253,"> Hi Yi,; > ; > Thanks for your work and the comments. I've been discussing some with Jonathon, and I think if you could do the below, that will clarify all the scaling factor and testing aspects of the PR, so we can move on to the I/O optimization and routing logic parts. Please let me know of any concerns.; > ; > * accept the various GH suggestions clarifying the scaling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; > * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; > ; > ```; > #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > se",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:499,Integrability,interface,interface,499,"> Hi Yi,; > ; > Thanks for your work and the comments. I've been discussing some with Jonathon, and I think if you could do the below, that will clarify all the scaling factor and testing aspects of the PR, so we can move on to the I/O optimization and routing logic parts. Please let me know of any concerns.; > ; > * accept the various GH suggestions clarifying the scaling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; > * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; > ; > ```; > #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > se",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:829,Integrability,rout,routing,829,"> Hi Yi,; > ; > Thanks for your work and the comments. I've been discussing some with Jonathon, and I think if you could do the below, that will clarify all the scaling factor and testing aspects of the PR, so we can move on to the I/O optimization and routing logic parts. Please let me know of any concerns.; > ; > * accept the various GH suggestions clarifying the scaling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; > * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; > ; > ```; > #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > se",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:2284,Modifiability,variab,variable,2284,"DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; > ref = (v - DHF) / 1000.0; > else:; > ref = v / 1000.0; > compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST; > ; > # No hybrid kernel & no exch-disp scaling; > set SAPT_DFT_DO_DHF True; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""!hyb, xd=none, dHF: "" + k) #TEST; > ; > # Hybrid kernel & exch-disp scaling (DISP); > set SAPT_DFT_DO_HYBRID True; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME disp; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_h_disp.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=disp, dHF: "" + k) #TEST; > ; > # Hybrid kernel & exch-disp scaling (FIXED); > set SAPT_DFT_DO_HYBRID True; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME fixed ; > set SAPT_DFT_EXCH_DISP_FIXED_SCALE 0.770; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_h_fixed.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=fixed, dHF: "" + k) #TEST; > ```; > ; > * I think it should be clear from the output file what exch-disp scheme/scale is applied. So perhaps add a couple lines to t",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:2600,Modifiability,variab,variable,2600," > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; > ref = (v - DHF) / 1000.0; > else:; > ref = v / 1000.0; > compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST; > ; > # No hybrid kernel & no exch-disp scaling; > set SAPT_DFT_DO_DHF True; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""!hyb, xd=none, dHF: "" + k) #TEST; > ; > # Hybrid kernel & exch-disp scaling (DISP); > set SAPT_DFT_DO_HYBRID True; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME disp; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_h_disp.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=disp, dHF: "" + k) #TEST; > ; > # Hybrid kernel & exch-disp scaling (FIXED); > set SAPT_DFT_DO_HYBRID True; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME fixed ; > set SAPT_DFT_EXCH_DISP_FIXED_SCALE 0.770; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_h_fixed.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=fixed, dHF: "" + k) #TEST; > ```; > ; > * I think it should be clear from the output file what exch-disp scheme/scale is applied. So perhaps add a couple lines to the printout like below. This should also satisfy Jonathon's request that the output file show the change in scaling defaults.; > ; > ```; > ==> E20 Dispersion (MP2) <==; > ; > ; > Disp20 (MP2) -0.37881730 [mEh]; > Exch-Disp20,u 0.02037338 [mEh]; > Scaling Scheme: Disp; > Scaling Factor: 0.707; > ; > SAP",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:2891,Modifiability,variab,variable,2891,"set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; > ref = (v - DHF) / 1000.0; > else:; > ref = v / 1000.0; > compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST; > ; > # No hybrid kernel & no exch-disp scaling; > set SAPT_DFT_DO_DHF True; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""!hyb, xd=none, dHF: "" + k) #TEST; > ; > # Hybrid kernel & exch-disp scaling (DISP); > set SAPT_DFT_DO_HYBRID True; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME disp; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_h_disp.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=disp, dHF: "" + k) #TEST; > ; > # Hybrid kernel & exch-disp scaling (FIXED); > set SAPT_DFT_DO_HYBRID True; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME fixed ; > set SAPT_DFT_EXCH_DISP_FIXED_SCALE 0.770; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_h_fixed.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=fixed, dHF: "" + k) #TEST; > ```; > ; > * I think it should be clear from the output file what exch-disp scheme/scale is applied. So perhaps add a couple lines to the printout like below. This should also satisfy Jonathon's request that the output file show the change in scaling defaults.; > ; > ```; > ==> E20 Dispersion (MP2) <==; > ; > ; > Disp20 (MP2) -0.37881730 [mEh]; > Exch-Disp20,u 0.02037338 [mEh]; > Scaling Scheme: Disp; > Scaling Factor: 0.707; > ; > SAPT(DFT) Results; > ---------------------------------------------------------------------------------------------------------; > Electrostatics -0.10197192 [mEh] -0.06398835 [kcal/mol] -0.26772724 [kJ/mol]; > Elst1,r -0.10197192 [mEh] -0.06398835 [kcal/mol] -0.26772724 [kJ/mol]; >",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:3229,Modifiability,variab,variable,3229,", xd=none, !dHF: "" + k) #TEST; > ; > # No hybrid kernel & no exch-disp scaling; > set SAPT_DFT_DO_DHF True; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""!hyb, xd=none, dHF: "" + k) #TEST; > ; > # Hybrid kernel & exch-disp scaling (DISP); > set SAPT_DFT_DO_HYBRID True; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME disp; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_h_disp.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=disp, dHF: "" + k) #TEST; > ; > # Hybrid kernel & exch-disp scaling (FIXED); > set SAPT_DFT_DO_HYBRID True; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME fixed ; > set SAPT_DFT_EXCH_DISP_FIXED_SCALE 0.770; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_h_fixed.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=fixed, dHF: "" + k) #TEST; > ```; > ; > * I think it should be clear from the output file what exch-disp scheme/scale is applied. So perhaps add a couple lines to the printout like below. This should also satisfy Jonathon's request that the output file show the change in scaling defaults.; > ; > ```; > ==> E20 Dispersion (MP2) <==; > ; > ; > Disp20 (MP2) -0.37881730 [mEh]; > Exch-Disp20,u 0.02037338 [mEh]; > Scaling Scheme: Disp; > Scaling Factor: 0.707; > ; > SAPT(DFT) Results; > ---------------------------------------------------------------------------------------------------------; > Electrostatics -0.10197192 [mEh] -0.06398835 [kcal/mol] -0.26772724 [kJ/mol]; > Elst1,r -0.10197192 [mEh] -0.06398835 [kcal/mol] -0.26772724 [kJ/mol]; > ```. Added the !dHF cases in `sapt-dft1` and `sapt-dft2`. For `sapt-dft-api`, the dHF feature is intrinsically unsupported, because the dHF calculation is not fully contained in the sapt_dft() call; a part of it is in the run_sapt_dft() call. . Added the scaling scheme/factor output lines in the output f",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:236,Performance,optimiz,optimization,236,"> Hi Yi,; > ; > Thanks for your work and the comments. I've been discussing some with Jonathon, and I think if you could do the below, that will clarify all the scaling factor and testing aspects of the PR, so we can move on to the I/O optimization and routing logic parts. Please let me know of any concerns.; > ; > * accept the various GH suggestions clarifying the scaling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; > * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; > ; > ```; > #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > se",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:180,Testability,test,testing,180,"> Hi Yi,; > ; > Thanks for your work and the comments. I've been discussing some with Jonathon, and I think if you could do the below, that will clarify all the scaling factor and testing aspects of the PR, so we can move on to the I/O optimization and routing logic parts. Please let me know of any concerns.; > ; > * accept the various GH suggestions clarifying the scaling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; > * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; > ; > ```; > #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > se",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:261,Testability,log,logic,261,"> Hi Yi,; > ; > Thanks for your work and the comments. I've been discussing some with Jonathon, and I think if you could do the below, that will clarify all the scaling factor and testing aspects of the PR, so we can move on to the I/O optimization and routing logic parts. Please let me know of any concerns.; > ; > * accept the various GH suggestions clarifying the scaling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; > * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; > ; > ```; > #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > se",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:571,Testability,test,test,571,"> Hi Yi,; > ; > Thanks for your work and the comments. I've been discussing some with Jonathon, and I think if you could do the below, that will clarify all the scaling factor and testing aspects of the PR, so we can move on to the I/O optimization and routing logic parts. Please let me know of any concerns.; > ; > * accept the various GH suggestions clarifying the scaling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; > * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; > ; > ```; > #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > se",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:690,Testability,test,test,690,"> Hi Yi,; > ; > Thanks for your work and the comments. I've been discussing some with Jonathon, and I think if you could do the below, that will clarify all the scaling factor and testing aspects of the PR, so we can move on to the I/O optimization and routing logic parts. Please let me know of any concerns.; > ; > * accept the various GH suggestions clarifying the scaling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; > * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; > ; > ```; > #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > se",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:837,Testability,log,logic,837,"> Hi Yi,; > ; > Thanks for your work and the comments. I've been discussing some with Jonathon, and I think if you could do the below, that will clarify all the scaling factor and testing aspects of the PR, so we can move on to the I/O optimization and routing logic parts. Please let me know of any concerns.; > ; > * accept the various GH suggestions clarifying the scaling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; > * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; > ; > ```; > #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > se",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:912,Testability,test,tests,912,"> Hi Yi,; > ; > Thanks for your work and the comments. I've been discussing some with Jonathon, and I think if you could do the below, that will clarify all the scaling factor and testing aspects of the PR, so we can move on to the I/O optimization and routing logic parts. Please let me know of any concerns.; > ; > * accept the various GH suggestions clarifying the scaling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; > * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; > ; > ```; > #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > se",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:1044,Testability,TEST,TEST,1044,"been discussing some with Jonathon, and I think if you could do the below, that will clarify all the scaling factor and testing aspects of the PR, so we can move on to the I/O optimization and routing logic parts. Please let me know of any concerns.; > ; > * accept the various GH suggestions clarifying the scaling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; > * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; > ; > ```; > #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:1097,Testability,TEST,TEST,1097,"k if you could do the below, that will clarify all the scaling factor and testing aspects of the PR, so we can move on to the I/O optimization and routing logic parts. Please let me know of any concerns.; > ; > * accept the various GH suggestions clarifying the scaling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; > * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; > ; > ```; > #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dim",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:1138,Testability,TEST,TEST,1138,"arify all the scaling factor and testing aspects of the PR, so we can move on to the I/O optimization and routing logic parts. Please let me know of any concerns.; > ; > * accept the various GH suggestions clarifying the scaling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; > * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; > ; > ```; > #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:1179,Testability,TEST,TEST,1179,"spects of the PR, so we can move on to the I/O optimization and routing logic parts. Please let me know of any concerns.; > ; > * accept the various GH suggestions clarifying the scaling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; > * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; > ; > ```; > #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > if k in [""SAPT IND ENERGY"", ""CURRENT ",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:1221,Testability,TEST,TEST,1221,"he I/O optimization and routing logic parts. Please let me know of any concerns.; > ; > * accept the various GH suggestions clarifying the scaling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; > * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; > ; > ```; > #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; > ref = (v - DHF) / 1000.0; > ",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:1260,Testability,TEST,TEST,1260,"e let me know of any concerns.; > ; > * accept the various GH suggestions clarifying the scaling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; > * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; > ; > ```; > #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; > ref = (v - DHF) / 1000.0; > else:; > ref = v / 1000.0; > compare_values(ref, p",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:1321,Testability,TEST,TEST,1321,"various GH suggestions clarifying the scaling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; > * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; > ; > ```; > #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; > ref = (v - DHF) / 1000.0; > else:; > ref = v / 1000.0; > compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #T",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:1362,Testability,TEST,TEST,1362,"ling scheme changes (only if you agree with them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; > * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; > ; > ```; > #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; > ref = (v - DHF) / 1000.0; > else:; > ref = v / 1000.0; > compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST; > ; > # No hybrid kernel & no exch-d",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:1403,Testability,TEST,TEST,1403,"h them, of course). Feel free to make the changes locally, rather than through the GH interface, if that makes the git operations easier.; > * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; > ; > ```; > #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; > ref = (v - DHF) / 1000.0; > else:; > ref = v / 1000.0; > compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST; > ; > # No hybrid kernel & no exch-disp scaling; > set SAPT_DFT_DO_DHF True; ",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:1445,Testability,TEST,TEST,1445," changes locally, rather than through the GH interface, if that makes the git operations easier.; > * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; > ; > ```; > #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; > ref = (v - DHF) / 1000.0; > else:; > ref = v / 1000.0; > compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST; > ; > # No hybrid kernel & no exch-disp scaling; > set SAPT_DFT_DO_DHF True; > set SAPT_DFT_DO_HYBRID False; > set SAP",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:1485,Testability,TEST,TEST,1485,"ace, if that makes the git operations easier.; > * edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; > ; > ```; > #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; > ref = (v - DHF) / 1000.0; > else:; > ref = v / 1000.0; > compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST; > ; > # No hybrid kernel & no exch-disp scaling; > set SAPT_DFT_DO_DHF True; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(d",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:1547,Testability,TEST,TEST,1547,"edit sapt-dft1 test to be something like the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; > ; > ```; > #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; > ref = (v - DHF) / 1000.0; > else:; > ref = v / 1000.0; > compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST; > ; > # No hybrid kernel & no exch-disp scaling; > set SAPT_DFT_DO_DHF True; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items()",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:1588,Testability,TEST,TEST,1588,"the below. This adds an extra section without the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; > ; > ```; > #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; > ref = (v - DHF) / 1000.0; > else:; > ref = v / 1000.0; > compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST; > ; > # No hybrid kernel & no exch-disp scaling; > set SAPT_DFT_DO_DHF True; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > compare_values(v / 1000.0, psi",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:1629,Testability,TEST,TEST,1629,"out the deltaHF correction. The analogous value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; > ; > ```; > #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; > ref = (v - DHF) / 1000.0; > else:; > ref = v / 1000.0; > compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST; > ; > # No hybrid kernel & no exch-disp scaling; > set SAPT_DFT_DO_DHF True; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""!hyb, xd=none, dHF: "" ",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:1671,Testability,TEST,TEST,1671," value in test sapt-dft2 is `DHF = -1.42620815`. This passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; > ; > ```; > #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; > ref = (v - DHF) / 1000.0; > else:; > ref = v / 1000.0; > compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST; > ; > # No hybrid kernel & no exch-disp scaling; > set SAPT_DFT_DO_DHF True; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""!hyb, xd=none, dHF: "" + k) #TEST; > ; > # Hybrid kernel & exch-",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:1711,Testability,TEST,TEST,1711,"is passes on master for me, so having the dHF=False pass on your PR will help verify the separate routing logic you added. With this in place, there won't be a need to separate out tests into another PR.; > ; > ```; > #! SAPT(DFT) aug-cc-pVDZ interaction energy between Ne and Ar atoms.; > ; > DHF = -0.01189736 #TEST; > Eref_nh = {""SAPT ELST ENERGY"": -0.10190449, #TEST; > ""SAPT EXCH ENERGY"": 0.36545706, #TEST; > ""SAPT IND ENERGY"": -0.00840483, #TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; > ref = (v - DHF) / 1000.0; > else:; > ref = v / 1000.0; > compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST; > ; > # No hybrid kernel & no exch-disp scaling; > set SAPT_DFT_DO_DHF True; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""!hyb, xd=none, dHF: "" + k) #TEST; > ; > # Hybrid kernel & exch-disp scaling (DISP); > set SAPT_DFT_DO_HYBRID True;",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:2144,Testability,TEST,TEST,2144,"TEST; > ""SAPT DISP ENERGY"": -0.24398704, #TEST; > ""CURRENT ENERGY"": 0.01122234} #TEST; > ; > Eref_h_disp = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; > ref = (v - DHF) / 1000.0; > else:; > ref = v / 1000.0; > compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST; > ; > # No hybrid kernel & no exch-disp scaling; > set SAPT_DFT_DO_DHF True; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""!hyb, xd=none, dHF: "" + k) #TEST; > ; > # Hybrid kernel & exch-disp scaling (DISP); > set SAPT_DFT_DO_HYBRID True; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME disp; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_h_disp.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=disp, dHF: "" + k) #TEST; > ; > # Hybrid kernel & exch-disp scaling (FIXED); > set SAPT_DFT_DO_HYBRID True; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME fixed ; > set SAPT_DFT_EXCH_DISP_FIXED_SCALE 0.770; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_h_fixed.i",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:2330,Testability,TEST,TEST,2330,"DISP ENERGY"": -0.26658499, #TEST; > ""CURRENT ENERGY"": -0.01126250} #TEST; > ; > Eref_h_fixed = {""SAPT ELST ENERGY"": -0.10197193, #TEST; > ""SAPT EXCH ENERGY"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; > ref = (v - DHF) / 1000.0; > else:; > ref = v / 1000.0; > compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST; > ; > # No hybrid kernel & no exch-disp scaling; > set SAPT_DFT_DO_DHF True; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""!hyb, xd=none, dHF: "" + k) #TEST; > ; > # Hybrid kernel & exch-disp scaling (DISP); > set SAPT_DFT_DO_HYBRID True; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME disp; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_h_disp.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=disp, dHF: "" + k) #TEST; > ; > # Hybrid kernel & exch-disp scaling (FIXED); > set SAPT_DFT_DO_HYBRID True; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME fixed ; > set SAPT_DFT_EXCH_DISP_FIXED_SCALE 0.770; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_h_fixed.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=fixed, dHF: "" + k) #TEST; > ```; > ; > * I think it should be clear from the output file what exch-disp scheme/scale is applied. So perhaps add a couple lines to t",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:2560,Testability,TEST,TEST,2560,"Y"": 0.36569812, #TEST; > ""SAPT IND ENERGY"": -0.00840370, #TEST; > ""SAPT DISP ENERGY"": -0.26605283, #TEST; > ""CURRENT ENERGY"": -0.01073034} #TEST; > ; > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; > ref = (v - DHF) / 1000.0; > else:; > ref = v / 1000.0; > compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST; > ; > # No hybrid kernel & no exch-disp scaling; > set SAPT_DFT_DO_DHF True; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""!hyb, xd=none, dHF: "" + k) #TEST; > ; > # Hybrid kernel & exch-disp scaling (DISP); > set SAPT_DFT_DO_HYBRID True; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME disp; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_h_disp.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=disp, dHF: "" + k) #TEST; > ; > # Hybrid kernel & exch-disp scaling (FIXED); > set SAPT_DFT_DO_HYBRID True; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME fixed ; > set SAPT_DFT_EXCH_DISP_FIXED_SCALE 0.770; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_h_fixed.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=fixed, dHF: "" + k) #TEST; > ```; > ; > * I think it should be clear from the output file what exch-disp scheme/scale is applied. So perhaps add a couple lines to the printout like below. This should also satisfy Jonathon's request that the output file show the change in scaling defaults.; > ; > ```; > ==> E20 Disper",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:2645,Testability,TEST,TEST,2645," > molecule dimer {; > Ne; > --; > Ar 1 6.5; > units bohr; > }; > ; > set {; > basis aug-cc-pvdz; > scf_type df; > sapt_dft_grac_shift_a 0.203293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; > ref = (v - DHF) / 1000.0; > else:; > ref = v / 1000.0; > compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST; > ; > # No hybrid kernel & no exch-disp scaling; > set SAPT_DFT_DO_DHF True; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""!hyb, xd=none, dHF: "" + k) #TEST; > ; > # Hybrid kernel & exch-disp scaling (DISP); > set SAPT_DFT_DO_HYBRID True; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME disp; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_h_disp.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=disp, dHF: "" + k) #TEST; > ; > # Hybrid kernel & exch-disp scaling (FIXED); > set SAPT_DFT_DO_HYBRID True; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME fixed ; > set SAPT_DFT_EXCH_DISP_FIXED_SCALE 0.770; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_h_fixed.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=fixed, dHF: "" + k) #TEST; > ```; > ; > * I think it should be clear from the output file what exch-disp scheme/scale is applied. So perhaps add a couple lines to the printout like below. This should also satisfy Jonathon's request that the output file show the change in scaling defaults.; > ; > ```; > ==> E20 Dispersion (MP2) <==; > ; > ; > Disp20 (MP2) -0.37881730 [mEh]; > Exch-Disp20,u 0.02037338 [mEh]; > Scaling Scheme: Disp; > Scaling Factor: 0.707; > ; > SAP",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:2851,Testability,TEST,TEST,2851,"293; > sapt_dft_grac_shift_b 0.138264; > }; > ; > # No hybrid kernel & no exch-disp scaling & no deltaHF; > set SAPT_DFT_DO_DHF False; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; > ref = (v - DHF) / 1000.0; > else:; > ref = v / 1000.0; > compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST; > ; > # No hybrid kernel & no exch-disp scaling; > set SAPT_DFT_DO_DHF True; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""!hyb, xd=none, dHF: "" + k) #TEST; > ; > # Hybrid kernel & exch-disp scaling (DISP); > set SAPT_DFT_DO_HYBRID True; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME disp; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_h_disp.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=disp, dHF: "" + k) #TEST; > ; > # Hybrid kernel & exch-disp scaling (FIXED); > set SAPT_DFT_DO_HYBRID True; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME fixed ; > set SAPT_DFT_EXCH_DISP_FIXED_SCALE 0.770; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_h_fixed.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=fixed, dHF: "" + k) #TEST; > ```; > ; > * I think it should be clear from the output file what exch-disp scheme/scale is applied. So perhaps add a couple lines to the printout like below. This should also satisfy Jonathon's request that the output file show the change in scaling defaults.; > ; > ```; > ==> E20 Dispersion (MP2) <==; > ; > ; > Disp20 (MP2) -0.37881730 [mEh]; > Exch-Disp20,u 0.02037338 [mEh]; > Scaling Scheme: Disp; > Scaling Factor: 0.707; > ; > SAPT(DFT) Results; > ---------------------------------------------------------------------------------------------------------; > Electrostatics",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:2935,Testability,TEST,TEST,2935,"set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > if k in [""SAPT IND ENERGY"", ""CURRENT ENERGY""]:; > ref = (v - DHF) / 1000.0; > else:; > ref = v / 1000.0; > compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST; > ; > # No hybrid kernel & no exch-disp scaling; > set SAPT_DFT_DO_DHF True; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""!hyb, xd=none, dHF: "" + k) #TEST; > ; > # Hybrid kernel & exch-disp scaling (DISP); > set SAPT_DFT_DO_HYBRID True; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME disp; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_h_disp.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=disp, dHF: "" + k) #TEST; > ; > # Hybrid kernel & exch-disp scaling (FIXED); > set SAPT_DFT_DO_HYBRID True; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME fixed ; > set SAPT_DFT_EXCH_DISP_FIXED_SCALE 0.770; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_h_fixed.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=fixed, dHF: "" + k) #TEST; > ```; > ; > * I think it should be clear from the output file what exch-disp scheme/scale is applied. So perhaps add a couple lines to the printout like below. This should also satisfy Jonathon's request that the output file show the change in scaling defaults.; > ; > ```; > ==> E20 Dispersion (MP2) <==; > ; > ; > Disp20 (MP2) -0.37881730 [mEh]; > Exch-Disp20,u 0.02037338 [mEh]; > Scaling Scheme: Disp; > Scaling Factor: 0.707; > ; > SAPT(DFT) Results; > ---------------------------------------------------------------------------------------------------------; > Electrostatics -0.10197192 [mEh] -0.06398835 [kcal/mol] -0.26772724 [kJ/mol]; > Elst1,r -0.10197192 [mEh] -0.06398835 [kcal/mol] -0.26772724 [kJ/mol]; >",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:3189,Testability,TEST,TEST,3189,"> ref = (v - DHF) / 1000.0; > else:; > ref = v / 1000.0; > compare_values(ref, psi4.variable(k), 6, ""!hyb, xd=none, !dHF: "" + k) #TEST; > ; > # No hybrid kernel & no exch-disp scaling; > set SAPT_DFT_DO_DHF True; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""!hyb, xd=none, dHF: "" + k) #TEST; > ; > # Hybrid kernel & exch-disp scaling (DISP); > set SAPT_DFT_DO_HYBRID True; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME disp; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_h_disp.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=disp, dHF: "" + k) #TEST; > ; > # Hybrid kernel & exch-disp scaling (FIXED); > set SAPT_DFT_DO_HYBRID True; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME fixed ; > set SAPT_DFT_EXCH_DISP_FIXED_SCALE 0.770; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_h_fixed.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=fixed, dHF: "" + k) #TEST; > ```; > ; > * I think it should be clear from the output file what exch-disp scheme/scale is applied. So perhaps add a couple lines to the printout like below. This should also satisfy Jonathon's request that the output file show the change in scaling defaults.; > ; > ```; > ==> E20 Dispersion (MP2) <==; > ; > ; > Disp20 (MP2) -0.37881730 [mEh]; > Exch-Disp20,u 0.02037338 [mEh]; > Scaling Scheme: Disp; > Scaling Factor: 0.707; > ; > SAPT(DFT) Results; > ---------------------------------------------------------------------------------------------------------; > Electrostatics -0.10197192 [mEh] -0.06398835 [kcal/mol] -0.26772724 [kJ/mol]; > Elst1,r -0.10197192 [mEh] -0.06398835 [kcal/mol] -0.26772724 [kJ/mol]; > ```. Added the !dHF cases in `sapt-dft1` and `sapt-dft2`. For `sapt-dft-api`, the dHF feature is intrinsically unsupported, because the dHF calculation is not fully contained in the sapt_dft() call; ",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:3274,Testability,TEST,TEST,3274,", xd=none, !dHF: "" + k) #TEST; > ; > # No hybrid kernel & no exch-disp scaling; > set SAPT_DFT_DO_DHF True; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""!hyb, xd=none, dHF: "" + k) #TEST; > ; > # Hybrid kernel & exch-disp scaling (DISP); > set SAPT_DFT_DO_HYBRID True; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME disp; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_h_disp.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=disp, dHF: "" + k) #TEST; > ; > # Hybrid kernel & exch-disp scaling (FIXED); > set SAPT_DFT_DO_HYBRID True; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME fixed ; > set SAPT_DFT_EXCH_DISP_FIXED_SCALE 0.770; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_h_fixed.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=fixed, dHF: "" + k) #TEST; > ```; > ; > * I think it should be clear from the output file what exch-disp scheme/scale is applied. So perhaps add a couple lines to the printout like below. This should also satisfy Jonathon's request that the output file show the change in scaling defaults.; > ; > ```; > ==> E20 Dispersion (MP2) <==; > ; > ; > Disp20 (MP2) -0.37881730 [mEh]; > Exch-Disp20,u 0.02037338 [mEh]; > Scaling Scheme: Disp; > Scaling Factor: 0.707; > ; > SAPT(DFT) Results; > ---------------------------------------------------------------------------------------------------------; > Electrostatics -0.10197192 [mEh] -0.06398835 [kcal/mol] -0.26772724 [kJ/mol]; > Elst1,r -0.10197192 [mEh] -0.06398835 [kcal/mol] -0.26772724 [kJ/mol]; > ```. Added the !dHF cases in `sapt-dft1` and `sapt-dft2`. For `sapt-dft-api`, the dHF feature is intrinsically unsupported, because the dHF calculation is not fully contained in the sapt_dft() call; a part of it is in the run_sapt_dft() call. . Added the scaling scheme/factor output lines in the output f",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967:3316,Usability,clear,clear,3316,", xd=none, !dHF: "" + k) #TEST; > ; > # No hybrid kernel & no exch-disp scaling; > set SAPT_DFT_DO_DHF True; > set SAPT_DFT_DO_HYBRID False; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME none; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_nh.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""!hyb, xd=none, dHF: "" + k) #TEST; > ; > # Hybrid kernel & exch-disp scaling (DISP); > set SAPT_DFT_DO_HYBRID True; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME disp; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_h_disp.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=disp, dHF: "" + k) #TEST; > ; > # Hybrid kernel & exch-disp scaling (FIXED); > set SAPT_DFT_DO_HYBRID True; > set SAPT_DFT_EXCH_DISP_SCALE_SCHEME fixed ; > set SAPT_DFT_EXCH_DISP_FIXED_SCALE 0.770; > energy('sapt(dft)', molecule=dimer); > for k, v in Eref_h_fixed.items(): #TEST; > compare_values(v / 1000.0, psi4.variable(k), 6, ""hyb, xd=fixed, dHF: "" + k) #TEST; > ```; > ; > * I think it should be clear from the output file what exch-disp scheme/scale is applied. So perhaps add a couple lines to the printout like below. This should also satisfy Jonathon's request that the output file show the change in scaling defaults.; > ; > ```; > ==> E20 Dispersion (MP2) <==; > ; > ; > Disp20 (MP2) -0.37881730 [mEh]; > Exch-Disp20,u 0.02037338 [mEh]; > Scaling Scheme: Disp; > Scaling Factor: 0.707; > ; > SAPT(DFT) Results; > ---------------------------------------------------------------------------------------------------------; > Electrostatics -0.10197192 [mEh] -0.06398835 [kcal/mol] -0.26772724 [kJ/mol]; > Elst1,r -0.10197192 [mEh] -0.06398835 [kcal/mol] -0.26772724 [kJ/mol]; > ```. Added the !dHF cases in `sapt-dft1` and `sapt-dft2`. For `sapt-dft-api`, the dHF feature is intrinsically unsupported, because the dHF calculation is not fully contained in the sapt_dft() call; a part of it is in the run_sapt_dft() call. . Added the scaling scheme/factor output lines in the output f",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2481#issuecomment-1284653967
https://github.com/psi4/psi4/pull/2483#issuecomment-1069347742:46,Deployability,upgrade,upgrade,46,"Yeah, if we're going to allow C++17 we should upgrade the minimum [GCC to version 7](https://en.cppreference.com/w/cpp/compiler_support) in our CI.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2483#issuecomment-1069347742
https://github.com/psi4/psi4/pull/2483#issuecomment-1069494244:60,Usability,simpl,simply,60,"Yeah, I would preallocate the E in the constructor and then simply fill it with zeroes in the compute pair function.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2483#issuecomment-1069494244
https://github.com/psi4/psi4/pull/2485#issuecomment-1075088445:322,Energy Efficiency,efficient,efficient,322,"The conversion to traceless form can be done for any order of multipole, but I'm not really sure it's got a use case at this point. Quadrupoles in traceless form can be useful for force field definitions. Our CFMM code uses very high orders of multipoles, but they're converted to spherical harmonics to work with all the efficient machinery we've developed so that doesn't need the traceless definition.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2485#issuecomment-1075088445
https://github.com/psi4/psi4/pull/2485#issuecomment-1075186676:324,Energy Efficiency,efficient,efficient,324,"> The conversion to traceless form can be done for any order of multipole, but I'm not really sure it's got a use case at this point. Quadrupoles in traceless form can be useful for force field definitions. Our CFMM code uses very high orders of multipoles, but they're converted to spherical harmonics to work with all the efficient machinery we've developed so that doesn't need the traceless definition. Max and I have traded Slack messages, and we're agreed on adding traceless quadrupoles so those still exist, but not to bother with the other multipoles for the time being. I'll add that to the PR hopefully today. I've been too busy fixing `ambit` to respond to PR feedback here at my usual pace.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2485#issuecomment-1075186676
https://github.com/psi4/psi4/pull/2485#issuecomment-1075186676:435,Integrability,message,messages,435,"> The conversion to traceless form can be done for any order of multipole, but I'm not really sure it's got a use case at this point. Quadrupoles in traceless form can be useful for force field definitions. Our CFMM code uses very high orders of multipoles, but they're converted to spherical harmonics to work with all the efficient machinery we've developed so that doesn't need the traceless definition. Max and I have traded Slack messages, and we're agreed on adding traceless quadrupoles so those still exist, but not to bother with the other multipoles for the time being. I'll add that to the PR hopefully today. I've been too busy fixing `ambit` to respond to PR feedback here at my usual pace.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2485#issuecomment-1075186676
https://github.com/psi4/psi4/pull/2485#issuecomment-1075186676:672,Usability,feedback,feedback,672,"> The conversion to traceless form can be done for any order of multipole, but I'm not really sure it's got a use case at this point. Quadrupoles in traceless form can be useful for force field definitions. Our CFMM code uses very high orders of multipoles, but they're converted to spherical harmonics to work with all the efficient machinery we've developed so that doesn't need the traceless definition. Max and I have traded Slack messages, and we're agreed on adding traceless quadrupoles so those still exist, but not to bother with the other multipoles for the time being. I'll add that to the PR hopefully today. I've been too busy fixing `ambit` to respond to PR feedback here at my usual pace.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2485#issuecomment-1075186676
https://github.com/psi4/psi4/pull/2485#issuecomment-1075271664:147,Integrability,message,message,147,"> format changes and traceless quad are in the next PR? in that case, lgtm. They will be included in this PR, when I get back to it. Disregard the message about ""the next PR"" that still lingers on the Slack GH feed. I meant to post that to the `ambit` repo, which is getting most of my development time at the moment.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2485#issuecomment-1075271664
https://github.com/psi4/psi4/pull/2488#issuecomment-1073393998:119,Availability,error,error,119,"Update your PR description. Behavior changes are not ""minor cleanup"", even if that behavior is as simple as raising an error where there wasn't one before.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2488#issuecomment-1073393998
https://github.com/psi4/psi4/pull/2488#issuecomment-1073393998:0,Deployability,Update,Update,0,"Update your PR description. Behavior changes are not ""minor cleanup"", even if that behavior is as simple as raising an error where there wasn't one before.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2488#issuecomment-1073393998
https://github.com/psi4/psi4/pull/2488#issuecomment-1073393998:98,Usability,simpl,simple,98,"Update your PR description. Behavior changes are not ""minor cleanup"", even if that behavior is as simple as raising an error where there wasn't one before.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2488#issuecomment-1073393998
https://github.com/psi4/psi4/pull/2488#issuecomment-1073970696:365,Safety,sanity check,sanity checks,365,"Between plain calcs, user-specified-occ-calcs, successive calcs, calcs involving pre-SCF-cycles, wavefunction reloading, restarts, etc., getting the SCF initialization info from places in the right priority is fraught and, I fear, not defensively tested. So it'd be useful to understand the circumstances and reasoning behind the proposed changes. I'm all for more sanity checks.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2488#issuecomment-1073970696
https://github.com/psi4/psi4/pull/2488#issuecomment-1073970696:247,Testability,test,tested,247,"Between plain calcs, user-specified-occ-calcs, successive calcs, calcs involving pre-SCF-cycles, wavefunction reloading, restarts, etc., getting the SCF initialization info from places in the right priority is fraught and, I fear, not defensively tested. So it'd be useful to understand the circumstances and reasoning behind the proposed changes. I'm all for more sanity checks.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2488#issuecomment-1073970696
https://github.com/psi4/psi4/pull/2488#issuecomment-1074139322:121,Availability,error,error,121,"> Update your PR description. Behavior changes are not ""minor cleanup"", even if that behavior is as simple as raising an error where there wasn't one before. Done",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2488#issuecomment-1074139322
https://github.com/psi4/psi4/pull/2488#issuecomment-1074139322:2,Deployability,Update,Update,2,"> Update your PR description. Behavior changes are not ""minor cleanup"", even if that behavior is as simple as raising an error where there wasn't one before. Done",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2488#issuecomment-1074139322
https://github.com/psi4/psi4/pull/2488#issuecomment-1074139322:100,Usability,simpl,simple,100,"> Update your PR description. Behavior changes are not ""minor cleanup"", even if that behavior is as simple as raising an error where there wasn't one before. Done",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2488#issuecomment-1074139322
https://github.com/psi4/psi4/issues/2491#issuecomment-1075511627:114,Performance,cache,cache,114,"I have no idea if this is the cause here, but there is a somewhat obscure effect called ""false sharing"" where CPU cache interference between threads can wreck parallel scaling.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2491#issuecomment-1075511627
https://github.com/psi4/psi4/issues/2491#issuecomment-1075521918:56,Testability,test,tested,56,Interesting find hokru and something that can be easily tested!,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2491#issuecomment-1075521918
https://github.com/psi4/psi4/issues/2491#issuecomment-1075534869:220,Performance,cache,cached,220,"@TiborGY That's a good idea! False sharing is a reasonable thing to think about. From what I've just now read, it sounds like false sharing occurs when two threads repeatedly write to nearby array elements, invalidating cached values of those elements. In this minimal test case, the threads aren't writing to any shared data, so I don't think false sharing applies here. However, it's something I'll look out for in the actual semi-numerical exchange implementation. @jturney I haven't gotten desperate enough to learn VTune yet, but I'm getting close. @hokru Thank you! The changelog entry would perfectly explain this strange behavior. I'll wait for #2413 before doing any more investigation.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2491#issuecomment-1075534869
https://github.com/psi4/psi4/issues/2491#issuecomment-1075534869:269,Testability,test,test,269,"@TiborGY That's a good idea! False sharing is a reasonable thing to think about. From what I've just now read, it sounds like false sharing occurs when two threads repeatedly write to nearby array elements, invalidating cached values of those elements. In this minimal test case, the threads aren't writing to any shared data, so I don't think false sharing applies here. However, it's something I'll look out for in the actual semi-numerical exchange implementation. @jturney I haven't gotten desperate enough to learn VTune yet, but I'm getting close. @hokru Thank you! The changelog entry would perfectly explain this strange behavior. I'll wait for #2413 before doing any more investigation.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2491#issuecomment-1075534869
https://github.com/psi4/psi4/issues/2491#issuecomment-1075534869:514,Usability,learn,learn,514,"@TiborGY That's a good idea! False sharing is a reasonable thing to think about. From what I've just now read, it sounds like false sharing occurs when two threads repeatedly write to nearby array elements, invalidating cached values of those elements. In this minimal test case, the threads aren't writing to any shared data, so I don't think false sharing applies here. However, it's something I'll look out for in the actual semi-numerical exchange implementation. @jturney I haven't gotten desperate enough to learn VTune yet, but I'm getting close. @hokru Thank you! The changelog entry would perfectly explain this strange behavior. I'll wait for #2413 before doing any more investigation.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2491#issuecomment-1075534869
https://github.com/psi4/psi4/issues/2491#issuecomment-1077047578:0,Deployability,Update,Update,0,"Update: This performance issue was fixed by #2413, which upgraded libint2 from 2.6.0 to 2.7.1. For completeness, here are the timings on the above test case:. | Cores | Psi4 OS<br/>Wall Time (s) | Psi4 OS<br/>Parallel Speedup | Libint 2.6.0<br/>Wall Time (s) | Libint 2.6.0<br/>Parallel Speedup | Libint 2.7.1<br/>Wall Time (s) | Libint 2.7.1<br/>Parallel Speedup |; | :--- | :--- | :--- | :--- | :--- | :--- | :--- |; | 1 | 191.7 | --- | 105.3 | --- | 99.4 | --- |; | 2 | 96.1 | x2.00 | 72.6 | x1.45 | 49.9 | x1.99 |; | 4 | 48.4 | x3.96 | 71.5 | x1.47 | 25.2 | x3.94 |; | 8 | 24.3 | x7.88 | 74.5 | x1.41 | 13.0 | x7.66 |; | 18 | 11.5 | x16.62 | 72.8 | x1.45 | 6.4 | x15.45 |",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2491#issuecomment-1077047578
https://github.com/psi4/psi4/issues/2491#issuecomment-1077047578:57,Deployability,upgrade,upgraded,57,"Update: This performance issue was fixed by #2413, which upgraded libint2 from 2.6.0 to 2.7.1. For completeness, here are the timings on the above test case:. | Cores | Psi4 OS<br/>Wall Time (s) | Psi4 OS<br/>Parallel Speedup | Libint 2.6.0<br/>Wall Time (s) | Libint 2.6.0<br/>Parallel Speedup | Libint 2.7.1<br/>Wall Time (s) | Libint 2.7.1<br/>Parallel Speedup |; | :--- | :--- | :--- | :--- | :--- | :--- | :--- |; | 1 | 191.7 | --- | 105.3 | --- | 99.4 | --- |; | 2 | 96.1 | x2.00 | 72.6 | x1.45 | 49.9 | x1.99 |; | 4 | 48.4 | x3.96 | 71.5 | x1.47 | 25.2 | x3.94 |; | 8 | 24.3 | x7.88 | 74.5 | x1.41 | 13.0 | x7.66 |; | 18 | 11.5 | x16.62 | 72.8 | x1.45 | 6.4 | x15.45 |",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2491#issuecomment-1077047578
https://github.com/psi4/psi4/issues/2491#issuecomment-1077047578:13,Performance,perform,performance,13,"Update: This performance issue was fixed by #2413, which upgraded libint2 from 2.6.0 to 2.7.1. For completeness, here are the timings on the above test case:. | Cores | Psi4 OS<br/>Wall Time (s) | Psi4 OS<br/>Parallel Speedup | Libint 2.6.0<br/>Wall Time (s) | Libint 2.6.0<br/>Parallel Speedup | Libint 2.7.1<br/>Wall Time (s) | Libint 2.7.1<br/>Parallel Speedup |; | :--- | :--- | :--- | :--- | :--- | :--- | :--- |; | 1 | 191.7 | --- | 105.3 | --- | 99.4 | --- |; | 2 | 96.1 | x2.00 | 72.6 | x1.45 | 49.9 | x1.99 |; | 4 | 48.4 | x3.96 | 71.5 | x1.47 | 25.2 | x3.94 |; | 8 | 24.3 | x7.88 | 74.5 | x1.41 | 13.0 | x7.66 |; | 18 | 11.5 | x16.62 | 72.8 | x1.45 | 6.4 | x15.45 |",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2491#issuecomment-1077047578
https://github.com/psi4/psi4/issues/2491#issuecomment-1077047578:147,Testability,test,test,147,"Update: This performance issue was fixed by #2413, which upgraded libint2 from 2.6.0 to 2.7.1. For completeness, here are the timings on the above test case:. | Cores | Psi4 OS<br/>Wall Time (s) | Psi4 OS<br/>Parallel Speedup | Libint 2.6.0<br/>Wall Time (s) | Libint 2.6.0<br/>Parallel Speedup | Libint 2.7.1<br/>Wall Time (s) | Libint 2.7.1<br/>Parallel Speedup |; | :--- | :--- | :--- | :--- | :--- | :--- | :--- |; | 1 | 191.7 | --- | 105.3 | --- | 99.4 | --- |; | 2 | 96.1 | x2.00 | 72.6 | x1.45 | 49.9 | x1.99 |; | 4 | 48.4 | x3.96 | 71.5 | x1.47 | 25.2 | x3.94 |; | 8 | 24.3 | x7.88 | 74.5 | x1.41 | 13.0 | x7.66 |; | 18 | 11.5 | x16.62 | 72.8 | x1.45 | 6.4 | x15.45 |",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2491#issuecomment-1077047578
https://github.com/psi4/psi4/pull/2496#issuecomment-1077741209:377,Availability,ping,ping,377,> Why do we have DipoleInt as a class unrelated to MultipoleInt?. I don't know. There's also `QuadrupoleInt` and `TracelessQuadrupoleInt` which both use L2. Some more senior developer would have to comment on whether a) we should keep all of the multipole classes as-is or b) hard-wire some to the general `MultipoleInt` or c) remove the specialized integral classes entirely. ping @loriab @andysim @jturney,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2496#issuecomment-1077741209
https://github.com/psi4/psi4/pull/2496#issuecomment-1077778935:189,Integrability,wrap,wrappers,189,"> This is fantastic Max! I really like the generalized `MultipoleInt` class. I'm good with options (b) and (c). I think that `DipoleInt` and `QuadrupoleInt` classes which function as light wrappers around `MultipoleInt` are more user-friendly than requiring users to pluck the appropriate integrals out of the `MultipoleInt` return.; > ; > Have you done any performance comparisons between the new MD code and the old OS code? I don't know if one is expected to be faster than the other. It would be good to do some simple timings (maybe one low angmom system and one high angmom system?) before completely ditching the OS code. @maxscheurer If you want, I can test CFMM with your new code to see if the multipole calculations are indeed faster. Just let me know.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2496#issuecomment-1077778935
https://github.com/psi4/psi4/pull/2496#issuecomment-1077778935:358,Performance,perform,performance,358,"> This is fantastic Max! I really like the generalized `MultipoleInt` class. I'm good with options (b) and (c). I think that `DipoleInt` and `QuadrupoleInt` classes which function as light wrappers around `MultipoleInt` are more user-friendly than requiring users to pluck the appropriate integrals out of the `MultipoleInt` return.; > ; > Have you done any performance comparisons between the new MD code and the old OS code? I don't know if one is expected to be faster than the other. It would be good to do some simple timings (maybe one low angmom system and one high angmom system?) before completely ditching the OS code. @maxscheurer If you want, I can test CFMM with your new code to see if the multipole calculations are indeed faster. Just let me know.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2496#issuecomment-1077778935
https://github.com/psi4/psi4/pull/2496#issuecomment-1077778935:661,Testability,test,test,661,"> This is fantastic Max! I really like the generalized `MultipoleInt` class. I'm good with options (b) and (c). I think that `DipoleInt` and `QuadrupoleInt` classes which function as light wrappers around `MultipoleInt` are more user-friendly than requiring users to pluck the appropriate integrals out of the `MultipoleInt` return.; > ; > Have you done any performance comparisons between the new MD code and the old OS code? I don't know if one is expected to be faster than the other. It would be good to do some simple timings (maybe one low angmom system and one high angmom system?) before completely ditching the OS code. @maxscheurer If you want, I can test CFMM with your new code to see if the multipole calculations are indeed faster. Just let me know.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2496#issuecomment-1077778935
https://github.com/psi4/psi4/pull/2496#issuecomment-1077778935:229,Usability,user-friendly,user-friendly,229,"> This is fantastic Max! I really like the generalized `MultipoleInt` class. I'm good with options (b) and (c). I think that `DipoleInt` and `QuadrupoleInt` classes which function as light wrappers around `MultipoleInt` are more user-friendly than requiring users to pluck the appropriate integrals out of the `MultipoleInt` return.; > ; > Have you done any performance comparisons between the new MD code and the old OS code? I don't know if one is expected to be faster than the other. It would be good to do some simple timings (maybe one low angmom system and one high angmom system?) before completely ditching the OS code. @maxscheurer If you want, I can test CFMM with your new code to see if the multipole calculations are indeed faster. Just let me know.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2496#issuecomment-1077778935
https://github.com/psi4/psi4/pull/2496#issuecomment-1077778935:516,Usability,simpl,simple,516,"> This is fantastic Max! I really like the generalized `MultipoleInt` class. I'm good with options (b) and (c). I think that `DipoleInt` and `QuadrupoleInt` classes which function as light wrappers around `MultipoleInt` are more user-friendly than requiring users to pluck the appropriate integrals out of the `MultipoleInt` return.; > ; > Have you done any performance comparisons between the new MD code and the old OS code? I don't know if one is expected to be faster than the other. It would be good to do some simple timings (maybe one low angmom system and one high angmom system?) before completely ditching the OS code. @maxscheurer If you want, I can test CFMM with your new code to see if the multipole calculations are indeed faster. Just let me know.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2496#issuecomment-1077778935
https://github.com/psi4/psi4/pull/2496#issuecomment-1077805490:21,Testability,test,test,21,"> If you want, I can test CFMM with your new code to see if the multipole calculations are indeed faster. Just let me know. It's okay, I already have a script to benchmark the old code vs. the new one -- will report some of the benchmarks soon ",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2496#issuecomment-1077805490
https://github.com/psi4/psi4/pull/2496#issuecomment-1077805490:162,Testability,benchmark,benchmark,162,"> If you want, I can test CFMM with your new code to see if the multipole calculations are indeed faster. Just let me know. It's okay, I already have a script to benchmark the old code vs. the new one -- will report some of the benchmarks soon ",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2496#issuecomment-1077805490
https://github.com/psi4/psi4/pull/2496#issuecomment-1077805490:228,Testability,benchmark,benchmarks,228,"> If you want, I can test CFMM with your new code to see if the multipole calculations are indeed faster. Just let me know. It's okay, I already have a script to benchmark the old code vs. the new one -- will report some of the benchmarks soon ",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2496#issuecomment-1077805490
https://github.com/psi4/psi4/pull/2496#issuecomment-1077806309:568,Availability,mainten,maintenance,568,"Regarding the general case `MultipoleInt` vs. special routines like `DipoleInt`. Keep in mind that asking for `MultipoleInt`s with order=2 will give overlap, dipole, quadrupole. Asking for `QuadrupoleInt`s will only give quadrupoles. Computing the extra integrals isn't really a big deal in terms of efficiency, but it might be a little surprising for the user to find that the indexing doesn't start from zero. The current quadrupole integral implementation just calls Libint2 and picks out only the quadrupole components. Going with only MultipoleInts is better for maintenance, but changes the API and could lead to some surprises. However, there isn't really any efficiency penalty for doing that, so I don't really have a strong opinion either way.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2496#issuecomment-1077806309
https://github.com/psi4/psi4/pull/2496#issuecomment-1077806309:54,Integrability,rout,routines,54,"Regarding the general case `MultipoleInt` vs. special routines like `DipoleInt`. Keep in mind that asking for `MultipoleInt`s with order=2 will give overlap, dipole, quadrupole. Asking for `QuadrupoleInt`s will only give quadrupoles. Computing the extra integrals isn't really a big deal in terms of efficiency, but it might be a little surprising for the user to find that the indexing doesn't start from zero. The current quadrupole integral implementation just calls Libint2 and picks out only the quadrupole components. Going with only MultipoleInts is better for maintenance, but changes the API and could lead to some surprises. However, there isn't really any efficiency penalty for doing that, so I don't really have a strong opinion either way.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2496#issuecomment-1077806309
https://github.com/psi4/psi4/pull/2496#issuecomment-1077840949:105,Testability,test,tests,105,"I'll approve this when Zach's comments are addressed. Otherwise, this looks great!. Thanks a lot for the tests.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2496#issuecomment-1077840949
https://github.com/psi4/psi4/pull/2496#issuecomment-1078476272:248,Performance,perform,performance,248,"## Small benchmark. The following timings were obtained for H2O from 3 ""takes"", where in each take, the; integral is repeatedly evaluated 15x. The result shown here is that of the fastest take, divided by the number of repeats (i.e., 15 here). The performance of M-D is actually quite nice -- of course one could tweak it a little bit here and there, but that's not needed right now IMHO. The code snippet from my benchmark script looks sth like:; ```Python; takes = 3; repeat = 15; for b in bas:; for m in [1, 4, 8, 16, 24, 36]:; basis = psi4.core.BasisSet.build(mol, 'orbital', b); mints = psi4.core.MintsHelper(basis); key = f""{b}/m = {m}""; keys.append(key); print(key); for _ in tqdm(range(takes)):; with timer.record(key):; for i in range(repeat):; M = mints.ao_multipoles(order=m, origin=[1.0, 2.0, 3.0]); for k in keys:; best = timer.best(k) / repeat; print(f""{k:<15} | {best * 1000:8.2f} ms""); ```. ### Results. | basis set | order | M-D | OS |; |-----------|-------|------------|------------|; | cc-pvdz | 1 | 0.11 ms | 0.20 ms |; | | 4 | 0.46 ms | 0.73 ms |; | | 8 | 1.87 ms | 2.19 ms |; | | 16 | 11.25 ms | 10.88 ms |; | | 24 | 47.11 ms | 43.30 ms |; | | 36 | 193.20 ms | 177.40 ms |; | cc-pvtz | 1 | 0.27 ms | 0.52 ms |; | | 4 | 1.34 ms | 2.19 ms |; | | 8 | 5.97 ms | 7.36 ms |; | | 16 | 46.39 ms | 47.05 ms |; | | 24 | 172.76 ms | 170.22 ms |; | | 36 | 742.18 ms | 725.64 ms |; | cc-pvqz | 1 | 0.81 ms | 1.53 ms |; | | 4 | 4.16 ms | 7.12 ms |; | | 8 | 20.47 ms | 26.56 ms |; | | 16 | 153.60 ms | 168.69 ms |; | | 24 | 543.86 ms | 579.47 ms |; | | 36 | 2327.06 ms | 2436.51 ms |; | cc-pv5z | 1 | 2.09 ms | 4.37 ms |; | | 4 | 12.59 ms | 22.29 ms |; | | 8 | 63.34 ms | 84.20 ms |; | | 16 | 457.24 ms | 522.29 ms |; | | 24 | 1634.66 ms | 1807.03 ms |; | | 36 | 6654.10 ms | 7198.05 ms |",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2496#issuecomment-1078476272
https://github.com/psi4/psi4/pull/2496#issuecomment-1078476272:9,Testability,benchmark,benchmark,9,"## Small benchmark. The following timings were obtained for H2O from 3 ""takes"", where in each take, the; integral is repeatedly evaluated 15x. The result shown here is that of the fastest take, divided by the number of repeats (i.e., 15 here). The performance of M-D is actually quite nice -- of course one could tweak it a little bit here and there, but that's not needed right now IMHO. The code snippet from my benchmark script looks sth like:; ```Python; takes = 3; repeat = 15; for b in bas:; for m in [1, 4, 8, 16, 24, 36]:; basis = psi4.core.BasisSet.build(mol, 'orbital', b); mints = psi4.core.MintsHelper(basis); key = f""{b}/m = {m}""; keys.append(key); print(key); for _ in tqdm(range(takes)):; with timer.record(key):; for i in range(repeat):; M = mints.ao_multipoles(order=m, origin=[1.0, 2.0, 3.0]); for k in keys:; best = timer.best(k) / repeat; print(f""{k:<15} | {best * 1000:8.2f} ms""); ```. ### Results. | basis set | order | M-D | OS |; |-----------|-------|------------|------------|; | cc-pvdz | 1 | 0.11 ms | 0.20 ms |; | | 4 | 0.46 ms | 0.73 ms |; | | 8 | 1.87 ms | 2.19 ms |; | | 16 | 11.25 ms | 10.88 ms |; | | 24 | 47.11 ms | 43.30 ms |; | | 36 | 193.20 ms | 177.40 ms |; | cc-pvtz | 1 | 0.27 ms | 0.52 ms |; | | 4 | 1.34 ms | 2.19 ms |; | | 8 | 5.97 ms | 7.36 ms |; | | 16 | 46.39 ms | 47.05 ms |; | | 24 | 172.76 ms | 170.22 ms |; | | 36 | 742.18 ms | 725.64 ms |; | cc-pvqz | 1 | 0.81 ms | 1.53 ms |; | | 4 | 4.16 ms | 7.12 ms |; | | 8 | 20.47 ms | 26.56 ms |; | | 16 | 153.60 ms | 168.69 ms |; | | 24 | 543.86 ms | 579.47 ms |; | | 36 | 2327.06 ms | 2436.51 ms |; | cc-pv5z | 1 | 2.09 ms | 4.37 ms |; | | 4 | 12.59 ms | 22.29 ms |; | | 8 | 63.34 ms | 84.20 ms |; | | 16 | 457.24 ms | 522.29 ms |; | | 24 | 1634.66 ms | 1807.03 ms |; | | 36 | 6654.10 ms | 7198.05 ms |",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2496#issuecomment-1078476272
https://github.com/psi4/psi4/pull/2496#issuecomment-1078476272:414,Testability,benchmark,benchmark,414,"## Small benchmark. The following timings were obtained for H2O from 3 ""takes"", where in each take, the; integral is repeatedly evaluated 15x. The result shown here is that of the fastest take, divided by the number of repeats (i.e., 15 here). The performance of M-D is actually quite nice -- of course one could tweak it a little bit here and there, but that's not needed right now IMHO. The code snippet from my benchmark script looks sth like:; ```Python; takes = 3; repeat = 15; for b in bas:; for m in [1, 4, 8, 16, 24, 36]:; basis = psi4.core.BasisSet.build(mol, 'orbital', b); mints = psi4.core.MintsHelper(basis); key = f""{b}/m = {m}""; keys.append(key); print(key); for _ in tqdm(range(takes)):; with timer.record(key):; for i in range(repeat):; M = mints.ao_multipoles(order=m, origin=[1.0, 2.0, 3.0]); for k in keys:; best = timer.best(k) / repeat; print(f""{k:<15} | {best * 1000:8.2f} ms""); ```. ### Results. | basis set | order | M-D | OS |; |-----------|-------|------------|------------|; | cc-pvdz | 1 | 0.11 ms | 0.20 ms |; | | 4 | 0.46 ms | 0.73 ms |; | | 8 | 1.87 ms | 2.19 ms |; | | 16 | 11.25 ms | 10.88 ms |; | | 24 | 47.11 ms | 43.30 ms |; | | 36 | 193.20 ms | 177.40 ms |; | cc-pvtz | 1 | 0.27 ms | 0.52 ms |; | | 4 | 1.34 ms | 2.19 ms |; | | 8 | 5.97 ms | 7.36 ms |; | | 16 | 46.39 ms | 47.05 ms |; | | 24 | 172.76 ms | 170.22 ms |; | | 36 | 742.18 ms | 725.64 ms |; | cc-pvqz | 1 | 0.81 ms | 1.53 ms |; | | 4 | 4.16 ms | 7.12 ms |; | | 8 | 20.47 ms | 26.56 ms |; | | 16 | 153.60 ms | 168.69 ms |; | | 24 | 543.86 ms | 579.47 ms |; | | 36 | 2327.06 ms | 2436.51 ms |; | cc-pv5z | 1 | 2.09 ms | 4.37 ms |; | | 4 | 12.59 ms | 22.29 ms |; | | 8 | 63.34 ms | 84.20 ms |; | | 16 | 457.24 ms | 522.29 ms |; | | 24 | 1634.66 ms | 1807.03 ms |; | | 36 | 6654.10 ms | 7198.05 ms |",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2496#issuecomment-1078476272
https://github.com/psi4/psi4/issues/2497#issuecomment-1077501281:34,Availability,down,download,34,"oh no, not again. Yes, one had to download patched files for the previous version from their homepage.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2497#issuecomment-1077501281
https://github.com/psi4/psi4/issues/2497#issuecomment-1077501281:43,Deployability,patch,patched,43,"oh no, not again. Yes, one had to download patched files for the previous version from their homepage.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2497#issuecomment-1077501281
https://github.com/psi4/psi4/issues/2497#issuecomment-1077506388:21,Integrability,interface,interface,21,"My hunch is that the interface is not ""actually buggy"", but that it was silently changed MRCC-side.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2497#issuecomment-1077506388
https://github.com/psi4/psi4/issues/2497#issuecomment-1077599645:36,Availability,down,download,36,"> oh no, not again. Yes, one had to download patched files for the previous version from their homepage. See [the issue about the 2020 release](https://github.com/psi4/psi4/issues/1866) for additional information on ""the previous version"" and Psi.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2497#issuecomment-1077599645
https://github.com/psi4/psi4/issues/2497#issuecomment-1077599645:45,Deployability,patch,patched,45,"> oh no, not again. Yes, one had to download patched files for the previous version from their homepage. See [the issue about the 2020 release](https://github.com/psi4/psi4/issues/1866) for additional information on ""the previous version"" and Psi.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2497#issuecomment-1077599645
https://github.com/psi4/psi4/issues/2497#issuecomment-1077599645:135,Deployability,release,release,135,"> oh no, not again. Yes, one had to download patched files for the previous version from their homepage. See [the issue about the 2020 release](https://github.com/psi4/psi4/issues/1866) for additional information on ""the previous version"" and Psi.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2497#issuecomment-1077599645
https://github.com/psi4/psi4/issues/2497#issuecomment-1092754283:240,Integrability,interface,interface,240,"The issue has been reported to the MRCC forum. It is broken even with Molpro 2022.; Perhaps it would be more maintainable to teach QCEngine how to run standalone MRCC calculations, rather than trying to pass SCF wavefunctions via a fragile interface that keeps being broken?. PS: [MRCC forum topic](https://www.mrcc.hu/index.php/forum/running-mrcc/287-molpro-w-mrcc-keywd-errror)",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2497#issuecomment-1092754283
https://github.com/psi4/psi4/issues/2497#issuecomment-1092754283:109,Modifiability,maintainab,maintainable,109,"The issue has been reported to the MRCC forum. It is broken even with Molpro 2022.; Perhaps it would be more maintainable to teach QCEngine how to run standalone MRCC calculations, rather than trying to pass SCF wavefunctions via a fragile interface that keeps being broken?. PS: [MRCC forum topic](https://www.mrcc.hu/index.php/forum/running-mrcc/287-molpro-w-mrcc-keywd-errror)",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2497#issuecomment-1092754283
https://github.com/psi4/psi4/issues/2497#issuecomment-1092765492:46,Integrability,interface,interface,46,QCEngine support would be great for a general interface and access to all the LNO and F12 goodies!. The PSI4 (and I suspect also ORCA and Molpro) interface is a bit different in the sense that those programs compute the integrals and hand them over to MRCC for arbitrary order CC(n) type of calculations. Dates back to when MRCC was essentially only doing that. . Not sure how much use the (broken) 'classic' interface has.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2497#issuecomment-1092765492
https://github.com/psi4/psi4/issues/2497#issuecomment-1092765492:146,Integrability,interface,interface,146,QCEngine support would be great for a general interface and access to all the LNO and F12 goodies!. The PSI4 (and I suspect also ORCA and Molpro) interface is a bit different in the sense that those programs compute the integrals and hand them over to MRCC for arbitrary order CC(n) type of calculations. Dates back to when MRCC was essentially only doing that. . Not sure how much use the (broken) 'classic' interface has.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2497#issuecomment-1092765492
https://github.com/psi4/psi4/issues/2497#issuecomment-1092765492:409,Integrability,interface,interface,409,QCEngine support would be great for a general interface and access to all the LNO and F12 goodies!. The PSI4 (and I suspect also ORCA and Molpro) interface is a bit different in the sense that those programs compute the integrals and hand them over to MRCC for arbitrary order CC(n) type of calculations. Dates back to when MRCC was essentially only doing that. . Not sure how much use the (broken) 'classic' interface has.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2497#issuecomment-1092765492
https://github.com/psi4/psi4/issues/2497#issuecomment-1092765492:60,Security,access,access,60,QCEngine support would be great for a general interface and access to all the LNO and F12 goodies!. The PSI4 (and I suspect also ORCA and Molpro) interface is a bit different in the sense that those programs compute the integrals and hand them over to MRCC for arbitrary order CC(n) type of calculations. Dates back to when MRCC was essentially only doing that. . Not sure how much use the (broken) 'classic' interface has.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2497#issuecomment-1092765492
https://github.com/psi4/psi4/issues/2497#issuecomment-1176411227:32,Deployability,patch,patch,32,Confirmed fixed with the latest patch files for MRCC.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2497#issuecomment-1176411227
https://github.com/psi4/psi4/pull/2502#issuecomment-1079254859:43,Testability,test,tests,43,An HFS student is going to be running some tests that L1 and L2 agree here. Let's hold off on merging until those tests come back clean.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2502#issuecomment-1079254859
https://github.com/psi4/psi4/pull/2502#issuecomment-1079254859:114,Testability,test,tests,114,An HFS student is going to be running some tests that L1 and L2 agree here. Let's hold off on merging until those tests come back clean.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2502#issuecomment-1079254859
https://github.com/psi4/psi4/pull/2502#issuecomment-1090638982:15,Testability,test,tests,15,thanks for the tests!,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2502#issuecomment-1090638982
https://github.com/psi4/psi4/pull/2502#issuecomment-1091841264:32,Availability,down,down,32,I was able to get the json file down to 5MB. . It's a little challenging to get it smaller since I wanted a comprehensive test (up through d-orbitals) for four different two-electron integral tensors.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2502#issuecomment-1091841264
https://github.com/psi4/psi4/pull/2502#issuecomment-1091841264:122,Testability,test,test,122,I was able to get the json file down to 5MB. . It's a little challenging to get it smaller since I wanted a comprehensive test (up through d-orbitals) for four different two-electron integral tensors.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2502#issuecomment-1091841264
https://github.com/psi4/psi4/pull/2503#issuecomment-1079287117:28,Testability,test,tests,28,there's more erd traces in `tests/erd/` and https://github.com/psi4/psi4/blob/cf0a0d80f5f35e9a2136253d6e476cf5a74b6145/tests/pytests/test_addons.py#L733-L738,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2503#issuecomment-1079287117
https://github.com/psi4/psi4/pull/2503#issuecomment-1079287117:119,Testability,test,tests,119,there's more erd traces in `tests/erd/` and https://github.com/psi4/psi4/blob/cf0a0d80f5f35e9a2136253d6e476cf5a74b6145/tests/pytests/test_addons.py#L733-L738,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2503#issuecomment-1079287117
https://github.com/psi4/psi4/pull/2504#issuecomment-1081633908:24,Performance,perform,performance,24,"## Small benchmark; The performance issues are resolved. :tada: As in #2496, only for small basis set angular momentum, the old code is faster than M-D, but for larger basis set/angmom, M-D outperforms the OS code. Performed as in #2496. Here, the molecule is para-nitroaniline (typical example for EFP/PE :smile:). ### Results; | basis | order | M-D [ms] | OS [ms] | ratio M-D/OS |; |----------------------|-------|----------|---------|-------------|; | cc-pvdz (nbf = 170) | 0 | 5.75 | 5.45 | 1.05 |; | | 1 | 9.55 | 7.72 | 1.24 |; | | 2 | 17.69 | 12.06 | 1.47 |; | | 3 | 30.41 | 19.61 | 1.55 |; | cc-pvtz (nbf = 384) | 0 | 14.2 | 14.02 | 1.01 |; | | 1 | 27.75 | 25.62 | 1.08 |; | | 2 | 55.37 | 50.41 | 1.1 |; | | 3 | 99.74 | 89.52 | 1.1 |; | cc-pvqz (nbf = 730) | 0 | 43.66 | 45.69 | 0.96 |; | | 1 | 94.84 | 101.92 | 0.93 |; | | 2 | 197.61 | 222.04 | 0.89 |; | | 3 | 366.13 | 428.15 | 0.85 |; | cc-pv5z (nbf = 1240) | 0 | 132.84 | 160.85 | 0.83 |; | | 1 | 323.07 | 406.33 | 0.8 |; | | 2 | 694.14 | 942.28 | 0.74 |; | | 3 | 1291.59 | 2011.75 | 0.64 |",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2504#issuecomment-1081633908
https://github.com/psi4/psi4/pull/2504#issuecomment-1081633908:215,Performance,Perform,Performed,215,"## Small benchmark; The performance issues are resolved. :tada: As in #2496, only for small basis set angular momentum, the old code is faster than M-D, but for larger basis set/angmom, M-D outperforms the OS code. Performed as in #2496. Here, the molecule is para-nitroaniline (typical example for EFP/PE :smile:). ### Results; | basis | order | M-D [ms] | OS [ms] | ratio M-D/OS |; |----------------------|-------|----------|---------|-------------|; | cc-pvdz (nbf = 170) | 0 | 5.75 | 5.45 | 1.05 |; | | 1 | 9.55 | 7.72 | 1.24 |; | | 2 | 17.69 | 12.06 | 1.47 |; | | 3 | 30.41 | 19.61 | 1.55 |; | cc-pvtz (nbf = 384) | 0 | 14.2 | 14.02 | 1.01 |; | | 1 | 27.75 | 25.62 | 1.08 |; | | 2 | 55.37 | 50.41 | 1.1 |; | | 3 | 99.74 | 89.52 | 1.1 |; | cc-pvqz (nbf = 730) | 0 | 43.66 | 45.69 | 0.96 |; | | 1 | 94.84 | 101.92 | 0.93 |; | | 2 | 197.61 | 222.04 | 0.89 |; | | 3 | 366.13 | 428.15 | 0.85 |; | cc-pv5z (nbf = 1240) | 0 | 132.84 | 160.85 | 0.83 |; | | 1 | 323.07 | 406.33 | 0.8 |; | | 2 | 694.14 | 942.28 | 0.74 |; | | 3 | 1291.59 | 2011.75 | 0.64 |",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2504#issuecomment-1081633908
https://github.com/psi4/psi4/pull/2504#issuecomment-1081633908:9,Testability,benchmark,benchmark,9,"## Small benchmark; The performance issues are resolved. :tada: As in #2496, only for small basis set angular momentum, the old code is faster than M-D, but for larger basis set/angmom, M-D outperforms the OS code. Performed as in #2496. Here, the molecule is para-nitroaniline (typical example for EFP/PE :smile:). ### Results; | basis | order | M-D [ms] | OS [ms] | ratio M-D/OS |; |----------------------|-------|----------|---------|-------------|; | cc-pvdz (nbf = 170) | 0 | 5.75 | 5.45 | 1.05 |; | | 1 | 9.55 | 7.72 | 1.24 |; | | 2 | 17.69 | 12.06 | 1.47 |; | | 3 | 30.41 | 19.61 | 1.55 |; | cc-pvtz (nbf = 384) | 0 | 14.2 | 14.02 | 1.01 |; | | 1 | 27.75 | 25.62 | 1.08 |; | | 2 | 55.37 | 50.41 | 1.1 |; | | 3 | 99.74 | 89.52 | 1.1 |; | cc-pvqz (nbf = 730) | 0 | 43.66 | 45.69 | 0.96 |; | | 1 | 94.84 | 101.92 | 0.93 |; | | 2 | 197.61 | 222.04 | 0.89 |; | | 3 | 366.13 | 428.15 | 0.85 |; | cc-pv5z (nbf = 1240) | 0 | 132.84 | 160.85 | 0.83 |; | | 1 | 323.07 | 406.33 | 0.8 |; | | 2 | 694.14 | 942.28 | 0.74 |; | | 3 | 1291.59 | 2011.75 | 0.64 |",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2504#issuecomment-1081633908
https://github.com/psi4/psi4/pull/2505#issuecomment-1079771361:239,Testability,test,tests,239,"> This is a nice feature! Is there a good place (perhaps a docstring) to explicitly state that DIIS is now compatible with ambit tensors?. Added. Some changes were requested in the `ambit` PR, so I'll need to double-check that the `forte` tests still work before I can merge this in.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2505#issuecomment-1079771361
https://github.com/psi4/psi4/pull/2508#issuecomment-1079728084:103,Testability,test,test,103,"Yes, I think it would make much more sense to combine the components. At the time I wrote the original test, I'd only written a code to compare matrices, so I had to compare each sub-tensor individually. Obviously, that's no longer necessary.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2508#issuecomment-1079728084
https://github.com/psi4/psi4/pull/2508#issuecomment-1079731553:555,Availability,avail,available,555,"I second combining the components as TDC suggests if possible. Comparing them is no problem -- `compare_values(ndarray_xptd, ndarray_cptd, ...` can handle the 3x3x3. Storing them c-side isn't perfectly straightforward b/c Wavefunctions.arrays only takes Matrix. So I think it'd have to be akin to octupole, as you anticipated. c-side, the tensor stays stacked into a 3x9. Then in python-helpers.py, the Matrix gets intercepted and reshaped into 3x3x3, and same on reverse. The qcvars so treated are a little different from the others in that they're only available as ndarrays, not Matrix _or_ ndarray, but no one's complained in practice.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2508#issuecomment-1079731553
https://github.com/psi4/psi4/pull/2508#issuecomment-1080012512:8,Deployability,Update,Updated,8,"Thanks! Updated the quadrupole, and I'll refer back here if I see other tensors in needs of a.u. labels.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2508#issuecomment-1080012512
https://github.com/psi4/psi4/issues/2510#issuecomment-1080979081:264,Deployability,install,install,264,"Two of the versions of Psi4 dependencies on your machine are incompatible with each other. For us to have any idea _why_ they are incompatible, we need to know how you got these dependencies in the first place. Did you try to build Psi from source? Did you try to install Psi4 with conda?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2510#issuecomment-1080979081
https://github.com/psi4/psi4/issues/2510#issuecomment-1080979081:28,Integrability,depend,dependencies,28,"Two of the versions of Psi4 dependencies on your machine are incompatible with each other. For us to have any idea _why_ they are incompatible, we need to know how you got these dependencies in the first place. Did you try to build Psi from source? Did you try to install Psi4 with conda?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2510#issuecomment-1080979081
https://github.com/psi4/psi4/issues/2510#issuecomment-1080979081:178,Integrability,depend,dependencies,178,"Two of the versions of Psi4 dependencies on your machine are incompatible with each other. For us to have any idea _why_ they are incompatible, we need to know how you got these dependencies in the first place. Did you try to build Psi from source? Did you try to install Psi4 with conda?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2510#issuecomment-1080979081
https://github.com/psi4/psi4/issues/2510#issuecomment-1080993168:45,Performance,load,load,45,"Yes, please post your `conda list`. The yaml load isn't in psi4 itself, so I'm guessing that the dask compatible with py37 uses the plain load syntax but pyyaml 6 is in your env that uses the new syntax. py37-based packages may not be getting built anymore. I'd use py38 or py39 or add `pyyaml<6` to your env to force a solve with the plain load syntax.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2510#issuecomment-1080993168
https://github.com/psi4/psi4/issues/2510#issuecomment-1080993168:138,Performance,load,load,138,"Yes, please post your `conda list`. The yaml load isn't in psi4 itself, so I'm guessing that the dask compatible with py37 uses the plain load syntax but pyyaml 6 is in your env that uses the new syntax. py37-based packages may not be getting built anymore. I'd use py38 or py39 or add `pyyaml<6` to your env to force a solve with the plain load syntax.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2510#issuecomment-1080993168
https://github.com/psi4/psi4/issues/2510#issuecomment-1080993168:341,Performance,load,load,341,"Yes, please post your `conda list`. The yaml load isn't in psi4 itself, so I'm guessing that the dask compatible with py37 uses the plain load syntax but pyyaml 6 is in your env that uses the new syntax. py37-based packages may not be getting built anymore. I'd use py38 or py39 or add `pyyaml<6` to your env to force a solve with the plain load syntax.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2510#issuecomment-1080993168
https://github.com/psi4/psi4/issues/2510#issuecomment-1081031693:141,Availability,error,error,141,"I am actually performing these calculations on Google Colab. (It is for a future workshop.) You can access a Colab notebook exemplifying the error [here](https://colab.research.google.com/drive/1uTsmVcFJY5xArRbo4sQ0RGgPiT406xdM?usp=sharing). Additionally, here is the output from `conda list`. . ```; # packages in environment at /usr/local:; #; # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 1_gnu conda-forge; alsa-lib 1.2.3 h516909a_0 conda-forge; ambit 0.5.1 hbe8a562_1 psi4; argon2-cffi 21.3.0 pyhd8ed1ab_0 conda-forge; argon2-cffi-bindings 21.2.0 py37h5e8e339_1 conda-forge; attrs 21.4.0 pyhd3eb1b0_0 ; backcall 0.2.0 pyh9f0ad1d_0 conda-forge; backports 1.0 py_2 conda-forge; backports.functools_lru_cache 1.6.4 pyhd8ed1ab_0 conda-forge; beautifulsoup4 4.10.0 pyha770c72_0 conda-forge; blas 1.0 mkl ; bleach 4.1.0 pyhd8ed1ab_0 conda-forge; boost 1.74.0 py37h6dcda5c_3 conda-forge; boost-cpp 1.74.0 h312852a_4 conda-forge; bottleneck 1.3.4 py37hce1f21e_0 ; brotli 1.0.9 he6710b0_2 ; brotlipy 0.7.0 py37h5e8e339_1001 conda-forge; bzip2 1.0.8 h7f98852_4 conda-forge; c-ares 1.17.1 h7f98852_1 conda-forge; ca-certificates 2021.10.8 ha878542_0 conda-forge; cairo 1.16.0 hf32fb01_1 ; certifi 2021.10.8 py37h89c1867_1 conda-forge; cffi 1.15.0 py37h036bc23_0 conda-forge; chardet 4.0.0 py37h89c1867_1 conda-forge; chemps2 1.8.10 hbe8a562_0 psi4; conda 4.12.0 py37h89c1867_0 conda-forge; conda-package-handling 1.7.2 py37hb5d75c8_0 conda-forge; cryptography 3.4.5 py37h5d9358c_1 conda-forge; cudatoolkit 11.1.1 h6406543_8 conda-forge; cycler 0.11.0 pyhd3eb1b0_0 ; dbus 1.13.6 h5008d03_3 conda-forge; debtcollector 2.5.0 pyhd8ed1ab_0 conda-forge; debugpy 1.5.1 py37hcd2ae1e_0 conda-forge; decorator 5.1.1 pyhd3eb1b0_0 ; defusedxml 0.7.1 pyhd8ed1ab_0 conda-forge; dftd3 3.2.1 h84218bc_2 psi4; dkh 1.2 h173d85e_2 psi4; entrypoints 0.4 pyhd8ed1ab_0 conda-forge; expat 2.4.7 h27087fc_0 conda-forge; flit-core 3.7.1 pyhd8ed1ab_0 conda-forge; fontconfig 2.13.1 h6c099",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2510#issuecomment-1081031693
https://github.com/psi4/psi4/issues/2510#issuecomment-1081031693:2304,Energy Efficiency,green,greenlet,2304,23_0 conda-forge; chardet 4.0.0 py37h89c1867_1 conda-forge; chemps2 1.8.10 hbe8a562_0 psi4; conda 4.12.0 py37h89c1867_0 conda-forge; conda-package-handling 1.7.2 py37hb5d75c8_0 conda-forge; cryptography 3.4.5 py37h5d9358c_1 conda-forge; cudatoolkit 11.1.1 h6406543_8 conda-forge; cycler 0.11.0 pyhd3eb1b0_0 ; dbus 1.13.6 h5008d03_3 conda-forge; debtcollector 2.5.0 pyhd8ed1ab_0 conda-forge; debugpy 1.5.1 py37hcd2ae1e_0 conda-forge; decorator 5.1.1 pyhd3eb1b0_0 ; defusedxml 0.7.1 pyhd8ed1ab_0 conda-forge; dftd3 3.2.1 h84218bc_2 psi4; dkh 1.2 h173d85e_2 psi4; entrypoints 0.4 pyhd8ed1ab_0 conda-forge; expat 2.4.7 h27087fc_0 conda-forge; flit-core 3.7.1 pyhd8ed1ab_0 conda-forge; fontconfig 2.13.1 h6c09931_0 ; fonttools 4.25.0 pyhd3eb1b0_0 ; freetype 2.11.0 h70c0345_0 ; gau2grid 2.0.7 hd18ef5c_0 psi4; gcp 2.0.2 he991be0_2 psi4; gdma 2.2.6 h0e1e685_6 psi4; gettext 0.19.8.1 h73d1719_1008 conda-forge; giflib 5.2.1 h7b6447c_0 ; glib 2.70.2 h780b84a_4 conda-forge; glib-tools 2.70.2 h780b84a_4 conda-forge; greenlet 1.1.1 py37h295c915_0 ; gst-plugins-base 1.14.5 h0935bb2_2 conda-forge; gstreamer 1.18.5 h9f60fe5_3 conda-forge; hdf5 1.10.6 hb1b8bf9_0 ; icu 68.1 h58526e2_0 conda-forge; idna 2.10 pyh9f0ad1d_0 conda-forge; importlib-metadata 4.8.2 py37h06a4308_0 ; importlib_metadata 4.8.2 hd3eb1b0_0 ; importlib_resources 5.2.0 pyhd3eb1b0_1 ; iniconfig 1.1.1 pyhd3eb1b0_0 ; intel-openmp 2021.4.0 h06a4308_3561 ; ipykernel 6.10.0 py37h25bab4e_0 conda-forge; ipython 7.32.0 py37h89c1867_0 conda-forge; ipython_genutils 0.2.0 py_1 conda-forge; ipywidgets 7.7.0 pyhd8ed1ab_0 conda-forge; jbig 2.1 h7f98852_2003 conda-forge; jedi 0.18.1 py37h89c1867_0 conda-forge; jinja2 3.1.1 pyhd8ed1ab_0 conda-forge; jpeg 9d h7f8727e_0 ; jsonschema 4.4.0 pyhd8ed1ab_0 conda-forge; jupyter 1.0.0 py37h89c1867_7 conda-forge; jupyter_client 7.1.2 pyhd8ed1ab_0 conda-forge; jupyter_console 6.4.3 pyhd8ed1ab_0 conda-forge; jupyter_core 4.9.2 py37h89c1867_0 conda-forge; jupyterlab_pygments 0.1.2 pyh9f0ad1d_0 conda-forge; j,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2510#issuecomment-1081031693
https://github.com/psi4/psi4/issues/2510#issuecomment-1081031693:8795,Integrability,wrap,wrapt,8795,e; pyqtchart 5.12 py37he336c9b_8 conda-forge; pyqtwebengine 5.12.1 py37he336c9b_8 conda-forge; pyrsistent 0.18.1 py37h5e8e339_0 conda-forge; pysocks 1.7.1 py37h89c1867_3 conda-forge; pytest 6.2.5 py37h06a4308_2 ; python 3.7.12 hb7a2778_100_cpython conda-forge; python-dateutil 2.8.2 pyhd3eb1b0_0 ; python_abi 3.7 2_cp37m conda-forge; pytz 2021.3 pyhd3eb1b0_0 ; pyyaml 6.0 py37h7f8727e_1 ; pyzmq 22.3.0 py37h336d617_1 conda-forge; qcelemental 0.24.0 pyhd8ed1ab_0 psi4; qcengine 0.23.0 pyhd8ed1ab_0 psi4; qt 5.12.9 h9d6b050_2 conda-forge; qtconsole 5.2.2 pyhd8ed1ab_1 conda-forge; qtconsole-base 5.2.2 pyhd8ed1ab_1 conda-forge; qtpy 2.0.1 pyhd8ed1ab_0 conda-forge; rdkit 2020.09.5 py37he53b9e1_0 conda-forge; readline 8.1 h46c0cb4_0 conda-forge; reportlab 3.5.67 py37hfdd840d_1 ; reproc 14.2.1 h36c2ea0_0 conda-forge; reproc-cpp 14.2.1 h58526e2_0 conda-forge; requests 2.25.1 pyhd3deb0d_0 conda-forge; ruamel_yaml 0.15.80 py37h5e8e339_1004 conda-forge; send2trash 1.8.0 pyhd8ed1ab_0 conda-forge; setuptools 49.6.0 py37h89c1867_3 conda-forge; simint 0.7 h642920c_1 psi4; six 1.15.0 pyh9f0ad1d_0 conda-forge; soupsieve 2.3.1 pyhd8ed1ab_0 conda-forge; sqlalchemy 1.4.32 py37h7f8727e_0 ; sqlite 3.38.0 hc218d9a_0 ; terminado 0.13.3 py37h89c1867_0 conda-forge; testpath 0.6.0 pyhd8ed1ab_0 conda-forge; tk 8.6.12 h27826a3_0 conda-forge; toml 0.10.2 pyhd3eb1b0_0 ; tornado 6.1 py37h5e8e339_2 conda-forge; tqdm 4.59.0 pyhd8ed1ab_0 conda-forge; traitlets 5.1.1 pyhd8ed1ab_0 conda-forge; typing-extensions 4.1.1 hd3eb1b0_0 ; typing_extensions 4.1.1 pyh06a4308_0 ; urllib3 1.26.3 pyhd8ed1ab_0 conda-forge; wcwidth 0.2.5 pyh9f0ad1d_2 conda-forge; webencodings 0.5.1 py_1 conda-forge; wheel 0.36.2 pyhd3deb0d_0 conda-forge; widgetsnbextension 3.6.0 py37h89c1867_0 conda-forge; wrapt 1.13.3 py37h7f8727e_2 ; xz 5.2.5 h516909a_1 conda-forge; yaml 0.2.5 h516909a_0 conda-forge; zeromq 4.3.4 h9c3ff4c_1 conda-forge; zipp 3.7.0 pyhd3eb1b0_0 ; zlib 1.2.11 h166bdaf_1014 conda-forge; zstd 1.5.2 ha95c52a_0 conda-forge; ```,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2510#issuecomment-1081031693
https://github.com/psi4/psi4/issues/2510#issuecomment-1081031693:2340,Modifiability,plugin,plugins-base,2340,1867_1 conda-forge; chemps2 1.8.10 hbe8a562_0 psi4; conda 4.12.0 py37h89c1867_0 conda-forge; conda-package-handling 1.7.2 py37hb5d75c8_0 conda-forge; cryptography 3.4.5 py37h5d9358c_1 conda-forge; cudatoolkit 11.1.1 h6406543_8 conda-forge; cycler 0.11.0 pyhd3eb1b0_0 ; dbus 1.13.6 h5008d03_3 conda-forge; debtcollector 2.5.0 pyhd8ed1ab_0 conda-forge; debugpy 1.5.1 py37hcd2ae1e_0 conda-forge; decorator 5.1.1 pyhd3eb1b0_0 ; defusedxml 0.7.1 pyhd8ed1ab_0 conda-forge; dftd3 3.2.1 h84218bc_2 psi4; dkh 1.2 h173d85e_2 psi4; entrypoints 0.4 pyhd8ed1ab_0 conda-forge; expat 2.4.7 h27087fc_0 conda-forge; flit-core 3.7.1 pyhd8ed1ab_0 conda-forge; fontconfig 2.13.1 h6c09931_0 ; fonttools 4.25.0 pyhd3eb1b0_0 ; freetype 2.11.0 h70c0345_0 ; gau2grid 2.0.7 hd18ef5c_0 psi4; gcp 2.0.2 he991be0_2 psi4; gdma 2.2.6 h0e1e685_6 psi4; gettext 0.19.8.1 h73d1719_1008 conda-forge; giflib 5.2.1 h7b6447c_0 ; glib 2.70.2 h780b84a_4 conda-forge; glib-tools 2.70.2 h780b84a_4 conda-forge; greenlet 1.1.1 py37h295c915_0 ; gst-plugins-base 1.14.5 h0935bb2_2 conda-forge; gstreamer 1.18.5 h9f60fe5_3 conda-forge; hdf5 1.10.6 hb1b8bf9_0 ; icu 68.1 h58526e2_0 conda-forge; idna 2.10 pyh9f0ad1d_0 conda-forge; importlib-metadata 4.8.2 py37h06a4308_0 ; importlib_metadata 4.8.2 hd3eb1b0_0 ; importlib_resources 5.2.0 pyhd3eb1b0_1 ; iniconfig 1.1.1 pyhd3eb1b0_0 ; intel-openmp 2021.4.0 h06a4308_3561 ; ipykernel 6.10.0 py37h25bab4e_0 conda-forge; ipython 7.32.0 py37h89c1867_0 conda-forge; ipython_genutils 0.2.0 py_1 conda-forge; ipywidgets 7.7.0 pyhd8ed1ab_0 conda-forge; jbig 2.1 h7f98852_2003 conda-forge; jedi 0.18.1 py37h89c1867_0 conda-forge; jinja2 3.1.1 pyhd8ed1ab_0 conda-forge; jpeg 9d h7f8727e_0 ; jsonschema 4.4.0 pyhd8ed1ab_0 conda-forge; jupyter 1.0.0 py37h89c1867_7 conda-forge; jupyter_client 7.1.2 pyhd8ed1ab_0 conda-forge; jupyter_console 6.4.3 pyhd8ed1ab_0 conda-forge; jupyter_core 4.9.2 py37h89c1867_0 conda-forge; jupyterlab_pygments 0.1.2 pyh9f0ad1d_0 conda-forge; jupyterlab_widgets 1.1.0 pyhd8ed1ab_0 co,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2510#issuecomment-1081031693
https://github.com/psi4/psi4/issues/2510#issuecomment-1081031693:14,Performance,perform,performing,14,"I am actually performing these calculations on Google Colab. (It is for a future workshop.) You can access a Colab notebook exemplifying the error [here](https://colab.research.google.com/drive/1uTsmVcFJY5xArRbo4sQ0RGgPiT406xdM?usp=sharing). Additionally, here is the output from `conda list`. . ```; # packages in environment at /usr/local:; #; # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 1_gnu conda-forge; alsa-lib 1.2.3 h516909a_0 conda-forge; ambit 0.5.1 hbe8a562_1 psi4; argon2-cffi 21.3.0 pyhd8ed1ab_0 conda-forge; argon2-cffi-bindings 21.2.0 py37h5e8e339_1 conda-forge; attrs 21.4.0 pyhd3eb1b0_0 ; backcall 0.2.0 pyh9f0ad1d_0 conda-forge; backports 1.0 py_2 conda-forge; backports.functools_lru_cache 1.6.4 pyhd8ed1ab_0 conda-forge; beautifulsoup4 4.10.0 pyha770c72_0 conda-forge; blas 1.0 mkl ; bleach 4.1.0 pyhd8ed1ab_0 conda-forge; boost 1.74.0 py37h6dcda5c_3 conda-forge; boost-cpp 1.74.0 h312852a_4 conda-forge; bottleneck 1.3.4 py37hce1f21e_0 ; brotli 1.0.9 he6710b0_2 ; brotlipy 0.7.0 py37h5e8e339_1001 conda-forge; bzip2 1.0.8 h7f98852_4 conda-forge; c-ares 1.17.1 h7f98852_1 conda-forge; ca-certificates 2021.10.8 ha878542_0 conda-forge; cairo 1.16.0 hf32fb01_1 ; certifi 2021.10.8 py37h89c1867_1 conda-forge; cffi 1.15.0 py37h036bc23_0 conda-forge; chardet 4.0.0 py37h89c1867_1 conda-forge; chemps2 1.8.10 hbe8a562_0 psi4; conda 4.12.0 py37h89c1867_0 conda-forge; conda-package-handling 1.7.2 py37hb5d75c8_0 conda-forge; cryptography 3.4.5 py37h5d9358c_1 conda-forge; cudatoolkit 11.1.1 h6406543_8 conda-forge; cycler 0.11.0 pyhd3eb1b0_0 ; dbus 1.13.6 h5008d03_3 conda-forge; debtcollector 2.5.0 pyhd8ed1ab_0 conda-forge; debugpy 1.5.1 py37hcd2ae1e_0 conda-forge; decorator 5.1.1 pyhd3eb1b0_0 ; defusedxml 0.7.1 pyhd8ed1ab_0 conda-forge; dftd3 3.2.1 h84218bc_2 psi4; dkh 1.2 h173d85e_2 psi4; entrypoints 0.4 pyhd8ed1ab_0 conda-forge; expat 2.4.7 h27087fc_0 conda-forge; flit-core 3.7.1 pyhd8ed1ab_0 conda-forge; fontconfig 2.13.1 h6c099",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2510#issuecomment-1081031693
https://github.com/psi4/psi4/issues/2510#issuecomment-1081031693:972,Performance,bottleneck,bottleneck,972,"I am actually performing these calculations on Google Colab. (It is for a future workshop.) You can access a Colab notebook exemplifying the error [here](https://colab.research.google.com/drive/1uTsmVcFJY5xArRbo4sQ0RGgPiT406xdM?usp=sharing). Additionally, here is the output from `conda list`. . ```; # packages in environment at /usr/local:; #; # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 1_gnu conda-forge; alsa-lib 1.2.3 h516909a_0 conda-forge; ambit 0.5.1 hbe8a562_1 psi4; argon2-cffi 21.3.0 pyhd8ed1ab_0 conda-forge; argon2-cffi-bindings 21.2.0 py37h5e8e339_1 conda-forge; attrs 21.4.0 pyhd3eb1b0_0 ; backcall 0.2.0 pyh9f0ad1d_0 conda-forge; backports 1.0 py_2 conda-forge; backports.functools_lru_cache 1.6.4 pyhd8ed1ab_0 conda-forge; beautifulsoup4 4.10.0 pyha770c72_0 conda-forge; blas 1.0 mkl ; bleach 4.1.0 pyhd8ed1ab_0 conda-forge; boost 1.74.0 py37h6dcda5c_3 conda-forge; boost-cpp 1.74.0 h312852a_4 conda-forge; bottleneck 1.3.4 py37hce1f21e_0 ; brotli 1.0.9 he6710b0_2 ; brotlipy 0.7.0 py37h5e8e339_1001 conda-forge; bzip2 1.0.8 h7f98852_4 conda-forge; c-ares 1.17.1 h7f98852_1 conda-forge; ca-certificates 2021.10.8 ha878542_0 conda-forge; cairo 1.16.0 hf32fb01_1 ; certifi 2021.10.8 py37h89c1867_1 conda-forge; cffi 1.15.0 py37h036bc23_0 conda-forge; chardet 4.0.0 py37h89c1867_1 conda-forge; chemps2 1.8.10 hbe8a562_0 psi4; conda 4.12.0 py37h89c1867_0 conda-forge; conda-package-handling 1.7.2 py37hb5d75c8_0 conda-forge; cryptography 3.4.5 py37h5d9358c_1 conda-forge; cudatoolkit 11.1.1 h6406543_8 conda-forge; cycler 0.11.0 pyhd3eb1b0_0 ; dbus 1.13.6 h5008d03_3 conda-forge; debtcollector 2.5.0 pyhd8ed1ab_0 conda-forge; debugpy 1.5.1 py37hcd2ae1e_0 conda-forge; decorator 5.1.1 pyhd3eb1b0_0 ; defusedxml 0.7.1 pyhd8ed1ab_0 conda-forge; dftd3 3.2.1 h84218bc_2 psi4; dkh 1.2 h173d85e_2 psi4; entrypoints 0.4 pyhd8ed1ab_0 conda-forge; expat 2.4.7 h27087fc_0 conda-forge; flit-core 3.7.1 pyhd8ed1ab_0 conda-forge; fontconfig 2.13.1 h6c099",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2510#issuecomment-1081031693
https://github.com/psi4/psi4/issues/2510#issuecomment-1081031693:100,Security,access,access,100,"I am actually performing these calculations on Google Colab. (It is for a future workshop.) You can access a Colab notebook exemplifying the error [here](https://colab.research.google.com/drive/1uTsmVcFJY5xArRbo4sQ0RGgPiT406xdM?usp=sharing). Additionally, here is the output from `conda list`. . ```; # packages in environment at /usr/local:; #; # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 1_gnu conda-forge; alsa-lib 1.2.3 h516909a_0 conda-forge; ambit 0.5.1 hbe8a562_1 psi4; argon2-cffi 21.3.0 pyhd8ed1ab_0 conda-forge; argon2-cffi-bindings 21.2.0 py37h5e8e339_1 conda-forge; attrs 21.4.0 pyhd3eb1b0_0 ; backcall 0.2.0 pyh9f0ad1d_0 conda-forge; backports 1.0 py_2 conda-forge; backports.functools_lru_cache 1.6.4 pyhd8ed1ab_0 conda-forge; beautifulsoup4 4.10.0 pyha770c72_0 conda-forge; blas 1.0 mkl ; bleach 4.1.0 pyhd8ed1ab_0 conda-forge; boost 1.74.0 py37h6dcda5c_3 conda-forge; boost-cpp 1.74.0 h312852a_4 conda-forge; bottleneck 1.3.4 py37hce1f21e_0 ; brotli 1.0.9 he6710b0_2 ; brotlipy 0.7.0 py37h5e8e339_1001 conda-forge; bzip2 1.0.8 h7f98852_4 conda-forge; c-ares 1.17.1 h7f98852_1 conda-forge; ca-certificates 2021.10.8 ha878542_0 conda-forge; cairo 1.16.0 hf32fb01_1 ; certifi 2021.10.8 py37h89c1867_1 conda-forge; cffi 1.15.0 py37h036bc23_0 conda-forge; chardet 4.0.0 py37h89c1867_1 conda-forge; chemps2 1.8.10 hbe8a562_0 psi4; conda 4.12.0 py37h89c1867_0 conda-forge; conda-package-handling 1.7.2 py37hb5d75c8_0 conda-forge; cryptography 3.4.5 py37h5d9358c_1 conda-forge; cudatoolkit 11.1.1 h6406543_8 conda-forge; cycler 0.11.0 pyhd3eb1b0_0 ; dbus 1.13.6 h5008d03_3 conda-forge; debtcollector 2.5.0 pyhd8ed1ab_0 conda-forge; debugpy 1.5.1 py37hcd2ae1e_0 conda-forge; decorator 5.1.1 pyhd3eb1b0_0 ; defusedxml 0.7.1 pyhd8ed1ab_0 conda-forge; dftd3 3.2.1 h84218bc_2 psi4; dkh 1.2 h173d85e_2 psi4; entrypoints 0.4 pyhd8ed1ab_0 conda-forge; expat 2.4.7 h27087fc_0 conda-forge; flit-core 3.7.1 pyhd8ed1ab_0 conda-forge; fontconfig 2.13.1 h6c099",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2510#issuecomment-1081031693
https://github.com/psi4/psi4/issues/2510#issuecomment-1081031693:1155,Security,certificate,certificates,1155,"ere](https://colab.research.google.com/drive/1uTsmVcFJY5xArRbo4sQ0RGgPiT406xdM?usp=sharing). Additionally, here is the output from `conda list`. . ```; # packages in environment at /usr/local:; #; # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 1_gnu conda-forge; alsa-lib 1.2.3 h516909a_0 conda-forge; ambit 0.5.1 hbe8a562_1 psi4; argon2-cffi 21.3.0 pyhd8ed1ab_0 conda-forge; argon2-cffi-bindings 21.2.0 py37h5e8e339_1 conda-forge; attrs 21.4.0 pyhd3eb1b0_0 ; backcall 0.2.0 pyh9f0ad1d_0 conda-forge; backports 1.0 py_2 conda-forge; backports.functools_lru_cache 1.6.4 pyhd8ed1ab_0 conda-forge; beautifulsoup4 4.10.0 pyha770c72_0 conda-forge; blas 1.0 mkl ; bleach 4.1.0 pyhd8ed1ab_0 conda-forge; boost 1.74.0 py37h6dcda5c_3 conda-forge; boost-cpp 1.74.0 h312852a_4 conda-forge; bottleneck 1.3.4 py37hce1f21e_0 ; brotli 1.0.9 he6710b0_2 ; brotlipy 0.7.0 py37h5e8e339_1001 conda-forge; bzip2 1.0.8 h7f98852_4 conda-forge; c-ares 1.17.1 h7f98852_1 conda-forge; ca-certificates 2021.10.8 ha878542_0 conda-forge; cairo 1.16.0 hf32fb01_1 ; certifi 2021.10.8 py37h89c1867_1 conda-forge; cffi 1.15.0 py37h036bc23_0 conda-forge; chardet 4.0.0 py37h89c1867_1 conda-forge; chemps2 1.8.10 hbe8a562_0 psi4; conda 4.12.0 py37h89c1867_0 conda-forge; conda-package-handling 1.7.2 py37hb5d75c8_0 conda-forge; cryptography 3.4.5 py37h5d9358c_1 conda-forge; cudatoolkit 11.1.1 h6406543_8 conda-forge; cycler 0.11.0 pyhd3eb1b0_0 ; dbus 1.13.6 h5008d03_3 conda-forge; debtcollector 2.5.0 pyhd8ed1ab_0 conda-forge; debugpy 1.5.1 py37hcd2ae1e_0 conda-forge; decorator 5.1.1 pyhd3eb1b0_0 ; defusedxml 0.7.1 pyhd8ed1ab_0 conda-forge; dftd3 3.2.1 h84218bc_2 psi4; dkh 1.2 h173d85e_2 psi4; entrypoints 0.4 pyhd8ed1ab_0 conda-forge; expat 2.4.7 h27087fc_0 conda-forge; flit-core 3.7.1 pyhd8ed1ab_0 conda-forge; fontconfig 2.13.1 h6c09931_0 ; fonttools 4.25.0 pyhd3eb1b0_0 ; freetype 2.11.0 h70c0345_0 ; gau2grid 2.0.7 hd18ef5c_0 psi4; gcp 2.0.2 he991be0_2 psi4; gdma 2.2.6 h0e1e685_6 ",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2510#issuecomment-1081031693
https://github.com/psi4/psi4/issues/2510#issuecomment-1081031693:8287,Testability,test,testpath,8287,e; pyqtchart 5.12 py37he336c9b_8 conda-forge; pyqtwebengine 5.12.1 py37he336c9b_8 conda-forge; pyrsistent 0.18.1 py37h5e8e339_0 conda-forge; pysocks 1.7.1 py37h89c1867_3 conda-forge; pytest 6.2.5 py37h06a4308_2 ; python 3.7.12 hb7a2778_100_cpython conda-forge; python-dateutil 2.8.2 pyhd3eb1b0_0 ; python_abi 3.7 2_cp37m conda-forge; pytz 2021.3 pyhd3eb1b0_0 ; pyyaml 6.0 py37h7f8727e_1 ; pyzmq 22.3.0 py37h336d617_1 conda-forge; qcelemental 0.24.0 pyhd8ed1ab_0 psi4; qcengine 0.23.0 pyhd8ed1ab_0 psi4; qt 5.12.9 h9d6b050_2 conda-forge; qtconsole 5.2.2 pyhd8ed1ab_1 conda-forge; qtconsole-base 5.2.2 pyhd8ed1ab_1 conda-forge; qtpy 2.0.1 pyhd8ed1ab_0 conda-forge; rdkit 2020.09.5 py37he53b9e1_0 conda-forge; readline 8.1 h46c0cb4_0 conda-forge; reportlab 3.5.67 py37hfdd840d_1 ; reproc 14.2.1 h36c2ea0_0 conda-forge; reproc-cpp 14.2.1 h58526e2_0 conda-forge; requests 2.25.1 pyhd3deb0d_0 conda-forge; ruamel_yaml 0.15.80 py37h5e8e339_1004 conda-forge; send2trash 1.8.0 pyhd8ed1ab_0 conda-forge; setuptools 49.6.0 py37h89c1867_3 conda-forge; simint 0.7 h642920c_1 psi4; six 1.15.0 pyh9f0ad1d_0 conda-forge; soupsieve 2.3.1 pyhd8ed1ab_0 conda-forge; sqlalchemy 1.4.32 py37h7f8727e_0 ; sqlite 3.38.0 hc218d9a_0 ; terminado 0.13.3 py37h89c1867_0 conda-forge; testpath 0.6.0 pyhd8ed1ab_0 conda-forge; tk 8.6.12 h27826a3_0 conda-forge; toml 0.10.2 pyhd3eb1b0_0 ; tornado 6.1 py37h5e8e339_2 conda-forge; tqdm 4.59.0 pyhd8ed1ab_0 conda-forge; traitlets 5.1.1 pyhd8ed1ab_0 conda-forge; typing-extensions 4.1.1 hd3eb1b0_0 ; typing_extensions 4.1.1 pyh06a4308_0 ; urllib3 1.26.3 pyhd8ed1ab_0 conda-forge; wcwidth 0.2.5 pyh9f0ad1d_2 conda-forge; webencodings 0.5.1 py_1 conda-forge; wheel 0.36.2 pyhd3deb0d_0 conda-forge; widgetsnbextension 3.6.0 py37h89c1867_0 conda-forge; wrapt 1.13.3 py37h7f8727e_2 ; xz 5.2.5 h516909a_1 conda-forge; yaml 0.2.5 h516909a_0 conda-forge; zeromq 4.3.4 h9c3ff4c_1 conda-forge; zipp 3.7.0 pyhd3eb1b0_0 ; zlib 1.2.11 h166bdaf_1014 conda-forge; zstd 1.5.2 ha95c52a_0 conda-forge; ```,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2510#issuecomment-1081031693
https://github.com/psi4/psi4/pull/2512#issuecomment-1081905619:25,Testability,test,tests,25,I'm okay with this (once tests pass) but do want to see the docs. I especially need to know _how developers decide what's worth logging_.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2512#issuecomment-1081905619
https://github.com/psi4/psi4/pull/2512#issuecomment-1082126210:379,Availability,error,error,379,"ok, docs and hopefully a fix for efp is up. > especially need to know how developers decide what's worth logging. I don't have a good answer. On the DDD side, stuff goes in the log that no longer appends nicely to the output (because its run in a separate process), so logging is on the generous side. In general, the stuff we want to log doesn't map evenly to the (critical=50, error=40, warn=30, info=20, debug=10) levels that Python sets up. Something more like https://www.ibm.com/docs/en/cognos-analytics/10.2.2?topic=SSEP7J_10.2.2/com.ibm.swg.ba.cognos.ug_rtm_wb.10.2.2.doc/c_n30e74.html with ""debug-low"" etc. might be better. After all, geometry of the molecule is pretty essential, but it's not ""progress of the job"", so I called it debug. For the moment, log contents are a free-for-all, so I've tried to make that clear in the docs.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2512#issuecomment-1082126210
https://github.com/psi4/psi4/pull/2512#issuecomment-1082126210:105,Testability,log,logging,105,"ok, docs and hopefully a fix for efp is up. > especially need to know how developers decide what's worth logging. I don't have a good answer. On the DDD side, stuff goes in the log that no longer appends nicely to the output (because its run in a separate process), so logging is on the generous side. In general, the stuff we want to log doesn't map evenly to the (critical=50, error=40, warn=30, info=20, debug=10) levels that Python sets up. Something more like https://www.ibm.com/docs/en/cognos-analytics/10.2.2?topic=SSEP7J_10.2.2/com.ibm.swg.ba.cognos.ug_rtm_wb.10.2.2.doc/c_n30e74.html with ""debug-low"" etc. might be better. After all, geometry of the molecule is pretty essential, but it's not ""progress of the job"", so I called it debug. For the moment, log contents are a free-for-all, so I've tried to make that clear in the docs.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2512#issuecomment-1082126210
https://github.com/psi4/psi4/pull/2512#issuecomment-1082126210:177,Testability,log,log,177,"ok, docs and hopefully a fix for efp is up. > especially need to know how developers decide what's worth logging. I don't have a good answer. On the DDD side, stuff goes in the log that no longer appends nicely to the output (because its run in a separate process), so logging is on the generous side. In general, the stuff we want to log doesn't map evenly to the (critical=50, error=40, warn=30, info=20, debug=10) levels that Python sets up. Something more like https://www.ibm.com/docs/en/cognos-analytics/10.2.2?topic=SSEP7J_10.2.2/com.ibm.swg.ba.cognos.ug_rtm_wb.10.2.2.doc/c_n30e74.html with ""debug-low"" etc. might be better. After all, geometry of the molecule is pretty essential, but it's not ""progress of the job"", so I called it debug. For the moment, log contents are a free-for-all, so I've tried to make that clear in the docs.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2512#issuecomment-1082126210
https://github.com/psi4/psi4/pull/2512#issuecomment-1082126210:269,Testability,log,logging,269,"ok, docs and hopefully a fix for efp is up. > especially need to know how developers decide what's worth logging. I don't have a good answer. On the DDD side, stuff goes in the log that no longer appends nicely to the output (because its run in a separate process), so logging is on the generous side. In general, the stuff we want to log doesn't map evenly to the (critical=50, error=40, warn=30, info=20, debug=10) levels that Python sets up. Something more like https://www.ibm.com/docs/en/cognos-analytics/10.2.2?topic=SSEP7J_10.2.2/com.ibm.swg.ba.cognos.ug_rtm_wb.10.2.2.doc/c_n30e74.html with ""debug-low"" etc. might be better. After all, geometry of the molecule is pretty essential, but it's not ""progress of the job"", so I called it debug. For the moment, log contents are a free-for-all, so I've tried to make that clear in the docs.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2512#issuecomment-1082126210
https://github.com/psi4/psi4/pull/2512#issuecomment-1082126210:335,Testability,log,log,335,"ok, docs and hopefully a fix for efp is up. > especially need to know how developers decide what's worth logging. I don't have a good answer. On the DDD side, stuff goes in the log that no longer appends nicely to the output (because its run in a separate process), so logging is on the generous side. In general, the stuff we want to log doesn't map evenly to the (critical=50, error=40, warn=30, info=20, debug=10) levels that Python sets up. Something more like https://www.ibm.com/docs/en/cognos-analytics/10.2.2?topic=SSEP7J_10.2.2/com.ibm.swg.ba.cognos.ug_rtm_wb.10.2.2.doc/c_n30e74.html with ""debug-low"" etc. might be better. After all, geometry of the molecule is pretty essential, but it's not ""progress of the job"", so I called it debug. For the moment, log contents are a free-for-all, so I've tried to make that clear in the docs.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2512#issuecomment-1082126210
https://github.com/psi4/psi4/pull/2512#issuecomment-1082126210:764,Testability,log,log,764,"ok, docs and hopefully a fix for efp is up. > especially need to know how developers decide what's worth logging. I don't have a good answer. On the DDD side, stuff goes in the log that no longer appends nicely to the output (because its run in a separate process), so logging is on the generous side. In general, the stuff we want to log doesn't map evenly to the (critical=50, error=40, warn=30, info=20, debug=10) levels that Python sets up. Something more like https://www.ibm.com/docs/en/cognos-analytics/10.2.2?topic=SSEP7J_10.2.2/com.ibm.swg.ba.cognos.ug_rtm_wb.10.2.2.doc/c_n30e74.html with ""debug-low"" etc. might be better. After all, geometry of the molecule is pretty essential, but it's not ""progress of the job"", so I called it debug. For the moment, log contents are a free-for-all, so I've tried to make that clear in the docs.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2512#issuecomment-1082126210
https://github.com/psi4/psi4/pull/2512#issuecomment-1082126210:824,Usability,clear,clear,824,"ok, docs and hopefully a fix for efp is up. > especially need to know how developers decide what's worth logging. I don't have a good answer. On the DDD side, stuff goes in the log that no longer appends nicely to the output (because its run in a separate process), so logging is on the generous side. In general, the stuff we want to log doesn't map evenly to the (critical=50, error=40, warn=30, info=20, debug=10) levels that Python sets up. Something more like https://www.ibm.com/docs/en/cognos-analytics/10.2.2?topic=SSEP7J_10.2.2/com.ibm.swg.ba.cognos.ug_rtm_wb.10.2.2.doc/c_n30e74.html with ""debug-low"" etc. might be better. After all, geometry of the molecule is pretty essential, but it's not ""progress of the job"", so I called it debug. For the moment, log contents are a free-for-all, so I've tried to make that clear in the docs.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2512#issuecomment-1082126210
https://github.com/psi4/psi4/pull/2512#issuecomment-1082170261:37,Testability,log,log,37,"> On the DDD side, stuff goes in the log that no longer appends nicely to the output (because its run in a separate process), so logging is on the generous side. Can you elaborate on how DDD affects our ability to output to file?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2512#issuecomment-1082170261
https://github.com/psi4/psi4/pull/2512#issuecomment-1082170261:129,Testability,log,logging,129,"> On the DDD side, stuff goes in the log that no longer appends nicely to the output (because its run in a separate process), so logging is on the generous side. Can you elaborate on how DDD affects our ability to output to file?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2512#issuecomment-1082170261
https://github.com/psi4/psi4/pull/2512#issuecomment-1082191447:1236,Deployability,continuous,continuous,1236,"> Can you elaborate on how DDD affects our ability to output to file?. Sure. For everything but analytic single points (effectively, any composite, finite difference, or many-body expansion), the individual pieces are sent to qcengine as a qcschema atomicinput job that returns a qcschema atomicresult (that has the usual output file printout as a field). So all the usual output is collected, but some of the most important stuff (the atomicresult) is in a dict, which would be weird for an output file. Also, the psi4 output file isn't a wonderfully behaved object for being opened and closed and reset, potentially for dozens of jobs running at the same time. It looks like the individual pieces outputs are being accumulated in the outfile now in DDD (see below). But logging _is_ a natural object for accumulating the results of potentially multiple libraries into one file or stream, so it seems the right trajectory to get started along for distributed calcs. ```; gof = core.get_output_file(). # EITHER ...; # from psi4.driver import schema_wrapper; # self.result = schema_wrapper.run_qcschema(self.plan()); # ... OR ...; self.result = qcng.compute(; self.plan(),; ""psi4"",; raise_error=True,; # local_options below suitable for continuous mode; local_options={; ""memory"": core.get_memory() / (2 ** 30),; ""ncores"": core.get_num_threads(),; },; ); # ... END. core.set_output_file(gof, True); core.reopen_outfile(); logger.debug(pp.pformat(self.result.dict())); core.print_out(_drink_filter(self.result.dict()[""stdout""])); ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2512#issuecomment-1082191447
https://github.com/psi4/psi4/pull/2512#issuecomment-1082191447:772,Testability,log,logging,772,"> Can you elaborate on how DDD affects our ability to output to file?. Sure. For everything but analytic single points (effectively, any composite, finite difference, or many-body expansion), the individual pieces are sent to qcengine as a qcschema atomicinput job that returns a qcschema atomicresult (that has the usual output file printout as a field). So all the usual output is collected, but some of the most important stuff (the atomicresult) is in a dict, which would be weird for an output file. Also, the psi4 output file isn't a wonderfully behaved object for being opened and closed and reset, potentially for dozens of jobs running at the same time. It looks like the individual pieces outputs are being accumulated in the outfile now in DDD (see below). But logging _is_ a natural object for accumulating the results of potentially multiple libraries into one file or stream, so it seems the right trajectory to get started along for distributed calcs. ```; gof = core.get_output_file(). # EITHER ...; # from psi4.driver import schema_wrapper; # self.result = schema_wrapper.run_qcschema(self.plan()); # ... OR ...; self.result = qcng.compute(; self.plan(),; ""psi4"",; raise_error=True,; # local_options below suitable for continuous mode; local_options={; ""memory"": core.get_memory() / (2 ** 30),; ""ncores"": core.get_num_threads(),; },; ); # ... END. core.set_output_file(gof, True); core.reopen_outfile(); logger.debug(pp.pformat(self.result.dict())); core.print_out(_drink_filter(self.result.dict()[""stdout""])); ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2512#issuecomment-1082191447
https://github.com/psi4/psi4/pull/2512#issuecomment-1082191447:1421,Testability,log,logger,1421,"> Can you elaborate on how DDD affects our ability to output to file?. Sure. For everything but analytic single points (effectively, any composite, finite difference, or many-body expansion), the individual pieces are sent to qcengine as a qcschema atomicinput job that returns a qcschema atomicresult (that has the usual output file printout as a field). So all the usual output is collected, but some of the most important stuff (the atomicresult) is in a dict, which would be weird for an output file. Also, the psi4 output file isn't a wonderfully behaved object for being opened and closed and reset, potentially for dozens of jobs running at the same time. It looks like the individual pieces outputs are being accumulated in the outfile now in DDD (see below). But logging _is_ a natural object for accumulating the results of potentially multiple libraries into one file or stream, so it seems the right trajectory to get started along for distributed calcs. ```; gof = core.get_output_file(). # EITHER ...; # from psi4.driver import schema_wrapper; # self.result = schema_wrapper.run_qcschema(self.plan()); # ... OR ...; self.result = qcng.compute(; self.plan(),; ""psi4"",; raise_error=True,; # local_options below suitable for continuous mode; local_options={; ""memory"": core.get_memory() / (2 ** 30),; ""ncores"": core.get_num_threads(),; },; ); # ... END. core.set_output_file(gof, True); core.reopen_outfile(); logger.debug(pp.pformat(self.result.dict())); core.print_out(_drink_filter(self.result.dict()[""stdout""])); ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2512#issuecomment-1082191447
https://github.com/psi4/psi4/pull/2512#issuecomment-1082310204:31,Testability,log,log,31,"Generally I'd like the default log level to be more verbose and spam the log file instead of having something crucial missing and the user needs to repeat a calculation. That said, I haven't used the internal python logger object and these high numbers are and multiple categories unexpected and for a compchem program a bit confusing to be honest.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2512#issuecomment-1082310204
https://github.com/psi4/psi4/pull/2512#issuecomment-1082310204:73,Testability,log,log,73,"Generally I'd like the default log level to be more verbose and spam the log file instead of having something crucial missing and the user needs to repeat a calculation. That said, I haven't used the internal python logger object and these high numbers are and multiple categories unexpected and for a compchem program a bit confusing to be honest.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2512#issuecomment-1082310204
https://github.com/psi4/psi4/pull/2512#issuecomment-1082310204:216,Testability,log,logger,216,"Generally I'd like the default log level to be more verbose and spam the log file instead of having something crucial missing and the user needs to repeat a calculation. That said, I haven't used the internal python logger object and these high numbers are and multiple categories unexpected and for a compchem program a bit confusing to be honest.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2512#issuecomment-1082310204
https://github.com/psi4/psi4/pull/2513#issuecomment-1084625953:22,Modifiability,refactor,refactoring,22,"Question: Is it worth refactoring `adcc` ctests to pytest? I will need to touch *every* `adcc` test to accommodate for new variables (previously all excitation energies were just stored in a single array, so that we could use `compare_arrays`) anyways.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2513#issuecomment-1084625953
https://github.com/psi4/psi4/pull/2513#issuecomment-1084625953:123,Modifiability,variab,variables,123,"Question: Is it worth refactoring `adcc` ctests to pytest? I will need to touch *every* `adcc` test to accommodate for new variables (previously all excitation energies were just stored in a single array, so that we could use `compare_arrays`) anyways.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2513#issuecomment-1084625953
https://github.com/psi4/psi4/pull/2513#issuecomment-1084625953:95,Testability,test,test,95,"Question: Is it worth refactoring `adcc` ctests to pytest? I will need to touch *every* `adcc` test to accommodate for new variables (previously all excitation energies were just stored in a single array, so that we could use `compare_arrays`) anyways.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2513#issuecomment-1084625953
https://github.com/psi4/psi4/pull/2513#issuecomment-1084628549:185,Testability,test,test,185,"Lori introduced a mechanism to run any `ctest` through `pytest` [in a recent PR](https://github.com/psi4/psi4/pull/2454), so I don't think it'd be worth it unless there's a very clear ""test template"" that all of your tests follow.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2513#issuecomment-1084628549
https://github.com/psi4/psi4/pull/2513#issuecomment-1084628549:217,Testability,test,tests,217,"Lori introduced a mechanism to run any `ctest` through `pytest` [in a recent PR](https://github.com/psi4/psi4/pull/2454), so I don't think it'd be worth it unless there's a very clear ""test template"" that all of your tests follow.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2513#issuecomment-1084628549
https://github.com/psi4/psi4/pull/2513#issuecomment-1084628549:178,Usability,clear,clear,178,"Lori introduced a mechanism to run any `ctest` through `pytest` [in a recent PR](https://github.com/psi4/psi4/pull/2454), so I don't think it'd be worth it unless there's a very clear ""test template"" that all of your tests follow.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2513#issuecomment-1084628549
https://github.com/psi4/psi4/pull/2513#issuecomment-1084636181:18,Modifiability,refactor,refactor,18,"Yes, I think I'll refactor all the `adcc` tests using `pytest`...",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2513#issuecomment-1084636181
https://github.com/psi4/psi4/pull/2513#issuecomment-1084636181:42,Testability,test,tests,42,"Yes, I think I'll refactor all the `adcc` tests using `pytest`...",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2513#issuecomment-1084636181
https://github.com/psi4/psi4/pull/2514#issuecomment-1083215686:132,Modifiability,refactor,refactor,132,Thanks for the review!. > Just want to check that the TODO in `ccdensity/Params.h` wasn't really intended for this PR. Confirmed. A refactor of the fundamental data structures used in the `ccdensity` module is outside the scope of this PR. This PR just _motivates_ such a refactor.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2514#issuecomment-1083215686
https://github.com/psi4/psi4/pull/2514#issuecomment-1083215686:272,Modifiability,refactor,refactor,272,Thanks for the review!. > Just want to check that the TODO in `ccdensity/Params.h` wasn't really intended for this PR. Confirmed. A refactor of the fundamental data structures used in the `ccdensity` module is outside the scope of this PR. This PR just _motivates_ such a refactor.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2514#issuecomment-1083215686
https://github.com/psi4/psi4/issues/2519#issuecomment-1089612589:281,Energy Efficiency,energy,energy,281,Please note that `libdiis` did not exist when the DIIS code was written in the `cc` modules. Convergence difficulties in `cclambda` are not due to DIIS difficulties but due to the fact that linear equations become poorly conditioned for excited states that are relatively close in energy.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2519#issuecomment-1089612589
https://github.com/psi4/psi4/issues/2520#issuecomment-1089609984:117,Safety,avoid,avoid,117,"I agree that `cclambda` should honor the user's `r_convergence` choice, but the default settings we chose are not to avoid breaking tests but because tighter settings are wholly unnecessary (and often exceedingly difficult to achieve) for transition properties. The `cc55` test case just revealed the problem on certain hardware.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2520#issuecomment-1089609984
https://github.com/psi4/psi4/issues/2520#issuecomment-1089609984:132,Testability,test,tests,132,"I agree that `cclambda` should honor the user's `r_convergence` choice, but the default settings we chose are not to avoid breaking tests but because tighter settings are wholly unnecessary (and often exceedingly difficult to achieve) for transition properties. The `cc55` test case just revealed the problem on certain hardware.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2520#issuecomment-1089609984
https://github.com/psi4/psi4/issues/2520#issuecomment-1089609984:273,Testability,test,test,273,"I agree that `cclambda` should honor the user's `r_convergence` choice, but the default settings we chose are not to avoid breaking tests but because tighter settings are wholly unnecessary (and often exceedingly difficult to achieve) for transition properties. The `cc55` test case just revealed the problem on certain hardware.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2520#issuecomment-1089609984
https://github.com/psi4/psi4/issues/2520#issuecomment-1089636980:43,Safety,avoid,avoid,43,"> the default settings we chose are not to avoid breaking tests but because tighter settings are wholly unnecessary (and often exceedingly difficult to achieve) for transition properties. > may be useful to separate the convergence criteria for the t's and lambdas, if not already done. The running plan is to rename `r_convergence` to `lambda_convergence` or somesuch within `cclambda`, with some logic to auto-set `lambda_convergence` is that is _not_ set but `r_convergence` _is_. `occ` and `dfocc` use a similar trick. For context, ""exceedingly difficult to achieve"" means [you're trying to solve ill-conditioned equations](https://github.com/psi4/psi4/issues/2519#issuecomment-1089612589). I'm expecting to be the one who picks this up, and when the time comes, I'll do a quick convergence study to double-check the sensitivity of properties to this parameter.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2520#issuecomment-1089636980
https://github.com/psi4/psi4/issues/2520#issuecomment-1089636980:58,Testability,test,tests,58,"> the default settings we chose are not to avoid breaking tests but because tighter settings are wholly unnecessary (and often exceedingly difficult to achieve) for transition properties. > may be useful to separate the convergence criteria for the t's and lambdas, if not already done. The running plan is to rename `r_convergence` to `lambda_convergence` or somesuch within `cclambda`, with some logic to auto-set `lambda_convergence` is that is _not_ set but `r_convergence` _is_. `occ` and `dfocc` use a similar trick. For context, ""exceedingly difficult to achieve"" means [you're trying to solve ill-conditioned equations](https://github.com/psi4/psi4/issues/2519#issuecomment-1089612589). I'm expecting to be the one who picks this up, and when the time comes, I'll do a quick convergence study to double-check the sensitivity of properties to this parameter.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2520#issuecomment-1089636980
https://github.com/psi4/psi4/issues/2520#issuecomment-1089636980:398,Testability,log,logic,398,"> the default settings we chose are not to avoid breaking tests but because tighter settings are wholly unnecessary (and often exceedingly difficult to achieve) for transition properties. > may be useful to separate the convergence criteria for the t's and lambdas, if not already done. The running plan is to rename `r_convergence` to `lambda_convergence` or somesuch within `cclambda`, with some logic to auto-set `lambda_convergence` is that is _not_ set but `r_convergence` _is_. `occ` and `dfocc` use a similar trick. For context, ""exceedingly difficult to achieve"" means [you're trying to solve ill-conditioned equations](https://github.com/psi4/psi4/issues/2519#issuecomment-1089612589). I'm expecting to be the one who picks this up, and when the time comes, I'll do a quick convergence study to double-check the sensitivity of properties to this parameter.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2520#issuecomment-1089636980
https://github.com/psi4/psi4/issues/2521#issuecomment-1089615657:42,Usability,clear,clearly,42,"I agree that it should warn the user more clearly, but the lack-of-exit behavior is intentional. It's an attempt to salvage useful data rather than simply quitting and giving nothing from a potentially very long excited-state calculation.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2521#issuecomment-1089615657
https://github.com/psi4/psi4/issues/2521#issuecomment-1089615657:148,Usability,simpl,simply,148,"I agree that it should warn the user more clearly, but the lack-of-exit behavior is intentional. It's an attempt to salvage useful data rather than simply quitting and giving nothing from a potentially very long excited-state calculation.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2521#issuecomment-1089615657
https://github.com/psi4/psi4/issues/2521#issuecomment-1089623349:168,Safety,avoid,avoid,168,We were supposing it was something like that. Would it be reasonable to print results only from converged roots and then ending with coffee instead of beer? That could avoid the banks of zeros and the quick impression that all's well.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2521#issuecomment-1089623349
https://github.com/psi4/psi4/pull/2525#issuecomment-1084589177:308,Deployability,update,updated,308,"That's right. I made three different mistakes in the units (missed the section you pointed out, didn't realize you were converting _to_ not _from_ SI at the end, and mixed up the probability-from-mean-intensity definition vs. the probability-from-energy-density definition of the Einstein B.). Documentation updated.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2525#issuecomment-1084589177
https://github.com/psi4/psi4/pull/2525#issuecomment-1084589177:247,Energy Efficiency,energy,energy-density,247,"That's right. I made three different mistakes in the units (missed the section you pointed out, didn't realize you were converting _to_ not _from_ SI at the end, and mixed up the probability-from-mean-intensity definition vs. the probability-from-energy-density definition of the Einstein B.). Documentation updated.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2525#issuecomment-1084589177
https://github.com/psi4/psi4/pull/2525#issuecomment-1087975547:49,Availability,redundant,redundant,49,"I rebased the PR. In addition to eliminating the redundant argument, I did some `const` marking.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2525#issuecomment-1087975547
https://github.com/psi4/psi4/pull/2525#issuecomment-1087975547:49,Safety,redund,redundant,49,"I rebased the PR. In addition to eliminating the redundant argument, I did some `const` marking.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2525#issuecomment-1087975547
https://github.com/psi4/psi4/pull/2529#issuecomment-1086413448:323,Usability,simpl,simplifies,323,"I know next-to-nothing about the CDS's group's future JK plans. Before I can approve this, I'd like some confidence that these changes really are essential preparation for work-in-progress in the CDS group that you expect to be submtited soon. Can you give me an outline, or a draft PR, of how this responsibility transfer simplifies Incremeental Fock?. Is `early_screening_` for this ""semi-numerical exchange,"" or something else? How close is this other PR to completion.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2529#issuecomment-1086413448
https://github.com/psi4/psi4/pull/2529#issuecomment-1089141879:738,Deployability,update,updates,738,"> I'd like some confidence that these changes really are essential preparation for work-in-progress in the CDS group that you expect to be submtited soon. Both of these changes are necessary for semi-numerical exchange, which I plan to submit in the next week or two. Because these changes touch important parts of the SCF/JK code but shouldn't change any existing behavior, I thought it would be best to submit them separately. > Can you give me an outline, or a draft PR, of how this responsibility transfer simplifies Incremeental Fock?. Sure, I'll do my best to explain. As you probably know, `JK` objects are used throughout the codebase via calls to `JK::compute()`. In SCF, many calls to `JK::compute()` are made interspersed with updates to the object's orbitals. `JK::compute()` does a [few things](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libfock/jk.cc#L550): performs sanity checks, creates densities from the orbitals, zeroes out the object's `J`/`K`/`wK` matrices, and finally calls the virtual function `compute_JK()`, which is where each child class implements some algorithm to fill `J`/`K`/`wK`. Now consider incremental Fock construction. Instead of recomputing `J`/`K`/`wK` each SCF iteration, the previous iteration's `J`/`K`/`wK` are added to a `J`/`K`/`wK` computed with the difference in densities between the current and previous iterations. As [implemented in the `DirectJK` class](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libfock/jk.h#L724-L734), this accomplished by storing the entire `J`/`K`/`wK` matrices of the previous iteration, computing the difference density update to `J`/`K`/`wK`, adding the two together, and storing in the `JK` objects `J`/`K`/`wK` matrices. This requires a lot of [convoluted bookkeeping](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libfock/DirectJK.cc#L138-L217). Future JK classes that would want to do incremental Fock build would have to duplicate a lot of code, too. Instead, a much simpler approach",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2529#issuecomment-1089141879
https://github.com/psi4/psi4/pull/2529#issuecomment-1089141879:1623,Deployability,update,update,1623,"jects are used throughout the codebase via calls to `JK::compute()`. In SCF, many calls to `JK::compute()` are made interspersed with updates to the object's orbitals. `JK::compute()` does a [few things](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libfock/jk.cc#L550): performs sanity checks, creates densities from the orbitals, zeroes out the object's `J`/`K`/`wK` matrices, and finally calls the virtual function `compute_JK()`, which is where each child class implements some algorithm to fill `J`/`K`/`wK`. Now consider incremental Fock construction. Instead of recomputing `J`/`K`/`wK` each SCF iteration, the previous iteration's `J`/`K`/`wK` are added to a `J`/`K`/`wK` computed with the difference in densities between the current and previous iterations. As [implemented in the `DirectJK` class](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libfock/jk.h#L724-L734), this accomplished by storing the entire `J`/`K`/`wK` matrices of the previous iteration, computing the difference density update to `J`/`K`/`wK`, adding the two together, and storing in the `JK` objects `J`/`K`/`wK` matrices. This requires a lot of [convoluted bookkeeping](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libfock/DirectJK.cc#L138-L217). Future JK classes that would want to do incremental Fock build would have to duplicate a lot of code, too. Instead, a much simpler approach would be this: The call to `JK::compute()` doesn't zero out the `J`/`K`/`wK` matrices. Instead, the child JK class can choose to zero out their `J`/`K`/`wK` matrices (if performing a normal Fock build) or leave them as-is from the previous iteration and add to them (if performing an incremental Fock build). This way no previous iterations' `J`/`K`/`wK` matrices have to be saved, and the logic in `compute_JK` becomes much simpler. . > Is `early_screening_` for this ""semi-numerical exchange,"" or something else? How close is this other PR to completion. Yes, this is used in semi-numerical exchange.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2529#issuecomment-1089141879
https://github.com/psi4/psi4/pull/2529#issuecomment-1089141879:884,Performance,perform,performs,884,"> I'd like some confidence that these changes really are essential preparation for work-in-progress in the CDS group that you expect to be submtited soon. Both of these changes are necessary for semi-numerical exchange, which I plan to submit in the next week or two. Because these changes touch important parts of the SCF/JK code but shouldn't change any existing behavior, I thought it would be best to submit them separately. > Can you give me an outline, or a draft PR, of how this responsibility transfer simplifies Incremeental Fock?. Sure, I'll do my best to explain. As you probably know, `JK` objects are used throughout the codebase via calls to `JK::compute()`. In SCF, many calls to `JK::compute()` are made interspersed with updates to the object's orbitals. `JK::compute()` does a [few things](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libfock/jk.cc#L550): performs sanity checks, creates densities from the orbitals, zeroes out the object's `J`/`K`/`wK` matrices, and finally calls the virtual function `compute_JK()`, which is where each child class implements some algorithm to fill `J`/`K`/`wK`. Now consider incremental Fock construction. Instead of recomputing `J`/`K`/`wK` each SCF iteration, the previous iteration's `J`/`K`/`wK` are added to a `J`/`K`/`wK` computed with the difference in densities between the current and previous iterations. As [implemented in the `DirectJK` class](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libfock/jk.h#L724-L734), this accomplished by storing the entire `J`/`K`/`wK` matrices of the previous iteration, computing the difference density update to `J`/`K`/`wK`, adding the two together, and storing in the `JK` objects `J`/`K`/`wK` matrices. This requires a lot of [convoluted bookkeeping](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libfock/DirectJK.cc#L138-L217). Future JK classes that would want to do incremental Fock build would have to duplicate a lot of code, too. Instead, a much simpler approac",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2529#issuecomment-1089141879
https://github.com/psi4/psi4/pull/2529#issuecomment-1089141879:2172,Performance,perform,performing,2172,"jects are used throughout the codebase via calls to `JK::compute()`. In SCF, many calls to `JK::compute()` are made interspersed with updates to the object's orbitals. `JK::compute()` does a [few things](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libfock/jk.cc#L550): performs sanity checks, creates densities from the orbitals, zeroes out the object's `J`/`K`/`wK` matrices, and finally calls the virtual function `compute_JK()`, which is where each child class implements some algorithm to fill `J`/`K`/`wK`. Now consider incremental Fock construction. Instead of recomputing `J`/`K`/`wK` each SCF iteration, the previous iteration's `J`/`K`/`wK` are added to a `J`/`K`/`wK` computed with the difference in densities between the current and previous iterations. As [implemented in the `DirectJK` class](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libfock/jk.h#L724-L734), this accomplished by storing the entire `J`/`K`/`wK` matrices of the previous iteration, computing the difference density update to `J`/`K`/`wK`, adding the two together, and storing in the `JK` objects `J`/`K`/`wK` matrices. This requires a lot of [convoluted bookkeeping](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libfock/DirectJK.cc#L138-L217). Future JK classes that would want to do incremental Fock build would have to duplicate a lot of code, too. Instead, a much simpler approach would be this: The call to `JK::compute()` doesn't zero out the `J`/`K`/`wK` matrices. Instead, the child JK class can choose to zero out their `J`/`K`/`wK` matrices (if performing a normal Fock build) or leave them as-is from the previous iteration and add to them (if performing an incremental Fock build). This way no previous iterations' `J`/`K`/`wK` matrices have to be saved, and the logic in `compute_JK` becomes much simpler. . > Is `early_screening_` for this ""semi-numerical exchange,"" or something else? How close is this other PR to completion. Yes, this is used in semi-numerical exchange.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2529#issuecomment-1089141879
https://github.com/psi4/psi4/pull/2529#issuecomment-1089141879:2272,Performance,perform,performing,2272,"jects are used throughout the codebase via calls to `JK::compute()`. In SCF, many calls to `JK::compute()` are made interspersed with updates to the object's orbitals. `JK::compute()` does a [few things](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libfock/jk.cc#L550): performs sanity checks, creates densities from the orbitals, zeroes out the object's `J`/`K`/`wK` matrices, and finally calls the virtual function `compute_JK()`, which is where each child class implements some algorithm to fill `J`/`K`/`wK`. Now consider incremental Fock construction. Instead of recomputing `J`/`K`/`wK` each SCF iteration, the previous iteration's `J`/`K`/`wK` are added to a `J`/`K`/`wK` computed with the difference in densities between the current and previous iterations. As [implemented in the `DirectJK` class](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libfock/jk.h#L724-L734), this accomplished by storing the entire `J`/`K`/`wK` matrices of the previous iteration, computing the difference density update to `J`/`K`/`wK`, adding the two together, and storing in the `JK` objects `J`/`K`/`wK` matrices. This requires a lot of [convoluted bookkeeping](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libfock/DirectJK.cc#L138-L217). Future JK classes that would want to do incremental Fock build would have to duplicate a lot of code, too. Instead, a much simpler approach would be this: The call to `JK::compute()` doesn't zero out the `J`/`K`/`wK` matrices. Instead, the child JK class can choose to zero out their `J`/`K`/`wK` matrices (if performing a normal Fock build) or leave them as-is from the previous iteration and add to them (if performing an incremental Fock build). This way no previous iterations' `J`/`K`/`wK` matrices have to be saved, and the logic in `compute_JK` becomes much simpler. . > Is `early_screening_` for this ""semi-numerical exchange,"" or something else? How close is this other PR to completion. Yes, this is used in semi-numerical exchange.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2529#issuecomment-1089141879
https://github.com/psi4/psi4/pull/2529#issuecomment-1089141879:893,Safety,sanity check,sanity checks,893,"> I'd like some confidence that these changes really are essential preparation for work-in-progress in the CDS group that you expect to be submtited soon. Both of these changes are necessary for semi-numerical exchange, which I plan to submit in the next week or two. Because these changes touch important parts of the SCF/JK code but shouldn't change any existing behavior, I thought it would be best to submit them separately. > Can you give me an outline, or a draft PR, of how this responsibility transfer simplifies Incremeental Fock?. Sure, I'll do my best to explain. As you probably know, `JK` objects are used throughout the codebase via calls to `JK::compute()`. In SCF, many calls to `JK::compute()` are made interspersed with updates to the object's orbitals. `JK::compute()` does a [few things](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libfock/jk.cc#L550): performs sanity checks, creates densities from the orbitals, zeroes out the object's `J`/`K`/`wK` matrices, and finally calls the virtual function `compute_JK()`, which is where each child class implements some algorithm to fill `J`/`K`/`wK`. Now consider incremental Fock construction. Instead of recomputing `J`/`K`/`wK` each SCF iteration, the previous iteration's `J`/`K`/`wK` are added to a `J`/`K`/`wK` computed with the difference in densities between the current and previous iterations. As [implemented in the `DirectJK` class](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libfock/jk.h#L724-L734), this accomplished by storing the entire `J`/`K`/`wK` matrices of the previous iteration, computing the difference density update to `J`/`K`/`wK`, adding the two together, and storing in the `JK` objects `J`/`K`/`wK` matrices. This requires a lot of [convoluted bookkeeping](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libfock/DirectJK.cc#L138-L217). Future JK classes that would want to do incremental Fock build would have to duplicate a lot of code, too. Instead, a much simpler approac",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2529#issuecomment-1089141879
https://github.com/psi4/psi4/pull/2529#issuecomment-1089141879:2392,Testability,log,logic,2392,"jects are used throughout the codebase via calls to `JK::compute()`. In SCF, many calls to `JK::compute()` are made interspersed with updates to the object's orbitals. `JK::compute()` does a [few things](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libfock/jk.cc#L550): performs sanity checks, creates densities from the orbitals, zeroes out the object's `J`/`K`/`wK` matrices, and finally calls the virtual function `compute_JK()`, which is where each child class implements some algorithm to fill `J`/`K`/`wK`. Now consider incremental Fock construction. Instead of recomputing `J`/`K`/`wK` each SCF iteration, the previous iteration's `J`/`K`/`wK` are added to a `J`/`K`/`wK` computed with the difference in densities between the current and previous iterations. As [implemented in the `DirectJK` class](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libfock/jk.h#L724-L734), this accomplished by storing the entire `J`/`K`/`wK` matrices of the previous iteration, computing the difference density update to `J`/`K`/`wK`, adding the two together, and storing in the `JK` objects `J`/`K`/`wK` matrices. This requires a lot of [convoluted bookkeeping](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libfock/DirectJK.cc#L138-L217). Future JK classes that would want to do incremental Fock build would have to duplicate a lot of code, too. Instead, a much simpler approach would be this: The call to `JK::compute()` doesn't zero out the `J`/`K`/`wK` matrices. Instead, the child JK class can choose to zero out their `J`/`K`/`wK` matrices (if performing a normal Fock build) or leave them as-is from the previous iteration and add to them (if performing an incremental Fock build). This way no previous iterations' `J`/`K`/`wK` matrices have to be saved, and the logic in `compute_JK` becomes much simpler. . > Is `early_screening_` for this ""semi-numerical exchange,"" or something else? How close is this other PR to completion. Yes, this is used in semi-numerical exchange.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2529#issuecomment-1089141879
https://github.com/psi4/psi4/pull/2529#issuecomment-1089141879:510,Usability,simpl,simplifies,510,"> I'd like some confidence that these changes really are essential preparation for work-in-progress in the CDS group that you expect to be submtited soon. Both of these changes are necessary for semi-numerical exchange, which I plan to submit in the next week or two. Because these changes touch important parts of the SCF/JK code but shouldn't change any existing behavior, I thought it would be best to submit them separately. > Can you give me an outline, or a draft PR, of how this responsibility transfer simplifies Incremeental Fock?. Sure, I'll do my best to explain. As you probably know, `JK` objects are used throughout the codebase via calls to `JK::compute()`. In SCF, many calls to `JK::compute()` are made interspersed with updates to the object's orbitals. `JK::compute()` does a [few things](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libfock/jk.cc#L550): performs sanity checks, creates densities from the orbitals, zeroes out the object's `J`/`K`/`wK` matrices, and finally calls the virtual function `compute_JK()`, which is where each child class implements some algorithm to fill `J`/`K`/`wK`. Now consider incremental Fock construction. Instead of recomputing `J`/`K`/`wK` each SCF iteration, the previous iteration's `J`/`K`/`wK` are added to a `J`/`K`/`wK` computed with the difference in densities between the current and previous iterations. As [implemented in the `DirectJK` class](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libfock/jk.h#L724-L734), this accomplished by storing the entire `J`/`K`/`wK` matrices of the previous iteration, computing the difference density update to `J`/`K`/`wK`, adding the two together, and storing in the `JK` objects `J`/`K`/`wK` matrices. This requires a lot of [convoluted bookkeeping](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libfock/DirectJK.cc#L138-L217). Future JK classes that would want to do incremental Fock build would have to duplicate a lot of code, too. Instead, a much simpler approach",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2529#issuecomment-1089141879
https://github.com/psi4/psi4/pull/2529#issuecomment-1089141879:1985,Usability,simpl,simpler,1985,"jects are used throughout the codebase via calls to `JK::compute()`. In SCF, many calls to `JK::compute()` are made interspersed with updates to the object's orbitals. `JK::compute()` does a [few things](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libfock/jk.cc#L550): performs sanity checks, creates densities from the orbitals, zeroes out the object's `J`/`K`/`wK` matrices, and finally calls the virtual function `compute_JK()`, which is where each child class implements some algorithm to fill `J`/`K`/`wK`. Now consider incremental Fock construction. Instead of recomputing `J`/`K`/`wK` each SCF iteration, the previous iteration's `J`/`K`/`wK` are added to a `J`/`K`/`wK` computed with the difference in densities between the current and previous iterations. As [implemented in the `DirectJK` class](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libfock/jk.h#L724-L734), this accomplished by storing the entire `J`/`K`/`wK` matrices of the previous iteration, computing the difference density update to `J`/`K`/`wK`, adding the two together, and storing in the `JK` objects `J`/`K`/`wK` matrices. This requires a lot of [convoluted bookkeeping](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libfock/DirectJK.cc#L138-L217). Future JK classes that would want to do incremental Fock build would have to duplicate a lot of code, too. Instead, a much simpler approach would be this: The call to `JK::compute()` doesn't zero out the `J`/`K`/`wK` matrices. Instead, the child JK class can choose to zero out their `J`/`K`/`wK` matrices (if performing a normal Fock build) or leave them as-is from the previous iteration and add to them (if performing an incremental Fock build). This way no previous iterations' `J`/`K`/`wK` matrices have to be saved, and the logic in `compute_JK` becomes much simpler. . > Is `early_screening_` for this ""semi-numerical exchange,"" or something else? How close is this other PR to completion. Yes, this is used in semi-numerical exchange.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2529#issuecomment-1089141879
https://github.com/psi4/psi4/pull/2529#issuecomment-1089141879:2427,Usability,simpl,simpler,2427,"jects are used throughout the codebase via calls to `JK::compute()`. In SCF, many calls to `JK::compute()` are made interspersed with updates to the object's orbitals. `JK::compute()` does a [few things](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libfock/jk.cc#L550): performs sanity checks, creates densities from the orbitals, zeroes out the object's `J`/`K`/`wK` matrices, and finally calls the virtual function `compute_JK()`, which is where each child class implements some algorithm to fill `J`/`K`/`wK`. Now consider incremental Fock construction. Instead of recomputing `J`/`K`/`wK` each SCF iteration, the previous iteration's `J`/`K`/`wK` are added to a `J`/`K`/`wK` computed with the difference in densities between the current and previous iterations. As [implemented in the `DirectJK` class](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libfock/jk.h#L724-L734), this accomplished by storing the entire `J`/`K`/`wK` matrices of the previous iteration, computing the difference density update to `J`/`K`/`wK`, adding the two together, and storing in the `JK` objects `J`/`K`/`wK` matrices. This requires a lot of [convoluted bookkeeping](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libfock/DirectJK.cc#L138-L217). Future JK classes that would want to do incremental Fock build would have to duplicate a lot of code, too. Instead, a much simpler approach would be this: The call to `JK::compute()` doesn't zero out the `J`/`K`/`wK` matrices. Instead, the child JK class can choose to zero out their `J`/`K`/`wK` matrices (if performing a normal Fock build) or leave them as-is from the previous iteration and add to them (if performing an incremental Fock build). This way no previous iterations' `J`/`K`/`wK` matrices have to be saved, and the logic in `compute_JK` becomes much simpler. . > Is `early_screening_` for this ""semi-numerical exchange,"" or something else? How close is this other PR to completion. Yes, this is used in semi-numerical exchange.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2529#issuecomment-1089141879
https://github.com/psi4/psi4/pull/2533#issuecomment-1089317532:112,Availability,redundant,redundant,112,"> ah, was this choking in `OEProp` when you pushed an EOM wfn? or was it computing properly and just giving the redundant name? regardless, good catch. Computing properly and not giving the expected `CCSD DIPOLE`. This led to an error when I fixed a bug in AJ's code. That should be fixed in the next `cc` series PR.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2533#issuecomment-1089317532
https://github.com/psi4/psi4/pull/2533#issuecomment-1089317532:229,Availability,error,error,229,"> ah, was this choking in `OEProp` when you pushed an EOM wfn? or was it computing properly and just giving the redundant name? regardless, good catch. Computing properly and not giving the expected `CCSD DIPOLE`. This led to an error when I fixed a bug in AJ's code. That should be fixed in the next `cc` series PR.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2533#issuecomment-1089317532
https://github.com/psi4/psi4/pull/2533#issuecomment-1089317532:112,Safety,redund,redundant,112,"> ah, was this choking in `OEProp` when you pushed an EOM wfn? or was it computing properly and just giving the redundant name? regardless, good catch. Computing properly and not giving the expected `CCSD DIPOLE`. This led to an error when I fixed a bug in AJ's code. That should be fixed in the next `cc` series PR.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2533#issuecomment-1089317532
https://github.com/psi4/psi4/pull/2534#issuecomment-1090483411:155,Safety,safe,safely,155,"@loriab . Reverted the elimination of `title_`. Although I still don't believe it _should_ exist, we need more density matrix standardization before I can safely eliminate it, and I can't standardize density matrices until after this PR is in.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2534#issuecomment-1090483411
https://github.com/psi4/psi4/issues/2535#issuecomment-1092277160:1446,Security,Access,Access,1446,"ties/input.py; @@ -43,6 +43,9 @@ json_data = {; },; ""keywords"": {""scf_type"": ""df"",; ""mp2_type"": ""df"",; + ""function_kwargs"": {; + ""properties"": [""DIPOLE_POLARIZABILITIES"", ""dipole"", ""quadrupole"", ""mulliken_charges"", ""lowdin_charges"", ""wiberg_lowdin_indices"", ""mayer_indices""],; + },; ""e_convergence"": 9}; }; import copy; @@ -146,6 +149,8 @@ expected_return_result[""wiberg_lowdin_indices""] = np.array(expected_return_resul; expected_return_result[""mayer_indices""] = np.array(expected_return_result[""mayer_indices""]).reshape((3, 3)); ; json_ret = psi4.json_wrapper.run_qcschema(json_data).dict(); +import pprint; +pprint.pprint(json_ret, width=200); ; # can't write msgpack arrays to json; ; @@ -156,3 +161,5 @@ for k in expected_return_result.keys():; ; for k in expected_properties.keys(): #TEST; psi4.compare_values(expected_properties[k], json_ret[""properties""][k], 5, k.upper()) #TEST; +; +print(json_ret[""extras""][""qcvars""][""DIPOLE POLARIZABILITY XX""]); ```; * (2) Access the results afterwards in the AtomicResult through `print(json_ret[""extras""][""qcvars""][""DIPOLE POLARIZABILITY XX""])` and similarly for other 8 components. Bad news: as you see, none of that specification was intuitive or in line with other properties, the polarizability wasn't in return_result like other properties, and polarizabilities missed the boat when multipoles got converted to single arrays from multiple scalars. This could clearly use some cleanup, so please leave the issue open. ----; running the schema-1-properties test with mods above now ends with:. ```; '\n'; ' ==> Response Properties <==\n'; '\n'; ' => Dipole polarizabilities <=\n'; '\n'; ' X Y Z \n'; ' ----- ---------- ---------- ----------\n'; ' X 1.32497 -0.00000 -0.00000\n'; ' Y -0.00000 7.67620 0.00000\n'; ' Z -0.00000 -0.00000 4.87695\n'; '\n'; '*** tstop() called on psinet at Thu Apr 7 18:34:48 2022\n'; 'Module time:\n'; '\tuser time = 0.24 seconds = 0.00 minutes\n'; '\tsystem time = 0.01 seconds = 0.00 minutes\n'; '\ttotal time = 0 second",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2535#issuecomment-1092277160
https://github.com/psi4/psi4/issues/2535#issuecomment-1092277160:285,Testability,test,tests,285,"Thanks for the report. Good news: what you want can be done without altering the code:. * (1) place _all_ the properties you want, including dipole polarizability into a list under `AtomicInput.keywords[""function_kwargs""][""properties""]` like in the first bit below:. ```; diff --git a/tests/json/schema-1-properties/input.py b/tests/json/schema-1-properties/input.py; index b7c1657..7389d88 100644; --- a/tests/json/schema-1-properties/input.py; +++ b/tests/json/schema-1-properties/input.py; @@ -43,6 +43,9 @@ json_data = {; },; ""keywords"": {""scf_type"": ""df"",; ""mp2_type"": ""df"",; + ""function_kwargs"": {; + ""properties"": [""DIPOLE_POLARIZABILITIES"", ""dipole"", ""quadrupole"", ""mulliken_charges"", ""lowdin_charges"", ""wiberg_lowdin_indices"", ""mayer_indices""],; + },; ""e_convergence"": 9}; }; import copy; @@ -146,6 +149,8 @@ expected_return_result[""wiberg_lowdin_indices""] = np.array(expected_return_resul; expected_return_result[""mayer_indices""] = np.array(expected_return_result[""mayer_indices""]).reshape((3, 3)); ; json_ret = psi4.json_wrapper.run_qcschema(json_data).dict(); +import pprint; +pprint.pprint(json_ret, width=200); ; # can't write msgpack arrays to json; ; @@ -156,3 +161,5 @@ for k in expected_return_result.keys():; ; for k in expected_properties.keys(): #TEST; psi4.compare_values(expected_properties[k], json_ret[""properties""][k], 5, k.upper()) #TEST; +; +print(json_ret[""extras""][""qcvars""][""DIPOLE POLARIZABILITY XX""]); ```; * (2) Access the results afterwards in the AtomicResult through `print(json_ret[""extras""][""qcvars""][""DIPOLE POLARIZABILITY XX""])` and similarly for other 8 components. Bad news: as you see, none of that specification was intuitive or in line with other properties, the polarizability wasn't in return_result like other properties, and polarizabilities missed the boat when multipoles got converted to single arrays from multiple scalars. This could clearly use some cleanup, so please leave the issue open. ----; running the schema-1-properties test with mods a",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2535#issuecomment-1092277160
https://github.com/psi4/psi4/issues/2535#issuecomment-1092277160:327,Testability,test,tests,327,"Thanks for the report. Good news: what you want can be done without altering the code:. * (1) place _all_ the properties you want, including dipole polarizability into a list under `AtomicInput.keywords[""function_kwargs""][""properties""]` like in the first bit below:. ```; diff --git a/tests/json/schema-1-properties/input.py b/tests/json/schema-1-properties/input.py; index b7c1657..7389d88 100644; --- a/tests/json/schema-1-properties/input.py; +++ b/tests/json/schema-1-properties/input.py; @@ -43,6 +43,9 @@ json_data = {; },; ""keywords"": {""scf_type"": ""df"",; ""mp2_type"": ""df"",; + ""function_kwargs"": {; + ""properties"": [""DIPOLE_POLARIZABILITIES"", ""dipole"", ""quadrupole"", ""mulliken_charges"", ""lowdin_charges"", ""wiberg_lowdin_indices"", ""mayer_indices""],; + },; ""e_convergence"": 9}; }; import copy; @@ -146,6 +149,8 @@ expected_return_result[""wiberg_lowdin_indices""] = np.array(expected_return_resul; expected_return_result[""mayer_indices""] = np.array(expected_return_result[""mayer_indices""]).reshape((3, 3)); ; json_ret = psi4.json_wrapper.run_qcschema(json_data).dict(); +import pprint; +pprint.pprint(json_ret, width=200); ; # can't write msgpack arrays to json; ; @@ -156,3 +161,5 @@ for k in expected_return_result.keys():; ; for k in expected_properties.keys(): #TEST; psi4.compare_values(expected_properties[k], json_ret[""properties""][k], 5, k.upper()) #TEST; +; +print(json_ret[""extras""][""qcvars""][""DIPOLE POLARIZABILITY XX""]); ```; * (2) Access the results afterwards in the AtomicResult through `print(json_ret[""extras""][""qcvars""][""DIPOLE POLARIZABILITY XX""])` and similarly for other 8 components. Bad news: as you see, none of that specification was intuitive or in line with other properties, the polarizability wasn't in return_result like other properties, and polarizabilities missed the boat when multipoles got converted to single arrays from multiple scalars. This could clearly use some cleanup, so please leave the issue open. ----; running the schema-1-properties test with mods a",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2535#issuecomment-1092277160
https://github.com/psi4/psi4/issues/2535#issuecomment-1092277160:405,Testability,test,tests,405,"Thanks for the report. Good news: what you want can be done without altering the code:. * (1) place _all_ the properties you want, including dipole polarizability into a list under `AtomicInput.keywords[""function_kwargs""][""properties""]` like in the first bit below:. ```; diff --git a/tests/json/schema-1-properties/input.py b/tests/json/schema-1-properties/input.py; index b7c1657..7389d88 100644; --- a/tests/json/schema-1-properties/input.py; +++ b/tests/json/schema-1-properties/input.py; @@ -43,6 +43,9 @@ json_data = {; },; ""keywords"": {""scf_type"": ""df"",; ""mp2_type"": ""df"",; + ""function_kwargs"": {; + ""properties"": [""DIPOLE_POLARIZABILITIES"", ""dipole"", ""quadrupole"", ""mulliken_charges"", ""lowdin_charges"", ""wiberg_lowdin_indices"", ""mayer_indices""],; + },; ""e_convergence"": 9}; }; import copy; @@ -146,6 +149,8 @@ expected_return_result[""wiberg_lowdin_indices""] = np.array(expected_return_resul; expected_return_result[""mayer_indices""] = np.array(expected_return_result[""mayer_indices""]).reshape((3, 3)); ; json_ret = psi4.json_wrapper.run_qcschema(json_data).dict(); +import pprint; +pprint.pprint(json_ret, width=200); ; # can't write msgpack arrays to json; ; @@ -156,3 +161,5 @@ for k in expected_return_result.keys():; ; for k in expected_properties.keys(): #TEST; psi4.compare_values(expected_properties[k], json_ret[""properties""][k], 5, k.upper()) #TEST; +; +print(json_ret[""extras""][""qcvars""][""DIPOLE POLARIZABILITY XX""]); ```; * (2) Access the results afterwards in the AtomicResult through `print(json_ret[""extras""][""qcvars""][""DIPOLE POLARIZABILITY XX""])` and similarly for other 8 components. Bad news: as you see, none of that specification was intuitive or in line with other properties, the polarizability wasn't in return_result like other properties, and polarizabilities missed the boat when multipoles got converted to single arrays from multiple scalars. This could clearly use some cleanup, so please leave the issue open. ----; running the schema-1-properties test with mods a",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2535#issuecomment-1092277160
https://github.com/psi4/psi4/issues/2535#issuecomment-1092277160:452,Testability,test,tests,452,"Thanks for the report. Good news: what you want can be done without altering the code:. * (1) place _all_ the properties you want, including dipole polarizability into a list under `AtomicInput.keywords[""function_kwargs""][""properties""]` like in the first bit below:. ```; diff --git a/tests/json/schema-1-properties/input.py b/tests/json/schema-1-properties/input.py; index b7c1657..7389d88 100644; --- a/tests/json/schema-1-properties/input.py; +++ b/tests/json/schema-1-properties/input.py; @@ -43,6 +43,9 @@ json_data = {; },; ""keywords"": {""scf_type"": ""df"",; ""mp2_type"": ""df"",; + ""function_kwargs"": {; + ""properties"": [""DIPOLE_POLARIZABILITIES"", ""dipole"", ""quadrupole"", ""mulliken_charges"", ""lowdin_charges"", ""wiberg_lowdin_indices"", ""mayer_indices""],; + },; ""e_convergence"": 9}; }; import copy; @@ -146,6 +149,8 @@ expected_return_result[""wiberg_lowdin_indices""] = np.array(expected_return_resul; expected_return_result[""mayer_indices""] = np.array(expected_return_result[""mayer_indices""]).reshape((3, 3)); ; json_ret = psi4.json_wrapper.run_qcschema(json_data).dict(); +import pprint; +pprint.pprint(json_ret, width=200); ; # can't write msgpack arrays to json; ; @@ -156,3 +161,5 @@ for k in expected_return_result.keys():; ; for k in expected_properties.keys(): #TEST; psi4.compare_values(expected_properties[k], json_ret[""properties""][k], 5, k.upper()) #TEST; +; +print(json_ret[""extras""][""qcvars""][""DIPOLE POLARIZABILITY XX""]); ```; * (2) Access the results afterwards in the AtomicResult through `print(json_ret[""extras""][""qcvars""][""DIPOLE POLARIZABILITY XX""])` and similarly for other 8 components. Bad news: as you see, none of that specification was intuitive or in line with other properties, the polarizability wasn't in return_result like other properties, and polarizabilities missed the boat when multipoles got converted to single arrays from multiple scalars. This could clearly use some cleanup, so please leave the issue open. ----; running the schema-1-properties test with mods a",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2535#issuecomment-1092277160
https://github.com/psi4/psi4/issues/2535#issuecomment-1092277160:1268,Testability,TEST,TEST,1268,"`; diff --git a/tests/json/schema-1-properties/input.py b/tests/json/schema-1-properties/input.py; index b7c1657..7389d88 100644; --- a/tests/json/schema-1-properties/input.py; +++ b/tests/json/schema-1-properties/input.py; @@ -43,6 +43,9 @@ json_data = {; },; ""keywords"": {""scf_type"": ""df"",; ""mp2_type"": ""df"",; + ""function_kwargs"": {; + ""properties"": [""DIPOLE_POLARIZABILITIES"", ""dipole"", ""quadrupole"", ""mulliken_charges"", ""lowdin_charges"", ""wiberg_lowdin_indices"", ""mayer_indices""],; + },; ""e_convergence"": 9}; }; import copy; @@ -146,6 +149,8 @@ expected_return_result[""wiberg_lowdin_indices""] = np.array(expected_return_resul; expected_return_result[""mayer_indices""] = np.array(expected_return_result[""mayer_indices""]).reshape((3, 3)); ; json_ret = psi4.json_wrapper.run_qcschema(json_data).dict(); +import pprint; +pprint.pprint(json_ret, width=200); ; # can't write msgpack arrays to json; ; @@ -156,3 +161,5 @@ for k in expected_return_result.keys():; ; for k in expected_properties.keys(): #TEST; psi4.compare_values(expected_properties[k], json_ret[""properties""][k], 5, k.upper()) #TEST; +; +print(json_ret[""extras""][""qcvars""][""DIPOLE POLARIZABILITY XX""]); ```; * (2) Access the results afterwards in the AtomicResult through `print(json_ret[""extras""][""qcvars""][""DIPOLE POLARIZABILITY XX""])` and similarly for other 8 components. Bad news: as you see, none of that specification was intuitive or in line with other properties, the polarizability wasn't in return_result like other properties, and polarizabilities missed the boat when multipoles got converted to single arrays from multiple scalars. This could clearly use some cleanup, so please leave the issue open. ----; running the schema-1-properties test with mods above now ends with:. ```; '\n'; ' ==> Response Properties <==\n'; '\n'; ' => Dipole polarizabilities <=\n'; '\n'; ' X Y Z \n'; ' ----- ---------- ---------- ----------\n'; ' X 1.32497 -0.00000 -0.00000\n'; ' Y -0.00000 7.67620 0.00000\n'; ' Z -0.00000 -0.00000 4.87695",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2535#issuecomment-1092277160
https://github.com/psi4/psi4/issues/2535#issuecomment-1092277160:1360,Testability,TEST,TEST,1360,"ties/input.py; @@ -43,6 +43,9 @@ json_data = {; },; ""keywords"": {""scf_type"": ""df"",; ""mp2_type"": ""df"",; + ""function_kwargs"": {; + ""properties"": [""DIPOLE_POLARIZABILITIES"", ""dipole"", ""quadrupole"", ""mulliken_charges"", ""lowdin_charges"", ""wiberg_lowdin_indices"", ""mayer_indices""],; + },; ""e_convergence"": 9}; }; import copy; @@ -146,6 +149,8 @@ expected_return_result[""wiberg_lowdin_indices""] = np.array(expected_return_resul; expected_return_result[""mayer_indices""] = np.array(expected_return_result[""mayer_indices""]).reshape((3, 3)); ; json_ret = psi4.json_wrapper.run_qcschema(json_data).dict(); +import pprint; +pprint.pprint(json_ret, width=200); ; # can't write msgpack arrays to json; ; @@ -156,3 +161,5 @@ for k in expected_return_result.keys():; ; for k in expected_properties.keys(): #TEST; psi4.compare_values(expected_properties[k], json_ret[""properties""][k], 5, k.upper()) #TEST; +; +print(json_ret[""extras""][""qcvars""][""DIPOLE POLARIZABILITY XX""]); ```; * (2) Access the results afterwards in the AtomicResult through `print(json_ret[""extras""][""qcvars""][""DIPOLE POLARIZABILITY XX""])` and similarly for other 8 components. Bad news: as you see, none of that specification was intuitive or in line with other properties, the polarizability wasn't in return_result like other properties, and polarizabilities missed the boat when multipoles got converted to single arrays from multiple scalars. This could clearly use some cleanup, so please leave the issue open. ----; running the schema-1-properties test with mods above now ends with:. ```; '\n'; ' ==> Response Properties <==\n'; '\n'; ' => Dipole polarizabilities <=\n'; '\n'; ' X Y Z \n'; ' ----- ---------- ---------- ----------\n'; ' X 1.32497 -0.00000 -0.00000\n'; ' Y -0.00000 7.67620 0.00000\n'; ' Z -0.00000 -0.00000 4.87695\n'; '\n'; '*** tstop() called on psinet at Thu Apr 7 18:34:48 2022\n'; 'Module time:\n'; '\tuser time = 0.24 seconds = 0.00 minutes\n'; '\tsystem time = 0.01 seconds = 0.00 minutes\n'; '\ttotal time = 0 second",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2535#issuecomment-1092277160
https://github.com/psi4/psi4/issues/2535#issuecomment-1092277160:1985,Testability,test,test,1985,"dices""]).reshape((3, 3)); ; json_ret = psi4.json_wrapper.run_qcschema(json_data).dict(); +import pprint; +pprint.pprint(json_ret, width=200); ; # can't write msgpack arrays to json; ; @@ -156,3 +161,5 @@ for k in expected_return_result.keys():; ; for k in expected_properties.keys(): #TEST; psi4.compare_values(expected_properties[k], json_ret[""properties""][k], 5, k.upper()) #TEST; +; +print(json_ret[""extras""][""qcvars""][""DIPOLE POLARIZABILITY XX""]); ```; * (2) Access the results afterwards in the AtomicResult through `print(json_ret[""extras""][""qcvars""][""DIPOLE POLARIZABILITY XX""])` and similarly for other 8 components. Bad news: as you see, none of that specification was intuitive or in line with other properties, the polarizability wasn't in return_result like other properties, and polarizabilities missed the boat when multipoles got converted to single arrays from multiple scalars. This could clearly use some cleanup, so please leave the issue open. ----; running the schema-1-properties test with mods above now ends with:. ```; '\n'; ' ==> Response Properties <==\n'; '\n'; ' => Dipole polarizabilities <=\n'; '\n'; ' X Y Z \n'; ' ----- ---------- ---------- ----------\n'; ' X 1.32497 -0.00000 -0.00000\n'; ' Y -0.00000 7.67620 0.00000\n'; ' Z -0.00000 -0.00000 4.87695\n'; '\n'; '*** tstop() called on psinet at Thu Apr 7 18:34:48 2022\n'; 'Module time:\n'; '\tuser time = 0.24 seconds = 0.00 minutes\n'; '\tsystem time = 0.01 seconds = 0.00 minutes\n'; '\ttotal time = 0 seconds = 0.00 minutes\n'; 'Total time:\n'; '\tuser time = 0.53 seconds = 0.01 minutes\n'; '\tsystem time = 0.02 seconds = 0.00 minutes\n'; '\ttotal time = 1 seconds = 0.02 minutes\n'; '\n'; ' Psi4 stopped on: Thursday, 07 April 2022 06:34PM\n'; ' Psi4 wall time for execution: 0:00:00.24\n'; '\n'; '*** Psi4 exiting successfully. Buy a developer a beer!\n',; 'success': True,; 'wavefunction': None}; JSON Success..........................................................................PASSED; Schema Name.....",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2535#issuecomment-1092277160
https://github.com/psi4/psi4/issues/2535#issuecomment-1092277160:1661,Usability,intuit,intuitive,1661,"_indices""],; + },; ""e_convergence"": 9}; }; import copy; @@ -146,6 +149,8 @@ expected_return_result[""wiberg_lowdin_indices""] = np.array(expected_return_resul; expected_return_result[""mayer_indices""] = np.array(expected_return_result[""mayer_indices""]).reshape((3, 3)); ; json_ret = psi4.json_wrapper.run_qcschema(json_data).dict(); +import pprint; +pprint.pprint(json_ret, width=200); ; # can't write msgpack arrays to json; ; @@ -156,3 +161,5 @@ for k in expected_return_result.keys():; ; for k in expected_properties.keys(): #TEST; psi4.compare_values(expected_properties[k], json_ret[""properties""][k], 5, k.upper()) #TEST; +; +print(json_ret[""extras""][""qcvars""][""DIPOLE POLARIZABILITY XX""]); ```; * (2) Access the results afterwards in the AtomicResult through `print(json_ret[""extras""][""qcvars""][""DIPOLE POLARIZABILITY XX""])` and similarly for other 8 components. Bad news: as you see, none of that specification was intuitive or in line with other properties, the polarizability wasn't in return_result like other properties, and polarizabilities missed the boat when multipoles got converted to single arrays from multiple scalars. This could clearly use some cleanup, so please leave the issue open. ----; running the schema-1-properties test with mods above now ends with:. ```; '\n'; ' ==> Response Properties <==\n'; '\n'; ' => Dipole polarizabilities <=\n'; '\n'; ' X Y Z \n'; ' ----- ---------- ---------- ----------\n'; ' X 1.32497 -0.00000 -0.00000\n'; ' Y -0.00000 7.67620 0.00000\n'; ' Z -0.00000 -0.00000 4.87695\n'; '\n'; '*** tstop() called on psinet at Thu Apr 7 18:34:48 2022\n'; 'Module time:\n'; '\tuser time = 0.24 seconds = 0.00 minutes\n'; '\tsystem time = 0.01 seconds = 0.00 minutes\n'; '\ttotal time = 0 seconds = 0.00 minutes\n'; 'Total time:\n'; '\tuser time = 0.53 seconds = 0.01 minutes\n'; '\tsystem time = 0.02 seconds = 0.00 minutes\n'; '\ttotal time = 1 seconds = 0.02 minutes\n'; '\n'; ' Psi4 stopped on: Thursday, 07 April 2022 06:34PM\n'; ' Psi4 wall time for ex",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2535#issuecomment-1092277160
https://github.com/psi4/psi4/issues/2535#issuecomment-1092277160:1889,Usability,clear,clearly,1889,"turn_result[""mayer_indices""] = np.array(expected_return_result[""mayer_indices""]).reshape((3, 3)); ; json_ret = psi4.json_wrapper.run_qcschema(json_data).dict(); +import pprint; +pprint.pprint(json_ret, width=200); ; # can't write msgpack arrays to json; ; @@ -156,3 +161,5 @@ for k in expected_return_result.keys():; ; for k in expected_properties.keys(): #TEST; psi4.compare_values(expected_properties[k], json_ret[""properties""][k], 5, k.upper()) #TEST; +; +print(json_ret[""extras""][""qcvars""][""DIPOLE POLARIZABILITY XX""]); ```; * (2) Access the results afterwards in the AtomicResult through `print(json_ret[""extras""][""qcvars""][""DIPOLE POLARIZABILITY XX""])` and similarly for other 8 components. Bad news: as you see, none of that specification was intuitive or in line with other properties, the polarizability wasn't in return_result like other properties, and polarizabilities missed the boat when multipoles got converted to single arrays from multiple scalars. This could clearly use some cleanup, so please leave the issue open. ----; running the schema-1-properties test with mods above now ends with:. ```; '\n'; ' ==> Response Properties <==\n'; '\n'; ' => Dipole polarizabilities <=\n'; '\n'; ' X Y Z \n'; ' ----- ---------- ---------- ----------\n'; ' X 1.32497 -0.00000 -0.00000\n'; ' Y -0.00000 7.67620 0.00000\n'; ' Z -0.00000 -0.00000 4.87695\n'; '\n'; '*** tstop() called on psinet at Thu Apr 7 18:34:48 2022\n'; 'Module time:\n'; '\tuser time = 0.24 seconds = 0.00 minutes\n'; '\tsystem time = 0.01 seconds = 0.00 minutes\n'; '\ttotal time = 0 seconds = 0.00 minutes\n'; 'Total time:\n'; '\tuser time = 0.53 seconds = 0.01 minutes\n'; '\tsystem time = 0.02 seconds = 0.00 minutes\n'; '\ttotal time = 1 seconds = 0.02 minutes\n'; '\n'; ' Psi4 stopped on: Thursday, 07 April 2022 06:34PM\n'; ' Psi4 wall time for execution: 0:00:00.24\n'; '\n'; '*** Psi4 exiting successfully. Buy a developer a beer!\n',; 'success': True,; 'wavefunction': None}; JSON Success..........................",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2535#issuecomment-1092277160
https://github.com/psi4/psi4/pull/2536#issuecomment-1092773416:0,Availability,Ping,Ping,0,"Ping me when merge conflicts are fixed, and I'll review it.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2536#issuecomment-1092773416
https://github.com/psi4/psi4/pull/2536#issuecomment-1092933878:20,Availability,repair,repaired,20,"merge conflicts now repaired, @JonathonMisiewicz",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2536#issuecomment-1092933878
https://github.com/psi4/psi4/pull/2537#issuecomment-1092760393:8,Availability,failure,failures,8,The DFT failures are almost certainly because of Gau2Grid using the wrong ordering convention. Thankfully [CCA is supported](https://github.com/dgasmith/gau2grid/blob/master/docs/source/order.rst#spherical-order) so it should be fixable by a simple reconfiguration.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2537#issuecomment-1092760393
https://github.com/psi4/psi4/pull/2537#issuecomment-1092760393:242,Usability,simpl,simple,242,The DFT failures are almost certainly because of Gau2Grid using the wrong ordering convention. Thankfully [CCA is supported](https://github.com/dgasmith/gau2grid/blob/master/docs/source/order.rst#spherical-order) so it should be fixable by a simple reconfiguration.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2537#issuecomment-1092760393
https://github.com/psi4/psi4/pull/2537#issuecomment-1092773639:309,Testability,test,tests,309,"> For g2g, maybe just [this](https://github.com/psi4/psi4/blob/d9093c75c71c2b33fbe86f32b25d138675ac22eb/psi4/src/psi4/libfock/points.cc#L767) line needs to be changed?. That looks exactly right to me - good call. Switching `GG_SPHERICAL_GAUSSIAN` to `GG_SPHERICAL_CCA` should be all that's needed for the DFT tests.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2537#issuecomment-1092773639
https://github.com/psi4/psi4/pull/2537#issuecomment-1092824100:229,Testability,test,tests,229,"> For g2g, maybe just [this](https://github.com/psi4/psi4/blob/d9093c75c71c2b33fbe86f32b25d138675ac22eb/psi4/src/psi4/libfock/points.cc#L767) line needs to be changed?. Confirmed to work locally. This fixes *a lot* of the failed tests above ",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2537#issuecomment-1092824100
https://github.com/psi4/psi4/pull/2537#issuecomment-1133519662:342,Availability,toler,tolerate,342,"I don't comment here all that often anymore, which is bittersweet (and I very much miss both my colleagues on PSI4 and the Vortex). We have gone through my old notes on CCA (sketch at best, we know), and many nested references therein. For Cartesian AOs, CCA matters - this lets you use a single normalization coefficient for everything, and tolerate non-normalized off-diagonal cartesian tensor components (i.e, xx is normalized in D, xy is not normalized in D, xxx is normalized in F, xxy or xyz is not normalized in F) - Jet taught me this and it is one of the coolest tricks in the book. For spherical AOs, as far as we can tell, there is *no* CCA convention except that everything be normalized (as literally all codes do). The one ""CCA"" paper we can find on this topic itself glancingly cites an older Schlegel / Frisch paper (I think before the big happening), which itself is outdated by about > two dozen articles on solid harmonics. Everyone who codes integrals deals with basis ordering - what you shudder about is weird normalization factors (particularly non-diagonal ones), not rigid permutations. . The message is this: I am not convinced there is a standard. So maybe not optimal to follow to follow an implied one. Show me a reference of a real, used standard, and Lightspeed and Tachyon will be there tomorrow. . [report (7).pdf](https://github.com/psi4/psi4/files/8746880/report.7.pdf); [jcc.20815.pdf](https://github.com/psi4/psi4/files/8746882/jcc.20815.pdf); [sh.pdf](https://github.com/psi4/psi4/files/8746881/sh.pdf)",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2537#issuecomment-1133519662
https://github.com/psi4/psi4/pull/2537#issuecomment-1133519662:1118,Integrability,message,message,1118,"I don't comment here all that often anymore, which is bittersweet (and I very much miss both my colleagues on PSI4 and the Vortex). We have gone through my old notes on CCA (sketch at best, we know), and many nested references therein. For Cartesian AOs, CCA matters - this lets you use a single normalization coefficient for everything, and tolerate non-normalized off-diagonal cartesian tensor components (i.e, xx is normalized in D, xy is not normalized in D, xxx is normalized in F, xxy or xyz is not normalized in F) - Jet taught me this and it is one of the coolest tricks in the book. For spherical AOs, as far as we can tell, there is *no* CCA convention except that everything be normalized (as literally all codes do). The one ""CCA"" paper we can find on this topic itself glancingly cites an older Schlegel / Frisch paper (I think before the big happening), which itself is outdated by about > two dozen articles on solid harmonics. Everyone who codes integrals deals with basis ordering - what you shudder about is weird normalization factors (particularly non-diagonal ones), not rigid permutations. . The message is this: I am not convinced there is a standard. So maybe not optimal to follow to follow an implied one. Show me a reference of a real, used standard, and Lightspeed and Tachyon will be there tomorrow. . [report (7).pdf](https://github.com/psi4/psi4/files/8746880/report.7.pdf); [jcc.20815.pdf](https://github.com/psi4/psi4/files/8746882/jcc.20815.pdf); [sh.pdf](https://github.com/psi4/psi4/files/8746881/sh.pdf)",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2537#issuecomment-1133519662
https://github.com/psi4/psi4/pull/2541#issuecomment-1094422746:2016,Modifiability,refactor,refactoring,2016,"rs thoughts?. I hope you know what you're asking for. Storage of ground-state densities is lawless, let alone excited-state densities. For excited-state densities...; * ADC won't export densities of any sort.; * TD-DFT will save left and right eigenvectors. From my (very shaky) knowledge of TD-DFT theory, those are left and right transition densities.; * EOM-CC creates but will not save its left and right transition densities. Before this PR, it would write excited state densities to the wavefunction. (In the current version of the PR, it still does). For ground-state densities...; * For fully variational methods (including in orbitals), the density of the correlated method is unambiguous and saved to the wavefunction.; * For methods that are not fully variational, you have orbital-relaxed and orbital-unrelaxed densities. If orbital relaxation is not needed, this density may or may not get saved to the wavefunction. If it is not saved, the density is probably still the SCF density.; * Some methods have it even worse. For example, ODC-12 with perturbative lambda has _three conceivable densities_. ODC-12 density, ODC-12 density + perturbative lambda, and ODC-12 + perturbative lambda + orbital relaxtion.; * CAS-DMRG-PT2 through the `dmrg` module saves the DMRG density to the wavefunction, which is not the DMRGPT2 density.; * If the user requests a spin-scaled density, the standard densities need to be further monkeyed with to be correct in gradients. I don't know if this is actually done. I suspect it is not. And to represent all that, the current tools we have are `Da`, `Db`, and the pool of psivars. I'm in favor of deprecating `Da` and `Db` for anything other than internal SCF use and creating a new wavefunction member to store all the densities, _with proper labeling_. This will of course be a lot of code refactoring, but that is quite literally the entire point of me doing all this `cc` PRs. And of course, somebody will need to tell `dfocc` about this API change. ",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2541#issuecomment-1094422746
https://github.com/psi4/psi4/pull/2541#issuecomment-1094491672:848,Energy Efficiency,charge,charges,848,"> I'm in favor of deprecating Da and Db for anything other than internal SCF use and creating a new wavefunction member to store all the densities, with proper labeling. This will of course be a lot of code refactoring, but that is quite literally the entire point of me doing all this cc PRs. And of course, somebody will need to tell dfocc about this API change. . Thanks for the enumeration of the organizational state of all the densities. The new Wfn member for finalized, labeled densities sounds good to me. Are the ES CC densities ready for that state yet, or are they still in preparation? For any that are still in preparation but still in need of saving, I guess I propose a temporary member of Wfn that is marked as having a finite lifetime. Same as Wfn.arrays, just not Wfn.arrays :-) Ben's already nervous about storing the per-atom charges that end up in qcvars, so I'm just not in favor of densities there.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2541#issuecomment-1094491672
https://github.com/psi4/psi4/pull/2541#issuecomment-1094491672:207,Modifiability,refactor,refactoring,207,"> I'm in favor of deprecating Da and Db for anything other than internal SCF use and creating a new wavefunction member to store all the densities, with proper labeling. This will of course be a lot of code refactoring, but that is quite literally the entire point of me doing all this cc PRs. And of course, somebody will need to tell dfocc about this API change. . Thanks for the enumeration of the organizational state of all the densities. The new Wfn member for finalized, labeled densities sounds good to me. Are the ES CC densities ready for that state yet, or are they still in preparation? For any that are still in preparation but still in need of saving, I guess I propose a temporary member of Wfn that is marked as having a finite lifetime. Same as Wfn.arrays, just not Wfn.arrays :-) Ben's already nervous about storing the per-atom charges that end up in qcvars, so I'm just not in favor of densities there.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2541#issuecomment-1094491672
https://github.com/psi4/psi4/pull/2541#issuecomment-1094494232:329,Testability,test,test,329,"The CC excited state densities are most definitely correct. If they _weren't_, EOM analytic gradients would be wrong, and `cc23` would fail. I would expect that correctness is enough to finalize these, but I defer to our resident Crawdad on this. I don't know whether the transition densities pass some kind of finite difference test, but I am prepared to save that question for another day.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2541#issuecomment-1094494232
https://github.com/psi4/psi4/pull/2541#issuecomment-1094517187:57,Testability,test,test,57,"Can you clarify what you mean about a ""finite difference test"" for the transition densities?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2541#issuecomment-1094517187
https://github.com/psi4/psi4/pull/2541#issuecomment-1094528284:384,Availability,error,error,384,"By finite-difference test, I mean ""there is some property that we can compute either by finite difference of energies or by contracting appropriately defined densities against derivative integrals,"" e.g., geometry gradients and dipoles. By checking that both routes predict the same result, we can be much more confident that the densities are correctly implemented. (I recall a sign error in the CASPT2 gradients of another package. This error went uncaught for decades because the impact on calculations was relatively small.). I don't know if this is an option for transition densities. I'm not sure if EOM-CC transition properties are defined by some variational criteria, some variational criteria but neglecting orbital relaxation, or something else altogether. EDIT: The '93 Stanton and Bartlett paper explicitly says orbital relaxation is neglected, so I imagine the finite difference test is not an option. I'm not sure if there's some other technique to validate the correctness of the transition densities, other than matching other code. I know ""matching other code"" is done in the test suite.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2541#issuecomment-1094528284
https://github.com/psi4/psi4/pull/2541#issuecomment-1094528284:439,Availability,error,error,439,"By finite-difference test, I mean ""there is some property that we can compute either by finite difference of energies or by contracting appropriately defined densities against derivative integrals,"" e.g., geometry gradients and dipoles. By checking that both routes predict the same result, we can be much more confident that the densities are correctly implemented. (I recall a sign error in the CASPT2 gradients of another package. This error went uncaught for decades because the impact on calculations was relatively small.). I don't know if this is an option for transition densities. I'm not sure if EOM-CC transition properties are defined by some variational criteria, some variational criteria but neglecting orbital relaxation, or something else altogether. EDIT: The '93 Stanton and Bartlett paper explicitly says orbital relaxation is neglected, so I imagine the finite difference test is not an option. I'm not sure if there's some other technique to validate the correctness of the transition densities, other than matching other code. I know ""matching other code"" is done in the test suite.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2541#issuecomment-1094528284
https://github.com/psi4/psi4/pull/2541#issuecomment-1094528284:124,Integrability,contract,contracting,124,"By finite-difference test, I mean ""there is some property that we can compute either by finite difference of energies or by contracting appropriately defined densities against derivative integrals,"" e.g., geometry gradients and dipoles. By checking that both routes predict the same result, we can be much more confident that the densities are correctly implemented. (I recall a sign error in the CASPT2 gradients of another package. This error went uncaught for decades because the impact on calculations was relatively small.). I don't know if this is an option for transition densities. I'm not sure if EOM-CC transition properties are defined by some variational criteria, some variational criteria but neglecting orbital relaxation, or something else altogether. EDIT: The '93 Stanton and Bartlett paper explicitly says orbital relaxation is neglected, so I imagine the finite difference test is not an option. I'm not sure if there's some other technique to validate the correctness of the transition densities, other than matching other code. I know ""matching other code"" is done in the test suite.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2541#issuecomment-1094528284
https://github.com/psi4/psi4/pull/2541#issuecomment-1094528284:259,Integrability,rout,routes,259,"By finite-difference test, I mean ""there is some property that we can compute either by finite difference of energies or by contracting appropriately defined densities against derivative integrals,"" e.g., geometry gradients and dipoles. By checking that both routes predict the same result, we can be much more confident that the densities are correctly implemented. (I recall a sign error in the CASPT2 gradients of another package. This error went uncaught for decades because the impact on calculations was relatively small.). I don't know if this is an option for transition densities. I'm not sure if EOM-CC transition properties are defined by some variational criteria, some variational criteria but neglecting orbital relaxation, or something else altogether. EDIT: The '93 Stanton and Bartlett paper explicitly says orbital relaxation is neglected, so I imagine the finite difference test is not an option. I'm not sure if there's some other technique to validate the correctness of the transition densities, other than matching other code. I know ""matching other code"" is done in the test suite.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2541#issuecomment-1094528284
https://github.com/psi4/psi4/pull/2541#issuecomment-1094528284:266,Safety,predict,predict,266,"By finite-difference test, I mean ""there is some property that we can compute either by finite difference of energies or by contracting appropriately defined densities against derivative integrals,"" e.g., geometry gradients and dipoles. By checking that both routes predict the same result, we can be much more confident that the densities are correctly implemented. (I recall a sign error in the CASPT2 gradients of another package. This error went uncaught for decades because the impact on calculations was relatively small.). I don't know if this is an option for transition densities. I'm not sure if EOM-CC transition properties are defined by some variational criteria, some variational criteria but neglecting orbital relaxation, or something else altogether. EDIT: The '93 Stanton and Bartlett paper explicitly says orbital relaxation is neglected, so I imagine the finite difference test is not an option. I'm not sure if there's some other technique to validate the correctness of the transition densities, other than matching other code. I know ""matching other code"" is done in the test suite.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2541#issuecomment-1094528284
https://github.com/psi4/psi4/pull/2541#issuecomment-1094528284:964,Security,validat,validate,964,"By finite-difference test, I mean ""there is some property that we can compute either by finite difference of energies or by contracting appropriately defined densities against derivative integrals,"" e.g., geometry gradients and dipoles. By checking that both routes predict the same result, we can be much more confident that the densities are correctly implemented. (I recall a sign error in the CASPT2 gradients of another package. This error went uncaught for decades because the impact on calculations was relatively small.). I don't know if this is an option for transition densities. I'm not sure if EOM-CC transition properties are defined by some variational criteria, some variational criteria but neglecting orbital relaxation, or something else altogether. EDIT: The '93 Stanton and Bartlett paper explicitly says orbital relaxation is neglected, so I imagine the finite difference test is not an option. I'm not sure if there's some other technique to validate the correctness of the transition densities, other than matching other code. I know ""matching other code"" is done in the test suite.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2541#issuecomment-1094528284
https://github.com/psi4/psi4/pull/2541#issuecomment-1094528284:21,Testability,test,test,21,"By finite-difference test, I mean ""there is some property that we can compute either by finite difference of energies or by contracting appropriately defined densities against derivative integrals,"" e.g., geometry gradients and dipoles. By checking that both routes predict the same result, we can be much more confident that the densities are correctly implemented. (I recall a sign error in the CASPT2 gradients of another package. This error went uncaught for decades because the impact on calculations was relatively small.). I don't know if this is an option for transition densities. I'm not sure if EOM-CC transition properties are defined by some variational criteria, some variational criteria but neglecting orbital relaxation, or something else altogether. EDIT: The '93 Stanton and Bartlett paper explicitly says orbital relaxation is neglected, so I imagine the finite difference test is not an option. I'm not sure if there's some other technique to validate the correctness of the transition densities, other than matching other code. I know ""matching other code"" is done in the test suite.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2541#issuecomment-1094528284
https://github.com/psi4/psi4/pull/2541#issuecomment-1094528284:893,Testability,test,test,893,"By finite-difference test, I mean ""there is some property that we can compute either by finite difference of energies or by contracting appropriately defined densities against derivative integrals,"" e.g., geometry gradients and dipoles. By checking that both routes predict the same result, we can be much more confident that the densities are correctly implemented. (I recall a sign error in the CASPT2 gradients of another package. This error went uncaught for decades because the impact on calculations was relatively small.). I don't know if this is an option for transition densities. I'm not sure if EOM-CC transition properties are defined by some variational criteria, some variational criteria but neglecting orbital relaxation, or something else altogether. EDIT: The '93 Stanton and Bartlett paper explicitly says orbital relaxation is neglected, so I imagine the finite difference test is not an option. I'm not sure if there's some other technique to validate the correctness of the transition densities, other than matching other code. I know ""matching other code"" is done in the test suite.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2541#issuecomment-1094528284
https://github.com/psi4/psi4/pull/2541#issuecomment-1094528284:1094,Testability,test,test,1094,"By finite-difference test, I mean ""there is some property that we can compute either by finite difference of energies or by contracting appropriately defined densities against derivative integrals,"" e.g., geometry gradients and dipoles. By checking that both routes predict the same result, we can be much more confident that the densities are correctly implemented. (I recall a sign error in the CASPT2 gradients of another package. This error went uncaught for decades because the impact on calculations was relatively small.). I don't know if this is an option for transition densities. I'm not sure if EOM-CC transition properties are defined by some variational criteria, some variational criteria but neglecting orbital relaxation, or something else altogether. EDIT: The '93 Stanton and Bartlett paper explicitly says orbital relaxation is neglected, so I imagine the finite difference test is not an option. I'm not sure if there's some other technique to validate the correctness of the transition densities, other than matching other code. I know ""matching other code"" is done in the test suite.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2541#issuecomment-1094528284
https://github.com/psi4/psi4/pull/2541#issuecomment-1094533852:62,Usability,clear,clearly,62,"OK, then we're on the same page. Transition properties aren't clearly defined as derivatives, so I don't see how a finite-difference approach can help in this case, but we might be able to identify some limiting cases. But I agree it can/should wait for another day.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2541#issuecomment-1094533852
https://github.com/psi4/psi4/pull/2541#issuecomment-1098334427:73,Availability,error,errors,73,"> I'm not really qualified to appraise this, but I don't see any obvious errors. Alas, nobody is fully qualified to appraise this. TDC knows the `cc` code and Lori knows psivars, but densities touch so many parts of the code that we'd need expertise in every single module, which we simply don't have. I won't be free to work on the next PR for a while, so we can leave this open to collect more comments.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2541#issuecomment-1098334427
https://github.com/psi4/psi4/pull/2541#issuecomment-1098334427:283,Usability,simpl,simply,283,"> I'm not really qualified to appraise this, but I don't see any obvious errors. Alas, nobody is fully qualified to appraise this. TDC knows the `cc` code and Lori knows psivars, but densities touch so many parts of the code that we'd need expertise in every single module, which we simply don't have. I won't be free to work on the next PR for a while, so we can leave this open to collect more comments.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2541#issuecomment-1098334427
https://github.com/psi4/psi4/pull/2543#issuecomment-1094954498:34,Testability,test,tests,34,"I will not review this until both tests pass and somebody from GATech (Zach, Lori, David Poole) does a thorough review pass. I have no strong opinion on whether this comes in for 1.6 or 1.7, but if this PR doesn't make 1.6, there needs to be a separate PR which implements the API changes. That PR _must_ come in for 1.6.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2543#issuecomment-1094954498
https://github.com/psi4/psi4/pull/2543#issuecomment-1095549080:58,Deployability,update,update,58,"Made all the necessary code changes. Have not had time to update docs yet (classes). Feel free to review the code, and I will update the docs tomorrow.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2543#issuecomment-1095549080
https://github.com/psi4/psi4/pull/2543#issuecomment-1095549080:126,Deployability,update,update,126,"Made all the necessary code changes. Have not had time to update docs yet (classes). Feel free to review the code, and I will update the docs tomorrow.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2543#issuecomment-1095549080
https://github.com/psi4/psi4/pull/2543#issuecomment-1096292699:0,Deployability,Update,Updated,0,"Updated the docs, please proceed with review @loriab @zachglick @davpoolechem",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2543#issuecomment-1096292699
https://github.com/psi4/psi4/pull/2543#issuecomment-1097060877:527,Modifiability,refactor,refactor,527,"> Nice work Andy! As I see it, this PR does three things:; > ; > 1. Adds a direct DFJ algorithm; > 2. Moves the LinK code out of the DirectJK class; > 3. Adds individual J/K classes in order to prevent future code duplication; > ; > Because these additions are fairly independent, I think it would be appropriate to break up this PR into two separate PRs. In the first PR, you do steps (1) and (2) by implementing a `DFJlinK` class which is derived from `JK`, just like all of the existing JK algorithms. In the second PR, you refactor the `DFJlinK` class so that it uses a `DFJ` and `LinK` class.; > ; > Also before any of this is done, I think it would be good to address the changes to density-screening we discussed last week. In the interest of minimizing the work of both me and the reviewers, I do _not_ think it would be a good idea to split this into two PRs, since it would involve adding a new JK class (`DFJLinK`), and then removing it, and then adding one again (`CompositeJK`). This would lead to a whole mess of merge conflicts, and involves me taking apart code that is 100% working, and then rewriting it. The second reason is that we already have reviews on CompositeJK, and to break this into two PRs at this point would also involve extra work for the core developers too. Comments on this are appreciated, but I feel __strongly__ about this opinion. On the other hand, I do agree that it would be good to discuss the density screening changes first before this PR is merged.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2543#issuecomment-1097060877
https://github.com/psi4/psi4/pull/2543#issuecomment-1097072812:436,Modifiability,refactor,refactoring,436,"> The second reason is that we already have reviews on CompositeJK, and to break this into two PRs at this point would also involve extra work for the core developers too. You have it backwards. Most of the work in PR reviewing is reading the code and figuring out what you're trying to do. Seeing ""oh, this is just moving code"" around is not work for me. Figuring out what parts of your PR are about Composite JK, what parts are about refactoring LinK, and what parts are about Direct-DF-J is a lot of work. Zach's plan does mean more work for you, but a smoother review process.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2543#issuecomment-1097072812
https://github.com/psi4/psi4/pull/2543#issuecomment-1097103857:445,Modifiability,refactor,refactoring,445,"> > The second reason is that we already have reviews on CompositeJK, and to break this into two PRs at this point would also involve extra work for the core developers too.; > ; > You have it backwards. Most of the work in PR reviewing is reading the code and figuring out what you're trying to do. Seeing ""oh, this is just moving code"" around is not work for me. Figuring out what parts of your PR are about Composite JK, what parts are about refactoring LinK, and what parts are about Direct-DF-J is a lot of work. Zach's plan does mean more work for you, but a smoother review process. I am still not willing to break this into two PRs (due to the fact that I am in finals season and do not have much time). However, what I can do, is point to which parts of the code involve refactoring the LinK, Direct-DF-J, and CompositeJK in the PR description.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2543#issuecomment-1097103857
https://github.com/psi4/psi4/pull/2543#issuecomment-1097103857:780,Modifiability,refactor,refactoring,780,"> > The second reason is that we already have reviews on CompositeJK, and to break this into two PRs at this point would also involve extra work for the core developers too.; > ; > You have it backwards. Most of the work in PR reviewing is reading the code and figuring out what you're trying to do. Seeing ""oh, this is just moving code"" around is not work for me. Figuring out what parts of your PR are about Composite JK, what parts are about refactoring LinK, and what parts are about Direct-DF-J is a lot of work. Zach's plan does mean more work for you, but a smoother review process. I am still not willing to break this into two PRs (due to the fact that I am in finals season and do not have much time). However, what I can do, is point to which parts of the code involve refactoring the LinK, Direct-DF-J, and CompositeJK in the PR description.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2543#issuecomment-1097103857
https://github.com/psi4/psi4/pull/2543#issuecomment-1129658643:74,Modifiability,refactor,refactor,74,"Now that seminumerical exchange is in, it would make more sense for me to refactor that code into this framework as well. Waiting on density screening refactor would also be helpful @davpoolechem",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2543#issuecomment-1129658643
https://github.com/psi4/psi4/pull/2543#issuecomment-1129658643:151,Modifiability,refactor,refactor,151,"Now that seminumerical exchange is in, it would make more sense for me to refactor that code into this framework as well. Waiting on density screening refactor would also be helpful @davpoolechem",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2543#issuecomment-1129658643
https://github.com/psi4/psi4/pull/2547#issuecomment-1112143902:149,Modifiability,variab,variable,149,"Details about how the integrals were computed should be the province of the JK object, not the HF wavefunction, so I disagree with creating this new variable as described. Can we instead have `computed_shells_per_iter_` on the JK object and query the JK object, after the HF, for test purposes?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2547#issuecomment-1112143902
https://github.com/psi4/psi4/pull/2547#issuecomment-1112143902:280,Testability,test,test,280,"Details about how the integrals were computed should be the province of the JK object, not the HF wavefunction, so I disagree with creating this new variable as described. Can we instead have `computed_shells_per_iter_` on the JK object and query the JK object, after the HF, for test purposes?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2547#issuecomment-1112143902
https://github.com/psi4/psi4/pull/2547#issuecomment-1112211696:151,Modifiability,variab,variable,151,"> Details about how the integrals were computed should be the province of the JK object, not the HF wavefunction, so I disagree with creating this new variable as described.; > ; > Can we instead have `computed_shells_per_iter_` on the JK object and query the JK object, after the HF, for test purposes?. That should definitely be doable! Give me a bit, and that change can be made.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2547#issuecomment-1112211696
https://github.com/psi4/psi4/pull/2547#issuecomment-1112211696:289,Testability,test,test,289,"> Details about how the integrals were computed should be the province of the JK object, not the HF wavefunction, so I disagree with creating this new variable as described.; > ; > Can we instead have `computed_shells_per_iter_` on the JK object and query the JK object, after the HF, for test purposes?. That should definitely be doable! Give me a bit, and that change can be made.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2547#issuecomment-1112211696
https://github.com/psi4/psi4/pull/2547#issuecomment-1152700048:212,Modifiability,extend,extend,212,"So I now realize something - we may want to apply some of the benchmarking changes made in this PR to DFJCOSK, as well. It will increase the size of the PR, but the benchmarking changes in this PR currently only extend to DirectJK at the moment. Since DFJCOSK has two methods that it separately benchmarks, it will require a bit of retooling regarding some of the internals of the benchmarking framework. It should not have a significant impact on test_erisieve, however. Thoughts?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2547#issuecomment-1152700048
https://github.com/psi4/psi4/pull/2547#issuecomment-1152700048:62,Testability,benchmark,benchmarking,62,"So I now realize something - we may want to apply some of the benchmarking changes made in this PR to DFJCOSK, as well. It will increase the size of the PR, but the benchmarking changes in this PR currently only extend to DirectJK at the moment. Since DFJCOSK has two methods that it separately benchmarks, it will require a bit of retooling regarding some of the internals of the benchmarking framework. It should not have a significant impact on test_erisieve, however. Thoughts?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2547#issuecomment-1152700048
https://github.com/psi4/psi4/pull/2547#issuecomment-1152700048:165,Testability,benchmark,benchmarking,165,"So I now realize something - we may want to apply some of the benchmarking changes made in this PR to DFJCOSK, as well. It will increase the size of the PR, but the benchmarking changes in this PR currently only extend to DirectJK at the moment. Since DFJCOSK has two methods that it separately benchmarks, it will require a bit of retooling regarding some of the internals of the benchmarking framework. It should not have a significant impact on test_erisieve, however. Thoughts?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2547#issuecomment-1152700048
https://github.com/psi4/psi4/pull/2547#issuecomment-1152700048:295,Testability,benchmark,benchmarks,295,"So I now realize something - we may want to apply some of the benchmarking changes made in this PR to DFJCOSK, as well. It will increase the size of the PR, but the benchmarking changes in this PR currently only extend to DirectJK at the moment. Since DFJCOSK has two methods that it separately benchmarks, it will require a bit of retooling regarding some of the internals of the benchmarking framework. It should not have a significant impact on test_erisieve, however. Thoughts?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2547#issuecomment-1152700048
https://github.com/psi4/psi4/pull/2547#issuecomment-1152700048:381,Testability,benchmark,benchmarking,381,"So I now realize something - we may want to apply some of the benchmarking changes made in this PR to DFJCOSK, as well. It will increase the size of the PR, but the benchmarking changes in this PR currently only extend to DirectJK at the moment. Since DFJCOSK has two methods that it separately benchmarks, it will require a bit of retooling regarding some of the internals of the benchmarking framework. It should not have a significant impact on test_erisieve, however. Thoughts?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2547#issuecomment-1152700048
https://github.com/psi4/psi4/pull/2547#issuecomment-1152702693:214,Modifiability,extend,extend,214,"> So I now realize something - we may want to apply some of the benchmarking changes made in this PR to DFJCOSK, as well. It will increase the size of the PR, but the benchmarking changes in this PR currently only extend to DirectJK at the moment. Since DFJCOSK has two methods that it separately benchmarks, it will require a bit of retooling regarding some of the internals of the benchmarking framework. It should not have a significant impact on test_erisieve, however. > Thoughts?. Unless the DFJCOSK changes would undo much of this PR, I think a follow-up PR would be best.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2547#issuecomment-1152702693
https://github.com/psi4/psi4/pull/2547#issuecomment-1152702693:64,Testability,benchmark,benchmarking,64,"> So I now realize something - we may want to apply some of the benchmarking changes made in this PR to DFJCOSK, as well. It will increase the size of the PR, but the benchmarking changes in this PR currently only extend to DirectJK at the moment. Since DFJCOSK has two methods that it separately benchmarks, it will require a bit of retooling regarding some of the internals of the benchmarking framework. It should not have a significant impact on test_erisieve, however. > Thoughts?. Unless the DFJCOSK changes would undo much of this PR, I think a follow-up PR would be best.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2547#issuecomment-1152702693
https://github.com/psi4/psi4/pull/2547#issuecomment-1152702693:167,Testability,benchmark,benchmarking,167,"> So I now realize something - we may want to apply some of the benchmarking changes made in this PR to DFJCOSK, as well. It will increase the size of the PR, but the benchmarking changes in this PR currently only extend to DirectJK at the moment. Since DFJCOSK has two methods that it separately benchmarks, it will require a bit of retooling regarding some of the internals of the benchmarking framework. It should not have a significant impact on test_erisieve, however. > Thoughts?. Unless the DFJCOSK changes would undo much of this PR, I think a follow-up PR would be best.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2547#issuecomment-1152702693
https://github.com/psi4/psi4/pull/2547#issuecomment-1152702693:297,Testability,benchmark,benchmarks,297,"> So I now realize something - we may want to apply some of the benchmarking changes made in this PR to DFJCOSK, as well. It will increase the size of the PR, but the benchmarking changes in this PR currently only extend to DirectJK at the moment. Since DFJCOSK has two methods that it separately benchmarks, it will require a bit of retooling regarding some of the internals of the benchmarking framework. It should not have a significant impact on test_erisieve, however. > Thoughts?. Unless the DFJCOSK changes would undo much of this PR, I think a follow-up PR would be best.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2547#issuecomment-1152702693
https://github.com/psi4/psi4/pull/2547#issuecomment-1152702693:383,Testability,benchmark,benchmarking,383,"> So I now realize something - we may want to apply some of the benchmarking changes made in this PR to DFJCOSK, as well. It will increase the size of the PR, but the benchmarking changes in this PR currently only extend to DirectJK at the moment. Since DFJCOSK has two methods that it separately benchmarks, it will require a bit of retooling regarding some of the internals of the benchmarking framework. It should not have a significant impact on test_erisieve, however. > Thoughts?. Unless the DFJCOSK changes would undo much of this PR, I think a follow-up PR would be best.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2547#issuecomment-1152702693
https://github.com/psi4/psi4/pull/2547#issuecomment-1152702693:520,Usability,undo,undo,520,"> So I now realize something - we may want to apply some of the benchmarking changes made in this PR to DFJCOSK, as well. It will increase the size of the PR, but the benchmarking changes in this PR currently only extend to DirectJK at the moment. Since DFJCOSK has two methods that it separately benchmarks, it will require a bit of retooling regarding some of the internals of the benchmarking framework. It should not have a significant impact on test_erisieve, however. > Thoughts?. Unless the DFJCOSK changes would undo much of this PR, I think a follow-up PR would be best.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2547#issuecomment-1152702693
https://github.com/psi4/psi4/pull/2547#issuecomment-1152705815:216,Modifiability,extend,extend,216,"> > So I now realize something - we may want to apply some of the benchmarking changes made in this PR to DFJCOSK, as well. It will increase the size of the PR, but the benchmarking changes in this PR currently only extend to DirectJK at the moment. Since DFJCOSK has two methods that it separately benchmarks, it will require a bit of retooling regarding some of the internals of the benchmarking framework. It should not have a significant impact on test_erisieve, however.; > ; > > Thoughts?; > ; > Unless the DFJCOSK changes would undo much of this PR, I think a follow-up PR would be best. DFJCOSK won't explicitly undo most of this PR, nicely enough, though it will require some changes to how the computed_shells member functions/variables are handled. Regardless, it won't lead to significant changes in test_erisieve, so a separate PR should work fine. And ultimately, the big point of this PR is to allow testing of density screening in test_erisieve without needing to directly construct and use separate TwoBodyAOInt objects, since the plan is to remove density screening from TwoBodyAOInt entirely. . Thank you for your feedback!",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2547#issuecomment-1152705815
https://github.com/psi4/psi4/pull/2547#issuecomment-1152705815:737,Modifiability,variab,variables,737,"> > So I now realize something - we may want to apply some of the benchmarking changes made in this PR to DFJCOSK, as well. It will increase the size of the PR, but the benchmarking changes in this PR currently only extend to DirectJK at the moment. Since DFJCOSK has two methods that it separately benchmarks, it will require a bit of retooling regarding some of the internals of the benchmarking framework. It should not have a significant impact on test_erisieve, however.; > ; > > Thoughts?; > ; > Unless the DFJCOSK changes would undo much of this PR, I think a follow-up PR would be best. DFJCOSK won't explicitly undo most of this PR, nicely enough, though it will require some changes to how the computed_shells member functions/variables are handled. Regardless, it won't lead to significant changes in test_erisieve, so a separate PR should work fine. And ultimately, the big point of this PR is to allow testing of density screening in test_erisieve without needing to directly construct and use separate TwoBodyAOInt objects, since the plan is to remove density screening from TwoBodyAOInt entirely. . Thank you for your feedback!",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2547#issuecomment-1152705815
https://github.com/psi4/psi4/pull/2547#issuecomment-1152705815:66,Testability,benchmark,benchmarking,66,"> > So I now realize something - we may want to apply some of the benchmarking changes made in this PR to DFJCOSK, as well. It will increase the size of the PR, but the benchmarking changes in this PR currently only extend to DirectJK at the moment. Since DFJCOSK has two methods that it separately benchmarks, it will require a bit of retooling regarding some of the internals of the benchmarking framework. It should not have a significant impact on test_erisieve, however.; > ; > > Thoughts?; > ; > Unless the DFJCOSK changes would undo much of this PR, I think a follow-up PR would be best. DFJCOSK won't explicitly undo most of this PR, nicely enough, though it will require some changes to how the computed_shells member functions/variables are handled. Regardless, it won't lead to significant changes in test_erisieve, so a separate PR should work fine. And ultimately, the big point of this PR is to allow testing of density screening in test_erisieve without needing to directly construct and use separate TwoBodyAOInt objects, since the plan is to remove density screening from TwoBodyAOInt entirely. . Thank you for your feedback!",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2547#issuecomment-1152705815
https://github.com/psi4/psi4/pull/2547#issuecomment-1152705815:169,Testability,benchmark,benchmarking,169,"> > So I now realize something - we may want to apply some of the benchmarking changes made in this PR to DFJCOSK, as well. It will increase the size of the PR, but the benchmarking changes in this PR currently only extend to DirectJK at the moment. Since DFJCOSK has two methods that it separately benchmarks, it will require a bit of retooling regarding some of the internals of the benchmarking framework. It should not have a significant impact on test_erisieve, however.; > ; > > Thoughts?; > ; > Unless the DFJCOSK changes would undo much of this PR, I think a follow-up PR would be best. DFJCOSK won't explicitly undo most of this PR, nicely enough, though it will require some changes to how the computed_shells member functions/variables are handled. Regardless, it won't lead to significant changes in test_erisieve, so a separate PR should work fine. And ultimately, the big point of this PR is to allow testing of density screening in test_erisieve without needing to directly construct and use separate TwoBodyAOInt objects, since the plan is to remove density screening from TwoBodyAOInt entirely. . Thank you for your feedback!",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2547#issuecomment-1152705815
https://github.com/psi4/psi4/pull/2547#issuecomment-1152705815:299,Testability,benchmark,benchmarks,299,"> > So I now realize something - we may want to apply some of the benchmarking changes made in this PR to DFJCOSK, as well. It will increase the size of the PR, but the benchmarking changes in this PR currently only extend to DirectJK at the moment. Since DFJCOSK has two methods that it separately benchmarks, it will require a bit of retooling regarding some of the internals of the benchmarking framework. It should not have a significant impact on test_erisieve, however.; > ; > > Thoughts?; > ; > Unless the DFJCOSK changes would undo much of this PR, I think a follow-up PR would be best. DFJCOSK won't explicitly undo most of this PR, nicely enough, though it will require some changes to how the computed_shells member functions/variables are handled. Regardless, it won't lead to significant changes in test_erisieve, so a separate PR should work fine. And ultimately, the big point of this PR is to allow testing of density screening in test_erisieve without needing to directly construct and use separate TwoBodyAOInt objects, since the plan is to remove density screening from TwoBodyAOInt entirely. . Thank you for your feedback!",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2547#issuecomment-1152705815
https://github.com/psi4/psi4/pull/2547#issuecomment-1152705815:385,Testability,benchmark,benchmarking,385,"> > So I now realize something - we may want to apply some of the benchmarking changes made in this PR to DFJCOSK, as well. It will increase the size of the PR, but the benchmarking changes in this PR currently only extend to DirectJK at the moment. Since DFJCOSK has two methods that it separately benchmarks, it will require a bit of retooling regarding some of the internals of the benchmarking framework. It should not have a significant impact on test_erisieve, however.; > ; > > Thoughts?; > ; > Unless the DFJCOSK changes would undo much of this PR, I think a follow-up PR would be best. DFJCOSK won't explicitly undo most of this PR, nicely enough, though it will require some changes to how the computed_shells member functions/variables are handled. Regardless, it won't lead to significant changes in test_erisieve, so a separate PR should work fine. And ultimately, the big point of this PR is to allow testing of density screening in test_erisieve without needing to directly construct and use separate TwoBodyAOInt objects, since the plan is to remove density screening from TwoBodyAOInt entirely. . Thank you for your feedback!",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2547#issuecomment-1152705815
https://github.com/psi4/psi4/pull/2547#issuecomment-1152705815:915,Testability,test,testing,915,"> > So I now realize something - we may want to apply some of the benchmarking changes made in this PR to DFJCOSK, as well. It will increase the size of the PR, but the benchmarking changes in this PR currently only extend to DirectJK at the moment. Since DFJCOSK has two methods that it separately benchmarks, it will require a bit of retooling regarding some of the internals of the benchmarking framework. It should not have a significant impact on test_erisieve, however.; > ; > > Thoughts?; > ; > Unless the DFJCOSK changes would undo much of this PR, I think a follow-up PR would be best. DFJCOSK won't explicitly undo most of this PR, nicely enough, though it will require some changes to how the computed_shells member functions/variables are handled. Regardless, it won't lead to significant changes in test_erisieve, so a separate PR should work fine. And ultimately, the big point of this PR is to allow testing of density screening in test_erisieve without needing to directly construct and use separate TwoBodyAOInt objects, since the plan is to remove density screening from TwoBodyAOInt entirely. . Thank you for your feedback!",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2547#issuecomment-1152705815
https://github.com/psi4/psi4/pull/2547#issuecomment-1152705815:535,Usability,undo,undo,535,"> > So I now realize something - we may want to apply some of the benchmarking changes made in this PR to DFJCOSK, as well. It will increase the size of the PR, but the benchmarking changes in this PR currently only extend to DirectJK at the moment. Since DFJCOSK has two methods that it separately benchmarks, it will require a bit of retooling regarding some of the internals of the benchmarking framework. It should not have a significant impact on test_erisieve, however.; > ; > > Thoughts?; > ; > Unless the DFJCOSK changes would undo much of this PR, I think a follow-up PR would be best. DFJCOSK won't explicitly undo most of this PR, nicely enough, though it will require some changes to how the computed_shells member functions/variables are handled. Regardless, it won't lead to significant changes in test_erisieve, so a separate PR should work fine. And ultimately, the big point of this PR is to allow testing of density screening in test_erisieve without needing to directly construct and use separate TwoBodyAOInt objects, since the plan is to remove density screening from TwoBodyAOInt entirely. . Thank you for your feedback!",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2547#issuecomment-1152705815
https://github.com/psi4/psi4/pull/2547#issuecomment-1152705815:620,Usability,undo,undo,620,"> > So I now realize something - we may want to apply some of the benchmarking changes made in this PR to DFJCOSK, as well. It will increase the size of the PR, but the benchmarking changes in this PR currently only extend to DirectJK at the moment. Since DFJCOSK has two methods that it separately benchmarks, it will require a bit of retooling regarding some of the internals of the benchmarking framework. It should not have a significant impact on test_erisieve, however.; > ; > > Thoughts?; > ; > Unless the DFJCOSK changes would undo much of this PR, I think a follow-up PR would be best. DFJCOSK won't explicitly undo most of this PR, nicely enough, though it will require some changes to how the computed_shells member functions/variables are handled. Regardless, it won't lead to significant changes in test_erisieve, so a separate PR should work fine. And ultimately, the big point of this PR is to allow testing of density screening in test_erisieve without needing to directly construct and use separate TwoBodyAOInt objects, since the plan is to remove density screening from TwoBodyAOInt entirely. . Thank you for your feedback!",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2547#issuecomment-1152705815
https://github.com/psi4/psi4/pull/2547#issuecomment-1152705815:1133,Usability,feedback,feedback,1133,"> > So I now realize something - we may want to apply some of the benchmarking changes made in this PR to DFJCOSK, as well. It will increase the size of the PR, but the benchmarking changes in this PR currently only extend to DirectJK at the moment. Since DFJCOSK has two methods that it separately benchmarks, it will require a bit of retooling regarding some of the internals of the benchmarking framework. It should not have a significant impact on test_erisieve, however.; > ; > > Thoughts?; > ; > Unless the DFJCOSK changes would undo much of this PR, I think a follow-up PR would be best. DFJCOSK won't explicitly undo most of this PR, nicely enough, though it will require some changes to how the computed_shells member functions/variables are handled. Regardless, it won't lead to significant changes in test_erisieve, so a separate PR should work fine. And ultimately, the big point of this PR is to allow testing of density screening in test_erisieve without needing to directly construct and use separate TwoBodyAOInt objects, since the plan is to remove density screening from TwoBodyAOInt entirely. . Thank you for your feedback!",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2547#issuecomment-1152705815
https://github.com/psi4/psi4/issues/2548#issuecomment-1100248399:176,Modifiability,config,config,176,"Does `/home/jacobson/bin/psi4_wb97xd3_def2tzvp.py` contain a `qcng.compute()` call? May I see that file?. I don't run much through queues, so I don't have a feel for what qcng/config.py can/should pick up from the environment or host setup.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2548#issuecomment-1100248399
https://github.com/psi4/psi4/issues/2548#issuecomment-1100248399:131,Performance,queue,queues,131,"Does `/home/jacobson/bin/psi4_wb97xd3_def2tzvp.py` contain a `qcng.compute()` call? May I see that file?. I don't run much through queues, so I don't have a feel for what qcng/config.py can/should pick up from the environment or host setup.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2548#issuecomment-1100248399
https://github.com/psi4/psi4/issues/2548#issuecomment-1100260046:1020,Availability,robust,robust,1020,"Sure, here is the script:. ```; import time; import sys; import os; import json. import psi4. def run_fxyz(fxyz, theory='wB97X-D3/def2-TZVP'):; '''; fxyz: absolute path to an xyz file; '''; elements, xyz = [], []; with open(fxyz) as f:; line = next(f); numb_atoms = int(line.split()[0]); line = next(f); charge, multiplicity = map(int, line.split()); for i in range(numb_atoms):; line = next(f); elmnt, x, y, z = line.split() ; elements.append(elmnt); xyz.append((float(x), float(y), float(z))). fxyz = os.path.basename(fxyz); base, ext = os.path.splitext(fxyz). name = base + '_wB97XD3_def2-TZVP'. geom_string = '\n'.join(['%s %f %f %f' % (e, x, y, z) for e, (x, y, z) in zip(elements, xyz)]); geom_string = str(charge) + ' ' + str(multiplicity) + '\n' + geom_string; print(""geom_string"", geom_string). outfile = name + '.psi4'; psi4.core.set_output_file(outfile, False); geom = psi4.geometry(geom_string); settings = {; 'scf_type': 'DF',; 'dft_basis_tolerance': 1e-10,; 'ints_tolerance': 1e-10,; 'dft_pruning_scheme':'robust',; 'S_ORTHOGONALIZATION': 'PARTIALCHOLESKY',; 'S_CHOLESKY_TOLERANCE': 1e-6,; 'wcombine': False,; }; psi4.set_options(settings); start_time = time.time(); grad = psi4.gradient(theory) ; psi4.core.print_variables(); energy = psi4.variable(""SCF TOTAL ENERGY""); psi4.core.clean(); jobtime = time.time() - start; results = {; ""time"": float(jobtime),; ""energy"": energy,; ""gradient"": grad; }. with open(name + "".json"", ""w"") as fout:; json.dump(results, fout, indent=4). print(""Job %s completed in %.2f seconds with energy %.10f"" % (base, jobtime, energy)). def main(args):; assert args[1].endswith("".xyz""); psi4.set_num_threads(1); run_fxyz(args[1]). if __name__ == '__main__':; main(sys.argv); ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2548#issuecomment-1100260046
https://github.com/psi4/psi4/issues/2548#issuecomment-1100260046:304,Energy Efficiency,charge,charge,304,"Sure, here is the script:. ```; import time; import sys; import os; import json. import psi4. def run_fxyz(fxyz, theory='wB97X-D3/def2-TZVP'):; '''; fxyz: absolute path to an xyz file; '''; elements, xyz = [], []; with open(fxyz) as f:; line = next(f); numb_atoms = int(line.split()[0]); line = next(f); charge, multiplicity = map(int, line.split()); for i in range(numb_atoms):; line = next(f); elmnt, x, y, z = line.split() ; elements.append(elmnt); xyz.append((float(x), float(y), float(z))). fxyz = os.path.basename(fxyz); base, ext = os.path.splitext(fxyz). name = base + '_wB97XD3_def2-TZVP'. geom_string = '\n'.join(['%s %f %f %f' % (e, x, y, z) for e, (x, y, z) in zip(elements, xyz)]); geom_string = str(charge) + ' ' + str(multiplicity) + '\n' + geom_string; print(""geom_string"", geom_string). outfile = name + '.psi4'; psi4.core.set_output_file(outfile, False); geom = psi4.geometry(geom_string); settings = {; 'scf_type': 'DF',; 'dft_basis_tolerance': 1e-10,; 'ints_tolerance': 1e-10,; 'dft_pruning_scheme':'robust',; 'S_ORTHOGONALIZATION': 'PARTIALCHOLESKY',; 'S_CHOLESKY_TOLERANCE': 1e-6,; 'wcombine': False,; }; psi4.set_options(settings); start_time = time.time(); grad = psi4.gradient(theory) ; psi4.core.print_variables(); energy = psi4.variable(""SCF TOTAL ENERGY""); psi4.core.clean(); jobtime = time.time() - start; results = {; ""time"": float(jobtime),; ""energy"": energy,; ""gradient"": grad; }. with open(name + "".json"", ""w"") as fout:; json.dump(results, fout, indent=4). print(""Job %s completed in %.2f seconds with energy %.10f"" % (base, jobtime, energy)). def main(args):; assert args[1].endswith("".xyz""); psi4.set_num_threads(1); run_fxyz(args[1]). if __name__ == '__main__':; main(sys.argv); ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2548#issuecomment-1100260046
https://github.com/psi4/psi4/issues/2548#issuecomment-1100260046:713,Energy Efficiency,charge,charge,713,"Sure, here is the script:. ```; import time; import sys; import os; import json. import psi4. def run_fxyz(fxyz, theory='wB97X-D3/def2-TZVP'):; '''; fxyz: absolute path to an xyz file; '''; elements, xyz = [], []; with open(fxyz) as f:; line = next(f); numb_atoms = int(line.split()[0]); line = next(f); charge, multiplicity = map(int, line.split()); for i in range(numb_atoms):; line = next(f); elmnt, x, y, z = line.split() ; elements.append(elmnt); xyz.append((float(x), float(y), float(z))). fxyz = os.path.basename(fxyz); base, ext = os.path.splitext(fxyz). name = base + '_wB97XD3_def2-TZVP'. geom_string = '\n'.join(['%s %f %f %f' % (e, x, y, z) for e, (x, y, z) in zip(elements, xyz)]); geom_string = str(charge) + ' ' + str(multiplicity) + '\n' + geom_string; print(""geom_string"", geom_string). outfile = name + '.psi4'; psi4.core.set_output_file(outfile, False); geom = psi4.geometry(geom_string); settings = {; 'scf_type': 'DF',; 'dft_basis_tolerance': 1e-10,; 'ints_tolerance': 1e-10,; 'dft_pruning_scheme':'robust',; 'S_ORTHOGONALIZATION': 'PARTIALCHOLESKY',; 'S_CHOLESKY_TOLERANCE': 1e-6,; 'wcombine': False,; }; psi4.set_options(settings); start_time = time.time(); grad = psi4.gradient(theory) ; psi4.core.print_variables(); energy = psi4.variable(""SCF TOTAL ENERGY""); psi4.core.clean(); jobtime = time.time() - start; results = {; ""time"": float(jobtime),; ""energy"": energy,; ""gradient"": grad; }. with open(name + "".json"", ""w"") as fout:; json.dump(results, fout, indent=4). print(""Job %s completed in %.2f seconds with energy %.10f"" % (base, jobtime, energy)). def main(args):; assert args[1].endswith("".xyz""); psi4.set_num_threads(1); run_fxyz(args[1]). if __name__ == '__main__':; main(sys.argv); ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2548#issuecomment-1100260046
https://github.com/psi4/psi4/issues/2548#issuecomment-1100260046:1241,Energy Efficiency,energy,energy,1241,"Sure, here is the script:. ```; import time; import sys; import os; import json. import psi4. def run_fxyz(fxyz, theory='wB97X-D3/def2-TZVP'):; '''; fxyz: absolute path to an xyz file; '''; elements, xyz = [], []; with open(fxyz) as f:; line = next(f); numb_atoms = int(line.split()[0]); line = next(f); charge, multiplicity = map(int, line.split()); for i in range(numb_atoms):; line = next(f); elmnt, x, y, z = line.split() ; elements.append(elmnt); xyz.append((float(x), float(y), float(z))). fxyz = os.path.basename(fxyz); base, ext = os.path.splitext(fxyz). name = base + '_wB97XD3_def2-TZVP'. geom_string = '\n'.join(['%s %f %f %f' % (e, x, y, z) for e, (x, y, z) in zip(elements, xyz)]); geom_string = str(charge) + ' ' + str(multiplicity) + '\n' + geom_string; print(""geom_string"", geom_string). outfile = name + '.psi4'; psi4.core.set_output_file(outfile, False); geom = psi4.geometry(geom_string); settings = {; 'scf_type': 'DF',; 'dft_basis_tolerance': 1e-10,; 'ints_tolerance': 1e-10,; 'dft_pruning_scheme':'robust',; 'S_ORTHOGONALIZATION': 'PARTIALCHOLESKY',; 'S_CHOLESKY_TOLERANCE': 1e-6,; 'wcombine': False,; }; psi4.set_options(settings); start_time = time.time(); grad = psi4.gradient(theory) ; psi4.core.print_variables(); energy = psi4.variable(""SCF TOTAL ENERGY""); psi4.core.clean(); jobtime = time.time() - start; results = {; ""time"": float(jobtime),; ""energy"": energy,; ""gradient"": grad; }. with open(name + "".json"", ""w"") as fout:; json.dump(results, fout, indent=4). print(""Job %s completed in %.2f seconds with energy %.10f"" % (base, jobtime, energy)). def main(args):; assert args[1].endswith("".xyz""); psi4.set_num_threads(1); run_fxyz(args[1]). if __name__ == '__main__':; main(sys.argv); ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2548#issuecomment-1100260046
https://github.com/psi4/psi4/issues/2548#issuecomment-1100260046:1275,Energy Efficiency,ENERGY,ENERGY,1275,"Sure, here is the script:. ```; import time; import sys; import os; import json. import psi4. def run_fxyz(fxyz, theory='wB97X-D3/def2-TZVP'):; '''; fxyz: absolute path to an xyz file; '''; elements, xyz = [], []; with open(fxyz) as f:; line = next(f); numb_atoms = int(line.split()[0]); line = next(f); charge, multiplicity = map(int, line.split()); for i in range(numb_atoms):; line = next(f); elmnt, x, y, z = line.split() ; elements.append(elmnt); xyz.append((float(x), float(y), float(z))). fxyz = os.path.basename(fxyz); base, ext = os.path.splitext(fxyz). name = base + '_wB97XD3_def2-TZVP'. geom_string = '\n'.join(['%s %f %f %f' % (e, x, y, z) for e, (x, y, z) in zip(elements, xyz)]); geom_string = str(charge) + ' ' + str(multiplicity) + '\n' + geom_string; print(""geom_string"", geom_string). outfile = name + '.psi4'; psi4.core.set_output_file(outfile, False); geom = psi4.geometry(geom_string); settings = {; 'scf_type': 'DF',; 'dft_basis_tolerance': 1e-10,; 'ints_tolerance': 1e-10,; 'dft_pruning_scheme':'robust',; 'S_ORTHOGONALIZATION': 'PARTIALCHOLESKY',; 'S_CHOLESKY_TOLERANCE': 1e-6,; 'wcombine': False,; }; psi4.set_options(settings); start_time = time.time(); grad = psi4.gradient(theory) ; psi4.core.print_variables(); energy = psi4.variable(""SCF TOTAL ENERGY""); psi4.core.clean(); jobtime = time.time() - start; results = {; ""time"": float(jobtime),; ""energy"": energy,; ""gradient"": grad; }. with open(name + "".json"", ""w"") as fout:; json.dump(results, fout, indent=4). print(""Job %s completed in %.2f seconds with energy %.10f"" % (base, jobtime, energy)). def main(args):; assert args[1].endswith("".xyz""); psi4.set_num_threads(1); run_fxyz(args[1]). if __name__ == '__main__':; main(sys.argv); ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2548#issuecomment-1100260046
https://github.com/psi4/psi4/issues/2548#issuecomment-1100260046:1374,Energy Efficiency,energy,energy,1374,"Sure, here is the script:. ```; import time; import sys; import os; import json. import psi4. def run_fxyz(fxyz, theory='wB97X-D3/def2-TZVP'):; '''; fxyz: absolute path to an xyz file; '''; elements, xyz = [], []; with open(fxyz) as f:; line = next(f); numb_atoms = int(line.split()[0]); line = next(f); charge, multiplicity = map(int, line.split()); for i in range(numb_atoms):; line = next(f); elmnt, x, y, z = line.split() ; elements.append(elmnt); xyz.append((float(x), float(y), float(z))). fxyz = os.path.basename(fxyz); base, ext = os.path.splitext(fxyz). name = base + '_wB97XD3_def2-TZVP'. geom_string = '\n'.join(['%s %f %f %f' % (e, x, y, z) for e, (x, y, z) in zip(elements, xyz)]); geom_string = str(charge) + ' ' + str(multiplicity) + '\n' + geom_string; print(""geom_string"", geom_string). outfile = name + '.psi4'; psi4.core.set_output_file(outfile, False); geom = psi4.geometry(geom_string); settings = {; 'scf_type': 'DF',; 'dft_basis_tolerance': 1e-10,; 'ints_tolerance': 1e-10,; 'dft_pruning_scheme':'robust',; 'S_ORTHOGONALIZATION': 'PARTIALCHOLESKY',; 'S_CHOLESKY_TOLERANCE': 1e-6,; 'wcombine': False,; }; psi4.set_options(settings); start_time = time.time(); grad = psi4.gradient(theory) ; psi4.core.print_variables(); energy = psi4.variable(""SCF TOTAL ENERGY""); psi4.core.clean(); jobtime = time.time() - start; results = {; ""time"": float(jobtime),; ""energy"": energy,; ""gradient"": grad; }. with open(name + "".json"", ""w"") as fout:; json.dump(results, fout, indent=4). print(""Job %s completed in %.2f seconds with energy %.10f"" % (base, jobtime, energy)). def main(args):; assert args[1].endswith("".xyz""); psi4.set_num_threads(1); run_fxyz(args[1]). if __name__ == '__main__':; main(sys.argv); ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2548#issuecomment-1100260046
https://github.com/psi4/psi4/issues/2548#issuecomment-1100260046:1383,Energy Efficiency,energy,energy,1383,"Sure, here is the script:. ```; import time; import sys; import os; import json. import psi4. def run_fxyz(fxyz, theory='wB97X-D3/def2-TZVP'):; '''; fxyz: absolute path to an xyz file; '''; elements, xyz = [], []; with open(fxyz) as f:; line = next(f); numb_atoms = int(line.split()[0]); line = next(f); charge, multiplicity = map(int, line.split()); for i in range(numb_atoms):; line = next(f); elmnt, x, y, z = line.split() ; elements.append(elmnt); xyz.append((float(x), float(y), float(z))). fxyz = os.path.basename(fxyz); base, ext = os.path.splitext(fxyz). name = base + '_wB97XD3_def2-TZVP'. geom_string = '\n'.join(['%s %f %f %f' % (e, x, y, z) for e, (x, y, z) in zip(elements, xyz)]); geom_string = str(charge) + ' ' + str(multiplicity) + '\n' + geom_string; print(""geom_string"", geom_string). outfile = name + '.psi4'; psi4.core.set_output_file(outfile, False); geom = psi4.geometry(geom_string); settings = {; 'scf_type': 'DF',; 'dft_basis_tolerance': 1e-10,; 'ints_tolerance': 1e-10,; 'dft_pruning_scheme':'robust',; 'S_ORTHOGONALIZATION': 'PARTIALCHOLESKY',; 'S_CHOLESKY_TOLERANCE': 1e-6,; 'wcombine': False,; }; psi4.set_options(settings); start_time = time.time(); grad = psi4.gradient(theory) ; psi4.core.print_variables(); energy = psi4.variable(""SCF TOTAL ENERGY""); psi4.core.clean(); jobtime = time.time() - start; results = {; ""time"": float(jobtime),; ""energy"": energy,; ""gradient"": grad; }. with open(name + "".json"", ""w"") as fout:; json.dump(results, fout, indent=4). print(""Job %s completed in %.2f seconds with energy %.10f"" % (base, jobtime, energy)). def main(args):; assert args[1].endswith("".xyz""); psi4.set_num_threads(1); run_fxyz(args[1]). if __name__ == '__main__':; main(sys.argv); ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2548#issuecomment-1100260046
https://github.com/psi4/psi4/issues/2548#issuecomment-1100260046:1535,Energy Efficiency,energy,energy,1535,"Sure, here is the script:. ```; import time; import sys; import os; import json. import psi4. def run_fxyz(fxyz, theory='wB97X-D3/def2-TZVP'):; '''; fxyz: absolute path to an xyz file; '''; elements, xyz = [], []; with open(fxyz) as f:; line = next(f); numb_atoms = int(line.split()[0]); line = next(f); charge, multiplicity = map(int, line.split()); for i in range(numb_atoms):; line = next(f); elmnt, x, y, z = line.split() ; elements.append(elmnt); xyz.append((float(x), float(y), float(z))). fxyz = os.path.basename(fxyz); base, ext = os.path.splitext(fxyz). name = base + '_wB97XD3_def2-TZVP'. geom_string = '\n'.join(['%s %f %f %f' % (e, x, y, z) for e, (x, y, z) in zip(elements, xyz)]); geom_string = str(charge) + ' ' + str(multiplicity) + '\n' + geom_string; print(""geom_string"", geom_string). outfile = name + '.psi4'; psi4.core.set_output_file(outfile, False); geom = psi4.geometry(geom_string); settings = {; 'scf_type': 'DF',; 'dft_basis_tolerance': 1e-10,; 'ints_tolerance': 1e-10,; 'dft_pruning_scheme':'robust',; 'S_ORTHOGONALIZATION': 'PARTIALCHOLESKY',; 'S_CHOLESKY_TOLERANCE': 1e-6,; 'wcombine': False,; }; psi4.set_options(settings); start_time = time.time(); grad = psi4.gradient(theory) ; psi4.core.print_variables(); energy = psi4.variable(""SCF TOTAL ENERGY""); psi4.core.clean(); jobtime = time.time() - start; results = {; ""time"": float(jobtime),; ""energy"": energy,; ""gradient"": grad; }. with open(name + "".json"", ""w"") as fout:; json.dump(results, fout, indent=4). print(""Job %s completed in %.2f seconds with energy %.10f"" % (base, jobtime, energy)). def main(args):; assert args[1].endswith("".xyz""); psi4.set_num_threads(1); run_fxyz(args[1]). if __name__ == '__main__':; main(sys.argv); ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2548#issuecomment-1100260046
https://github.com/psi4/psi4/issues/2548#issuecomment-1100260046:1567,Energy Efficiency,energy,energy,1567,"Sure, here is the script:. ```; import time; import sys; import os; import json. import psi4. def run_fxyz(fxyz, theory='wB97X-D3/def2-TZVP'):; '''; fxyz: absolute path to an xyz file; '''; elements, xyz = [], []; with open(fxyz) as f:; line = next(f); numb_atoms = int(line.split()[0]); line = next(f); charge, multiplicity = map(int, line.split()); for i in range(numb_atoms):; line = next(f); elmnt, x, y, z = line.split() ; elements.append(elmnt); xyz.append((float(x), float(y), float(z))). fxyz = os.path.basename(fxyz); base, ext = os.path.splitext(fxyz). name = base + '_wB97XD3_def2-TZVP'. geom_string = '\n'.join(['%s %f %f %f' % (e, x, y, z) for e, (x, y, z) in zip(elements, xyz)]); geom_string = str(charge) + ' ' + str(multiplicity) + '\n' + geom_string; print(""geom_string"", geom_string). outfile = name + '.psi4'; psi4.core.set_output_file(outfile, False); geom = psi4.geometry(geom_string); settings = {; 'scf_type': 'DF',; 'dft_basis_tolerance': 1e-10,; 'ints_tolerance': 1e-10,; 'dft_pruning_scheme':'robust',; 'S_ORTHOGONALIZATION': 'PARTIALCHOLESKY',; 'S_CHOLESKY_TOLERANCE': 1e-6,; 'wcombine': False,; }; psi4.set_options(settings); start_time = time.time(); grad = psi4.gradient(theory) ; psi4.core.print_variables(); energy = psi4.variable(""SCF TOTAL ENERGY""); psi4.core.clean(); jobtime = time.time() - start; results = {; ""time"": float(jobtime),; ""energy"": energy,; ""gradient"": grad; }. with open(name + "".json"", ""w"") as fout:; json.dump(results, fout, indent=4). print(""Job %s completed in %.2f seconds with energy %.10f"" % (base, jobtime, energy)). def main(args):; assert args[1].endswith("".xyz""); psi4.set_num_threads(1); run_fxyz(args[1]). if __name__ == '__main__':; main(sys.argv); ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2548#issuecomment-1100260046
https://github.com/psi4/psi4/issues/2548#issuecomment-1100260046:1255,Modifiability,variab,variable,1255,"Sure, here is the script:. ```; import time; import sys; import os; import json. import psi4. def run_fxyz(fxyz, theory='wB97X-D3/def2-TZVP'):; '''; fxyz: absolute path to an xyz file; '''; elements, xyz = [], []; with open(fxyz) as f:; line = next(f); numb_atoms = int(line.split()[0]); line = next(f); charge, multiplicity = map(int, line.split()); for i in range(numb_atoms):; line = next(f); elmnt, x, y, z = line.split() ; elements.append(elmnt); xyz.append((float(x), float(y), float(z))). fxyz = os.path.basename(fxyz); base, ext = os.path.splitext(fxyz). name = base + '_wB97XD3_def2-TZVP'. geom_string = '\n'.join(['%s %f %f %f' % (e, x, y, z) for e, (x, y, z) in zip(elements, xyz)]); geom_string = str(charge) + ' ' + str(multiplicity) + '\n' + geom_string; print(""geom_string"", geom_string). outfile = name + '.psi4'; psi4.core.set_output_file(outfile, False); geom = psi4.geometry(geom_string); settings = {; 'scf_type': 'DF',; 'dft_basis_tolerance': 1e-10,; 'ints_tolerance': 1e-10,; 'dft_pruning_scheme':'robust',; 'S_ORTHOGONALIZATION': 'PARTIALCHOLESKY',; 'S_CHOLESKY_TOLERANCE': 1e-6,; 'wcombine': False,; }; psi4.set_options(settings); start_time = time.time(); grad = psi4.gradient(theory) ; psi4.core.print_variables(); energy = psi4.variable(""SCF TOTAL ENERGY""); psi4.core.clean(); jobtime = time.time() - start; results = {; ""time"": float(jobtime),; ""energy"": energy,; ""gradient"": grad; }. with open(name + "".json"", ""w"") as fout:; json.dump(results, fout, indent=4). print(""Job %s completed in %.2f seconds with energy %.10f"" % (base, jobtime, energy)). def main(args):; assert args[1].endswith("".xyz""); psi4.set_num_threads(1); run_fxyz(args[1]). if __name__ == '__main__':; main(sys.argv); ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2548#issuecomment-1100260046
https://github.com/psi4/psi4/issues/2548#issuecomment-1100260046:1594,Testability,assert,assert,1594,"Sure, here is the script:. ```; import time; import sys; import os; import json. import psi4. def run_fxyz(fxyz, theory='wB97X-D3/def2-TZVP'):; '''; fxyz: absolute path to an xyz file; '''; elements, xyz = [], []; with open(fxyz) as f:; line = next(f); numb_atoms = int(line.split()[0]); line = next(f); charge, multiplicity = map(int, line.split()); for i in range(numb_atoms):; line = next(f); elmnt, x, y, z = line.split() ; elements.append(elmnt); xyz.append((float(x), float(y), float(z))). fxyz = os.path.basename(fxyz); base, ext = os.path.splitext(fxyz). name = base + '_wB97XD3_def2-TZVP'. geom_string = '\n'.join(['%s %f %f %f' % (e, x, y, z) for e, (x, y, z) in zip(elements, xyz)]); geom_string = str(charge) + ' ' + str(multiplicity) + '\n' + geom_string; print(""geom_string"", geom_string). outfile = name + '.psi4'; psi4.core.set_output_file(outfile, False); geom = psi4.geometry(geom_string); settings = {; 'scf_type': 'DF',; 'dft_basis_tolerance': 1e-10,; 'ints_tolerance': 1e-10,; 'dft_pruning_scheme':'robust',; 'S_ORTHOGONALIZATION': 'PARTIALCHOLESKY',; 'S_CHOLESKY_TOLERANCE': 1e-6,; 'wcombine': False,; }; psi4.set_options(settings); start_time = time.time(); grad = psi4.gradient(theory) ; psi4.core.print_variables(); energy = psi4.variable(""SCF TOTAL ENERGY""); psi4.core.clean(); jobtime = time.time() - start; results = {; ""time"": float(jobtime),; ""energy"": energy,; ""gradient"": grad; }. with open(name + "".json"", ""w"") as fout:; json.dump(results, fout, indent=4). print(""Job %s completed in %.2f seconds with energy %.10f"" % (base, jobtime, energy)). def main(args):; assert args[1].endswith("".xyz""); psi4.set_num_threads(1); run_fxyz(args[1]). if __name__ == '__main__':; main(sys.argv); ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2548#issuecomment-1100260046
https://github.com/psi4/psi4/issues/2548#issuecomment-1100294938:4128,Availability,robust,robust,4128," working version:; ```; import time; import sys; import os; import json. import psi4. def run_fxyz(fxyz, theory='wB97X-D3/def2-TZVP'):; '''; fxyz: absolute path to an xyz file; '''; elements, xyz = [], []; with open(fxyz) as f:; line = next(f); numb_atoms = int(line.split()[0]); line = next(f); charge, multiplicity = map(int, line.split()); for i in range(numb_atoms):; line = next(f); elmnt, x, y, z = line.split() ; elements.append(elmnt); xyz.append((float(x), float(y), float(z))). fxyz = os.path.basename(fxyz); base, ext = os.path.splitext(fxyz). name = base + '_wB97XD3_def2-TZVP'. geom_string = '\n'.join(['%s %f %f %f' % (e, x, y, z) for e, (x, y, z) in zip(elements, xyz)]); geom_string = str(charge) + ' ' + str(multiplicity) + '\n' + geom_string; print(""geom_string"", geom_string). outfile = name + '.psi4'; psi4.core.set_output_file(outfile, False); geom = psi4.geometry(geom_string); settings = {; 'scf_type': 'DF',; 'dft_basis_tolerance': 1e-10,; 'ints_tolerance': 1e-10,; 'dft_pruning_scheme':'robust',; 'S_ORTHOGONALIZATION': 'PARTIALCHOLESKY',; 'S_CHOLESKY_TOLERANCE': 1e-6,; 'wcombine': False,; }; psi4.set_options(settings); start_time = time.time(); grad = psi4.gradient(theory) ; psi4.core.print_variables(); energy = psi4.variable(""SCF TOTAL ENERGY""); psi4.core.clean(); jobtime = time.time() - start_time; results = {; ""time"": float(jobtime),; ""energy"": energy,; ""gradient"": grad.np.tolist(); }; print(f""{psi4.core.get_num_threads()=}""). with open(name + "".json"", ""w"") as fout:; json.dump(results, fout, indent=4). print(""Job %s completed in %.2f seconds with energy %.10f"" % (base, jobtime, energy)). def main(args):; assert args[1].endswith("".xyz""); psi4.set_num_threads(1); run_fxyz(args[1]). if __name__ == '__main__':; main(sys.argv); ```. ## Psithon vs. QCSchema. Another aside -- your input is written as a python script containing a single job and dropping the key results to json. This could also run through QCSchema with json input and json output, either API like",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2548#issuecomment-1100294938
https://github.com/psi4/psi4/issues/2548#issuecomment-1100294938:1118,Deployability,install,installed,1118,"e coordinates. chg/mult from the xyz are possible https://github.com/MolSSI/QCElemental/blob/master/qcelemental/molparse/from_string.py#L117-L136. tu1.py; ```; import psi4. psi4.set_memory(""600 mb""). ### <<< Either ; #with open(""h2o.xyz"") as fp:; # fh2o = fp.read(); #; #psi4.geometry(fh2o). ### --- Or. h2o = psi4.core.Molecule.from_arrays(elem=[""O"", ""H"", ""H""], units=""Angstrom"", geom=[; 0.000000000000, 0.000000000000, -0.065775570538, ; 0.000000000000, -0.759061990794, 0.521953018295, ; 0.000000000000, 0.759061990794, 0.521953018295]) ; psi4.activate(h2o). ### >>> End. psi4.set_options({; ""basis"": ""cc-pVDZ"",; }); psi4.energy('scf'). psi4.compare_values(-76.0266327341067125, psi4.variable('SCF TOTAL ENERGY'), 6, 'SCF energy') #TEST; ```. h2o.xyz; ```; 3; sdlkfs; O 0.000000000000 0.000000000000 -0.065775570538 ; H 0.000000000000 -0.759061990794 0.521953018295 ; H 0.000000000000 0.759061990794 0.521953018295 . ```; ## Single Core. To actually address your problem, can you try the following edits? If you edit the installed copy, no recompile needed. Hopefully this solves it -- thanks for the report!; ```; diff --git a/psi4/driver/procrouting/empirical_dispersion.py b/psi4/driver/procrouting/empirical_dispersion.py; index d23f016..ea4f79d 100644; --- a/psi4/driver/procrouting/empirical_dispersion.py; +++ b/psi4/driver/procrouting/empirical_dispersion.py; @@ -213,7 +213,7 @@ class EmpiricalDispersion(object):; resi,; self.engine,; raise_error=True,; - local_options={""scratch_directory"": core.IOManager.shared_object().get_default_path()}); + local_options={""scratch_directory"": core.IOManager.shared_object().get_default_path(), ""ncores"": core.get_num_threads()}); ; dashd_part = float(jobrec.extras['qcvars']['DISPERSION CORRECTION ENERGY']); if wfn is not None:; @@ -231,7 +231,7 @@ class EmpiricalDispersion(object):; resi,; ""gcp"",; raise_error=True,; - local_options={""scratch_directory"": core.IOManager.shared_object().get_default_path()}); + local_options={""scratch_directory""",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2548#issuecomment-1100294938
https://github.com/psi4/psi4/issues/2548#issuecomment-1100294938:719,Energy Efficiency,energy,energy,719,"## XYZ Files. Just as an aside, here's two easier ways to deal with molecules when you have the coordinates. chg/mult from the xyz are possible https://github.com/MolSSI/QCElemental/blob/master/qcelemental/molparse/from_string.py#L117-L136. tu1.py; ```; import psi4. psi4.set_memory(""600 mb""). ### <<< Either ; #with open(""h2o.xyz"") as fp:; # fh2o = fp.read(); #; #psi4.geometry(fh2o). ### --- Or. h2o = psi4.core.Molecule.from_arrays(elem=[""O"", ""H"", ""H""], units=""Angstrom"", geom=[; 0.000000000000, 0.000000000000, -0.065775570538, ; 0.000000000000, -0.759061990794, 0.521953018295, ; 0.000000000000, 0.759061990794, 0.521953018295]) ; psi4.activate(h2o). ### >>> End. psi4.set_options({; ""basis"": ""cc-pVDZ"",; }); psi4.energy('scf'). psi4.compare_values(-76.0266327341067125, psi4.variable('SCF TOTAL ENERGY'), 6, 'SCF energy') #TEST; ```. h2o.xyz; ```; 3; sdlkfs; O 0.000000000000 0.000000000000 -0.065775570538 ; H 0.000000000000 -0.759061990794 0.521953018295 ; H 0.000000000000 0.759061990794 0.521953018295 . ```; ## Single Core. To actually address your problem, can you try the following edits? If you edit the installed copy, no recompile needed. Hopefully this solves it -- thanks for the report!; ```; diff --git a/psi4/driver/procrouting/empirical_dispersion.py b/psi4/driver/procrouting/empirical_dispersion.py; index d23f016..ea4f79d 100644; --- a/psi4/driver/procrouting/empirical_dispersion.py; +++ b/psi4/driver/procrouting/empirical_dispersion.py; @@ -213,7 +213,7 @@ class EmpiricalDispersion(object):; resi,; self.engine,; raise_error=True,; - local_options={""scratch_directory"": core.IOManager.shared_object().get_default_path()}); + local_options={""scratch_directory"": core.IOManager.shared_object().get_default_path(), ""ncores"": core.get_num_threads()}); ; dashd_part = float(jobrec.extras['qcvars']['DISPERSION CORRECTION ENERGY']); if wfn is not None:; @@ -231,7 +231,7 @@ class EmpiricalDispersion(object):; resi,; ""gcp"",; raise_error=True,; - local_options={""scratch_director",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2548#issuecomment-1100294938
https://github.com/psi4/psi4/issues/2548#issuecomment-1100294938:801,Energy Efficiency,ENERGY,ENERGY,801,"## XYZ Files. Just as an aside, here's two easier ways to deal with molecules when you have the coordinates. chg/mult from the xyz are possible https://github.com/MolSSI/QCElemental/blob/master/qcelemental/molparse/from_string.py#L117-L136. tu1.py; ```; import psi4. psi4.set_memory(""600 mb""). ### <<< Either ; #with open(""h2o.xyz"") as fp:; # fh2o = fp.read(); #; #psi4.geometry(fh2o). ### --- Or. h2o = psi4.core.Molecule.from_arrays(elem=[""O"", ""H"", ""H""], units=""Angstrom"", geom=[; 0.000000000000, 0.000000000000, -0.065775570538, ; 0.000000000000, -0.759061990794, 0.521953018295, ; 0.000000000000, 0.759061990794, 0.521953018295]) ; psi4.activate(h2o). ### >>> End. psi4.set_options({; ""basis"": ""cc-pVDZ"",; }); psi4.energy('scf'). psi4.compare_values(-76.0266327341067125, psi4.variable('SCF TOTAL ENERGY'), 6, 'SCF energy') #TEST; ```. h2o.xyz; ```; 3; sdlkfs; O 0.000000000000 0.000000000000 -0.065775570538 ; H 0.000000000000 -0.759061990794 0.521953018295 ; H 0.000000000000 0.759061990794 0.521953018295 . ```; ## Single Core. To actually address your problem, can you try the following edits? If you edit the installed copy, no recompile needed. Hopefully this solves it -- thanks for the report!; ```; diff --git a/psi4/driver/procrouting/empirical_dispersion.py b/psi4/driver/procrouting/empirical_dispersion.py; index d23f016..ea4f79d 100644; --- a/psi4/driver/procrouting/empirical_dispersion.py; +++ b/psi4/driver/procrouting/empirical_dispersion.py; @@ -213,7 +213,7 @@ class EmpiricalDispersion(object):; resi,; self.engine,; raise_error=True,; - local_options={""scratch_directory"": core.IOManager.shared_object().get_default_path()}); + local_options={""scratch_directory"": core.IOManager.shared_object().get_default_path(), ""ncores"": core.get_num_threads()}); ; dashd_part = float(jobrec.extras['qcvars']['DISPERSION CORRECTION ENERGY']); if wfn is not None:; @@ -231,7 +231,7 @@ class EmpiricalDispersion(object):; resi,; ""gcp"",; raise_error=True,; - local_options={""scratch_director",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2548#issuecomment-1100294938
https://github.com/psi4/psi4/issues/2548#issuecomment-1100294938:819,Energy Efficiency,energy,energy,819,"## XYZ Files. Just as an aside, here's two easier ways to deal with molecules when you have the coordinates. chg/mult from the xyz are possible https://github.com/MolSSI/QCElemental/blob/master/qcelemental/molparse/from_string.py#L117-L136. tu1.py; ```; import psi4. psi4.set_memory(""600 mb""). ### <<< Either ; #with open(""h2o.xyz"") as fp:; # fh2o = fp.read(); #; #psi4.geometry(fh2o). ### --- Or. h2o = psi4.core.Molecule.from_arrays(elem=[""O"", ""H"", ""H""], units=""Angstrom"", geom=[; 0.000000000000, 0.000000000000, -0.065775570538, ; 0.000000000000, -0.759061990794, 0.521953018295, ; 0.000000000000, 0.759061990794, 0.521953018295]) ; psi4.activate(h2o). ### >>> End. psi4.set_options({; ""basis"": ""cc-pVDZ"",; }); psi4.energy('scf'). psi4.compare_values(-76.0266327341067125, psi4.variable('SCF TOTAL ENERGY'), 6, 'SCF energy') #TEST; ```. h2o.xyz; ```; 3; sdlkfs; O 0.000000000000 0.000000000000 -0.065775570538 ; H 0.000000000000 -0.759061990794 0.521953018295 ; H 0.000000000000 0.759061990794 0.521953018295 . ```; ## Single Core. To actually address your problem, can you try the following edits? If you edit the installed copy, no recompile needed. Hopefully this solves it -- thanks for the report!; ```; diff --git a/psi4/driver/procrouting/empirical_dispersion.py b/psi4/driver/procrouting/empirical_dispersion.py; index d23f016..ea4f79d 100644; --- a/psi4/driver/procrouting/empirical_dispersion.py; +++ b/psi4/driver/procrouting/empirical_dispersion.py; @@ -213,7 +213,7 @@ class EmpiricalDispersion(object):; resi,; self.engine,; raise_error=True,; - local_options={""scratch_directory"": core.IOManager.shared_object().get_default_path()}); + local_options={""scratch_directory"": core.IOManager.shared_object().get_default_path(), ""ncores"": core.get_num_threads()}); ; dashd_part = float(jobrec.extras['qcvars']['DISPERSION CORRECTION ENERGY']); if wfn is not None:; @@ -231,7 +231,7 @@ class EmpiricalDispersion(object):; resi,; ""gcp"",; raise_error=True,; - local_options={""scratch_director",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2548#issuecomment-1100294938
https://github.com/psi4/psi4/issues/2548#issuecomment-1100294938:1845,Energy Efficiency,ENERGY,ENERGY,1845,"70538 ; H 0.000000000000 -0.759061990794 0.521953018295 ; H 0.000000000000 0.759061990794 0.521953018295 . ```; ## Single Core. To actually address your problem, can you try the following edits? If you edit the installed copy, no recompile needed. Hopefully this solves it -- thanks for the report!; ```; diff --git a/psi4/driver/procrouting/empirical_dispersion.py b/psi4/driver/procrouting/empirical_dispersion.py; index d23f016..ea4f79d 100644; --- a/psi4/driver/procrouting/empirical_dispersion.py; +++ b/psi4/driver/procrouting/empirical_dispersion.py; @@ -213,7 +213,7 @@ class EmpiricalDispersion(object):; resi,; self.engine,; raise_error=True,; - local_options={""scratch_directory"": core.IOManager.shared_object().get_default_path()}); + local_options={""scratch_directory"": core.IOManager.shared_object().get_default_path(), ""ncores"": core.get_num_threads()}); ; dashd_part = float(jobrec.extras['qcvars']['DISPERSION CORRECTION ENERGY']); if wfn is not None:; @@ -231,7 +231,7 @@ class EmpiricalDispersion(object):; resi,; ""gcp"",; raise_error=True,; - local_options={""scratch_directory"": core.IOManager.shared_object().get_default_path()}); + local_options={""scratch_directory"": core.IOManager.shared_object().get_default_path(), ""ncores"": core.get_num_threads()}); gcp_part = jobrec.return_result; dashd_part += gcp_part; ; @@ -283,7 +283,7 @@ class EmpiricalDispersion(object):; resi,; self.engine,; raise_error=True,; - local_options={""scratch_directory"": core.IOManager.shared_object().get_default_path()}); + local_options={""scratch_directory"": core.IOManager.shared_object().get_default_path(), ""ncores"": core.get_num_threads()}); ; dashd_part = core.Matrix.from_array(jobrec.extras['qcvars']['DISPERSION CORRECTION GRADIENT']); if wfn is not None:; @@ -296,7 +296,7 @@ class EmpiricalDispersion(object):; resi,; ""gcp"",; raise_error=True,; - local_options={""scratch_directory"": core.IOManager.shared_object().get_default_path()}); + local_options={""scratch_directory"": core.IOManager.s",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2548#issuecomment-1100294938
https://github.com/psi4/psi4/issues/2548#issuecomment-1100294938:3412,Energy Efficiency,charge,charge,3412,"lt_path()}); + local_options={""scratch_directory"": core.IOManager.shared_object().get_default_path(), ""ncores"": core.get_num_threads()}); ; dashd_part = core.Matrix.from_array(jobrec.extras['qcvars']['DISPERSION CORRECTION GRADIENT']); if wfn is not None:; @@ -296,7 +296,7 @@ class EmpiricalDispersion(object):; resi,; ""gcp"",; raise_error=True,; - local_options={""scratch_directory"": core.IOManager.shared_object().get_default_path()}); + local_options={""scratch_directory"": core.IOManager.shared_object().get_default_path(), ""ncores"": core.get_num_threads()}); gcp_part = core.Matrix.from_array(jobrec.return_result); dashd_part.add(gcp_part); ; ```. your script needed a couple tweaks, so here's a working version:; ```; import time; import sys; import os; import json. import psi4. def run_fxyz(fxyz, theory='wB97X-D3/def2-TZVP'):; '''; fxyz: absolute path to an xyz file; '''; elements, xyz = [], []; with open(fxyz) as f:; line = next(f); numb_atoms = int(line.split()[0]); line = next(f); charge, multiplicity = map(int, line.split()); for i in range(numb_atoms):; line = next(f); elmnt, x, y, z = line.split() ; elements.append(elmnt); xyz.append((float(x), float(y), float(z))). fxyz = os.path.basename(fxyz); base, ext = os.path.splitext(fxyz). name = base + '_wB97XD3_def2-TZVP'. geom_string = '\n'.join(['%s %f %f %f' % (e, x, y, z) for e, (x, y, z) in zip(elements, xyz)]); geom_string = str(charge) + ' ' + str(multiplicity) + '\n' + geom_string; print(""geom_string"", geom_string). outfile = name + '.psi4'; psi4.core.set_output_file(outfile, False); geom = psi4.geometry(geom_string); settings = {; 'scf_type': 'DF',; 'dft_basis_tolerance': 1e-10,; 'ints_tolerance': 1e-10,; 'dft_pruning_scheme':'robust',; 'S_ORTHOGONALIZATION': 'PARTIALCHOLESKY',; 'S_CHOLESKY_TOLERANCE': 1e-6,; 'wcombine': False,; }; psi4.set_options(settings); start_time = time.time(); grad = psi4.gradient(theory) ; psi4.core.print_variables(); energy = psi4.variable(""SCF TOTAL ENERGY""); psi4.core.clean(); jobt",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2548#issuecomment-1100294938
https://github.com/psi4/psi4/issues/2548#issuecomment-1100294938:3821,Energy Efficiency,charge,charge,3821,"ared_object().get_default_path()}); + local_options={""scratch_directory"": core.IOManager.shared_object().get_default_path(), ""ncores"": core.get_num_threads()}); gcp_part = core.Matrix.from_array(jobrec.return_result); dashd_part.add(gcp_part); ; ```. your script needed a couple tweaks, so here's a working version:; ```; import time; import sys; import os; import json. import psi4. def run_fxyz(fxyz, theory='wB97X-D3/def2-TZVP'):; '''; fxyz: absolute path to an xyz file; '''; elements, xyz = [], []; with open(fxyz) as f:; line = next(f); numb_atoms = int(line.split()[0]); line = next(f); charge, multiplicity = map(int, line.split()); for i in range(numb_atoms):; line = next(f); elmnt, x, y, z = line.split() ; elements.append(elmnt); xyz.append((float(x), float(y), float(z))). fxyz = os.path.basename(fxyz); base, ext = os.path.splitext(fxyz). name = base + '_wB97XD3_def2-TZVP'. geom_string = '\n'.join(['%s %f %f %f' % (e, x, y, z) for e, (x, y, z) in zip(elements, xyz)]); geom_string = str(charge) + ' ' + str(multiplicity) + '\n' + geom_string; print(""geom_string"", geom_string). outfile = name + '.psi4'; psi4.core.set_output_file(outfile, False); geom = psi4.geometry(geom_string); settings = {; 'scf_type': 'DF',; 'dft_basis_tolerance': 1e-10,; 'ints_tolerance': 1e-10,; 'dft_pruning_scheme':'robust',; 'S_ORTHOGONALIZATION': 'PARTIALCHOLESKY',; 'S_CHOLESKY_TOLERANCE': 1e-6,; 'wcombine': False,; }; psi4.set_options(settings); start_time = time.time(); grad = psi4.gradient(theory) ; psi4.core.print_variables(); energy = psi4.variable(""SCF TOTAL ENERGY""); psi4.core.clean(); jobtime = time.time() - start_time; results = {; ""time"": float(jobtime),; ""energy"": energy,; ""gradient"": grad.np.tolist(); }; print(f""{psi4.core.get_num_threads()=}""). with open(name + "".json"", ""w"") as fout:; json.dump(results, fout, indent=4). print(""Job %s completed in %.2f seconds with energy %.10f"" % (base, jobtime, energy)). def main(args):; assert args[1].endswith("".xyz""); psi4.set_num_threads(1); ",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2548#issuecomment-1100294938
https://github.com/psi4/psi4/issues/2548#issuecomment-1100294938:4349,Energy Efficiency,energy,energy,4349,"'; fxyz: absolute path to an xyz file; '''; elements, xyz = [], []; with open(fxyz) as f:; line = next(f); numb_atoms = int(line.split()[0]); line = next(f); charge, multiplicity = map(int, line.split()); for i in range(numb_atoms):; line = next(f); elmnt, x, y, z = line.split() ; elements.append(elmnt); xyz.append((float(x), float(y), float(z))). fxyz = os.path.basename(fxyz); base, ext = os.path.splitext(fxyz). name = base + '_wB97XD3_def2-TZVP'. geom_string = '\n'.join(['%s %f %f %f' % (e, x, y, z) for e, (x, y, z) in zip(elements, xyz)]); geom_string = str(charge) + ' ' + str(multiplicity) + '\n' + geom_string; print(""geom_string"", geom_string). outfile = name + '.psi4'; psi4.core.set_output_file(outfile, False); geom = psi4.geometry(geom_string); settings = {; 'scf_type': 'DF',; 'dft_basis_tolerance': 1e-10,; 'ints_tolerance': 1e-10,; 'dft_pruning_scheme':'robust',; 'S_ORTHOGONALIZATION': 'PARTIALCHOLESKY',; 'S_CHOLESKY_TOLERANCE': 1e-6,; 'wcombine': False,; }; psi4.set_options(settings); start_time = time.time(); grad = psi4.gradient(theory) ; psi4.core.print_variables(); energy = psi4.variable(""SCF TOTAL ENERGY""); psi4.core.clean(); jobtime = time.time() - start_time; results = {; ""time"": float(jobtime),; ""energy"": energy,; ""gradient"": grad.np.tolist(); }; print(f""{psi4.core.get_num_threads()=}""). with open(name + "".json"", ""w"") as fout:; json.dump(results, fout, indent=4). print(""Job %s completed in %.2f seconds with energy %.10f"" % (base, jobtime, energy)). def main(args):; assert args[1].endswith("".xyz""); psi4.set_num_threads(1); run_fxyz(args[1]). if __name__ == '__main__':; main(sys.argv); ```. ## Psithon vs. QCSchema. Another aside -- your input is written as a python script containing a single job and dropping the key results to json. This could also run through QCSchema with json input and json output, either API like https://github.com/psi4/psi4/blob/master/tests/pytests/test_addons.py#L792-L819 or command-line. Let me know if you'd want more details.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2548#issuecomment-1100294938
https://github.com/psi4/psi4/issues/2548#issuecomment-1100294938:4383,Energy Efficiency,ENERGY,ENERGY,4383,"'; fxyz: absolute path to an xyz file; '''; elements, xyz = [], []; with open(fxyz) as f:; line = next(f); numb_atoms = int(line.split()[0]); line = next(f); charge, multiplicity = map(int, line.split()); for i in range(numb_atoms):; line = next(f); elmnt, x, y, z = line.split() ; elements.append(elmnt); xyz.append((float(x), float(y), float(z))). fxyz = os.path.basename(fxyz); base, ext = os.path.splitext(fxyz). name = base + '_wB97XD3_def2-TZVP'. geom_string = '\n'.join(['%s %f %f %f' % (e, x, y, z) for e, (x, y, z) in zip(elements, xyz)]); geom_string = str(charge) + ' ' + str(multiplicity) + '\n' + geom_string; print(""geom_string"", geom_string). outfile = name + '.psi4'; psi4.core.set_output_file(outfile, False); geom = psi4.geometry(geom_string); settings = {; 'scf_type': 'DF',; 'dft_basis_tolerance': 1e-10,; 'ints_tolerance': 1e-10,; 'dft_pruning_scheme':'robust',; 'S_ORTHOGONALIZATION': 'PARTIALCHOLESKY',; 'S_CHOLESKY_TOLERANCE': 1e-6,; 'wcombine': False,; }; psi4.set_options(settings); start_time = time.time(); grad = psi4.gradient(theory) ; psi4.core.print_variables(); energy = psi4.variable(""SCF TOTAL ENERGY""); psi4.core.clean(); jobtime = time.time() - start_time; results = {; ""time"": float(jobtime),; ""energy"": energy,; ""gradient"": grad.np.tolist(); }; print(f""{psi4.core.get_num_threads()=}""). with open(name + "".json"", ""w"") as fout:; json.dump(results, fout, indent=4). print(""Job %s completed in %.2f seconds with energy %.10f"" % (base, jobtime, energy)). def main(args):; assert args[1].endswith("".xyz""); psi4.set_num_threads(1); run_fxyz(args[1]). if __name__ == '__main__':; main(sys.argv); ```. ## Psithon vs. QCSchema. Another aside -- your input is written as a python script containing a single job and dropping the key results to json. This could also run through QCSchema with json input and json output, either API like https://github.com/psi4/psi4/blob/master/tests/pytests/test_addons.py#L792-L819 or command-line. Let me know if you'd want more details.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2548#issuecomment-1100294938
https://github.com/psi4/psi4/issues/2548#issuecomment-1100294938:4487,Energy Efficiency,energy,energy,4487,"'; fxyz: absolute path to an xyz file; '''; elements, xyz = [], []; with open(fxyz) as f:; line = next(f); numb_atoms = int(line.split()[0]); line = next(f); charge, multiplicity = map(int, line.split()); for i in range(numb_atoms):; line = next(f); elmnt, x, y, z = line.split() ; elements.append(elmnt); xyz.append((float(x), float(y), float(z))). fxyz = os.path.basename(fxyz); base, ext = os.path.splitext(fxyz). name = base + '_wB97XD3_def2-TZVP'. geom_string = '\n'.join(['%s %f %f %f' % (e, x, y, z) for e, (x, y, z) in zip(elements, xyz)]); geom_string = str(charge) + ' ' + str(multiplicity) + '\n' + geom_string; print(""geom_string"", geom_string). outfile = name + '.psi4'; psi4.core.set_output_file(outfile, False); geom = psi4.geometry(geom_string); settings = {; 'scf_type': 'DF',; 'dft_basis_tolerance': 1e-10,; 'ints_tolerance': 1e-10,; 'dft_pruning_scheme':'robust',; 'S_ORTHOGONALIZATION': 'PARTIALCHOLESKY',; 'S_CHOLESKY_TOLERANCE': 1e-6,; 'wcombine': False,; }; psi4.set_options(settings); start_time = time.time(); grad = psi4.gradient(theory) ; psi4.core.print_variables(); energy = psi4.variable(""SCF TOTAL ENERGY""); psi4.core.clean(); jobtime = time.time() - start_time; results = {; ""time"": float(jobtime),; ""energy"": energy,; ""gradient"": grad.np.tolist(); }; print(f""{psi4.core.get_num_threads()=}""). with open(name + "".json"", ""w"") as fout:; json.dump(results, fout, indent=4). print(""Job %s completed in %.2f seconds with energy %.10f"" % (base, jobtime, energy)). def main(args):; assert args[1].endswith("".xyz""); psi4.set_num_threads(1); run_fxyz(args[1]). if __name__ == '__main__':; main(sys.argv); ```. ## Psithon vs. QCSchema. Another aside -- your input is written as a python script containing a single job and dropping the key results to json. This could also run through QCSchema with json input and json output, either API like https://github.com/psi4/psi4/blob/master/tests/pytests/test_addons.py#L792-L819 or command-line. Let me know if you'd want more details.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2548#issuecomment-1100294938
https://github.com/psi4/psi4/issues/2548#issuecomment-1100294938:4496,Energy Efficiency,energy,energy,4496,"'; fxyz: absolute path to an xyz file; '''; elements, xyz = [], []; with open(fxyz) as f:; line = next(f); numb_atoms = int(line.split()[0]); line = next(f); charge, multiplicity = map(int, line.split()); for i in range(numb_atoms):; line = next(f); elmnt, x, y, z = line.split() ; elements.append(elmnt); xyz.append((float(x), float(y), float(z))). fxyz = os.path.basename(fxyz); base, ext = os.path.splitext(fxyz). name = base + '_wB97XD3_def2-TZVP'. geom_string = '\n'.join(['%s %f %f %f' % (e, x, y, z) for e, (x, y, z) in zip(elements, xyz)]); geom_string = str(charge) + ' ' + str(multiplicity) + '\n' + geom_string; print(""geom_string"", geom_string). outfile = name + '.psi4'; psi4.core.set_output_file(outfile, False); geom = psi4.geometry(geom_string); settings = {; 'scf_type': 'DF',; 'dft_basis_tolerance': 1e-10,; 'ints_tolerance': 1e-10,; 'dft_pruning_scheme':'robust',; 'S_ORTHOGONALIZATION': 'PARTIALCHOLESKY',; 'S_CHOLESKY_TOLERANCE': 1e-6,; 'wcombine': False,; }; psi4.set_options(settings); start_time = time.time(); grad = psi4.gradient(theory) ; psi4.core.print_variables(); energy = psi4.variable(""SCF TOTAL ENERGY""); psi4.core.clean(); jobtime = time.time() - start_time; results = {; ""time"": float(jobtime),; ""energy"": energy,; ""gradient"": grad.np.tolist(); }; print(f""{psi4.core.get_num_threads()=}""). with open(name + "".json"", ""w"") as fout:; json.dump(results, fout, indent=4). print(""Job %s completed in %.2f seconds with energy %.10f"" % (base, jobtime, energy)). def main(args):; assert args[1].endswith("".xyz""); psi4.set_num_threads(1); run_fxyz(args[1]). if __name__ == '__main__':; main(sys.argv); ```. ## Psithon vs. QCSchema. Another aside -- your input is written as a python script containing a single job and dropping the key results to json. This could also run through QCSchema with json input and json output, either API like https://github.com/psi4/psi4/blob/master/tests/pytests/test_addons.py#L792-L819 or command-line. Let me know if you'd want more details.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2548#issuecomment-1100294938
https://github.com/psi4/psi4/issues/2548#issuecomment-1100294938:4702,Energy Efficiency,energy,energy,4702,"'; fxyz: absolute path to an xyz file; '''; elements, xyz = [], []; with open(fxyz) as f:; line = next(f); numb_atoms = int(line.split()[0]); line = next(f); charge, multiplicity = map(int, line.split()); for i in range(numb_atoms):; line = next(f); elmnt, x, y, z = line.split() ; elements.append(elmnt); xyz.append((float(x), float(y), float(z))). fxyz = os.path.basename(fxyz); base, ext = os.path.splitext(fxyz). name = base + '_wB97XD3_def2-TZVP'. geom_string = '\n'.join(['%s %f %f %f' % (e, x, y, z) for e, (x, y, z) in zip(elements, xyz)]); geom_string = str(charge) + ' ' + str(multiplicity) + '\n' + geom_string; print(""geom_string"", geom_string). outfile = name + '.psi4'; psi4.core.set_output_file(outfile, False); geom = psi4.geometry(geom_string); settings = {; 'scf_type': 'DF',; 'dft_basis_tolerance': 1e-10,; 'ints_tolerance': 1e-10,; 'dft_pruning_scheme':'robust',; 'S_ORTHOGONALIZATION': 'PARTIALCHOLESKY',; 'S_CHOLESKY_TOLERANCE': 1e-6,; 'wcombine': False,; }; psi4.set_options(settings); start_time = time.time(); grad = psi4.gradient(theory) ; psi4.core.print_variables(); energy = psi4.variable(""SCF TOTAL ENERGY""); psi4.core.clean(); jobtime = time.time() - start_time; results = {; ""time"": float(jobtime),; ""energy"": energy,; ""gradient"": grad.np.tolist(); }; print(f""{psi4.core.get_num_threads()=}""). with open(name + "".json"", ""w"") as fout:; json.dump(results, fout, indent=4). print(""Job %s completed in %.2f seconds with energy %.10f"" % (base, jobtime, energy)). def main(args):; assert args[1].endswith("".xyz""); psi4.set_num_threads(1); run_fxyz(args[1]). if __name__ == '__main__':; main(sys.argv); ```. ## Psithon vs. QCSchema. Another aside -- your input is written as a python script containing a single job and dropping the key results to json. This could also run through QCSchema with json input and json output, either API like https://github.com/psi4/psi4/blob/master/tests/pytests/test_addons.py#L792-L819 or command-line. Let me know if you'd want more details.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2548#issuecomment-1100294938
https://github.com/psi4/psi4/issues/2548#issuecomment-1100294938:4734,Energy Efficiency,energy,energy,4734,"'; fxyz: absolute path to an xyz file; '''; elements, xyz = [], []; with open(fxyz) as f:; line = next(f); numb_atoms = int(line.split()[0]); line = next(f); charge, multiplicity = map(int, line.split()); for i in range(numb_atoms):; line = next(f); elmnt, x, y, z = line.split() ; elements.append(elmnt); xyz.append((float(x), float(y), float(z))). fxyz = os.path.basename(fxyz); base, ext = os.path.splitext(fxyz). name = base + '_wB97XD3_def2-TZVP'. geom_string = '\n'.join(['%s %f %f %f' % (e, x, y, z) for e, (x, y, z) in zip(elements, xyz)]); geom_string = str(charge) + ' ' + str(multiplicity) + '\n' + geom_string; print(""geom_string"", geom_string). outfile = name + '.psi4'; psi4.core.set_output_file(outfile, False); geom = psi4.geometry(geom_string); settings = {; 'scf_type': 'DF',; 'dft_basis_tolerance': 1e-10,; 'ints_tolerance': 1e-10,; 'dft_pruning_scheme':'robust',; 'S_ORTHOGONALIZATION': 'PARTIALCHOLESKY',; 'S_CHOLESKY_TOLERANCE': 1e-6,; 'wcombine': False,; }; psi4.set_options(settings); start_time = time.time(); grad = psi4.gradient(theory) ; psi4.core.print_variables(); energy = psi4.variable(""SCF TOTAL ENERGY""); psi4.core.clean(); jobtime = time.time() - start_time; results = {; ""time"": float(jobtime),; ""energy"": energy,; ""gradient"": grad.np.tolist(); }; print(f""{psi4.core.get_num_threads()=}""). with open(name + "".json"", ""w"") as fout:; json.dump(results, fout, indent=4). print(""Job %s completed in %.2f seconds with energy %.10f"" % (base, jobtime, energy)). def main(args):; assert args[1].endswith("".xyz""); psi4.set_num_threads(1); run_fxyz(args[1]). if __name__ == '__main__':; main(sys.argv); ```. ## Psithon vs. QCSchema. Another aside -- your input is written as a python script containing a single job and dropping the key results to json. This could also run through QCSchema with json input and json output, either API like https://github.com/psi4/psi4/blob/master/tests/pytests/test_addons.py#L792-L819 or command-line. Let me know if you'd want more details.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2548#issuecomment-1100294938
https://github.com/psi4/psi4/issues/2548#issuecomment-1100294938:781,Modifiability,variab,variable,781,"## XYZ Files. Just as an aside, here's two easier ways to deal with molecules when you have the coordinates. chg/mult from the xyz are possible https://github.com/MolSSI/QCElemental/blob/master/qcelemental/molparse/from_string.py#L117-L136. tu1.py; ```; import psi4. psi4.set_memory(""600 mb""). ### <<< Either ; #with open(""h2o.xyz"") as fp:; # fh2o = fp.read(); #; #psi4.geometry(fh2o). ### --- Or. h2o = psi4.core.Molecule.from_arrays(elem=[""O"", ""H"", ""H""], units=""Angstrom"", geom=[; 0.000000000000, 0.000000000000, -0.065775570538, ; 0.000000000000, -0.759061990794, 0.521953018295, ; 0.000000000000, 0.759061990794, 0.521953018295]) ; psi4.activate(h2o). ### >>> End. psi4.set_options({; ""basis"": ""cc-pVDZ"",; }); psi4.energy('scf'). psi4.compare_values(-76.0266327341067125, psi4.variable('SCF TOTAL ENERGY'), 6, 'SCF energy') #TEST; ```. h2o.xyz; ```; 3; sdlkfs; O 0.000000000000 0.000000000000 -0.065775570538 ; H 0.000000000000 -0.759061990794 0.521953018295 ; H 0.000000000000 0.759061990794 0.521953018295 . ```; ## Single Core. To actually address your problem, can you try the following edits? If you edit the installed copy, no recompile needed. Hopefully this solves it -- thanks for the report!; ```; diff --git a/psi4/driver/procrouting/empirical_dispersion.py b/psi4/driver/procrouting/empirical_dispersion.py; index d23f016..ea4f79d 100644; --- a/psi4/driver/procrouting/empirical_dispersion.py; +++ b/psi4/driver/procrouting/empirical_dispersion.py; @@ -213,7 +213,7 @@ class EmpiricalDispersion(object):; resi,; self.engine,; raise_error=True,; - local_options={""scratch_directory"": core.IOManager.shared_object().get_default_path()}); + local_options={""scratch_directory"": core.IOManager.shared_object().get_default_path(), ""ncores"": core.get_num_threads()}); ; dashd_part = float(jobrec.extras['qcvars']['DISPERSION CORRECTION ENERGY']); if wfn is not None:; @@ -231,7 +231,7 @@ class EmpiricalDispersion(object):; resi,; ""gcp"",; raise_error=True,; - local_options={""scratch_director",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2548#issuecomment-1100294938
https://github.com/psi4/psi4/issues/2548#issuecomment-1100294938:4363,Modifiability,variab,variable,4363,"'; fxyz: absolute path to an xyz file; '''; elements, xyz = [], []; with open(fxyz) as f:; line = next(f); numb_atoms = int(line.split()[0]); line = next(f); charge, multiplicity = map(int, line.split()); for i in range(numb_atoms):; line = next(f); elmnt, x, y, z = line.split() ; elements.append(elmnt); xyz.append((float(x), float(y), float(z))). fxyz = os.path.basename(fxyz); base, ext = os.path.splitext(fxyz). name = base + '_wB97XD3_def2-TZVP'. geom_string = '\n'.join(['%s %f %f %f' % (e, x, y, z) for e, (x, y, z) in zip(elements, xyz)]); geom_string = str(charge) + ' ' + str(multiplicity) + '\n' + geom_string; print(""geom_string"", geom_string). outfile = name + '.psi4'; psi4.core.set_output_file(outfile, False); geom = psi4.geometry(geom_string); settings = {; 'scf_type': 'DF',; 'dft_basis_tolerance': 1e-10,; 'ints_tolerance': 1e-10,; 'dft_pruning_scheme':'robust',; 'S_ORTHOGONALIZATION': 'PARTIALCHOLESKY',; 'S_CHOLESKY_TOLERANCE': 1e-6,; 'wcombine': False,; }; psi4.set_options(settings); start_time = time.time(); grad = psi4.gradient(theory) ; psi4.core.print_variables(); energy = psi4.variable(""SCF TOTAL ENERGY""); psi4.core.clean(); jobtime = time.time() - start_time; results = {; ""time"": float(jobtime),; ""energy"": energy,; ""gradient"": grad.np.tolist(); }; print(f""{psi4.core.get_num_threads()=}""). with open(name + "".json"", ""w"") as fout:; json.dump(results, fout, indent=4). print(""Job %s completed in %.2f seconds with energy %.10f"" % (base, jobtime, energy)). def main(args):; assert args[1].endswith("".xyz""); psi4.set_num_threads(1); run_fxyz(args[1]). if __name__ == '__main__':; main(sys.argv); ```. ## Psithon vs. QCSchema. Another aside -- your input is written as a python script containing a single job and dropping the key results to json. This could also run through QCSchema with json input and json output, either API like https://github.com/psi4/psi4/blob/master/tests/pytests/test_addons.py#L792-L819 or command-line. Let me know if you'd want more details.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2548#issuecomment-1100294938
https://github.com/psi4/psi4/issues/2548#issuecomment-1100294938:829,Testability,TEST,TEST,829,"## XYZ Files. Just as an aside, here's two easier ways to deal with molecules when you have the coordinates. chg/mult from the xyz are possible https://github.com/MolSSI/QCElemental/blob/master/qcelemental/molparse/from_string.py#L117-L136. tu1.py; ```; import psi4. psi4.set_memory(""600 mb""). ### <<< Either ; #with open(""h2o.xyz"") as fp:; # fh2o = fp.read(); #; #psi4.geometry(fh2o). ### --- Or. h2o = psi4.core.Molecule.from_arrays(elem=[""O"", ""H"", ""H""], units=""Angstrom"", geom=[; 0.000000000000, 0.000000000000, -0.065775570538, ; 0.000000000000, -0.759061990794, 0.521953018295, ; 0.000000000000, 0.759061990794, 0.521953018295]) ; psi4.activate(h2o). ### >>> End. psi4.set_options({; ""basis"": ""cc-pVDZ"",; }); psi4.energy('scf'). psi4.compare_values(-76.0266327341067125, psi4.variable('SCF TOTAL ENERGY'), 6, 'SCF energy') #TEST; ```. h2o.xyz; ```; 3; sdlkfs; O 0.000000000000 0.000000000000 -0.065775570538 ; H 0.000000000000 -0.759061990794 0.521953018295 ; H 0.000000000000 0.759061990794 0.521953018295 . ```; ## Single Core. To actually address your problem, can you try the following edits? If you edit the installed copy, no recompile needed. Hopefully this solves it -- thanks for the report!; ```; diff --git a/psi4/driver/procrouting/empirical_dispersion.py b/psi4/driver/procrouting/empirical_dispersion.py; index d23f016..ea4f79d 100644; --- a/psi4/driver/procrouting/empirical_dispersion.py; +++ b/psi4/driver/procrouting/empirical_dispersion.py; @@ -213,7 +213,7 @@ class EmpiricalDispersion(object):; resi,; self.engine,; raise_error=True,; - local_options={""scratch_directory"": core.IOManager.shared_object().get_default_path()}); + local_options={""scratch_directory"": core.IOManager.shared_object().get_default_path(), ""ncores"": core.get_num_threads()}); ; dashd_part = float(jobrec.extras['qcvars']['DISPERSION CORRECTION ENERGY']); if wfn is not None:; @@ -231,7 +231,7 @@ class EmpiricalDispersion(object):; resi,; ""gcp"",; raise_error=True,; - local_options={""scratch_director",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2548#issuecomment-1100294938
https://github.com/psi4/psi4/issues/2548#issuecomment-1100294938:4761,Testability,assert,assert,4761,"'; fxyz: absolute path to an xyz file; '''; elements, xyz = [], []; with open(fxyz) as f:; line = next(f); numb_atoms = int(line.split()[0]); line = next(f); charge, multiplicity = map(int, line.split()); for i in range(numb_atoms):; line = next(f); elmnt, x, y, z = line.split() ; elements.append(elmnt); xyz.append((float(x), float(y), float(z))). fxyz = os.path.basename(fxyz); base, ext = os.path.splitext(fxyz). name = base + '_wB97XD3_def2-TZVP'. geom_string = '\n'.join(['%s %f %f %f' % (e, x, y, z) for e, (x, y, z) in zip(elements, xyz)]); geom_string = str(charge) + ' ' + str(multiplicity) + '\n' + geom_string; print(""geom_string"", geom_string). outfile = name + '.psi4'; psi4.core.set_output_file(outfile, False); geom = psi4.geometry(geom_string); settings = {; 'scf_type': 'DF',; 'dft_basis_tolerance': 1e-10,; 'ints_tolerance': 1e-10,; 'dft_pruning_scheme':'robust',; 'S_ORTHOGONALIZATION': 'PARTIALCHOLESKY',; 'S_CHOLESKY_TOLERANCE': 1e-6,; 'wcombine': False,; }; psi4.set_options(settings); start_time = time.time(); grad = psi4.gradient(theory) ; psi4.core.print_variables(); energy = psi4.variable(""SCF TOTAL ENERGY""); psi4.core.clean(); jobtime = time.time() - start_time; results = {; ""time"": float(jobtime),; ""energy"": energy,; ""gradient"": grad.np.tolist(); }; print(f""{psi4.core.get_num_threads()=}""). with open(name + "".json"", ""w"") as fout:; json.dump(results, fout, indent=4). print(""Job %s completed in %.2f seconds with energy %.10f"" % (base, jobtime, energy)). def main(args):; assert args[1].endswith("".xyz""); psi4.set_num_threads(1); run_fxyz(args[1]). if __name__ == '__main__':; main(sys.argv); ```. ## Psithon vs. QCSchema. Another aside -- your input is written as a python script containing a single job and dropping the key results to json. This could also run through QCSchema with json input and json output, either API like https://github.com/psi4/psi4/blob/master/tests/pytests/test_addons.py#L792-L819 or command-line. Let me know if you'd want more details.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2548#issuecomment-1100294938
https://github.com/psi4/psi4/issues/2548#issuecomment-1100294938:5159,Testability,test,tests,5159,"'; fxyz: absolute path to an xyz file; '''; elements, xyz = [], []; with open(fxyz) as f:; line = next(f); numb_atoms = int(line.split()[0]); line = next(f); charge, multiplicity = map(int, line.split()); for i in range(numb_atoms):; line = next(f); elmnt, x, y, z = line.split() ; elements.append(elmnt); xyz.append((float(x), float(y), float(z))). fxyz = os.path.basename(fxyz); base, ext = os.path.splitext(fxyz). name = base + '_wB97XD3_def2-TZVP'. geom_string = '\n'.join(['%s %f %f %f' % (e, x, y, z) for e, (x, y, z) in zip(elements, xyz)]); geom_string = str(charge) + ' ' + str(multiplicity) + '\n' + geom_string; print(""geom_string"", geom_string). outfile = name + '.psi4'; psi4.core.set_output_file(outfile, False); geom = psi4.geometry(geom_string); settings = {; 'scf_type': 'DF',; 'dft_basis_tolerance': 1e-10,; 'ints_tolerance': 1e-10,; 'dft_pruning_scheme':'robust',; 'S_ORTHOGONALIZATION': 'PARTIALCHOLESKY',; 'S_CHOLESKY_TOLERANCE': 1e-6,; 'wcombine': False,; }; psi4.set_options(settings); start_time = time.time(); grad = psi4.gradient(theory) ; psi4.core.print_variables(); energy = psi4.variable(""SCF TOTAL ENERGY""); psi4.core.clean(); jobtime = time.time() - start_time; results = {; ""time"": float(jobtime),; ""energy"": energy,; ""gradient"": grad.np.tolist(); }; print(f""{psi4.core.get_num_threads()=}""). with open(name + "".json"", ""w"") as fout:; json.dump(results, fout, indent=4). print(""Job %s completed in %.2f seconds with energy %.10f"" % (base, jobtime, energy)). def main(args):; assert args[1].endswith("".xyz""); psi4.set_num_threads(1); run_fxyz(args[1]). if __name__ == '__main__':; main(sys.argv); ```. ## Psithon vs. QCSchema. Another aside -- your input is written as a python script containing a single job and dropping the key results to json. This could also run through QCSchema with json input and json output, either API like https://github.com/psi4/psi4/blob/master/tests/pytests/test_addons.py#L792-L819 or command-line. Let me know if you'd want more details.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2548#issuecomment-1100294938
https://github.com/psi4/psi4/pull/2549#issuecomment-1117822674:17,Testability,test,tests,17,"> I see that the tests in tests/optking are nested and didn't get individual python files. Is this intentional / okay? Otherwise LGTM!. Yes, I deferred all the cleanup to #2555, and RAK is fine with deleting most.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2549#issuecomment-1117822674
https://github.com/psi4/psi4/pull/2549#issuecomment-1117822674:26,Testability,test,tests,26,"> I see that the tests in tests/optking are nested and didn't get individual python files. Is this intentional / okay? Otherwise LGTM!. Yes, I deferred all the cleanup to #2555, and RAK is fine with deleting most.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2549#issuecomment-1117822674
https://github.com/psi4/psi4/pull/2550#issuecomment-1104634251:20,Availability,error,error,20,"Hmm, I got an ADIIS error in windows (on a pytest) for my tests. Is this to be expected?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2550#issuecomment-1104634251
https://github.com/psi4/psi4/pull/2550#issuecomment-1104634251:58,Testability,test,tests,58,"Hmm, I got an ADIIS error in windows (on a pytest) for my tests. Is this to be expected?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2550#issuecomment-1104634251
https://github.com/psi4/psi4/pull/2550#issuecomment-1104645481:7,Availability,error,error,7,"aediis error for windows + test_psi4_sapt may be intermittent since not seen in first commit. there's no reason incfock should be on in that test, right? in that case, no problem.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2550#issuecomment-1104645481
https://github.com/psi4/psi4/pull/2550#issuecomment-1104645481:141,Testability,test,test,141,"aediis error for windows + test_psi4_sapt may be intermittent since not seen in first commit. there's no reason incfock should be on in that test, right? in that case, no problem.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2550#issuecomment-1104645481
https://github.com/psi4/psi4/pull/2550#issuecomment-1104653717:86,Availability,failure,failures,86,"That test is DF, not direct, so this PR is innocent. I had observed some random ADIIS failures previously but thought I had fixed them. I recommend we rerun the failed test and save investigation into the ADIIS situation for a future PR. (Probably to be done by me.)",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2550#issuecomment-1104653717
https://github.com/psi4/psi4/pull/2550#issuecomment-1104653717:5,Testability,test,test,5,"That test is DF, not direct, so this PR is innocent. I had observed some random ADIIS failures previously but thought I had fixed them. I recommend we rerun the failed test and save investigation into the ADIIS situation for a future PR. (Probably to be done by me.)",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2550#issuecomment-1104653717
https://github.com/psi4/psi4/pull/2550#issuecomment-1104653717:168,Testability,test,test,168,"That test is DF, not direct, so this PR is innocent. I had observed some random ADIIS failures previously but thought I had fixed them. I recommend we rerun the failed test and save investigation into the ADIIS situation for a future PR. (Probably to be done by me.)",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2550#issuecomment-1104653717
https://github.com/psi4/psi4/pull/2551#issuecomment-1105931246:11,Availability,down,down,11,"One kicked down to future work, but all others applied.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2551#issuecomment-1105931246
https://github.com/psi4/psi4/issues/2553#issuecomment-1105670625:940,Energy Efficiency,energy,energy,940,"Yes, you can use `from_arrays` like below that takes [these arguments](https://github.com/MolSSI/QCElemental/blob/master/qcelemental/molparse/from_arrays.py#L136-L293). Then you have to either activate the molecule (`psi4.geometry()` does this behind the scenes) or pass the molecule explicitly to each calculation line. `from_arrays` is the same fn that `geometry()` is calling after parsing the string. If you want to get the arrays back out of a built molecule, there's a `to_dict()` fn. Let me know if there's other functionality that would be handy but you can't find. Also, be aware of running in schema mode with json in and json out. ```; h2o = psi4.core.Molecule.from_arrays(elem=[""O"", ""H"", ""H""], units=""Angstrom"", geom=[; 0.000000000000, 0.000000000000, -0.065775570538, ; 0.000000000000, -0.759061990794, 0.521953018295, ; 0.000000000000, 0.759061990794, 0.521953018295]) ; psi4.activate(h2o); # activate -or- pass into fn; psi4.energy(..., molecule=h2o); ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2553#issuecomment-1105670625
https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137:101,Availability,avail,available,101,"The only thing worth hanging onto might be the bakerjcc93. But if we've; got that database otherwise available, then deletion fine with me. On Fri, Apr 22, 2022 at 11:14 AM Lori A. Burns ***@***.***>; wrote:. > after #2549 <https://github.com/psi4/psi4/pull/2549>, the list from python; > tester.py looks like the below. Most of these are easily healed by; > figuring out if they're intended to be a test or not. Nots should be; > removed to an attic or deleted. Also related is #2234; > <https://github.com/psi4/psi4/issues/2234> . don't rely on the below --; > rerun tester.py as needed.; >; > @psi-rking <https://github.com/psi-rking>, do you prefer attic or; > deletion for the un-run optimizer tests?; > Complaints; >; > - 1. cc5: missing cmake directory registration. vi CMakeLists.txt; > - 2. cookbook/manual-sow-reap: missing cmake directory registration. vi; > cookbook/CMakeLists.txt; > - 3. cookbook/manual-sow-reap: missing CMakeLists. vi; > cookbook/manual-sow-reap/CMakeLists.txt; > - 4. dfmp2-freq1: missing cmake directory registration. vi; > CMakeLists.txt; > - 5. dfmp2-freq2: missing cmake directory registration. vi; > CMakeLists.txt; > - 6. dfomp2p5-1: missing ctest registration. vi; > dfomp2p5-1/CMakeLists.txt; > - 7. dfomp2p5-2: missing ctest registration. vi; > dfomp2p5-2/CMakeLists.txt; > - 8. dfomp2p5-grad1: missing ctest registration. vi; > dfomp2p5-grad1/CMakeLists.txt; > - 9. dfomp2p5-grad2: missing ctest registration. vi; > dfomp2p5-grad2/CMakeLists.txt; > - 10. dft-dldf: missing cmake directory registration. vi CMakeLists.txt; > - 11. dft-dsd: missing cmake directory registration. vi CMakeLists.txt; > - 12. dft-pbe0-2: missing cmake directory registration. vi; > CMakeLists.txt; > - 13. explicit-am-basis: mismatched directory (explicit-am-basis) and; > ctest registration name (explicit_am_basis). vi; > explicit-am-basis/CMakeLists.txt; > - 14. fsapt-diff1: missing cmake directory registration. vi; > CMakeLists.txt; > - 15. fsapt-diff1: missing CMakeLists.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137
https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137:8701,Integrability,Message,Message,8701," marks ctest (longtests;snsmp;cart) and; > pytest (long;cart). vi snsmp2/cc-cc/CMakeLists.txt; > snsmp2/cc-cc/test_input.py; > - 66. snsmp2/cf-o: mismatched marks ctest (snsmp;cart) and pytest; > (cart). vi snsmp2/cf-o/CMakeLists.txt snsmp2/cf-o/test_input.py; > - 67. snsmp2/he-he: mismatched marks ctest (quick;smoke;snsmp;cart); > and pytest (quick;smoke;cart). vi snsmp2/he-he/CMakeLists.txt; > snsmp2/he-he/test_input.py; > - 68. v2rdm_casscf/v2rdm1: mismatched marks ctest (v2rdm) and pytest; > (). vi v2rdm_casscf/v2rdm1/CMakeLists.txt; > v2rdm_casscf/v2rdm1/test_input.py; > - 69. v2rdm_casscf/v2rdm2: mismatched marks ctest (v2rdm) and pytest; > (). vi v2rdm_casscf/v2rdm2/CMakeLists.txt; > v2rdm_casscf/v2rdm2/test_input.py; > - 70. v2rdm_casscf/v2rdm3: mismatched marks ctest (quick;smoke;v2rdm); > and pytest (quick;smoke). vi v2rdm_casscf/v2rdm3/CMakeLists.txt; > v2rdm_casscf/v2rdm3/test_input.py; > - 71. v2rdm_casscf/v2rdm4: mismatched marks ctest (v2rdm;cart) and; > pytest (cart). vi v2rdm_casscf/v2rdm4/CMakeLists.txt; > v2rdm_casscf/v2rdm4/test_input.py; > - 72. v2rdm_casscf/v2rdm5: mismatched marks ctest (v2rdm) and pytest; > (). vi v2rdm_casscf/v2rdm5/CMakeLists.txt; > v2rdm_casscf/v2rdm5/test_input.py; > - 73. v2rdm_casscf/v2rdm6: mismatched marks ctest (opt;v2rdm) and; > pytest (opt). vi v2rdm_casscf/v2rdm6/CMakeLists.txt; > v2rdm_casscf/v2rdm6/test_input.py; > - 74. v2rdm_casscf/v2rdm7: mismatched marks ctest (opt;v2rdm) and; > pytest (opt). vi v2rdm_casscf/v2rdm7/CMakeLists.txt; > v2rdm_casscf/v2rdm7/test_input.py; > - 75. x2c-perturb-h: mismatched directory (x2c-perturb-h) and ctest; > registration name (x2c-perturb_h). vi x2c-perturb-h/CMakeLists.txt; >; > ; > Reply to this email directly, view it on GitHub; > <https://github.com/psi4/psi4/issues/2555>, or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AA4C4TEYSZO53JGHUQ2E3ETVGLF65ANCNFSM5UCYRSWQ>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137
https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137:4506,Modifiability,plugin,plugins,4506,ng/bakerjcc93/CMakeLists.txt; > - 31. optking/beran: missing cmake directory registration. vi; > optking/CMakeLists.txt; > - 32. optking/beran: missing docs comment. vi optking/beran/input.dat; > - 33. optking/beran: missing CMakeLists. vi; > optking/beran/CMakeLists.txt; > - 34. optking/dlpc: missing cmake directory registration. vi; > optking/CMakeLists.txt; > - 35. optking/dlpc: missing docs comment. vi optking/dlpc/input.dat; > - 36. optking/dlpc: missing CMakeLists. vi optking/dlpc/CMakeLists.txt; > - 37. optking/h2o: missing cmake directory registration. vi; > optking/CMakeLists.txt; > - 38. optking/h2o: missing docs comment. vi optking/h2o/input.dat; > - 39. optking/h2o: missing CMakeLists. vi optking/h2o/CMakeLists.txt; > - 40. optking/h2os: missing cmake directory registration. vi; > optking/CMakeLists.txt; > - 41. optking/h2os: missing docs comment. vi optking/h2os/input.dat; > - 42. optking/h2os: missing CMakeLists. vi optking/h2os/CMakeLists.txt; > - 43. plugins/skeleton: missing docs comment. vi; > plugins/skeleton/input.dat; > - 44. plugins/skeleton: missing ctest registration. vi; > plugins/skeleton/CMakeLists.txt; > - 45. plugins/skeletonaointegrals: missing docs comment. vi; > plugins/skeletonaointegrals/input.dat; > - 46. plugins/skeletonaointegrals: missing ctest registration. vi; > plugins/skeletonaointegrals/CMakeLists.txt; > - 47. plugins/skeletondfmp2: missing docs comment. vi; > plugins/skeletondfmp2/input.dat; > - 48. plugins/skeletondfmp2: missing ctest registration. vi; > plugins/skeletondfmp2/CMakeLists.txt; > - 49. plugins/skeletonmointegrals: missing docs comment. vi; > plugins/skeletonmointegrals/input.dat; > - 50. plugins/skeletonmointegrals: missing ctest registration. vi; > plugins/skeletonmointegrals/CMakeLists.txt; > - 51. plugins/skeletonscf: missing docs comment. vi; > plugins/skeletonscf/input.dat; > - 52. plugins/skeletonscf: missing ctest registration. vi; > plugins/skeletonscf/CMakeLists.txt; > - 53. plugins/skeletonsointegr,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137
https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137:4552,Modifiability,plugin,plugins,4552,1. optking/beran: missing cmake directory registration. vi; > optking/CMakeLists.txt; > - 32. optking/beran: missing docs comment. vi optking/beran/input.dat; > - 33. optking/beran: missing CMakeLists. vi; > optking/beran/CMakeLists.txt; > - 34. optking/dlpc: missing cmake directory registration. vi; > optking/CMakeLists.txt; > - 35. optking/dlpc: missing docs comment. vi optking/dlpc/input.dat; > - 36. optking/dlpc: missing CMakeLists. vi optking/dlpc/CMakeLists.txt; > - 37. optking/h2o: missing cmake directory registration. vi; > optking/CMakeLists.txt; > - 38. optking/h2o: missing docs comment. vi optking/h2o/input.dat; > - 39. optking/h2o: missing CMakeLists. vi optking/h2o/CMakeLists.txt; > - 40. optking/h2os: missing cmake directory registration. vi; > optking/CMakeLists.txt; > - 41. optking/h2os: missing docs comment. vi optking/h2os/input.dat; > - 42. optking/h2os: missing CMakeLists. vi optking/h2os/CMakeLists.txt; > - 43. plugins/skeleton: missing docs comment. vi; > plugins/skeleton/input.dat; > - 44. plugins/skeleton: missing ctest registration. vi; > plugins/skeleton/CMakeLists.txt; > - 45. plugins/skeletonaointegrals: missing docs comment. vi; > plugins/skeletonaointegrals/input.dat; > - 46. plugins/skeletonaointegrals: missing ctest registration. vi; > plugins/skeletonaointegrals/CMakeLists.txt; > - 47. plugins/skeletondfmp2: missing docs comment. vi; > plugins/skeletondfmp2/input.dat; > - 48. plugins/skeletondfmp2: missing ctest registration. vi; > plugins/skeletondfmp2/CMakeLists.txt; > - 49. plugins/skeletonmointegrals: missing docs comment. vi; > plugins/skeletonmointegrals/input.dat; > - 50. plugins/skeletonmointegrals: missing ctest registration. vi; > plugins/skeletonmointegrals/CMakeLists.txt; > - 51. plugins/skeletonscf: missing docs comment. vi; > plugins/skeletonscf/input.dat; > - 52. plugins/skeletonscf: missing ctest registration. vi; > plugins/skeletonscf/CMakeLists.txt; > - 53. plugins/skeletonsointegrals: missing docs comment. vi; > pl,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137
https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137:4588,Modifiability,plugin,plugins,4588,tion. vi; > optking/CMakeLists.txt; > - 32. optking/beran: missing docs comment. vi optking/beran/input.dat; > - 33. optking/beran: missing CMakeLists. vi; > optking/beran/CMakeLists.txt; > - 34. optking/dlpc: missing cmake directory registration. vi; > optking/CMakeLists.txt; > - 35. optking/dlpc: missing docs comment. vi optking/dlpc/input.dat; > - 36. optking/dlpc: missing CMakeLists. vi optking/dlpc/CMakeLists.txt; > - 37. optking/h2o: missing cmake directory registration. vi; > optking/CMakeLists.txt; > - 38. optking/h2o: missing docs comment. vi optking/h2o/input.dat; > - 39. optking/h2o: missing CMakeLists. vi optking/h2o/CMakeLists.txt; > - 40. optking/h2os: missing cmake directory registration. vi; > optking/CMakeLists.txt; > - 41. optking/h2os: missing docs comment. vi optking/h2os/input.dat; > - 42. optking/h2os: missing CMakeLists. vi optking/h2os/CMakeLists.txt; > - 43. plugins/skeleton: missing docs comment. vi; > plugins/skeleton/input.dat; > - 44. plugins/skeleton: missing ctest registration. vi; > plugins/skeleton/CMakeLists.txt; > - 45. plugins/skeletonaointegrals: missing docs comment. vi; > plugins/skeletonaointegrals/input.dat; > - 46. plugins/skeletonaointegrals: missing ctest registration. vi; > plugins/skeletonaointegrals/CMakeLists.txt; > - 47. plugins/skeletondfmp2: missing docs comment. vi; > plugins/skeletondfmp2/input.dat; > - 48. plugins/skeletondfmp2: missing ctest registration. vi; > plugins/skeletondfmp2/CMakeLists.txt; > - 49. plugins/skeletonmointegrals: missing docs comment. vi; > plugins/skeletonmointegrals/input.dat; > - 50. plugins/skeletonmointegrals: missing ctest registration. vi; > plugins/skeletonmointegrals/CMakeLists.txt; > - 51. plugins/skeletonscf: missing docs comment. vi; > plugins/skeletonscf/input.dat; > - 52. plugins/skeletonscf: missing ctest registration. vi; > plugins/skeletonscf/CMakeLists.txt; > - 53. plugins/skeletonsointegrals: missing docs comment. vi; > plugins/skeletonsointegrals/input.dat; > - 54. plugi,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137
https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137:4640,Modifiability,plugin,plugins,4640,32. optking/beran: missing docs comment. vi optking/beran/input.dat; > - 33. optking/beran: missing CMakeLists. vi; > optking/beran/CMakeLists.txt; > - 34. optking/dlpc: missing cmake directory registration. vi; > optking/CMakeLists.txt; > - 35. optking/dlpc: missing docs comment. vi optking/dlpc/input.dat; > - 36. optking/dlpc: missing CMakeLists. vi optking/dlpc/CMakeLists.txt; > - 37. optking/h2o: missing cmake directory registration. vi; > optking/CMakeLists.txt; > - 38. optking/h2o: missing docs comment. vi optking/h2o/input.dat; > - 39. optking/h2o: missing CMakeLists. vi optking/h2o/CMakeLists.txt; > - 40. optking/h2os: missing cmake directory registration. vi; > optking/CMakeLists.txt; > - 41. optking/h2os: missing docs comment. vi optking/h2os/input.dat; > - 42. optking/h2os: missing CMakeLists. vi optking/h2os/CMakeLists.txt; > - 43. plugins/skeleton: missing docs comment. vi; > plugins/skeleton/input.dat; > - 44. plugins/skeleton: missing ctest registration. vi; > plugins/skeleton/CMakeLists.txt; > - 45. plugins/skeletonaointegrals: missing docs comment. vi; > plugins/skeletonaointegrals/input.dat; > - 46. plugins/skeletonaointegrals: missing ctest registration. vi; > plugins/skeletonaointegrals/CMakeLists.txt; > - 47. plugins/skeletondfmp2: missing docs comment. vi; > plugins/skeletondfmp2/input.dat; > - 48. plugins/skeletondfmp2: missing ctest registration. vi; > plugins/skeletondfmp2/CMakeLists.txt; > - 49. plugins/skeletonmointegrals: missing docs comment. vi; > plugins/skeletonmointegrals/input.dat; > - 50. plugins/skeletonmointegrals: missing ctest registration. vi; > plugins/skeletonmointegrals/CMakeLists.txt; > - 51. plugins/skeletonscf: missing docs comment. vi; > plugins/skeletonscf/input.dat; > - 52. plugins/skeletonscf: missing ctest registration. vi; > plugins/skeletonscf/CMakeLists.txt; > - 53. plugins/skeletonsointegrals: missing docs comment. vi; > plugins/skeletonsointegrals/input.dat; > - 54. plugins/skeletonsointegrals: missing ctest reg,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137
https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137:4681,Modifiability,plugin,plugins,4681,an/input.dat; > - 33. optking/beran: missing CMakeLists. vi; > optking/beran/CMakeLists.txt; > - 34. optking/dlpc: missing cmake directory registration. vi; > optking/CMakeLists.txt; > - 35. optking/dlpc: missing docs comment. vi optking/dlpc/input.dat; > - 36. optking/dlpc: missing CMakeLists. vi optking/dlpc/CMakeLists.txt; > - 37. optking/h2o: missing cmake directory registration. vi; > optking/CMakeLists.txt; > - 38. optking/h2o: missing docs comment. vi optking/h2o/input.dat; > - 39. optking/h2o: missing CMakeLists. vi optking/h2o/CMakeLists.txt; > - 40. optking/h2os: missing cmake directory registration. vi; > optking/CMakeLists.txt; > - 41. optking/h2os: missing docs comment. vi optking/h2os/input.dat; > - 42. optking/h2os: missing CMakeLists. vi optking/h2os/CMakeLists.txt; > - 43. plugins/skeleton: missing docs comment. vi; > plugins/skeleton/input.dat; > - 44. plugins/skeleton: missing ctest registration. vi; > plugins/skeleton/CMakeLists.txt; > - 45. plugins/skeletonaointegrals: missing docs comment. vi; > plugins/skeletonaointegrals/input.dat; > - 46. plugins/skeletonaointegrals: missing ctest registration. vi; > plugins/skeletonaointegrals/CMakeLists.txt; > - 47. plugins/skeletondfmp2: missing docs comment. vi; > plugins/skeletondfmp2/input.dat; > - 48. plugins/skeletondfmp2: missing ctest registration. vi; > plugins/skeletondfmp2/CMakeLists.txt; > - 49. plugins/skeletonmointegrals: missing docs comment. vi; > plugins/skeletonmointegrals/input.dat; > - 50. plugins/skeletonmointegrals: missing ctest registration. vi; > plugins/skeletonmointegrals/CMakeLists.txt; > - 51. plugins/skeletonscf: missing docs comment. vi; > plugins/skeletonscf/input.dat; > - 52. plugins/skeletonscf: missing ctest registration. vi; > plugins/skeletonscf/CMakeLists.txt; > - 53. plugins/skeletonsointegrals: missing docs comment. vi; > plugins/skeletonsointegrals/input.dat; > - 54. plugins/skeletonsointegrals: missing ctest registration. vi; > plugins/skeletonsointegrals/CMakeLists,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137
https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137:4738,Modifiability,plugin,plugins,4738,MakeLists. vi; > optking/beran/CMakeLists.txt; > - 34. optking/dlpc: missing cmake directory registration. vi; > optking/CMakeLists.txt; > - 35. optking/dlpc: missing docs comment. vi optking/dlpc/input.dat; > - 36. optking/dlpc: missing CMakeLists. vi optking/dlpc/CMakeLists.txt; > - 37. optking/h2o: missing cmake directory registration. vi; > optking/CMakeLists.txt; > - 38. optking/h2o: missing docs comment. vi optking/h2o/input.dat; > - 39. optking/h2o: missing CMakeLists. vi optking/h2o/CMakeLists.txt; > - 40. optking/h2os: missing cmake directory registration. vi; > optking/CMakeLists.txt; > - 41. optking/h2os: missing docs comment. vi optking/h2os/input.dat; > - 42. optking/h2os: missing CMakeLists. vi optking/h2os/CMakeLists.txt; > - 43. plugins/skeleton: missing docs comment. vi; > plugins/skeleton/input.dat; > - 44. plugins/skeleton: missing ctest registration. vi; > plugins/skeleton/CMakeLists.txt; > - 45. plugins/skeletonaointegrals: missing docs comment. vi; > plugins/skeletonaointegrals/input.dat; > - 46. plugins/skeletonaointegrals: missing ctest registration. vi; > plugins/skeletonaointegrals/CMakeLists.txt; > - 47. plugins/skeletondfmp2: missing docs comment. vi; > plugins/skeletondfmp2/input.dat; > - 48. plugins/skeletondfmp2: missing ctest registration. vi; > plugins/skeletondfmp2/CMakeLists.txt; > - 49. plugins/skeletonmointegrals: missing docs comment. vi; > plugins/skeletonmointegrals/input.dat; > - 50. plugins/skeletonmointegrals: missing ctest registration. vi; > plugins/skeletonmointegrals/CMakeLists.txt; > - 51. plugins/skeletonscf: missing docs comment. vi; > plugins/skeletonscf/input.dat; > - 52. plugins/skeletonscf: missing ctest registration. vi; > plugins/skeletonscf/CMakeLists.txt; > - 53. plugins/skeletonsointegrals: missing docs comment. vi; > plugins/skeletonsointegrals/input.dat; > - 54. plugins/skeletonsointegrals: missing ctest registration. vi; > plugins/skeletonsointegrals/CMakeLists.txt; > - 55. plugins/skeletonwavefunction: mi,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137
https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137:4785,Modifiability,plugin,plugins,4785,g/dlpc: missing cmake directory registration. vi; > optking/CMakeLists.txt; > - 35. optking/dlpc: missing docs comment. vi optking/dlpc/input.dat; > - 36. optking/dlpc: missing CMakeLists. vi optking/dlpc/CMakeLists.txt; > - 37. optking/h2o: missing cmake directory registration. vi; > optking/CMakeLists.txt; > - 38. optking/h2o: missing docs comment. vi optking/h2o/input.dat; > - 39. optking/h2o: missing CMakeLists. vi optking/h2o/CMakeLists.txt; > - 40. optking/h2os: missing cmake directory registration. vi; > optking/CMakeLists.txt; > - 41. optking/h2os: missing docs comment. vi optking/h2os/input.dat; > - 42. optking/h2os: missing CMakeLists. vi optking/h2os/CMakeLists.txt; > - 43. plugins/skeleton: missing docs comment. vi; > plugins/skeleton/input.dat; > - 44. plugins/skeleton: missing ctest registration. vi; > plugins/skeleton/CMakeLists.txt; > - 45. plugins/skeletonaointegrals: missing docs comment. vi; > plugins/skeletonaointegrals/input.dat; > - 46. plugins/skeletonaointegrals: missing ctest registration. vi; > plugins/skeletonaointegrals/CMakeLists.txt; > - 47. plugins/skeletondfmp2: missing docs comment. vi; > plugins/skeletondfmp2/input.dat; > - 48. plugins/skeletondfmp2: missing ctest registration. vi; > plugins/skeletondfmp2/CMakeLists.txt; > - 49. plugins/skeletonmointegrals: missing docs comment. vi; > plugins/skeletonmointegrals/input.dat; > - 50. plugins/skeletonmointegrals: missing ctest registration. vi; > plugins/skeletonmointegrals/CMakeLists.txt; > - 51. plugins/skeletonscf: missing docs comment. vi; > plugins/skeletonscf/input.dat; > - 52. plugins/skeletonscf: missing ctest registration. vi; > plugins/skeletonscf/CMakeLists.txt; > - 53. plugins/skeletonsointegrals: missing docs comment. vi; > plugins/skeletonsointegrals/input.dat; > - 54. plugins/skeletonsointegrals: missing ctest registration. vi; > plugins/skeletonsointegrals/CMakeLists.txt; > - 55. plugins/skeletonwavefunction: missing docs comment. vi; > plugins/skeletonwavefunction/input.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137
https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137:4848,Modifiability,plugin,plugins,4848,optking/CMakeLists.txt; > - 35. optking/dlpc: missing docs comment. vi optking/dlpc/input.dat; > - 36. optking/dlpc: missing CMakeLists. vi optking/dlpc/CMakeLists.txt; > - 37. optking/h2o: missing cmake directory registration. vi; > optking/CMakeLists.txt; > - 38. optking/h2o: missing docs comment. vi optking/h2o/input.dat; > - 39. optking/h2o: missing CMakeLists. vi optking/h2o/CMakeLists.txt; > - 40. optking/h2os: missing cmake directory registration. vi; > optking/CMakeLists.txt; > - 41. optking/h2os: missing docs comment. vi optking/h2os/input.dat; > - 42. optking/h2os: missing CMakeLists. vi optking/h2os/CMakeLists.txt; > - 43. plugins/skeleton: missing docs comment. vi; > plugins/skeleton/input.dat; > - 44. plugins/skeleton: missing ctest registration. vi; > plugins/skeleton/CMakeLists.txt; > - 45. plugins/skeletonaointegrals: missing docs comment. vi; > plugins/skeletonaointegrals/input.dat; > - 46. plugins/skeletonaointegrals: missing ctest registration. vi; > plugins/skeletonaointegrals/CMakeLists.txt; > - 47. plugins/skeletondfmp2: missing docs comment. vi; > plugins/skeletondfmp2/input.dat; > - 48. plugins/skeletondfmp2: missing ctest registration. vi; > plugins/skeletondfmp2/CMakeLists.txt; > - 49. plugins/skeletonmointegrals: missing docs comment. vi; > plugins/skeletonmointegrals/input.dat; > - 50. plugins/skeletonmointegrals: missing ctest registration. vi; > plugins/skeletonmointegrals/CMakeLists.txt; > - 51. plugins/skeletonscf: missing docs comment. vi; > plugins/skeletonscf/input.dat; > - 52. plugins/skeletonscf: missing ctest registration. vi; > plugins/skeletonscf/CMakeLists.txt; > - 53. plugins/skeletonsointegrals: missing docs comment. vi; > plugins/skeletonsointegrals/input.dat; > - 54. plugins/skeletonsointegrals: missing ctest registration. vi; > plugins/skeletonsointegrals/CMakeLists.txt; > - 55. plugins/skeletonwavefunction: missing docs comment. vi; > plugins/skeletonwavefunction/input.dat; > - 56. plugins/skeletonwavefunction: missing ,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137
https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137:4900,Modifiability,plugin,plugins,4900,s comment. vi optking/dlpc/input.dat; > - 36. optking/dlpc: missing CMakeLists. vi optking/dlpc/CMakeLists.txt; > - 37. optking/h2o: missing cmake directory registration. vi; > optking/CMakeLists.txt; > - 38. optking/h2o: missing docs comment. vi optking/h2o/input.dat; > - 39. optking/h2o: missing CMakeLists. vi optking/h2o/CMakeLists.txt; > - 40. optking/h2os: missing cmake directory registration. vi; > optking/CMakeLists.txt; > - 41. optking/h2os: missing docs comment. vi optking/h2os/input.dat; > - 42. optking/h2os: missing CMakeLists. vi optking/h2os/CMakeLists.txt; > - 43. plugins/skeleton: missing docs comment. vi; > plugins/skeleton/input.dat; > - 44. plugins/skeleton: missing ctest registration. vi; > plugins/skeleton/CMakeLists.txt; > - 45. plugins/skeletonaointegrals: missing docs comment. vi; > plugins/skeletonaointegrals/input.dat; > - 46. plugins/skeletonaointegrals: missing ctest registration. vi; > plugins/skeletonaointegrals/CMakeLists.txt; > - 47. plugins/skeletondfmp2: missing docs comment. vi; > plugins/skeletondfmp2/input.dat; > - 48. plugins/skeletondfmp2: missing ctest registration. vi; > plugins/skeletondfmp2/CMakeLists.txt; > - 49. plugins/skeletonmointegrals: missing docs comment. vi; > plugins/skeletonmointegrals/input.dat; > - 50. plugins/skeletonmointegrals: missing ctest registration. vi; > plugins/skeletonmointegrals/CMakeLists.txt; > - 51. plugins/skeletonscf: missing docs comment. vi; > plugins/skeletonscf/input.dat; > - 52. plugins/skeletonscf: missing ctest registration. vi; > plugins/skeletonscf/CMakeLists.txt; > - 53. plugins/skeletonsointegrals: missing docs comment. vi; > plugins/skeletonsointegrals/input.dat; > - 54. plugins/skeletonsointegrals: missing ctest registration. vi; > plugins/skeletonsointegrals/CMakeLists.txt; > - 55. plugins/skeletonwavefunction: missing docs comment. vi; > plugins/skeletonwavefunction/input.dat; > - 56. plugins/skeletonwavefunction: missing ctest registration. vi; > plugins/skeletonwavefunction/CMa,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137
https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137:4951,Modifiability,plugin,plugins,4951,- 36. optking/dlpc: missing CMakeLists. vi optking/dlpc/CMakeLists.txt; > - 37. optking/h2o: missing cmake directory registration. vi; > optking/CMakeLists.txt; > - 38. optking/h2o: missing docs comment. vi optking/h2o/input.dat; > - 39. optking/h2o: missing CMakeLists. vi optking/h2o/CMakeLists.txt; > - 40. optking/h2os: missing cmake directory registration. vi; > optking/CMakeLists.txt; > - 41. optking/h2os: missing docs comment. vi optking/h2os/input.dat; > - 42. optking/h2os: missing CMakeLists. vi optking/h2os/CMakeLists.txt; > - 43. plugins/skeleton: missing docs comment. vi; > plugins/skeleton/input.dat; > - 44. plugins/skeleton: missing ctest registration. vi; > plugins/skeleton/CMakeLists.txt; > - 45. plugins/skeletonaointegrals: missing docs comment. vi; > plugins/skeletonaointegrals/input.dat; > - 46. plugins/skeletonaointegrals: missing ctest registration. vi; > plugins/skeletonaointegrals/CMakeLists.txt; > - 47. plugins/skeletondfmp2: missing docs comment. vi; > plugins/skeletondfmp2/input.dat; > - 48. plugins/skeletondfmp2: missing ctest registration. vi; > plugins/skeletondfmp2/CMakeLists.txt; > - 49. plugins/skeletonmointegrals: missing docs comment. vi; > plugins/skeletonmointegrals/input.dat; > - 50. plugins/skeletonmointegrals: missing ctest registration. vi; > plugins/skeletonmointegrals/CMakeLists.txt; > - 51. plugins/skeletonscf: missing docs comment. vi; > plugins/skeletonscf/input.dat; > - 52. plugins/skeletonscf: missing ctest registration. vi; > plugins/skeletonscf/CMakeLists.txt; > - 53. plugins/skeletonsointegrals: missing docs comment. vi; > plugins/skeletonsointegrals/input.dat; > - 54. plugins/skeletonsointegrals: missing ctest registration. vi; > plugins/skeletonsointegrals/CMakeLists.txt; > - 55. plugins/skeletonwavefunction: missing docs comment. vi; > plugins/skeletonwavefunction/input.dat; > - 56. plugins/skeletonwavefunction: missing ctest registration. vi; > plugins/skeletonwavefunction/CMakeLists.txt; > - 57. props4: missing cma,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137
https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137:4992,Modifiability,plugin,plugins,4992,/CMakeLists.txt; > - 37. optking/h2o: missing cmake directory registration. vi; > optking/CMakeLists.txt; > - 38. optking/h2o: missing docs comment. vi optking/h2o/input.dat; > - 39. optking/h2o: missing CMakeLists. vi optking/h2o/CMakeLists.txt; > - 40. optking/h2os: missing cmake directory registration. vi; > optking/CMakeLists.txt; > - 41. optking/h2os: missing docs comment. vi optking/h2os/input.dat; > - 42. optking/h2os: missing CMakeLists. vi optking/h2os/CMakeLists.txt; > - 43. plugins/skeleton: missing docs comment. vi; > plugins/skeleton/input.dat; > - 44. plugins/skeleton: missing ctest registration. vi; > plugins/skeleton/CMakeLists.txt; > - 45. plugins/skeletonaointegrals: missing docs comment. vi; > plugins/skeletonaointegrals/input.dat; > - 46. plugins/skeletonaointegrals: missing ctest registration. vi; > plugins/skeletonaointegrals/CMakeLists.txt; > - 47. plugins/skeletondfmp2: missing docs comment. vi; > plugins/skeletondfmp2/input.dat; > - 48. plugins/skeletondfmp2: missing ctest registration. vi; > plugins/skeletondfmp2/CMakeLists.txt; > - 49. plugins/skeletonmointegrals: missing docs comment. vi; > plugins/skeletonmointegrals/input.dat; > - 50. plugins/skeletonmointegrals: missing ctest registration. vi; > plugins/skeletonmointegrals/CMakeLists.txt; > - 51. plugins/skeletonscf: missing docs comment. vi; > plugins/skeletonscf/input.dat; > - 52. plugins/skeletonscf: missing ctest registration. vi; > plugins/skeletonscf/CMakeLists.txt; > - 53. plugins/skeletonsointegrals: missing docs comment. vi; > plugins/skeletonsointegrals/input.dat; > - 54. plugins/skeletonsointegrals: missing ctest registration. vi; > plugins/skeletonsointegrals/CMakeLists.txt; > - 55. plugins/skeletonwavefunction: missing docs comment. vi; > plugins/skeletonwavefunction/input.dat; > - 56. plugins/skeletonwavefunction: missing ctest registration. vi; > plugins/skeletonwavefunction/CMakeLists.txt; > - 57. props4: missing cmake directory registration. vi CMakeLists.txt; > - 58. p,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137
https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137:5049,Modifiability,plugin,plugins,5049,cmake directory registration. vi; > optking/CMakeLists.txt; > - 38. optking/h2o: missing docs comment. vi optking/h2o/input.dat; > - 39. optking/h2o: missing CMakeLists. vi optking/h2o/CMakeLists.txt; > - 40. optking/h2os: missing cmake directory registration. vi; > optking/CMakeLists.txt; > - 41. optking/h2os: missing docs comment. vi optking/h2os/input.dat; > - 42. optking/h2os: missing CMakeLists. vi optking/h2os/CMakeLists.txt; > - 43. plugins/skeleton: missing docs comment. vi; > plugins/skeleton/input.dat; > - 44. plugins/skeleton: missing ctest registration. vi; > plugins/skeleton/CMakeLists.txt; > - 45. plugins/skeletonaointegrals: missing docs comment. vi; > plugins/skeletonaointegrals/input.dat; > - 46. plugins/skeletonaointegrals: missing ctest registration. vi; > plugins/skeletonaointegrals/CMakeLists.txt; > - 47. plugins/skeletondfmp2: missing docs comment. vi; > plugins/skeletondfmp2/input.dat; > - 48. plugins/skeletondfmp2: missing ctest registration. vi; > plugins/skeletondfmp2/CMakeLists.txt; > - 49. plugins/skeletonmointegrals: missing docs comment. vi; > plugins/skeletonmointegrals/input.dat; > - 50. plugins/skeletonmointegrals: missing ctest registration. vi; > plugins/skeletonmointegrals/CMakeLists.txt; > - 51. plugins/skeletonscf: missing docs comment. vi; > plugins/skeletonscf/input.dat; > - 52. plugins/skeletonscf: missing ctest registration. vi; > plugins/skeletonscf/CMakeLists.txt; > - 53. plugins/skeletonsointegrals: missing docs comment. vi; > plugins/skeletonsointegrals/input.dat; > - 54. plugins/skeletonsointegrals: missing ctest registration. vi; > plugins/skeletonsointegrals/CMakeLists.txt; > - 55. plugins/skeletonwavefunction: missing docs comment. vi; > plugins/skeletonwavefunction/input.dat; > - 56. plugins/skeletonwavefunction: missing ctest registration. vi; > plugins/skeletonwavefunction/CMakeLists.txt; > - 57. props4: missing cmake directory registration. vi CMakeLists.txt; > - 58. python/cc-amps: mismatched directory (python-c,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137
https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137:5095,Modifiability,plugin,plugins,5095,t; > - 38. optking/h2o: missing docs comment. vi optking/h2o/input.dat; > - 39. optking/h2o: missing CMakeLists. vi optking/h2o/CMakeLists.txt; > - 40. optking/h2os: missing cmake directory registration. vi; > optking/CMakeLists.txt; > - 41. optking/h2os: missing docs comment. vi optking/h2os/input.dat; > - 42. optking/h2os: missing CMakeLists. vi optking/h2os/CMakeLists.txt; > - 43. plugins/skeleton: missing docs comment. vi; > plugins/skeleton/input.dat; > - 44. plugins/skeleton: missing ctest registration. vi; > plugins/skeleton/CMakeLists.txt; > - 45. plugins/skeletonaointegrals: missing docs comment. vi; > plugins/skeletonaointegrals/input.dat; > - 46. plugins/skeletonaointegrals: missing ctest registration. vi; > plugins/skeletonaointegrals/CMakeLists.txt; > - 47. plugins/skeletondfmp2: missing docs comment. vi; > plugins/skeletondfmp2/input.dat; > - 48. plugins/skeletondfmp2: missing ctest registration. vi; > plugins/skeletondfmp2/CMakeLists.txt; > - 49. plugins/skeletonmointegrals: missing docs comment. vi; > plugins/skeletonmointegrals/input.dat; > - 50. plugins/skeletonmointegrals: missing ctest registration. vi; > plugins/skeletonmointegrals/CMakeLists.txt; > - 51. plugins/skeletonscf: missing docs comment. vi; > plugins/skeletonscf/input.dat; > - 52. plugins/skeletonscf: missing ctest registration. vi; > plugins/skeletonscf/CMakeLists.txt; > - 53. plugins/skeletonsointegrals: missing docs comment. vi; > plugins/skeletonsointegrals/input.dat; > - 54. plugins/skeletonsointegrals: missing ctest registration. vi; > plugins/skeletonsointegrals/CMakeLists.txt; > - 55. plugins/skeletonwavefunction: missing docs comment. vi; > plugins/skeletonwavefunction/input.dat; > - 56. plugins/skeletonwavefunction: missing ctest registration. vi; > plugins/skeletonwavefunction/CMakeLists.txt; > - 57. props4: missing cmake directory registration. vi CMakeLists.txt; > - 58. python/cc-amps: mismatched directory (python-cc-amps) and ctest; > registration name (python-cc_amps). v,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137
https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137:5152,Modifiability,plugin,plugins,5152,vi optking/h2o/input.dat; > - 39. optking/h2o: missing CMakeLists. vi optking/h2o/CMakeLists.txt; > - 40. optking/h2os: missing cmake directory registration. vi; > optking/CMakeLists.txt; > - 41. optking/h2os: missing docs comment. vi optking/h2os/input.dat; > - 42. optking/h2os: missing CMakeLists. vi optking/h2os/CMakeLists.txt; > - 43. plugins/skeleton: missing docs comment. vi; > plugins/skeleton/input.dat; > - 44. plugins/skeleton: missing ctest registration. vi; > plugins/skeleton/CMakeLists.txt; > - 45. plugins/skeletonaointegrals: missing docs comment. vi; > plugins/skeletonaointegrals/input.dat; > - 46. plugins/skeletonaointegrals: missing ctest registration. vi; > plugins/skeletonaointegrals/CMakeLists.txt; > - 47. plugins/skeletondfmp2: missing docs comment. vi; > plugins/skeletondfmp2/input.dat; > - 48. plugins/skeletondfmp2: missing ctest registration. vi; > plugins/skeletondfmp2/CMakeLists.txt; > - 49. plugins/skeletonmointegrals: missing docs comment. vi; > plugins/skeletonmointegrals/input.dat; > - 50. plugins/skeletonmointegrals: missing ctest registration. vi; > plugins/skeletonmointegrals/CMakeLists.txt; > - 51. plugins/skeletonscf: missing docs comment. vi; > plugins/skeletonscf/input.dat; > - 52. plugins/skeletonscf: missing ctest registration. vi; > plugins/skeletonscf/CMakeLists.txt; > - 53. plugins/skeletonsointegrals: missing docs comment. vi; > plugins/skeletonsointegrals/input.dat; > - 54. plugins/skeletonsointegrals: missing ctest registration. vi; > plugins/skeletonsointegrals/CMakeLists.txt; > - 55. plugins/skeletonwavefunction: missing docs comment. vi; > plugins/skeletonwavefunction/input.dat; > - 56. plugins/skeletonwavefunction: missing ctest registration. vi; > plugins/skeletonwavefunction/CMakeLists.txt; > - 57. props4: missing cmake directory registration. vi CMakeLists.txt; > - 58. python/cc-amps: mismatched directory (python-cc-amps) and ctest; > registration name (python-cc_amps). vi python/cc-amps/CMakeLists.txt; > - 59. pytho,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137
https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137:5199,Modifiability,plugin,plugins,5199,ists. vi optking/h2o/CMakeLists.txt; > - 40. optking/h2os: missing cmake directory registration. vi; > optking/CMakeLists.txt; > - 41. optking/h2os: missing docs comment. vi optking/h2os/input.dat; > - 42. optking/h2os: missing CMakeLists. vi optking/h2os/CMakeLists.txt; > - 43. plugins/skeleton: missing docs comment. vi; > plugins/skeleton/input.dat; > - 44. plugins/skeleton: missing ctest registration. vi; > plugins/skeleton/CMakeLists.txt; > - 45. plugins/skeletonaointegrals: missing docs comment. vi; > plugins/skeletonaointegrals/input.dat; > - 46. plugins/skeletonaointegrals: missing ctest registration. vi; > plugins/skeletonaointegrals/CMakeLists.txt; > - 47. plugins/skeletondfmp2: missing docs comment. vi; > plugins/skeletondfmp2/input.dat; > - 48. plugins/skeletondfmp2: missing ctest registration. vi; > plugins/skeletondfmp2/CMakeLists.txt; > - 49. plugins/skeletonmointegrals: missing docs comment. vi; > plugins/skeletonmointegrals/input.dat; > - 50. plugins/skeletonmointegrals: missing ctest registration. vi; > plugins/skeletonmointegrals/CMakeLists.txt; > - 51. plugins/skeletonscf: missing docs comment. vi; > plugins/skeletonscf/input.dat; > - 52. plugins/skeletonscf: missing ctest registration. vi; > plugins/skeletonscf/CMakeLists.txt; > - 53. plugins/skeletonsointegrals: missing docs comment. vi; > plugins/skeletonsointegrals/input.dat; > - 54. plugins/skeletonsointegrals: missing ctest registration. vi; > plugins/skeletonsointegrals/CMakeLists.txt; > - 55. plugins/skeletonwavefunction: missing docs comment. vi; > plugins/skeletonwavefunction/input.dat; > - 56. plugins/skeletonwavefunction: missing ctest registration. vi; > plugins/skeletonwavefunction/CMakeLists.txt; > - 57. props4: missing cmake directory registration. vi CMakeLists.txt; > - 58. python/cc-amps: mismatched directory (python-cc-amps) and ctest; > registration name (python-cc_amps). vi python/cc-amps/CMakeLists.txt; > - 59. python/mints13: missing pytest input generated. check it! vi; > py,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137
https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137:5262,Modifiability,plugin,plugins,5262,/h2os: missing cmake directory registration. vi; > optking/CMakeLists.txt; > - 41. optking/h2os: missing docs comment. vi optking/h2os/input.dat; > - 42. optking/h2os: missing CMakeLists. vi optking/h2os/CMakeLists.txt; > - 43. plugins/skeleton: missing docs comment. vi; > plugins/skeleton/input.dat; > - 44. plugins/skeleton: missing ctest registration. vi; > plugins/skeleton/CMakeLists.txt; > - 45. plugins/skeletonaointegrals: missing docs comment. vi; > plugins/skeletonaointegrals/input.dat; > - 46. plugins/skeletonaointegrals: missing ctest registration. vi; > plugins/skeletonaointegrals/CMakeLists.txt; > - 47. plugins/skeletondfmp2: missing docs comment. vi; > plugins/skeletondfmp2/input.dat; > - 48. plugins/skeletondfmp2: missing ctest registration. vi; > plugins/skeletondfmp2/CMakeLists.txt; > - 49. plugins/skeletonmointegrals: missing docs comment. vi; > plugins/skeletonmointegrals/input.dat; > - 50. plugins/skeletonmointegrals: missing ctest registration. vi; > plugins/skeletonmointegrals/CMakeLists.txt; > - 51. plugins/skeletonscf: missing docs comment. vi; > plugins/skeletonscf/input.dat; > - 52. plugins/skeletonscf: missing ctest registration. vi; > plugins/skeletonscf/CMakeLists.txt; > - 53. plugins/skeletonsointegrals: missing docs comment. vi; > plugins/skeletonsointegrals/input.dat; > - 54. plugins/skeletonsointegrals: missing ctest registration. vi; > plugins/skeletonsointegrals/CMakeLists.txt; > - 55. plugins/skeletonwavefunction: missing docs comment. vi; > plugins/skeletonwavefunction/input.dat; > - 56. plugins/skeletonwavefunction: missing ctest registration. vi; > plugins/skeletonwavefunction/CMakeLists.txt; > - 57. props4: missing cmake directory registration. vi CMakeLists.txt; > - 58. python/cc-amps: mismatched directory (python-cc-amps) and ctest; > registration name (python-cc_amps). vi python/cc-amps/CMakeLists.txt; > - 59. python/mints13: missing pytest input generated. check it! vi; > python/mints13/test_input.py; > - 60. pywrap-db2: mis,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137
https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137:5314,Modifiability,plugin,plugins,5314,ng/CMakeLists.txt; > - 41. optking/h2os: missing docs comment. vi optking/h2os/input.dat; > - 42. optking/h2os: missing CMakeLists. vi optking/h2os/CMakeLists.txt; > - 43. plugins/skeleton: missing docs comment. vi; > plugins/skeleton/input.dat; > - 44. plugins/skeleton: missing ctest registration. vi; > plugins/skeleton/CMakeLists.txt; > - 45. plugins/skeletonaointegrals: missing docs comment. vi; > plugins/skeletonaointegrals/input.dat; > - 46. plugins/skeletonaointegrals: missing ctest registration. vi; > plugins/skeletonaointegrals/CMakeLists.txt; > - 47. plugins/skeletondfmp2: missing docs comment. vi; > plugins/skeletondfmp2/input.dat; > - 48. plugins/skeletondfmp2: missing ctest registration. vi; > plugins/skeletondfmp2/CMakeLists.txt; > - 49. plugins/skeletonmointegrals: missing docs comment. vi; > plugins/skeletonmointegrals/input.dat; > - 50. plugins/skeletonmointegrals: missing ctest registration. vi; > plugins/skeletonmointegrals/CMakeLists.txt; > - 51. plugins/skeletonscf: missing docs comment. vi; > plugins/skeletonscf/input.dat; > - 52. plugins/skeletonscf: missing ctest registration. vi; > plugins/skeletonscf/CMakeLists.txt; > - 53. plugins/skeletonsointegrals: missing docs comment. vi; > plugins/skeletonsointegrals/input.dat; > - 54. plugins/skeletonsointegrals: missing ctest registration. vi; > plugins/skeletonsointegrals/CMakeLists.txt; > - 55. plugins/skeletonwavefunction: missing docs comment. vi; > plugins/skeletonwavefunction/input.dat; > - 56. plugins/skeletonwavefunction: missing ctest registration. vi; > plugins/skeletonwavefunction/CMakeLists.txt; > - 57. props4: missing cmake directory registration. vi CMakeLists.txt; > - 58. python/cc-amps: mismatched directory (python-cc-amps) and ctest; > registration name (python-cc_amps). vi python/cc-amps/CMakeLists.txt; > - 59. python/mints13: missing pytest input generated. check it! vi; > python/mints13/test_input.py; > - 60. pywrap-db2: missing cmake directory registration. vi; > CMakeLists.txt; ,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137
https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137:5363,Modifiability,plugin,plugins,5363,s: missing docs comment. vi optking/h2os/input.dat; > - 42. optking/h2os: missing CMakeLists. vi optking/h2os/CMakeLists.txt; > - 43. plugins/skeleton: missing docs comment. vi; > plugins/skeleton/input.dat; > - 44. plugins/skeleton: missing ctest registration. vi; > plugins/skeleton/CMakeLists.txt; > - 45. plugins/skeletonaointegrals: missing docs comment. vi; > plugins/skeletonaointegrals/input.dat; > - 46. plugins/skeletonaointegrals: missing ctest registration. vi; > plugins/skeletonaointegrals/CMakeLists.txt; > - 47. plugins/skeletondfmp2: missing docs comment. vi; > plugins/skeletondfmp2/input.dat; > - 48. plugins/skeletondfmp2: missing ctest registration. vi; > plugins/skeletondfmp2/CMakeLists.txt; > - 49. plugins/skeletonmointegrals: missing docs comment. vi; > plugins/skeletonmointegrals/input.dat; > - 50. plugins/skeletonmointegrals: missing ctest registration. vi; > plugins/skeletonmointegrals/CMakeLists.txt; > - 51. plugins/skeletonscf: missing docs comment. vi; > plugins/skeletonscf/input.dat; > - 52. plugins/skeletonscf: missing ctest registration. vi; > plugins/skeletonscf/CMakeLists.txt; > - 53. plugins/skeletonsointegrals: missing docs comment. vi; > plugins/skeletonsointegrals/input.dat; > - 54. plugins/skeletonsointegrals: missing ctest registration. vi; > plugins/skeletonsointegrals/CMakeLists.txt; > - 55. plugins/skeletonwavefunction: missing docs comment. vi; > plugins/skeletonwavefunction/input.dat; > - 56. plugins/skeletonwavefunction: missing ctest registration. vi; > plugins/skeletonwavefunction/CMakeLists.txt; > - 57. props4: missing cmake directory registration. vi CMakeLists.txt; > - 58. python/cc-amps: mismatched directory (python-cc-amps) and ctest; > registration name (python-cc_amps). vi python/cc-amps/CMakeLists.txt; > - 59. python/mints13: missing pytest input generated. check it! vi; > python/mints13/test_input.py; > - 60. pywrap-db2: missing cmake directory registration. vi; > CMakeLists.txt; > - 61. pywrap-freq-e-sowreap: missing,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137
https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137:5402,Modifiability,plugin,plugins,5402, - 42. optking/h2os: missing CMakeLists. vi optking/h2os/CMakeLists.txt; > - 43. plugins/skeleton: missing docs comment. vi; > plugins/skeleton/input.dat; > - 44. plugins/skeleton: missing ctest registration. vi; > plugins/skeleton/CMakeLists.txt; > - 45. plugins/skeletonaointegrals: missing docs comment. vi; > plugins/skeletonaointegrals/input.dat; > - 46. plugins/skeletonaointegrals: missing ctest registration. vi; > plugins/skeletonaointegrals/CMakeLists.txt; > - 47. plugins/skeletondfmp2: missing docs comment. vi; > plugins/skeletondfmp2/input.dat; > - 48. plugins/skeletondfmp2: missing ctest registration. vi; > plugins/skeletondfmp2/CMakeLists.txt; > - 49. plugins/skeletonmointegrals: missing docs comment. vi; > plugins/skeletonmointegrals/input.dat; > - 50. plugins/skeletonmointegrals: missing ctest registration. vi; > plugins/skeletonmointegrals/CMakeLists.txt; > - 51. plugins/skeletonscf: missing docs comment. vi; > plugins/skeletonscf/input.dat; > - 52. plugins/skeletonscf: missing ctest registration. vi; > plugins/skeletonscf/CMakeLists.txt; > - 53. plugins/skeletonsointegrals: missing docs comment. vi; > plugins/skeletonsointegrals/input.dat; > - 54. plugins/skeletonsointegrals: missing ctest registration. vi; > plugins/skeletonsointegrals/CMakeLists.txt; > - 55. plugins/skeletonwavefunction: missing docs comment. vi; > plugins/skeletonwavefunction/input.dat; > - 56. plugins/skeletonwavefunction: missing ctest registration. vi; > plugins/skeletonwavefunction/CMakeLists.txt; > - 57. props4: missing cmake directory registration. vi CMakeLists.txt; > - 58. python/cc-amps: mismatched directory (python-cc-amps) and ctest; > registration name (python-cc_amps). vi python/cc-amps/CMakeLists.txt; > - 59. python/mints13: missing pytest input generated. check it! vi; > python/mints13/test_input.py; > - 60. pywrap-db2: missing cmake directory registration. vi; > CMakeLists.txt; > - 61. pywrap-freq-e-sowreap: missing cmake directory registration. vi; > CMakeLists.txt; ,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137
https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137:5457,Modifiability,plugin,plugins,5457,optking/h2os/CMakeLists.txt; > - 43. plugins/skeleton: missing docs comment. vi; > plugins/skeleton/input.dat; > - 44. plugins/skeleton: missing ctest registration. vi; > plugins/skeleton/CMakeLists.txt; > - 45. plugins/skeletonaointegrals: missing docs comment. vi; > plugins/skeletonaointegrals/input.dat; > - 46. plugins/skeletonaointegrals: missing ctest registration. vi; > plugins/skeletonaointegrals/CMakeLists.txt; > - 47. plugins/skeletondfmp2: missing docs comment. vi; > plugins/skeletondfmp2/input.dat; > - 48. plugins/skeletondfmp2: missing ctest registration. vi; > plugins/skeletondfmp2/CMakeLists.txt; > - 49. plugins/skeletonmointegrals: missing docs comment. vi; > plugins/skeletonmointegrals/input.dat; > - 50. plugins/skeletonmointegrals: missing ctest registration. vi; > plugins/skeletonmointegrals/CMakeLists.txt; > - 51. plugins/skeletonscf: missing docs comment. vi; > plugins/skeletonscf/input.dat; > - 52. plugins/skeletonscf: missing ctest registration. vi; > plugins/skeletonscf/CMakeLists.txt; > - 53. plugins/skeletonsointegrals: missing docs comment. vi; > plugins/skeletonsointegrals/input.dat; > - 54. plugins/skeletonsointegrals: missing ctest registration. vi; > plugins/skeletonsointegrals/CMakeLists.txt; > - 55. plugins/skeletonwavefunction: missing docs comment. vi; > plugins/skeletonwavefunction/input.dat; > - 56. plugins/skeletonwavefunction: missing ctest registration. vi; > plugins/skeletonwavefunction/CMakeLists.txt; > - 57. props4: missing cmake directory registration. vi CMakeLists.txt; > - 58. python/cc-amps: mismatched directory (python-cc-amps) and ctest; > registration name (python-cc_amps). vi python/cc-amps/CMakeLists.txt; > - 59. python/mints13: missing pytest input generated. check it! vi; > python/mints13/test_input.py; > - 60. pywrap-db2: missing cmake directory registration. vi; > CMakeLists.txt; > - 61. pywrap-freq-e-sowreap: missing cmake directory registration. vi; > CMakeLists.txt; > - 62. pywrap-freq-g-sowreap: missing cmak,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137
https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137:5501,Modifiability,plugin,plugins,5501,issing docs comment. vi; > plugins/skeleton/input.dat; > - 44. plugins/skeleton: missing ctest registration. vi; > plugins/skeleton/CMakeLists.txt; > - 45. plugins/skeletonaointegrals: missing docs comment. vi; > plugins/skeletonaointegrals/input.dat; > - 46. plugins/skeletonaointegrals: missing ctest registration. vi; > plugins/skeletonaointegrals/CMakeLists.txt; > - 47. plugins/skeletondfmp2: missing docs comment. vi; > plugins/skeletondfmp2/input.dat; > - 48. plugins/skeletondfmp2: missing ctest registration. vi; > plugins/skeletondfmp2/CMakeLists.txt; > - 49. plugins/skeletonmointegrals: missing docs comment. vi; > plugins/skeletonmointegrals/input.dat; > - 50. plugins/skeletonmointegrals: missing ctest registration. vi; > plugins/skeletonmointegrals/CMakeLists.txt; > - 51. plugins/skeletonscf: missing docs comment. vi; > plugins/skeletonscf/input.dat; > - 52. plugins/skeletonscf: missing ctest registration. vi; > plugins/skeletonscf/CMakeLists.txt; > - 53. plugins/skeletonsointegrals: missing docs comment. vi; > plugins/skeletonsointegrals/input.dat; > - 54. plugins/skeletonsointegrals: missing ctest registration. vi; > plugins/skeletonsointegrals/CMakeLists.txt; > - 55. plugins/skeletonwavefunction: missing docs comment. vi; > plugins/skeletonwavefunction/input.dat; > - 56. plugins/skeletonwavefunction: missing ctest registration. vi; > plugins/skeletonwavefunction/CMakeLists.txt; > - 57. props4: missing cmake directory registration. vi CMakeLists.txt; > - 58. python/cc-amps: mismatched directory (python-cc-amps) and ctest; > registration name (python-cc_amps). vi python/cc-amps/CMakeLists.txt; > - 59. python/mints13: missing pytest input generated. check it! vi; > python/mints13/test_input.py; > - 60. pywrap-db2: missing cmake directory registration. vi; > CMakeLists.txt; > - 61. pywrap-freq-e-sowreap: missing cmake directory registration. vi; > CMakeLists.txt; > - 62. pywrap-freq-g-sowreap: missing cmake directory registration. vi; > CMakeLists.txt; > - 63. p,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137
https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137:5558,Modifiability,plugin,plugins,5558,put.dat; > - 44. plugins/skeleton: missing ctest registration. vi; > plugins/skeleton/CMakeLists.txt; > - 45. plugins/skeletonaointegrals: missing docs comment. vi; > plugins/skeletonaointegrals/input.dat; > - 46. plugins/skeletonaointegrals: missing ctest registration. vi; > plugins/skeletonaointegrals/CMakeLists.txt; > - 47. plugins/skeletondfmp2: missing docs comment. vi; > plugins/skeletondfmp2/input.dat; > - 48. plugins/skeletondfmp2: missing ctest registration. vi; > plugins/skeletondfmp2/CMakeLists.txt; > - 49. plugins/skeletonmointegrals: missing docs comment. vi; > plugins/skeletonmointegrals/input.dat; > - 50. plugins/skeletonmointegrals: missing ctest registration. vi; > plugins/skeletonmointegrals/CMakeLists.txt; > - 51. plugins/skeletonscf: missing docs comment. vi; > plugins/skeletonscf/input.dat; > - 52. plugins/skeletonscf: missing ctest registration. vi; > plugins/skeletonscf/CMakeLists.txt; > - 53. plugins/skeletonsointegrals: missing docs comment. vi; > plugins/skeletonsointegrals/input.dat; > - 54. plugins/skeletonsointegrals: missing ctest registration. vi; > plugins/skeletonsointegrals/CMakeLists.txt; > - 55. plugins/skeletonwavefunction: missing docs comment. vi; > plugins/skeletonwavefunction/input.dat; > - 56. plugins/skeletonwavefunction: missing ctest registration. vi; > plugins/skeletonwavefunction/CMakeLists.txt; > - 57. props4: missing cmake directory registration. vi CMakeLists.txt; > - 58. python/cc-amps: mismatched directory (python-cc-amps) and ctest; > registration name (python-cc_amps). vi python/cc-amps/CMakeLists.txt; > - 59. python/mints13: missing pytest input generated. check it! vi; > python/mints13/test_input.py; > - 60. pywrap-db2: missing cmake directory registration. vi; > CMakeLists.txt; > - 61. pywrap-freq-e-sowreap: missing cmake directory registration. vi; > CMakeLists.txt; > - 62. pywrap-freq-g-sowreap: missing cmake directory registration. vi; > CMakeLists.txt; > - 63. pywrap-opt-sowreap: missing cmake directory reg,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137
https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137:5605,Modifiability,plugin,plugins,5605,. vi; > plugins/skeleton/CMakeLists.txt; > - 45. plugins/skeletonaointegrals: missing docs comment. vi; > plugins/skeletonaointegrals/input.dat; > - 46. plugins/skeletonaointegrals: missing ctest registration. vi; > plugins/skeletonaointegrals/CMakeLists.txt; > - 47. plugins/skeletondfmp2: missing docs comment. vi; > plugins/skeletondfmp2/input.dat; > - 48. plugins/skeletondfmp2: missing ctest registration. vi; > plugins/skeletondfmp2/CMakeLists.txt; > - 49. plugins/skeletonmointegrals: missing docs comment. vi; > plugins/skeletonmointegrals/input.dat; > - 50. plugins/skeletonmointegrals: missing ctest registration. vi; > plugins/skeletonmointegrals/CMakeLists.txt; > - 51. plugins/skeletonscf: missing docs comment. vi; > plugins/skeletonscf/input.dat; > - 52. plugins/skeletonscf: missing ctest registration. vi; > plugins/skeletonscf/CMakeLists.txt; > - 53. plugins/skeletonsointegrals: missing docs comment. vi; > plugins/skeletonsointegrals/input.dat; > - 54. plugins/skeletonsointegrals: missing ctest registration. vi; > plugins/skeletonsointegrals/CMakeLists.txt; > - 55. plugins/skeletonwavefunction: missing docs comment. vi; > plugins/skeletonwavefunction/input.dat; > - 56. plugins/skeletonwavefunction: missing ctest registration. vi; > plugins/skeletonwavefunction/CMakeLists.txt; > - 57. props4: missing cmake directory registration. vi CMakeLists.txt; > - 58. python/cc-amps: mismatched directory (python-cc-amps) and ctest; > registration name (python-cc_amps). vi python/cc-amps/CMakeLists.txt; > - 59. python/mints13: missing pytest input generated. check it! vi; > python/mints13/test_input.py; > - 60. pywrap-db2: missing cmake directory registration. vi; > CMakeLists.txt; > - 61. pywrap-freq-e-sowreap: missing cmake directory registration. vi; > CMakeLists.txt; > - 62. pywrap-freq-g-sowreap: missing cmake directory registration. vi; > CMakeLists.txt; > - 63. pywrap-opt-sowreap: missing cmake directory registration. vi; > CMakeLists.txt; > - 64. scf11-freq-from-ener,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137
https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137:5668,Modifiability,plugin,plugins,5668,gins/skeletonaointegrals: missing docs comment. vi; > plugins/skeletonaointegrals/input.dat; > - 46. plugins/skeletonaointegrals: missing ctest registration. vi; > plugins/skeletonaointegrals/CMakeLists.txt; > - 47. plugins/skeletondfmp2: missing docs comment. vi; > plugins/skeletondfmp2/input.dat; > - 48. plugins/skeletondfmp2: missing ctest registration. vi; > plugins/skeletondfmp2/CMakeLists.txt; > - 49. plugins/skeletonmointegrals: missing docs comment. vi; > plugins/skeletonmointegrals/input.dat; > - 50. plugins/skeletonmointegrals: missing ctest registration. vi; > plugins/skeletonmointegrals/CMakeLists.txt; > - 51. plugins/skeletonscf: missing docs comment. vi; > plugins/skeletonscf/input.dat; > - 52. plugins/skeletonscf: missing ctest registration. vi; > plugins/skeletonscf/CMakeLists.txt; > - 53. plugins/skeletonsointegrals: missing docs comment. vi; > plugins/skeletonsointegrals/input.dat; > - 54. plugins/skeletonsointegrals: missing ctest registration. vi; > plugins/skeletonsointegrals/CMakeLists.txt; > - 55. plugins/skeletonwavefunction: missing docs comment. vi; > plugins/skeletonwavefunction/input.dat; > - 56. plugins/skeletonwavefunction: missing ctest registration. vi; > plugins/skeletonwavefunction/CMakeLists.txt; > - 57. props4: missing cmake directory registration. vi CMakeLists.txt; > - 58. python/cc-amps: mismatched directory (python-cc-amps) and ctest; > registration name (python-cc_amps). vi python/cc-amps/CMakeLists.txt; > - 59. python/mints13: missing pytest input generated. check it! vi; > python/mints13/test_input.py; > - 60. pywrap-db2: missing cmake directory registration. vi; > CMakeLists.txt; > - 61. pywrap-freq-e-sowreap: missing cmake directory registration. vi; > CMakeLists.txt; > - 62. pywrap-freq-g-sowreap: missing cmake directory registration. vi; > CMakeLists.txt; > - 63. pywrap-opt-sowreap: missing cmake directory registration. vi; > CMakeLists.txt; > - 64. scf11-freq-from-energies: missing cmake directory registration. vi; > C,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137
https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137:5720,Modifiability,plugin,plugins,5720,/skeletonaointegrals/input.dat; > - 46. plugins/skeletonaointegrals: missing ctest registration. vi; > plugins/skeletonaointegrals/CMakeLists.txt; > - 47. plugins/skeletondfmp2: missing docs comment. vi; > plugins/skeletondfmp2/input.dat; > - 48. plugins/skeletondfmp2: missing ctest registration. vi; > plugins/skeletondfmp2/CMakeLists.txt; > - 49. plugins/skeletonmointegrals: missing docs comment. vi; > plugins/skeletonmointegrals/input.dat; > - 50. plugins/skeletonmointegrals: missing ctest registration. vi; > plugins/skeletonmointegrals/CMakeLists.txt; > - 51. plugins/skeletonscf: missing docs comment. vi; > plugins/skeletonscf/input.dat; > - 52. plugins/skeletonscf: missing ctest registration. vi; > plugins/skeletonscf/CMakeLists.txt; > - 53. plugins/skeletonsointegrals: missing docs comment. vi; > plugins/skeletonsointegrals/input.dat; > - 54. plugins/skeletonsointegrals: missing ctest registration. vi; > plugins/skeletonsointegrals/CMakeLists.txt; > - 55. plugins/skeletonwavefunction: missing docs comment. vi; > plugins/skeletonwavefunction/input.dat; > - 56. plugins/skeletonwavefunction: missing ctest registration. vi; > plugins/skeletonwavefunction/CMakeLists.txt; > - 57. props4: missing cmake directory registration. vi CMakeLists.txt; > - 58. python/cc-amps: mismatched directory (python-cc-amps) and ctest; > registration name (python-cc_amps). vi python/cc-amps/CMakeLists.txt; > - 59. python/mints13: missing pytest input generated. check it! vi; > python/mints13/test_input.py; > - 60. pywrap-db2: missing cmake directory registration. vi; > CMakeLists.txt; > - 61. pywrap-freq-e-sowreap: missing cmake directory registration. vi; > CMakeLists.txt; > - 62. pywrap-freq-g-sowreap: missing cmake directory registration. vi; > CMakeLists.txt; > - 63. pywrap-opt-sowreap: missing cmake directory registration. vi; > CMakeLists.txt; > - 64. scf11-freq-from-energies: missing cmake directory registration. vi; > CMakeLists.txt; > - 65. snsmp2/cc-cc: mismatched marks ctest (,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137
https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137:5778,Modifiability,plugin,plugins,5778,/skeletonaointegrals: missing ctest registration. vi; > plugins/skeletonaointegrals/CMakeLists.txt; > - 47. plugins/skeletondfmp2: missing docs comment. vi; > plugins/skeletondfmp2/input.dat; > - 48. plugins/skeletondfmp2: missing ctest registration. vi; > plugins/skeletondfmp2/CMakeLists.txt; > - 49. plugins/skeletonmointegrals: missing docs comment. vi; > plugins/skeletonmointegrals/input.dat; > - 50. plugins/skeletonmointegrals: missing ctest registration. vi; > plugins/skeletonmointegrals/CMakeLists.txt; > - 51. plugins/skeletonscf: missing docs comment. vi; > plugins/skeletonscf/input.dat; > - 52. plugins/skeletonscf: missing ctest registration. vi; > plugins/skeletonscf/CMakeLists.txt; > - 53. plugins/skeletonsointegrals: missing docs comment. vi; > plugins/skeletonsointegrals/input.dat; > - 54. plugins/skeletonsointegrals: missing ctest registration. vi; > plugins/skeletonsointegrals/CMakeLists.txt; > - 55. plugins/skeletonwavefunction: missing docs comment. vi; > plugins/skeletonwavefunction/input.dat; > - 56. plugins/skeletonwavefunction: missing ctest registration. vi; > plugins/skeletonwavefunction/CMakeLists.txt; > - 57. props4: missing cmake directory registration. vi CMakeLists.txt; > - 58. python/cc-amps: mismatched directory (python-cc-amps) and ctest; > registration name (python-cc_amps). vi python/cc-amps/CMakeLists.txt; > - 59. python/mints13: missing pytest input generated. check it! vi; > python/mints13/test_input.py; > - 60. pywrap-db2: missing cmake directory registration. vi; > CMakeLists.txt; > - 61. pywrap-freq-e-sowreap: missing cmake directory registration. vi; > CMakeLists.txt; > - 62. pywrap-freq-g-sowreap: missing cmake directory registration. vi; > CMakeLists.txt; > - 63. pywrap-opt-sowreap: missing cmake directory registration. vi; > CMakeLists.txt; > - 64. scf11-freq-from-energies: missing cmake directory registration. vi; > CMakeLists.txt; > - 65. snsmp2/cc-cc: mismatched marks ctest (longtests;snsmp;cart) and; > pytest (long;cart),MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137
https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137:5826,Modifiability,plugin,plugins,5826,s/skeletonaointegrals/CMakeLists.txt; > - 47. plugins/skeletondfmp2: missing docs comment. vi; > plugins/skeletondfmp2/input.dat; > - 48. plugins/skeletondfmp2: missing ctest registration. vi; > plugins/skeletondfmp2/CMakeLists.txt; > - 49. plugins/skeletonmointegrals: missing docs comment. vi; > plugins/skeletonmointegrals/input.dat; > - 50. plugins/skeletonmointegrals: missing ctest registration. vi; > plugins/skeletonmointegrals/CMakeLists.txt; > - 51. plugins/skeletonscf: missing docs comment. vi; > plugins/skeletonscf/input.dat; > - 52. plugins/skeletonscf: missing ctest registration. vi; > plugins/skeletonscf/CMakeLists.txt; > - 53. plugins/skeletonsointegrals: missing docs comment. vi; > plugins/skeletonsointegrals/input.dat; > - 54. plugins/skeletonsointegrals: missing ctest registration. vi; > plugins/skeletonsointegrals/CMakeLists.txt; > - 55. plugins/skeletonwavefunction: missing docs comment. vi; > plugins/skeletonwavefunction/input.dat; > - 56. plugins/skeletonwavefunction: missing ctest registration. vi; > plugins/skeletonwavefunction/CMakeLists.txt; > - 57. props4: missing cmake directory registration. vi CMakeLists.txt; > - 58. python/cc-amps: mismatched directory (python-cc-amps) and ctest; > registration name (python-cc_amps). vi python/cc-amps/CMakeLists.txt; > - 59. python/mints13: missing pytest input generated. check it! vi; > python/mints13/test_input.py; > - 60. pywrap-db2: missing cmake directory registration. vi; > CMakeLists.txt; > - 61. pywrap-freq-e-sowreap: missing cmake directory registration. vi; > CMakeLists.txt; > - 62. pywrap-freq-g-sowreap: missing cmake directory registration. vi; > CMakeLists.txt; > - 63. pywrap-opt-sowreap: missing cmake directory registration. vi; > CMakeLists.txt; > - 64. scf11-freq-from-energies: missing cmake directory registration. vi; > CMakeLists.txt; > - 65. snsmp2/cc-cc: mismatched marks ctest (longtests;snsmp;cart) and; > pytest (long;cart). vi snsmp2/cc-cc/CMakeLists.txt; > snsmp2/cc-cc/test_input.py,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137
https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137:5890,Modifiability,plugin,plugins,5890,s/skeletondfmp2: missing docs comment. vi; > plugins/skeletondfmp2/input.dat; > - 48. plugins/skeletondfmp2: missing ctest registration. vi; > plugins/skeletondfmp2/CMakeLists.txt; > - 49. plugins/skeletonmointegrals: missing docs comment. vi; > plugins/skeletonmointegrals/input.dat; > - 50. plugins/skeletonmointegrals: missing ctest registration. vi; > plugins/skeletonmointegrals/CMakeLists.txt; > - 51. plugins/skeletonscf: missing docs comment. vi; > plugins/skeletonscf/input.dat; > - 52. plugins/skeletonscf: missing ctest registration. vi; > plugins/skeletonscf/CMakeLists.txt; > - 53. plugins/skeletonsointegrals: missing docs comment. vi; > plugins/skeletonsointegrals/input.dat; > - 54. plugins/skeletonsointegrals: missing ctest registration. vi; > plugins/skeletonsointegrals/CMakeLists.txt; > - 55. plugins/skeletonwavefunction: missing docs comment. vi; > plugins/skeletonwavefunction/input.dat; > - 56. plugins/skeletonwavefunction: missing ctest registration. vi; > plugins/skeletonwavefunction/CMakeLists.txt; > - 57. props4: missing cmake directory registration. vi CMakeLists.txt; > - 58. python/cc-amps: mismatched directory (python-cc-amps) and ctest; > registration name (python-cc_amps). vi python/cc-amps/CMakeLists.txt; > - 59. python/mints13: missing pytest input generated. check it! vi; > python/mints13/test_input.py; > - 60. pywrap-db2: missing cmake directory registration. vi; > CMakeLists.txt; > - 61. pywrap-freq-e-sowreap: missing cmake directory registration. vi; > CMakeLists.txt; > - 62. pywrap-freq-g-sowreap: missing cmake directory registration. vi; > CMakeLists.txt; > - 63. pywrap-opt-sowreap: missing cmake directory registration. vi; > CMakeLists.txt; > - 64. scf11-freq-from-energies: missing cmake directory registration. vi; > CMakeLists.txt; > - 65. snsmp2/cc-cc: mismatched marks ctest (longtests;snsmp;cart) and; > pytest (long;cart). vi snsmp2/cc-cc/CMakeLists.txt; > snsmp2/cc-cc/test_input.py; > - 66. snsmp2/cf-o: mismatched marks ctest (snsmp;,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137
https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137:689,Performance,optimiz,optimizer,689,"The only thing worth hanging onto might be the bakerjcc93. But if we've; got that database otherwise available, then deletion fine with me. On Fri, Apr 22, 2022 at 11:14 AM Lori A. Burns ***@***.***>; wrote:. > after #2549 <https://github.com/psi4/psi4/pull/2549>, the list from python; > tester.py looks like the below. Most of these are easily healed by; > figuring out if they're intended to be a test or not. Nots should be; > removed to an attic or deleted. Also related is #2234; > <https://github.com/psi4/psi4/issues/2234> . don't rely on the below --; > rerun tester.py as needed.; >; > @psi-rking <https://github.com/psi-rking>, do you prefer attic or; > deletion for the un-run optimizer tests?; > Complaints; >; > - 1. cc5: missing cmake directory registration. vi CMakeLists.txt; > - 2. cookbook/manual-sow-reap: missing cmake directory registration. vi; > cookbook/CMakeLists.txt; > - 3. cookbook/manual-sow-reap: missing CMakeLists. vi; > cookbook/manual-sow-reap/CMakeLists.txt; > - 4. dfmp2-freq1: missing cmake directory registration. vi; > CMakeLists.txt; > - 5. dfmp2-freq2: missing cmake directory registration. vi; > CMakeLists.txt; > - 6. dfomp2p5-1: missing ctest registration. vi; > dfomp2p5-1/CMakeLists.txt; > - 7. dfomp2p5-2: missing ctest registration. vi; > dfomp2p5-2/CMakeLists.txt; > - 8. dfomp2p5-grad1: missing ctest registration. vi; > dfomp2p5-grad1/CMakeLists.txt; > - 9. dfomp2p5-grad2: missing ctest registration. vi; > dfomp2p5-grad2/CMakeLists.txt; > - 10. dft-dldf: missing cmake directory registration. vi CMakeLists.txt; > - 11. dft-dsd: missing cmake directory registration. vi CMakeLists.txt; > - 12. dft-pbe0-2: missing cmake directory registration. vi; > CMakeLists.txt; > - 13. explicit-am-basis: mismatched directory (explicit-am-basis) and; > ctest registration name (explicit_am_basis). vi; > explicit-am-basis/CMakeLists.txt; > - 14. fsapt-diff1: missing cmake directory registration. vi; > CMakeLists.txt; > - 15. fsapt-diff1: missing CMakeLists.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137
https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137:289,Testability,test,tester,289,"The only thing worth hanging onto might be the bakerjcc93. But if we've; got that database otherwise available, then deletion fine with me. On Fri, Apr 22, 2022 at 11:14 AM Lori A. Burns ***@***.***>; wrote:. > after #2549 <https://github.com/psi4/psi4/pull/2549>, the list from python; > tester.py looks like the below. Most of these are easily healed by; > figuring out if they're intended to be a test or not. Nots should be; > removed to an attic or deleted. Also related is #2234; > <https://github.com/psi4/psi4/issues/2234> . don't rely on the below --; > rerun tester.py as needed.; >; > @psi-rking <https://github.com/psi-rking>, do you prefer attic or; > deletion for the un-run optimizer tests?; > Complaints; >; > - 1. cc5: missing cmake directory registration. vi CMakeLists.txt; > - 2. cookbook/manual-sow-reap: missing cmake directory registration. vi; > cookbook/CMakeLists.txt; > - 3. cookbook/manual-sow-reap: missing CMakeLists. vi; > cookbook/manual-sow-reap/CMakeLists.txt; > - 4. dfmp2-freq1: missing cmake directory registration. vi; > CMakeLists.txt; > - 5. dfmp2-freq2: missing cmake directory registration. vi; > CMakeLists.txt; > - 6. dfomp2p5-1: missing ctest registration. vi; > dfomp2p5-1/CMakeLists.txt; > - 7. dfomp2p5-2: missing ctest registration. vi; > dfomp2p5-2/CMakeLists.txt; > - 8. dfomp2p5-grad1: missing ctest registration. vi; > dfomp2p5-grad1/CMakeLists.txt; > - 9. dfomp2p5-grad2: missing ctest registration. vi; > dfomp2p5-grad2/CMakeLists.txt; > - 10. dft-dldf: missing cmake directory registration. vi CMakeLists.txt; > - 11. dft-dsd: missing cmake directory registration. vi CMakeLists.txt; > - 12. dft-pbe0-2: missing cmake directory registration. vi; > CMakeLists.txt; > - 13. explicit-am-basis: mismatched directory (explicit-am-basis) and; > ctest registration name (explicit_am_basis). vi; > explicit-am-basis/CMakeLists.txt; > - 14. fsapt-diff1: missing cmake directory registration. vi; > CMakeLists.txt; > - 15. fsapt-diff1: missing CMakeLists.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137
https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137:400,Testability,test,test,400,"The only thing worth hanging onto might be the bakerjcc93. But if we've; got that database otherwise available, then deletion fine with me. On Fri, Apr 22, 2022 at 11:14 AM Lori A. Burns ***@***.***>; wrote:. > after #2549 <https://github.com/psi4/psi4/pull/2549>, the list from python; > tester.py looks like the below. Most of these are easily healed by; > figuring out if they're intended to be a test or not. Nots should be; > removed to an attic or deleted. Also related is #2234; > <https://github.com/psi4/psi4/issues/2234> . don't rely on the below --; > rerun tester.py as needed.; >; > @psi-rking <https://github.com/psi-rking>, do you prefer attic or; > deletion for the un-run optimizer tests?; > Complaints; >; > - 1. cc5: missing cmake directory registration. vi CMakeLists.txt; > - 2. cookbook/manual-sow-reap: missing cmake directory registration. vi; > cookbook/CMakeLists.txt; > - 3. cookbook/manual-sow-reap: missing CMakeLists. vi; > cookbook/manual-sow-reap/CMakeLists.txt; > - 4. dfmp2-freq1: missing cmake directory registration. vi; > CMakeLists.txt; > - 5. dfmp2-freq2: missing cmake directory registration. vi; > CMakeLists.txt; > - 6. dfomp2p5-1: missing ctest registration. vi; > dfomp2p5-1/CMakeLists.txt; > - 7. dfomp2p5-2: missing ctest registration. vi; > dfomp2p5-2/CMakeLists.txt; > - 8. dfomp2p5-grad1: missing ctest registration. vi; > dfomp2p5-grad1/CMakeLists.txt; > - 9. dfomp2p5-grad2: missing ctest registration. vi; > dfomp2p5-grad2/CMakeLists.txt; > - 10. dft-dldf: missing cmake directory registration. vi CMakeLists.txt; > - 11. dft-dsd: missing cmake directory registration. vi CMakeLists.txt; > - 12. dft-pbe0-2: missing cmake directory registration. vi; > CMakeLists.txt; > - 13. explicit-am-basis: mismatched directory (explicit-am-basis) and; > ctest registration name (explicit_am_basis). vi; > explicit-am-basis/CMakeLists.txt; > - 14. fsapt-diff1: missing cmake directory registration. vi; > CMakeLists.txt; > - 15. fsapt-diff1: missing CMakeLists.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137
https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137:569,Testability,test,tester,569,"The only thing worth hanging onto might be the bakerjcc93. But if we've; got that database otherwise available, then deletion fine with me. On Fri, Apr 22, 2022 at 11:14 AM Lori A. Burns ***@***.***>; wrote:. > after #2549 <https://github.com/psi4/psi4/pull/2549>, the list from python; > tester.py looks like the below. Most of these are easily healed by; > figuring out if they're intended to be a test or not. Nots should be; > removed to an attic or deleted. Also related is #2234; > <https://github.com/psi4/psi4/issues/2234> . don't rely on the below --; > rerun tester.py as needed.; >; > @psi-rking <https://github.com/psi-rking>, do you prefer attic or; > deletion for the un-run optimizer tests?; > Complaints; >; > - 1. cc5: missing cmake directory registration. vi CMakeLists.txt; > - 2. cookbook/manual-sow-reap: missing cmake directory registration. vi; > cookbook/CMakeLists.txt; > - 3. cookbook/manual-sow-reap: missing CMakeLists. vi; > cookbook/manual-sow-reap/CMakeLists.txt; > - 4. dfmp2-freq1: missing cmake directory registration. vi; > CMakeLists.txt; > - 5. dfmp2-freq2: missing cmake directory registration. vi; > CMakeLists.txt; > - 6. dfomp2p5-1: missing ctest registration. vi; > dfomp2p5-1/CMakeLists.txt; > - 7. dfomp2p5-2: missing ctest registration. vi; > dfomp2p5-2/CMakeLists.txt; > - 8. dfomp2p5-grad1: missing ctest registration. vi; > dfomp2p5-grad1/CMakeLists.txt; > - 9. dfomp2p5-grad2: missing ctest registration. vi; > dfomp2p5-grad2/CMakeLists.txt; > - 10. dft-dldf: missing cmake directory registration. vi CMakeLists.txt; > - 11. dft-dsd: missing cmake directory registration. vi CMakeLists.txt; > - 12. dft-pbe0-2: missing cmake directory registration. vi; > CMakeLists.txt; > - 13. explicit-am-basis: mismatched directory (explicit-am-basis) and; > ctest registration name (explicit_am_basis). vi; > explicit-am-basis/CMakeLists.txt; > - 14. fsapt-diff1: missing cmake directory registration. vi; > CMakeLists.txt; > - 15. fsapt-diff1: missing CMakeLists.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137
https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137:699,Testability,test,tests,699,"The only thing worth hanging onto might be the bakerjcc93. But if we've; got that database otherwise available, then deletion fine with me. On Fri, Apr 22, 2022 at 11:14 AM Lori A. Burns ***@***.***>; wrote:. > after #2549 <https://github.com/psi4/psi4/pull/2549>, the list from python; > tester.py looks like the below. Most of these are easily healed by; > figuring out if they're intended to be a test or not. Nots should be; > removed to an attic or deleted. Also related is #2234; > <https://github.com/psi4/psi4/issues/2234> . don't rely on the below --; > rerun tester.py as needed.; >; > @psi-rking <https://github.com/psi-rking>, do you prefer attic or; > deletion for the un-run optimizer tests?; > Complaints; >; > - 1. cc5: missing cmake directory registration. vi CMakeLists.txt; > - 2. cookbook/manual-sow-reap: missing cmake directory registration. vi; > cookbook/CMakeLists.txt; > - 3. cookbook/manual-sow-reap: missing CMakeLists. vi; > cookbook/manual-sow-reap/CMakeLists.txt; > - 4. dfmp2-freq1: missing cmake directory registration. vi; > CMakeLists.txt; > - 5. dfmp2-freq2: missing cmake directory registration. vi; > CMakeLists.txt; > - 6. dfomp2p5-1: missing ctest registration. vi; > dfomp2p5-1/CMakeLists.txt; > - 7. dfomp2p5-2: missing ctest registration. vi; > dfomp2p5-2/CMakeLists.txt; > - 8. dfomp2p5-grad1: missing ctest registration. vi; > dfomp2p5-grad1/CMakeLists.txt; > - 9. dfomp2p5-grad2: missing ctest registration. vi; > dfomp2p5-grad2/CMakeLists.txt; > - 10. dft-dldf: missing cmake directory registration. vi CMakeLists.txt; > - 11. dft-dsd: missing cmake directory registration. vi CMakeLists.txt; > - 12. dft-pbe0-2: missing cmake directory registration. vi; > CMakeLists.txt; > - 13. explicit-am-basis: mismatched directory (explicit-am-basis) and; > ctest registration name (explicit_am_basis). vi; > explicit-am-basis/CMakeLists.txt; > - 14. fsapt-diff1: missing cmake directory registration. vi; > CMakeLists.txt; > - 15. fsapt-diff1: missing CMakeLists.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2555#issuecomment-1106781137
https://github.com/psi4/psi4/issues/2555#issuecomment-1230383695:15,Deployability,update,update,15,If @loriab can update current status post-#2655?,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2555#issuecomment-1230383695
https://github.com/psi4/psi4/issues/2555#issuecomment-1232090320:13,Testability,test,tester,13,"After #2655 `tester.py` complaints look like this:. Complaints; ----------; - [ ] 1. fsapt-diff1: missing cmake directory registration. `vi CMakeLists.txt`; - [ ] 2. fsapt-diff1: missing CMakeLists. `vi fsapt-diff1/CMakeLists.txt`; - [ ] 3. large-atoms: missing cmake directory registration. `vi CMakeLists.txt`; - [ ] 4. python/mints13: missing pytest input generated. check it! `vi python/mints13/test_input.py`. ------; `fsapt-diff1` contains useful reference data, but not currently tested. `large-atoms` is a draft test that was waiting on ECP gradients. Now that these are in, this should be able to be fleshed out. `python/mints13` is not currently working with pytest, so the generated input should be ignored for now. This test works through `python` but fails when run through `psi4` executable (ctest does the first, pytest the latter). It seems that the way pytest treats python input files might need to be fixed. See the note here: https://github.com/psi4/psi4/blob/master/tests/pytests/addons.py#L194-L203",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2555#issuecomment-1232090320
https://github.com/psi4/psi4/issues/2555#issuecomment-1232090320:487,Testability,test,tested,487,"After #2655 `tester.py` complaints look like this:. Complaints; ----------; - [ ] 1. fsapt-diff1: missing cmake directory registration. `vi CMakeLists.txt`; - [ ] 2. fsapt-diff1: missing CMakeLists. `vi fsapt-diff1/CMakeLists.txt`; - [ ] 3. large-atoms: missing cmake directory registration. `vi CMakeLists.txt`; - [ ] 4. python/mints13: missing pytest input generated. check it! `vi python/mints13/test_input.py`. ------; `fsapt-diff1` contains useful reference data, but not currently tested. `large-atoms` is a draft test that was waiting on ECP gradients. Now that these are in, this should be able to be fleshed out. `python/mints13` is not currently working with pytest, so the generated input should be ignored for now. This test works through `python` but fails when run through `psi4` executable (ctest does the first, pytest the latter). It seems that the way pytest treats python input files might need to be fixed. See the note here: https://github.com/psi4/psi4/blob/master/tests/pytests/addons.py#L194-L203",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2555#issuecomment-1232090320
https://github.com/psi4/psi4/issues/2555#issuecomment-1232090320:520,Testability,test,test,520,"After #2655 `tester.py` complaints look like this:. Complaints; ----------; - [ ] 1. fsapt-diff1: missing cmake directory registration. `vi CMakeLists.txt`; - [ ] 2. fsapt-diff1: missing CMakeLists. `vi fsapt-diff1/CMakeLists.txt`; - [ ] 3. large-atoms: missing cmake directory registration. `vi CMakeLists.txt`; - [ ] 4. python/mints13: missing pytest input generated. check it! `vi python/mints13/test_input.py`. ------; `fsapt-diff1` contains useful reference data, but not currently tested. `large-atoms` is a draft test that was waiting on ECP gradients. Now that these are in, this should be able to be fleshed out. `python/mints13` is not currently working with pytest, so the generated input should be ignored for now. This test works through `python` but fails when run through `psi4` executable (ctest does the first, pytest the latter). It seems that the way pytest treats python input files might need to be fixed. See the note here: https://github.com/psi4/psi4/blob/master/tests/pytests/addons.py#L194-L203",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2555#issuecomment-1232090320
https://github.com/psi4/psi4/issues/2555#issuecomment-1232090320:732,Testability,test,test,732,"After #2655 `tester.py` complaints look like this:. Complaints; ----------; - [ ] 1. fsapt-diff1: missing cmake directory registration. `vi CMakeLists.txt`; - [ ] 2. fsapt-diff1: missing CMakeLists. `vi fsapt-diff1/CMakeLists.txt`; - [ ] 3. large-atoms: missing cmake directory registration. `vi CMakeLists.txt`; - [ ] 4. python/mints13: missing pytest input generated. check it! `vi python/mints13/test_input.py`. ------; `fsapt-diff1` contains useful reference data, but not currently tested. `large-atoms` is a draft test that was waiting on ECP gradients. Now that these are in, this should be able to be fleshed out. `python/mints13` is not currently working with pytest, so the generated input should be ignored for now. This test works through `python` but fails when run through `psi4` executable (ctest does the first, pytest the latter). It seems that the way pytest treats python input files might need to be fixed. See the note here: https://github.com/psi4/psi4/blob/master/tests/pytests/addons.py#L194-L203",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2555#issuecomment-1232090320
https://github.com/psi4/psi4/issues/2555#issuecomment-1232090320:987,Testability,test,tests,987,"After #2655 `tester.py` complaints look like this:. Complaints; ----------; - [ ] 1. fsapt-diff1: missing cmake directory registration. `vi CMakeLists.txt`; - [ ] 2. fsapt-diff1: missing CMakeLists. `vi fsapt-diff1/CMakeLists.txt`; - [ ] 3. large-atoms: missing cmake directory registration. `vi CMakeLists.txt`; - [ ] 4. python/mints13: missing pytest input generated. check it! `vi python/mints13/test_input.py`. ------; `fsapt-diff1` contains useful reference data, but not currently tested. `large-atoms` is a draft test that was waiting on ECP gradients. Now that these are in, this should be able to be fleshed out. `python/mints13` is not currently working with pytest, so the generated input should be ignored for now. This test works through `python` but fails when run through `psi4` executable (ctest does the first, pytest the latter). It seems that the way pytest treats python input files might need to be fixed. See the note here: https://github.com/psi4/psi4/blob/master/tests/pytests/addons.py#L194-L203",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2555#issuecomment-1232090320
https://github.com/psi4/psi4/issues/2559#issuecomment-1111277619:474,Performance,perform,performance,474,"I agree @susilehtola , the problematic code is [here](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/scfgrad/jk_grad.cc#L308-L310) and [here](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/scfgrad/jk_grad.cc#L883-L888). What's happening is this: the JKGrad code creates a `TwoBodyAOInt` object per thread, in serial. The extra overhead in creating 8 vs 1 of these objects far outweighs any parallelism gained in the use of additional threads. I suspect this performance issue was introduced by the libint2 ERI overhaul, which happened in psi4 v1.4. If I recall correctly, as part of the overhaul, the `TwoBodyAOInt` constructor was changed to automatically perform Schwarz/CSAM screening and store a list of significant shell pairs. Before the overhaul, such a list of significant shell pairs was determined outside of the `TwoBodyAOInt` object, using an `ERISieve` object. As a consequence of this overhaul, the `TwoBodyAOInt` constructor is now very expensive (because it computes all `(mn|mn)` shell quartets to do the screening), and `TwoBodyAOInt` objects should be initialized sparingly. When many identical `TwoBodyAOInt` objects are needed, we should instead construct a single object and clone the rest, as is done [here](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/dlpno/mp2.cc#L635-L638) for example. Hopefully @andysim can confirm this.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2559#issuecomment-1111277619
https://github.com/psi4/psi4/issues/2559#issuecomment-1111277619:673,Performance,perform,perform,673,"I agree @susilehtola , the problematic code is [here](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/scfgrad/jk_grad.cc#L308-L310) and [here](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/scfgrad/jk_grad.cc#L883-L888). What's happening is this: the JKGrad code creates a `TwoBodyAOInt` object per thread, in serial. The extra overhead in creating 8 vs 1 of these objects far outweighs any parallelism gained in the use of additional threads. I suspect this performance issue was introduced by the libint2 ERI overhaul, which happened in psi4 v1.4. If I recall correctly, as part of the overhaul, the `TwoBodyAOInt` constructor was changed to automatically perform Schwarz/CSAM screening and store a list of significant shell pairs. Before the overhaul, such a list of significant shell pairs was determined outside of the `TwoBodyAOInt` object, using an `ERISieve` object. As a consequence of this overhaul, the `TwoBodyAOInt` constructor is now very expensive (because it computes all `(mn|mn)` shell quartets to do the screening), and `TwoBodyAOInt` objects should be initialized sparingly. When many identical `TwoBodyAOInt` objects are needed, we should instead construct a single object and clone the rest, as is done [here](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/dlpno/mp2.cc#L635-L638) for example. Hopefully @andysim can confirm this.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2559#issuecomment-1111277619
https://github.com/psi4/psi4/issues/2564#issuecomment-1112962032:38,Deployability,patch,patch,38,"Hi Rob, great to hear from you!. I'll patch up https://github.com/psi4/psi4/pull/2135 so that psi is using libecpint rather than internal ecp code. That'll be a better starting point for debugging. Thanks for the report!",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2564#issuecomment-1112962032
https://github.com/psi4/psi4/issues/2564#issuecomment-1133500319:1228,Integrability,Message,Message,1228,"Hi Peter - typically it is the house's job to determine if a bug has been; resolved or not - did you all (1) find evidence of my reported bug and (2); find evidence that it was fixed? I did not report that one lightly. Also; quite worried - I am seeing indications you all are switching basis; function ordering from one perfectly well-defined lexical convention which; is well documented to yet another perfectly well-defined lexical; convention. Both equally valid except that the first has been baked into a; half-million line code over more than a decade. If the switch of basis; functions is made at a similar time, this will provide additional barriers; for our staff to verify your proposed fix. On Thu, May 19, 2022 at 10:32 PM Peter Kraus ***@***.***>; wrote:. > @robparrishqc <https://github.com/robparrishqc> libecpint is now used by; > default in Psi4 1.6 - could you check whether the issue is still present?; >; > ; > Reply to this email directly, view it on GitHub; > <https://github.com/psi4/psi4/issues/2564#issuecomment-1132490820>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AKO3LYYQB4CGKQI4W2P73IDVK4PVRANCNFSM5UT7U6LA>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2564#issuecomment-1133500319
https://github.com/psi4/psi4/issues/2564#issuecomment-1133518145:541,Availability,error,errors,541,"Hi, Rob. All ECP-related issues are marked with the `ecpint-needed` tag. There are currently five open ones. I'm going to go through them and attempt to reproduce them with the v1.6 release, so we can assess if ECPs are broken. You raise a good point: debugging ECP issues is going to be harder if we also change basis functions. @loriab, can we put a moratorium on #2537 until we've had more time to investigate the ECP issues and evaluate the performance of DDD ""in the wild""? While I would not expect DDD to introduce strange correctness errors like I would expect of integral convention swaps, I am too paranoid to neglect the possibility. Say hi to Nick Stair for me. I'll report back once I've finished my preliminary investigations.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2564#issuecomment-1133518145
https://github.com/psi4/psi4/issues/2564#issuecomment-1133518145:182,Deployability,release,release,182,"Hi, Rob. All ECP-related issues are marked with the `ecpint-needed` tag. There are currently five open ones. I'm going to go through them and attempt to reproduce them with the v1.6 release, so we can assess if ECPs are broken. You raise a good point: debugging ECP issues is going to be harder if we also change basis functions. @loriab, can we put a moratorium on #2537 until we've had more time to investigate the ECP issues and evaluate the performance of DDD ""in the wild""? While I would not expect DDD to introduce strange correctness errors like I would expect of integral convention swaps, I am too paranoid to neglect the possibility. Say hi to Nick Stair for me. I'll report back once I've finished my preliminary investigations.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2564#issuecomment-1133518145
https://github.com/psi4/psi4/issues/2564#issuecomment-1133518145:445,Performance,perform,performance,445,"Hi, Rob. All ECP-related issues are marked with the `ecpint-needed` tag. There are currently five open ones. I'm going to go through them and attempt to reproduce them with the v1.6 release, so we can assess if ECPs are broken. You raise a good point: debugging ECP issues is going to be harder if we also change basis functions. @loriab, can we put a moratorium on #2537 until we've had more time to investigate the ECP issues and evaluate the performance of DDD ""in the wild""? While I would not expect DDD to introduce strange correctness errors like I would expect of integral convention swaps, I am too paranoid to neglect the possibility. Say hi to Nick Stair for me. I'll report back once I've finished my preliminary investigations.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2564#issuecomment-1133518145
https://github.com/psi4/psi4/issues/2564#issuecomment-1157785855:304,Availability,toler,tolerance,304,"I've been able to reproduce a disagreement between Psi4 and PySCF integrals. I've reached out to the `libecpint` developer to figure out if this may be an issue of numerical tightness. As far as I can tell, there's no mechanism for Psi4 to tell `libecpint` that we want our integrals to within a certain tolerance. That may be the issue for the iron pentacarbonyl system. The disagreement for your second system is much more disturbing, but my policy with debugging is to start with the simple cases first.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2564#issuecomment-1157785855
https://github.com/psi4/psi4/issues/2564#issuecomment-1157785855:487,Usability,simpl,simple,487,"I've been able to reproduce a disagreement between Psi4 and PySCF integrals. I've reached out to the `libecpint` developer to figure out if this may be an issue of numerical tightness. As far as I can tell, there's no mechanism for Psi4 to tell `libecpint` that we want our integrals to within a certain tolerance. That may be the issue for the iron pentacarbonyl system. The disagreement for your second system is much more disturbing, but my policy with debugging is to start with the simple cases first.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2564#issuecomment-1157785855
https://github.com/psi4/psi4/pull/2567#issuecomment-1115769652:296,Energy Efficiency,efficient,efficient,296,"I would keep the ""COSX"" for recognition. This PR implements 2 grids instead of 3? That Turbomole team showed it worked well, just asking. I am in general for a simple way of setting quadrature grids, psi4-specific named grids. That is a bigger project though.; Here it would be enough to have an efficient default and in the manual a suggestion how to make a tight/accurate one.; After we gain experience with the psi4 COSX we can make a couple useful defaults. Couple of things about grids later.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2567#issuecomment-1115769652
https://github.com/psi4/psi4/pull/2567#issuecomment-1115769652:160,Usability,simpl,simple,160,"I would keep the ""COSX"" for recognition. This PR implements 2 grids instead of 3? That Turbomole team showed it worked well, just asking. I am in general for a simple way of setting quadrature grids, psi4-specific named grids. That is a bigger project though.; Here it would be enough to have an efficient default and in the manual a suggestion how to make a tight/accurate one.; After we gain experience with the psi4 COSX we can make a couple useful defaults. Couple of things about grids later.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2567#issuecomment-1115769652
https://github.com/psi4/psi4/pull/2567#issuecomment-1116516160:1191,Deployability,update,update,1191,"> I would keep the ""COSX"" for recognition. That's a good point; ""COSX"" is a fairly well-known algorithm. For consistency throughout the psi4's `libfock` library, I think it would be good to call it ""COSK"" over ""COSX""; all reference to the exchange matrix use the variable ""K"". > This PR implements 2 grids instead of 3? That Turbomole team showed it worked well, just asking. Yes, the SCF is first converged on a small grid (specified by `COSK_RADIAL_POINTS` and `COSK_SPHERICAL_POINTS`). Afterwards, a single iteration is performed on a larger grid (specified by `COSK_RADIAL_POINTS_FINAL` and `COSK_SPHERICAL_POINTS_FINAL`). A good future mini-optimization would be to add a third medium grid, which would be used to converge the SCF after the small grid but before the final grid evaluation. > I am in general for a simple way of setting quadrature grids, psi4-specific named grids. That is a bigger project though. Here it would be enough to have an efficient default and in the manual a suggestion how to make a tight/accurate one. After we gain experience with the psi4 COSX we can make a couple useful defaults. I agree, it would be nice to have named quadrature grids. For now, I'll update the manual with some recommended spherical/radial point values.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2567#issuecomment-1116516160
https://github.com/psi4/psi4/pull/2567#issuecomment-1116516160:954,Energy Efficiency,efficient,efficient,954,"> I would keep the ""COSX"" for recognition. That's a good point; ""COSX"" is a fairly well-known algorithm. For consistency throughout the psi4's `libfock` library, I think it would be good to call it ""COSK"" over ""COSX""; all reference to the exchange matrix use the variable ""K"". > This PR implements 2 grids instead of 3? That Turbomole team showed it worked well, just asking. Yes, the SCF is first converged on a small grid (specified by `COSK_RADIAL_POINTS` and `COSK_SPHERICAL_POINTS`). Afterwards, a single iteration is performed on a larger grid (specified by `COSK_RADIAL_POINTS_FINAL` and `COSK_SPHERICAL_POINTS_FINAL`). A good future mini-optimization would be to add a third medium grid, which would be used to converge the SCF after the small grid but before the final grid evaluation. > I am in general for a simple way of setting quadrature grids, psi4-specific named grids. That is a bigger project though. Here it would be enough to have an efficient default and in the manual a suggestion how to make a tight/accurate one. After we gain experience with the psi4 COSX we can make a couple useful defaults. I agree, it would be nice to have named quadrature grids. For now, I'll update the manual with some recommended spherical/radial point values.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2567#issuecomment-1116516160
https://github.com/psi4/psi4/pull/2567#issuecomment-1116516160:263,Modifiability,variab,variable,263,"> I would keep the ""COSX"" for recognition. That's a good point; ""COSX"" is a fairly well-known algorithm. For consistency throughout the psi4's `libfock` library, I think it would be good to call it ""COSK"" over ""COSX""; all reference to the exchange matrix use the variable ""K"". > This PR implements 2 grids instead of 3? That Turbomole team showed it worked well, just asking. Yes, the SCF is first converged on a small grid (specified by `COSK_RADIAL_POINTS` and `COSK_SPHERICAL_POINTS`). Afterwards, a single iteration is performed on a larger grid (specified by `COSK_RADIAL_POINTS_FINAL` and `COSK_SPHERICAL_POINTS_FINAL`). A good future mini-optimization would be to add a third medium grid, which would be used to converge the SCF after the small grid but before the final grid evaluation. > I am in general for a simple way of setting quadrature grids, psi4-specific named grids. That is a bigger project though. Here it would be enough to have an efficient default and in the manual a suggestion how to make a tight/accurate one. After we gain experience with the psi4 COSX we can make a couple useful defaults. I agree, it would be nice to have named quadrature grids. For now, I'll update the manual with some recommended spherical/radial point values.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2567#issuecomment-1116516160
https://github.com/psi4/psi4/pull/2567#issuecomment-1116516160:523,Performance,perform,performed,523,"> I would keep the ""COSX"" for recognition. That's a good point; ""COSX"" is a fairly well-known algorithm. For consistency throughout the psi4's `libfock` library, I think it would be good to call it ""COSK"" over ""COSX""; all reference to the exchange matrix use the variable ""K"". > This PR implements 2 grids instead of 3? That Turbomole team showed it worked well, just asking. Yes, the SCF is first converged on a small grid (specified by `COSK_RADIAL_POINTS` and `COSK_SPHERICAL_POINTS`). Afterwards, a single iteration is performed on a larger grid (specified by `COSK_RADIAL_POINTS_FINAL` and `COSK_SPHERICAL_POINTS_FINAL`). A good future mini-optimization would be to add a third medium grid, which would be used to converge the SCF after the small grid but before the final grid evaluation. > I am in general for a simple way of setting quadrature grids, psi4-specific named grids. That is a bigger project though. Here it would be enough to have an efficient default and in the manual a suggestion how to make a tight/accurate one. After we gain experience with the psi4 COSX we can make a couple useful defaults. I agree, it would be nice to have named quadrature grids. For now, I'll update the manual with some recommended spherical/radial point values.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2567#issuecomment-1116516160
https://github.com/psi4/psi4/pull/2567#issuecomment-1116516160:646,Performance,optimiz,optimization,646,"> I would keep the ""COSX"" for recognition. That's a good point; ""COSX"" is a fairly well-known algorithm. For consistency throughout the psi4's `libfock` library, I think it would be good to call it ""COSK"" over ""COSX""; all reference to the exchange matrix use the variable ""K"". > This PR implements 2 grids instead of 3? That Turbomole team showed it worked well, just asking. Yes, the SCF is first converged on a small grid (specified by `COSK_RADIAL_POINTS` and `COSK_SPHERICAL_POINTS`). Afterwards, a single iteration is performed on a larger grid (specified by `COSK_RADIAL_POINTS_FINAL` and `COSK_SPHERICAL_POINTS_FINAL`). A good future mini-optimization would be to add a third medium grid, which would be used to converge the SCF after the small grid but before the final grid evaluation. > I am in general for a simple way of setting quadrature grids, psi4-specific named grids. That is a bigger project though. Here it would be enough to have an efficient default and in the manual a suggestion how to make a tight/accurate one. After we gain experience with the psi4 COSX we can make a couple useful defaults. I agree, it would be nice to have named quadrature grids. For now, I'll update the manual with some recommended spherical/radial point values.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2567#issuecomment-1116516160
https://github.com/psi4/psi4/pull/2567#issuecomment-1116516160:819,Usability,simpl,simple,819,"> I would keep the ""COSX"" for recognition. That's a good point; ""COSX"" is a fairly well-known algorithm. For consistency throughout the psi4's `libfock` library, I think it would be good to call it ""COSK"" over ""COSX""; all reference to the exchange matrix use the variable ""K"". > This PR implements 2 grids instead of 3? That Turbomole team showed it worked well, just asking. Yes, the SCF is first converged on a small grid (specified by `COSK_RADIAL_POINTS` and `COSK_SPHERICAL_POINTS`). Afterwards, a single iteration is performed on a larger grid (specified by `COSK_RADIAL_POINTS_FINAL` and `COSK_SPHERICAL_POINTS_FINAL`). A good future mini-optimization would be to add a third medium grid, which would be used to converge the SCF after the small grid but before the final grid evaluation. > I am in general for a simple way of setting quadrature grids, psi4-specific named grids. That is a bigger project though. Here it would be enough to have an efficient default and in the manual a suggestion how to make a tight/accurate one. After we gain experience with the psi4 COSX we can make a couple useful defaults. I agree, it would be nice to have named quadrature grids. For now, I'll update the manual with some recommended spherical/radial point values.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2567#issuecomment-1116516160
https://github.com/psi4/psi4/pull/2567#issuecomment-1117521179:904,Availability,ROBUST,ROBUST,904,"> Internally it's fine to use COSK, however user-facing it is better to use COSX, imo. That's a good idea, done. > Ideally the COSK grids can use all the options the normal DFT grid uses. At the very least pruning. However it is a bit annoying that one has to duplicate/triplicate the normal DFT grid options for this. Not sure how this can be solved best. Yes, the fact that the COSX grids are affected by keywords such as `DFT_PRUNING_SCHEME`, `DFT_RADIAL_SCHEME`, `DFT_NUCLEAR_SCHEME`, etc. is not ideal. I don't think we should duplicate/triplicate these keywords (resulting in independent but parallel keywords like `COSX_RADIAL_SCHEME`, `COSX_RADIAL_SCHEME_FINAL`, etc.) because I can't imagine any users realistically wanting to manually set those values. I think it makes more sense to hardwire some of the grid settings when building the grids for COSX. For example, we probably always want do `ROBUST` pruning on those grids.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2567#issuecomment-1117521179
https://github.com/psi4/psi4/pull/2567#issuecomment-1119732227:25,Testability,benchmark,benchmarks,25,"> As a side comment, the benchmarks look pretty great, but it would be interesting to see how the benchmark results look with a system spread out three-dimensionally instead of a linear system. Thanks, I have run additional tests on three-dimensional systems not shown here. On the [human insulin protein](https://www.rcsb.org/structure/2HIU) (405 heavy atoms), a HF/cc-pVDZ calculation with `COSX` is a bit more than twice as fast as the corresponding `DF` calculation.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2567#issuecomment-1119732227
https://github.com/psi4/psi4/pull/2567#issuecomment-1119732227:98,Testability,benchmark,benchmark,98,"> As a side comment, the benchmarks look pretty great, but it would be interesting to see how the benchmark results look with a system spread out three-dimensionally instead of a linear system. Thanks, I have run additional tests on three-dimensional systems not shown here. On the [human insulin protein](https://www.rcsb.org/structure/2HIU) (405 heavy atoms), a HF/cc-pVDZ calculation with `COSX` is a bit more than twice as fast as the corresponding `DF` calculation.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2567#issuecomment-1119732227
https://github.com/psi4/psi4/pull/2567#issuecomment-1119732227:224,Testability,test,tests,224,"> As a side comment, the benchmarks look pretty great, but it would be interesting to see how the benchmark results look with a system spread out three-dimensionally instead of a linear system. Thanks, I have run additional tests on three-dimensional systems not shown here. On the [human insulin protein](https://www.rcsb.org/structure/2HIU) (405 heavy atoms), a HF/cc-pVDZ calculation with `COSX` is a bit more than twice as fast as the corresponding `DF` calculation.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2567#issuecomment-1119732227
https://github.com/psi4/psi4/pull/2567#issuecomment-1119740205:27,Testability,benchmark,benchmarks,27,"> > As a side comment, the benchmarks look pretty great, but it would be interesting to see how the benchmark results look with a system spread out three-dimensionally instead of a linear system.; > ; > Thanks, I have run additional tests on three-dimensional systems not shown here. On the [human insulin protein](https://www.rcsb.org/structure/2HIU) (405 heavy atoms), a HF/cc-pVDZ calculation with `COSX` is a bit more than twice as fast as the corresponding `DF` calculation. You're welcome! And that is a very nice result on the protein system.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2567#issuecomment-1119740205
https://github.com/psi4/psi4/pull/2567#issuecomment-1119740205:100,Testability,benchmark,benchmark,100,"> > As a side comment, the benchmarks look pretty great, but it would be interesting to see how the benchmark results look with a system spread out three-dimensionally instead of a linear system.; > ; > Thanks, I have run additional tests on three-dimensional systems not shown here. On the [human insulin protein](https://www.rcsb.org/structure/2HIU) (405 heavy atoms), a HF/cc-pVDZ calculation with `COSX` is a bit more than twice as fast as the corresponding `DF` calculation. You're welcome! And that is a very nice result on the protein system.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2567#issuecomment-1119740205
https://github.com/psi4/psi4/pull/2567#issuecomment-1119740205:233,Testability,test,tests,233,"> > As a side comment, the benchmarks look pretty great, but it would be interesting to see how the benchmark results look with a system spread out three-dimensionally instead of a linear system.; > ; > Thanks, I have run additional tests on three-dimensional systems not shown here. On the [human insulin protein](https://www.rcsb.org/structure/2HIU) (405 heavy atoms), a HF/cc-pVDZ calculation with `COSX` is a bit more than twice as fast as the corresponding `DF` calculation. You're welcome! And that is a very nice result on the protein system.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2567#issuecomment-1119740205
https://github.com/psi4/psi4/pull/2567#issuecomment-1120024084:91,Testability,benchmark,benchmark,91,"IIRC speedups of seminumerical methods increase with larger basis sets, so you may want to benchmark those as well...",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2567#issuecomment-1120024084
https://github.com/psi4/psi4/pull/2567#issuecomment-1120037065:372,Performance,perform,performance,372,"> IIRC speedups of seminumerical methods increase with larger basis sets, so you may want to benchmark those as well... Youre totally right. I have DZ timings, which agree with your statement. I need to run QZ eventually. Side note: the integral bound used in this PR is looser for higher angular momentum. I expect future improvements to this integral bound to make the performance of higher angular momentum basis sets even better.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2567#issuecomment-1120037065
https://github.com/psi4/psi4/pull/2567#issuecomment-1120037065:93,Testability,benchmark,benchmark,93,"> IIRC speedups of seminumerical methods increase with larger basis sets, so you may want to benchmark those as well... Youre totally right. I have DZ timings, which agree with your statement. I need to run QZ eventually. Side note: the integral bound used in this PR is looser for higher angular momentum. I expect future improvements to this integral bound to make the performance of higher angular momentum basis sets even better.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2567#issuecomment-1120037065
https://github.com/psi4/psi4/pull/2567#issuecomment-1120063699:167,Availability,error,errors,167,"I didn't examine the code in detail; does it use aliasing? I think Neese and coworkers use it a lot, the idea is to make the integrand smoother so that the quadrature errors are smaller and one can get away with smaller grids.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2567#issuecomment-1120063699
https://github.com/psi4/psi4/pull/2567#issuecomment-1120084494:169,Availability,error,errors,169,"> I didn't examine the code in detail; does it use aliasing? I think Neese and coworkers use it a lot, the idea is to make the integrand smoother so that the quadrature errors are smaller and one can get away with smaller grids. Yes, this PR uses aliasing (also called ""overlap fitting""). This feature is enabled with the `COSX_OVERLAP_FITTING` keyword. The second reference added to the bibliography covers the theory behind this idea, and the code references equations from this paper.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2567#issuecomment-1120084494
https://github.com/psi4/psi4/pull/2569#issuecomment-1129504422:181,Deployability,update,update,181,"Still in the draft stage, but next round of edits is in. I need to give the tests another pass to make sure we have proper coverage. The other major issue is the docs. I'll need to update the section describing excite state psivars, but @loriab, how do you feel about grouping psivars together? See discussion [here](https://github.com/psi4/psi4/pull/2462#discussion_r822344906).",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2569#issuecomment-1129504422
https://github.com/psi4/psi4/pull/2569#issuecomment-1129504422:76,Testability,test,tests,76,"Still in the draft stage, but next round of edits is in. I need to give the tests another pass to make sure we have proper coverage. The other major issue is the docs. I'll need to update the section describing excite state psivars, but @loriab, how do you feel about grouping psivars together? See discussion [here](https://github.com/psi4/psi4/pull/2462#discussion_r822344906).",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2569#issuecomment-1129504422
https://github.com/psi4/psi4/pull/2569#issuecomment-1129510593:50,Deployability,update,update,50,"> The other major issue is the docs. I'll need to update the section describing excite state psivars, but @loriab, how do you feel about grouping psivars together? See discussion https://github.com/psi4/psi4/pull/2462#discussion_r822344906. I'd still strongly favor something like the below. It lets the variables (n,m,h,i) be defined in the definition, and new methods can join existing psivar entries. Also just less visual clutter when all but the methods line up. What do you think?. ```; .. psivar:: ADC ROOT n TOTAL ENERGY; TDDFT ROOT n TOTAL ENERGY; TD-fctl ROOT n TOTAL ENERGY; CCSD ROOT n TOTAL ENERGY; ... def incl n. .. psivar:: TDDFT ROOT n (h) -> ROOT m (i) OSCILLATOR ENERGY; CCSD ROOT n (h) -> ROOT m (i) OSCILLATOR ENERGY. def incl n, m, h, i; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2569#issuecomment-1129510593
https://github.com/psi4/psi4/pull/2569#issuecomment-1129510593:522,Energy Efficiency,ENERGY,ENERGY,522,"> The other major issue is the docs. I'll need to update the section describing excite state psivars, but @loriab, how do you feel about grouping psivars together? See discussion https://github.com/psi4/psi4/pull/2462#discussion_r822344906. I'd still strongly favor something like the below. It lets the variables (n,m,h,i) be defined in the definition, and new methods can join existing psivar entries. Also just less visual clutter when all but the methods line up. What do you think?. ```; .. psivar:: ADC ROOT n TOTAL ENERGY; TDDFT ROOT n TOTAL ENERGY; TD-fctl ROOT n TOTAL ENERGY; CCSD ROOT n TOTAL ENERGY; ... def incl n. .. psivar:: TDDFT ROOT n (h) -> ROOT m (i) OSCILLATOR ENERGY; CCSD ROOT n (h) -> ROOT m (i) OSCILLATOR ENERGY. def incl n, m, h, i; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2569#issuecomment-1129510593
https://github.com/psi4/psi4/pull/2569#issuecomment-1129510593:549,Energy Efficiency,ENERGY,ENERGY,549,"> The other major issue is the docs. I'll need to update the section describing excite state psivars, but @loriab, how do you feel about grouping psivars together? See discussion https://github.com/psi4/psi4/pull/2462#discussion_r822344906. I'd still strongly favor something like the below. It lets the variables (n,m,h,i) be defined in the definition, and new methods can join existing psivar entries. Also just less visual clutter when all but the methods line up. What do you think?. ```; .. psivar:: ADC ROOT n TOTAL ENERGY; TDDFT ROOT n TOTAL ENERGY; TD-fctl ROOT n TOTAL ENERGY; CCSD ROOT n TOTAL ENERGY; ... def incl n. .. psivar:: TDDFT ROOT n (h) -> ROOT m (i) OSCILLATOR ENERGY; CCSD ROOT n (h) -> ROOT m (i) OSCILLATOR ENERGY. def incl n, m, h, i; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2569#issuecomment-1129510593
https://github.com/psi4/psi4/pull/2569#issuecomment-1129510593:578,Energy Efficiency,ENERGY,ENERGY,578,"> The other major issue is the docs. I'll need to update the section describing excite state psivars, but @loriab, how do you feel about grouping psivars together? See discussion https://github.com/psi4/psi4/pull/2462#discussion_r822344906. I'd still strongly favor something like the below. It lets the variables (n,m,h,i) be defined in the definition, and new methods can join existing psivar entries. Also just less visual clutter when all but the methods line up. What do you think?. ```; .. psivar:: ADC ROOT n TOTAL ENERGY; TDDFT ROOT n TOTAL ENERGY; TD-fctl ROOT n TOTAL ENERGY; CCSD ROOT n TOTAL ENERGY; ... def incl n. .. psivar:: TDDFT ROOT n (h) -> ROOT m (i) OSCILLATOR ENERGY; CCSD ROOT n (h) -> ROOT m (i) OSCILLATOR ENERGY. def incl n, m, h, i; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2569#issuecomment-1129510593
https://github.com/psi4/psi4/pull/2569#issuecomment-1129510593:604,Energy Efficiency,ENERGY,ENERGY,604,"> The other major issue is the docs. I'll need to update the section describing excite state psivars, but @loriab, how do you feel about grouping psivars together? See discussion https://github.com/psi4/psi4/pull/2462#discussion_r822344906. I'd still strongly favor something like the below. It lets the variables (n,m,h,i) be defined in the definition, and new methods can join existing psivar entries. Also just less visual clutter when all but the methods line up. What do you think?. ```; .. psivar:: ADC ROOT n TOTAL ENERGY; TDDFT ROOT n TOTAL ENERGY; TD-fctl ROOT n TOTAL ENERGY; CCSD ROOT n TOTAL ENERGY; ... def incl n. .. psivar:: TDDFT ROOT n (h) -> ROOT m (i) OSCILLATOR ENERGY; CCSD ROOT n (h) -> ROOT m (i) OSCILLATOR ENERGY. def incl n, m, h, i; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2569#issuecomment-1129510593
https://github.com/psi4/psi4/pull/2569#issuecomment-1129510593:682,Energy Efficiency,ENERGY,ENERGY,682,"> The other major issue is the docs. I'll need to update the section describing excite state psivars, but @loriab, how do you feel about grouping psivars together? See discussion https://github.com/psi4/psi4/pull/2462#discussion_r822344906. I'd still strongly favor something like the below. It lets the variables (n,m,h,i) be defined in the definition, and new methods can join existing psivar entries. Also just less visual clutter when all but the methods line up. What do you think?. ```; .. psivar:: ADC ROOT n TOTAL ENERGY; TDDFT ROOT n TOTAL ENERGY; TD-fctl ROOT n TOTAL ENERGY; CCSD ROOT n TOTAL ENERGY; ... def incl n. .. psivar:: TDDFT ROOT n (h) -> ROOT m (i) OSCILLATOR ENERGY; CCSD ROOT n (h) -> ROOT m (i) OSCILLATOR ENERGY. def incl n, m, h, i; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2569#issuecomment-1129510593
https://github.com/psi4/psi4/pull/2569#issuecomment-1129510593:731,Energy Efficiency,ENERGY,ENERGY,731,"> The other major issue is the docs. I'll need to update the section describing excite state psivars, but @loriab, how do you feel about grouping psivars together? See discussion https://github.com/psi4/psi4/pull/2462#discussion_r822344906. I'd still strongly favor something like the below. It lets the variables (n,m,h,i) be defined in the definition, and new methods can join existing psivar entries. Also just less visual clutter when all but the methods line up. What do you think?. ```; .. psivar:: ADC ROOT n TOTAL ENERGY; TDDFT ROOT n TOTAL ENERGY; TD-fctl ROOT n TOTAL ENERGY; CCSD ROOT n TOTAL ENERGY; ... def incl n. .. psivar:: TDDFT ROOT n (h) -> ROOT m (i) OSCILLATOR ENERGY; CCSD ROOT n (h) -> ROOT m (i) OSCILLATOR ENERGY. def incl n, m, h, i; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2569#issuecomment-1129510593
https://github.com/psi4/psi4/pull/2569#issuecomment-1129510593:304,Modifiability,variab,variables,304,"> The other major issue is the docs. I'll need to update the section describing excite state psivars, but @loriab, how do you feel about grouping psivars together? See discussion https://github.com/psi4/psi4/pull/2462#discussion_r822344906. I'd still strongly favor something like the below. It lets the variables (n,m,h,i) be defined in the definition, and new methods can join existing psivar entries. Also just less visual clutter when all but the methods line up. What do you think?. ```; .. psivar:: ADC ROOT n TOTAL ENERGY; TDDFT ROOT n TOTAL ENERGY; TD-fctl ROOT n TOTAL ENERGY; CCSD ROOT n TOTAL ENERGY; ... def incl n. .. psivar:: TDDFT ROOT n (h) -> ROOT m (i) OSCILLATOR ENERGY; CCSD ROOT n (h) -> ROOT m (i) OSCILLATOR ENERGY. def incl n, m, h, i; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2569#issuecomment-1129510593
https://github.com/psi4/psi4/pull/2569#issuecomment-1129511560:30,Availability,down,down,30,"I wish there was a way to cut down the repetition in variable description, but from the user standpoint, that probably is the way to go... I'll get docs up and un-draft this (hopefully tonight) and save test pass for tomorrow.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2569#issuecomment-1129511560
https://github.com/psi4/psi4/pull/2569#issuecomment-1129511560:53,Modifiability,variab,variable,53,"I wish there was a way to cut down the repetition in variable description, but from the user standpoint, that probably is the way to go... I'll get docs up and un-draft this (hopefully tonight) and save test pass for tomorrow.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2569#issuecomment-1129511560
https://github.com/psi4/psi4/pull/2569#issuecomment-1129511560:203,Testability,test,test,203,"I wish there was a way to cut down the repetition in variable description, but from the user standpoint, that probably is the way to go... I'll get docs up and un-draft this (hopefully tonight) and save test pass for tomorrow.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2569#issuecomment-1129511560
https://github.com/psi4/psi4/pull/2569#issuecomment-1129513001:32,Availability,down,down,32,"> I wish there was a way to cut down the repetition in variable description, but from the user standpoint, that probably is the way to go... In another project, I have the glossary-like doc generated by python to cut down on that. Perhaps someday ...",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2569#issuecomment-1129513001
https://github.com/psi4/psi4/pull/2569#issuecomment-1129513001:217,Availability,down,down,217,"> I wish there was a way to cut down the repetition in variable description, but from the user standpoint, that probably is the way to go... In another project, I have the glossary-like doc generated by python to cut down on that. Perhaps someday ...",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2569#issuecomment-1129513001
https://github.com/psi4/psi4/pull/2569#issuecomment-1129513001:55,Modifiability,variab,variable,55,"> I wish there was a way to cut down the repetition in variable description, but from the user standpoint, that probably is the way to go... In another project, I have the glossary-like doc generated by python to cut down on that. Perhaps someday ...",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2569#issuecomment-1129513001
https://github.com/psi4/psi4/pull/2569#issuecomment-1130254831:71,Testability,test,tests,71,"Docs took way longer than expected, but that part is done. Now to give tests a sweep.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2569#issuecomment-1130254831
https://github.com/psi4/psi4/issues/2571#issuecomment-1120477445:944,Availability,error,error,944,"Hi,. I suspect that this problem is related to the definition of your basis set. The `basis` block in your input file is part of psi4's special syntax to define [custom, mixed basis sets](https://psicode.org/psi4manual/1.5.0/basissets.html#mixing-basis-sets):; ```; basis {; assign def2-SVP; }; ```. I can run your inputs successfully if I swap out that `basis` block for the standard basis syntax:; ```; set {; basis def2-SVP; }; ```. Here's the SCF output from the second input, which starts the SCF from the serialized orbitals:; ```; ==> Iterations <== . Total Energy Delta E RMS |[F,P]|. @DF-RKS iter 0: -270.15381570481316 -2.70154e+02 1.44676e-07 ; @DF-RKS iter 1: -270.15381570483822 -2.50679e-11 1.66794e-07 DIIS; Energy and wave function converged.; ```. This fix should be sufficient if all of your calculations require standard, pre-defined basis sets. If you do need to use custom, mixed basis sets, we'll need to investigate this error further.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2571#issuecomment-1120477445
https://github.com/psi4/psi4/issues/2571#issuecomment-1120477445:565,Energy Efficiency,Energy,Energy,565,"Hi,. I suspect that this problem is related to the definition of your basis set. The `basis` block in your input file is part of psi4's special syntax to define [custom, mixed basis sets](https://psicode.org/psi4manual/1.5.0/basissets.html#mixing-basis-sets):; ```; basis {; assign def2-SVP; }; ```. I can run your inputs successfully if I swap out that `basis` block for the standard basis syntax:; ```; set {; basis def2-SVP; }; ```. Here's the SCF output from the second input, which starts the SCF from the serialized orbitals:; ```; ==> Iterations <== . Total Energy Delta E RMS |[F,P]|. @DF-RKS iter 0: -270.15381570481316 -2.70154e+02 1.44676e-07 ; @DF-RKS iter 1: -270.15381570483822 -2.50679e-11 1.66794e-07 DIIS; Energy and wave function converged.; ```. This fix should be sufficient if all of your calculations require standard, pre-defined basis sets. If you do need to use custom, mixed basis sets, we'll need to investigate this error further.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2571#issuecomment-1120477445
https://github.com/psi4/psi4/issues/2571#issuecomment-1120477445:723,Energy Efficiency,Energy,Energy,723,"Hi,. I suspect that this problem is related to the definition of your basis set. The `basis` block in your input file is part of psi4's special syntax to define [custom, mixed basis sets](https://psicode.org/psi4manual/1.5.0/basissets.html#mixing-basis-sets):; ```; basis {; assign def2-SVP; }; ```. I can run your inputs successfully if I swap out that `basis` block for the standard basis syntax:; ```; set {; basis def2-SVP; }; ```. Here's the SCF output from the second input, which starts the SCF from the serialized orbitals:; ```; ==> Iterations <== . Total Energy Delta E RMS |[F,P]|. @DF-RKS iter 0: -270.15381570481316 -2.70154e+02 1.44676e-07 ; @DF-RKS iter 1: -270.15381570483822 -2.50679e-11 1.66794e-07 DIIS; Energy and wave function converged.; ```. This fix should be sufficient if all of your calculations require standard, pre-defined basis sets. If you do need to use custom, mixed basis sets, we'll need to investigate this error further.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2571#issuecomment-1120477445
https://github.com/psi4/psi4/issues/2571#issuecomment-1120488692:862,Modifiability,flexible,flexible,862,"Thanks! It looks like naming the basis (`basis this_basis { ... }`) and then using `set basis this_basis` also works. That being said, I don't I understand why this would be an issue. The way I have requested the basis set is not unusual. Although I'm using the syntax for a mixed/custom basis set, it's the first example presented on that page of the documentation. It's also a valid way to request a basis set - the first job worked after all. The documentation says that `basis { assign ... }` statements can be used to request a basis set and replace `set basis X`. It looks like mixed basis sets also work... as long as you use `basis this_basis { ... }` and `set basis this_basis`. I've used that syntax to apply def2-SVP to C and O, and STO-3G to H, and then restarted the SCF successfully. . Is there another syntax for reading an SCF guess that is more flexible? For the application I have in mind, I'd be using it for gradients rather than single-point energies.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2571#issuecomment-1120488692
https://github.com/psi4/psi4/issues/2571#issuecomment-1120579737:80,Availability,error,error,80,"Thanks for looking into this! I now have a better understanding of the original error. . First, a note about the SCF restart technology: when you use the `wfn.to_file()` function in the first file, psi4 saves (1) the name of the basis set and (2) the matrix of orbital coefficients. The numbers contained in the orbital matrix aren't useful without knowing which basis they correspond to. In the second file, psi4 reconstructs the basis set using both the saved name and orbital coefficients. When a `basis` object is defined without a name, psi4 gives that object a [randomly generated name](https://github.com/psi4/psi4/blob/master/psi4/driver/inputparser.py#L273). This is a problem when you want to use the same `basis` object in a new file, since the same object defined in different files will receive different, random names. In the error you posted, the bit about `ANONYMOUS5AA41DFC` refers to the randomly generated name of the basis. Psi4 has no way of knowing what this basis set is. Your solution of using `basis this_basis { ... }` and `set basis this_basis` certainly works, but you actually don't even need the second line; all you need is `basis this_basis { ... }`. You asked about a more flexible syntax for reading SCF guesses. What about the current syntax is limiting?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2571#issuecomment-1120579737
https://github.com/psi4/psi4/issues/2571#issuecomment-1120579737:840,Availability,error,error,840,"Thanks for looking into this! I now have a better understanding of the original error. . First, a note about the SCF restart technology: when you use the `wfn.to_file()` function in the first file, psi4 saves (1) the name of the basis set and (2) the matrix of orbital coefficients. The numbers contained in the orbital matrix aren't useful without knowing which basis they correspond to. In the second file, psi4 reconstructs the basis set using both the saved name and orbital coefficients. When a `basis` object is defined without a name, psi4 gives that object a [randomly generated name](https://github.com/psi4/psi4/blob/master/psi4/driver/inputparser.py#L273). This is a problem when you want to use the same `basis` object in a new file, since the same object defined in different files will receive different, random names. In the error you posted, the bit about `ANONYMOUS5AA41DFC` refers to the randomly generated name of the basis. Psi4 has no way of knowing what this basis set is. Your solution of using `basis this_basis { ... }` and `set basis this_basis` certainly works, but you actually don't even need the second line; all you need is `basis this_basis { ... }`. You asked about a more flexible syntax for reading SCF guesses. What about the current syntax is limiting?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2571#issuecomment-1120579737
https://github.com/psi4/psi4/issues/2571#issuecomment-1120579737:1206,Modifiability,flexible,flexible,1206,"Thanks for looking into this! I now have a better understanding of the original error. . First, a note about the SCF restart technology: when you use the `wfn.to_file()` function in the first file, psi4 saves (1) the name of the basis set and (2) the matrix of orbital coefficients. The numbers contained in the orbital matrix aren't useful without knowing which basis they correspond to. In the second file, psi4 reconstructs the basis set using both the saved name and orbital coefficients. When a `basis` object is defined without a name, psi4 gives that object a [randomly generated name](https://github.com/psi4/psi4/blob/master/psi4/driver/inputparser.py#L273). This is a problem when you want to use the same `basis` object in a new file, since the same object defined in different files will receive different, random names. In the error you posted, the bit about `ANONYMOUS5AA41DFC` refers to the randomly generated name of the basis. Psi4 has no way of knowing what this basis set is. Your solution of using `basis this_basis { ... }` and `set basis this_basis` certainly works, but you actually don't even need the second line; all you need is `basis this_basis { ... }`. You asked about a more flexible syntax for reading SCF guesses. What about the current syntax is limiting?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2571#issuecomment-1120579737
https://github.com/psi4/psi4/issues/2571#issuecomment-1121436485:391,Energy Efficiency,energy,energy,391,"Thanks, the basis set name makes sense. I will start naming my basis sets, but would it be possible to use a deterministic name for basis sets instead of a random one?. The `gradient` method does not use the `restart_file` keyword. I tried it, and it defaulted to the SAD guess. the SCF took 13 iterations to converge for the molecule in the original input file. As far as I can tell, only `energy` will utilize the guess from the restart file. I suppose I could call `energy(..., restart_file=X)`, then use `set guess read`, and then call `gradient`. That feels like more juggling than should be necessary.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2571#issuecomment-1121436485
https://github.com/psi4/psi4/issues/2571#issuecomment-1121436485:469,Energy Efficiency,energy,energy,469,"Thanks, the basis set name makes sense. I will start naming my basis sets, but would it be possible to use a deterministic name for basis sets instead of a random one?. The `gradient` method does not use the `restart_file` keyword. I tried it, and it defaulted to the SAD guess. the SCF took 13 iterations to converge for the molecule in the original input file. As far as I can tell, only `energy` will utilize the guess from the restart file. I suppose I could call `energy(..., restart_file=X)`, then use `set guess read`, and then call `gradient`. That feels like more juggling than should be necessary.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2571#issuecomment-1121436485
https://github.com/psi4/psi4/issues/2571#issuecomment-1121447923:431,Energy Efficiency,energy,energy,431,"> Thanks, the basis set name makes sense. I will start naming my basis sets, but would it be possible to use a deterministic name for basis sets instead of a random one?. This feels like a @loriab question. > The `gradient` method does not use the `restart_file` keyword. I tried it, and it defaulted to the SAD guess. the SCF took 13 iterations to converge for the molecule in the original input file. As far as I can tell, only `energy` will utilize the guess from the restart file. I suppose I could call `energy(..., restart_file=X)`, then use `set guess read`, and then call `gradient`. That feels like more juggling than should be necessary. If `energy` takes this, then `gradient`, `frequencies`, and `properties`, etc. _should_ as well. We (meaning @loriab) are currently refactoring the above functions, to better support for embarrassingly parallel computations. I recommend that we wait until _after_ that refactoring to make the necessary changes here.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2571#issuecomment-1121447923
https://github.com/psi4/psi4/issues/2571#issuecomment-1121447923:509,Energy Efficiency,energy,energy,509,"> Thanks, the basis set name makes sense. I will start naming my basis sets, but would it be possible to use a deterministic name for basis sets instead of a random one?. This feels like a @loriab question. > The `gradient` method does not use the `restart_file` keyword. I tried it, and it defaulted to the SAD guess. the SCF took 13 iterations to converge for the molecule in the original input file. As far as I can tell, only `energy` will utilize the guess from the restart file. I suppose I could call `energy(..., restart_file=X)`, then use `set guess read`, and then call `gradient`. That feels like more juggling than should be necessary. If `energy` takes this, then `gradient`, `frequencies`, and `properties`, etc. _should_ as well. We (meaning @loriab) are currently refactoring the above functions, to better support for embarrassingly parallel computations. I recommend that we wait until _after_ that refactoring to make the necessary changes here.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2571#issuecomment-1121447923
https://github.com/psi4/psi4/issues/2571#issuecomment-1121447923:652,Energy Efficiency,energy,energy,652,"> Thanks, the basis set name makes sense. I will start naming my basis sets, but would it be possible to use a deterministic name for basis sets instead of a random one?. This feels like a @loriab question. > The `gradient` method does not use the `restart_file` keyword. I tried it, and it defaulted to the SAD guess. the SCF took 13 iterations to converge for the molecule in the original input file. As far as I can tell, only `energy` will utilize the guess from the restart file. I suppose I could call `energy(..., restart_file=X)`, then use `set guess read`, and then call `gradient`. That feels like more juggling than should be necessary. If `energy` takes this, then `gradient`, `frequencies`, and `properties`, etc. _should_ as well. We (meaning @loriab) are currently refactoring the above functions, to better support for embarrassingly parallel computations. I recommend that we wait until _after_ that refactoring to make the necessary changes here.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2571#issuecomment-1121447923
https://github.com/psi4/psi4/issues/2571#issuecomment-1121447923:780,Modifiability,refactor,refactoring,780,"> Thanks, the basis set name makes sense. I will start naming my basis sets, but would it be possible to use a deterministic name for basis sets instead of a random one?. This feels like a @loriab question. > The `gradient` method does not use the `restart_file` keyword. I tried it, and it defaulted to the SAD guess. the SCF took 13 iterations to converge for the molecule in the original input file. As far as I can tell, only `energy` will utilize the guess from the restart file. I suppose I could call `energy(..., restart_file=X)`, then use `set guess read`, and then call `gradient`. That feels like more juggling than should be necessary. If `energy` takes this, then `gradient`, `frequencies`, and `properties`, etc. _should_ as well. We (meaning @loriab) are currently refactoring the above functions, to better support for embarrassingly parallel computations. I recommend that we wait until _after_ that refactoring to make the necessary changes here.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2571#issuecomment-1121447923
https://github.com/psi4/psi4/issues/2571#issuecomment-1121447923:917,Modifiability,refactor,refactoring,917,"> Thanks, the basis set name makes sense. I will start naming my basis sets, but would it be possible to use a deterministic name for basis sets instead of a random one?. This feels like a @loriab question. > The `gradient` method does not use the `restart_file` keyword. I tried it, and it defaulted to the SAD guess. the SCF took 13 iterations to converge for the molecule in the original input file. As far as I can tell, only `energy` will utilize the guess from the restart file. I suppose I could call `energy(..., restart_file=X)`, then use `set guess read`, and then call `gradient`. That feels like more juggling than should be necessary. If `energy` takes this, then `gradient`, `frequencies`, and `properties`, etc. _should_ as well. We (meaning @loriab) are currently refactoring the above functions, to better support for embarrassingly parallel computations. I recommend that we wait until _after_ that refactoring to make the necessary changes here.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2571#issuecomment-1121447923
https://github.com/psi4/psi4/issues/2572#issuecomment-1121151090:56,Deployability,update,update,56,What's the output of `conda list`? You probably need to update your version of libint2.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2572#issuecomment-1121151090
https://github.com/psi4/psi4/issues/2572#issuecomment-1121208944:184,Availability,down,downloaded,184,"@JonathonMisiewicz I'm not using conda at all, as described above, i started from a clean directory, cloned the source, ran cmake and make. The libint is the one that is automatically downloaded if no libint was found:; ```; -- Suitable Libint2 could not be located, Building Libint2 5-4-3-6-5-4 instead.; ```; in the cmake step and; ```; [ 10%] Performing download step (download, verify and extract) for 'libint2_external'; [ 12%] Performing download step (download, verify and extract) for 'pybind11_external'; -- Downloading...; dst='/scr/behnle/psi4_clean_cmake_3.19/psi4/objdir/external/upstream/libint2/libint2_external-prefix/src/Libint2-export-5-4-3-6-5-4_mm4f12ob2.tgz'; timeout='none'; inactivity timeout='none'; -- Using src='https://github.com/loriab/libint/releases/download/v0.1/Libint2-export-5-4-3-6-5-4_mm4f12ob2.tgz'; -- Downloading...; ``` ; in the make step. @loriab Thanks for the quick reply, i will try and report back.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2572#issuecomment-1121208944
https://github.com/psi4/psi4/issues/2572#issuecomment-1121208944:357,Availability,down,download,357,"@JonathonMisiewicz I'm not using conda at all, as described above, i started from a clean directory, cloned the source, ran cmake and make. The libint is the one that is automatically downloaded if no libint was found:; ```; -- Suitable Libint2 could not be located, Building Libint2 5-4-3-6-5-4 instead.; ```; in the cmake step and; ```; [ 10%] Performing download step (download, verify and extract) for 'libint2_external'; [ 12%] Performing download step (download, verify and extract) for 'pybind11_external'; -- Downloading...; dst='/scr/behnle/psi4_clean_cmake_3.19/psi4/objdir/external/upstream/libint2/libint2_external-prefix/src/Libint2-export-5-4-3-6-5-4_mm4f12ob2.tgz'; timeout='none'; inactivity timeout='none'; -- Using src='https://github.com/loriab/libint/releases/download/v0.1/Libint2-export-5-4-3-6-5-4_mm4f12ob2.tgz'; -- Downloading...; ``` ; in the make step. @loriab Thanks for the quick reply, i will try and report back.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2572#issuecomment-1121208944
https://github.com/psi4/psi4/issues/2572#issuecomment-1121208944:372,Availability,down,download,372,"@JonathonMisiewicz I'm not using conda at all, as described above, i started from a clean directory, cloned the source, ran cmake and make. The libint is the one that is automatically downloaded if no libint was found:; ```; -- Suitable Libint2 could not be located, Building Libint2 5-4-3-6-5-4 instead.; ```; in the cmake step and; ```; [ 10%] Performing download step (download, verify and extract) for 'libint2_external'; [ 12%] Performing download step (download, verify and extract) for 'pybind11_external'; -- Downloading...; dst='/scr/behnle/psi4_clean_cmake_3.19/psi4/objdir/external/upstream/libint2/libint2_external-prefix/src/Libint2-export-5-4-3-6-5-4_mm4f12ob2.tgz'; timeout='none'; inactivity timeout='none'; -- Using src='https://github.com/loriab/libint/releases/download/v0.1/Libint2-export-5-4-3-6-5-4_mm4f12ob2.tgz'; -- Downloading...; ``` ; in the make step. @loriab Thanks for the quick reply, i will try and report back.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2572#issuecomment-1121208944
https://github.com/psi4/psi4/issues/2572#issuecomment-1121208944:444,Availability,down,download,444,"@JonathonMisiewicz I'm not using conda at all, as described above, i started from a clean directory, cloned the source, ran cmake and make. The libint is the one that is automatically downloaded if no libint was found:; ```; -- Suitable Libint2 could not be located, Building Libint2 5-4-3-6-5-4 instead.; ```; in the cmake step and; ```; [ 10%] Performing download step (download, verify and extract) for 'libint2_external'; [ 12%] Performing download step (download, verify and extract) for 'pybind11_external'; -- Downloading...; dst='/scr/behnle/psi4_clean_cmake_3.19/psi4/objdir/external/upstream/libint2/libint2_external-prefix/src/Libint2-export-5-4-3-6-5-4_mm4f12ob2.tgz'; timeout='none'; inactivity timeout='none'; -- Using src='https://github.com/loriab/libint/releases/download/v0.1/Libint2-export-5-4-3-6-5-4_mm4f12ob2.tgz'; -- Downloading...; ``` ; in the make step. @loriab Thanks for the quick reply, i will try and report back.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2572#issuecomment-1121208944
https://github.com/psi4/psi4/issues/2572#issuecomment-1121208944:459,Availability,down,download,459,"@JonathonMisiewicz I'm not using conda at all, as described above, i started from a clean directory, cloned the source, ran cmake and make. The libint is the one that is automatically downloaded if no libint was found:; ```; -- Suitable Libint2 could not be located, Building Libint2 5-4-3-6-5-4 instead.; ```; in the cmake step and; ```; [ 10%] Performing download step (download, verify and extract) for 'libint2_external'; [ 12%] Performing download step (download, verify and extract) for 'pybind11_external'; -- Downloading...; dst='/scr/behnle/psi4_clean_cmake_3.19/psi4/objdir/external/upstream/libint2/libint2_external-prefix/src/Libint2-export-5-4-3-6-5-4_mm4f12ob2.tgz'; timeout='none'; inactivity timeout='none'; -- Using src='https://github.com/loriab/libint/releases/download/v0.1/Libint2-export-5-4-3-6-5-4_mm4f12ob2.tgz'; -- Downloading...; ``` ; in the make step. @loriab Thanks for the quick reply, i will try and report back.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2572#issuecomment-1121208944
https://github.com/psi4/psi4/issues/2572#issuecomment-1121208944:517,Availability,Down,Downloading,517,"@JonathonMisiewicz I'm not using conda at all, as described above, i started from a clean directory, cloned the source, ran cmake and make. The libint is the one that is automatically downloaded if no libint was found:; ```; -- Suitable Libint2 could not be located, Building Libint2 5-4-3-6-5-4 instead.; ```; in the cmake step and; ```; [ 10%] Performing download step (download, verify and extract) for 'libint2_external'; [ 12%] Performing download step (download, verify and extract) for 'pybind11_external'; -- Downloading...; dst='/scr/behnle/psi4_clean_cmake_3.19/psi4/objdir/external/upstream/libint2/libint2_external-prefix/src/Libint2-export-5-4-3-6-5-4_mm4f12ob2.tgz'; timeout='none'; inactivity timeout='none'; -- Using src='https://github.com/loriab/libint/releases/download/v0.1/Libint2-export-5-4-3-6-5-4_mm4f12ob2.tgz'; -- Downloading...; ``` ; in the make step. @loriab Thanks for the quick reply, i will try and report back.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2572#issuecomment-1121208944
https://github.com/psi4/psi4/issues/2572#issuecomment-1121208944:780,Availability,down,download,780,"@JonathonMisiewicz I'm not using conda at all, as described above, i started from a clean directory, cloned the source, ran cmake and make. The libint is the one that is automatically downloaded if no libint was found:; ```; -- Suitable Libint2 could not be located, Building Libint2 5-4-3-6-5-4 instead.; ```; in the cmake step and; ```; [ 10%] Performing download step (download, verify and extract) for 'libint2_external'; [ 12%] Performing download step (download, verify and extract) for 'pybind11_external'; -- Downloading...; dst='/scr/behnle/psi4_clean_cmake_3.19/psi4/objdir/external/upstream/libint2/libint2_external-prefix/src/Libint2-export-5-4-3-6-5-4_mm4f12ob2.tgz'; timeout='none'; inactivity timeout='none'; -- Using src='https://github.com/loriab/libint/releases/download/v0.1/Libint2-export-5-4-3-6-5-4_mm4f12ob2.tgz'; -- Downloading...; ``` ; in the make step. @loriab Thanks for the quick reply, i will try and report back.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2572#issuecomment-1121208944
https://github.com/psi4/psi4/issues/2572#issuecomment-1121208944:840,Availability,Down,Downloading,840,"@JonathonMisiewicz I'm not using conda at all, as described above, i started from a clean directory, cloned the source, ran cmake and make. The libint is the one that is automatically downloaded if no libint was found:; ```; -- Suitable Libint2 could not be located, Building Libint2 5-4-3-6-5-4 instead.; ```; in the cmake step and; ```; [ 10%] Performing download step (download, verify and extract) for 'libint2_external'; [ 12%] Performing download step (download, verify and extract) for 'pybind11_external'; -- Downloading...; dst='/scr/behnle/psi4_clean_cmake_3.19/psi4/objdir/external/upstream/libint2/libint2_external-prefix/src/Libint2-export-5-4-3-6-5-4_mm4f12ob2.tgz'; timeout='none'; inactivity timeout='none'; -- Using src='https://github.com/loriab/libint/releases/download/v0.1/Libint2-export-5-4-3-6-5-4_mm4f12ob2.tgz'; -- Downloading...; ``` ; in the make step. @loriab Thanks for the quick reply, i will try and report back.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2572#issuecomment-1121208944
https://github.com/psi4/psi4/issues/2572#issuecomment-1121208944:771,Deployability,release,releases,771,"@JonathonMisiewicz I'm not using conda at all, as described above, i started from a clean directory, cloned the source, ran cmake and make. The libint is the one that is automatically downloaded if no libint was found:; ```; -- Suitable Libint2 could not be located, Building Libint2 5-4-3-6-5-4 instead.; ```; in the cmake step and; ```; [ 10%] Performing download step (download, verify and extract) for 'libint2_external'; [ 12%] Performing download step (download, verify and extract) for 'pybind11_external'; -- Downloading...; dst='/scr/behnle/psi4_clean_cmake_3.19/psi4/objdir/external/upstream/libint2/libint2_external-prefix/src/Libint2-export-5-4-3-6-5-4_mm4f12ob2.tgz'; timeout='none'; inactivity timeout='none'; -- Using src='https://github.com/loriab/libint/releases/download/v0.1/Libint2-export-5-4-3-6-5-4_mm4f12ob2.tgz'; -- Downloading...; ``` ; in the make step. @loriab Thanks for the quick reply, i will try and report back.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2572#issuecomment-1121208944
https://github.com/psi4/psi4/issues/2572#issuecomment-1121208944:346,Performance,Perform,Performing,346,"@JonathonMisiewicz I'm not using conda at all, as described above, i started from a clean directory, cloned the source, ran cmake and make. The libint is the one that is automatically downloaded if no libint was found:; ```; -- Suitable Libint2 could not be located, Building Libint2 5-4-3-6-5-4 instead.; ```; in the cmake step and; ```; [ 10%] Performing download step (download, verify and extract) for 'libint2_external'; [ 12%] Performing download step (download, verify and extract) for 'pybind11_external'; -- Downloading...; dst='/scr/behnle/psi4_clean_cmake_3.19/psi4/objdir/external/upstream/libint2/libint2_external-prefix/src/Libint2-export-5-4-3-6-5-4_mm4f12ob2.tgz'; timeout='none'; inactivity timeout='none'; -- Using src='https://github.com/loriab/libint/releases/download/v0.1/Libint2-export-5-4-3-6-5-4_mm4f12ob2.tgz'; -- Downloading...; ``` ; in the make step. @loriab Thanks for the quick reply, i will try and report back.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2572#issuecomment-1121208944
https://github.com/psi4/psi4/issues/2572#issuecomment-1121208944:433,Performance,Perform,Performing,433,"@JonathonMisiewicz I'm not using conda at all, as described above, i started from a clean directory, cloned the source, ran cmake and make. The libint is the one that is automatically downloaded if no libint was found:; ```; -- Suitable Libint2 could not be located, Building Libint2 5-4-3-6-5-4 instead.; ```; in the cmake step and; ```; [ 10%] Performing download step (download, verify and extract) for 'libint2_external'; [ 12%] Performing download step (download, verify and extract) for 'pybind11_external'; -- Downloading...; dst='/scr/behnle/psi4_clean_cmake_3.19/psi4/objdir/external/upstream/libint2/libint2_external-prefix/src/Libint2-export-5-4-3-6-5-4_mm4f12ob2.tgz'; timeout='none'; inactivity timeout='none'; -- Using src='https://github.com/loriab/libint/releases/download/v0.1/Libint2-export-5-4-3-6-5-4_mm4f12ob2.tgz'; -- Downloading...; ``` ; in the make step. @loriab Thanks for the quick reply, i will try and report back.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2572#issuecomment-1121208944
https://github.com/psi4/psi4/issues/2572#issuecomment-1121208944:681,Safety,timeout,timeout,681,"@JonathonMisiewicz I'm not using conda at all, as described above, i started from a clean directory, cloned the source, ran cmake and make. The libint is the one that is automatically downloaded if no libint was found:; ```; -- Suitable Libint2 could not be located, Building Libint2 5-4-3-6-5-4 instead.; ```; in the cmake step and; ```; [ 10%] Performing download step (download, verify and extract) for 'libint2_external'; [ 12%] Performing download step (download, verify and extract) for 'pybind11_external'; -- Downloading...; dst='/scr/behnle/psi4_clean_cmake_3.19/psi4/objdir/external/upstream/libint2/libint2_external-prefix/src/Libint2-export-5-4-3-6-5-4_mm4f12ob2.tgz'; timeout='none'; inactivity timeout='none'; -- Using src='https://github.com/loriab/libint/releases/download/v0.1/Libint2-export-5-4-3-6-5-4_mm4f12ob2.tgz'; -- Downloading...; ``` ; in the make step. @loriab Thanks for the quick reply, i will try and report back.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2572#issuecomment-1121208944
https://github.com/psi4/psi4/issues/2572#issuecomment-1121208944:708,Safety,timeout,timeout,708,"@JonathonMisiewicz I'm not using conda at all, as described above, i started from a clean directory, cloned the source, ran cmake and make. The libint is the one that is automatically downloaded if no libint was found:; ```; -- Suitable Libint2 could not be located, Building Libint2 5-4-3-6-5-4 instead.; ```; in the cmake step and; ```; [ 10%] Performing download step (download, verify and extract) for 'libint2_external'; [ 12%] Performing download step (download, verify and extract) for 'pybind11_external'; -- Downloading...; dst='/scr/behnle/psi4_clean_cmake_3.19/psi4/objdir/external/upstream/libint2/libint2_external-prefix/src/Libint2-export-5-4-3-6-5-4_mm4f12ob2.tgz'; timeout='none'; inactivity timeout='none'; -- Using src='https://github.com/loriab/libint/releases/download/v0.1/Libint2-export-5-4-3-6-5-4_mm4f12ob2.tgz'; -- Downloading...; ``` ; in the make step. @loriab Thanks for the quick reply, i will try and report back.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2572#issuecomment-1121208944
https://github.com/psi4/psi4/issues/2572#issuecomment-1121326370:1602,Availability,error,error,1602,"@loriab No success, unfortunately. The option is recognized (initial cmake); ```; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Building using CMake 3.19.4 Generator Unix Makefiles; -- Setting option BUILD_SHARED_LIBS: ON <=================; -- Setting (unspecified) option ENABLE_OPENMP: ON; -- Setting (unspecified) option ENABLE_AUTO_BLAS: ON; -- Setting (unspecified) option ENABLE_AUTO_LAPACK: ON; ```; but somehow does not get passed to the libint2 build step (make):; ```; [ 73%] No update step for 'libint2_external'; [ 75%] No patch step for 'libint2_external'; [ 77%] Performing configure step for 'libint2_external'; loading initial cache file /scr/behnle/psi4_clean_cmake_3.19/psi4/objdir/external/upstream/libint2/libint2_external-prefix/tmp/libint2_external-cache-Release.cmake; -- Version: Full 2.7.1 Numeric 2.7.1; -- SO Version: Full 2:3:0 Major 2; -- The CXX compiler identification is GNU 11.2.1; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Check for working CXX compiler: /usr/bin/g++-11 - skipped; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Setting option CMAKE_BUILD_TYPE: Release; -- Setting option REQUIRE_CXX_API: ON; -- Setting option REQUIRE_CXX_API_COMPILED: OFF; -- Setting option ENABLE_FORTRAN: OFF; -- Setting (unspecified) option ENABLE_MPFR: OFF; -- Setting option BUILD_SHARED_LIBS: OFF <==================; -- Setting (unspecified) option LIBINT2_BUILD_SHARED_AND_STATIC_LIBS: OFF; -- Setting (unspecified) option LIBINT_LOCAL_Eigen3_INSTALL: OFF; ```. The error message is exactly the same.; I wiped the build directory completely in between, so there were no leftovers that might have influenced the build process.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2572#issuecomment-1121326370
https://github.com/psi4/psi4/issues/2572#issuecomment-1121326370:524,Deployability,update,update,524,"@loriab No success, unfortunately. The option is recognized (initial cmake); ```; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Building using CMake 3.19.4 Generator Unix Makefiles; -- Setting option BUILD_SHARED_LIBS: ON <=================; -- Setting (unspecified) option ENABLE_OPENMP: ON; -- Setting (unspecified) option ENABLE_AUTO_BLAS: ON; -- Setting (unspecified) option ENABLE_AUTO_LAPACK: ON; ```; but somehow does not get passed to the libint2 build step (make):; ```; [ 73%] No update step for 'libint2_external'; [ 75%] No patch step for 'libint2_external'; [ 77%] Performing configure step for 'libint2_external'; loading initial cache file /scr/behnle/psi4_clean_cmake_3.19/psi4/objdir/external/upstream/libint2/libint2_external-prefix/tmp/libint2_external-cache-Release.cmake; -- Version: Full 2.7.1 Numeric 2.7.1; -- SO Version: Full 2:3:0 Major 2; -- The CXX compiler identification is GNU 11.2.1; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Check for working CXX compiler: /usr/bin/g++-11 - skipped; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Setting option CMAKE_BUILD_TYPE: Release; -- Setting option REQUIRE_CXX_API: ON; -- Setting option REQUIRE_CXX_API_COMPILED: OFF; -- Setting option ENABLE_FORTRAN: OFF; -- Setting (unspecified) option ENABLE_MPFR: OFF; -- Setting option BUILD_SHARED_LIBS: OFF <==================; -- Setting (unspecified) option LIBINT2_BUILD_SHARED_AND_STATIC_LIBS: OFF; -- Setting (unspecified) option LIBINT_LOCAL_Eigen3_INSTALL: OFF; ```. The error message is exactly the same.; I wiped the build directory completely in between, so there were no leftovers that might have influenced the build process.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2572#issuecomment-1121326370
https://github.com/psi4/psi4/issues/2572#issuecomment-1121326370:570,Deployability,patch,patch,570,"@loriab No success, unfortunately. The option is recognized (initial cmake); ```; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Building using CMake 3.19.4 Generator Unix Makefiles; -- Setting option BUILD_SHARED_LIBS: ON <=================; -- Setting (unspecified) option ENABLE_OPENMP: ON; -- Setting (unspecified) option ENABLE_AUTO_BLAS: ON; -- Setting (unspecified) option ENABLE_AUTO_LAPACK: ON; ```; but somehow does not get passed to the libint2 build step (make):; ```; [ 73%] No update step for 'libint2_external'; [ 75%] No patch step for 'libint2_external'; [ 77%] Performing configure step for 'libint2_external'; loading initial cache file /scr/behnle/psi4_clean_cmake_3.19/psi4/objdir/external/upstream/libint2/libint2_external-prefix/tmp/libint2_external-cache-Release.cmake; -- Version: Full 2.7.1 Numeric 2.7.1; -- SO Version: Full 2:3:0 Major 2; -- The CXX compiler identification is GNU 11.2.1; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Check for working CXX compiler: /usr/bin/g++-11 - skipped; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Setting option CMAKE_BUILD_TYPE: Release; -- Setting option REQUIRE_CXX_API: ON; -- Setting option REQUIRE_CXX_API_COMPILED: OFF; -- Setting option ENABLE_FORTRAN: OFF; -- Setting (unspecified) option ENABLE_MPFR: OFF; -- Setting option BUILD_SHARED_LIBS: OFF <==================; -- Setting (unspecified) option LIBINT2_BUILD_SHARED_AND_STATIC_LIBS: OFF; -- Setting (unspecified) option LIBINT_LOCAL_Eigen3_INSTALL: OFF; ```. The error message is exactly the same.; I wiped the build directory completely in between, so there were no leftovers that might have influenced the build process.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2572#issuecomment-1121326370
https://github.com/psi4/psi4/issues/2572#issuecomment-1121326370:812,Deployability,Release,Release,812,"@loriab No success, unfortunately. The option is recognized (initial cmake); ```; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Building using CMake 3.19.4 Generator Unix Makefiles; -- Setting option BUILD_SHARED_LIBS: ON <=================; -- Setting (unspecified) option ENABLE_OPENMP: ON; -- Setting (unspecified) option ENABLE_AUTO_BLAS: ON; -- Setting (unspecified) option ENABLE_AUTO_LAPACK: ON; ```; but somehow does not get passed to the libint2 build step (make):; ```; [ 73%] No update step for 'libint2_external'; [ 75%] No patch step for 'libint2_external'; [ 77%] Performing configure step for 'libint2_external'; loading initial cache file /scr/behnle/psi4_clean_cmake_3.19/psi4/objdir/external/upstream/libint2/libint2_external-prefix/tmp/libint2_external-cache-Release.cmake; -- Version: Full 2.7.1 Numeric 2.7.1; -- SO Version: Full 2:3:0 Major 2; -- The CXX compiler identification is GNU 11.2.1; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Check for working CXX compiler: /usr/bin/g++-11 - skipped; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Setting option CMAKE_BUILD_TYPE: Release; -- Setting option REQUIRE_CXX_API: ON; -- Setting option REQUIRE_CXX_API_COMPILED: OFF; -- Setting option ENABLE_FORTRAN: OFF; -- Setting (unspecified) option ENABLE_MPFR: OFF; -- Setting option BUILD_SHARED_LIBS: OFF <==================; -- Setting (unspecified) option LIBINT2_BUILD_SHARED_AND_STATIC_LIBS: OFF; -- Setting (unspecified) option LIBINT_LOCAL_Eigen3_INSTALL: OFF; ```. The error message is exactly the same.; I wiped the build directory completely in between, so there were no leftovers that might have influenced the build process.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2572#issuecomment-1121326370
https://github.com/psi4/psi4/issues/2572#issuecomment-1121326370:1204,Deployability,Release,Release,1204,"@loriab No success, unfortunately. The option is recognized (initial cmake); ```; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Building using CMake 3.19.4 Generator Unix Makefiles; -- Setting option BUILD_SHARED_LIBS: ON <=================; -- Setting (unspecified) option ENABLE_OPENMP: ON; -- Setting (unspecified) option ENABLE_AUTO_BLAS: ON; -- Setting (unspecified) option ENABLE_AUTO_LAPACK: ON; ```; but somehow does not get passed to the libint2 build step (make):; ```; [ 73%] No update step for 'libint2_external'; [ 75%] No patch step for 'libint2_external'; [ 77%] Performing configure step for 'libint2_external'; loading initial cache file /scr/behnle/psi4_clean_cmake_3.19/psi4/objdir/external/upstream/libint2/libint2_external-prefix/tmp/libint2_external-cache-Release.cmake; -- Version: Full 2.7.1 Numeric 2.7.1; -- SO Version: Full 2:3:0 Major 2; -- The CXX compiler identification is GNU 11.2.1; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Check for working CXX compiler: /usr/bin/g++-11 - skipped; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Setting option CMAKE_BUILD_TYPE: Release; -- Setting option REQUIRE_CXX_API: ON; -- Setting option REQUIRE_CXX_API_COMPILED: OFF; -- Setting option ENABLE_FORTRAN: OFF; -- Setting (unspecified) option ENABLE_MPFR: OFF; -- Setting option BUILD_SHARED_LIBS: OFF <==================; -- Setting (unspecified) option LIBINT2_BUILD_SHARED_AND_STATIC_LIBS: OFF; -- Setting (unspecified) option LIBINT_LOCAL_Eigen3_INSTALL: OFF; ```. The error message is exactly the same.; I wiped the build directory completely in between, so there were no leftovers that might have influenced the build process.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2572#issuecomment-1121326370
https://github.com/psi4/psi4/issues/2572#issuecomment-1121326370:1608,Integrability,message,message,1608,"@loriab No success, unfortunately. The option is recognized (initial cmake); ```; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Building using CMake 3.19.4 Generator Unix Makefiles; -- Setting option BUILD_SHARED_LIBS: ON <=================; -- Setting (unspecified) option ENABLE_OPENMP: ON; -- Setting (unspecified) option ENABLE_AUTO_BLAS: ON; -- Setting (unspecified) option ENABLE_AUTO_LAPACK: ON; ```; but somehow does not get passed to the libint2 build step (make):; ```; [ 73%] No update step for 'libint2_external'; [ 75%] No patch step for 'libint2_external'; [ 77%] Performing configure step for 'libint2_external'; loading initial cache file /scr/behnle/psi4_clean_cmake_3.19/psi4/objdir/external/upstream/libint2/libint2_external-prefix/tmp/libint2_external-cache-Release.cmake; -- Version: Full 2.7.1 Numeric 2.7.1; -- SO Version: Full 2:3:0 Major 2; -- The CXX compiler identification is GNU 11.2.1; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Check for working CXX compiler: /usr/bin/g++-11 - skipped; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Setting option CMAKE_BUILD_TYPE: Release; -- Setting option REQUIRE_CXX_API: ON; -- Setting option REQUIRE_CXX_API_COMPILED: OFF; -- Setting option ENABLE_FORTRAN: OFF; -- Setting (unspecified) option ENABLE_MPFR: OFF; -- Setting option BUILD_SHARED_LIBS: OFF <==================; -- Setting (unspecified) option LIBINT2_BUILD_SHARED_AND_STATIC_LIBS: OFF; -- Setting (unspecified) option LIBINT_LOCAL_Eigen3_INSTALL: OFF; ```. The error message is exactly the same.; I wiped the build directory completely in between, so there were no leftovers that might have influenced the build process.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2572#issuecomment-1121326370
https://github.com/psi4/psi4/issues/2572#issuecomment-1121326370:623,Modifiability,config,configure,623,"@loriab No success, unfortunately. The option is recognized (initial cmake); ```; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Building using CMake 3.19.4 Generator Unix Makefiles; -- Setting option BUILD_SHARED_LIBS: ON <=================; -- Setting (unspecified) option ENABLE_OPENMP: ON; -- Setting (unspecified) option ENABLE_AUTO_BLAS: ON; -- Setting (unspecified) option ENABLE_AUTO_LAPACK: ON; ```; but somehow does not get passed to the libint2 build step (make):; ```; [ 73%] No update step for 'libint2_external'; [ 75%] No patch step for 'libint2_external'; [ 77%] Performing configure step for 'libint2_external'; loading initial cache file /scr/behnle/psi4_clean_cmake_3.19/psi4/objdir/external/upstream/libint2/libint2_external-prefix/tmp/libint2_external-cache-Release.cmake; -- Version: Full 2.7.1 Numeric 2.7.1; -- SO Version: Full 2:3:0 Major 2; -- The CXX compiler identification is GNU 11.2.1; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Check for working CXX compiler: /usr/bin/g++-11 - skipped; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Setting option CMAKE_BUILD_TYPE: Release; -- Setting option REQUIRE_CXX_API: ON; -- Setting option REQUIRE_CXX_API_COMPILED: OFF; -- Setting option ENABLE_FORTRAN: OFF; -- Setting (unspecified) option ENABLE_MPFR: OFF; -- Setting option BUILD_SHARED_LIBS: OFF <==================; -- Setting (unspecified) option LIBINT2_BUILD_SHARED_AND_STATIC_LIBS: OFF; -- Setting (unspecified) option LIBINT_LOCAL_Eigen3_INSTALL: OFF; ```. The error message is exactly the same.; I wiped the build directory completely in between, so there were no leftovers that might have influenced the build process.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2572#issuecomment-1121326370
https://github.com/psi4/psi4/issues/2572#issuecomment-1121326370:612,Performance,Perform,Performing,612,"@loriab No success, unfortunately. The option is recognized (initial cmake); ```; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Building using CMake 3.19.4 Generator Unix Makefiles; -- Setting option BUILD_SHARED_LIBS: ON <=================; -- Setting (unspecified) option ENABLE_OPENMP: ON; -- Setting (unspecified) option ENABLE_AUTO_BLAS: ON; -- Setting (unspecified) option ENABLE_AUTO_LAPACK: ON; ```; but somehow does not get passed to the libint2 build step (make):; ```; [ 73%] No update step for 'libint2_external'; [ 75%] No patch step for 'libint2_external'; [ 77%] Performing configure step for 'libint2_external'; loading initial cache file /scr/behnle/psi4_clean_cmake_3.19/psi4/objdir/external/upstream/libint2/libint2_external-prefix/tmp/libint2_external-cache-Release.cmake; -- Version: Full 2.7.1 Numeric 2.7.1; -- SO Version: Full 2:3:0 Major 2; -- The CXX compiler identification is GNU 11.2.1; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Check for working CXX compiler: /usr/bin/g++-11 - skipped; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Setting option CMAKE_BUILD_TYPE: Release; -- Setting option REQUIRE_CXX_API: ON; -- Setting option REQUIRE_CXX_API_COMPILED: OFF; -- Setting option ENABLE_FORTRAN: OFF; -- Setting (unspecified) option ENABLE_MPFR: OFF; -- Setting option BUILD_SHARED_LIBS: OFF <==================; -- Setting (unspecified) option LIBINT2_BUILD_SHARED_AND_STATIC_LIBS: OFF; -- Setting (unspecified) option LIBINT_LOCAL_Eigen3_INSTALL: OFF; ```. The error message is exactly the same.; I wiped the build directory completely in between, so there were no leftovers that might have influenced the build process.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2572#issuecomment-1121326370
https://github.com/psi4/psi4/issues/2572#issuecomment-1121326370:662,Performance,load,loading,662,"@loriab No success, unfortunately. The option is recognized (initial cmake); ```; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Building using CMake 3.19.4 Generator Unix Makefiles; -- Setting option BUILD_SHARED_LIBS: ON <=================; -- Setting (unspecified) option ENABLE_OPENMP: ON; -- Setting (unspecified) option ENABLE_AUTO_BLAS: ON; -- Setting (unspecified) option ENABLE_AUTO_LAPACK: ON; ```; but somehow does not get passed to the libint2 build step (make):; ```; [ 73%] No update step for 'libint2_external'; [ 75%] No patch step for 'libint2_external'; [ 77%] Performing configure step for 'libint2_external'; loading initial cache file /scr/behnle/psi4_clean_cmake_3.19/psi4/objdir/external/upstream/libint2/libint2_external-prefix/tmp/libint2_external-cache-Release.cmake; -- Version: Full 2.7.1 Numeric 2.7.1; -- SO Version: Full 2:3:0 Major 2; -- The CXX compiler identification is GNU 11.2.1; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Check for working CXX compiler: /usr/bin/g++-11 - skipped; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Setting option CMAKE_BUILD_TYPE: Release; -- Setting option REQUIRE_CXX_API: ON; -- Setting option REQUIRE_CXX_API_COMPILED: OFF; -- Setting option ENABLE_FORTRAN: OFF; -- Setting (unspecified) option ENABLE_MPFR: OFF; -- Setting option BUILD_SHARED_LIBS: OFF <==================; -- Setting (unspecified) option LIBINT2_BUILD_SHARED_AND_STATIC_LIBS: OFF; -- Setting (unspecified) option LIBINT_LOCAL_Eigen3_INSTALL: OFF; ```. The error message is exactly the same.; I wiped the build directory completely in between, so there were no leftovers that might have influenced the build process.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2572#issuecomment-1121326370
https://github.com/psi4/psi4/issues/2572#issuecomment-1121326370:678,Performance,cache,cache,678,"@loriab No success, unfortunately. The option is recognized (initial cmake); ```; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Building using CMake 3.19.4 Generator Unix Makefiles; -- Setting option BUILD_SHARED_LIBS: ON <=================; -- Setting (unspecified) option ENABLE_OPENMP: ON; -- Setting (unspecified) option ENABLE_AUTO_BLAS: ON; -- Setting (unspecified) option ENABLE_AUTO_LAPACK: ON; ```; but somehow does not get passed to the libint2 build step (make):; ```; [ 73%] No update step for 'libint2_external'; [ 75%] No patch step for 'libint2_external'; [ 77%] Performing configure step for 'libint2_external'; loading initial cache file /scr/behnle/psi4_clean_cmake_3.19/psi4/objdir/external/upstream/libint2/libint2_external-prefix/tmp/libint2_external-cache-Release.cmake; -- Version: Full 2.7.1 Numeric 2.7.1; -- SO Version: Full 2:3:0 Major 2; -- The CXX compiler identification is GNU 11.2.1; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Check for working CXX compiler: /usr/bin/g++-11 - skipped; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Setting option CMAKE_BUILD_TYPE: Release; -- Setting option REQUIRE_CXX_API: ON; -- Setting option REQUIRE_CXX_API_COMPILED: OFF; -- Setting option ENABLE_FORTRAN: OFF; -- Setting (unspecified) option ENABLE_MPFR: OFF; -- Setting option BUILD_SHARED_LIBS: OFF <==================; -- Setting (unspecified) option LIBINT2_BUILD_SHARED_AND_STATIC_LIBS: OFF; -- Setting (unspecified) option LIBINT_LOCAL_Eigen3_INSTALL: OFF; ```. The error message is exactly the same.; I wiped the build directory completely in between, so there were no leftovers that might have influenced the build process.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2572#issuecomment-1121326370
https://github.com/psi4/psi4/issues/2572#issuecomment-1121326370:806,Performance,cache,cache-Release,806,"@loriab No success, unfortunately. The option is recognized (initial cmake); ```; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Building using CMake 3.19.4 Generator Unix Makefiles; -- Setting option BUILD_SHARED_LIBS: ON <=================; -- Setting (unspecified) option ENABLE_OPENMP: ON; -- Setting (unspecified) option ENABLE_AUTO_BLAS: ON; -- Setting (unspecified) option ENABLE_AUTO_LAPACK: ON; ```; but somehow does not get passed to the libint2 build step (make):; ```; [ 73%] No update step for 'libint2_external'; [ 75%] No patch step for 'libint2_external'; [ 77%] Performing configure step for 'libint2_external'; loading initial cache file /scr/behnle/psi4_clean_cmake_3.19/psi4/objdir/external/upstream/libint2/libint2_external-prefix/tmp/libint2_external-cache-Release.cmake; -- Version: Full 2.7.1 Numeric 2.7.1; -- SO Version: Full 2:3:0 Major 2; -- The CXX compiler identification is GNU 11.2.1; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Check for working CXX compiler: /usr/bin/g++-11 - skipped; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Setting option CMAKE_BUILD_TYPE: Release; -- Setting option REQUIRE_CXX_API: ON; -- Setting option REQUIRE_CXX_API_COMPILED: OFF; -- Setting option ENABLE_FORTRAN: OFF; -- Setting (unspecified) option ENABLE_MPFR: OFF; -- Setting option BUILD_SHARED_LIBS: OFF <==================; -- Setting (unspecified) option LIBINT2_BUILD_SHARED_AND_STATIC_LIBS: OFF; -- Setting (unspecified) option LIBINT_LOCAL_Eigen3_INSTALL: OFF; ```. The error message is exactly the same.; I wiped the build directory completely in between, so there were no leftovers that might have influenced the build process.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2572#issuecomment-1121326370
https://github.com/psi4/psi4/issues/2572#issuecomment-1121326370:85,Safety,Detect,Detecting,85,"@loriab No success, unfortunately. The option is recognized (initial cmake); ```; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Building using CMake 3.19.4 Generator Unix Makefiles; -- Setting option BUILD_SHARED_LIBS: ON <=================; -- Setting (unspecified) option ENABLE_OPENMP: ON; -- Setting (unspecified) option ENABLE_AUTO_BLAS: ON; -- Setting (unspecified) option ENABLE_AUTO_LAPACK: ON; ```; but somehow does not get passed to the libint2 build step (make):; ```; [ 73%] No update step for 'libint2_external'; [ 75%] No patch step for 'libint2_external'; [ 77%] Performing configure step for 'libint2_external'; loading initial cache file /scr/behnle/psi4_clean_cmake_3.19/psi4/objdir/external/upstream/libint2/libint2_external-prefix/tmp/libint2_external-cache-Release.cmake; -- Version: Full 2.7.1 Numeric 2.7.1; -- SO Version: Full 2:3:0 Major 2; -- The CXX compiler identification is GNU 11.2.1; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Check for working CXX compiler: /usr/bin/g++-11 - skipped; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Setting option CMAKE_BUILD_TYPE: Release; -- Setting option REQUIRE_CXX_API: ON; -- Setting option REQUIRE_CXX_API_COMPILED: OFF; -- Setting option ENABLE_FORTRAN: OFF; -- Setting (unspecified) option ENABLE_MPFR: OFF; -- Setting option BUILD_SHARED_LIBS: OFF <==================; -- Setting (unspecified) option LIBINT2_BUILD_SHARED_AND_STATIC_LIBS: OFF; -- Setting (unspecified) option LIBINT_LOCAL_Eigen3_INSTALL: OFF; ```. The error message is exactly the same.; I wiped the build directory completely in between, so there were no leftovers that might have influenced the build process.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2572#issuecomment-1121326370
https://github.com/psi4/psi4/issues/2572#issuecomment-1121326370:120,Safety,Detect,Detecting,120,"@loriab No success, unfortunately. The option is recognized (initial cmake); ```; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Building using CMake 3.19.4 Generator Unix Makefiles; -- Setting option BUILD_SHARED_LIBS: ON <=================; -- Setting (unspecified) option ENABLE_OPENMP: ON; -- Setting (unspecified) option ENABLE_AUTO_BLAS: ON; -- Setting (unspecified) option ENABLE_AUTO_LAPACK: ON; ```; but somehow does not get passed to the libint2 build step (make):; ```; [ 73%] No update step for 'libint2_external'; [ 75%] No patch step for 'libint2_external'; [ 77%] Performing configure step for 'libint2_external'; loading initial cache file /scr/behnle/psi4_clean_cmake_3.19/psi4/objdir/external/upstream/libint2/libint2_external-prefix/tmp/libint2_external-cache-Release.cmake; -- Version: Full 2.7.1 Numeric 2.7.1; -- SO Version: Full 2:3:0 Major 2; -- The CXX compiler identification is GNU 11.2.1; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Check for working CXX compiler: /usr/bin/g++-11 - skipped; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Setting option CMAKE_BUILD_TYPE: Release; -- Setting option REQUIRE_CXX_API: ON; -- Setting option REQUIRE_CXX_API_COMPILED: OFF; -- Setting option ENABLE_FORTRAN: OFF; -- Setting (unspecified) option ENABLE_MPFR: OFF; -- Setting option BUILD_SHARED_LIBS: OFF <==================; -- Setting (unspecified) option LIBINT2_BUILD_SHARED_AND_STATIC_LIBS: OFF; -- Setting (unspecified) option LIBINT_LOCAL_Eigen3_INSTALL: OFF; ```. The error message is exactly the same.; I wiped the build directory completely in between, so there were no leftovers that might have influenced the build process.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2572#issuecomment-1121326370
https://github.com/psi4/psi4/issues/2572#issuecomment-1121326370:953,Safety,Detect,Detecting,953,"@loriab No success, unfortunately. The option is recognized (initial cmake); ```; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Building using CMake 3.19.4 Generator Unix Makefiles; -- Setting option BUILD_SHARED_LIBS: ON <=================; -- Setting (unspecified) option ENABLE_OPENMP: ON; -- Setting (unspecified) option ENABLE_AUTO_BLAS: ON; -- Setting (unspecified) option ENABLE_AUTO_LAPACK: ON; ```; but somehow does not get passed to the libint2 build step (make):; ```; [ 73%] No update step for 'libint2_external'; [ 75%] No patch step for 'libint2_external'; [ 77%] Performing configure step for 'libint2_external'; loading initial cache file /scr/behnle/psi4_clean_cmake_3.19/psi4/objdir/external/upstream/libint2/libint2_external-prefix/tmp/libint2_external-cache-Release.cmake; -- Version: Full 2.7.1 Numeric 2.7.1; -- SO Version: Full 2:3:0 Major 2; -- The CXX compiler identification is GNU 11.2.1; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Check for working CXX compiler: /usr/bin/g++-11 - skipped; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Setting option CMAKE_BUILD_TYPE: Release; -- Setting option REQUIRE_CXX_API: ON; -- Setting option REQUIRE_CXX_API_COMPILED: OFF; -- Setting option ENABLE_FORTRAN: OFF; -- Setting (unspecified) option ENABLE_MPFR: OFF; -- Setting option BUILD_SHARED_LIBS: OFF <==================; -- Setting (unspecified) option LIBINT2_BUILD_SHARED_AND_STATIC_LIBS: OFF; -- Setting (unspecified) option LIBINT_LOCAL_Eigen3_INSTALL: OFF; ```. The error message is exactly the same.; I wiped the build directory completely in between, so there were no leftovers that might have influenced the build process.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2572#issuecomment-1121326370
https://github.com/psi4/psi4/issues/2572#issuecomment-1121326370:989,Safety,Detect,Detecting,989,"@loriab No success, unfortunately. The option is recognized (initial cmake); ```; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Building using CMake 3.19.4 Generator Unix Makefiles; -- Setting option BUILD_SHARED_LIBS: ON <=================; -- Setting (unspecified) option ENABLE_OPENMP: ON; -- Setting (unspecified) option ENABLE_AUTO_BLAS: ON; -- Setting (unspecified) option ENABLE_AUTO_LAPACK: ON; ```; but somehow does not get passed to the libint2 build step (make):; ```; [ 73%] No update step for 'libint2_external'; [ 75%] No patch step for 'libint2_external'; [ 77%] Performing configure step for 'libint2_external'; loading initial cache file /scr/behnle/psi4_clean_cmake_3.19/psi4/objdir/external/upstream/libint2/libint2_external-prefix/tmp/libint2_external-cache-Release.cmake; -- Version: Full 2.7.1 Numeric 2.7.1; -- SO Version: Full 2:3:0 Major 2; -- The CXX compiler identification is GNU 11.2.1; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Check for working CXX compiler: /usr/bin/g++-11 - skipped; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Setting option CMAKE_BUILD_TYPE: Release; -- Setting option REQUIRE_CXX_API: ON; -- Setting option REQUIRE_CXX_API_COMPILED: OFF; -- Setting option ENABLE_FORTRAN: OFF; -- Setting (unspecified) option ENABLE_MPFR: OFF; -- Setting option BUILD_SHARED_LIBS: OFF <==================; -- Setting (unspecified) option LIBINT2_BUILD_SHARED_AND_STATIC_LIBS: OFF; -- Setting (unspecified) option LIBINT_LOCAL_Eigen3_INSTALL: OFF; ```. The error message is exactly the same.; I wiped the build directory completely in between, so there were no leftovers that might have influenced the build process.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2572#issuecomment-1121326370
https://github.com/psi4/psi4/issues/2572#issuecomment-1121326370:1094,Safety,Detect,Detecting,1094,"@loriab No success, unfortunately. The option is recognized (initial cmake); ```; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Building using CMake 3.19.4 Generator Unix Makefiles; -- Setting option BUILD_SHARED_LIBS: ON <=================; -- Setting (unspecified) option ENABLE_OPENMP: ON; -- Setting (unspecified) option ENABLE_AUTO_BLAS: ON; -- Setting (unspecified) option ENABLE_AUTO_LAPACK: ON; ```; but somehow does not get passed to the libint2 build step (make):; ```; [ 73%] No update step for 'libint2_external'; [ 75%] No patch step for 'libint2_external'; [ 77%] Performing configure step for 'libint2_external'; loading initial cache file /scr/behnle/psi4_clean_cmake_3.19/psi4/objdir/external/upstream/libint2/libint2_external-prefix/tmp/libint2_external-cache-Release.cmake; -- Version: Full 2.7.1 Numeric 2.7.1; -- SO Version: Full 2:3:0 Major 2; -- The CXX compiler identification is GNU 11.2.1; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Check for working CXX compiler: /usr/bin/g++-11 - skipped; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Setting option CMAKE_BUILD_TYPE: Release; -- Setting option REQUIRE_CXX_API: ON; -- Setting option REQUIRE_CXX_API_COMPILED: OFF; -- Setting option ENABLE_FORTRAN: OFF; -- Setting (unspecified) option ENABLE_MPFR: OFF; -- Setting option BUILD_SHARED_LIBS: OFF <==================; -- Setting (unspecified) option LIBINT2_BUILD_SHARED_AND_STATIC_LIBS: OFF; -- Setting (unspecified) option LIBINT_LOCAL_Eigen3_INSTALL: OFF; ```. The error message is exactly the same.; I wiped the build directory completely in between, so there were no leftovers that might have influenced the build process.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2572#issuecomment-1121326370
https://github.com/psi4/psi4/issues/2572#issuecomment-1121326370:1129,Safety,Detect,Detecting,1129,"@loriab No success, unfortunately. The option is recognized (initial cmake); ```; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Building using CMake 3.19.4 Generator Unix Makefiles; -- Setting option BUILD_SHARED_LIBS: ON <=================; -- Setting (unspecified) option ENABLE_OPENMP: ON; -- Setting (unspecified) option ENABLE_AUTO_BLAS: ON; -- Setting (unspecified) option ENABLE_AUTO_LAPACK: ON; ```; but somehow does not get passed to the libint2 build step (make):; ```; [ 73%] No update step for 'libint2_external'; [ 75%] No patch step for 'libint2_external'; [ 77%] Performing configure step for 'libint2_external'; loading initial cache file /scr/behnle/psi4_clean_cmake_3.19/psi4/objdir/external/upstream/libint2/libint2_external-prefix/tmp/libint2_external-cache-Release.cmake; -- Version: Full 2.7.1 Numeric 2.7.1; -- SO Version: Full 2:3:0 Major 2; -- The CXX compiler identification is GNU 11.2.1; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Check for working CXX compiler: /usr/bin/g++-11 - skipped; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Setting option CMAKE_BUILD_TYPE: Release; -- Setting option REQUIRE_CXX_API: ON; -- Setting option REQUIRE_CXX_API_COMPILED: OFF; -- Setting option ENABLE_FORTRAN: OFF; -- Setting (unspecified) option ENABLE_MPFR: OFF; -- Setting option BUILD_SHARED_LIBS: OFF <==================; -- Setting (unspecified) option LIBINT2_BUILD_SHARED_AND_STATIC_LIBS: OFF; -- Setting (unspecified) option LIBINT_LOCAL_Eigen3_INSTALL: OFF; ```. The error message is exactly the same.; I wiped the build directory completely in between, so there were no leftovers that might have influenced the build process.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2572#issuecomment-1121326370
https://github.com/psi4/psi4/issues/2572#issuecomment-1121341503:329,Testability,test,tested,329,"To my embarrassment, that makes perfect sense considering https://github.com/psi4/psi4/blob/master/external/upstream/libint2/CMakeLists.txt#L80-L81 . If you care to try again, switch the comment marker so the BUILD_SHARED_LIBS can pass through. None of this fixes why the static lib is giving you trouble at psi4 link time (I've tested static libs with Linux but use them rarely, so there's probably another position_independent_code property needed at L2); that'll need further investigation. I think I hard-coded the static build in external/libint2/CMakeLists.txt for generality since a dynamic L2 library _can't_ work for Windows.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2572#issuecomment-1121341503
https://github.com/psi4/psi4/issues/2572#issuecomment-1121402243:130,Testability,test,test,130,"@loriab Cheers, this seems to work! Thanks, i would have never found the culprit. At least it compiles and links, tomorrow i will test whether it runs :-). Edit: after some fiddling with runtest.py, also all included tests pass.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2572#issuecomment-1121402243
https://github.com/psi4/psi4/issues/2572#issuecomment-1121402243:217,Testability,test,tests,217,"@loriab Cheers, this seems to work! Thanks, i would have never found the culprit. At least it compiles and links, tomorrow i will test whether it runs :-). Edit: after some fiddling with runtest.py, also all included tests pass.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2572#issuecomment-1121402243
https://github.com/psi4/psi4/issues/2576#issuecomment-1540837654:188,Integrability,rout,routing,188,"Weirdly, cc44 was failing with `-n2` as expected a couple weeks ago, but today it runs just fine. Threads and low mem appear to be setting correctly. Possibly something with the extra SCF routing control or composite JK.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2576#issuecomment-1540837654
https://github.com/psi4/psi4/issues/2576#issuecomment-1540856066:302,Energy Efficiency,allocate,allocated,302,"Of the recent SCF PRs that may have had an impact on SAD and this bug, the relevant one would have been https://github.com/psi4/psi4/pull/2848, I think. In making that PR, I ran into a bug where the code would throw an exception with `SCF_TYPE=MEM_DF` + `SCF_SUBTYPE=INCORE`, even if enough memory was allocated to run in-core. The issue was that there is a point in DFHelper (the `get_core_size()` function) at which the SCF subalgorithm is determined via `AO_core()`, before the memory is actually allocated to the JK object. Some of the commits in https://github.com/psi4/psi4/pull/2848 (specifically, commits e8f8bdad573f43aaf1a1eca5871606b29a77ae50 and 3d3f138eb53e3ee4abe8b8c8d23ad6e457fa68ef) deal with fixing this bug. If it was the SCF PRs that fixed the cc44 bug, it is likely that range of commits in https://github.com/psi4/psi4/pull/2848.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2576#issuecomment-1540856066
https://github.com/psi4/psi4/issues/2576#issuecomment-1540856066:500,Energy Efficiency,allocate,allocated,500,"Of the recent SCF PRs that may have had an impact on SAD and this bug, the relevant one would have been https://github.com/psi4/psi4/pull/2848, I think. In making that PR, I ran into a bug where the code would throw an exception with `SCF_TYPE=MEM_DF` + `SCF_SUBTYPE=INCORE`, even if enough memory was allocated to run in-core. The issue was that there is a point in DFHelper (the `get_core_size()` function) at which the SCF subalgorithm is determined via `AO_core()`, before the memory is actually allocated to the JK object. Some of the commits in https://github.com/psi4/psi4/pull/2848 (specifically, commits e8f8bdad573f43aaf1a1eca5871606b29a77ae50 and 3d3f138eb53e3ee4abe8b8c8d23ad6e457fa68ef) deal with fixing this bug. If it was the SCF PRs that fixed the cc44 bug, it is likely that range of commits in https://github.com/psi4/psi4/pull/2848.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2576#issuecomment-1540856066
https://github.com/psi4/psi4/issues/2577#issuecomment-1125639718:158,Availability,error,error,158,"@TiborGY is right. Even though you've set ""uhf"", that switches to ""uks"" behind the scenes (so you're not having to set DFT in two places). When I release the error you hit, the further error shows: . ```. Printing out the relevant lines from the Psithon --> Python processed input file:; psi4.set_options({'reference': 'uks', 'stability_analysis': 'follow'}); mol = psi4.geometry(""""""; 0 1; O; """""");; --> psi4.energy('wB97M-D3BJ/def2-TZVPPD', molecule=mol). !-----------------------------------------------------------!; ! !; ! Stability analysis not yet supported for XC functionals. !; ! !; !-----------------------------------------------------------!; ```. Agree that the existing error looks contradictory. I've adjusted it to show:. ```; Printing out the relevant lines from the Psithon --> Python processed input file:; psi4.set_options({'reference': 'uhf', 'stability_analysis': 'follow'}); mol = psi4.geometry(""""""; 0 1; O; """""");; --> psi4.energy('wB97M-D3BJ/def2-TZVPPD', molecule=mol). !----------------------------------------------------------------------------------!; ! !; ! Stability analysis root following is only available for unrestricted Hartree-- !; ! Fock, not present UKS !; ! !; !----------------------------------------------------------------------------------!; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2577#issuecomment-1125639718
https://github.com/psi4/psi4/issues/2577#issuecomment-1125639718:185,Availability,error,error,185,"@TiborGY is right. Even though you've set ""uhf"", that switches to ""uks"" behind the scenes (so you're not having to set DFT in two places). When I release the error you hit, the further error shows: . ```. Printing out the relevant lines from the Psithon --> Python processed input file:; psi4.set_options({'reference': 'uks', 'stability_analysis': 'follow'}); mol = psi4.geometry(""""""; 0 1; O; """""");; --> psi4.energy('wB97M-D3BJ/def2-TZVPPD', molecule=mol). !-----------------------------------------------------------!; ! !; ! Stability analysis not yet supported for XC functionals. !; ! !; !-----------------------------------------------------------!; ```. Agree that the existing error looks contradictory. I've adjusted it to show:. ```; Printing out the relevant lines from the Psithon --> Python processed input file:; psi4.set_options({'reference': 'uhf', 'stability_analysis': 'follow'}); mol = psi4.geometry(""""""; 0 1; O; """""");; --> psi4.energy('wB97M-D3BJ/def2-TZVPPD', molecule=mol). !----------------------------------------------------------------------------------!; ! !; ! Stability analysis root following is only available for unrestricted Hartree-- !; ! Fock, not present UKS !; ! !; !----------------------------------------------------------------------------------!; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2577#issuecomment-1125639718
https://github.com/psi4/psi4/issues/2577#issuecomment-1125639718:684,Availability,error,error,684,"@TiborGY is right. Even though you've set ""uhf"", that switches to ""uks"" behind the scenes (so you're not having to set DFT in two places). When I release the error you hit, the further error shows: . ```. Printing out the relevant lines from the Psithon --> Python processed input file:; psi4.set_options({'reference': 'uks', 'stability_analysis': 'follow'}); mol = psi4.geometry(""""""; 0 1; O; """""");; --> psi4.energy('wB97M-D3BJ/def2-TZVPPD', molecule=mol). !-----------------------------------------------------------!; ! !; ! Stability analysis not yet supported for XC functionals. !; ! !; !-----------------------------------------------------------!; ```. Agree that the existing error looks contradictory. I've adjusted it to show:. ```; Printing out the relevant lines from the Psithon --> Python processed input file:; psi4.set_options({'reference': 'uhf', 'stability_analysis': 'follow'}); mol = psi4.geometry(""""""; 0 1; O; """""");; --> psi4.energy('wB97M-D3BJ/def2-TZVPPD', molecule=mol). !----------------------------------------------------------------------------------!; ! !; ! Stability analysis root following is only available for unrestricted Hartree-- !; ! Fock, not present UKS !; ! !; !----------------------------------------------------------------------------------!; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2577#issuecomment-1125639718
https://github.com/psi4/psi4/issues/2577#issuecomment-1125639718:1130,Availability,avail,available,1130,"@TiborGY is right. Even though you've set ""uhf"", that switches to ""uks"" behind the scenes (so you're not having to set DFT in two places). When I release the error you hit, the further error shows: . ```. Printing out the relevant lines from the Psithon --> Python processed input file:; psi4.set_options({'reference': 'uks', 'stability_analysis': 'follow'}); mol = psi4.geometry(""""""; 0 1; O; """""");; --> psi4.energy('wB97M-D3BJ/def2-TZVPPD', molecule=mol). !-----------------------------------------------------------!; ! !; ! Stability analysis not yet supported for XC functionals. !; ! !; !-----------------------------------------------------------!; ```. Agree that the existing error looks contradictory. I've adjusted it to show:. ```; Printing out the relevant lines from the Psithon --> Python processed input file:; psi4.set_options({'reference': 'uhf', 'stability_analysis': 'follow'}); mol = psi4.geometry(""""""; 0 1; O; """""");; --> psi4.energy('wB97M-D3BJ/def2-TZVPPD', molecule=mol). !----------------------------------------------------------------------------------!; ! !; ! Stability analysis root following is only available for unrestricted Hartree-- !; ! Fock, not present UKS !; ! !; !----------------------------------------------------------------------------------!; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2577#issuecomment-1125639718
https://github.com/psi4/psi4/issues/2577#issuecomment-1125639718:146,Deployability,release,release,146,"@TiborGY is right. Even though you've set ""uhf"", that switches to ""uks"" behind the scenes (so you're not having to set DFT in two places). When I release the error you hit, the further error shows: . ```. Printing out the relevant lines from the Psithon --> Python processed input file:; psi4.set_options({'reference': 'uks', 'stability_analysis': 'follow'}); mol = psi4.geometry(""""""; 0 1; O; """""");; --> psi4.energy('wB97M-D3BJ/def2-TZVPPD', molecule=mol). !-----------------------------------------------------------!; ! !; ! Stability analysis not yet supported for XC functionals. !; ! !; !-----------------------------------------------------------!; ```. Agree that the existing error looks contradictory. I've adjusted it to show:. ```; Printing out the relevant lines from the Psithon --> Python processed input file:; psi4.set_options({'reference': 'uhf', 'stability_analysis': 'follow'}); mol = psi4.geometry(""""""; 0 1; O; """""");; --> psi4.energy('wB97M-D3BJ/def2-TZVPPD', molecule=mol). !----------------------------------------------------------------------------------!; ! !; ! Stability analysis root following is only available for unrestricted Hartree-- !; ! Fock, not present UKS !; ! !; !----------------------------------------------------------------------------------!; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2577#issuecomment-1125639718
https://github.com/psi4/psi4/issues/2577#issuecomment-1125639718:409,Energy Efficiency,energy,energy,409,"@TiborGY is right. Even though you've set ""uhf"", that switches to ""uks"" behind the scenes (so you're not having to set DFT in two places). When I release the error you hit, the further error shows: . ```. Printing out the relevant lines from the Psithon --> Python processed input file:; psi4.set_options({'reference': 'uks', 'stability_analysis': 'follow'}); mol = psi4.geometry(""""""; 0 1; O; """""");; --> psi4.energy('wB97M-D3BJ/def2-TZVPPD', molecule=mol). !-----------------------------------------------------------!; ! !; ! Stability analysis not yet supported for XC functionals. !; ! !; !-----------------------------------------------------------!; ```. Agree that the existing error looks contradictory. I've adjusted it to show:. ```; Printing out the relevant lines from the Psithon --> Python processed input file:; psi4.set_options({'reference': 'uhf', 'stability_analysis': 'follow'}); mol = psi4.geometry(""""""; 0 1; O; """""");; --> psi4.energy('wB97M-D3BJ/def2-TZVPPD', molecule=mol). !----------------------------------------------------------------------------------!; ! !; ! Stability analysis root following is only available for unrestricted Hartree-- !; ! Fock, not present UKS !; ! !; !----------------------------------------------------------------------------------!; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2577#issuecomment-1125639718
https://github.com/psi4/psi4/issues/2577#issuecomment-1125639718:947,Energy Efficiency,energy,energy,947,"@TiborGY is right. Even though you've set ""uhf"", that switches to ""uks"" behind the scenes (so you're not having to set DFT in two places). When I release the error you hit, the further error shows: . ```. Printing out the relevant lines from the Psithon --> Python processed input file:; psi4.set_options({'reference': 'uks', 'stability_analysis': 'follow'}); mol = psi4.geometry(""""""; 0 1; O; """""");; --> psi4.energy('wB97M-D3BJ/def2-TZVPPD', molecule=mol). !-----------------------------------------------------------!; ! !; ! Stability analysis not yet supported for XC functionals. !; ! !; !-----------------------------------------------------------!; ```. Agree that the existing error looks contradictory. I've adjusted it to show:. ```; Printing out the relevant lines from the Psithon --> Python processed input file:; psi4.set_options({'reference': 'uhf', 'stability_analysis': 'follow'}); mol = psi4.geometry(""""""; 0 1; O; """""");; --> psi4.energy('wB97M-D3BJ/def2-TZVPPD', molecule=mol). !----------------------------------------------------------------------------------!; ! !; ! Stability analysis root following is only available for unrestricted Hartree-- !; ! Fock, not present UKS !; ! !; !----------------------------------------------------------------------------------!; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2577#issuecomment-1125639718
https://github.com/psi4/psi4/issues/2577#issuecomment-1126191477:43,Availability,error,error,43,Thanks for the clarification! Revising the error message should reduce confusion.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2577#issuecomment-1126191477
https://github.com/psi4/psi4/issues/2577#issuecomment-1126191477:64,Energy Efficiency,reduce,reduce,64,Thanks for the clarification! Revising the error message should reduce confusion.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2577#issuecomment-1126191477
https://github.com/psi4/psi4/issues/2577#issuecomment-1126191477:49,Integrability,message,message,49,Thanks for the clarification! Revising the error message should reduce confusion.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2577#issuecomment-1126191477
https://github.com/psi4/psi4/issues/2578#issuecomment-1125631043:211,Deployability,install,install,211,"""gg"" is ""gau2grid"" which is a required dependency. that's built in to the dep list (search for ""nofortran"" build and click the little ""i"") https://anaconda.org/psi4/psi4/files, so I don't know how mamba let you install that psi4 without gau2grid. I'm not quite sure what you're trying to solve. iirc, the ambertools issue was a libgfortran one, so ideally defaults and c-f would get back in sync. I can build a new nofortran build for you, but not for several days. Alternately, you can try a dual-environment setup keeping psi in a defaults-based env and keeping c-f based deps in a c-f-based env. There's a gha that models that at [github/workflows/ecosys](https://github.com/psi4/psi4/blob/master/.github/workflows/ecosystem.yml). If you continue with the nofortran build, be aware that in psi4 current master, py37 isn't supported, libint is now v2, and libxc is v5.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2578#issuecomment-1125631043
https://github.com/psi4/psi4/issues/2578#issuecomment-1125631043:39,Integrability,depend,dependency,39,"""gg"" is ""gau2grid"" which is a required dependency. that's built in to the dep list (search for ""nofortran"" build and click the little ""i"") https://anaconda.org/psi4/psi4/files, so I don't know how mamba let you install that psi4 without gau2grid. I'm not quite sure what you're trying to solve. iirc, the ambertools issue was a libgfortran one, so ideally defaults and c-f would get back in sync. I can build a new nofortran build for you, but not for several days. Alternately, you can try a dual-environment setup keeping psi in a defaults-based env and keeping c-f based deps in a c-f-based env. There's a gha that models that at [github/workflows/ecosys](https://github.com/psi4/psi4/blob/master/.github/workflows/ecosystem.yml). If you continue with the nofortran build, be aware that in psi4 current master, py37 isn't supported, libint is now v2, and libxc is v5.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2578#issuecomment-1125631043
https://github.com/psi4/psi4/issues/2578#issuecomment-1125640496:432,Availability,error,errors,432,"Thanks for the response. I will try out conda install again. . In the meantime, I want to explain why I turned to #2024. ; I encounter this issue while installing just normal psi4: (this is from mamba install); ```; package libgfortran4-7.5.0-h1a10cd1_23 has constraint libgfortran 4.0.0 *_23 conflicting with libgfortran-3.0.1-0; ```. How I get to this point: ; First I used `conda install psi4 -c psi4`, but it will throw me this errors. (nothing is conflicting?) So I turned to `mamba` to help me with the conflicts. ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: -; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```. This is what mamba got back to me if I installed the normal build. `mamba install psi4=1.5+e9f4d6d=py38ha809fef_0 -c psi4`. ```; package psi4-1.5+e9f4d6d-py38ha809fef_0 requires chemps2 >=1.8.10,<1.8.11.0a0, but none of the providers can be installed; ```. So then I tried to install `chemps2`, this can be installed normally. . Then I tried mamba to install psi4 again. . `mamba install psi4=1.5+e9f4d6d=py38ha809fef_0 -c psi4`. ```; package psi4-1.5+e9f4d6d-py38ha809fef_0 requires libgfortran >=3.0.1,<4.0.0.a0, but none of the providers can be installed; ```. Lastly, I tried to install libgfortran, but resulted in the above message. ; ```; package libgfortran4-7.5.0-h1a10cd1_23 has constraint libgfortran 4.0.0 *_23 conflicting with libgfortran-3.0.1-0; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2578#issuecomment-1125640496
https://github.com/psi4/psi4/issues/2578#issuecomment-1125640496:1192,Availability,Avail,Available,1192,"Thanks for the response. I will try out conda install again. . In the meantime, I want to explain why I turned to #2024. ; I encounter this issue while installing just normal psi4: (this is from mamba install); ```; package libgfortran4-7.5.0-h1a10cd1_23 has constraint libgfortran 4.0.0 *_23 conflicting with libgfortran-3.0.1-0; ```. How I get to this point: ; First I used `conda install psi4 -c psi4`, but it will throw me this errors. (nothing is conflicting?) So I turned to `mamba` to help me with the conflicts. ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: -; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```. This is what mamba got back to me if I installed the normal build. `mamba install psi4=1.5+e9f4d6d=py38ha809fef_0 -c psi4`. ```; package psi4-1.5+e9f4d6d-py38ha809fef_0 requires chemps2 >=1.8.10,<1.8.11.0a0, but none of the providers can be installed; ```. So then I tried to install `chemps2`, this can be installed normally. . Then I tried mamba to install psi4 again. . `mamba install psi4=1.5+e9f4d6d=py38ha809fef_0 -c psi4`. ```; package psi4-1.5+e9f4d6d-py38ha809fef_0 requires libgfortran >=3.0.1,<4.0.0.a0, but none of the providers can be installed; ```. Lastly, I tried to install libgfortran, but resulted in the above message. ; ```; package libgfortran4-7.5.0-h1a10cd1_23 has constraint libgfortran 4.0.0 *_23 conflicting with libgfortran-3.0.1-0; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2578#issuecomment-1125640496
https://github.com/psi4/psi4/issues/2578#issuecomment-1125640496:46,Deployability,install,install,46,"Thanks for the response. I will try out conda install again. . In the meantime, I want to explain why I turned to #2024. ; I encounter this issue while installing just normal psi4: (this is from mamba install); ```; package libgfortran4-7.5.0-h1a10cd1_23 has constraint libgfortran 4.0.0 *_23 conflicting with libgfortran-3.0.1-0; ```. How I get to this point: ; First I used `conda install psi4 -c psi4`, but it will throw me this errors. (nothing is conflicting?) So I turned to `mamba` to help me with the conflicts. ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: -; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```. This is what mamba got back to me if I installed the normal build. `mamba install psi4=1.5+e9f4d6d=py38ha809fef_0 -c psi4`. ```; package psi4-1.5+e9f4d6d-py38ha809fef_0 requires chemps2 >=1.8.10,<1.8.11.0a0, but none of the providers can be installed; ```. So then I tried to install `chemps2`, this can be installed normally. . Then I tried mamba to install psi4 again. . `mamba install psi4=1.5+e9f4d6d=py38ha809fef_0 -c psi4`. ```; package psi4-1.5+e9f4d6d-py38ha809fef_0 requires libgfortran >=3.0.1,<4.0.0.a0, but none of the providers can be installed; ```. Lastly, I tried to install libgfortran, but resulted in the above message. ; ```; package libgfortran4-7.5.0-h1a10cd1_23 has constraint libgfortran 4.0.0 *_23 conflicting with libgfortran-3.0.1-0; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2578#issuecomment-1125640496
https://github.com/psi4/psi4/issues/2578#issuecomment-1125640496:152,Deployability,install,installing,152,"Thanks for the response. I will try out conda install again. . In the meantime, I want to explain why I turned to #2024. ; I encounter this issue while installing just normal psi4: (this is from mamba install); ```; package libgfortran4-7.5.0-h1a10cd1_23 has constraint libgfortran 4.0.0 *_23 conflicting with libgfortran-3.0.1-0; ```. How I get to this point: ; First I used `conda install psi4 -c psi4`, but it will throw me this errors. (nothing is conflicting?) So I turned to `mamba` to help me with the conflicts. ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: -; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```. This is what mamba got back to me if I installed the normal build. `mamba install psi4=1.5+e9f4d6d=py38ha809fef_0 -c psi4`. ```; package psi4-1.5+e9f4d6d-py38ha809fef_0 requires chemps2 >=1.8.10,<1.8.11.0a0, but none of the providers can be installed; ```. So then I tried to install `chemps2`, this can be installed normally. . Then I tried mamba to install psi4 again. . `mamba install psi4=1.5+e9f4d6d=py38ha809fef_0 -c psi4`. ```; package psi4-1.5+e9f4d6d-py38ha809fef_0 requires libgfortran >=3.0.1,<4.0.0.a0, but none of the providers can be installed; ```. Lastly, I tried to install libgfortran, but resulted in the above message. ; ```; package libgfortran4-7.5.0-h1a10cd1_23 has constraint libgfortran 4.0.0 *_23 conflicting with libgfortran-3.0.1-0; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2578#issuecomment-1125640496
https://github.com/psi4/psi4/issues/2578#issuecomment-1125640496:201,Deployability,install,install,201,"Thanks for the response. I will try out conda install again. . In the meantime, I want to explain why I turned to #2024. ; I encounter this issue while installing just normal psi4: (this is from mamba install); ```; package libgfortran4-7.5.0-h1a10cd1_23 has constraint libgfortran 4.0.0 *_23 conflicting with libgfortran-3.0.1-0; ```. How I get to this point: ; First I used `conda install psi4 -c psi4`, but it will throw me this errors. (nothing is conflicting?) So I turned to `mamba` to help me with the conflicts. ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: -; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```. This is what mamba got back to me if I installed the normal build. `mamba install psi4=1.5+e9f4d6d=py38ha809fef_0 -c psi4`. ```; package psi4-1.5+e9f4d6d-py38ha809fef_0 requires chemps2 >=1.8.10,<1.8.11.0a0, but none of the providers can be installed; ```. So then I tried to install `chemps2`, this can be installed normally. . Then I tried mamba to install psi4 again. . `mamba install psi4=1.5+e9f4d6d=py38ha809fef_0 -c psi4`. ```; package psi4-1.5+e9f4d6d-py38ha809fef_0 requires libgfortran >=3.0.1,<4.0.0.a0, but none of the providers can be installed; ```. Lastly, I tried to install libgfortran, but resulted in the above message. ; ```; package libgfortran4-7.5.0-h1a10cd1_23 has constraint libgfortran 4.0.0 *_23 conflicting with libgfortran-3.0.1-0; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2578#issuecomment-1125640496
https://github.com/psi4/psi4/issues/2578#issuecomment-1125640496:383,Deployability,install,install,383,"Thanks for the response. I will try out conda install again. . In the meantime, I want to explain why I turned to #2024. ; I encounter this issue while installing just normal psi4: (this is from mamba install); ```; package libgfortran4-7.5.0-h1a10cd1_23 has constraint libgfortran 4.0.0 *_23 conflicting with libgfortran-3.0.1-0; ```. How I get to this point: ; First I used `conda install psi4 -c psi4`, but it will throw me this errors. (nothing is conflicting?) So I turned to `mamba` to help me with the conflicts. ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: -; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```. This is what mamba got back to me if I installed the normal build. `mamba install psi4=1.5+e9f4d6d=py38ha809fef_0 -c psi4`. ```; package psi4-1.5+e9f4d6d-py38ha809fef_0 requires chemps2 >=1.8.10,<1.8.11.0a0, but none of the providers can be installed; ```. So then I tried to install `chemps2`, this can be installed normally. . Then I tried mamba to install psi4 again. . `mamba install psi4=1.5+e9f4d6d=py38ha809fef_0 -c psi4`. ```; package psi4-1.5+e9f4d6d-py38ha809fef_0 requires libgfortran >=3.0.1,<4.0.0.a0, but none of the providers can be installed; ```. Lastly, I tried to install libgfortran, but resulted in the above message. ; ```; package libgfortran4-7.5.0-h1a10cd1_23 has constraint libgfortran 4.0.0 *_23 conflicting with libgfortran-3.0.1-0; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2578#issuecomment-1125640496
https://github.com/psi4/psi4/issues/2578#issuecomment-1125640496:1256,Deployability,install,installed,1256,"Thanks for the response. I will try out conda install again. . In the meantime, I want to explain why I turned to #2024. ; I encounter this issue while installing just normal psi4: (this is from mamba install); ```; package libgfortran4-7.5.0-h1a10cd1_23 has constraint libgfortran 4.0.0 *_23 conflicting with libgfortran-3.0.1-0; ```. How I get to this point: ; First I used `conda install psi4 -c psi4`, but it will throw me this errors. (nothing is conflicting?) So I turned to `mamba` to help me with the conflicts. ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: -; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```. This is what mamba got back to me if I installed the normal build. `mamba install psi4=1.5+e9f4d6d=py38ha809fef_0 -c psi4`. ```; package psi4-1.5+e9f4d6d-py38ha809fef_0 requires chemps2 >=1.8.10,<1.8.11.0a0, but none of the providers can be installed; ```. So then I tried to install `chemps2`, this can be installed normally. . Then I tried mamba to install psi4 again. . `mamba install psi4=1.5+e9f4d6d=py38ha809fef_0 -c psi4`. ```; package psi4-1.5+e9f4d6d-py38ha809fef_0 requires libgfortran >=3.0.1,<4.0.0.a0, but none of the providers can be installed; ```. Lastly, I tried to install libgfortran, but resulted in the above message. ; ```; package libgfortran4-7.5.0-h1a10cd1_23 has constraint libgfortran 4.0.0 *_23 conflicting with libgfortran-3.0.1-0; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2578#issuecomment-1125640496
https://github.com/psi4/psi4/issues/2578#issuecomment-1125640496:1291,Deployability,install,install,1291,"Thanks for the response. I will try out conda install again. . In the meantime, I want to explain why I turned to #2024. ; I encounter this issue while installing just normal psi4: (this is from mamba install); ```; package libgfortran4-7.5.0-h1a10cd1_23 has constraint libgfortran 4.0.0 *_23 conflicting with libgfortran-3.0.1-0; ```. How I get to this point: ; First I used `conda install psi4 -c psi4`, but it will throw me this errors. (nothing is conflicting?) So I turned to `mamba` to help me with the conflicts. ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: -; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```. This is what mamba got back to me if I installed the normal build. `mamba install psi4=1.5+e9f4d6d=py38ha809fef_0 -c psi4`. ```; package psi4-1.5+e9f4d6d-py38ha809fef_0 requires chemps2 >=1.8.10,<1.8.11.0a0, but none of the providers can be installed; ```. So then I tried to install `chemps2`, this can be installed normally. . Then I tried mamba to install psi4 again. . `mamba install psi4=1.5+e9f4d6d=py38ha809fef_0 -c psi4`. ```; package psi4-1.5+e9f4d6d-py38ha809fef_0 requires libgfortran >=3.0.1,<4.0.0.a0, but none of the providers can be installed; ```. Lastly, I tried to install libgfortran, but resulted in the above message. ; ```; package libgfortran4-7.5.0-h1a10cd1_23 has constraint libgfortran 4.0.0 *_23 conflicting with libgfortran-3.0.1-0; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2578#issuecomment-1125640496
https://github.com/psi4/psi4/issues/2578#issuecomment-1125640496:1458,Deployability,install,installed,1458,"Thanks for the response. I will try out conda install again. . In the meantime, I want to explain why I turned to #2024. ; I encounter this issue while installing just normal psi4: (this is from mamba install); ```; package libgfortran4-7.5.0-h1a10cd1_23 has constraint libgfortran 4.0.0 *_23 conflicting with libgfortran-3.0.1-0; ```. How I get to this point: ; First I used `conda install psi4 -c psi4`, but it will throw me this errors. (nothing is conflicting?) So I turned to `mamba` to help me with the conflicts. ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: -; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```. This is what mamba got back to me if I installed the normal build. `mamba install psi4=1.5+e9f4d6d=py38ha809fef_0 -c psi4`. ```; package psi4-1.5+e9f4d6d-py38ha809fef_0 requires chemps2 >=1.8.10,<1.8.11.0a0, but none of the providers can be installed; ```. So then I tried to install `chemps2`, this can be installed normally. . Then I tried mamba to install psi4 again. . `mamba install psi4=1.5+e9f4d6d=py38ha809fef_0 -c psi4`. ```; package psi4-1.5+e9f4d6d-py38ha809fef_0 requires libgfortran >=3.0.1,<4.0.0.a0, but none of the providers can be installed; ```. Lastly, I tried to install libgfortran, but resulted in the above message. ; ```; package libgfortran4-7.5.0-h1a10cd1_23 has constraint libgfortran 4.0.0 *_23 conflicting with libgfortran-3.0.1-0; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2578#issuecomment-1125640496
https://github.com/psi4/psi4/issues/2578#issuecomment-1125640496:1493,Deployability,install,install,1493,"Thanks for the response. I will try out conda install again. . In the meantime, I want to explain why I turned to #2024. ; I encounter this issue while installing just normal psi4: (this is from mamba install); ```; package libgfortran4-7.5.0-h1a10cd1_23 has constraint libgfortran 4.0.0 *_23 conflicting with libgfortran-3.0.1-0; ```. How I get to this point: ; First I used `conda install psi4 -c psi4`, but it will throw me this errors. (nothing is conflicting?) So I turned to `mamba` to help me with the conflicts. ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: -; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```. This is what mamba got back to me if I installed the normal build. `mamba install psi4=1.5+e9f4d6d=py38ha809fef_0 -c psi4`. ```; package psi4-1.5+e9f4d6d-py38ha809fef_0 requires chemps2 >=1.8.10,<1.8.11.0a0, but none of the providers can be installed; ```. So then I tried to install `chemps2`, this can be installed normally. . Then I tried mamba to install psi4 again. . `mamba install psi4=1.5+e9f4d6d=py38ha809fef_0 -c psi4`. ```; package psi4-1.5+e9f4d6d-py38ha809fef_0 requires libgfortran >=3.0.1,<4.0.0.a0, but none of the providers can be installed; ```. Lastly, I tried to install libgfortran, but resulted in the above message. ; ```; package libgfortran4-7.5.0-h1a10cd1_23 has constraint libgfortran 4.0.0 *_23 conflicting with libgfortran-3.0.1-0; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2578#issuecomment-1125640496
https://github.com/psi4/psi4/issues/2578#issuecomment-1125640496:1524,Deployability,install,installed,1524,"Thanks for the response. I will try out conda install again. . In the meantime, I want to explain why I turned to #2024. ; I encounter this issue while installing just normal psi4: (this is from mamba install); ```; package libgfortran4-7.5.0-h1a10cd1_23 has constraint libgfortran 4.0.0 *_23 conflicting with libgfortran-3.0.1-0; ```. How I get to this point: ; First I used `conda install psi4 -c psi4`, but it will throw me this errors. (nothing is conflicting?) So I turned to `mamba` to help me with the conflicts. ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: -; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```. This is what mamba got back to me if I installed the normal build. `mamba install psi4=1.5+e9f4d6d=py38ha809fef_0 -c psi4`. ```; package psi4-1.5+e9f4d6d-py38ha809fef_0 requires chemps2 >=1.8.10,<1.8.11.0a0, but none of the providers can be installed; ```. So then I tried to install `chemps2`, this can be installed normally. . Then I tried mamba to install psi4 again. . `mamba install psi4=1.5+e9f4d6d=py38ha809fef_0 -c psi4`. ```; package psi4-1.5+e9f4d6d-py38ha809fef_0 requires libgfortran >=3.0.1,<4.0.0.a0, but none of the providers can be installed; ```. Lastly, I tried to install libgfortran, but resulted in the above message. ; ```; package libgfortran4-7.5.0-h1a10cd1_23 has constraint libgfortran 4.0.0 *_23 conflicting with libgfortran-3.0.1-0; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2578#issuecomment-1125640496
https://github.com/psi4/psi4/issues/2578#issuecomment-1125640496:1568,Deployability,install,install,1568,"Thanks for the response. I will try out conda install again. . In the meantime, I want to explain why I turned to #2024. ; I encounter this issue while installing just normal psi4: (this is from mamba install); ```; package libgfortran4-7.5.0-h1a10cd1_23 has constraint libgfortran 4.0.0 *_23 conflicting with libgfortran-3.0.1-0; ```. How I get to this point: ; First I used `conda install psi4 -c psi4`, but it will throw me this errors. (nothing is conflicting?) So I turned to `mamba` to help me with the conflicts. ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: -; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```. This is what mamba got back to me if I installed the normal build. `mamba install psi4=1.5+e9f4d6d=py38ha809fef_0 -c psi4`. ```; package psi4-1.5+e9f4d6d-py38ha809fef_0 requires chemps2 >=1.8.10,<1.8.11.0a0, but none of the providers can be installed; ```. So then I tried to install `chemps2`, this can be installed normally. . Then I tried mamba to install psi4 again. . `mamba install psi4=1.5+e9f4d6d=py38ha809fef_0 -c psi4`. ```; package psi4-1.5+e9f4d6d-py38ha809fef_0 requires libgfortran >=3.0.1,<4.0.0.a0, but none of the providers can be installed; ```. Lastly, I tried to install libgfortran, but resulted in the above message. ; ```; package libgfortran4-7.5.0-h1a10cd1_23 has constraint libgfortran 4.0.0 *_23 conflicting with libgfortran-3.0.1-0; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2578#issuecomment-1125640496
https://github.com/psi4/psi4/issues/2578#issuecomment-1125640496:1597,Deployability,install,install,1597,"Thanks for the response. I will try out conda install again. . In the meantime, I want to explain why I turned to #2024. ; I encounter this issue while installing just normal psi4: (this is from mamba install); ```; package libgfortran4-7.5.0-h1a10cd1_23 has constraint libgfortran 4.0.0 *_23 conflicting with libgfortran-3.0.1-0; ```. How I get to this point: ; First I used `conda install psi4 -c psi4`, but it will throw me this errors. (nothing is conflicting?) So I turned to `mamba` to help me with the conflicts. ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: -; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```. This is what mamba got back to me if I installed the normal build. `mamba install psi4=1.5+e9f4d6d=py38ha809fef_0 -c psi4`. ```; package psi4-1.5+e9f4d6d-py38ha809fef_0 requires chemps2 >=1.8.10,<1.8.11.0a0, but none of the providers can be installed; ```. So then I tried to install `chemps2`, this can be installed normally. . Then I tried mamba to install psi4 again. . `mamba install psi4=1.5+e9f4d6d=py38ha809fef_0 -c psi4`. ```; package psi4-1.5+e9f4d6d-py38ha809fef_0 requires libgfortran >=3.0.1,<4.0.0.a0, but none of the providers can be installed; ```. Lastly, I tried to install libgfortran, but resulted in the above message. ; ```; package libgfortran4-7.5.0-h1a10cd1_23 has constraint libgfortran 4.0.0 *_23 conflicting with libgfortran-3.0.1-0; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2578#issuecomment-1125640496
https://github.com/psi4/psi4/issues/2578#issuecomment-1125640496:1765,Deployability,install,installed,1765,"Thanks for the response. I will try out conda install again. . In the meantime, I want to explain why I turned to #2024. ; I encounter this issue while installing just normal psi4: (this is from mamba install); ```; package libgfortran4-7.5.0-h1a10cd1_23 has constraint libgfortran 4.0.0 *_23 conflicting with libgfortran-3.0.1-0; ```. How I get to this point: ; First I used `conda install psi4 -c psi4`, but it will throw me this errors. (nothing is conflicting?) So I turned to `mamba` to help me with the conflicts. ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: -; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```. This is what mamba got back to me if I installed the normal build. `mamba install psi4=1.5+e9f4d6d=py38ha809fef_0 -c psi4`. ```; package psi4-1.5+e9f4d6d-py38ha809fef_0 requires chemps2 >=1.8.10,<1.8.11.0a0, but none of the providers can be installed; ```. So then I tried to install `chemps2`, this can be installed normally. . Then I tried mamba to install psi4 again. . `mamba install psi4=1.5+e9f4d6d=py38ha809fef_0 -c psi4`. ```; package psi4-1.5+e9f4d6d-py38ha809fef_0 requires libgfortran >=3.0.1,<4.0.0.a0, but none of the providers can be installed; ```. Lastly, I tried to install libgfortran, but resulted in the above message. ; ```; package libgfortran4-7.5.0-h1a10cd1_23 has constraint libgfortran 4.0.0 *_23 conflicting with libgfortran-3.0.1-0; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2578#issuecomment-1125640496
https://github.com/psi4/psi4/issues/2578#issuecomment-1125640496:1800,Deployability,install,install,1800,"Thanks for the response. I will try out conda install again. . In the meantime, I want to explain why I turned to #2024. ; I encounter this issue while installing just normal psi4: (this is from mamba install); ```; package libgfortran4-7.5.0-h1a10cd1_23 has constraint libgfortran 4.0.0 *_23 conflicting with libgfortran-3.0.1-0; ```. How I get to this point: ; First I used `conda install psi4 -c psi4`, but it will throw me this errors. (nothing is conflicting?) So I turned to `mamba` to help me with the conflicts. ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: -; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```. This is what mamba got back to me if I installed the normal build. `mamba install psi4=1.5+e9f4d6d=py38ha809fef_0 -c psi4`. ```; package psi4-1.5+e9f4d6d-py38ha809fef_0 requires chemps2 >=1.8.10,<1.8.11.0a0, but none of the providers can be installed; ```. So then I tried to install `chemps2`, this can be installed normally. . Then I tried mamba to install psi4 again. . `mamba install psi4=1.5+e9f4d6d=py38ha809fef_0 -c psi4`. ```; package psi4-1.5+e9f4d6d-py38ha809fef_0 requires libgfortran >=3.0.1,<4.0.0.a0, but none of the providers can be installed; ```. Lastly, I tried to install libgfortran, but resulted in the above message. ; ```; package libgfortran4-7.5.0-h1a10cd1_23 has constraint libgfortran 4.0.0 *_23 conflicting with libgfortran-3.0.1-0; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2578#issuecomment-1125640496
https://github.com/psi4/psi4/issues/2578#issuecomment-1125640496:1847,Integrability,message,message,1847,"Thanks for the response. I will try out conda install again. . In the meantime, I want to explain why I turned to #2024. ; I encounter this issue while installing just normal psi4: (this is from mamba install); ```; package libgfortran4-7.5.0-h1a10cd1_23 has constraint libgfortran 4.0.0 *_23 conflicting with libgfortran-3.0.1-0; ```. How I get to this point: ; First I used `conda install psi4 -c psi4`, but it will throw me this errors. (nothing is conflicting?) So I turned to `mamba` to help me with the conflicts. ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: -; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```. This is what mamba got back to me if I installed the normal build. `mamba install psi4=1.5+e9f4d6d=py38ha809fef_0 -c psi4`. ```; package psi4-1.5+e9f4d6d-py38ha809fef_0 requires chemps2 >=1.8.10,<1.8.11.0a0, but none of the providers can be installed; ```. So then I tried to install `chemps2`, this can be installed normally. . Then I tried mamba to install psi4 again. . `mamba install psi4=1.5+e9f4d6d=py38ha809fef_0 -c psi4`. ```; package psi4-1.5+e9f4d6d-py38ha809fef_0 requires libgfortran >=3.0.1,<4.0.0.a0, but none of the providers can be installed; ```. Lastly, I tried to install libgfortran, but resulted in the above message. ; ```; package libgfortran4-7.5.0-h1a10cd1_23 has constraint libgfortran 4.0.0 *_23 conflicting with libgfortran-3.0.1-0; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2578#issuecomment-1125640496
https://github.com/psi4/psi4/issues/2578#issuecomment-1125640496:653,Modifiability,flexible,flexible,653,"Thanks for the response. I will try out conda install again. . In the meantime, I want to explain why I turned to #2024. ; I encounter this issue while installing just normal psi4: (this is from mamba install); ```; package libgfortran4-7.5.0-h1a10cd1_23 has constraint libgfortran 4.0.0 *_23 conflicting with libgfortran-3.0.1-0; ```. How I get to this point: ; First I used `conda install psi4 -c psi4`, but it will throw me this errors. (nothing is conflicting?) So I turned to `mamba` to help me with the conflicts. ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: -; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```. This is what mamba got back to me if I installed the normal build. `mamba install psi4=1.5+e9f4d6d=py38ha809fef_0 -c psi4`. ```; package psi4-1.5+e9f4d6d-py38ha809fef_0 requires chemps2 >=1.8.10,<1.8.11.0a0, but none of the providers can be installed; ```. So then I tried to install `chemps2`, this can be installed normally. . Then I tried mamba to install psi4 again. . `mamba install psi4=1.5+e9f4d6d=py38ha809fef_0 -c psi4`. ```; package psi4-1.5+e9f4d6d-py38ha809fef_0 requires libgfortran >=3.0.1,<4.0.0.a0, but none of the providers can be installed; ```. Lastly, I tried to install libgfortran, but resulted in the above message. ; ```; package libgfortran4-7.5.0-h1a10cd1_23 has constraint libgfortran 4.0.0 *_23 conflicting with libgfortran-3.0.1-0; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2578#issuecomment-1125640496
https://github.com/psi4/psi4/issues/2578#issuecomment-1125640496:899,Modifiability,flexible,flexible,899,"Thanks for the response. I will try out conda install again. . In the meantime, I want to explain why I turned to #2024. ; I encounter this issue while installing just normal psi4: (this is from mamba install); ```; package libgfortran4-7.5.0-h1a10cd1_23 has constraint libgfortran 4.0.0 *_23 conflicting with libgfortran-3.0.1-0; ```. How I get to this point: ; First I used `conda install psi4 -c psi4`, but it will throw me this errors. (nothing is conflicting?) So I turned to `mamba` to help me with the conflicts. ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: -; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```. This is what mamba got back to me if I installed the normal build. `mamba install psi4=1.5+e9f4d6d=py38ha809fef_0 -c psi4`. ```; package psi4-1.5+e9f4d6d-py38ha809fef_0 requires chemps2 >=1.8.10,<1.8.11.0a0, but none of the providers can be installed; ```. So then I tried to install `chemps2`, this can be installed normally. . Then I tried mamba to install psi4 again. . `mamba install psi4=1.5+e9f4d6d=py38ha809fef_0 -c psi4`. ```; package psi4-1.5+e9f4d6d-py38ha809fef_0 requires libgfortran >=3.0.1,<4.0.0.a0, but none of the providers can be installed; ```. Lastly, I tried to install libgfortran, but resulted in the above message. ; ```; package libgfortran4-7.5.0-h1a10cd1_23 has constraint libgfortran 4.0.0 *_23 conflicting with libgfortran-3.0.1-0; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2578#issuecomment-1125640496
https://github.com/psi4/psi4/issues/2578#issuecomment-1125640496:1040,Safety,abort,abort,1040,"Thanks for the response. I will try out conda install again. . In the meantime, I want to explain why I turned to #2024. ; I encounter this issue while installing just normal psi4: (this is from mamba install); ```; package libgfortran4-7.5.0-h1a10cd1_23 has constraint libgfortran 4.0.0 *_23 conflicting with libgfortran-3.0.1-0; ```. How I get to this point: ; First I used `conda install psi4 -c psi4`, but it will throw me this errors. (nothing is conflicting?) So I turned to `mamba` to help me with the conflicts. ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: -; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```. This is what mamba got back to me if I installed the normal build. `mamba install psi4=1.5+e9f4d6d=py38ha809fef_0 -c psi4`. ```; package psi4-1.5+e9f4d6d-py38ha809fef_0 requires chemps2 >=1.8.10,<1.8.11.0a0, but none of the providers can be installed; ```. So then I tried to install `chemps2`, this can be installed normally. . Then I tried mamba to install psi4 again. . `mamba install psi4=1.5+e9f4d6d=py38ha809fef_0 -c psi4`. ```; package psi4-1.5+e9f4d6d-py38ha809fef_0 requires libgfortran >=3.0.1,<4.0.0.a0, but none of the providers can be installed; ```. Lastly, I tried to install libgfortran, but resulted in the above message. ; ```; package libgfortran4-7.5.0-h1a10cd1_23 has constraint libgfortran 4.0.0 *_23 conflicting with libgfortran-3.0.1-0; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2578#issuecomment-1125640496
https://github.com/psi4/psi4/pull/2581#issuecomment-1129039670:478,Deployability,update,updated,478,"Thanks for the reviews! @zachglick and I tested this fix on water with the custom basis set reported in the [forum post.](http://forum.psicode.org/t/calculations-with-custom-basis-sets-run-slower-with-multiple-threads/2461). Input file:; ```; memory 50 GB. molecule h2o {; 0 1 ; O; H 1 1.0 ; H 1 1.0 2 109.5; }. set basis custombasis. gradient(""pbe0""); ```; Wall time results:. | | 1 core | 18 cores |; |-- | ---------- | ----------|; | original code | 28.00 s | 2:45.96 s |; | updated code | 28.01 s | 25.96 s |. Let me know if more testing is needed!",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2581#issuecomment-1129039670
https://github.com/psi4/psi4/pull/2581#issuecomment-1129039670:41,Testability,test,tested,41,"Thanks for the reviews! @zachglick and I tested this fix on water with the custom basis set reported in the [forum post.](http://forum.psicode.org/t/calculations-with-custom-basis-sets-run-slower-with-multiple-threads/2461). Input file:; ```; memory 50 GB. molecule h2o {; 0 1 ; O; H 1 1.0 ; H 1 1.0 2 109.5; }. set basis custombasis. gradient(""pbe0""); ```; Wall time results:. | | 1 core | 18 cores |; |-- | ---------- | ----------|; | original code | 28.00 s | 2:45.96 s |; | updated code | 28.01 s | 25.96 s |. Let me know if more testing is needed!",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2581#issuecomment-1129039670
https://github.com/psi4/psi4/pull/2581#issuecomment-1129039670:534,Testability,test,testing,534,"Thanks for the reviews! @zachglick and I tested this fix on water with the custom basis set reported in the [forum post.](http://forum.psicode.org/t/calculations-with-custom-basis-sets-run-slower-with-multiple-threads/2461). Input file:; ```; memory 50 GB. molecule h2o {; 0 1 ; O; H 1 1.0 ; H 1 1.0 2 109.5; }. set basis custombasis. gradient(""pbe0""); ```; Wall time results:. | | 1 core | 18 cores |; |-- | ---------- | ----------|; | original code | 28.00 s | 2:45.96 s |; | updated code | 28.01 s | 25.96 s |. Let me know if more testing is needed!",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2581#issuecomment-1129039670
https://github.com/psi4/psi4/issues/2586#issuecomment-1133782381:376,Deployability,patch,patch,376,"I should have read this first before replying on twitter. That 7-7-4-8-8-5 file was a trial I was making (https://github.com/psi4/psi4/issues/1341#issuecomment-1130271539). And in generating the tarball, I caught some uncommitted local changes that I was trying to fix a separate issue of paths in Windows. Thanks for the report, and I'm sorry for the trouble. I'll certainly patch it up before officially recommending that larger AM tarball. Out of curiosity, what architecture/threads were you using that you got that tarball to build in 3 hours?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2586#issuecomment-1133782381
https://github.com/psi4/psi4/issues/2586#issuecomment-1133800433:711,Deployability,configurat,configuration,711,"Three hours and nine minutes, according to the timestamps I have for relevant events. I _believe_ the build ran on a 32-thread (16-core) intel broadwell (with ample memory to avoid paging, for however much that helps), and the build was the only event happening on the machine at that time. (I am a little unsure, though, as it's a build-server, and I don't have any way of telling who else might've submitted a build job to the machine at that time. It was ~1AM on a Saturday, though, so probably just me). Also, the .so file generated was 925MB, if that's of any interest. Should I worry at all that the tarball represents a WIP in terms of the actual integral files? Or does the trial status only regard the configuration?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2586#issuecomment-1133800433
https://github.com/psi4/psi4/issues/2586#issuecomment-1133800433:711,Modifiability,config,configuration,711,"Three hours and nine minutes, according to the timestamps I have for relevant events. I _believe_ the build ran on a 32-thread (16-core) intel broadwell (with ample memory to avoid paging, for however much that helps), and the build was the only event happening on the machine at that time. (I am a little unsure, though, as it's a build-server, and I don't have any way of telling who else might've submitted a build job to the machine at that time. It was ~1AM on a Saturday, though, so probably just me). Also, the .so file generated was 925MB, if that's of any interest. Should I worry at all that the tarball represents a WIP in terms of the actual integral files? Or does the trial status only regard the configuration?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2586#issuecomment-1133800433
https://github.com/psi4/psi4/issues/2586#issuecomment-1133800433:175,Safety,avoid,avoid,175,"Three hours and nine minutes, according to the timestamps I have for relevant events. I _believe_ the build ran on a 32-thread (16-core) intel broadwell (with ample memory to avoid paging, for however much that helps), and the build was the only event happening on the machine at that time. (I am a little unsure, though, as it's a build-server, and I don't have any way of telling who else might've submitted a build job to the machine at that time. It was ~1AM on a Saturday, though, so probably just me). Also, the .so file generated was 925MB, if that's of any interest. Should I worry at all that the tarball represents a WIP in terms of the actual integral files? Or does the trial status only regard the configuration?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2586#issuecomment-1133800433
https://github.com/psi4/psi4/issues/2586#issuecomment-1133805493:834,Deployability,configurat,configuration,834,"> Three hours and nine minutes, according to the timestamps I have for relevant events. I believe the build ran on a 32-thread (16-core) intel broadwell (with ample memory to avoid paging, for however much that helps), and the build was the only event happening on the machine at that time. (I am a little unsure, though, as it's a build-server, and I don't have any way of telling who else might've submitted a build job to the machine at that time. It was ~1AM on a Saturday, though, so probably just me). Also, the .so file generated was 925MB, if that's of any interest. Thanks for the info. It must be the Intel compiler and multiarch flags that lengthen my builds by an order of magnitude. > Should I worry at all that the tarball represents a WIP in terms of the actual integral files? Or does the trial status only regard the configuration?. I expect the integral files in that tarball to be perfectly good. I've checked my local diff again, and nothing else should be harmful. One caveat is that the integrals author generally dissuades building AM>7, so I had to defeat those checks, but I know people who have built higher than that tarball (albeit different versions of the code) without known ill effects. If you've got an `.so`, and psi4 passes a few tests, I think you're good to go.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2586#issuecomment-1133805493
https://github.com/psi4/psi4/issues/2586#issuecomment-1133805493:834,Modifiability,config,configuration,834,"> Three hours and nine minutes, according to the timestamps I have for relevant events. I believe the build ran on a 32-thread (16-core) intel broadwell (with ample memory to avoid paging, for however much that helps), and the build was the only event happening on the machine at that time. (I am a little unsure, though, as it's a build-server, and I don't have any way of telling who else might've submitted a build job to the machine at that time. It was ~1AM on a Saturday, though, so probably just me). Also, the .so file generated was 925MB, if that's of any interest. Thanks for the info. It must be the Intel compiler and multiarch flags that lengthen my builds by an order of magnitude. > Should I worry at all that the tarball represents a WIP in terms of the actual integral files? Or does the trial status only regard the configuration?. I expect the integral files in that tarball to be perfectly good. I've checked my local diff again, and nothing else should be harmful. One caveat is that the integrals author generally dissuades building AM>7, so I had to defeat those checks, but I know people who have built higher than that tarball (albeit different versions of the code) without known ill effects. If you've got an `.so`, and psi4 passes a few tests, I think you're good to go.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2586#issuecomment-1133805493
https://github.com/psi4/psi4/issues/2586#issuecomment-1133805493:175,Safety,avoid,avoid,175,"> Three hours and nine minutes, according to the timestamps I have for relevant events. I believe the build ran on a 32-thread (16-core) intel broadwell (with ample memory to avoid paging, for however much that helps), and the build was the only event happening on the machine at that time. (I am a little unsure, though, as it's a build-server, and I don't have any way of telling who else might've submitted a build job to the machine at that time. It was ~1AM on a Saturday, though, so probably just me). Also, the .so file generated was 925MB, if that's of any interest. Thanks for the info. It must be the Intel compiler and multiarch flags that lengthen my builds by an order of magnitude. > Should I worry at all that the tarball represents a WIP in terms of the actual integral files? Or does the trial status only regard the configuration?. I expect the integral files in that tarball to be perfectly good. I've checked my local diff again, and nothing else should be harmful. One caveat is that the integrals author generally dissuades building AM>7, so I had to defeat those checks, but I know people who have built higher than that tarball (albeit different versions of the code) without known ill effects. If you've got an `.so`, and psi4 passes a few tests, I think you're good to go.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2586#issuecomment-1133805493
https://github.com/psi4/psi4/issues/2586#issuecomment-1133805493:1265,Testability,test,tests,1265,"> Three hours and nine minutes, according to the timestamps I have for relevant events. I believe the build ran on a 32-thread (16-core) intel broadwell (with ample memory to avoid paging, for however much that helps), and the build was the only event happening on the machine at that time. (I am a little unsure, though, as it's a build-server, and I don't have any way of telling who else might've submitted a build job to the machine at that time. It was ~1AM on a Saturday, though, so probably just me). Also, the .so file generated was 925MB, if that's of any interest. Thanks for the info. It must be the Intel compiler and multiarch flags that lengthen my builds by an order of magnitude. > Should I worry at all that the tarball represents a WIP in terms of the actual integral files? Or does the trial status only regard the configuration?. I expect the integral files in that tarball to be perfectly good. I've checked my local diff again, and nothing else should be harmful. One caveat is that the integrals author generally dissuades building AM>7, so I had to defeat those checks, but I know people who have built higher than that tarball (albeit different versions of the code) without known ill effects. If you've got an `.so`, and psi4 passes a few tests, I think you're good to go.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2586#issuecomment-1133805493
https://github.com/psi4/psi4/issues/2587#issuecomment-1137216947:262,Security,access,access,262,"`Ca` and `Cb` are the same in RHF and ROHF theory, yes. For this reason, the spin name is not _incorrect_ but _confusing_. On the C++ side, `Ca` and `Cb` are probably the same object for restricted orbitals, so of course you will find the same name, whether you access the object by `Ca` or `Cb`. For this reason, naming the orbitals ""Alpha"" and ""Beta"" is unacceptable. The best we could remove a spin-specifier from the name entirely.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2587#issuecomment-1137216947
https://github.com/psi4/psi4/pull/2590#issuecomment-1140108136:16,Testability,test,test,16,"1. Please add a test showing the bug is fixed.; 2. Please explain the bug in more detail. Is the expected behavior that Psi reports some jobs in the plan can't run? If the expected behavior is that you get a number, why are any PsiExceptions appearing in the plan?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2590#issuecomment-1140108136
https://github.com/psi4/psi4/pull/2590#issuecomment-1145418829:409,Availability,error,error,409,"> Please explain the bug in more detail. Is the expected behavior that Psi reports some jobs in the plan can't run? If the expected behavior is that you get a number, why are any PsiExceptions appearing in the plan?. Good point. The new driver_util tech separates figuring out what derivative psi can do analytically under the specified conditions from what derivative requested or demanded by user. So those error strings you see in `analytic` are just being stored _in case_ user demanded analytic gradient. In the given case, energy was requested and the error strings were never used. If the user wanted gradient, calc would fall back to findif by E and the error strings wouldn't be used. If the user wanted gradient and also gave `dertype=1` for analytic, the error string pops up. For the last case, this needs to be improved in future to show the user _all_ the errors, not just the first (mp2) one. But that's more than a couple-line fix, so not suitable for backport.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2590#issuecomment-1145418829
https://github.com/psi4/psi4/pull/2590#issuecomment-1145418829:558,Availability,error,error,558,"> Please explain the bug in more detail. Is the expected behavior that Psi reports some jobs in the plan can't run? If the expected behavior is that you get a number, why are any PsiExceptions appearing in the plan?. Good point. The new driver_util tech separates figuring out what derivative psi can do analytically under the specified conditions from what derivative requested or demanded by user. So those error strings you see in `analytic` are just being stored _in case_ user demanded analytic gradient. In the given case, energy was requested and the error strings were never used. If the user wanted gradient, calc would fall back to findif by E and the error strings wouldn't be used. If the user wanted gradient and also gave `dertype=1` for analytic, the error string pops up. For the last case, this needs to be improved in future to show the user _all_ the errors, not just the first (mp2) one. But that's more than a couple-line fix, so not suitable for backport.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2590#issuecomment-1145418829
https://github.com/psi4/psi4/pull/2590#issuecomment-1145418829:662,Availability,error,error,662,"> Please explain the bug in more detail. Is the expected behavior that Psi reports some jobs in the plan can't run? If the expected behavior is that you get a number, why are any PsiExceptions appearing in the plan?. Good point. The new driver_util tech separates figuring out what derivative psi can do analytically under the specified conditions from what derivative requested or demanded by user. So those error strings you see in `analytic` are just being stored _in case_ user demanded analytic gradient. In the given case, energy was requested and the error strings were never used. If the user wanted gradient, calc would fall back to findif by E and the error strings wouldn't be used. If the user wanted gradient and also gave `dertype=1` for analytic, the error string pops up. For the last case, this needs to be improved in future to show the user _all_ the errors, not just the first (mp2) one. But that's more than a couple-line fix, so not suitable for backport.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2590#issuecomment-1145418829
https://github.com/psi4/psi4/pull/2590#issuecomment-1145418829:766,Availability,error,error,766,"> Please explain the bug in more detail. Is the expected behavior that Psi reports some jobs in the plan can't run? If the expected behavior is that you get a number, why are any PsiExceptions appearing in the plan?. Good point. The new driver_util tech separates figuring out what derivative psi can do analytically under the specified conditions from what derivative requested or demanded by user. So those error strings you see in `analytic` are just being stored _in case_ user demanded analytic gradient. In the given case, energy was requested and the error strings were never used. If the user wanted gradient, calc would fall back to findif by E and the error strings wouldn't be used. If the user wanted gradient and also gave `dertype=1` for analytic, the error string pops up. For the last case, this needs to be improved in future to show the user _all_ the errors, not just the first (mp2) one. But that's more than a couple-line fix, so not suitable for backport.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2590#issuecomment-1145418829
https://github.com/psi4/psi4/pull/2590#issuecomment-1145418829:870,Availability,error,errors,870,"> Please explain the bug in more detail. Is the expected behavior that Psi reports some jobs in the plan can't run? If the expected behavior is that you get a number, why are any PsiExceptions appearing in the plan?. Good point. The new driver_util tech separates figuring out what derivative psi can do analytically under the specified conditions from what derivative requested or demanded by user. So those error strings you see in `analytic` are just being stored _in case_ user demanded analytic gradient. In the given case, energy was requested and the error strings were never used. If the user wanted gradient, calc would fall back to findif by E and the error strings wouldn't be used. If the user wanted gradient and also gave `dertype=1` for analytic, the error string pops up. For the last case, this needs to be improved in future to show the user _all_ the errors, not just the first (mp2) one. But that's more than a couple-line fix, so not suitable for backport.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2590#issuecomment-1145418829
https://github.com/psi4/psi4/pull/2590#issuecomment-1145418829:529,Energy Efficiency,energy,energy,529,"> Please explain the bug in more detail. Is the expected behavior that Psi reports some jobs in the plan can't run? If the expected behavior is that you get a number, why are any PsiExceptions appearing in the plan?. Good point. The new driver_util tech separates figuring out what derivative psi can do analytically under the specified conditions from what derivative requested or demanded by user. So those error strings you see in `analytic` are just being stored _in case_ user demanded analytic gradient. In the given case, energy was requested and the error strings were never used. If the user wanted gradient, calc would fall back to findif by E and the error strings wouldn't be used. If the user wanted gradient and also gave `dertype=1` for analytic, the error string pops up. For the last case, this needs to be improved in future to show the user _all_ the errors, not just the first (mp2) one. But that's more than a couple-line fix, so not suitable for backport.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2590#issuecomment-1145418829
https://github.com/psi4/psi4/issues/2591#issuecomment-1141902495:60,Deployability,release,release,60,"Ouch, the problem cannot be reproduced with the current 1.5 release as the release version will die even much earlier with ``MemoryError: std::bad_array_new_length``. When calculating array lengths for ampiitudes, residua and density fitting b factors, simple int32 arithmethic is used, which overflows at some point. `new` is then called with a negative size. i fixed this already in my development branch... Input for reproducing the problem:; ```; memory 160 GB; molecule PR20 {; 0 1; Ir -0.0036453 -0.0067418 0.0546240; P 2.3412316 0.2633260 -0.0827666; C 2.8322725 1.6499560 -1.1514034; C 3.1508965 0.5810022 1.5225953; H 2.7397226 1.4975243 1.9544020; H 3.0796627 -2.0414912 -0.0970847; H 4.2325349 0.6920499 1.3971415; H 2.8126116 -1.4065392 -1.7435421; H 3.9236645 1.7279364 -1.1921940; H 2.9451701 -0.2527656 2.1998134; C 3.2265215 -1.1827248 -0.7571267; H 2.4227823 1.4722103 -2.1484758; H 4.2962318 -0.9681045 -0.8457994; H 2.3889675 2.5675955 -0.7590075; P -2.3731653 -0.0356822 -0.0699620; C -3.1396700 1.0016926 1.2209589; C -3.0094090 0.6380218 -1.6352816; H -2.9455753 -2.3068093 -0.7136733; H -4.2946110 -1.5213106 0.1442505; H -2.8800339 -2.1267692 1.0512420; C -3.2080716 -1.6536880 0.1215551; H -4.1029305 0.6851097 -1.6068349; H -2.5824278 1.6361161 -1.7615996; H -4.2216153 1.0653282 1.0682275; H -2.6891213 1.9959193 1.1600952; H -2.6744520 0.0098950 -2.4628143; H -2.9377790 0.5752071 2.2074361; C -0.0445914 0.2683835 1.8872601; O -0.0651117 0.4624335 3.0248963; Cl -0.3329573 2.5059651 -0.2539036; C 0.2355846 -2.0382203 0.3696479; O 0.5870862 -2.4771706 1.4540805; Cl 0.1349587 -0.2718086 -2.3358022; C 0.0008664 -3.0153971 -0.7782268; H -0.1231146 -4.0205893 -0.3660997; H 0.8774694 -2.9930708 -1.4340628; H -0.8449842 -2.7261204 -1.4026378; }. set reference rhf; set basis def2-TZVPP; set{; freeze_core false; cc_type df; mp2_type df; } . set{; e_convergence 1.0E-9; r_convergence 1.0E-8; max_mograd_convergence 1.0E-7; rms_mograd_convergence 1.0E-8; TPDM_ABCD_TYPE direct",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2591#issuecomment-1141902495
https://github.com/psi4/psi4/issues/2591#issuecomment-1141902495:75,Deployability,release,release,75,"Ouch, the problem cannot be reproduced with the current 1.5 release as the release version will die even much earlier with ``MemoryError: std::bad_array_new_length``. When calculating array lengths for ampiitudes, residua and density fitting b factors, simple int32 arithmethic is used, which overflows at some point. `new` is then called with a negative size. i fixed this already in my development branch... Input for reproducing the problem:; ```; memory 160 GB; molecule PR20 {; 0 1; Ir -0.0036453 -0.0067418 0.0546240; P 2.3412316 0.2633260 -0.0827666; C 2.8322725 1.6499560 -1.1514034; C 3.1508965 0.5810022 1.5225953; H 2.7397226 1.4975243 1.9544020; H 3.0796627 -2.0414912 -0.0970847; H 4.2325349 0.6920499 1.3971415; H 2.8126116 -1.4065392 -1.7435421; H 3.9236645 1.7279364 -1.1921940; H 2.9451701 -0.2527656 2.1998134; C 3.2265215 -1.1827248 -0.7571267; H 2.4227823 1.4722103 -2.1484758; H 4.2962318 -0.9681045 -0.8457994; H 2.3889675 2.5675955 -0.7590075; P -2.3731653 -0.0356822 -0.0699620; C -3.1396700 1.0016926 1.2209589; C -3.0094090 0.6380218 -1.6352816; H -2.9455753 -2.3068093 -0.7136733; H -4.2946110 -1.5213106 0.1442505; H -2.8800339 -2.1267692 1.0512420; C -3.2080716 -1.6536880 0.1215551; H -4.1029305 0.6851097 -1.6068349; H -2.5824278 1.6361161 -1.7615996; H -4.2216153 1.0653282 1.0682275; H -2.6891213 1.9959193 1.1600952; H -2.6744520 0.0098950 -2.4628143; H -2.9377790 0.5752071 2.2074361; C -0.0445914 0.2683835 1.8872601; O -0.0651117 0.4624335 3.0248963; Cl -0.3329573 2.5059651 -0.2539036; C 0.2355846 -2.0382203 0.3696479; O 0.5870862 -2.4771706 1.4540805; Cl 0.1349587 -0.2718086 -2.3358022; C 0.0008664 -3.0153971 -0.7782268; H -0.1231146 -4.0205893 -0.3660997; H 0.8774694 -2.9930708 -1.4340628; H -0.8449842 -2.7261204 -1.4026378; }. set reference rhf; set basis def2-TZVPP; set{; freeze_core false; cc_type df; mp2_type df; } . set{; e_convergence 1.0E-9; r_convergence 1.0E-8; max_mograd_convergence 1.0E-7; rms_mograd_convergence 1.0E-8; TPDM_ABCD_TYPE direct",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2591#issuecomment-1141902495
https://github.com/psi4/psi4/issues/2591#issuecomment-1141902495:2022,Energy Efficiency,energy,energy,2022," much earlier with ``MemoryError: std::bad_array_new_length``. When calculating array lengths for ampiitudes, residua and density fitting b factors, simple int32 arithmethic is used, which overflows at some point. `new` is then called with a negative size. i fixed this already in my development branch... Input for reproducing the problem:; ```; memory 160 GB; molecule PR20 {; 0 1; Ir -0.0036453 -0.0067418 0.0546240; P 2.3412316 0.2633260 -0.0827666; C 2.8322725 1.6499560 -1.1514034; C 3.1508965 0.5810022 1.5225953; H 2.7397226 1.4975243 1.9544020; H 3.0796627 -2.0414912 -0.0970847; H 4.2325349 0.6920499 1.3971415; H 2.8126116 -1.4065392 -1.7435421; H 3.9236645 1.7279364 -1.1921940; H 2.9451701 -0.2527656 2.1998134; C 3.2265215 -1.1827248 -0.7571267; H 2.4227823 1.4722103 -2.1484758; H 4.2962318 -0.9681045 -0.8457994; H 2.3889675 2.5675955 -0.7590075; P -2.3731653 -0.0356822 -0.0699620; C -3.1396700 1.0016926 1.2209589; C -3.0094090 0.6380218 -1.6352816; H -2.9455753 -2.3068093 -0.7136733; H -4.2946110 -1.5213106 0.1442505; H -2.8800339 -2.1267692 1.0512420; C -3.2080716 -1.6536880 0.1215551; H -4.1029305 0.6851097 -1.6068349; H -2.5824278 1.6361161 -1.7615996; H -4.2216153 1.0653282 1.0682275; H -2.6891213 1.9959193 1.1600952; H -2.6744520 0.0098950 -2.4628143; H -2.9377790 0.5752071 2.2074361; C -0.0445914 0.2683835 1.8872601; O -0.0651117 0.4624335 3.0248963; Cl -0.3329573 2.5059651 -0.2539036; C 0.2355846 -2.0382203 0.3696479; O 0.5870862 -2.4771706 1.4540805; Cl 0.1349587 -0.2718086 -2.3358022; C 0.0008664 -3.0153971 -0.7782268; H -0.1231146 -4.0205893 -0.3660997; H 0.8774694 -2.9930708 -1.4340628; H -0.8449842 -2.7261204 -1.4026378; }. set reference rhf; set basis def2-TZVPP; set{; freeze_core false; cc_type df; mp2_type df; } . set{; e_convergence 1.0E-9; r_convergence 1.0E-8; max_mograd_convergence 1.0E-7; rms_mograd_convergence 1.0E-8; TPDM_ABCD_TYPE direct; mo_maxiter 200; }. energy('scf',write_orbitals='scf_mos'); energy('omp2',restart_file='scf_mos'). ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2591#issuecomment-1141902495
https://github.com/psi4/psi4/issues/2591#issuecomment-1141902495:2062,Energy Efficiency,energy,energy,2062," much earlier with ``MemoryError: std::bad_array_new_length``. When calculating array lengths for ampiitudes, residua and density fitting b factors, simple int32 arithmethic is used, which overflows at some point. `new` is then called with a negative size. i fixed this already in my development branch... Input for reproducing the problem:; ```; memory 160 GB; molecule PR20 {; 0 1; Ir -0.0036453 -0.0067418 0.0546240; P 2.3412316 0.2633260 -0.0827666; C 2.8322725 1.6499560 -1.1514034; C 3.1508965 0.5810022 1.5225953; H 2.7397226 1.4975243 1.9544020; H 3.0796627 -2.0414912 -0.0970847; H 4.2325349 0.6920499 1.3971415; H 2.8126116 -1.4065392 -1.7435421; H 3.9236645 1.7279364 -1.1921940; H 2.9451701 -0.2527656 2.1998134; C 3.2265215 -1.1827248 -0.7571267; H 2.4227823 1.4722103 -2.1484758; H 4.2962318 -0.9681045 -0.8457994; H 2.3889675 2.5675955 -0.7590075; P -2.3731653 -0.0356822 -0.0699620; C -3.1396700 1.0016926 1.2209589; C -3.0094090 0.6380218 -1.6352816; H -2.9455753 -2.3068093 -0.7136733; H -4.2946110 -1.5213106 0.1442505; H -2.8800339 -2.1267692 1.0512420; C -3.2080716 -1.6536880 0.1215551; H -4.1029305 0.6851097 -1.6068349; H -2.5824278 1.6361161 -1.7615996; H -4.2216153 1.0653282 1.0682275; H -2.6891213 1.9959193 1.1600952; H -2.6744520 0.0098950 -2.4628143; H -2.9377790 0.5752071 2.2074361; C -0.0445914 0.2683835 1.8872601; O -0.0651117 0.4624335 3.0248963; Cl -0.3329573 2.5059651 -0.2539036; C 0.2355846 -2.0382203 0.3696479; O 0.5870862 -2.4771706 1.4540805; Cl 0.1349587 -0.2718086 -2.3358022; C 0.0008664 -3.0153971 -0.7782268; H -0.1231146 -4.0205893 -0.3660997; H 0.8774694 -2.9930708 -1.4340628; H -0.8449842 -2.7261204 -1.4026378; }. set reference rhf; set basis def2-TZVPP; set{; freeze_core false; cc_type df; mp2_type df; } . set{; e_convergence 1.0E-9; r_convergence 1.0E-8; max_mograd_convergence 1.0E-7; rms_mograd_convergence 1.0E-8; TPDM_ABCD_TYPE direct; mo_maxiter 200; }. energy('scf',write_orbitals='scf_mos'); energy('omp2',restart_file='scf_mos'). ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2591#issuecomment-1141902495
https://github.com/psi4/psi4/issues/2591#issuecomment-1141902495:253,Usability,simpl,simple,253,"Ouch, the problem cannot be reproduced with the current 1.5 release as the release version will die even much earlier with ``MemoryError: std::bad_array_new_length``. When calculating array lengths for ampiitudes, residua and density fitting b factors, simple int32 arithmethic is used, which overflows at some point. `new` is then called with a negative size. i fixed this already in my development branch... Input for reproducing the problem:; ```; memory 160 GB; molecule PR20 {; 0 1; Ir -0.0036453 -0.0067418 0.0546240; P 2.3412316 0.2633260 -0.0827666; C 2.8322725 1.6499560 -1.1514034; C 3.1508965 0.5810022 1.5225953; H 2.7397226 1.4975243 1.9544020; H 3.0796627 -2.0414912 -0.0970847; H 4.2325349 0.6920499 1.3971415; H 2.8126116 -1.4065392 -1.7435421; H 3.9236645 1.7279364 -1.1921940; H 2.9451701 -0.2527656 2.1998134; C 3.2265215 -1.1827248 -0.7571267; H 2.4227823 1.4722103 -2.1484758; H 4.2962318 -0.9681045 -0.8457994; H 2.3889675 2.5675955 -0.7590075; P -2.3731653 -0.0356822 -0.0699620; C -3.1396700 1.0016926 1.2209589; C -3.0094090 0.6380218 -1.6352816; H -2.9455753 -2.3068093 -0.7136733; H -4.2946110 -1.5213106 0.1442505; H -2.8800339 -2.1267692 1.0512420; C -3.2080716 -1.6536880 0.1215551; H -4.1029305 0.6851097 -1.6068349; H -2.5824278 1.6361161 -1.7615996; H -4.2216153 1.0653282 1.0682275; H -2.6891213 1.9959193 1.1600952; H -2.6744520 0.0098950 -2.4628143; H -2.9377790 0.5752071 2.2074361; C -0.0445914 0.2683835 1.8872601; O -0.0651117 0.4624335 3.0248963; Cl -0.3329573 2.5059651 -0.2539036; C 0.2355846 -2.0382203 0.3696479; O 0.5870862 -2.4771706 1.4540805; Cl 0.1349587 -0.2718086 -2.3358022; C 0.0008664 -3.0153971 -0.7782268; H -0.1231146 -4.0205893 -0.3660997; H 0.8774694 -2.9930708 -1.4340628; H -0.8449842 -2.7261204 -1.4026378; }. set reference rhf; set basis def2-TZVPP; set{; freeze_core false; cc_type df; mp2_type df; } . set{; e_convergence 1.0E-9; r_convergence 1.0E-8; max_mograd_convergence 1.0E-7; rms_mograd_convergence 1.0E-8; TPDM_ABCD_TYPE direct",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2591#issuecomment-1141902495
https://github.com/psi4/psi4/issues/2593#issuecomment-1145503237:51,Availability,fault,fault,51,"@zachglick reports he was able to get the same seg fault with just ; `conda create -n test_env4 -c psi4 python=3.7 psi4==1.5+e9f4d6d`; and ; ```; molecule mol {; 0 1 ; O ; H 1 1.0 ; H 1 1.0 2 109.5; }. set basis sto-3g; energy, wfn = energy(""HF"", return_wfn=True); ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2593#issuecomment-1145503237
https://github.com/psi4/psi4/issues/2593#issuecomment-1145503237:220,Energy Efficiency,energy,energy,220,"@zachglick reports he was able to get the same seg fault with just ; `conda create -n test_env4 -c psi4 python=3.7 psi4==1.5+e9f4d6d`; and ; ```; molecule mol {; 0 1 ; O ; H 1 1.0 ; H 1 1.0 2 109.5; }. set basis sto-3g; energy, wfn = energy(""HF"", return_wfn=True); ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2593#issuecomment-1145503237
https://github.com/psi4/psi4/issues/2593#issuecomment-1145503237:234,Energy Efficiency,energy,energy,234,"@zachglick reports he was able to get the same seg fault with just ; `conda create -n test_env4 -c psi4 python=3.7 psi4==1.5+e9f4d6d`; and ; ```; molecule mol {; 0 1 ; O ; H 1 1.0 ; H 1 1.0 2 109.5; }. set basis sto-3g; energy, wfn = energy(""HF"", return_wfn=True); ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2593#issuecomment-1145503237
https://github.com/psi4/psi4/issues/2593#issuecomment-1145503791:52,Deployability,install,install,52,"Are you definitely selecting the libint2 via `conda install psi4=1.5 libint2=*=hc9558a2_9 python=3.7 -c psi4`? I can definitely see a ""latest"" libint2 causing a segfault. The above cmd is from https://psicode.org/installs/v16/ with linux/conda/py37/previous selected. It's admittedly unexpected to not be able to use the installs/v15 cmd.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2593#issuecomment-1145503791
https://github.com/psi4/psi4/issues/2593#issuecomment-1145503791:213,Deployability,install,installs,213,"Are you definitely selecting the libint2 via `conda install psi4=1.5 libint2=*=hc9558a2_9 python=3.7 -c psi4`? I can definitely see a ""latest"" libint2 causing a segfault. The above cmd is from https://psicode.org/installs/v16/ with linux/conda/py37/previous selected. It's admittedly unexpected to not be able to use the installs/v15 cmd.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2593#issuecomment-1145503791
https://github.com/psi4/psi4/issues/2593#issuecomment-1145503791:321,Deployability,install,installs,321,"Are you definitely selecting the libint2 via `conda install psi4=1.5 libint2=*=hc9558a2_9 python=3.7 -c psi4`? I can definitely see a ""latest"" libint2 causing a segfault. The above cmd is from https://psicode.org/installs/v16/ with linux/conda/py37/previous selected. It's admittedly unexpected to not be able to use the installs/v15 cmd.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2593#issuecomment-1145503791
https://github.com/psi4/psi4/issues/2593#issuecomment-1146353841:29,Security,validat,validate,29,"Thank you @loriab!!! . I can validate that pinning libint2 fixes this on our Cloud platform as well, I'll close this case. ; Thanks again for addressing this so quickly!",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2593#issuecomment-1146353841
https://github.com/psi4/psi4/issues/2593#issuecomment-1146376321:8,Security,validat,validate,8,"> I can validate that pinning libint2 fixes this on our Cloud platform as well, I'll close this case.; Thanks again for addressing this so quickly!. Glad it's fixed. The Libint2 migration was bound to cause problems, so I'm glad you reported it. We started pinning psi4 conda packages to specific Libint2 builds earlier this year, so hopefully smoother future migrations.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2593#issuecomment-1146376321
https://github.com/psi4/psi4/issues/2593#issuecomment-1152600316:51,Deployability,release,release,51,"@loriab Thank you! We are still using 3.7 for this release, I'm planning to upgrade python in the next one.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2593#issuecomment-1152600316
https://github.com/psi4/psi4/issues/2593#issuecomment-1152600316:76,Deployability,upgrade,upgrade,76,"@loriab Thank you! We are still using 3.7 for this release, I'm planning to upgrade python in the next one.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2593#issuecomment-1152600316
https://github.com/psi4/psi4/issues/2594#issuecomment-1146678498:85,Availability,error,error-bug-in-,85,"Also, this is carried forward from [forums](http://forum.psicode.org/t/radical-anion-error-bug-in-1-6/2505/3).",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2594#issuecomment-1146678498
https://github.com/psi4/psi4/issues/2594#issuecomment-1147657283:26,Integrability,depend,dependent,26,"The bug is also basis set dependent (def2-SVPD runs fine in Psi4 1.3.2), which also points to this. As a workaround, this issue can probably be solved for this system by using a better initial guess.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2594#issuecomment-1147657283
https://github.com/psi4/psi4/issues/2594#issuecomment-1149297603:341,Energy Efficiency,efficient,efficient,341,"@sbembenek18 yes, this issue can either happen at random during the intermediate of solving SCF or by the physics of the ground state solution. If the issue is the latter, then you can't run the calculation with Psi4 at present. Also, I am not sure why you are using Dunning type basis sets for DFT; the pcseg-n or def2 series are much more efficient for SCF level calculations. I was able to converge the system in the def2-SVPD basis; I do not know if it converges in def2-TZVPD or def2-TZVPPD but I expect these solutions to be at least the same quality as the aug-cc-pVTZ result. Maybe the level splitting won't happen, maybe it will; you never know till you try. You may also to try out varying the occupations set by the initial guess, as well as testing other codes. If the calculation ran in version 1.5, the issue is not about the character of the ground state but simply that something has changed in the SCF code. If you fix the right occupations, the master branch should be able to find the same solution.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2594#issuecomment-1149297603
https://github.com/psi4/psi4/issues/2594#issuecomment-1149297603:753,Testability,test,testing,753,"@sbembenek18 yes, this issue can either happen at random during the intermediate of solving SCF or by the physics of the ground state solution. If the issue is the latter, then you can't run the calculation with Psi4 at present. Also, I am not sure why you are using Dunning type basis sets for DFT; the pcseg-n or def2 series are much more efficient for SCF level calculations. I was able to converge the system in the def2-SVPD basis; I do not know if it converges in def2-TZVPD or def2-TZVPPD but I expect these solutions to be at least the same quality as the aug-cc-pVTZ result. Maybe the level splitting won't happen, maybe it will; you never know till you try. You may also to try out varying the occupations set by the initial guess, as well as testing other codes. If the calculation ran in version 1.5, the issue is not about the character of the ground state but simply that something has changed in the SCF code. If you fix the right occupations, the master branch should be able to find the same solution.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2594#issuecomment-1149297603
https://github.com/psi4/psi4/issues/2594#issuecomment-1149297603:874,Usability,simpl,simply,874,"@sbembenek18 yes, this issue can either happen at random during the intermediate of solving SCF or by the physics of the ground state solution. If the issue is the latter, then you can't run the calculation with Psi4 at present. Also, I am not sure why you are using Dunning type basis sets for DFT; the pcseg-n or def2 series are much more efficient for SCF level calculations. I was able to converge the system in the def2-SVPD basis; I do not know if it converges in def2-TZVPD or def2-TZVPPD but I expect these solutions to be at least the same quality as the aug-cc-pVTZ result. Maybe the level splitting won't happen, maybe it will; you never know till you try. You may also to try out varying the occupations set by the initial guess, as well as testing other codes. If the calculation ran in version 1.5, the issue is not about the character of the ground state but simply that something has changed in the SCF code. If you fix the right occupations, the master branch should be able to find the same solution.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2594#issuecomment-1149297603
https://github.com/psi4/psi4/issues/2596#issuecomment-1151532059:458,Deployability,install,installation,458,"Acknowledged. Two problems, one solved, one not. * First issue is for v1.5 you have to grab a certain libint2 build as described here: https://github.com/psi4/psi4/issues/2593#issuecomment-1145503791 Probably you didn't get to the segfault the ""newest"" L2 would cause because the missing symbol got in the way. :-(; * Second issue is the missing symbol. I've seen it myself with py38. (It can incidentally be solved by preloading `libirc` if you've an Intel installation lying around (`LD_PRELOAD=/psi/gits/software/intel/oneapi/compiler/2021.1.1/linux/compiler/lib/intel64_lin/libirc.so python -c ""import psi4""` is clean), but that's not a worthy solution. But clearly the missing symbol wasn't happening in the earlier issue. Current theories:; * some newer version/build of a package got uploaded in the past week or so that throws off this env; * py37 _did not_ get updated versions of packages on the psi4 channel with the 1.6 release, so it's getting old, compatible versions of some psi4-channel based package and is fine, while py38 and py39 got a fresh package and got broken.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2596#issuecomment-1151532059
https://github.com/psi4/psi4/issues/2596#issuecomment-1151532059:870,Deployability,update,updated,870,"Acknowledged. Two problems, one solved, one not. * First issue is for v1.5 you have to grab a certain libint2 build as described here: https://github.com/psi4/psi4/issues/2593#issuecomment-1145503791 Probably you didn't get to the segfault the ""newest"" L2 would cause because the missing symbol got in the way. :-(; * Second issue is the missing symbol. I've seen it myself with py38. (It can incidentally be solved by preloading `libirc` if you've an Intel installation lying around (`LD_PRELOAD=/psi/gits/software/intel/oneapi/compiler/2021.1.1/linux/compiler/lib/intel64_lin/libirc.so python -c ""import psi4""` is clean), but that's not a worthy solution. But clearly the missing symbol wasn't happening in the earlier issue. Current theories:; * some newer version/build of a package got uploaded in the past week or so that throws off this env; * py37 _did not_ get updated versions of packages on the psi4 channel with the 1.6 release, so it's getting old, compatible versions of some psi4-channel based package and is fine, while py38 and py39 got a fresh package and got broken.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2596#issuecomment-1151532059
https://github.com/psi4/psi4/issues/2596#issuecomment-1151532059:932,Deployability,release,release,932,"Acknowledged. Two problems, one solved, one not. * First issue is for v1.5 you have to grab a certain libint2 build as described here: https://github.com/psi4/psi4/issues/2593#issuecomment-1145503791 Probably you didn't get to the segfault the ""newest"" L2 would cause because the missing symbol got in the way. :-(; * Second issue is the missing symbol. I've seen it myself with py38. (It can incidentally be solved by preloading `libirc` if you've an Intel installation lying around (`LD_PRELOAD=/psi/gits/software/intel/oneapi/compiler/2021.1.1/linux/compiler/lib/intel64_lin/libirc.so python -c ""import psi4""` is clean), but that's not a worthy solution. But clearly the missing symbol wasn't happening in the earlier issue. Current theories:; * some newer version/build of a package got uploaded in the past week or so that throws off this env; * py37 _did not_ get updated versions of packages on the psi4 channel with the 1.6 release, so it's getting old, compatible versions of some psi4-channel based package and is fine, while py38 and py39 got a fresh package and got broken.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2596#issuecomment-1151532059
https://github.com/psi4/psi4/issues/2596#issuecomment-1151532059:662,Usability,clear,clearly,662,"Acknowledged. Two problems, one solved, one not. * First issue is for v1.5 you have to grab a certain libint2 build as described here: https://github.com/psi4/psi4/issues/2593#issuecomment-1145503791 Probably you didn't get to the segfault the ""newest"" L2 would cause because the missing symbol got in the way. :-(; * Second issue is the missing symbol. I've seen it myself with py38. (It can incidentally be solved by preloading `libirc` if you've an Intel installation lying around (`LD_PRELOAD=/psi/gits/software/intel/oneapi/compiler/2021.1.1/linux/compiler/lib/intel64_lin/libirc.so python -c ""import psi4""` is clean), but that's not a worthy solution. But clearly the missing symbol wasn't happening in the earlier issue. Current theories:; * some newer version/build of a package got uploaded in the past week or so that throws off this env; * py37 _did not_ get updated versions of packages on the psi4 channel with the 1.6 release, so it's getting old, compatible versions of some psi4-channel based package and is fine, while py38 and py39 got a fresh package and got broken.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2596#issuecomment-1151532059
https://github.com/psi4/psi4/issues/2596#issuecomment-1151558412:587,Availability,down,download,587,"looks like pcmsolver is the culprit. add `psi4::libint2=*=hc9558a2_9 pytest=5 psi4::pcmsolver=*=py38h6d17ec8_2` to the env specs. py38 passes with that. note that you'll have to adjust the python version in the pcmsolver buildstring. Yes, v1.5 would be the primary victim. v1.6 is latest, so the newest-solving packages from `-c psi4` are built to work with it. Like wise v1.7.dev* and `-c psi4/label/dev`. In this case, v1.5 could have benefitted from more pins. For solid reproducibility, the psi4conda installers have the advantage. I'll have to add the add'l packages to the psicode download page command matrix.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2596#issuecomment-1151558412
https://github.com/psi4/psi4/issues/2596#issuecomment-1151558412:505,Deployability,install,installers,505,"looks like pcmsolver is the culprit. add `psi4::libint2=*=hc9558a2_9 pytest=5 psi4::pcmsolver=*=py38h6d17ec8_2` to the env specs. py38 passes with that. note that you'll have to adjust the python version in the pcmsolver buildstring. Yes, v1.5 would be the primary victim. v1.6 is latest, so the newest-solving packages from `-c psi4` are built to work with it. Like wise v1.7.dev* and `-c psi4/label/dev`. In this case, v1.5 could have benefitted from more pins. For solid reproducibility, the psi4conda installers have the advantage. I'll have to add the add'l packages to the psicode download page command matrix.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2596#issuecomment-1151558412
https://github.com/psi4/psi4/issues/2596#issuecomment-1151756100:346,Deployability,install,install,346,"For `conda` n00bs like myself who want a speclfic command to execute, your `Dockerfile` would now look like the following (using python3.9 since that is what comes with `miniconda3:4.10.3`). Can confirm this works. @loriab if you suggest any changes to the command below just let me know. ```docker; FROM continuumio/miniconda3:4.10.3; RUN conda install psi4=1.5 -c psi4 && \; conda install psi4::libint2=*=hc9558a2_9 pytest=5 psi4::pcmsolver=*=py39h6d17ec8_2 -c psi4; ```. > For solid reproducibility, the psi4conda installers have the advantage. What exactly do you mean by this? Is there a preferred way to install psi4 other than `conda install psi4=1.5 -c psi4`? Pardon my lack of depth with the nuances of conda distributions.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2596#issuecomment-1151756100
https://github.com/psi4/psi4/issues/2596#issuecomment-1151756100:383,Deployability,install,install,383,"For `conda` n00bs like myself who want a speclfic command to execute, your `Dockerfile` would now look like the following (using python3.9 since that is what comes with `miniconda3:4.10.3`). Can confirm this works. @loriab if you suggest any changes to the command below just let me know. ```docker; FROM continuumio/miniconda3:4.10.3; RUN conda install psi4=1.5 -c psi4 && \; conda install psi4::libint2=*=hc9558a2_9 pytest=5 psi4::pcmsolver=*=py39h6d17ec8_2 -c psi4; ```. > For solid reproducibility, the psi4conda installers have the advantage. What exactly do you mean by this? Is there a preferred way to install psi4 other than `conda install psi4=1.5 -c psi4`? Pardon my lack of depth with the nuances of conda distributions.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2596#issuecomment-1151756100
https://github.com/psi4/psi4/issues/2596#issuecomment-1151756100:517,Deployability,install,installers,517,"For `conda` n00bs like myself who want a speclfic command to execute, your `Dockerfile` would now look like the following (using python3.9 since that is what comes with `miniconda3:4.10.3`). Can confirm this works. @loriab if you suggest any changes to the command below just let me know. ```docker; FROM continuumio/miniconda3:4.10.3; RUN conda install psi4=1.5 -c psi4 && \; conda install psi4::libint2=*=hc9558a2_9 pytest=5 psi4::pcmsolver=*=py39h6d17ec8_2 -c psi4; ```. > For solid reproducibility, the psi4conda installers have the advantage. What exactly do you mean by this? Is there a preferred way to install psi4 other than `conda install psi4=1.5 -c psi4`? Pardon my lack of depth with the nuances of conda distributions.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2596#issuecomment-1151756100
https://github.com/psi4/psi4/issues/2596#issuecomment-1151756100:610,Deployability,install,install,610,"For `conda` n00bs like myself who want a speclfic command to execute, your `Dockerfile` would now look like the following (using python3.9 since that is what comes with `miniconda3:4.10.3`). Can confirm this works. @loriab if you suggest any changes to the command below just let me know. ```docker; FROM continuumio/miniconda3:4.10.3; RUN conda install psi4=1.5 -c psi4 && \; conda install psi4::libint2=*=hc9558a2_9 pytest=5 psi4::pcmsolver=*=py39h6d17ec8_2 -c psi4; ```. > For solid reproducibility, the psi4conda installers have the advantage. What exactly do you mean by this? Is there a preferred way to install psi4 other than `conda install psi4=1.5 -c psi4`? Pardon my lack of depth with the nuances of conda distributions.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2596#issuecomment-1151756100
https://github.com/psi4/psi4/issues/2596#issuecomment-1151756100:641,Deployability,install,install,641,"For `conda` n00bs like myself who want a speclfic command to execute, your `Dockerfile` would now look like the following (using python3.9 since that is what comes with `miniconda3:4.10.3`). Can confirm this works. @loriab if you suggest any changes to the command below just let me know. ```docker; FROM continuumio/miniconda3:4.10.3; RUN conda install psi4=1.5 -c psi4 && \; conda install psi4::libint2=*=hc9558a2_9 pytest=5 psi4::pcmsolver=*=py39h6d17ec8_2 -c psi4; ```. > For solid reproducibility, the psi4conda installers have the advantage. What exactly do you mean by this? Is there a preferred way to install psi4 other than `conda install psi4=1.5 -c psi4`? Pardon my lack of depth with the nuances of conda distributions.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2596#issuecomment-1151756100
https://github.com/psi4/psi4/issues/2596#issuecomment-1151767997:474,Deployability,install,install,474,"> For conda n00bs like myself who want a speclfic command to execute, your Dockerfile would now look like the following (using python3.9 since that is what comes with miniconda3:4.10.3). Can confirm this works. @loriab if you suggest any changes to the command below just let me know. You can do it all at once (in fact for new conda environments, it's always slightly preferred to use a single command line so that the solver knows all the requirements at once. so, `conda install psi4=1.5 python=3.9 libint2=*=hc9558a2_9 pytest=5 pcmsolver=*=py39h6d17ec8_2 -c psi4` should do nicely. >> For solid reproducibility, the psi4conda installers have the advantage. > What exactly do you mean by this? Is there a preferred way to install psi4 other than conda install psi4=1.5 -c psi4? Pardon my lack of depth with the nuances of conda distributions. oh, there's a single-file installer (""installer"" off https://psicode.org/installs/v16/) that fits the analogy `miniconda:""conda install python""::psi4conda:""conda install python psi4""` . Not what you'd want if psi4 is one of many changing envs, but it'd be fine for docker.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2596#issuecomment-1151767997
https://github.com/psi4/psi4/issues/2596#issuecomment-1151767997:630,Deployability,install,installers,630,"> For conda n00bs like myself who want a speclfic command to execute, your Dockerfile would now look like the following (using python3.9 since that is what comes with miniconda3:4.10.3). Can confirm this works. @loriab if you suggest any changes to the command below just let me know. You can do it all at once (in fact for new conda environments, it's always slightly preferred to use a single command line so that the solver knows all the requirements at once. so, `conda install psi4=1.5 python=3.9 libint2=*=hc9558a2_9 pytest=5 pcmsolver=*=py39h6d17ec8_2 -c psi4` should do nicely. >> For solid reproducibility, the psi4conda installers have the advantage. > What exactly do you mean by this? Is there a preferred way to install psi4 other than conda install psi4=1.5 -c psi4? Pardon my lack of depth with the nuances of conda distributions. oh, there's a single-file installer (""installer"" off https://psicode.org/installs/v16/) that fits the analogy `miniconda:""conda install python""::psi4conda:""conda install python psi4""` . Not what you'd want if psi4 is one of many changing envs, but it'd be fine for docker.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2596#issuecomment-1151767997
https://github.com/psi4/psi4/issues/2596#issuecomment-1151767997:725,Deployability,install,install,725,"> For conda n00bs like myself who want a speclfic command to execute, your Dockerfile would now look like the following (using python3.9 since that is what comes with miniconda3:4.10.3). Can confirm this works. @loriab if you suggest any changes to the command below just let me know. You can do it all at once (in fact for new conda environments, it's always slightly preferred to use a single command line so that the solver knows all the requirements at once. so, `conda install psi4=1.5 python=3.9 libint2=*=hc9558a2_9 pytest=5 pcmsolver=*=py39h6d17ec8_2 -c psi4` should do nicely. >> For solid reproducibility, the psi4conda installers have the advantage. > What exactly do you mean by this? Is there a preferred way to install psi4 other than conda install psi4=1.5 -c psi4? Pardon my lack of depth with the nuances of conda distributions. oh, there's a single-file installer (""installer"" off https://psicode.org/installs/v16/) that fits the analogy `miniconda:""conda install python""::psi4conda:""conda install python psi4""` . Not what you'd want if psi4 is one of many changing envs, but it'd be fine for docker.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2596#issuecomment-1151767997
https://github.com/psi4/psi4/issues/2596#issuecomment-1151767997:755,Deployability,install,install,755,"> For conda n00bs like myself who want a speclfic command to execute, your Dockerfile would now look like the following (using python3.9 since that is what comes with miniconda3:4.10.3). Can confirm this works. @loriab if you suggest any changes to the command below just let me know. You can do it all at once (in fact for new conda environments, it's always slightly preferred to use a single command line so that the solver knows all the requirements at once. so, `conda install psi4=1.5 python=3.9 libint2=*=hc9558a2_9 pytest=5 pcmsolver=*=py39h6d17ec8_2 -c psi4` should do nicely. >> For solid reproducibility, the psi4conda installers have the advantage. > What exactly do you mean by this? Is there a preferred way to install psi4 other than conda install psi4=1.5 -c psi4? Pardon my lack of depth with the nuances of conda distributions. oh, there's a single-file installer (""installer"" off https://psicode.org/installs/v16/) that fits the analogy `miniconda:""conda install python""::psi4conda:""conda install python psi4""` . Not what you'd want if psi4 is one of many changing envs, but it'd be fine for docker.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2596#issuecomment-1151767997
https://github.com/psi4/psi4/issues/2596#issuecomment-1151767997:872,Deployability,install,installer,872,"> For conda n00bs like myself who want a speclfic command to execute, your Dockerfile would now look like the following (using python3.9 since that is what comes with miniconda3:4.10.3). Can confirm this works. @loriab if you suggest any changes to the command below just let me know. You can do it all at once (in fact for new conda environments, it's always slightly preferred to use a single command line so that the solver knows all the requirements at once. so, `conda install psi4=1.5 python=3.9 libint2=*=hc9558a2_9 pytest=5 pcmsolver=*=py39h6d17ec8_2 -c psi4` should do nicely. >> For solid reproducibility, the psi4conda installers have the advantage. > What exactly do you mean by this? Is there a preferred way to install psi4 other than conda install psi4=1.5 -c psi4? Pardon my lack of depth with the nuances of conda distributions. oh, there's a single-file installer (""installer"" off https://psicode.org/installs/v16/) that fits the analogy `miniconda:""conda install python""::psi4conda:""conda install python psi4""` . Not what you'd want if psi4 is one of many changing envs, but it'd be fine for docker.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2596#issuecomment-1151767997
https://github.com/psi4/psi4/issues/2596#issuecomment-1151767997:884,Deployability,install,installer,884,"> For conda n00bs like myself who want a speclfic command to execute, your Dockerfile would now look like the following (using python3.9 since that is what comes with miniconda3:4.10.3). Can confirm this works. @loriab if you suggest any changes to the command below just let me know. You can do it all at once (in fact for new conda environments, it's always slightly preferred to use a single command line so that the solver knows all the requirements at once. so, `conda install psi4=1.5 python=3.9 libint2=*=hc9558a2_9 pytest=5 pcmsolver=*=py39h6d17ec8_2 -c psi4` should do nicely. >> For solid reproducibility, the psi4conda installers have the advantage. > What exactly do you mean by this? Is there a preferred way to install psi4 other than conda install psi4=1.5 -c psi4? Pardon my lack of depth with the nuances of conda distributions. oh, there's a single-file installer (""installer"" off https://psicode.org/installs/v16/) that fits the analogy `miniconda:""conda install python""::psi4conda:""conda install python psi4""` . Not what you'd want if psi4 is one of many changing envs, but it'd be fine for docker.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2596#issuecomment-1151767997
https://github.com/psi4/psi4/issues/2596#issuecomment-1151767997:919,Deployability,install,installs,919,"> For conda n00bs like myself who want a speclfic command to execute, your Dockerfile would now look like the following (using python3.9 since that is what comes with miniconda3:4.10.3). Can confirm this works. @loriab if you suggest any changes to the command below just let me know. You can do it all at once (in fact for new conda environments, it's always slightly preferred to use a single command line so that the solver knows all the requirements at once. so, `conda install psi4=1.5 python=3.9 libint2=*=hc9558a2_9 pytest=5 pcmsolver=*=py39h6d17ec8_2 -c psi4` should do nicely. >> For solid reproducibility, the psi4conda installers have the advantage. > What exactly do you mean by this? Is there a preferred way to install psi4 other than conda install psi4=1.5 -c psi4? Pardon my lack of depth with the nuances of conda distributions. oh, there's a single-file installer (""installer"" off https://psicode.org/installs/v16/) that fits the analogy `miniconda:""conda install python""::psi4conda:""conda install python psi4""` . Not what you'd want if psi4 is one of many changing envs, but it'd be fine for docker.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2596#issuecomment-1151767997
https://github.com/psi4/psi4/issues/2596#issuecomment-1151767997:974,Deployability,install,install,974,"> For conda n00bs like myself who want a speclfic command to execute, your Dockerfile would now look like the following (using python3.9 since that is what comes with miniconda3:4.10.3). Can confirm this works. @loriab if you suggest any changes to the command below just let me know. You can do it all at once (in fact for new conda environments, it's always slightly preferred to use a single command line so that the solver knows all the requirements at once. so, `conda install psi4=1.5 python=3.9 libint2=*=hc9558a2_9 pytest=5 pcmsolver=*=py39h6d17ec8_2 -c psi4` should do nicely. >> For solid reproducibility, the psi4conda installers have the advantage. > What exactly do you mean by this? Is there a preferred way to install psi4 other than conda install psi4=1.5 -c psi4? Pardon my lack of depth with the nuances of conda distributions. oh, there's a single-file installer (""installer"" off https://psicode.org/installs/v16/) that fits the analogy `miniconda:""conda install python""::psi4conda:""conda install python psi4""` . Not what you'd want if psi4 is one of many changing envs, but it'd be fine for docker.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2596#issuecomment-1151767997
https://github.com/psi4/psi4/issues/2596#issuecomment-1151767997:1008,Deployability,install,install,1008,"> For conda n00bs like myself who want a speclfic command to execute, your Dockerfile would now look like the following (using python3.9 since that is what comes with miniconda3:4.10.3). Can confirm this works. @loriab if you suggest any changes to the command below just let me know. You can do it all at once (in fact for new conda environments, it's always slightly preferred to use a single command line so that the solver knows all the requirements at once. so, `conda install psi4=1.5 python=3.9 libint2=*=hc9558a2_9 pytest=5 pcmsolver=*=py39h6d17ec8_2 -c psi4` should do nicely. >> For solid reproducibility, the psi4conda installers have the advantage. > What exactly do you mean by this? Is there a preferred way to install psi4 other than conda install psi4=1.5 -c psi4? Pardon my lack of depth with the nuances of conda distributions. oh, there's a single-file installer (""installer"" off https://psicode.org/installs/v16/) that fits the analogy `miniconda:""conda install python""::psi4conda:""conda install python psi4""` . Not what you'd want if psi4 is one of many changing envs, but it'd be fine for docker.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2596#issuecomment-1151767997
https://github.com/psi4/psi4/issues/2598#issuecomment-1152453242:560,Deployability,install,installing,560,"Hi, Sorry for your trouble. I haven't used Colab myself, but your commands look reasonable, and I don't see any red flags in your `conda list` (thanks for including that). Since you're seeing trouble, here's a few suggestions:; * I would ordinarily advise putting psi4 is a separate conda env, not the base one. That seems awkward in colab (has to be activated per cell!) but is a possibility, https://stackoverflow.com/questions/53031430/conda-environment-in-google-colab-google-colaboratory; * You're pulling a py37 miniconda, then updating everything, then installing a py38 psi4 into its base environment. That's not the smoothest path. I'd choose a py38 or py39 installer https://docs.conda.io/en/latest/miniconda.html#linux-installers, then don't update all the packages, and do install the psi4 of matching python.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2598#issuecomment-1152453242
https://github.com/psi4/psi4/issues/2598#issuecomment-1152453242:667,Deployability,install,installer,667,"Hi, Sorry for your trouble. I haven't used Colab myself, but your commands look reasonable, and I don't see any red flags in your `conda list` (thanks for including that). Since you're seeing trouble, here's a few suggestions:; * I would ordinarily advise putting psi4 is a separate conda env, not the base one. That seems awkward in colab (has to be activated per cell!) but is a possibility, https://stackoverflow.com/questions/53031430/conda-environment-in-google-colab-google-colaboratory; * You're pulling a py37 miniconda, then updating everything, then installing a py38 psi4 into its base environment. That's not the smoothest path. I'd choose a py38 or py39 installer https://docs.conda.io/en/latest/miniconda.html#linux-installers, then don't update all the packages, and do install the psi4 of matching python.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2598#issuecomment-1152453242
https://github.com/psi4/psi4/issues/2598#issuecomment-1152453242:730,Deployability,install,installers,730,"Hi, Sorry for your trouble. I haven't used Colab myself, but your commands look reasonable, and I don't see any red flags in your `conda list` (thanks for including that). Since you're seeing trouble, here's a few suggestions:; * I would ordinarily advise putting psi4 is a separate conda env, not the base one. That seems awkward in colab (has to be activated per cell!) but is a possibility, https://stackoverflow.com/questions/53031430/conda-environment-in-google-colab-google-colaboratory; * You're pulling a py37 miniconda, then updating everything, then installing a py38 psi4 into its base environment. That's not the smoothest path. I'd choose a py38 or py39 installer https://docs.conda.io/en/latest/miniconda.html#linux-installers, then don't update all the packages, and do install the psi4 of matching python.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2598#issuecomment-1152453242
https://github.com/psi4/psi4/issues/2598#issuecomment-1152453242:753,Deployability,update,update,753,"Hi, Sorry for your trouble. I haven't used Colab myself, but your commands look reasonable, and I don't see any red flags in your `conda list` (thanks for including that). Since you're seeing trouble, here's a few suggestions:; * I would ordinarily advise putting psi4 is a separate conda env, not the base one. That seems awkward in colab (has to be activated per cell!) but is a possibility, https://stackoverflow.com/questions/53031430/conda-environment-in-google-colab-google-colaboratory; * You're pulling a py37 miniconda, then updating everything, then installing a py38 psi4 into its base environment. That's not the smoothest path. I'd choose a py38 or py39 installer https://docs.conda.io/en/latest/miniconda.html#linux-installers, then don't update all the packages, and do install the psi4 of matching python.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2598#issuecomment-1152453242
https://github.com/psi4/psi4/issues/2598#issuecomment-1152453242:785,Deployability,install,install,785,"Hi, Sorry for your trouble. I haven't used Colab myself, but your commands look reasonable, and I don't see any red flags in your `conda list` (thanks for including that). Since you're seeing trouble, here's a few suggestions:; * I would ordinarily advise putting psi4 is a separate conda env, not the base one. That seems awkward in colab (has to be activated per cell!) but is a possibility, https://stackoverflow.com/questions/53031430/conda-environment-in-google-colab-google-colaboratory; * You're pulling a py37 miniconda, then updating everything, then installing a py38 psi4 into its base environment. That's not the smoothest path. I'd choose a py38 or py39 installer https://docs.conda.io/en/latest/miniconda.html#linux-installers, then don't update all the packages, and do install the psi4 of matching python.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2598#issuecomment-1152453242
https://github.com/psi4/psi4/issues/2598#issuecomment-1152894724:381,Availability,error,errors,381,"Hi, thank you very much for your response. > I would ordinarily advise putting psi4 is a separate conda env, not the base one. That seems awkward in colab (has to be activated per cell!) but is a possibility, https://stackoverflow.com/questions/53031430/conda-environment-in-google-colab-google-colaboratory. I tried this and am able to install psi4 and even import it without any errors. [psi4-test.txt](https://github.com/psi4/psi4/files/8883628/psi4-test.txt) contains the results of `psi4 --test`; kindly let me know if this mean that psi4 is in functional state.; Here is the `conda list` output in case it is needed.; [psi4-env_conda-list.txt](https://github.com/psi4/psi4/files/8883643/psi4-env_conda-list.txt). Now I have some compatibility issues against python3.8 but that's with other packages I am trying to use. Just to make sure, psi4 is no longer supported on python3.7, right?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2598#issuecomment-1152894724
https://github.com/psi4/psi4/issues/2598#issuecomment-1152894724:337,Deployability,install,install,337,"Hi, thank you very much for your response. > I would ordinarily advise putting psi4 is a separate conda env, not the base one. That seems awkward in colab (has to be activated per cell!) but is a possibility, https://stackoverflow.com/questions/53031430/conda-environment-in-google-colab-google-colaboratory. I tried this and am able to install psi4 and even import it without any errors. [psi4-test.txt](https://github.com/psi4/psi4/files/8883628/psi4-test.txt) contains the results of `psi4 --test`; kindly let me know if this mean that psi4 is in functional state.; Here is the `conda list` output in case it is needed.; [psi4-env_conda-list.txt](https://github.com/psi4/psi4/files/8883643/psi4-env_conda-list.txt). Now I have some compatibility issues against python3.8 but that's with other packages I am trying to use. Just to make sure, psi4 is no longer supported on python3.7, right?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2598#issuecomment-1152894724
https://github.com/psi4/psi4/issues/2598#issuecomment-1152894724:395,Testability,test,test,395,"Hi, thank you very much for your response. > I would ordinarily advise putting psi4 is a separate conda env, not the base one. That seems awkward in colab (has to be activated per cell!) but is a possibility, https://stackoverflow.com/questions/53031430/conda-environment-in-google-colab-google-colaboratory. I tried this and am able to install psi4 and even import it without any errors. [psi4-test.txt](https://github.com/psi4/psi4/files/8883628/psi4-test.txt) contains the results of `psi4 --test`; kindly let me know if this mean that psi4 is in functional state.; Here is the `conda list` output in case it is needed.; [psi4-env_conda-list.txt](https://github.com/psi4/psi4/files/8883643/psi4-env_conda-list.txt). Now I have some compatibility issues against python3.8 but that's with other packages I am trying to use. Just to make sure, psi4 is no longer supported on python3.7, right?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2598#issuecomment-1152894724
https://github.com/psi4/psi4/issues/2598#issuecomment-1152894724:453,Testability,test,test,453,"Hi, thank you very much for your response. > I would ordinarily advise putting psi4 is a separate conda env, not the base one. That seems awkward in colab (has to be activated per cell!) but is a possibility, https://stackoverflow.com/questions/53031430/conda-environment-in-google-colab-google-colaboratory. I tried this and am able to install psi4 and even import it without any errors. [psi4-test.txt](https://github.com/psi4/psi4/files/8883628/psi4-test.txt) contains the results of `psi4 --test`; kindly let me know if this mean that psi4 is in functional state.; Here is the `conda list` output in case it is needed.; [psi4-env_conda-list.txt](https://github.com/psi4/psi4/files/8883643/psi4-env_conda-list.txt). Now I have some compatibility issues against python3.8 but that's with other packages I am trying to use. Just to make sure, psi4 is no longer supported on python3.7, right?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2598#issuecomment-1152894724
https://github.com/psi4/psi4/issues/2598#issuecomment-1152894724:495,Testability,test,test,495,"Hi, thank you very much for your response. > I would ordinarily advise putting psi4 is a separate conda env, not the base one. That seems awkward in colab (has to be activated per cell!) but is a possibility, https://stackoverflow.com/questions/53031430/conda-environment-in-google-colab-google-colaboratory. I tried this and am able to install psi4 and even import it without any errors. [psi4-test.txt](https://github.com/psi4/psi4/files/8883628/psi4-test.txt) contains the results of `psi4 --test`; kindly let me know if this mean that psi4 is in functional state.; Here is the `conda list` output in case it is needed.; [psi4-env_conda-list.txt](https://github.com/psi4/psi4/files/8883643/psi4-env_conda-list.txt). Now I have some compatibility issues against python3.8 but that's with other packages I am trying to use. Just to make sure, psi4 is no longer supported on python3.7, right?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2598#issuecomment-1152894724
https://github.com/psi4/psi4/issues/2598#issuecomment-1152920803:1089,Availability,down,down,1089,"> [psi4-test.txt](https://github.com/psi4/psi4/files/8883628/psi4-test.txt) contains the results of `psi4 --test` kindly let me know if this mean that psi4 is in functional state. Here is the `conda list` output in case it is needed. [psi4-env_conda-list.txt](https://github.com/psi4/psi4/files/8883643/psi4-env_conda-list.txt). Yes, the base Psi4 is functional. All the messages about skipped tests indicate that there are addons that Psi4 _has_ but that your Psi4 installation isn't detecting as installed. Based on your conda list, these are probably not installed, so this behavior is expected. Let us know if there are addons that you need but don't know how to get. (Examples: `dftd4` for DFT dispersion corrections, `cct3` for some exotic coupled cluster variants, `cppe` for polarizable embedding.). > Now I have some compatibility issues against python3.8 but that's with other packages I am trying to use.; > ; > Just to make sure, psi4 is no longer supported on python3.7, right?. The latest Psi4 is no longer supported on Python 3.7, correct. If you need 3.7 support, dropping down to Psi4 1.5 is technically an option.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2598#issuecomment-1152920803
https://github.com/psi4/psi4/issues/2598#issuecomment-1152920803:466,Deployability,install,installation,466,"> [psi4-test.txt](https://github.com/psi4/psi4/files/8883628/psi4-test.txt) contains the results of `psi4 --test` kindly let me know if this mean that psi4 is in functional state. Here is the `conda list` output in case it is needed. [psi4-env_conda-list.txt](https://github.com/psi4/psi4/files/8883643/psi4-env_conda-list.txt). Yes, the base Psi4 is functional. All the messages about skipped tests indicate that there are addons that Psi4 _has_ but that your Psi4 installation isn't detecting as installed. Based on your conda list, these are probably not installed, so this behavior is expected. Let us know if there are addons that you need but don't know how to get. (Examples: `dftd4` for DFT dispersion corrections, `cct3` for some exotic coupled cluster variants, `cppe` for polarizable embedding.). > Now I have some compatibility issues against python3.8 but that's with other packages I am trying to use.; > ; > Just to make sure, psi4 is no longer supported on python3.7, right?. The latest Psi4 is no longer supported on Python 3.7, correct. If you need 3.7 support, dropping down to Psi4 1.5 is technically an option.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2598#issuecomment-1152920803
https://github.com/psi4/psi4/issues/2598#issuecomment-1152920803:498,Deployability,install,installed,498,"> [psi4-test.txt](https://github.com/psi4/psi4/files/8883628/psi4-test.txt) contains the results of `psi4 --test` kindly let me know if this mean that psi4 is in functional state. Here is the `conda list` output in case it is needed. [psi4-env_conda-list.txt](https://github.com/psi4/psi4/files/8883643/psi4-env_conda-list.txt). Yes, the base Psi4 is functional. All the messages about skipped tests indicate that there are addons that Psi4 _has_ but that your Psi4 installation isn't detecting as installed. Based on your conda list, these are probably not installed, so this behavior is expected. Let us know if there are addons that you need but don't know how to get. (Examples: `dftd4` for DFT dispersion corrections, `cct3` for some exotic coupled cluster variants, `cppe` for polarizable embedding.). > Now I have some compatibility issues against python3.8 but that's with other packages I am trying to use.; > ; > Just to make sure, psi4 is no longer supported on python3.7, right?. The latest Psi4 is no longer supported on Python 3.7, correct. If you need 3.7 support, dropping down to Psi4 1.5 is technically an option.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2598#issuecomment-1152920803
https://github.com/psi4/psi4/issues/2598#issuecomment-1152920803:558,Deployability,install,installed,558,"> [psi4-test.txt](https://github.com/psi4/psi4/files/8883628/psi4-test.txt) contains the results of `psi4 --test` kindly let me know if this mean that psi4 is in functional state. Here is the `conda list` output in case it is needed. [psi4-env_conda-list.txt](https://github.com/psi4/psi4/files/8883643/psi4-env_conda-list.txt). Yes, the base Psi4 is functional. All the messages about skipped tests indicate that there are addons that Psi4 _has_ but that your Psi4 installation isn't detecting as installed. Based on your conda list, these are probably not installed, so this behavior is expected. Let us know if there are addons that you need but don't know how to get. (Examples: `dftd4` for DFT dispersion corrections, `cct3` for some exotic coupled cluster variants, `cppe` for polarizable embedding.). > Now I have some compatibility issues against python3.8 but that's with other packages I am trying to use.; > ; > Just to make sure, psi4 is no longer supported on python3.7, right?. The latest Psi4 is no longer supported on Python 3.7, correct. If you need 3.7 support, dropping down to Psi4 1.5 is technically an option.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2598#issuecomment-1152920803
https://github.com/psi4/psi4/issues/2598#issuecomment-1152920803:371,Integrability,message,messages,371,"> [psi4-test.txt](https://github.com/psi4/psi4/files/8883628/psi4-test.txt) contains the results of `psi4 --test` kindly let me know if this mean that psi4 is in functional state. Here is the `conda list` output in case it is needed. [psi4-env_conda-list.txt](https://github.com/psi4/psi4/files/8883643/psi4-env_conda-list.txt). Yes, the base Psi4 is functional. All the messages about skipped tests indicate that there are addons that Psi4 _has_ but that your Psi4 installation isn't detecting as installed. Based on your conda list, these are probably not installed, so this behavior is expected. Let us know if there are addons that you need but don't know how to get. (Examples: `dftd4` for DFT dispersion corrections, `cct3` for some exotic coupled cluster variants, `cppe` for polarizable embedding.). > Now I have some compatibility issues against python3.8 but that's with other packages I am trying to use.; > ; > Just to make sure, psi4 is no longer supported on python3.7, right?. The latest Psi4 is no longer supported on Python 3.7, correct. If you need 3.7 support, dropping down to Psi4 1.5 is technically an option.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2598#issuecomment-1152920803
https://github.com/psi4/psi4/issues/2598#issuecomment-1152920803:485,Safety,detect,detecting,485,"> [psi4-test.txt](https://github.com/psi4/psi4/files/8883628/psi4-test.txt) contains the results of `psi4 --test` kindly let me know if this mean that psi4 is in functional state. Here is the `conda list` output in case it is needed. [psi4-env_conda-list.txt](https://github.com/psi4/psi4/files/8883643/psi4-env_conda-list.txt). Yes, the base Psi4 is functional. All the messages about skipped tests indicate that there are addons that Psi4 _has_ but that your Psi4 installation isn't detecting as installed. Based on your conda list, these are probably not installed, so this behavior is expected. Let us know if there are addons that you need but don't know how to get. (Examples: `dftd4` for DFT dispersion corrections, `cct3` for some exotic coupled cluster variants, `cppe` for polarizable embedding.). > Now I have some compatibility issues against python3.8 but that's with other packages I am trying to use.; > ; > Just to make sure, psi4 is no longer supported on python3.7, right?. The latest Psi4 is no longer supported on Python 3.7, correct. If you need 3.7 support, dropping down to Psi4 1.5 is technically an option.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2598#issuecomment-1152920803
https://github.com/psi4/psi4/issues/2598#issuecomment-1152920803:8,Testability,test,test,8,"> [psi4-test.txt](https://github.com/psi4/psi4/files/8883628/psi4-test.txt) contains the results of `psi4 --test` kindly let me know if this mean that psi4 is in functional state. Here is the `conda list` output in case it is needed. [psi4-env_conda-list.txt](https://github.com/psi4/psi4/files/8883643/psi4-env_conda-list.txt). Yes, the base Psi4 is functional. All the messages about skipped tests indicate that there are addons that Psi4 _has_ but that your Psi4 installation isn't detecting as installed. Based on your conda list, these are probably not installed, so this behavior is expected. Let us know if there are addons that you need but don't know how to get. (Examples: `dftd4` for DFT dispersion corrections, `cct3` for some exotic coupled cluster variants, `cppe` for polarizable embedding.). > Now I have some compatibility issues against python3.8 but that's with other packages I am trying to use.; > ; > Just to make sure, psi4 is no longer supported on python3.7, right?. The latest Psi4 is no longer supported on Python 3.7, correct. If you need 3.7 support, dropping down to Psi4 1.5 is technically an option.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2598#issuecomment-1152920803
https://github.com/psi4/psi4/issues/2598#issuecomment-1152920803:66,Testability,test,test,66,"> [psi4-test.txt](https://github.com/psi4/psi4/files/8883628/psi4-test.txt) contains the results of `psi4 --test` kindly let me know if this mean that psi4 is in functional state. Here is the `conda list` output in case it is needed. [psi4-env_conda-list.txt](https://github.com/psi4/psi4/files/8883643/psi4-env_conda-list.txt). Yes, the base Psi4 is functional. All the messages about skipped tests indicate that there are addons that Psi4 _has_ but that your Psi4 installation isn't detecting as installed. Based on your conda list, these are probably not installed, so this behavior is expected. Let us know if there are addons that you need but don't know how to get. (Examples: `dftd4` for DFT dispersion corrections, `cct3` for some exotic coupled cluster variants, `cppe` for polarizable embedding.). > Now I have some compatibility issues against python3.8 but that's with other packages I am trying to use.; > ; > Just to make sure, psi4 is no longer supported on python3.7, right?. The latest Psi4 is no longer supported on Python 3.7, correct. If you need 3.7 support, dropping down to Psi4 1.5 is technically an option.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2598#issuecomment-1152920803
https://github.com/psi4/psi4/issues/2598#issuecomment-1152920803:108,Testability,test,test,108,"> [psi4-test.txt](https://github.com/psi4/psi4/files/8883628/psi4-test.txt) contains the results of `psi4 --test` kindly let me know if this mean that psi4 is in functional state. Here is the `conda list` output in case it is needed. [psi4-env_conda-list.txt](https://github.com/psi4/psi4/files/8883643/psi4-env_conda-list.txt). Yes, the base Psi4 is functional. All the messages about skipped tests indicate that there are addons that Psi4 _has_ but that your Psi4 installation isn't detecting as installed. Based on your conda list, these are probably not installed, so this behavior is expected. Let us know if there are addons that you need but don't know how to get. (Examples: `dftd4` for DFT dispersion corrections, `cct3` for some exotic coupled cluster variants, `cppe` for polarizable embedding.). > Now I have some compatibility issues against python3.8 but that's with other packages I am trying to use.; > ; > Just to make sure, psi4 is no longer supported on python3.7, right?. The latest Psi4 is no longer supported on Python 3.7, correct. If you need 3.7 support, dropping down to Psi4 1.5 is technically an option.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2598#issuecomment-1152920803
https://github.com/psi4/psi4/issues/2598#issuecomment-1152920803:394,Testability,test,tests,394,"> [psi4-test.txt](https://github.com/psi4/psi4/files/8883628/psi4-test.txt) contains the results of `psi4 --test` kindly let me know if this mean that psi4 is in functional state. Here is the `conda list` output in case it is needed. [psi4-env_conda-list.txt](https://github.com/psi4/psi4/files/8883643/psi4-env_conda-list.txt). Yes, the base Psi4 is functional. All the messages about skipped tests indicate that there are addons that Psi4 _has_ but that your Psi4 installation isn't detecting as installed. Based on your conda list, these are probably not installed, so this behavior is expected. Let us know if there are addons that you need but don't know how to get. (Examples: `dftd4` for DFT dispersion corrections, `cct3` for some exotic coupled cluster variants, `cppe` for polarizable embedding.). > Now I have some compatibility issues against python3.8 but that's with other packages I am trying to use.; > ; > Just to make sure, psi4 is no longer supported on python3.7, right?. The latest Psi4 is no longer supported on Python 3.7, correct. If you need 3.7 support, dropping down to Psi4 1.5 is technically an option.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2598#issuecomment-1152920803
https://github.com/psi4/psi4/issues/2598#issuecomment-1154722714:350,Integrability,depend,dependencies,350,"Hi @JonathonMisiewicz ; Thank you for your response. > Let us know if there are addons that you need but don't know how to get. (Examples: dftd4 for DFT dispersion corrections, cct3 for some exotic coupled cluster variants, cppe for polarizable embedding.). I am using psi4 through geomeTRIC to minimize the structures of small molecules.; The other dependencies which I had mentioned earlier was to generate the input file (.in file) for the minimization; `geometric-optimize --psi4 <input.in>`. I am able to do this as long as I provide the `input.in` file, i.e. psi4 is working just fine for me. So thanks a lot @loriab and @JonathonMisiewicz",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2598#issuecomment-1154722714
https://github.com/psi4/psi4/issues/2598#issuecomment-1154722714:468,Performance,optimiz,optimize,468,"Hi @JonathonMisiewicz ; Thank you for your response. > Let us know if there are addons that you need but don't know how to get. (Examples: dftd4 for DFT dispersion corrections, cct3 for some exotic coupled cluster variants, cppe for polarizable embedding.). I am using psi4 through geomeTRIC to minimize the structures of small molecules.; The other dependencies which I had mentioned earlier was to generate the input file (.in file) for the minimization; `geometric-optimize --psi4 <input.in>`. I am able to do this as long as I provide the `input.in` file, i.e. psi4 is working just fine for me. So thanks a lot @loriab and @JonathonMisiewicz",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2598#issuecomment-1154722714
https://github.com/psi4/psi4/issues/2599#issuecomment-1152532615:39,Performance,optimiz,optimizer,39,"Psi4 is fine with cyclic mols, but the optimizer could benefit from a @psi-rking consult. We're in the middle of switching out optimizer implementations, btw. Are you able to post your input file?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2599#issuecomment-1152532615
https://github.com/psi4/psi4/issues/2599#issuecomment-1152532615:127,Performance,optimiz,optimizer,127,"Psi4 is fine with cyclic mols, but the optimizer could benefit from a @psi-rking consult. We're in the middle of switching out optimizer implementations, btw. Are you able to post your input file?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2599#issuecomment-1152532615
https://github.com/psi4/psi4/issues/2599#issuecomment-1152583288:83,Availability,error,error,83,"actually i cant even produce the input file for psi4 using FFParam-GUI i have this error:. `WARNING:root:Support for bonded parameter scan with Psi4 is experimental at best. Proceed with caution.; INFO:root:Using default names for the outputs.; [09:59:35] Molecule does not have explicit Hs. Consider calling AddHs(); ERROR:root:Uncaught Exception; Traceback (most recent call last):; File ""/home/ibrahim/miniconda3/envs/ffpenv/lib/python3.8/site-packages/ffparam-1.0.0-py3.8.egg/ffparam/FFPMainWindow.py"", line 1297, in execute_56; file2disp = self.chk.CreateQM(""dihe"",filein=coor,work_dir=self.qm_dir,recenter=False,qmeng=qmengi,qmtop=qmtop,char=chari,mult=multi,dihatomnam=dihl,dihrange=dihr); File ""/home/ibrahim/miniconda3/envs/ffpenv/lib/python3.8/site-packages/ffparam-1.0.0-py3.8.egg/ffparam/Windowsaction.py"", line 165, in CreateQM; fileout=piwclass.run('bondedscan',outpath=work_dir,bonded=[bonded],coor=self.coords,fixed=False); File ""/home/ibrahim/miniconda3/envs/ffpenv/lib/python3.8/site-packages/ffparam-1.0.0-py3.8.egg/ffparam/script_core/Psi4InputWriter.py"", line 307, in run; writtenfile=func(data,Psi4header); File ""/home/ibrahim/miniconda3/envs/ffpenv/lib/python3.8/site-packages/ffparam-1.0.0-py3.8.egg/ffparam/script_core/Psi4InputWriter.py"", line 564, in writebondedscan; rdcrds=ffrd.MolTransform(rdmol.mol,self.resn,self.reschrg,coor,self.atomnames,self.atomnrmap,self.topo['bondnames'],\; File ""/home/ibrahim/miniconda3/envs/ffpenv/lib/python3.8/site-packages/ffparam-1.0.0-py3.8.egg/ffparam/script_core/ffp_rdkit.py"", line 182, in __init__; self.__transform(); File ""/home/ibrahim/miniconda3/envs/ffpenv/lib/python3.8/site-packages/ffparam-1.0.0-py3.8.egg/ffparam/script_core/ffp_rdkit.py"", line 288, in __transform; newcoor=self.__transformcore(mol,self.coor,self.changetype,self.scanatomnr,values[val]); File ""/home/ibrahim/miniconda3/envs/ffpenv/lib/python3.8/site-packages/ffparam-1.0.0-py3.8.egg/ffparam/script_core/ffp_rdkit.py"", line 259, in __transformcore; funcs[cha",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2599#issuecomment-1152583288
https://github.com/psi4/psi4/issues/2599#issuecomment-1152583288:318,Availability,ERROR,ERROR,318,"actually i cant even produce the input file for psi4 using FFParam-GUI i have this error:. `WARNING:root:Support for bonded parameter scan with Psi4 is experimental at best. Proceed with caution.; INFO:root:Using default names for the outputs.; [09:59:35] Molecule does not have explicit Hs. Consider calling AddHs(); ERROR:root:Uncaught Exception; Traceback (most recent call last):; File ""/home/ibrahim/miniconda3/envs/ffpenv/lib/python3.8/site-packages/ffparam-1.0.0-py3.8.egg/ffparam/FFPMainWindow.py"", line 1297, in execute_56; file2disp = self.chk.CreateQM(""dihe"",filein=coor,work_dir=self.qm_dir,recenter=False,qmeng=qmengi,qmtop=qmtop,char=chari,mult=multi,dihatomnam=dihl,dihrange=dihr); File ""/home/ibrahim/miniconda3/envs/ffpenv/lib/python3.8/site-packages/ffparam-1.0.0-py3.8.egg/ffparam/Windowsaction.py"", line 165, in CreateQM; fileout=piwclass.run('bondedscan',outpath=work_dir,bonded=[bonded],coor=self.coords,fixed=False); File ""/home/ibrahim/miniconda3/envs/ffpenv/lib/python3.8/site-packages/ffparam-1.0.0-py3.8.egg/ffparam/script_core/Psi4InputWriter.py"", line 307, in run; writtenfile=func(data,Psi4header); File ""/home/ibrahim/miniconda3/envs/ffpenv/lib/python3.8/site-packages/ffparam-1.0.0-py3.8.egg/ffparam/script_core/Psi4InputWriter.py"", line 564, in writebondedscan; rdcrds=ffrd.MolTransform(rdmol.mol,self.resn,self.reschrg,coor,self.atomnames,self.atomnrmap,self.topo['bondnames'],\; File ""/home/ibrahim/miniconda3/envs/ffpenv/lib/python3.8/site-packages/ffparam-1.0.0-py3.8.egg/ffparam/script_core/ffp_rdkit.py"", line 182, in __init__; self.__transform(); File ""/home/ibrahim/miniconda3/envs/ffpenv/lib/python3.8/site-packages/ffparam-1.0.0-py3.8.egg/ffparam/script_core/ffp_rdkit.py"", line 288, in __transform; newcoor=self.__transformcore(mol,self.coor,self.changetype,self.scanatomnr,values[val]); File ""/home/ibrahim/miniconda3/envs/ffpenv/lib/python3.8/site-packages/ffparam-1.0.0-py3.8.egg/ffparam/script_core/ffp_rdkit.py"", line 259, in __transformcore; funcs[cha",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2599#issuecomment-1152583288
https://github.com/psi4/psi4/issues/2600#issuecomment-1152547044:446,Availability,avail,available,446,"From psi4 command-line, default cores is 1 and more added by `-n <cores>`. From qcengine, default is all-the-machine-has and user adjusted by `local_options` (maybe name changed). The former is a traditional research code expectation and reasoning -- this is a cutting-edge and semistable code that I'm going to run cautiously at first before trying for speed. The latter is more consumer software expectation -- do your fastest on the resources available. Would that explain what you're seeing?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2600#issuecomment-1152547044
https://github.com/psi4/psi4/issues/2600#issuecomment-1152555475:187,Modifiability,config,config,187,"Can confirm `qcengine` uses the number of physical cores on a machine by default, as seen [here](https://github.com/MolSSI/QCEngine/blob/c171e80c51afc5bc08ac8a84971b526fd33671d3/qcengine/config.py#L43-L46). Running psi4 with `8` threads (I have 8 logical CPU cores) produces similar performance:. ```sh; time qcengine run psi4 caffeine.json > qcng_out.json ; qcengine run psi4 caffeine.json > qcng_out.json 45.94s user 1.78s system 578% cpu 8.249 total; time psi4 -n 8 --qcschema -i caffeine.json -o psi4_out.json ; psi4 -n 8 --qcschema -i caffeine.json -o psi4_out.json 67.32s user 1.73s system 680% cpu 10.142 total; time psi4 -n 8 --qcschema -i caffeine.json -o psi4_out.json ; psi4 -n 8 --qcschema -i caffeine.json -o psi4_out.json 53.52s user 1.06s system 701% cpu 7.781 total; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2600#issuecomment-1152555475
https://github.com/psi4/psi4/issues/2600#issuecomment-1152555475:283,Performance,perform,performance,283,"Can confirm `qcengine` uses the number of physical cores on a machine by default, as seen [here](https://github.com/MolSSI/QCEngine/blob/c171e80c51afc5bc08ac8a84971b526fd33671d3/qcengine/config.py#L43-L46). Running psi4 with `8` threads (I have 8 logical CPU cores) produces similar performance:. ```sh; time qcengine run psi4 caffeine.json > qcng_out.json ; qcengine run psi4 caffeine.json > qcng_out.json 45.94s user 1.78s system 578% cpu 8.249 total; time psi4 -n 8 --qcschema -i caffeine.json -o psi4_out.json ; psi4 -n 8 --qcschema -i caffeine.json -o psi4_out.json 67.32s user 1.73s system 680% cpu 10.142 total; time psi4 -n 8 --qcschema -i caffeine.json -o psi4_out.json ; psi4 -n 8 --qcschema -i caffeine.json -o psi4_out.json 53.52s user 1.06s system 701% cpu 7.781 total; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2600#issuecomment-1152555475
https://github.com/psi4/psi4/issues/2600#issuecomment-1152555475:247,Testability,log,logical,247,"Can confirm `qcengine` uses the number of physical cores on a machine by default, as seen [here](https://github.com/MolSSI/QCEngine/blob/c171e80c51afc5bc08ac8a84971b526fd33671d3/qcengine/config.py#L43-L46). Running psi4 with `8` threads (I have 8 logical CPU cores) produces similar performance:. ```sh; time qcengine run psi4 caffeine.json > qcng_out.json ; qcengine run psi4 caffeine.json > qcng_out.json 45.94s user 1.78s system 578% cpu 8.249 total; time psi4 -n 8 --qcschema -i caffeine.json -o psi4_out.json ; psi4 -n 8 --qcschema -i caffeine.json -o psi4_out.json 67.32s user 1.73s system 680% cpu 10.142 total; time psi4 -n 8 --qcschema -i caffeine.json -o psi4_out.json ; psi4 -n 8 --qcschema -i caffeine.json -o psi4_out.json 53.52s user 1.06s system 701% cpu 7.781 total; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2600#issuecomment-1152555475
https://github.com/psi4/psi4/issues/2601#issuecomment-1152763335:328,Deployability,install,installation,328,"Quick notes on timer.dat; * the file is cummulative so run each calc in separate directory so you can match an input file with a timer.dat entry; * timer.dat is mostly for developers so it has just enough info to identify things but not much description; * if you're willing to compile the code (for c-side entries) or edit the installation (for py-side entries), adding more subdivisions to timer.dat is easy; * py-side, have matching labels like https://github.com/psi4/psi4/blob/master/psi4/driver/procrouting/scf_proc/scf_iterator.py#L196-L198; * c-side, have matching entries like https://github.com/psi4/psi4/blob/master/psi4/src/psi4/dfmp2/mp2.cc#L219-L221; * for a single run, timer.dat shows the same info two ways -- ; * one is sorted cummulative time spent w/i each label marker; * other is nested so you can see what label markers contain others; * so the hardest part is finding/adding appropriate marks that you want to measure the time over; * you can get the number of scf iterations from `psi4.variable(""SCF ITERATIONS"")` at the end of a calc. Hope this is broadly helpful. Feel free to ask questions.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2601#issuecomment-1152763335
https://github.com/psi4/psi4/issues/2601#issuecomment-1152763335:1011,Modifiability,variab,variable,1011,"Quick notes on timer.dat; * the file is cummulative so run each calc in separate directory so you can match an input file with a timer.dat entry; * timer.dat is mostly for developers so it has just enough info to identify things but not much description; * if you're willing to compile the code (for c-side entries) or edit the installation (for py-side entries), adding more subdivisions to timer.dat is easy; * py-side, have matching labels like https://github.com/psi4/psi4/blob/master/psi4/driver/procrouting/scf_proc/scf_iterator.py#L196-L198; * c-side, have matching entries like https://github.com/psi4/psi4/blob/master/psi4/src/psi4/dfmp2/mp2.cc#L219-L221; * for a single run, timer.dat shows the same info two ways -- ; * one is sorted cummulative time spent w/i each label marker; * other is nested so you can see what label markers contain others; * so the hardest part is finding/adding appropriate marks that you want to measure the time over; * you can get the number of scf iterations from `psi4.variable(""SCF ITERATIONS"")` at the end of a calc. Hope this is broadly helpful. Feel free to ask questions.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2601#issuecomment-1152763335
https://github.com/psi4/psi4/issues/2604#issuecomment-1152921733:33,Performance,optimiz,optimization,33,"We discuss this in the ""geometry optimization"" [page of the documentation](https://psicode.org/psi4manual/master/optking.html). Please check the documentation before filing issues.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2604#issuecomment-1152921733
https://github.com/psi4/psi4/pull/2605#issuecomment-1153836192:109,Availability,error,error,109,"I'll review this once it passes tests. `test_cppe.py:test_cppe_tdscf_uhf` is currently failing. Based on the error message, this has nothing to do with CPPE but represents an indexing error in the code. For a first debug attempt, I would recommend removing both CPPE and the comparison against reference energies, and make sure the TDSCF completes in the first place. Let me know if you need assistance.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2605#issuecomment-1153836192
https://github.com/psi4/psi4/pull/2605#issuecomment-1153836192:184,Availability,error,error,184,"I'll review this once it passes tests. `test_cppe.py:test_cppe_tdscf_uhf` is currently failing. Based on the error message, this has nothing to do with CPPE but represents an indexing error in the code. For a first debug attempt, I would recommend removing both CPPE and the comparison against reference energies, and make sure the TDSCF completes in the first place. Let me know if you need assistance.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2605#issuecomment-1153836192
https://github.com/psi4/psi4/pull/2605#issuecomment-1153836192:115,Integrability,message,message,115,"I'll review this once it passes tests. `test_cppe.py:test_cppe_tdscf_uhf` is currently failing. Based on the error message, this has nothing to do with CPPE but represents an indexing error in the code. For a first debug attempt, I would recommend removing both CPPE and the comparison against reference energies, and make sure the TDSCF completes in the first place. Let me know if you need assistance.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2605#issuecomment-1153836192
https://github.com/psi4/psi4/pull/2605#issuecomment-1153836192:32,Testability,test,tests,32,"I'll review this once it passes tests. `test_cppe.py:test_cppe_tdscf_uhf` is currently failing. Based on the error message, this has nothing to do with CPPE but represents an indexing error in the code. For a first debug attempt, I would recommend removing both CPPE and the comparison against reference energies, and make sure the TDSCF completes in the first place. Let me know if you need assistance.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2605#issuecomment-1153836192
https://github.com/psi4/psi4/pull/2605#issuecomment-1154178074:36,Testability,test,test,36,"Gah! I didn't know about the pytest test cases (the standard tdscf-n set ran OK, somewhat surprisingly). A standard copy-paste and then missing one part that needed changing! I've corrected it. My version of pytest is too old to run the tests (apparently) but extracting the various bits out of the pytest file and running that as a standard input file worked OK.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2605#issuecomment-1154178074
https://github.com/psi4/psi4/pull/2605#issuecomment-1154178074:237,Testability,test,tests,237,"Gah! I didn't know about the pytest test cases (the standard tdscf-n set ran OK, somewhat surprisingly). A standard copy-paste and then missing one part that needed changing! I've corrected it. My version of pytest is too old to run the tests (apparently) but extracting the various bits out of the pytest file and running that as a standard input file worked OK.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2605#issuecomment-1154178074
https://github.com/psi4/psi4/pull/2605#issuecomment-1154396287:38,Deployability,update,update,38,"Tests are passing, excellent!. Please update `output.ref` for `tdscf-7` and any of the other `tdscf` tests, so we can see how this PR changes the output printing.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2605#issuecomment-1154396287
https://github.com/psi4/psi4/pull/2605#issuecomment-1154396287:0,Testability,Test,Tests,0,"Tests are passing, excellent!. Please update `output.ref` for `tdscf-7` and any of the other `tdscf` tests, so we can see how this PR changes the output printing.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2605#issuecomment-1154396287
https://github.com/psi4/psi4/pull/2605#issuecomment-1154396287:101,Testability,test,tests,101,"Tests are passing, excellent!. Please update `output.ref` for `tdscf-7` and any of the other `tdscf` tests, so we can see how this PR changes the output printing.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2605#issuecomment-1154396287
https://github.com/psi4/psi4/pull/2605#issuecomment-1155599085:196,Availability,error,errors,196,I think that should have done the trick. (I ran the tdscf tests and then overwrote the respective output.ref files with the generated output.dat files.) I think the only differences are numerical errors during SCF and then formatting of the output. All final results should be unchanged.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2605#issuecomment-1155599085
https://github.com/psi4/psi4/pull/2605#issuecomment-1155599085:58,Testability,test,tests,58,I think that should have done the trick. (I ran the tdscf tests and then overwrote the respective output.ref files with the generated output.dat files.) I think the only differences are numerical errors during SCF and then formatting of the output. All final results should be unchanged.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2605#issuecomment-1155599085
https://github.com/psi4/psi4/issues/2608#issuecomment-1155129126:170,Availability,ping,pinging,170,"Please let us know how you installed Psi4. In particular, we need to know the version number that should appear in the header of your input file. @loriab, I hate to keep pinging you on things, but I feel that the CFOUR interface is your department.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155129126
https://github.com/psi4/psi4/issues/2608#issuecomment-1155129126:27,Deployability,install,installed,27,"Please let us know how you installed Psi4. In particular, we need to know the version number that should appear in the header of your input file. @loriab, I hate to keep pinging you on things, but I feel that the CFOUR interface is your department.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155129126
https://github.com/psi4/psi4/issues/2608#issuecomment-1155129126:219,Integrability,interface,interface,219,"Please let us know how you installed Psi4. In particular, we need to know the version number that should appear in the header of your input file. @loriab, I hate to keep pinging you on things, but I feel that the CFOUR interface is your department.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155129126
https://github.com/psi4/psi4/issues/2608#issuecomment-1155136649:50,Deployability,install,installed,50,"Dean Jonathon,. Thank you for your quick reply. I installed Psi4 by executing the bash script `Psi4conda-1.6-py38-Linux-x86_64.sh` (with the command `bash Psi4conda-1.6-py38-Linux-x86_64.sh -b -p /xstorage/tobias/bin/psi4`). I guess I installed the 1.6 version:. ```; Psi4: An Open-Source Ab Initio Electronic Structure Package; Psi4 1.6 release; ```; Thanks again. Best regards,. Roland",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155136649
https://github.com/psi4/psi4/issues/2608#issuecomment-1155136649:235,Deployability,install,installed,235,"Dean Jonathon,. Thank you for your quick reply. I installed Psi4 by executing the bash script `Psi4conda-1.6-py38-Linux-x86_64.sh` (with the command `bash Psi4conda-1.6-py38-Linux-x86_64.sh -b -p /xstorage/tobias/bin/psi4`). I guess I installed the 1.6 version:. ```; Psi4: An Open-Source Ab Initio Electronic Structure Package; Psi4 1.6 release; ```; Thanks again. Best regards,. Roland",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155136649
https://github.com/psi4/psi4/issues/2608#issuecomment-1155136649:338,Deployability,release,release,338,"Dean Jonathon,. Thank you for your quick reply. I installed Psi4 by executing the bash script `Psi4conda-1.6-py38-Linux-x86_64.sh` (with the command `bash Psi4conda-1.6-py38-Linux-x86_64.sh -b -p /xstorage/tobias/bin/psi4`). I guess I installed the 1.6 version:. ```; Psi4: An Open-Source Ab Initio Electronic Structure Package; Psi4 1.6 release; ```; Thanks again. Best regards,. Roland",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155136649
https://github.com/psi4/psi4/issues/2608#issuecomment-1155154225:236,Availability,error,error,236,"Yes, that's just what we needed. We made some changes in 1.6 (finally delivering on the driver refactor we promised in the 1.4 paper) with a very high likelihood of causing bugs in how Psi4 passes information around, which is what your error appears to be. ""Check the interface to CFOUR works"" may have slipped through the cracks of things we tested. Lori would know for sure. I unfortunately don't have CFOUR so can't test this myself, but I'll agitate to get a hold of one of the developers who does.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155154225
https://github.com/psi4/psi4/issues/2608#issuecomment-1155154225:268,Integrability,interface,interface,268,"Yes, that's just what we needed. We made some changes in 1.6 (finally delivering on the driver refactor we promised in the 1.4 paper) with a very high likelihood of causing bugs in how Psi4 passes information around, which is what your error appears to be. ""Check the interface to CFOUR works"" may have slipped through the cracks of things we tested. Lori would know for sure. I unfortunately don't have CFOUR so can't test this myself, but I'll agitate to get a hold of one of the developers who does.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155154225
https://github.com/psi4/psi4/issues/2608#issuecomment-1155154225:95,Modifiability,refactor,refactor,95,"Yes, that's just what we needed. We made some changes in 1.6 (finally delivering on the driver refactor we promised in the 1.4 paper) with a very high likelihood of causing bugs in how Psi4 passes information around, which is what your error appears to be. ""Check the interface to CFOUR works"" may have slipped through the cracks of things we tested. Lori would know for sure. I unfortunately don't have CFOUR so can't test this myself, but I'll agitate to get a hold of one of the developers who does.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155154225
https://github.com/psi4/psi4/issues/2608#issuecomment-1155154225:343,Testability,test,tested,343,"Yes, that's just what we needed. We made some changes in 1.6 (finally delivering on the driver refactor we promised in the 1.4 paper) with a very high likelihood of causing bugs in how Psi4 passes information around, which is what your error appears to be. ""Check the interface to CFOUR works"" may have slipped through the cracks of things we tested. Lori would know for sure. I unfortunately don't have CFOUR so can't test this myself, but I'll agitate to get a hold of one of the developers who does.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155154225
https://github.com/psi4/psi4/issues/2608#issuecomment-1155154225:419,Testability,test,test,419,"Yes, that's just what we needed. We made some changes in 1.6 (finally delivering on the driver refactor we promised in the 1.4 paper) with a very high likelihood of causing bugs in how Psi4 passes information around, which is what your error appears to be. ""Check the interface to CFOUR works"" may have slipped through the cracks of things we tested. Lori would know for sure. I unfortunately don't have CFOUR so can't test this myself, but I'll agitate to get a hold of one of the developers who does.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155154225
https://github.com/psi4/psi4/issues/2608#issuecomment-1155166619:50,Security,access,access,50,"Thanks Jonathon. If it is simpler, I can give you access to our cluster (by sending you the login data via email) where you can test the problematic input.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155166619
https://github.com/psi4/psi4/issues/2608#issuecomment-1155166619:92,Testability,log,login,92,"Thanks Jonathon. If it is simpler, I can give you access to our cluster (by sending you the login data via email) where you can test the problematic input.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155166619
https://github.com/psi4/psi4/issues/2608#issuecomment-1155166619:128,Testability,test,test,128,"Thanks Jonathon. If it is simpler, I can give you access to our cluster (by sending you the login data via email) where you can test the problematic input.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155166619
https://github.com/psi4/psi4/issues/2608#issuecomment-1155166619:26,Usability,simpl,simpler,26,"Thanks Jonathon. If it is simpler, I can give you access to our cluster (by sending you the login data via email) where you can test the problematic input.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155166619
https://github.com/psi4/psi4/issues/2608#issuecomment-1155480883:266,Deployability,install,installation,266,"Thanks for trying out Psi4 and the Psi4/Cfour interface, @tobirolinew. I can probably fix your immediate problem, but please read on. :-). There's three ways of running a Cfour calc through a more flexible front-end right now:; * QCEngine (already present in a Psi4 installation. takes a dictionary as input. geometry must be in Cartesians.); * QCDB (extra install. depends on QCEngine. inputs look much like Psi4/Cfour only `psi4.` becomes `qcdb.`. can use Z-Matrices.); * Psi4/Cfour (the first in time of these three. what you're trying now.). I'm trying to deprecate this last one in favor of the better maintained first ones. Your job would look something like the below through QCEngine (code below not tested). ```; import psi4; import qcengine as qcng. h2o = psi4.geometry(""""""; O; H 1 R; H 1 R 2 A. R=0.958; A=104.5; """"""). atomicinput = {; ""driver"": ""energy"",; ""molecule"": h2o.to_schema(dtype=2),; ""model"": {; ""method"": ""ccsd(t)"",; ""basis"": ""aug-pvqz"",; },; ""keywords"": {; ""SCF_CONV"": 12,; ""CC_CONV"": 12,; },; }. atomicresult = qcng.compute(atomicinput, ""cfour""). import pprint; pprint.pprint(atomic_result.dict()); ```. What types of calcs are you ultimately looking to run? How would you like to proceed: the QCEngine or Psi4/Cfour route? Thanks!",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155480883
https://github.com/psi4/psi4/issues/2608#issuecomment-1155480883:357,Deployability,install,install,357,"Thanks for trying out Psi4 and the Psi4/Cfour interface, @tobirolinew. I can probably fix your immediate problem, but please read on. :-). There's three ways of running a Cfour calc through a more flexible front-end right now:; * QCEngine (already present in a Psi4 installation. takes a dictionary as input. geometry must be in Cartesians.); * QCDB (extra install. depends on QCEngine. inputs look much like Psi4/Cfour only `psi4.` becomes `qcdb.`. can use Z-Matrices.); * Psi4/Cfour (the first in time of these three. what you're trying now.). I'm trying to deprecate this last one in favor of the better maintained first ones. Your job would look something like the below through QCEngine (code below not tested). ```; import psi4; import qcengine as qcng. h2o = psi4.geometry(""""""; O; H 1 R; H 1 R 2 A. R=0.958; A=104.5; """"""). atomicinput = {; ""driver"": ""energy"",; ""molecule"": h2o.to_schema(dtype=2),; ""model"": {; ""method"": ""ccsd(t)"",; ""basis"": ""aug-pvqz"",; },; ""keywords"": {; ""SCF_CONV"": 12,; ""CC_CONV"": 12,; },; }. atomicresult = qcng.compute(atomicinput, ""cfour""). import pprint; pprint.pprint(atomic_result.dict()); ```. What types of calcs are you ultimately looking to run? How would you like to proceed: the QCEngine or Psi4/Cfour route? Thanks!",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155480883
https://github.com/psi4/psi4/issues/2608#issuecomment-1155480883:858,Energy Efficiency,energy,energy,858,"Thanks for trying out Psi4 and the Psi4/Cfour interface, @tobirolinew. I can probably fix your immediate problem, but please read on. :-). There's three ways of running a Cfour calc through a more flexible front-end right now:; * QCEngine (already present in a Psi4 installation. takes a dictionary as input. geometry must be in Cartesians.); * QCDB (extra install. depends on QCEngine. inputs look much like Psi4/Cfour only `psi4.` becomes `qcdb.`. can use Z-Matrices.); * Psi4/Cfour (the first in time of these three. what you're trying now.). I'm trying to deprecate this last one in favor of the better maintained first ones. Your job would look something like the below through QCEngine (code below not tested). ```; import psi4; import qcengine as qcng. h2o = psi4.geometry(""""""; O; H 1 R; H 1 R 2 A. R=0.958; A=104.5; """"""). atomicinput = {; ""driver"": ""energy"",; ""molecule"": h2o.to_schema(dtype=2),; ""model"": {; ""method"": ""ccsd(t)"",; ""basis"": ""aug-pvqz"",; },; ""keywords"": {; ""SCF_CONV"": 12,; ""CC_CONV"": 12,; },; }. atomicresult = qcng.compute(atomicinput, ""cfour""). import pprint; pprint.pprint(atomic_result.dict()); ```. What types of calcs are you ultimately looking to run? How would you like to proceed: the QCEngine or Psi4/Cfour route? Thanks!",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155480883
https://github.com/psi4/psi4/issues/2608#issuecomment-1155480883:46,Integrability,interface,interface,46,"Thanks for trying out Psi4 and the Psi4/Cfour interface, @tobirolinew. I can probably fix your immediate problem, but please read on. :-). There's three ways of running a Cfour calc through a more flexible front-end right now:; * QCEngine (already present in a Psi4 installation. takes a dictionary as input. geometry must be in Cartesians.); * QCDB (extra install. depends on QCEngine. inputs look much like Psi4/Cfour only `psi4.` becomes `qcdb.`. can use Z-Matrices.); * Psi4/Cfour (the first in time of these three. what you're trying now.). I'm trying to deprecate this last one in favor of the better maintained first ones. Your job would look something like the below through QCEngine (code below not tested). ```; import psi4; import qcengine as qcng. h2o = psi4.geometry(""""""; O; H 1 R; H 1 R 2 A. R=0.958; A=104.5; """"""). atomicinput = {; ""driver"": ""energy"",; ""molecule"": h2o.to_schema(dtype=2),; ""model"": {; ""method"": ""ccsd(t)"",; ""basis"": ""aug-pvqz"",; },; ""keywords"": {; ""SCF_CONV"": 12,; ""CC_CONV"": 12,; },; }. atomicresult = qcng.compute(atomicinput, ""cfour""). import pprint; pprint.pprint(atomic_result.dict()); ```. What types of calcs are you ultimately looking to run? How would you like to proceed: the QCEngine or Psi4/Cfour route? Thanks!",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155480883
https://github.com/psi4/psi4/issues/2608#issuecomment-1155480883:366,Integrability,depend,depends,366,"Thanks for trying out Psi4 and the Psi4/Cfour interface, @tobirolinew. I can probably fix your immediate problem, but please read on. :-). There's three ways of running a Cfour calc through a more flexible front-end right now:; * QCEngine (already present in a Psi4 installation. takes a dictionary as input. geometry must be in Cartesians.); * QCDB (extra install. depends on QCEngine. inputs look much like Psi4/Cfour only `psi4.` becomes `qcdb.`. can use Z-Matrices.); * Psi4/Cfour (the first in time of these three. what you're trying now.). I'm trying to deprecate this last one in favor of the better maintained first ones. Your job would look something like the below through QCEngine (code below not tested). ```; import psi4; import qcengine as qcng. h2o = psi4.geometry(""""""; O; H 1 R; H 1 R 2 A. R=0.958; A=104.5; """"""). atomicinput = {; ""driver"": ""energy"",; ""molecule"": h2o.to_schema(dtype=2),; ""model"": {; ""method"": ""ccsd(t)"",; ""basis"": ""aug-pvqz"",; },; ""keywords"": {; ""SCF_CONV"": 12,; ""CC_CONV"": 12,; },; }. atomicresult = qcng.compute(atomicinput, ""cfour""). import pprint; pprint.pprint(atomic_result.dict()); ```. What types of calcs are you ultimately looking to run? How would you like to proceed: the QCEngine or Psi4/Cfour route? Thanks!",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155480883
https://github.com/psi4/psi4/issues/2608#issuecomment-1155480883:1241,Integrability,rout,route,1241,"Thanks for trying out Psi4 and the Psi4/Cfour interface, @tobirolinew. I can probably fix your immediate problem, but please read on. :-). There's three ways of running a Cfour calc through a more flexible front-end right now:; * QCEngine (already present in a Psi4 installation. takes a dictionary as input. geometry must be in Cartesians.); * QCDB (extra install. depends on QCEngine. inputs look much like Psi4/Cfour only `psi4.` becomes `qcdb.`. can use Z-Matrices.); * Psi4/Cfour (the first in time of these three. what you're trying now.). I'm trying to deprecate this last one in favor of the better maintained first ones. Your job would look something like the below through QCEngine (code below not tested). ```; import psi4; import qcengine as qcng. h2o = psi4.geometry(""""""; O; H 1 R; H 1 R 2 A. R=0.958; A=104.5; """"""). atomicinput = {; ""driver"": ""energy"",; ""molecule"": h2o.to_schema(dtype=2),; ""model"": {; ""method"": ""ccsd(t)"",; ""basis"": ""aug-pvqz"",; },; ""keywords"": {; ""SCF_CONV"": 12,; ""CC_CONV"": 12,; },; }. atomicresult = qcng.compute(atomicinput, ""cfour""). import pprint; pprint.pprint(atomic_result.dict()); ```. What types of calcs are you ultimately looking to run? How would you like to proceed: the QCEngine or Psi4/Cfour route? Thanks!",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155480883
https://github.com/psi4/psi4/issues/2608#issuecomment-1155480883:197,Modifiability,flexible,flexible,197,"Thanks for trying out Psi4 and the Psi4/Cfour interface, @tobirolinew. I can probably fix your immediate problem, but please read on. :-). There's three ways of running a Cfour calc through a more flexible front-end right now:; * QCEngine (already present in a Psi4 installation. takes a dictionary as input. geometry must be in Cartesians.); * QCDB (extra install. depends on QCEngine. inputs look much like Psi4/Cfour only `psi4.` becomes `qcdb.`. can use Z-Matrices.); * Psi4/Cfour (the first in time of these three. what you're trying now.). I'm trying to deprecate this last one in favor of the better maintained first ones. Your job would look something like the below through QCEngine (code below not tested). ```; import psi4; import qcengine as qcng. h2o = psi4.geometry(""""""; O; H 1 R; H 1 R 2 A. R=0.958; A=104.5; """"""). atomicinput = {; ""driver"": ""energy"",; ""molecule"": h2o.to_schema(dtype=2),; ""model"": {; ""method"": ""ccsd(t)"",; ""basis"": ""aug-pvqz"",; },; ""keywords"": {; ""SCF_CONV"": 12,; ""CC_CONV"": 12,; },; }. atomicresult = qcng.compute(atomicinput, ""cfour""). import pprint; pprint.pprint(atomic_result.dict()); ```. What types of calcs are you ultimately looking to run? How would you like to proceed: the QCEngine or Psi4/Cfour route? Thanks!",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155480883
https://github.com/psi4/psi4/issues/2608#issuecomment-1155480883:708,Testability,test,tested,708,"Thanks for trying out Psi4 and the Psi4/Cfour interface, @tobirolinew. I can probably fix your immediate problem, but please read on. :-). There's three ways of running a Cfour calc through a more flexible front-end right now:; * QCEngine (already present in a Psi4 installation. takes a dictionary as input. geometry must be in Cartesians.); * QCDB (extra install. depends on QCEngine. inputs look much like Psi4/Cfour only `psi4.` becomes `qcdb.`. can use Z-Matrices.); * Psi4/Cfour (the first in time of these three. what you're trying now.). I'm trying to deprecate this last one in favor of the better maintained first ones. Your job would look something like the below through QCEngine (code below not tested). ```; import psi4; import qcengine as qcng. h2o = psi4.geometry(""""""; O; H 1 R; H 1 R 2 A. R=0.958; A=104.5; """"""). atomicinput = {; ""driver"": ""energy"",; ""molecule"": h2o.to_schema(dtype=2),; ""model"": {; ""method"": ""ccsd(t)"",; ""basis"": ""aug-pvqz"",; },; ""keywords"": {; ""SCF_CONV"": 12,; ""CC_CONV"": 12,; },; }. atomicresult = qcng.compute(atomicinput, ""cfour""). import pprint; pprint.pprint(atomic_result.dict()); ```. What types of calcs are you ultimately looking to run? How would you like to proceed: the QCEngine or Psi4/Cfour route? Thanks!",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155480883
https://github.com/psi4/psi4/issues/2608#issuecomment-1155516048:797,Availability,error,error,797,"Thanks @loriab for your detailed answer. In fact, I would like to do focal-point analyses for small molecules (including HF, MP2, CC, DBOC, and relativistic corrections) in a somewhat automated form. Psi4, which is able to execute MRCC and CFOUR, seems to me an optimal frame for this purpose (I saw that certain FPA schemes are already implemented in it). . The Psi4/Cfour route looks simpler for me. Basically I will use Cartesian coordinates, but in some cases it would be useful to do CCSD(T) optimizations via CFOUR (requiring internal coordinates). How to execute the solution you posted with Psi4? I tried to put it into a file `test.dat` and run `psi4 test.dat`, but -- after correcting the possible typo [`atomic_result.dict()` instead of `atomicresult.dict()`], I received the following error: . ```; {'error': {'error_message': 'QCEngine Execution Error:\n'; 'Traceback (most recent call last):\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/util.py"", '; 'line 114, in compute_wrapper\n'; ' yield metadata\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/compute.py"", '; 'line 91, in compute\n'; ' output_data = executor.compute(input_data, '; 'config)\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/programs/cfour/runner.py"", '; 'line 71, in compute\n'; ' job_inputs = self.build_input(input_model, '; 'config)\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/programs/cfour/runner.py"", '; 'line 137, in build_input\n'; ' cfourrec[""infiles""][""GENBAS""] = '; 'genbas.read_text()\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1236, in read_text\n'; "" with self.open(mode='r', encoding=encoding, ""; 'errors=errors) as f:\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1222, in open\n'; ' return io.open(self, mode, buffering, '; 'encoding, errors, newline,\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155516048
https://github.com/psi4/psi4/issues/2608#issuecomment-1155516048:813,Availability,error,error,813,"Thanks @loriab for your detailed answer. In fact, I would like to do focal-point analyses for small molecules (including HF, MP2, CC, DBOC, and relativistic corrections) in a somewhat automated form. Psi4, which is able to execute MRCC and CFOUR, seems to me an optimal frame for this purpose (I saw that certain FPA schemes are already implemented in it). . The Psi4/Cfour route looks simpler for me. Basically I will use Cartesian coordinates, but in some cases it would be useful to do CCSD(T) optimizations via CFOUR (requiring internal coordinates). How to execute the solution you posted with Psi4? I tried to put it into a file `test.dat` and run `psi4 test.dat`, but -- after correcting the possible typo [`atomic_result.dict()` instead of `atomicresult.dict()`], I received the following error: . ```; {'error': {'error_message': 'QCEngine Execution Error:\n'; 'Traceback (most recent call last):\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/util.py"", '; 'line 114, in compute_wrapper\n'; ' yield metadata\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/compute.py"", '; 'line 91, in compute\n'; ' output_data = executor.compute(input_data, '; 'config)\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/programs/cfour/runner.py"", '; 'line 71, in compute\n'; ' job_inputs = self.build_input(input_model, '; 'config)\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/programs/cfour/runner.py"", '; 'line 137, in build_input\n'; ' cfourrec[""infiles""][""GENBAS""] = '; 'genbas.read_text()\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1236, in read_text\n'; "" with self.open(mode='r', encoding=encoding, ""; 'errors=errors) as f:\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1222, in open\n'; ' return io.open(self, mode, buffering, '; 'encoding, errors, newline,\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155516048
https://github.com/psi4/psi4/issues/2608#issuecomment-1155516048:859,Availability,Error,Error,859,"Thanks @loriab for your detailed answer. In fact, I would like to do focal-point analyses for small molecules (including HF, MP2, CC, DBOC, and relativistic corrections) in a somewhat automated form. Psi4, which is able to execute MRCC and CFOUR, seems to me an optimal frame for this purpose (I saw that certain FPA schemes are already implemented in it). . The Psi4/Cfour route looks simpler for me. Basically I will use Cartesian coordinates, but in some cases it would be useful to do CCSD(T) optimizations via CFOUR (requiring internal coordinates). How to execute the solution you posted with Psi4? I tried to put it into a file `test.dat` and run `psi4 test.dat`, but -- after correcting the possible typo [`atomic_result.dict()` instead of `atomicresult.dict()`], I received the following error: . ```; {'error': {'error_message': 'QCEngine Execution Error:\n'; 'Traceback (most recent call last):\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/util.py"", '; 'line 114, in compute_wrapper\n'; ' yield metadata\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/compute.py"", '; 'line 91, in compute\n'; ' output_data = executor.compute(input_data, '; 'config)\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/programs/cfour/runner.py"", '; 'line 71, in compute\n'; ' job_inputs = self.build_input(input_model, '; 'config)\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/programs/cfour/runner.py"", '; 'line 137, in build_input\n'; ' cfourrec[""infiles""][""GENBAS""] = '; 'genbas.read_text()\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1236, in read_text\n'; "" with self.open(mode='r', encoding=encoding, ""; 'errors=errors) as f:\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1222, in open\n'; ' return io.open(self, mode, buffering, '; 'encoding, errors, newline,\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155516048
https://github.com/psi4/psi4/issues/2608#issuecomment-1155516048:1768,Availability,error,errors,1768," following error: . ```; {'error': {'error_message': 'QCEngine Execution Error:\n'; 'Traceback (most recent call last):\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/util.py"", '; 'line 114, in compute_wrapper\n'; ' yield metadata\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/compute.py"", '; 'line 91, in compute\n'; ' output_data = executor.compute(input_data, '; 'config)\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/programs/cfour/runner.py"", '; 'line 71, in compute\n'; ' job_inputs = self.build_input(input_model, '; 'config)\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/programs/cfour/runner.py"", '; 'line 137, in build_input\n'; ' cfourrec[""infiles""][""GENBAS""] = '; 'genbas.read_text()\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1236, in read_text\n'; "" with self.open(mode='r', encoding=encoding, ""; 'errors=errors) as f:\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1222, in open\n'; ' return io.open(self, mode, buffering, '; 'encoding, errors, newline,\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1078, in _opener\n'; ' return self._accessor.open(self, flags, '; 'mode)\n'; 'FileNotFoundError: [Errno 2] No such file or '; 'directory: '; ""'/xstorage/tobias/bin/cfour/basis/GENBAS'\n"",; 'error_type': 'unknown_error',; 'extras': None},; 'extras': None,; 'id': None,; 'input_data': {'driver': 'energy',; 'keywords': {'CC_CONV': 12, 'SCF_CONV': 12},; 'model': {'basis': 'aug-pvqz', 'method': 'ccsd(t)'},; 'molecule': {'atom_labels': ['', '', ''],; 'atomic_numbers': [8, 1, 1],; 'fix_com': False,; 'fix_orientation': False,; 'fragment_charges': [0.0],; 'fragment_multiplicities': [1],; 'fragments': [[0, 1, 2]],; 'geometry': [0.0,; 0.0,; -0.12403886030029525,; 0.0,; -1.431430901356359,; 0.9842933627189459,; 0.0,; 1.431430901356359,; 0.9842933627189459]",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155516048
https://github.com/psi4/psi4/issues/2608#issuecomment-1155516048:1775,Availability,error,errors,1775," following error: . ```; {'error': {'error_message': 'QCEngine Execution Error:\n'; 'Traceback (most recent call last):\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/util.py"", '; 'line 114, in compute_wrapper\n'; ' yield metadata\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/compute.py"", '; 'line 91, in compute\n'; ' output_data = executor.compute(input_data, '; 'config)\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/programs/cfour/runner.py"", '; 'line 71, in compute\n'; ' job_inputs = self.build_input(input_model, '; 'config)\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/programs/cfour/runner.py"", '; 'line 137, in build_input\n'; ' cfourrec[""infiles""][""GENBAS""] = '; 'genbas.read_text()\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1236, in read_text\n'; "" with self.open(mode='r', encoding=encoding, ""; 'errors=errors) as f:\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1222, in open\n'; ' return io.open(self, mode, buffering, '; 'encoding, errors, newline,\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1078, in _opener\n'; ' return self._accessor.open(self, flags, '; 'mode)\n'; 'FileNotFoundError: [Errno 2] No such file or '; 'directory: '; ""'/xstorage/tobias/bin/cfour/basis/GENBAS'\n"",; 'error_type': 'unknown_error',; 'extras': None},; 'extras': None,; 'id': None,; 'input_data': {'driver': 'energy',; 'keywords': {'CC_CONV': 12, 'SCF_CONV': 12},; 'model': {'basis': 'aug-pvqz', 'method': 'ccsd(t)'},; 'molecule': {'atom_labels': ['', '', ''],; 'atomic_numbers': [8, 1, 1],; 'fix_com': False,; 'fix_orientation': False,; 'fragment_charges': [0.0],; 'fragment_multiplicities': [1],; 'fragments': [[0, 1, 2]],; 'geometry': [0.0,; 0.0,; -0.12403886030029525,; 0.0,; -1.431430901356359,; 0.9842933627189459,; 0.0,; 1.431430901356359,; 0.9842933627189459]",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155516048
https://github.com/psi4/psi4/issues/2608#issuecomment-1155516048:1939,Availability,error,errors,1939,"python3.8/site-packages/qcengine/util.py"", '; 'line 114, in compute_wrapper\n'; ' yield metadata\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/compute.py"", '; 'line 91, in compute\n'; ' output_data = executor.compute(input_data, '; 'config)\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/programs/cfour/runner.py"", '; 'line 71, in compute\n'; ' job_inputs = self.build_input(input_model, '; 'config)\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/programs/cfour/runner.py"", '; 'line 137, in build_input\n'; ' cfourrec[""infiles""][""GENBAS""] = '; 'genbas.read_text()\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1236, in read_text\n'; "" with self.open(mode='r', encoding=encoding, ""; 'errors=errors) as f:\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1222, in open\n'; ' return io.open(self, mode, buffering, '; 'encoding, errors, newline,\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1078, in _opener\n'; ' return self._accessor.open(self, flags, '; 'mode)\n'; 'FileNotFoundError: [Errno 2] No such file or '; 'directory: '; ""'/xstorage/tobias/bin/cfour/basis/GENBAS'\n"",; 'error_type': 'unknown_error',; 'extras': None},; 'extras': None,; 'id': None,; 'input_data': {'driver': 'energy',; 'keywords': {'CC_CONV': 12, 'SCF_CONV': 12},; 'model': {'basis': 'aug-pvqz', 'method': 'ccsd(t)'},; 'molecule': {'atom_labels': ['', '', ''],; 'atomic_numbers': [8, 1, 1],; 'fix_com': False,; 'fix_orientation': False,; 'fragment_charges': [0.0],; 'fragment_multiplicities': [1],; 'fragments': [[0, 1, 2]],; 'geometry': [0.0,; 0.0,; -0.12403886030029525,; 0.0,; -1.431430901356359,; 0.9842933627189459,; 0.0,; 1.431430901356359,; 0.9842933627189459],; 'mass_numbers': [16, 1, 1],; 'masses': [15.99491461957,; 1.00782503223,; 1.00782503223],; 'molecular_charge': 0.0,; 'molecular_multiplicity': 1,; 'name': 'H2O',; 'p",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155516048
https://github.com/psi4/psi4/issues/2608#issuecomment-1155516048:3504,Availability,error,error,3504,"four/runner.py"", '; 'line 137, in build_input\n'; ' cfourrec[""infiles""][""GENBAS""] = '; 'genbas.read_text()\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1236, in read_text\n'; "" with self.open(mode='r', encoding=encoding, ""; 'errors=errors) as f:\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1222, in open\n'; ' return io.open(self, mode, buffering, '; 'encoding, errors, newline,\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1078, in _opener\n'; ' return self._accessor.open(self, flags, '; 'mode)\n'; 'FileNotFoundError: [Errno 2] No such file or '; 'directory: '; ""'/xstorage/tobias/bin/cfour/basis/GENBAS'\n"",; 'error_type': 'unknown_error',; 'extras': None},; 'extras': None,; 'id': None,; 'input_data': {'driver': 'energy',; 'keywords': {'CC_CONV': 12, 'SCF_CONV': 12},; 'model': {'basis': 'aug-pvqz', 'method': 'ccsd(t)'},; 'molecule': {'atom_labels': ['', '', ''],; 'atomic_numbers': [8, 1, 1],; 'fix_com': False,; 'fix_orientation': False,; 'fragment_charges': [0.0],; 'fragment_multiplicities': [1],; 'fragments': [[0, 1, 2]],; 'geometry': [0.0,; 0.0,; -0.12403886030029525,; 0.0,; -1.431430901356359,; 0.9842933627189459,; 0.0,; 1.431430901356359,; 0.9842933627189459],; 'mass_numbers': [16, 1, 1],; 'masses': [15.99491461957,; 1.00782503223,; 1.00782503223],; 'molecular_charge': 0.0,; 'molecular_multiplicity': 1,; 'name': 'H2O',; 'provenance': {'creator': 'QCElemental',; 'routine': 'qcelemental.molparse.from_string',; 'version': 'v0.24.0'},; 'real': [True, True, True],; 'schema_name': 'qcschema_molecule',; 'schema_version': 2,; 'symbols': ['O', 'H', 'H'],; 'validated': True},; 'provenance': {'cpu': 'Intel(R) Xeon(R) CPU E7-4870 v2 @ '; '2.30GHz',; 'creator': 'QCEngine',; 'hostname': 'nod10',; 'qcengine_version': 'v0.23.0',; 'username': 'tobias',; 'version': 'v0.23.0',; 'wall_time': 1.2955999374389648}},; 'success': False}; ```; ; Could you please help me what causes this error?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155516048
https://github.com/psi4/psi4/issues/2608#issuecomment-1155516048:2329,Energy Efficiency,energy,energy,2329,"py"", '; 'line 71, in compute\n'; ' job_inputs = self.build_input(input_model, '; 'config)\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/programs/cfour/runner.py"", '; 'line 137, in build_input\n'; ' cfourrec[""infiles""][""GENBAS""] = '; 'genbas.read_text()\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1236, in read_text\n'; "" with self.open(mode='r', encoding=encoding, ""; 'errors=errors) as f:\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1222, in open\n'; ' return io.open(self, mode, buffering, '; 'encoding, errors, newline,\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1078, in _opener\n'; ' return self._accessor.open(self, flags, '; 'mode)\n'; 'FileNotFoundError: [Errno 2] No such file or '; 'directory: '; ""'/xstorage/tobias/bin/cfour/basis/GENBAS'\n"",; 'error_type': 'unknown_error',; 'extras': None},; 'extras': None,; 'id': None,; 'input_data': {'driver': 'energy',; 'keywords': {'CC_CONV': 12, 'SCF_CONV': 12},; 'model': {'basis': 'aug-pvqz', 'method': 'ccsd(t)'},; 'molecule': {'atom_labels': ['', '', ''],; 'atomic_numbers': [8, 1, 1],; 'fix_com': False,; 'fix_orientation': False,; 'fragment_charges': [0.0],; 'fragment_multiplicities': [1],; 'fragments': [[0, 1, 2]],; 'geometry': [0.0,; 0.0,; -0.12403886030029525,; 0.0,; -1.431430901356359,; 0.9842933627189459,; 0.0,; 1.431430901356359,; 0.9842933627189459],; 'mass_numbers': [16, 1, 1],; 'masses': [15.99491461957,; 1.00782503223,; 1.00782503223],; 'molecular_charge': 0.0,; 'molecular_multiplicity': 1,; 'name': 'H2O',; 'provenance': {'creator': 'QCElemental',; 'routine': 'qcelemental.molparse.from_string',; 'version': 'v0.24.0'},; 'real': [True, True, True],; 'schema_name': 'qcschema_molecule',; 'schema_version': 2,; 'symbols': ['O', 'H', 'H'],; 'validated': True},; 'provenance': {'cpu': 'Intel(R) Xeon(R) CPU E7-4870 v2 @ '; '2.30GHz',; 'creator': 'QCEngine',; 'hostname': 'nod10',; 'qcengin",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155516048
https://github.com/psi4/psi4/issues/2608#issuecomment-1155516048:374,Integrability,rout,route,374,"Thanks @loriab for your detailed answer. In fact, I would like to do focal-point analyses for small molecules (including HF, MP2, CC, DBOC, and relativistic corrections) in a somewhat automated form. Psi4, which is able to execute MRCC and CFOUR, seems to me an optimal frame for this purpose (I saw that certain FPA schemes are already implemented in it). . The Psi4/Cfour route looks simpler for me. Basically I will use Cartesian coordinates, but in some cases it would be useful to do CCSD(T) optimizations via CFOUR (requiring internal coordinates). How to execute the solution you posted with Psi4? I tried to put it into a file `test.dat` and run `psi4 test.dat`, but -- after correcting the possible typo [`atomic_result.dict()` instead of `atomicresult.dict()`], I received the following error: . ```; {'error': {'error_message': 'QCEngine Execution Error:\n'; 'Traceback (most recent call last):\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/util.py"", '; 'line 114, in compute_wrapper\n'; ' yield metadata\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/compute.py"", '; 'line 91, in compute\n'; ' output_data = executor.compute(input_data, '; 'config)\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/programs/cfour/runner.py"", '; 'line 71, in compute\n'; ' job_inputs = self.build_input(input_model, '; 'config)\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/programs/cfour/runner.py"", '; 'line 137, in build_input\n'; ' cfourrec[""infiles""][""GENBAS""] = '; 'genbas.read_text()\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1236, in read_text\n'; "" with self.open(mode='r', encoding=encoding, ""; 'errors=errors) as f:\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1222, in open\n'; ' return io.open(self, mode, buffering, '; 'encoding, errors, newline,\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155516048
https://github.com/psi4/psi4/issues/2608#issuecomment-1155516048:2995,Integrability,rout,routine,2995,"four/runner.py"", '; 'line 137, in build_input\n'; ' cfourrec[""infiles""][""GENBAS""] = '; 'genbas.read_text()\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1236, in read_text\n'; "" with self.open(mode='r', encoding=encoding, ""; 'errors=errors) as f:\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1222, in open\n'; ' return io.open(self, mode, buffering, '; 'encoding, errors, newline,\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1078, in _opener\n'; ' return self._accessor.open(self, flags, '; 'mode)\n'; 'FileNotFoundError: [Errno 2] No such file or '; 'directory: '; ""'/xstorage/tobias/bin/cfour/basis/GENBAS'\n"",; 'error_type': 'unknown_error',; 'extras': None},; 'extras': None,; 'id': None,; 'input_data': {'driver': 'energy',; 'keywords': {'CC_CONV': 12, 'SCF_CONV': 12},; 'model': {'basis': 'aug-pvqz', 'method': 'ccsd(t)'},; 'molecule': {'atom_labels': ['', '', ''],; 'atomic_numbers': [8, 1, 1],; 'fix_com': False,; 'fix_orientation': False,; 'fragment_charges': [0.0],; 'fragment_multiplicities': [1],; 'fragments': [[0, 1, 2]],; 'geometry': [0.0,; 0.0,; -0.12403886030029525,; 0.0,; -1.431430901356359,; 0.9842933627189459,; 0.0,; 1.431430901356359,; 0.9842933627189459],; 'mass_numbers': [16, 1, 1],; 'masses': [15.99491461957,; 1.00782503223,; 1.00782503223],; 'molecular_charge': 0.0,; 'molecular_multiplicity': 1,; 'name': 'H2O',; 'provenance': {'creator': 'QCElemental',; 'routine': 'qcelemental.molparse.from_string',; 'version': 'v0.24.0'},; 'real': [True, True, True],; 'schema_name': 'qcschema_molecule',; 'schema_version': 2,; 'symbols': ['O', 'H', 'H'],; 'validated': True},; 'provenance': {'cpu': 'Intel(R) Xeon(R) CPU E7-4870 v2 @ '; '2.30GHz',; 'creator': 'QCEngine',; 'hostname': 'nod10',; 'qcengine_version': 'v0.23.0',; 'username': 'tobias',; 'version': 'v0.23.0',; 'wall_time': 1.2955999374389648}},; 'success': False}; ```; ; Could you please help me what causes this error?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155516048
https://github.com/psi4/psi4/issues/2608#issuecomment-1155516048:1220,Modifiability,config,config,1220," CFOUR, seems to me an optimal frame for this purpose (I saw that certain FPA schemes are already implemented in it). . The Psi4/Cfour route looks simpler for me. Basically I will use Cartesian coordinates, but in some cases it would be useful to do CCSD(T) optimizations via CFOUR (requiring internal coordinates). How to execute the solution you posted with Psi4? I tried to put it into a file `test.dat` and run `psi4 test.dat`, but -- after correcting the possible typo [`atomic_result.dict()` instead of `atomicresult.dict()`], I received the following error: . ```; {'error': {'error_message': 'QCEngine Execution Error:\n'; 'Traceback (most recent call last):\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/util.py"", '; 'line 114, in compute_wrapper\n'; ' yield metadata\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/compute.py"", '; 'line 91, in compute\n'; ' output_data = executor.compute(input_data, '; 'config)\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/programs/cfour/runner.py"", '; 'line 71, in compute\n'; ' job_inputs = self.build_input(input_model, '; 'config)\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/programs/cfour/runner.py"", '; 'line 137, in build_input\n'; ' cfourrec[""infiles""][""GENBAS""] = '; 'genbas.read_text()\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1236, in read_text\n'; "" with self.open(mode='r', encoding=encoding, ""; 'errors=errors) as f:\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1222, in open\n'; ' return io.open(self, mode, buffering, '; 'encoding, errors, newline,\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1078, in _opener\n'; ' return self._accessor.open(self, flags, '; 'mode)\n'; 'FileNotFoundError: [Errno 2] No such file or '; 'directory: '; ""'/xstorage/tobias/bin/cfour/basis/GENBAS'\n"",; 'error_type': 'un",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155516048
https://github.com/psi4/psi4/issues/2608#issuecomment-1155516048:1412,Modifiability,config,config,1412,"ian coordinates, but in some cases it would be useful to do CCSD(T) optimizations via CFOUR (requiring internal coordinates). How to execute the solution you posted with Psi4? I tried to put it into a file `test.dat` and run `psi4 test.dat`, but -- after correcting the possible typo [`atomic_result.dict()` instead of `atomicresult.dict()`], I received the following error: . ```; {'error': {'error_message': 'QCEngine Execution Error:\n'; 'Traceback (most recent call last):\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/util.py"", '; 'line 114, in compute_wrapper\n'; ' yield metadata\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/compute.py"", '; 'line 91, in compute\n'; ' output_data = executor.compute(input_data, '; 'config)\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/programs/cfour/runner.py"", '; 'line 71, in compute\n'; ' job_inputs = self.build_input(input_model, '; 'config)\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/programs/cfour/runner.py"", '; 'line 137, in build_input\n'; ' cfourrec[""infiles""][""GENBAS""] = '; 'genbas.read_text()\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1236, in read_text\n'; "" with self.open(mode='r', encoding=encoding, ""; 'errors=errors) as f:\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1222, in open\n'; ' return io.open(self, mode, buffering, '; 'encoding, errors, newline,\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1078, in _opener\n'; ' return self._accessor.open(self, flags, '; 'mode)\n'; 'FileNotFoundError: [Errno 2] No such file or '; 'directory: '; ""'/xstorage/tobias/bin/cfour/basis/GENBAS'\n"",; 'error_type': 'unknown_error',; 'extras': None},; 'extras': None,; 'id': None,; 'input_data': {'driver': 'energy',; 'keywords': {'CC_CONV': 12, 'SCF_CONV': 12},; 'model': {'basis': 'aug-pvqz', 'method': 'cc",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155516048
https://github.com/psi4/psi4/issues/2608#issuecomment-1155516048:497,Performance,optimiz,optimizations,497,"Thanks @loriab for your detailed answer. In fact, I would like to do focal-point analyses for small molecules (including HF, MP2, CC, DBOC, and relativistic corrections) in a somewhat automated form. Psi4, which is able to execute MRCC and CFOUR, seems to me an optimal frame for this purpose (I saw that certain FPA schemes are already implemented in it). . The Psi4/Cfour route looks simpler for me. Basically I will use Cartesian coordinates, but in some cases it would be useful to do CCSD(T) optimizations via CFOUR (requiring internal coordinates). How to execute the solution you posted with Psi4? I tried to put it into a file `test.dat` and run `psi4 test.dat`, but -- after correcting the possible typo [`atomic_result.dict()` instead of `atomicresult.dict()`], I received the following error: . ```; {'error': {'error_message': 'QCEngine Execution Error:\n'; 'Traceback (most recent call last):\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/util.py"", '; 'line 114, in compute_wrapper\n'; ' yield metadata\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/compute.py"", '; 'line 91, in compute\n'; ' output_data = executor.compute(input_data, '; 'config)\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/programs/cfour/runner.py"", '; 'line 71, in compute\n'; ' job_inputs = self.build_input(input_model, '; 'config)\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/programs/cfour/runner.py"", '; 'line 137, in build_input\n'; ' cfourrec[""infiles""][""GENBAS""] = '; 'genbas.read_text()\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1236, in read_text\n'; "" with self.open(mode='r', encoding=encoding, ""; 'errors=errors) as f:\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1222, in open\n'; ' return io.open(self, mode, buffering, '; 'encoding, errors, newline,\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155516048
https://github.com/psi4/psi4/issues/2608#issuecomment-1155516048:3184,Security,validat,validated,3184,"four/runner.py"", '; 'line 137, in build_input\n'; ' cfourrec[""infiles""][""GENBAS""] = '; 'genbas.read_text()\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1236, in read_text\n'; "" with self.open(mode='r', encoding=encoding, ""; 'errors=errors) as f:\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1222, in open\n'; ' return io.open(self, mode, buffering, '; 'encoding, errors, newline,\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1078, in _opener\n'; ' return self._accessor.open(self, flags, '; 'mode)\n'; 'FileNotFoundError: [Errno 2] No such file or '; 'directory: '; ""'/xstorage/tobias/bin/cfour/basis/GENBAS'\n"",; 'error_type': 'unknown_error',; 'extras': None},; 'extras': None,; 'id': None,; 'input_data': {'driver': 'energy',; 'keywords': {'CC_CONV': 12, 'SCF_CONV': 12},; 'model': {'basis': 'aug-pvqz', 'method': 'ccsd(t)'},; 'molecule': {'atom_labels': ['', '', ''],; 'atomic_numbers': [8, 1, 1],; 'fix_com': False,; 'fix_orientation': False,; 'fragment_charges': [0.0],; 'fragment_multiplicities': [1],; 'fragments': [[0, 1, 2]],; 'geometry': [0.0,; 0.0,; -0.12403886030029525,; 0.0,; -1.431430901356359,; 0.9842933627189459,; 0.0,; 1.431430901356359,; 0.9842933627189459],; 'mass_numbers': [16, 1, 1],; 'masses': [15.99491461957,; 1.00782503223,; 1.00782503223],; 'molecular_charge': 0.0,; 'molecular_multiplicity': 1,; 'name': 'H2O',; 'provenance': {'creator': 'QCElemental',; 'routine': 'qcelemental.molparse.from_string',; 'version': 'v0.24.0'},; 'real': [True, True, True],; 'schema_name': 'qcschema_molecule',; 'schema_version': 2,; 'symbols': ['O', 'H', 'H'],; 'validated': True},; 'provenance': {'cpu': 'Intel(R) Xeon(R) CPU E7-4870 v2 @ '; '2.30GHz',; 'creator': 'QCEngine',; 'hostname': 'nod10',; 'qcengine_version': 'v0.23.0',; 'username': 'tobias',; 'version': 'v0.23.0',; 'wall_time': 1.2955999374389648}},; 'success': False}; ```; ; Could you please help me what causes this error?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155516048
https://github.com/psi4/psi4/issues/2608#issuecomment-1155516048:636,Testability,test,test,636,"Thanks @loriab for your detailed answer. In fact, I would like to do focal-point analyses for small molecules (including HF, MP2, CC, DBOC, and relativistic corrections) in a somewhat automated form. Psi4, which is able to execute MRCC and CFOUR, seems to me an optimal frame for this purpose (I saw that certain FPA schemes are already implemented in it). . The Psi4/Cfour route looks simpler for me. Basically I will use Cartesian coordinates, but in some cases it would be useful to do CCSD(T) optimizations via CFOUR (requiring internal coordinates). How to execute the solution you posted with Psi4? I tried to put it into a file `test.dat` and run `psi4 test.dat`, but -- after correcting the possible typo [`atomic_result.dict()` instead of `atomicresult.dict()`], I received the following error: . ```; {'error': {'error_message': 'QCEngine Execution Error:\n'; 'Traceback (most recent call last):\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/util.py"", '; 'line 114, in compute_wrapper\n'; ' yield metadata\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/compute.py"", '; 'line 91, in compute\n'; ' output_data = executor.compute(input_data, '; 'config)\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/programs/cfour/runner.py"", '; 'line 71, in compute\n'; ' job_inputs = self.build_input(input_model, '; 'config)\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/programs/cfour/runner.py"", '; 'line 137, in build_input\n'; ' cfourrec[""infiles""][""GENBAS""] = '; 'genbas.read_text()\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1236, in read_text\n'; "" with self.open(mode='r', encoding=encoding, ""; 'errors=errors) as f:\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1222, in open\n'; ' return io.open(self, mode, buffering, '; 'encoding, errors, newline,\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155516048
https://github.com/psi4/psi4/issues/2608#issuecomment-1155516048:660,Testability,test,test,660,"Thanks @loriab for your detailed answer. In fact, I would like to do focal-point analyses for small molecules (including HF, MP2, CC, DBOC, and relativistic corrections) in a somewhat automated form. Psi4, which is able to execute MRCC and CFOUR, seems to me an optimal frame for this purpose (I saw that certain FPA schemes are already implemented in it). . The Psi4/Cfour route looks simpler for me. Basically I will use Cartesian coordinates, but in some cases it would be useful to do CCSD(T) optimizations via CFOUR (requiring internal coordinates). How to execute the solution you posted with Psi4? I tried to put it into a file `test.dat` and run `psi4 test.dat`, but -- after correcting the possible typo [`atomic_result.dict()` instead of `atomicresult.dict()`], I received the following error: . ```; {'error': {'error_message': 'QCEngine Execution Error:\n'; 'Traceback (most recent call last):\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/util.py"", '; 'line 114, in compute_wrapper\n'; ' yield metadata\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/compute.py"", '; 'line 91, in compute\n'; ' output_data = executor.compute(input_data, '; 'config)\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/programs/cfour/runner.py"", '; 'line 71, in compute\n'; ' job_inputs = self.build_input(input_model, '; 'config)\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/programs/cfour/runner.py"", '; 'line 137, in build_input\n'; ' cfourrec[""infiles""][""GENBAS""] = '; 'genbas.read_text()\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1236, in read_text\n'; "" with self.open(mode='r', encoding=encoding, ""; 'errors=errors) as f:\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1222, in open\n'; ' return io.open(self, mode, buffering, '; 'encoding, errors, newline,\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155516048
https://github.com/psi4/psi4/issues/2608#issuecomment-1155516048:386,Usability,simpl,simpler,386,"Thanks @loriab for your detailed answer. In fact, I would like to do focal-point analyses for small molecules (including HF, MP2, CC, DBOC, and relativistic corrections) in a somewhat automated form. Psi4, which is able to execute MRCC and CFOUR, seems to me an optimal frame for this purpose (I saw that certain FPA schemes are already implemented in it). . The Psi4/Cfour route looks simpler for me. Basically I will use Cartesian coordinates, but in some cases it would be useful to do CCSD(T) optimizations via CFOUR (requiring internal coordinates). How to execute the solution you posted with Psi4? I tried to put it into a file `test.dat` and run `psi4 test.dat`, but -- after correcting the possible typo [`atomic_result.dict()` instead of `atomicresult.dict()`], I received the following error: . ```; {'error': {'error_message': 'QCEngine Execution Error:\n'; 'Traceback (most recent call last):\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/util.py"", '; 'line 114, in compute_wrapper\n'; ' yield metadata\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/compute.py"", '; 'line 91, in compute\n'; ' output_data = executor.compute(input_data, '; 'config)\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/programs/cfour/runner.py"", '; 'line 71, in compute\n'; ' job_inputs = self.build_input(input_model, '; 'config)\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib//python3.8/site-packages/qcengine/programs/cfour/runner.py"", '; 'line 137, in build_input\n'; ' cfourrec[""infiles""][""GENBAS""] = '; 'genbas.read_text()\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1236, in read_text\n'; "" with self.open(mode='r', encoding=encoding, ""; 'errors=errors) as f:\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib/python3.8/pathlib.py"", '; 'line 1222, in open\n'; ' return io.open(self, mode, buffering, '; 'encoding, errors, newline,\n'; ' File '; '""/xstorage/tobias/bin/psi4/lib",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155516048
https://github.com/psi4/psi4/issues/2608#issuecomment-1155521774:85,Deployability,install,installation,85,"I can answer more fully later, but check where the `GENBAS` file lives in your CFOUR installation. It looks like it's looking for it at `/xstorage/tobias/bin/cfour/basis/GENBAS`. (This could be the trouble in the Psi4/Cfour route, too.) I don't remember the exact fallback procedure for GENBAS, but if it's missing from that spot, you could copy it to there or copy the one from the psi4 install (approx <install>/share/psi4/basis/GENBAS).",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155521774
https://github.com/psi4/psi4/issues/2608#issuecomment-1155521774:388,Deployability,install,install,388,"I can answer more fully later, but check where the `GENBAS` file lives in your CFOUR installation. It looks like it's looking for it at `/xstorage/tobias/bin/cfour/basis/GENBAS`. (This could be the trouble in the Psi4/Cfour route, too.) I don't remember the exact fallback procedure for GENBAS, but if it's missing from that spot, you could copy it to there or copy the one from the psi4 install (approx <install>/share/psi4/basis/GENBAS).",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155521774
https://github.com/psi4/psi4/issues/2608#issuecomment-1155521774:405,Deployability,install,install,405,"I can answer more fully later, but check where the `GENBAS` file lives in your CFOUR installation. It looks like it's looking for it at `/xstorage/tobias/bin/cfour/basis/GENBAS`. (This could be the trouble in the Psi4/Cfour route, too.) I don't remember the exact fallback procedure for GENBAS, but if it's missing from that spot, you could copy it to there or copy the one from the psi4 install (approx <install>/share/psi4/basis/GENBAS).",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155521774
https://github.com/psi4/psi4/issues/2608#issuecomment-1155521774:224,Integrability,rout,route,224,"I can answer more fully later, but check where the `GENBAS` file lives in your CFOUR installation. It looks like it's looking for it at `/xstorage/tobias/bin/cfour/basis/GENBAS`. (This could be the trouble in the Psi4/Cfour route, too.) I don't remember the exact fallback procedure for GENBAS, but if it's missing from that spot, you could copy it to there or copy the one from the psi4 install (approx <install>/share/psi4/basis/GENBAS).",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155521774
https://github.com/psi4/psi4/issues/2608#issuecomment-1155600386:240,Integrability,rout,route,240,"@loriab Thanks, the GENBAS file was indeed missing from directory `/xstorage/tobias/bin/cfour/basis/`. After copying one into that directory, the input you provided now works on our cluster. I look forward to getting to know the Psi4/CFOUR route.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1155600386
https://github.com/psi4/psi4/issues/2608#issuecomment-1157965071:0,Deployability,update,update,0,"update: the immediate problem in this issue is fixed with something like the below. but there are other problems from the accumulation of qcengine harvesting, distributed driver, and neglecting this Psi4/Cfour mode. I should have a PR later today. ```; - if core.get_global_option('BASIS') == '':; + if core.get_global_option('BASIS') in ["""", ""(AUTO)""]:; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1157965071
https://github.com/psi4/psi4/issues/2608#issuecomment-1168954201:319,Availability,down,download,319,"@loriab, I noticed that you posted a fix for my Psi4/Cfour problem at https://github.com/psi4/psi4/pull/2615. Thank you for that! As I understand correctly, you have the updated files using which all Cfour test jobs run successfully. If so, could you please help me which files have been modified, and from where I can download them?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1168954201
https://github.com/psi4/psi4/issues/2608#issuecomment-1168954201:170,Deployability,update,updated,170,"@loriab, I noticed that you posted a fix for my Psi4/Cfour problem at https://github.com/psi4/psi4/pull/2615. Thank you for that! As I understand correctly, you have the updated files using which all Cfour test jobs run successfully. If so, could you please help me which files have been modified, and from where I can download them?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1168954201
https://github.com/psi4/psi4/issues/2608#issuecomment-1168954201:206,Testability,test,test,206,"@loriab, I noticed that you posted a fix for my Psi4/Cfour problem at https://github.com/psi4/psi4/pull/2615. Thank you for that! As I understand correctly, you have the updated files using which all Cfour test jobs run successfully. If so, could you please help me which files have been modified, and from where I can download them?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1168954201
https://github.com/psi4/psi4/issues/2608#issuecomment-1169479941:250,Deployability,install,install,250,"@tobirolinew, pretty much all you need for runtime are the changes in this file, https://github.com/psi4/psi4/pull/2615/files#diff-3ca8e1e030771d01af412b9603a6f8e06d4c04e44dbcb40a4f7248ff8120efdd . So, you could either make those edits in your local install, or compile psi4 from master, or grab the latest conda package next week after I build them again. I'll also probably back-port these fixes into v1.6.1.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2608#issuecomment-1169479941
https://github.com/psi4/psi4/pull/2611#issuecomment-1158381577:53,Integrability,interface,interface,53,"You might also consider putting a check in the Libxc interface. If the code can dump out the density data for the points yielding NaNs, this would be valuable information for filing bugs in Libxc.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2611#issuecomment-1158381577
https://github.com/psi4/psi4/pull/2611#issuecomment-1158434514:199,Usability,learn,learning,199,"Dumping debug information for `libxc`'s purposes sounds good to me. What do you need printed, and where should I put the print statements? (I'm guessing `lbfunctional/LibXCfunctional.cc`.) I'm still learning this part of the codebase.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2611#issuecomment-1158434514
https://github.com/psi4/psi4/pull/2611#issuecomment-1159839361:422,Energy Efficiency,reduce,reduced,422,"> Dumping debug information for `libxc`'s purposes sounds good to me. What do you need printed, and where should I put the print statements? (I'm guessing `lbfunctional/LibXCfunctional.cc`.) I'm still learning this part of the codebase. The point-wise density data, i.e. `rhoa rhob sigmaaa sigmaab sigmabb lapla laplb taua taub` for unrestricted and `rho sigma lapl tau` for restricted, where `rho` is density, `sigma` is reduced gradient, `lapl` is density Laplacian, and `tau` is local kinetic energy density.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2611#issuecomment-1159839361
https://github.com/psi4/psi4/pull/2611#issuecomment-1159839361:496,Energy Efficiency,energy,energy,496,"> Dumping debug information for `libxc`'s purposes sounds good to me. What do you need printed, and where should I put the print statements? (I'm guessing `lbfunctional/LibXCfunctional.cc`.) I'm still learning this part of the codebase. The point-wise density data, i.e. `rhoa rhob sigmaaa sigmaab sigmabb lapla laplb taua taub` for unrestricted and `rho sigma lapl tau` for restricted, where `rho` is density, `sigma` is reduced gradient, `lapl` is density Laplacian, and `tau` is local kinetic energy density.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2611#issuecomment-1159839361
https://github.com/psi4/psi4/pull/2611#issuecomment-1159839361:201,Usability,learn,learning,201,"> Dumping debug information for `libxc`'s purposes sounds good to me. What do you need printed, and where should I put the print statements? (I'm guessing `lbfunctional/LibXCfunctional.cc`.) I'm still learning this part of the codebase. The point-wise density data, i.e. `rhoa rhob sigmaaa sigmaab sigmabb lapla laplb taua taub` for unrestricted and `rho sigma lapl tau` for restricted, where `rho` is density, `sigma` is reduced gradient, `lapl` is density Laplacian, and `tau` is local kinetic energy density.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2611#issuecomment-1159839361
https://github.com/psi4/psi4/pull/2611#issuecomment-1163531527:262,Integrability,message,messages,262,I've added the checks for the deriv >= 1 spin-restricted case. Let me know if this is about right. The output is attached.; [nan_output.log](https://github.com/psi4/psi4/files/8960850/nan_output.log). I'll add the other cases after early feedback on the current messages.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2611#issuecomment-1163531527
https://github.com/psi4/psi4/pull/2611#issuecomment-1163531527:136,Testability,log,log,136,I've added the checks for the deriv >= 1 spin-restricted case. Let me know if this is about right. The output is attached.; [nan_output.log](https://github.com/psi4/psi4/files/8960850/nan_output.log). I'll add the other cases after early feedback on the current messages.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2611#issuecomment-1163531527
https://github.com/psi4/psi4/pull/2611#issuecomment-1163531527:195,Testability,log,log,195,I've added the checks for the deriv >= 1 spin-restricted case. Let me know if this is about right. The output is attached.; [nan_output.log](https://github.com/psi4/psi4/files/8960850/nan_output.log). I'll add the other cases after early feedback on the current messages.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2611#issuecomment-1163531527
https://github.com/psi4/psi4/pull/2611#issuecomment-1163531527:238,Usability,feedback,feedback,238,I've added the checks for the deriv >= 1 spin-restricted case. Let me know if this is about right. The output is attached.; [nan_output.log](https://github.com/psi4/psi4/files/8960850/nan_output.log). I'll add the other cases after early feedback on the current messages.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2611#issuecomment-1163531527
https://github.com/psi4/psi4/pull/2611#issuecomment-1166386314:261,Testability,log,log,261,"I thought based on a [previous post](https://github.com/psi4/psi4/pull/2611#issuecomment-1163642423), that there was a distinct format for spin-unrestricted and spin-restricted cases, but I can see there was a misunderstanding. How is this output?; [output.dat.log](https://github.com/psi4/psi4/files/8985763/output.dat.log)",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2611#issuecomment-1166386314
https://github.com/psi4/psi4/pull/2611#issuecomment-1166386314:320,Testability,log,log,320,"I thought based on a [previous post](https://github.com/psi4/psi4/pull/2611#issuecomment-1163642423), that there was a distinct format for spin-unrestricted and spin-restricted cases, but I can see there was a misunderstanding. How is this output?; [output.dat.log](https://github.com/psi4/psi4/files/8985763/output.dat.log)",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2611#issuecomment-1166386314
https://github.com/psi4/psi4/pull/2611#issuecomment-1166410085:34,Testability,log,log,34,> How is this output? [output.dat.log](https://github.com/psi4/psi4/files/8985763/output.dat.log). Perfect. ```; $ ./xc-get_data mgga_c_revscan 1 4.099718e-06 4.099718e-06 5.877423e-09 5.877423e-09 5.877423e-09 0 0 3.550767e-04 3.550767e-04; Unpolarized calculation; rhoa= 8.20E-06 sigmaaa= 2.35E-08 lapla= 0.00E+00 taua= 7.10E-04. 0: zk[ 0] = -NAN. 1: vrho[ 0] = -NAN; 2: vsigma[ 0] = -NAN; 3: vlapl[ 0] = 0.000000000000E+00; 4: vtau[ 0] = -NAN. 5: v2rho2[ 0] = -NAN; 6: v2rhosigma[ 0] = -NAN; 7: v2rholapl[ 0] = 0.000000000000E+00; 8: v2rhotau[ 0] = -NAN; 9: v2sigma2[ 0] = -NAN; 10: v2sigmalapl[ 0] = 0.000000000000E+00; 11: v2sigmatau[ 0] = -NAN; 12: v2lapl2[ 0] = 0.000000000000E+00; 13: v2lapltau[ 0] = 0.000000000000E+00; 14: v2tau2[ 0] = -NAN. $ ./xc-get_data mgga_c_revscan 2 4.099718e-06 4.099718e-06 5.877423e-09 5.877423e-09 5.877423e-09 0 0 3.550767e-04 3.550767e-04; Polarized calculation; rhoa= 4.10E-06 rhob= 4.10E-06 sigmaaa= 5.88E-09 sigmaab= 5.88E-09 sigmabb= 5.88E-09 lapla= 0.00E+00 laplb= 0.00E+00 taua= 3.55E-04 taub= 3.55E-04. 0: zk[ 0] = -NAN. 1: vrho[ 0] = -NAN; 2: vrho[ 1] = -NAN; 3: vsigma[ 0] = -NAN; 4: vsigma[ 1] = -NAN; 5: vsigma[ 2] = -NAN; 6: vlapl[ 0] = 0.000000000000E+00; 7: vlapl[ 1] = 0.000000000000E+00; 8: vtau[ 0] = -NAN; 9: vtau[ 1] = -NAN. 10: v2rho2[ 0] = -NAN; 11: v2rho2[ 1] = -NAN; 12: v2rho2[ 2] = -NAN; 13: v2rhosigma[ 0] = -NAN; 14: v2rhosigma[ 1] = -NAN; 15: v2rhosigma[ 2] = -NAN; 16: v2rhosigma[ 3] = -NAN; 17: v2rhosigma[ 4] = -NAN; 18: v2rhosigma[ 5] = -NAN; 19: v2rholapl[ 0] = 0.000000000000E+00; 20: v2rholapl[ 1] = 0.000000000000E+00; 21: v2rholapl[ 2] = 0.000000000000E+00; 22: v2rholapl[ 3] = 0.000000000000E+00; 23: v2rhotau[ 0] = -NAN; 24: v2rhotau[ 1] = -NAN; 25: v2rhotau[ 2] = -NAN; 26: v2rhotau[ 3] = -NAN; 27: v2sigma2[ 0] = -NAN; 28: v2sigma2[ 1] = -NAN; 29: v2sigma2[ 2] = -NAN; 30: v2sigma2[ 3] = -NAN; 31: v2sigma2[ 4] = -NAN; 32: v2sigma2[ 5] = -NAN; 33: v2sigmalapl[ 0] = 0.000000000000E+00; 34: v2sigmalapl[ 1] = 0.000000000,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2611#issuecomment-1166410085
https://github.com/psi4/psi4/pull/2611#issuecomment-1166410085:93,Testability,log,log,93,> How is this output? [output.dat.log](https://github.com/psi4/psi4/files/8985763/output.dat.log). Perfect. ```; $ ./xc-get_data mgga_c_revscan 1 4.099718e-06 4.099718e-06 5.877423e-09 5.877423e-09 5.877423e-09 0 0 3.550767e-04 3.550767e-04; Unpolarized calculation; rhoa= 8.20E-06 sigmaaa= 2.35E-08 lapla= 0.00E+00 taua= 7.10E-04. 0: zk[ 0] = -NAN. 1: vrho[ 0] = -NAN; 2: vsigma[ 0] = -NAN; 3: vlapl[ 0] = 0.000000000000E+00; 4: vtau[ 0] = -NAN. 5: v2rho2[ 0] = -NAN; 6: v2rhosigma[ 0] = -NAN; 7: v2rholapl[ 0] = 0.000000000000E+00; 8: v2rhotau[ 0] = -NAN; 9: v2sigma2[ 0] = -NAN; 10: v2sigmalapl[ 0] = 0.000000000000E+00; 11: v2sigmatau[ 0] = -NAN; 12: v2lapl2[ 0] = 0.000000000000E+00; 13: v2lapltau[ 0] = 0.000000000000E+00; 14: v2tau2[ 0] = -NAN. $ ./xc-get_data mgga_c_revscan 2 4.099718e-06 4.099718e-06 5.877423e-09 5.877423e-09 5.877423e-09 0 0 3.550767e-04 3.550767e-04; Polarized calculation; rhoa= 4.10E-06 rhob= 4.10E-06 sigmaaa= 5.88E-09 sigmaab= 5.88E-09 sigmabb= 5.88E-09 lapla= 0.00E+00 laplb= 0.00E+00 taua= 3.55E-04 taub= 3.55E-04. 0: zk[ 0] = -NAN. 1: vrho[ 0] = -NAN; 2: vrho[ 1] = -NAN; 3: vsigma[ 0] = -NAN; 4: vsigma[ 1] = -NAN; 5: vsigma[ 2] = -NAN; 6: vlapl[ 0] = 0.000000000000E+00; 7: vlapl[ 1] = 0.000000000000E+00; 8: vtau[ 0] = -NAN; 9: vtau[ 1] = -NAN. 10: v2rho2[ 0] = -NAN; 11: v2rho2[ 1] = -NAN; 12: v2rho2[ 2] = -NAN; 13: v2rhosigma[ 0] = -NAN; 14: v2rhosigma[ 1] = -NAN; 15: v2rhosigma[ 2] = -NAN; 16: v2rhosigma[ 3] = -NAN; 17: v2rhosigma[ 4] = -NAN; 18: v2rhosigma[ 5] = -NAN; 19: v2rholapl[ 0] = 0.000000000000E+00; 20: v2rholapl[ 1] = 0.000000000000E+00; 21: v2rholapl[ 2] = 0.000000000000E+00; 22: v2rholapl[ 3] = 0.000000000000E+00; 23: v2rhotau[ 0] = -NAN; 24: v2rhotau[ 1] = -NAN; 25: v2rhotau[ 2] = -NAN; 26: v2rhotau[ 3] = -NAN; 27: v2sigma2[ 0] = -NAN; 28: v2sigma2[ 1] = -NAN; 29: v2sigma2[ 2] = -NAN; 30: v2sigma2[ 3] = -NAN; 31: v2sigma2[ 4] = -NAN; 32: v2sigma2[ 5] = -NAN; 33: v2sigmalapl[ 0] = 0.000000000000E+00; 34: v2sigmalapl[ 1] = 0.000000000,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2611#issuecomment-1166410085
https://github.com/psi4/psi4/pull/2611#issuecomment-1179307181:58,Performance,perform,performance-negligible,58,"Mostly. Holger also was unconvinced the `nan` checks were performance-negligible, so I need to check that as well.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2611#issuecomment-1179307181
https://github.com/psi4/psi4/pull/2611#issuecomment-1180695095:1855,Testability,test,tests,1855,"I ran QZ Benzene (nso = 510). With 198.6 s walltime, we have...; ```; V: Grid : 1.383u 0.067s 1.243w 1 calls; | build grid : 1.183u 0.050s 1.093w 1 calls; | post-process grid : 0.200u 0.017s 0.150w 1 calls; DFH: sparsity prep : 2.067u 0.050s 1.461w 1 calls; | Libint2ERI::Libint2ERI : 1.417u 0.033s 1.055w 1 calls; Libint2ERI::Libint2ERI : 2.533u 0.033s 1.575w 2 calls; JK: (A|Q)^-1 : 1.300u 1.417s 1.553w 1 calls; | Libint2ERI::Libint2ERI : 0.000u 0.000s 0.000w 1 calls; JK: (A|mn) : 8.933u 0.050s 5.485w 3 calls; JK: (Q|mn) : 11.483u 0.083s 7.061w 3 calls; JK: (Q|mn) Write : 0.017u 0.583s 0.492w 3 calls; HF: Form core H : 0.133u 0.017s 0.086w 1 calls; HF: Form S/X : 0.183u 0.000s 0.117w 1 calls; HF: Guess : 0.233u 0.050s 0.164w 1 calls; | SAD Guess : 0.233u 0.050s 0.158w 1 calls; HF: Form G : 243.750u 9.350s 170.286w 8 calls; | RV: Form V : 179.867u 2.167s 122.104w 8 calls; | | Properties : 98.583u 0.933s 67.840w 15912 calls; | | Functional : 4.683u 0.150s 3.401w 15912 calls; | | | DFT NaN Check : 0.067u 0.033s 0.040w 15912 calls; | | V_xc : 76.250u 0.833s 50.572w 15912 calls; | JK: D : 0.017u 0.000s 0.005w 8 calls; | JK: USO2AO : 0.017u 0.000s 0.000w 8 calls; | JK: JK : 63.833u 7.183s 48.154w 8 calls; | | JK: (Q|mn) Read : 0.150u 4.217s 4.160w 25 calls; | | JK: J : 2.933u 0.017s 1.907w 25 calls; | | | JK: J1 : 1.333u 0.017s 0.862w 25 calls; | | | JK: J2 : 1.517u 0.000s 0.983w 25 calls; | | JK: K : 59.583u 0.683s 39.733w 25 calls; | | | JK: K1 : 54.533u 0.583s 36.065w 25 calls; | | | JK: K2 : 5.033u 0.100s 3.662w 25 calls; | JK: AO2USO : 0.000u 0.000s 0.000w 8 calls; HF: Form F : 0.000u 0.000s 0.011w 8 calls; HF: Form D : 0.000u 0.000s 0.007w 8 calls; HF: DIIS : 0.950u 0.350s 1.000w 7 calls; HF: Form C : 1.617u 0.017s 1.373w 7 calls; ```. NaN check time is negligible, and I think this resolves @hokru's concern. I'll re-trigger tests.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2611#issuecomment-1180695095
https://github.com/psi4/psi4/pull/2611#issuecomment-1181802960:16,Testability,test,tests,16,Will merge once tests pass.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2611#issuecomment-1181802960
https://github.com/psi4/psi4/issues/2612#issuecomment-1159340413:126,Availability,error,error,126,"The Molden documentation is unclear, but based on the code snippets you posted, your understanding of Molden's behavior is in error, and Psi is correct. 1. `rdmodd` is proof-positive that `[5D]` is used. For historical reasons, it means ""use spherical D and F functions"". This is consistent with what the Molden documentation says: ""Use the keyword [5D] on a separate line to specify the use of 'spherical' D and F functions (5 D and 7 F functions)."" While I find the meaning of the keyword unintuitive and confusing, I see nothing to support your assessment that the use of `[5D]` is _incorrect_.; 2. `rdmodd` shows that `[7F]` uses spherical f-functions but makes no statement whatsoever about the `d` functions. While the documentation says that keywords such as `[7F]` enable the use of mixed spherical and cartesians for the d and f, the documentation does not specify whether `[7F]` does this by implicitly assuming `6D` or by not changing the `D` at all, which may well be in Cartesians.; 3. Your third bullet point seem to have been miswritten. You want ""spherical or Cartesian"" and not ""Cartesian or spherical"". By specifying [5D], [7F], and [9G], Psi gives Molden the following instructions:; * Use spherical D and F shells.; * Use spherical F shells. (This is redundant but harmless, and therefore, your issue is in error.); * Use spherical G shells. I'll leave the issue open in case you point out something I've overlooked.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2612#issuecomment-1159340413
https://github.com/psi4/psi4/issues/2612#issuecomment-1159340413:1271,Availability,redundant,redundant,1271,"The Molden documentation is unclear, but based on the code snippets you posted, your understanding of Molden's behavior is in error, and Psi is correct. 1. `rdmodd` is proof-positive that `[5D]` is used. For historical reasons, it means ""use spherical D and F functions"". This is consistent with what the Molden documentation says: ""Use the keyword [5D] on a separate line to specify the use of 'spherical' D and F functions (5 D and 7 F functions)."" While I find the meaning of the keyword unintuitive and confusing, I see nothing to support your assessment that the use of `[5D]` is _incorrect_.; 2. `rdmodd` shows that `[7F]` uses spherical f-functions but makes no statement whatsoever about the `d` functions. While the documentation says that keywords such as `[7F]` enable the use of mixed spherical and cartesians for the d and f, the documentation does not specify whether `[7F]` does this by implicitly assuming `6D` or by not changing the `D` at all, which may well be in Cartesians.; 3. Your third bullet point seem to have been miswritten. You want ""spherical or Cartesian"" and not ""Cartesian or spherical"". By specifying [5D], [7F], and [9G], Psi gives Molden the following instructions:; * Use spherical D and F shells.; * Use spherical F shells. (This is redundant but harmless, and therefore, your issue is in error.); * Use spherical G shells. I'll leave the issue open in case you point out something I've overlooked.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2612#issuecomment-1159340413
https://github.com/psi4/psi4/issues/2612#issuecomment-1159340413:1327,Availability,error,error,1327,"The Molden documentation is unclear, but based on the code snippets you posted, your understanding of Molden's behavior is in error, and Psi is correct. 1. `rdmodd` is proof-positive that `[5D]` is used. For historical reasons, it means ""use spherical D and F functions"". This is consistent with what the Molden documentation says: ""Use the keyword [5D] on a separate line to specify the use of 'spherical' D and F functions (5 D and 7 F functions)."" While I find the meaning of the keyword unintuitive and confusing, I see nothing to support your assessment that the use of `[5D]` is _incorrect_.; 2. `rdmodd` shows that `[7F]` uses spherical f-functions but makes no statement whatsoever about the `d` functions. While the documentation says that keywords such as `[7F]` enable the use of mixed spherical and cartesians for the d and f, the documentation does not specify whether `[7F]` does this by implicitly assuming `6D` or by not changing the `D` at all, which may well be in Cartesians.; 3. Your third bullet point seem to have been miswritten. You want ""spherical or Cartesian"" and not ""Cartesian or spherical"". By specifying [5D], [7F], and [9G], Psi gives Molden the following instructions:; * Use spherical D and F shells.; * Use spherical F shells. (This is redundant but harmless, and therefore, your issue is in error.); * Use spherical G shells. I'll leave the issue open in case you point out something I've overlooked.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2612#issuecomment-1159340413
https://github.com/psi4/psi4/issues/2612#issuecomment-1159340413:1271,Safety,redund,redundant,1271,"The Molden documentation is unclear, but based on the code snippets you posted, your understanding of Molden's behavior is in error, and Psi is correct. 1. `rdmodd` is proof-positive that `[5D]` is used. For historical reasons, it means ""use spherical D and F functions"". This is consistent with what the Molden documentation says: ""Use the keyword [5D] on a separate line to specify the use of 'spherical' D and F functions (5 D and 7 F functions)."" While I find the meaning of the keyword unintuitive and confusing, I see nothing to support your assessment that the use of `[5D]` is _incorrect_.; 2. `rdmodd` shows that `[7F]` uses spherical f-functions but makes no statement whatsoever about the `d` functions. While the documentation says that keywords such as `[7F]` enable the use of mixed spherical and cartesians for the d and f, the documentation does not specify whether `[7F]` does this by implicitly assuming `6D` or by not changing the `D` at all, which may well be in Cartesians.; 3. Your third bullet point seem to have been miswritten. You want ""spherical or Cartesian"" and not ""Cartesian or spherical"". By specifying [5D], [7F], and [9G], Psi gives Molden the following instructions:; * Use spherical D and F shells.; * Use spherical F shells. (This is redundant but harmless, and therefore, your issue is in error.); * Use spherical G shells. I'll leave the issue open in case you point out something I've overlooked.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2612#issuecomment-1159340413
https://github.com/psi4/psi4/issues/2612#issuecomment-1159347342:158,Safety,avoid,avoid,158,"My first point was that Molden hasn't been using `[5D]` anymore for some time when writing Molden files (since 2004). It might be a good idea to follow it to avoid ambiguities. My second point is that software that follows Molden format specification (I am developing one such code) will likely see a conflict in `[5D]` and `[7F]`. Molden does not use these two flags together when writing Molden files and it never did. Even though it attempts to silently interpret their combination in some way, `[7F]` was introduced in the same version (4.1) when `[5D]` was abandoned. You are right about the interchanged words in the third point. Thank you for consideration.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2612#issuecomment-1159347342
https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542:2918,Availability,error,error,2918,"da-forge; pyyaml 6.0 py38h294d835_4 conda-forge; qcelemental 0.17.0 py_0 psi4; qcengine 0.19.0 pyhd8ed1ab_0 psi4; scipy 1.8.1 py38h9bf8e03_0 conda-forge; setuptools 61.2.0 py38haa95532_0; sqlite 3.38.3 h2bbff1b_0; tk 8.6.12 h8ffe710_0 conda-forge; tomli 2.0.1 pyhd8ed1ab_0 conda-forge; vc 14.2 h21ff451_1; vs2015_runtime 14.27.29016 h5e58377_2; wheel 0.37.1 pyhd3eb1b0_0; wincertstore 0.2 py38haa95532_2; xz 5.2.5 h62dcd97_1 conda-forge; yaml 0.2.5 h8ffe710_2 conda-forge; zipp 3.8.0 pyhd8ed1ab_0 conda-forge; ```. Manually updating pydantic with `pip install -U pydantic`, installs version 1.9.1 and then running `psi4 --test` gives:; ```; ================================================= test session starts =================================================; platform win32 -- Python 3.8.13, pytest-7.1.2, pluggy-1.0.0 -- Path\psi4conda\envs\psi16\python.exe; cachedir: .pytest_cache; rootdir: Path\psi4conda\envs\psi16\lib\site-packages\psi4, configfile: pytest.ini; collected 4042 items / 1 error / 3950 deselected / 92 selected. ======================================================= ERRORS ========================================================; _______________________________ ERROR collecting tests/test_qcel_molparse_to_string.py ________________________________; psi4conda\envs\psi16\lib\site-packages\psi4\tests\test_qcel_molparse_to_string.py:7: in <module>; from qcelemental.tests import test_molparse_to_string; <frozen importlib._bootstrap>:991: in _find_and_load; ???; <frozen importlib._bootstrap>:975: in _find_and_load_unlocked; ???; <frozen importlib._bootstrap>:671: in _load_unlocked; ???; psi4conda\envs\psi16\lib\site-packages\_pytest\assertion\rewrite.py:168: in exec_module; exec(co, module.__dict__); psi4conda\envs\psi16\lib\site-packages\qcelemental\tests\test_molparse_to_string.py:270: in <module>; ""subject1"": qcel.models.Molecule(; psi4conda\envs\psi16\lib\site-packages\qcelemental\models\molecule.py:294: in __init__; super().__init__(**kwargs); pydantic\main.p",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542
https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542:3013,Availability,ERROR,ERRORS,3013,"3_0 conda-forge; setuptools 61.2.0 py38haa95532_0; sqlite 3.38.3 h2bbff1b_0; tk 8.6.12 h8ffe710_0 conda-forge; tomli 2.0.1 pyhd8ed1ab_0 conda-forge; vc 14.2 h21ff451_1; vs2015_runtime 14.27.29016 h5e58377_2; wheel 0.37.1 pyhd3eb1b0_0; wincertstore 0.2 py38haa95532_2; xz 5.2.5 h62dcd97_1 conda-forge; yaml 0.2.5 h8ffe710_2 conda-forge; zipp 3.8.0 pyhd8ed1ab_0 conda-forge; ```. Manually updating pydantic with `pip install -U pydantic`, installs version 1.9.1 and then running `psi4 --test` gives:; ```; ================================================= test session starts =================================================; platform win32 -- Python 3.8.13, pytest-7.1.2, pluggy-1.0.0 -- Path\psi4conda\envs\psi16\python.exe; cachedir: .pytest_cache; rootdir: Path\psi4conda\envs\psi16\lib\site-packages\psi4, configfile: pytest.ini; collected 4042 items / 1 error / 3950 deselected / 92 selected. ======================================================= ERRORS ========================================================; _______________________________ ERROR collecting tests/test_qcel_molparse_to_string.py ________________________________; psi4conda\envs\psi16\lib\site-packages\psi4\tests\test_qcel_molparse_to_string.py:7: in <module>; from qcelemental.tests import test_molparse_to_string; <frozen importlib._bootstrap>:991: in _find_and_load; ???; <frozen importlib._bootstrap>:975: in _find_and_load_unlocked; ???; <frozen importlib._bootstrap>:671: in _load_unlocked; ???; psi4conda\envs\psi16\lib\site-packages\_pytest\assertion\rewrite.py:168: in exec_module; exec(co, module.__dict__); psi4conda\envs\psi16\lib\site-packages\qcelemental\tests\test_molparse_to_string.py:270: in <module>; ""subject1"": qcel.models.Molecule(; psi4conda\envs\psi16\lib\site-packages\qcelemental\models\molecule.py:294: in __init__; super().__init__(**kwargs); pydantic\main.py:341: in pydantic.main.BaseModel.__init__; ???; E pydantic.error_wrappers.ValidationError: 2 validation errors for Molecule; E connectiv",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542
https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542:3110,Availability,ERROR,ERROR,3110,"3_0 conda-forge; setuptools 61.2.0 py38haa95532_0; sqlite 3.38.3 h2bbff1b_0; tk 8.6.12 h8ffe710_0 conda-forge; tomli 2.0.1 pyhd8ed1ab_0 conda-forge; vc 14.2 h21ff451_1; vs2015_runtime 14.27.29016 h5e58377_2; wheel 0.37.1 pyhd3eb1b0_0; wincertstore 0.2 py38haa95532_2; xz 5.2.5 h62dcd97_1 conda-forge; yaml 0.2.5 h8ffe710_2 conda-forge; zipp 3.8.0 pyhd8ed1ab_0 conda-forge; ```. Manually updating pydantic with `pip install -U pydantic`, installs version 1.9.1 and then running `psi4 --test` gives:; ```; ================================================= test session starts =================================================; platform win32 -- Python 3.8.13, pytest-7.1.2, pluggy-1.0.0 -- Path\psi4conda\envs\psi16\python.exe; cachedir: .pytest_cache; rootdir: Path\psi4conda\envs\psi16\lib\site-packages\psi4, configfile: pytest.ini; collected 4042 items / 1 error / 3950 deselected / 92 selected. ======================================================= ERRORS ========================================================; _______________________________ ERROR collecting tests/test_qcel_molparse_to_string.py ________________________________; psi4conda\envs\psi16\lib\site-packages\psi4\tests\test_qcel_molparse_to_string.py:7: in <module>; from qcelemental.tests import test_molparse_to_string; <frozen importlib._bootstrap>:991: in _find_and_load; ???; <frozen importlib._bootstrap>:975: in _find_and_load_unlocked; ???; <frozen importlib._bootstrap>:671: in _load_unlocked; ???; psi4conda\envs\psi16\lib\site-packages\_pytest\assertion\rewrite.py:168: in exec_module; exec(co, module.__dict__); psi4conda\envs\psi16\lib\site-packages\qcelemental\tests\test_molparse_to_string.py:270: in <module>; ""subject1"": qcel.models.Molecule(; psi4conda\envs\psi16\lib\site-packages\qcelemental\models\molecule.py:294: in __init__; super().__init__(**kwargs); pydantic\main.py:341: in pydantic.main.BaseModel.__init__; ???; E pydantic.error_wrappers.ValidationError: 2 validation errors for Molecule; E connectiv",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542
https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542:4027,Availability,error,errors,4027,"6\lib\site-packages\psi4\tests\test_qcel_molparse_to_string.py:7: in <module>; from qcelemental.tests import test_molparse_to_string; <frozen importlib._bootstrap>:991: in _find_and_load; ???; <frozen importlib._bootstrap>:975: in _find_and_load_unlocked; ???; <frozen importlib._bootstrap>:671: in _load_unlocked; ???; psi4conda\envs\psi16\lib\site-packages\_pytest\assertion\rewrite.py:168: in exec_module; exec(co, module.__dict__); psi4conda\envs\psi16\lib\site-packages\qcelemental\tests\test_molparse_to_string.py:270: in <module>; ""subject1"": qcel.models.Molecule(; psi4conda\envs\psi16\lib\site-packages\qcelemental\models\molecule.py:294: in __init__; super().__init__(**kwargs); pydantic\main.py:341: in pydantic.main.BaseModel.__init__; ???; E pydantic.error_wrappers.ValidationError: 2 validation errors for Molecule; E connectivity -> 0; E '<' not supported between instances of 'tuple' and 'int' (type=type_error); E connectivity -> 1; E '<' not supported between instances of 'tuple' and 'int' (type=type_error); ================================================== warnings summary ===================================================; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:599; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:701; `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.; Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:698; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:699; `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542
https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542:6076,Availability,error,error,6076,"============================== warnings summary ===================================================; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:599; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:701; `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.; Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:698; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:699; `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.; Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:702; `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.; Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html; !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!; =================================== 3950 deselected, 5 warnings, 1 error in 20.79s ====================================; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542
https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542:6209,Availability,error,error,6209,"============================== warnings summary ===================================================; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:599; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:701; `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.; Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:698; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:699; `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.; Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:702; `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.; Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html; !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!; =================================== 3950 deselected, 5 warnings, 1 error in 20.79s ====================================; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542
https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542:75,Deployability,update,update,75,"This is the output and pydantic has version 1.3. How can it be that ""conda update --all"", or a fresh install for that matter, would not give me the up-to-date version?; ```; # Name Version Build Channel; atomicwrites 1.4.0 pyh9f0ad1d_0 conda-forge; attrs 21.4.0 pyhd8ed1ab_0 conda-forge; bzip2 1.0.8 h8ffe710_4 conda-forge; ca-certificates 2022.6.15 h5b45459_0 conda-forge; certifi 2022.6.15 py38haa244fe_0 conda-forge; colorama 0.4.4 pyh9f0ad1d_0 conda-forge; dftd3 3.2.1 1 psi4; gau2grid 2.0.7 hcb41399_1 conda-forge; gcp 2.0.2 0 psi4; importlib-metadata 4.11.4 py38haa244fe_0 conda-forge; importlib_metadata 4.11.4 hd8ed1ab_0 conda-forge; importlib_resources 5.8.0 pyhd8ed1ab_0 conda-forge; iniconfig 1.1.1 pyh9f0ad1d_0 conda-forge; intel-openmp 2019.1 144; libblas 3.8.0 8_mkl conda-forge; libcblas 3.8.0 8_mkl conda-forge; libffi 3.4.2 h8ffe710_5 conda-forge; libint2 2.6.0 h2e52968_4 psi4; liblapack 3.8.0 8_mkl conda-forge; libxc 5.2.3 py38h294d835_1 conda-forge; libzlib 1.2.12 h8ffe710_1 conda-forge; m2w64-gcc-libgfortran 5.3.0 6 conda-forge; m2w64-gcc-libs 5.3.0 7 conda-forge; m2w64-gcc-libs-core 5.3.0 7 conda-forge; m2w64-gmp 6.1.0 2 conda-forge; m2w64-libwinpthread-git 5.0.0.4634.697f757 2 conda-forge; mkl 2019.1 144; msgpack-python 1.0.4 py38hbd9d945_0 conda-forge; msys2-conda-epoch 20160418 1 conda-forge; networkx 2.8.4 pyhd8ed1ab_0 conda-forge; numpy 1.22.4 py38h1d2777f_0 conda-forge; openssl 3.0.3 h8ffe710_0 conda-forge; packaging 21.3 pyhd8ed1ab_0 conda-forge; pint 0.17 pyhd8ed1ab_0 psi4; pip 21.2.2 py38haa95532_0; pluggy 1.0.0 py38haa244fe_3 conda-forge; psi4 1.6+77475b5 py38_0 psi4; psutil 5.9.1 py38h294d835_0 conda-forge; py 1.11.0 pyh6c4a22f_0 conda-forge; py-cpuinfo 8.0.0 pyhd8ed1ab_0 conda-forge; pydantic 1.3 py38hfa6e2cd_0 psi4; pyparsing 3.0.9 pyhd8ed1ab_0 conda-forge; pytest 7.1.2 py38haa244fe_0 conda-forge; python 3.8.13 hcf16a7b_0_cpython conda-forge; python_abi 3.8 2_cp38 conda-forge; pyyaml 6.0 py38h294d835_4 conda-forge; qcelemental 0.17.0 py_0 psi4; ",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542
https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542:101,Deployability,install,install,101,"This is the output and pydantic has version 1.3. How can it be that ""conda update --all"", or a fresh install for that matter, would not give me the up-to-date version?; ```; # Name Version Build Channel; atomicwrites 1.4.0 pyh9f0ad1d_0 conda-forge; attrs 21.4.0 pyhd8ed1ab_0 conda-forge; bzip2 1.0.8 h8ffe710_4 conda-forge; ca-certificates 2022.6.15 h5b45459_0 conda-forge; certifi 2022.6.15 py38haa244fe_0 conda-forge; colorama 0.4.4 pyh9f0ad1d_0 conda-forge; dftd3 3.2.1 1 psi4; gau2grid 2.0.7 hcb41399_1 conda-forge; gcp 2.0.2 0 psi4; importlib-metadata 4.11.4 py38haa244fe_0 conda-forge; importlib_metadata 4.11.4 hd8ed1ab_0 conda-forge; importlib_resources 5.8.0 pyhd8ed1ab_0 conda-forge; iniconfig 1.1.1 pyh9f0ad1d_0 conda-forge; intel-openmp 2019.1 144; libblas 3.8.0 8_mkl conda-forge; libcblas 3.8.0 8_mkl conda-forge; libffi 3.4.2 h8ffe710_5 conda-forge; libint2 2.6.0 h2e52968_4 psi4; liblapack 3.8.0 8_mkl conda-forge; libxc 5.2.3 py38h294d835_1 conda-forge; libzlib 1.2.12 h8ffe710_1 conda-forge; m2w64-gcc-libgfortran 5.3.0 6 conda-forge; m2w64-gcc-libs 5.3.0 7 conda-forge; m2w64-gcc-libs-core 5.3.0 7 conda-forge; m2w64-gmp 6.1.0 2 conda-forge; m2w64-libwinpthread-git 5.0.0.4634.697f757 2 conda-forge; mkl 2019.1 144; msgpack-python 1.0.4 py38hbd9d945_0 conda-forge; msys2-conda-epoch 20160418 1 conda-forge; networkx 2.8.4 pyhd8ed1ab_0 conda-forge; numpy 1.22.4 py38h1d2777f_0 conda-forge; openssl 3.0.3 h8ffe710_0 conda-forge; packaging 21.3 pyhd8ed1ab_0 conda-forge; pint 0.17 pyhd8ed1ab_0 psi4; pip 21.2.2 py38haa95532_0; pluggy 1.0.0 py38haa244fe_3 conda-forge; psi4 1.6+77475b5 py38_0 psi4; psutil 5.9.1 py38h294d835_0 conda-forge; py 1.11.0 pyh6c4a22f_0 conda-forge; py-cpuinfo 8.0.0 pyhd8ed1ab_0 conda-forge; pydantic 1.3 py38hfa6e2cd_0 psi4; pyparsing 3.0.9 pyhd8ed1ab_0 conda-forge; pytest 7.1.2 py38haa244fe_0 conda-forge; python 3.8.13 hcf16a7b_0_cpython conda-forge; python_abi 3.8 2_cp38 conda-forge; pyyaml 6.0 py38h294d835_4 conda-forge; qcelemental 0.17.0 py_0 psi4; ",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542
https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542:2474,Deployability,install,install,2474,"onda-forge; pint 0.17 pyhd8ed1ab_0 psi4; pip 21.2.2 py38haa95532_0; pluggy 1.0.0 py38haa244fe_3 conda-forge; psi4 1.6+77475b5 py38_0 psi4; psutil 5.9.1 py38h294d835_0 conda-forge; py 1.11.0 pyh6c4a22f_0 conda-forge; py-cpuinfo 8.0.0 pyhd8ed1ab_0 conda-forge; pydantic 1.3 py38hfa6e2cd_0 psi4; pyparsing 3.0.9 pyhd8ed1ab_0 conda-forge; pytest 7.1.2 py38haa244fe_0 conda-forge; python 3.8.13 hcf16a7b_0_cpython conda-forge; python_abi 3.8 2_cp38 conda-forge; pyyaml 6.0 py38h294d835_4 conda-forge; qcelemental 0.17.0 py_0 psi4; qcengine 0.19.0 pyhd8ed1ab_0 psi4; scipy 1.8.1 py38h9bf8e03_0 conda-forge; setuptools 61.2.0 py38haa95532_0; sqlite 3.38.3 h2bbff1b_0; tk 8.6.12 h8ffe710_0 conda-forge; tomli 2.0.1 pyhd8ed1ab_0 conda-forge; vc 14.2 h21ff451_1; vs2015_runtime 14.27.29016 h5e58377_2; wheel 0.37.1 pyhd3eb1b0_0; wincertstore 0.2 py38haa95532_2; xz 5.2.5 h62dcd97_1 conda-forge; yaml 0.2.5 h8ffe710_2 conda-forge; zipp 3.8.0 pyhd8ed1ab_0 conda-forge; ```. Manually updating pydantic with `pip install -U pydantic`, installs version 1.9.1 and then running `psi4 --test` gives:; ```; ================================================= test session starts =================================================; platform win32 -- Python 3.8.13, pytest-7.1.2, pluggy-1.0.0 -- Path\psi4conda\envs\psi16\python.exe; cachedir: .pytest_cache; rootdir: Path\psi4conda\envs\psi16\lib\site-packages\psi4, configfile: pytest.ini; collected 4042 items / 1 error / 3950 deselected / 92 selected. ======================================================= ERRORS ========================================================; _______________________________ ERROR collecting tests/test_qcel_molparse_to_string.py ________________________________; psi4conda\envs\psi16\lib\site-packages\psi4\tests\test_qcel_molparse_to_string.py:7: in <module>; from qcelemental.tests import test_molparse_to_string; <frozen importlib._bootstrap>:991: in _find_and_load; ???; <frozen importlib._bootstrap>:975: in _find_and_load_unlocked; ??",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542
https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542:2496,Deployability,install,installs,2496,"onda-forge; pint 0.17 pyhd8ed1ab_0 psi4; pip 21.2.2 py38haa95532_0; pluggy 1.0.0 py38haa244fe_3 conda-forge; psi4 1.6+77475b5 py38_0 psi4; psutil 5.9.1 py38h294d835_0 conda-forge; py 1.11.0 pyh6c4a22f_0 conda-forge; py-cpuinfo 8.0.0 pyhd8ed1ab_0 conda-forge; pydantic 1.3 py38hfa6e2cd_0 psi4; pyparsing 3.0.9 pyhd8ed1ab_0 conda-forge; pytest 7.1.2 py38haa244fe_0 conda-forge; python 3.8.13 hcf16a7b_0_cpython conda-forge; python_abi 3.8 2_cp38 conda-forge; pyyaml 6.0 py38h294d835_4 conda-forge; qcelemental 0.17.0 py_0 psi4; qcengine 0.19.0 pyhd8ed1ab_0 psi4; scipy 1.8.1 py38h9bf8e03_0 conda-forge; setuptools 61.2.0 py38haa95532_0; sqlite 3.38.3 h2bbff1b_0; tk 8.6.12 h8ffe710_0 conda-forge; tomli 2.0.1 pyhd8ed1ab_0 conda-forge; vc 14.2 h21ff451_1; vs2015_runtime 14.27.29016 h5e58377_2; wheel 0.37.1 pyhd3eb1b0_0; wincertstore 0.2 py38haa95532_2; xz 5.2.5 h62dcd97_1 conda-forge; yaml 0.2.5 h8ffe710_2 conda-forge; zipp 3.8.0 pyhd8ed1ab_0 conda-forge; ```. Manually updating pydantic with `pip install -U pydantic`, installs version 1.9.1 and then running `psi4 --test` gives:; ```; ================================================= test session starts =================================================; platform win32 -- Python 3.8.13, pytest-7.1.2, pluggy-1.0.0 -- Path\psi4conda\envs\psi16\python.exe; cachedir: .pytest_cache; rootdir: Path\psi4conda\envs\psi16\lib\site-packages\psi4, configfile: pytest.ini; collected 4042 items / 1 error / 3950 deselected / 92 selected. ======================================================= ERRORS ========================================================; _______________________________ ERROR collecting tests/test_qcel_molparse_to_string.py ________________________________; psi4conda\envs\psi16\lib\site-packages\psi4\tests\test_qcel_molparse_to_string.py:7: in <module>; from qcelemental.tests import test_molparse_to_string; <frozen importlib._bootstrap>:991: in _find_and_load; ???; <frozen importlib._bootstrap>:975: in _find_and_load_unlocked; ??",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542
https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542:4843,Deployability,release,release,4843,"models\molecule.py:294: in __init__; super().__init__(**kwargs); pydantic\main.py:341: in pydantic.main.BaseModel.__init__; ???; E pydantic.error_wrappers.ValidationError: 2 validation errors for Molecule; E connectivity -> 0; E '<' not supported between instances of 'tuple' and 'int' (type=type_error); E connectivity -> 1; E '<' not supported between instances of 'tuple' and 'int' (type=type_error); ================================================== warnings summary ===================================================; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:599; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:701; `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.; Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:698; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:699; `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.; Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:702; `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.; Deprecated in Num",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542
https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542:5347,Deployability,release,release,5347,"============================== warnings summary ===================================================; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:599; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:701; `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.; Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:698; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:699; `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.; Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:702; `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.; Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html; !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!; =================================== 3950 deselected, 5 warnings, 1 error in 20.79s ====================================; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542
https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542:5477,Deployability,release,release,5477,"============================== warnings summary ===================================================; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:599; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:701; `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.; Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:698; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:699; `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.; Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:702; `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.; Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html; !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!; =================================== 3950 deselected, 5 warnings, 1 error in 20.79s ====================================; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542
https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542:5908,Deployability,release,release,5908,"============================== warnings summary ===================================================; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:599; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:701; `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.; Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:698; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:699; `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.; Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:702; `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.; Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html; !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!; =================================== 3950 deselected, 5 warnings, 1 error in 20.79s ====================================; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542
https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542:2869,Modifiability,config,configfile,2869,"a-forge; python 3.8.13 hcf16a7b_0_cpython conda-forge; python_abi 3.8 2_cp38 conda-forge; pyyaml 6.0 py38h294d835_4 conda-forge; qcelemental 0.17.0 py_0 psi4; qcengine 0.19.0 pyhd8ed1ab_0 psi4; scipy 1.8.1 py38h9bf8e03_0 conda-forge; setuptools 61.2.0 py38haa95532_0; sqlite 3.38.3 h2bbff1b_0; tk 8.6.12 h8ffe710_0 conda-forge; tomli 2.0.1 pyhd8ed1ab_0 conda-forge; vc 14.2 h21ff451_1; vs2015_runtime 14.27.29016 h5e58377_2; wheel 0.37.1 pyhd3eb1b0_0; wincertstore 0.2 py38haa95532_2; xz 5.2.5 h62dcd97_1 conda-forge; yaml 0.2.5 h8ffe710_2 conda-forge; zipp 3.8.0 pyhd8ed1ab_0 conda-forge; ```. Manually updating pydantic with `pip install -U pydantic`, installs version 1.9.1 and then running `psi4 --test` gives:; ```; ================================================= test session starts =================================================; platform win32 -- Python 3.8.13, pytest-7.1.2, pluggy-1.0.0 -- Path\psi4conda\envs\psi16\python.exe; cachedir: .pytest_cache; rootdir: Path\psi4conda\envs\psi16\lib\site-packages\psi4, configfile: pytest.ini; collected 4042 items / 1 error / 3950 deselected / 92 selected. ======================================================= ERRORS ========================================================; _______________________________ ERROR collecting tests/test_qcel_molparse_to_string.py ________________________________; psi4conda\envs\psi16\lib\site-packages\psi4\tests\test_qcel_molparse_to_string.py:7: in <module>; from qcelemental.tests import test_molparse_to_string; <frozen importlib._bootstrap>:991: in _find_and_load; ???; <frozen importlib._bootstrap>:975: in _find_and_load_unlocked; ???; <frozen importlib._bootstrap>:671: in _load_unlocked; ???; psi4conda\envs\psi16\lib\site-packages\_pytest\assertion\rewrite.py:168: in exec_module; exec(co, module.__dict__); psi4conda\envs\psi16\lib\site-packages\qcelemental\tests\test_molparse_to_string.py:270: in <module>; ""subject1"": qcel.models.Molecule(; psi4conda\envs\psi16\lib\site-packages\qcelemental\",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542
https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542:3595,Modifiability,rewrite,rewrite,3595,"gives:; ```; ================================================= test session starts =================================================; platform win32 -- Python 3.8.13, pytest-7.1.2, pluggy-1.0.0 -- Path\psi4conda\envs\psi16\python.exe; cachedir: .pytest_cache; rootdir: Path\psi4conda\envs\psi16\lib\site-packages\psi4, configfile: pytest.ini; collected 4042 items / 1 error / 3950 deselected / 92 selected. ======================================================= ERRORS ========================================================; _______________________________ ERROR collecting tests/test_qcel_molparse_to_string.py ________________________________; psi4conda\envs\psi16\lib\site-packages\psi4\tests\test_qcel_molparse_to_string.py:7: in <module>; from qcelemental.tests import test_molparse_to_string; <frozen importlib._bootstrap>:991: in _find_and_load; ???; <frozen importlib._bootstrap>:975: in _find_and_load_unlocked; ???; <frozen importlib._bootstrap>:671: in _load_unlocked; ???; psi4conda\envs\psi16\lib\site-packages\_pytest\assertion\rewrite.py:168: in exec_module; exec(co, module.__dict__); psi4conda\envs\psi16\lib\site-packages\qcelemental\tests\test_molparse_to_string.py:270: in <module>; ""subject1"": qcel.models.Molecule(; psi4conda\envs\psi16\lib\site-packages\qcelemental\models\molecule.py:294: in __init__; super().__init__(**kwargs); pydantic\main.py:341: in pydantic.main.BaseModel.__init__; ???; E pydantic.error_wrappers.ValidationError: 2 validation errors for Molecule; E connectivity -> 0; E '<' not supported between instances of 'tuple' and 'int' (type=type_error); E connectivity -> 1; E '<' not supported between instances of 'tuple' and 'int' (type=type_error); ================================================== warnings summary ===================================================; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:599; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:701; `np.float` is a depreca",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542
https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542:2785,Performance,cache,cachedir,2785,"8ed1ab_0 conda-forge; pytest 7.1.2 py38haa244fe_0 conda-forge; python 3.8.13 hcf16a7b_0_cpython conda-forge; python_abi 3.8 2_cp38 conda-forge; pyyaml 6.0 py38h294d835_4 conda-forge; qcelemental 0.17.0 py_0 psi4; qcengine 0.19.0 pyhd8ed1ab_0 psi4; scipy 1.8.1 py38h9bf8e03_0 conda-forge; setuptools 61.2.0 py38haa95532_0; sqlite 3.38.3 h2bbff1b_0; tk 8.6.12 h8ffe710_0 conda-forge; tomli 2.0.1 pyhd8ed1ab_0 conda-forge; vc 14.2 h21ff451_1; vs2015_runtime 14.27.29016 h5e58377_2; wheel 0.37.1 pyhd3eb1b0_0; wincertstore 0.2 py38haa95532_2; xz 5.2.5 h62dcd97_1 conda-forge; yaml 0.2.5 h8ffe710_2 conda-forge; zipp 3.8.0 pyhd8ed1ab_0 conda-forge; ```. Manually updating pydantic with `pip install -U pydantic`, installs version 1.9.1 and then running `psi4 --test` gives:; ```; ================================================= test session starts =================================================; platform win32 -- Python 3.8.13, pytest-7.1.2, pluggy-1.0.0 -- Path\psi4conda\envs\psi16\python.exe; cachedir: .pytest_cache; rootdir: Path\psi4conda\envs\psi16\lib\site-packages\psi4, configfile: pytest.ini; collected 4042 items / 1 error / 3950 deselected / 92 selected. ======================================================= ERRORS ========================================================; _______________________________ ERROR collecting tests/test_qcel_molparse_to_string.py ________________________________; psi4conda\envs\psi16\lib\site-packages\psi4\tests\test_qcel_molparse_to_string.py:7: in <module>; from qcelemental.tests import test_molparse_to_string; <frozen importlib._bootstrap>:991: in _find_and_load; ???; <frozen importlib._bootstrap>:975: in _find_and_load_unlocked; ???; <frozen importlib._bootstrap>:671: in _load_unlocked; ???; psi4conda\envs\psi16\lib\site-packages\_pytest\assertion\rewrite.py:168: in exec_module; exec(co, module.__dict__); psi4conda\envs\psi16\lib\site-packages\qcelemental\tests\test_molparse_to_string.py:270: in <module>; ""subject1"": qcel.models.Molecule",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542
https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542:4680,Safety,safe,safe,4680,"conda\envs\psi16\lib\site-packages\qcelemental\tests\test_molparse_to_string.py:270: in <module>; ""subject1"": qcel.models.Molecule(; psi4conda\envs\psi16\lib\site-packages\qcelemental\models\molecule.py:294: in __init__; super().__init__(**kwargs); pydantic\main.py:341: in pydantic.main.BaseModel.__init__; ???; E pydantic.error_wrappers.ValidationError: 2 validation errors for Molecule; E connectivity -> 0; E '<' not supported between instances of 'tuple' and 'int' (type=type_error); E connectivity -> 1; E '<' not supported between instances of 'tuple' and 'int' (type=type_error); ================================================== warnings summary ===================================================; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:599; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:701; `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.; Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:698; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:699; `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.; Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:702; `np.bool` is a deprecated alias for the builtin `bool`. To sil",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542
https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542:5190,Safety,safe,safe,5190,"E '<' not supported between instances of 'tuple' and 'int' (type=type_error); ================================================== warnings summary ===================================================; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:599; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:701; `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.; Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:698; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:699; `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.; Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:702; `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.; Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html; !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!; ===========================",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542
https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542:5747,Safety,safe,safe,5747,"============================== warnings summary ===================================================; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:599; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:701; `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.; Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:698; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:699; `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.; Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:702; `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.; Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html; !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!; =================================== 3950 deselected, 5 warnings, 1 error in 20.79s ====================================; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542
https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542:327,Security,certificate,certificates,327,"This is the output and pydantic has version 1.3. How can it be that ""conda update --all"", or a fresh install for that matter, would not give me the up-to-date version?; ```; # Name Version Build Channel; atomicwrites 1.4.0 pyh9f0ad1d_0 conda-forge; attrs 21.4.0 pyhd8ed1ab_0 conda-forge; bzip2 1.0.8 h8ffe710_4 conda-forge; ca-certificates 2022.6.15 h5b45459_0 conda-forge; certifi 2022.6.15 py38haa244fe_0 conda-forge; colorama 0.4.4 pyh9f0ad1d_0 conda-forge; dftd3 3.2.1 1 psi4; gau2grid 2.0.7 hcb41399_1 conda-forge; gcp 2.0.2 0 psi4; importlib-metadata 4.11.4 py38haa244fe_0 conda-forge; importlib_metadata 4.11.4 hd8ed1ab_0 conda-forge; importlib_resources 5.8.0 pyhd8ed1ab_0 conda-forge; iniconfig 1.1.1 pyh9f0ad1d_0 conda-forge; intel-openmp 2019.1 144; libblas 3.8.0 8_mkl conda-forge; libcblas 3.8.0 8_mkl conda-forge; libffi 3.4.2 h8ffe710_5 conda-forge; libint2 2.6.0 h2e52968_4 psi4; liblapack 3.8.0 8_mkl conda-forge; libxc 5.2.3 py38h294d835_1 conda-forge; libzlib 1.2.12 h8ffe710_1 conda-forge; m2w64-gcc-libgfortran 5.3.0 6 conda-forge; m2w64-gcc-libs 5.3.0 7 conda-forge; m2w64-gcc-libs-core 5.3.0 7 conda-forge; m2w64-gmp 6.1.0 2 conda-forge; m2w64-libwinpthread-git 5.0.0.4634.697f757 2 conda-forge; mkl 2019.1 144; msgpack-python 1.0.4 py38hbd9d945_0 conda-forge; msys2-conda-epoch 20160418 1 conda-forge; networkx 2.8.4 pyhd8ed1ab_0 conda-forge; numpy 1.22.4 py38h1d2777f_0 conda-forge; openssl 3.0.3 h8ffe710_0 conda-forge; packaging 21.3 pyhd8ed1ab_0 conda-forge; pint 0.17 pyhd8ed1ab_0 psi4; pip 21.2.2 py38haa95532_0; pluggy 1.0.0 py38haa244fe_3 conda-forge; psi4 1.6+77475b5 py38_0 psi4; psutil 5.9.1 py38h294d835_0 conda-forge; py 1.11.0 pyh6c4a22f_0 conda-forge; py-cpuinfo 8.0.0 pyhd8ed1ab_0 conda-forge; pydantic 1.3 py38hfa6e2cd_0 psi4; pyparsing 3.0.9 pyhd8ed1ab_0 conda-forge; pytest 7.1.2 py38haa244fe_0 conda-forge; python 3.8.13 hcf16a7b_0_cpython conda-forge; python_abi 3.8 2_cp38 conda-forge; pyyaml 6.0 py38h294d835_4 conda-forge; qcelemental 0.17.0 py_0 psi4; ",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542
https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542:3997,Security,Validat,ValidationError,3997,"6\lib\site-packages\psi4\tests\test_qcel_molparse_to_string.py:7: in <module>; from qcelemental.tests import test_molparse_to_string; <frozen importlib._bootstrap>:991: in _find_and_load; ???; <frozen importlib._bootstrap>:975: in _find_and_load_unlocked; ???; <frozen importlib._bootstrap>:671: in _load_unlocked; ???; psi4conda\envs\psi16\lib\site-packages\_pytest\assertion\rewrite.py:168: in exec_module; exec(co, module.__dict__); psi4conda\envs\psi16\lib\site-packages\qcelemental\tests\test_molparse_to_string.py:270: in <module>; ""subject1"": qcel.models.Molecule(; psi4conda\envs\psi16\lib\site-packages\qcelemental\models\molecule.py:294: in __init__; super().__init__(**kwargs); pydantic\main.py:341: in pydantic.main.BaseModel.__init__; ???; E pydantic.error_wrappers.ValidationError: 2 validation errors for Molecule; E connectivity -> 0; E '<' not supported between instances of 'tuple' and 'int' (type=type_error); E connectivity -> 1; E '<' not supported between instances of 'tuple' and 'int' (type=type_error); ================================================== warnings summary ===================================================; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:599; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:701; `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.; Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:698; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:699; `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542
https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542:4016,Security,validat,validation,4016,"6\lib\site-packages\psi4\tests\test_qcel_molparse_to_string.py:7: in <module>; from qcelemental.tests import test_molparse_to_string; <frozen importlib._bootstrap>:991: in _find_and_load; ???; <frozen importlib._bootstrap>:975: in _find_and_load_unlocked; ???; <frozen importlib._bootstrap>:671: in _load_unlocked; ???; psi4conda\envs\psi16\lib\site-packages\_pytest\assertion\rewrite.py:168: in exec_module; exec(co, module.__dict__); psi4conda\envs\psi16\lib\site-packages\qcelemental\tests\test_molparse_to_string.py:270: in <module>; ""subject1"": qcel.models.Molecule(; psi4conda\envs\psi16\lib\site-packages\qcelemental\models\molecule.py:294: in __init__; super().__init__(**kwargs); pydantic\main.py:341: in pydantic.main.BaseModel.__init__; ???; E pydantic.error_wrappers.ValidationError: 2 validation errors for Molecule; E connectivity -> 0; E '<' not supported between instances of 'tuple' and 'int' (type=type_error); E connectivity -> 1; E '<' not supported between instances of 'tuple' and 'int' (type=type_error); ================================================== warnings summary ===================================================; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:599; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:701; `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.; Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:698; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:699; `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542
https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542:2544,Testability,test,test,2544,"psutil 5.9.1 py38h294d835_0 conda-forge; py 1.11.0 pyh6c4a22f_0 conda-forge; py-cpuinfo 8.0.0 pyhd8ed1ab_0 conda-forge; pydantic 1.3 py38hfa6e2cd_0 psi4; pyparsing 3.0.9 pyhd8ed1ab_0 conda-forge; pytest 7.1.2 py38haa244fe_0 conda-forge; python 3.8.13 hcf16a7b_0_cpython conda-forge; python_abi 3.8 2_cp38 conda-forge; pyyaml 6.0 py38h294d835_4 conda-forge; qcelemental 0.17.0 py_0 psi4; qcengine 0.19.0 pyhd8ed1ab_0 psi4; scipy 1.8.1 py38h9bf8e03_0 conda-forge; setuptools 61.2.0 py38haa95532_0; sqlite 3.38.3 h2bbff1b_0; tk 8.6.12 h8ffe710_0 conda-forge; tomli 2.0.1 pyhd8ed1ab_0 conda-forge; vc 14.2 h21ff451_1; vs2015_runtime 14.27.29016 h5e58377_2; wheel 0.37.1 pyhd3eb1b0_0; wincertstore 0.2 py38haa95532_2; xz 5.2.5 h62dcd97_1 conda-forge; yaml 0.2.5 h8ffe710_2 conda-forge; zipp 3.8.0 pyhd8ed1ab_0 conda-forge; ```. Manually updating pydantic with `pip install -U pydantic`, installs version 1.9.1 and then running `psi4 --test` gives:; ```; ================================================= test session starts =================================================; platform win32 -- Python 3.8.13, pytest-7.1.2, pluggy-1.0.0 -- Path\psi4conda\envs\psi16\python.exe; cachedir: .pytest_cache; rootdir: Path\psi4conda\envs\psi16\lib\site-packages\psi4, configfile: pytest.ini; collected 4042 items / 1 error / 3950 deselected / 92 selected. ======================================================= ERRORS ========================================================; _______________________________ ERROR collecting tests/test_qcel_molparse_to_string.py ________________________________; psi4conda\envs\psi16\lib\site-packages\psi4\tests\test_qcel_molparse_to_string.py:7: in <module>; from qcelemental.tests import test_molparse_to_string; <frozen importlib._bootstrap>:991: in _find_and_load; ???; <frozen importlib._bootstrap>:975: in _find_and_load_unlocked; ???; <frozen importlib._bootstrap>:671: in _load_unlocked; ???; psi4conda\envs\psi16\lib\site-packages\_pytest\assertion\rewrite.py:168: in ",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542
https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542:2613,Testability,test,test,2613,"psutil 5.9.1 py38h294d835_0 conda-forge; py 1.11.0 pyh6c4a22f_0 conda-forge; py-cpuinfo 8.0.0 pyhd8ed1ab_0 conda-forge; pydantic 1.3 py38hfa6e2cd_0 psi4; pyparsing 3.0.9 pyhd8ed1ab_0 conda-forge; pytest 7.1.2 py38haa244fe_0 conda-forge; python 3.8.13 hcf16a7b_0_cpython conda-forge; python_abi 3.8 2_cp38 conda-forge; pyyaml 6.0 py38h294d835_4 conda-forge; qcelemental 0.17.0 py_0 psi4; qcengine 0.19.0 pyhd8ed1ab_0 psi4; scipy 1.8.1 py38h9bf8e03_0 conda-forge; setuptools 61.2.0 py38haa95532_0; sqlite 3.38.3 h2bbff1b_0; tk 8.6.12 h8ffe710_0 conda-forge; tomli 2.0.1 pyhd8ed1ab_0 conda-forge; vc 14.2 h21ff451_1; vs2015_runtime 14.27.29016 h5e58377_2; wheel 0.37.1 pyhd3eb1b0_0; wincertstore 0.2 py38haa95532_2; xz 5.2.5 h62dcd97_1 conda-forge; yaml 0.2.5 h8ffe710_2 conda-forge; zipp 3.8.0 pyhd8ed1ab_0 conda-forge; ```. Manually updating pydantic with `pip install -U pydantic`, installs version 1.9.1 and then running `psi4 --test` gives:; ```; ================================================= test session starts =================================================; platform win32 -- Python 3.8.13, pytest-7.1.2, pluggy-1.0.0 -- Path\psi4conda\envs\psi16\python.exe; cachedir: .pytest_cache; rootdir: Path\psi4conda\envs\psi16\lib\site-packages\psi4, configfile: pytest.ini; collected 4042 items / 1 error / 3950 deselected / 92 selected. ======================================================= ERRORS ========================================================; _______________________________ ERROR collecting tests/test_qcel_molparse_to_string.py ________________________________; psi4conda\envs\psi16\lib\site-packages\psi4\tests\test_qcel_molparse_to_string.py:7: in <module>; from qcelemental.tests import test_molparse_to_string; <frozen importlib._bootstrap>:991: in _find_and_load; ???; <frozen importlib._bootstrap>:975: in _find_and_load_unlocked; ???; <frozen importlib._bootstrap>:671: in _load_unlocked; ???; psi4conda\envs\psi16\lib\site-packages\_pytest\assertion\rewrite.py:168: in ",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542
https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542:3127,Testability,test,tests,3127,"3_0 conda-forge; setuptools 61.2.0 py38haa95532_0; sqlite 3.38.3 h2bbff1b_0; tk 8.6.12 h8ffe710_0 conda-forge; tomli 2.0.1 pyhd8ed1ab_0 conda-forge; vc 14.2 h21ff451_1; vs2015_runtime 14.27.29016 h5e58377_2; wheel 0.37.1 pyhd3eb1b0_0; wincertstore 0.2 py38haa95532_2; xz 5.2.5 h62dcd97_1 conda-forge; yaml 0.2.5 h8ffe710_2 conda-forge; zipp 3.8.0 pyhd8ed1ab_0 conda-forge; ```. Manually updating pydantic with `pip install -U pydantic`, installs version 1.9.1 and then running `psi4 --test` gives:; ```; ================================================= test session starts =================================================; platform win32 -- Python 3.8.13, pytest-7.1.2, pluggy-1.0.0 -- Path\psi4conda\envs\psi16\python.exe; cachedir: .pytest_cache; rootdir: Path\psi4conda\envs\psi16\lib\site-packages\psi4, configfile: pytest.ini; collected 4042 items / 1 error / 3950 deselected / 92 selected. ======================================================= ERRORS ========================================================; _______________________________ ERROR collecting tests/test_qcel_molparse_to_string.py ________________________________; psi4conda\envs\psi16\lib\site-packages\psi4\tests\test_qcel_molparse_to_string.py:7: in <module>; from qcelemental.tests import test_molparse_to_string; <frozen importlib._bootstrap>:991: in _find_and_load; ???; <frozen importlib._bootstrap>:975: in _find_and_load_unlocked; ???; <frozen importlib._bootstrap>:671: in _load_unlocked; ???; psi4conda\envs\psi16\lib\site-packages\_pytest\assertion\rewrite.py:168: in exec_module; exec(co, module.__dict__); psi4conda\envs\psi16\lib\site-packages\qcelemental\tests\test_molparse_to_string.py:270: in <module>; ""subject1"": qcel.models.Molecule(; psi4conda\envs\psi16\lib\site-packages\qcelemental\models\molecule.py:294: in __init__; super().__init__(**kwargs); pydantic\main.py:341: in pydantic.main.BaseModel.__init__; ???; E pydantic.error_wrappers.ValidationError: 2 validation errors for Molecule; E connectiv",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542
https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542:3243,Testability,test,tests,3243,"f451_1; vs2015_runtime 14.27.29016 h5e58377_2; wheel 0.37.1 pyhd3eb1b0_0; wincertstore 0.2 py38haa95532_2; xz 5.2.5 h62dcd97_1 conda-forge; yaml 0.2.5 h8ffe710_2 conda-forge; zipp 3.8.0 pyhd8ed1ab_0 conda-forge; ```. Manually updating pydantic with `pip install -U pydantic`, installs version 1.9.1 and then running `psi4 --test` gives:; ```; ================================================= test session starts =================================================; platform win32 -- Python 3.8.13, pytest-7.1.2, pluggy-1.0.0 -- Path\psi4conda\envs\psi16\python.exe; cachedir: .pytest_cache; rootdir: Path\psi4conda\envs\psi16\lib\site-packages\psi4, configfile: pytest.ini; collected 4042 items / 1 error / 3950 deselected / 92 selected. ======================================================= ERRORS ========================================================; _______________________________ ERROR collecting tests/test_qcel_molparse_to_string.py ________________________________; psi4conda\envs\psi16\lib\site-packages\psi4\tests\test_qcel_molparse_to_string.py:7: in <module>; from qcelemental.tests import test_molparse_to_string; <frozen importlib._bootstrap>:991: in _find_and_load; ???; <frozen importlib._bootstrap>:975: in _find_and_load_unlocked; ???; <frozen importlib._bootstrap>:671: in _load_unlocked; ???; psi4conda\envs\psi16\lib\site-packages\_pytest\assertion\rewrite.py:168: in exec_module; exec(co, module.__dict__); psi4conda\envs\psi16\lib\site-packages\qcelemental\tests\test_molparse_to_string.py:270: in <module>; ""subject1"": qcel.models.Molecule(; psi4conda\envs\psi16\lib\site-packages\qcelemental\models\molecule.py:294: in __init__; super().__init__(**kwargs); pydantic\main.py:341: in pydantic.main.BaseModel.__init__; ???; E pydantic.error_wrappers.ValidationError: 2 validation errors for Molecule; E connectivity -> 0; E '<' not supported between instances of 'tuple' and 'int' (type=type_error); E connectivity -> 1; E '<' not supported between instances of 'tuple' and",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542
https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542:3314,Testability,test,tests,3314,"97_1 conda-forge; yaml 0.2.5 h8ffe710_2 conda-forge; zipp 3.8.0 pyhd8ed1ab_0 conda-forge; ```. Manually updating pydantic with `pip install -U pydantic`, installs version 1.9.1 and then running `psi4 --test` gives:; ```; ================================================= test session starts =================================================; platform win32 -- Python 3.8.13, pytest-7.1.2, pluggy-1.0.0 -- Path\psi4conda\envs\psi16\python.exe; cachedir: .pytest_cache; rootdir: Path\psi4conda\envs\psi16\lib\site-packages\psi4, configfile: pytest.ini; collected 4042 items / 1 error / 3950 deselected / 92 selected. ======================================================= ERRORS ========================================================; _______________________________ ERROR collecting tests/test_qcel_molparse_to_string.py ________________________________; psi4conda\envs\psi16\lib\site-packages\psi4\tests\test_qcel_molparse_to_string.py:7: in <module>; from qcelemental.tests import test_molparse_to_string; <frozen importlib._bootstrap>:991: in _find_and_load; ???; <frozen importlib._bootstrap>:975: in _find_and_load_unlocked; ???; <frozen importlib._bootstrap>:671: in _load_unlocked; ???; psi4conda\envs\psi16\lib\site-packages\_pytest\assertion\rewrite.py:168: in exec_module; exec(co, module.__dict__); psi4conda\envs\psi16\lib\site-packages\qcelemental\tests\test_molparse_to_string.py:270: in <module>; ""subject1"": qcel.models.Molecule(; psi4conda\envs\psi16\lib\site-packages\qcelemental\models\molecule.py:294: in __init__; super().__init__(**kwargs); pydantic\main.py:341: in pydantic.main.BaseModel.__init__; ???; E pydantic.error_wrappers.ValidationError: 2 validation errors for Molecule; E connectivity -> 0; E '<' not supported between instances of 'tuple' and 'int' (type=type_error); E connectivity -> 1; E '<' not supported between instances of 'tuple' and 'int' (type=type_error); ================================================== warnings summary ============================",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542
https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542:3585,Testability,assert,assertion,3585,"gives:; ```; ================================================= test session starts =================================================; platform win32 -- Python 3.8.13, pytest-7.1.2, pluggy-1.0.0 -- Path\psi4conda\envs\psi16\python.exe; cachedir: .pytest_cache; rootdir: Path\psi4conda\envs\psi16\lib\site-packages\psi4, configfile: pytest.ini; collected 4042 items / 1 error / 3950 deselected / 92 selected. ======================================================= ERRORS ========================================================; _______________________________ ERROR collecting tests/test_qcel_molparse_to_string.py ________________________________; psi4conda\envs\psi16\lib\site-packages\psi4\tests\test_qcel_molparse_to_string.py:7: in <module>; from qcelemental.tests import test_molparse_to_string; <frozen importlib._bootstrap>:991: in _find_and_load; ???; <frozen importlib._bootstrap>:975: in _find_and_load_unlocked; ???; <frozen importlib._bootstrap>:671: in _load_unlocked; ???; psi4conda\envs\psi16\lib\site-packages\_pytest\assertion\rewrite.py:168: in exec_module; exec(co, module.__dict__); psi4conda\envs\psi16\lib\site-packages\qcelemental\tests\test_molparse_to_string.py:270: in <module>; ""subject1"": qcel.models.Molecule(; psi4conda\envs\psi16\lib\site-packages\qcelemental\models\molecule.py:294: in __init__; super().__init__(**kwargs); pydantic\main.py:341: in pydantic.main.BaseModel.__init__; ???; E pydantic.error_wrappers.ValidationError: 2 validation errors for Molecule; E connectivity -> 0; E '<' not supported between instances of 'tuple' and 'int' (type=type_error); E connectivity -> 1; E '<' not supported between instances of 'tuple' and 'int' (type=type_error); ================================================== warnings summary ===================================================; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:599; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:701; `np.float` is a depreca",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542
https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542:3705,Testability,test,tests,3705,"orm win32 -- Python 3.8.13, pytest-7.1.2, pluggy-1.0.0 -- Path\psi4conda\envs\psi16\python.exe; cachedir: .pytest_cache; rootdir: Path\psi4conda\envs\psi16\lib\site-packages\psi4, configfile: pytest.ini; collected 4042 items / 1 error / 3950 deselected / 92 selected. ======================================================= ERRORS ========================================================; _______________________________ ERROR collecting tests/test_qcel_molparse_to_string.py ________________________________; psi4conda\envs\psi16\lib\site-packages\psi4\tests\test_qcel_molparse_to_string.py:7: in <module>; from qcelemental.tests import test_molparse_to_string; <frozen importlib._bootstrap>:991: in _find_and_load; ???; <frozen importlib._bootstrap>:975: in _find_and_load_unlocked; ???; <frozen importlib._bootstrap>:671: in _load_unlocked; ???; psi4conda\envs\psi16\lib\site-packages\_pytest\assertion\rewrite.py:168: in exec_module; exec(co, module.__dict__); psi4conda\envs\psi16\lib\site-packages\qcelemental\tests\test_molparse_to_string.py:270: in <module>; ""subject1"": qcel.models.Molecule(; psi4conda\envs\psi16\lib\site-packages\qcelemental\models\molecule.py:294: in __init__; super().__init__(**kwargs); pydantic\main.py:341: in pydantic.main.BaseModel.__init__; ???; E pydantic.error_wrappers.ValidationError: 2 validation errors for Molecule; E connectivity -> 0; E '<' not supported between instances of 'tuple' and 'int' (type=type_error); E connectivity -> 1; E '<' not supported between instances of 'tuple' and 'int' (type=type_error); ================================================== warnings summary ===================================================; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:599; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:701; `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If ",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542
https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542:4807,Usability,guid,guidance,4807,"psi16\lib\site-packages\qcelemental\models\molecule.py:294: in __init__; super().__init__(**kwargs); pydantic\main.py:341: in pydantic.main.BaseModel.__init__; ???; E pydantic.error_wrappers.ValidationError: 2 validation errors for Molecule; E connectivity -> 0; E '<' not supported between instances of 'tuple' and 'int' (type=type_error); E connectivity -> 1; E '<' not supported between instances of 'tuple' and 'int' (type=type_error); ================================================== warnings summary ===================================================; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:599; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:701; `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.; Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:698; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:699; `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.; Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:702; `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use ",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542
https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542:5441,Usability,guid,guidance,5441,"============================== warnings summary ===================================================; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:599; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:701; `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.; Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:698; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:699; `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.; Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:702; `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.; Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html; !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!; =================================== 3950 deselected, 5 warnings, 1 error in 20.79s ====================================; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542
https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542:5872,Usability,guid,guidance,5872,"============================== warnings summary ===================================================; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:599; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:701; `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.; Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:698; psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:699; `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.; Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. psi4conda\envs\psi16\lib\site-packages\qcelemental\molparse\from_arrays.py:702; `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.; Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html; !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!; =================================== 3950 deselected, 5 warnings, 1 error in 20.79s ====================================; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1160363542
https://github.com/psi4/psi4/issues/2614#issuecomment-1160375262:76,Testability,test,test,76,"@JonathonMisiewicz I now edited the post before and added what doing psi4 --test and running a job outputs for me. Edit again: Ok, my bad I had a wrong input file. Will try again asap",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1160375262
https://github.com/psi4/psi4/issues/2614#issuecomment-1161383668:343,Deployability,update,update,343,"I ran your command but I get pydantic v1.3 again by default. Here is the output of `conda list`:. ```; # Name Version Build Channel; pydantic 1.3 py38hfa6e2cd_0 psi4; ```. Edit: Now it tells me that a newer conda version exists. ; ```; ==> WARNING: A newer version of conda exists. <==; current version: 4.12.0; latest version: 4.13.0. Please update conda by running; $ conda update -n base conda; ```. Having updated the base conda, it still gives me the default version of 1.3, however.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1161383668
https://github.com/psi4/psi4/issues/2614#issuecomment-1161383668:376,Deployability,update,update,376,"I ran your command but I get pydantic v1.3 again by default. Here is the output of `conda list`:. ```; # Name Version Build Channel; pydantic 1.3 py38hfa6e2cd_0 psi4; ```. Edit: Now it tells me that a newer conda version exists. ; ```; ==> WARNING: A newer version of conda exists. <==; current version: 4.12.0; latest version: 4.13.0. Please update conda by running; $ conda update -n base conda; ```. Having updated the base conda, it still gives me the default version of 1.3, however.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1161383668
https://github.com/psi4/psi4/issues/2614#issuecomment-1161383668:410,Deployability,update,updated,410,"I ran your command but I get pydantic v1.3 again by default. Here is the output of `conda list`:. ```; # Name Version Build Channel; pydantic 1.3 py38hfa6e2cd_0 psi4; ```. Edit: Now it tells me that a newer conda version exists. ; ```; ==> WARNING: A newer version of conda exists. <==; current version: 4.12.0; latest version: 4.13.0. Please update conda by running; $ conda update -n base conda; ```. Having updated the base conda, it still gives me the default version of 1.3, however.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1161383668
https://github.com/psi4/psi4/issues/2614#issuecomment-1161833721:449,Deployability,release,releases,449,"Ok, I understand what's going on now. Background is that the windows package goes through a different build process than linux and mac, so it doesn't get pinned as well as it ought (particularly, in this case, for qcelemental and qcengine). And the psi4 channel used to have to host some non-qc packages (like pydantic and pint) before the big base channels (defaults, conda-forge) had the needed versions. Anyway, the env you show has very old (10 releases behind) qcel and qcengine packages, and those use pre-1.8.2 pydantic. The solution is to switch the channel order `-c conda-forge -c psi4` so that only the few packages needed from the psi4 channel (psi4 itself, libint2) get pulled from it. Thanks for alerting us to this issue. For future reference, I'll post this handy command that lets one solve windows environments from non-win platforms: `CONDA_SUBDIR=win-64 conda create -n winprob python=3.8 psi4 -c psi4 -c conda-forge`",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1161833721
https://github.com/psi4/psi4/issues/2614#issuecomment-1175688640:23,Availability,error,error,23,still getting the same error after running the following:. conda create -n psi16 python=3.8; conda activate psi16; conda update --all; conda install psi4 python=3.8 -c psi4 -c conda-forge -c psi4; psi4 --test. :(,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1175688640
https://github.com/psi4/psi4/issues/2614#issuecomment-1175688640:121,Deployability,update,update,121,still getting the same error after running the following:. conda create -n psi16 python=3.8; conda activate psi16; conda update --all; conda install psi4 python=3.8 -c psi4 -c conda-forge -c psi4; psi4 --test. :(,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1175688640
https://github.com/psi4/psi4/issues/2614#issuecomment-1175688640:141,Deployability,install,install,141,still getting the same error after running the following:. conda create -n psi16 python=3.8; conda activate psi16; conda update --all; conda install psi4 python=3.8 -c psi4 -c conda-forge -c psi4; psi4 --test. :(,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1175688640
https://github.com/psi4/psi4/issues/2614#issuecomment-1175688640:204,Testability,test,test,204,still getting the same error after running the following:. conda create -n psi16 python=3.8; conda activate psi16; conda update --all; conda install psi4 python=3.8 -c psi4 -c conda-forge -c psi4; psi4 --test. :(,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1175688640
https://github.com/psi4/psi4/issues/2614#issuecomment-1175694537:56,Deployability,install,installing,56,sorry i'm new to this and i've been having trouble with installing and running psi4 on Windows,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1175694537
https://github.com/psi4/psi4/issues/2614#issuecomment-1175715270:386,Availability,error,error,386,"At a glance, your `conda list` is fine, though you should always copy the text from screen and paste within triple backticks for formatting rather than post screenshots. > how do you mean channel order reversed? :((. `conda create -n psi16 psi4 python=3.8 -c psi4 -c conda-forge` with ""channel order reversed"" makes `conda create -n psi16 psi4 python=3.8 -c conda-forge -c psi4`. ""same error"" is hard to diagnose -- you'd have to post the solve-time or run-time error.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1175715270
https://github.com/psi4/psi4/issues/2614#issuecomment-1175715270:462,Availability,error,error,462,"At a glance, your `conda list` is fine, though you should always copy the text from screen and paste within triple backticks for formatting rather than post screenshots. > how do you mean channel order reversed? :((. `conda create -n psi16 psi4 python=3.8 -c psi4 -c conda-forge` with ""channel order reversed"" makes `conda create -n psi16 psi4 python=3.8 -c conda-forge -c psi4`. ""same error"" is hard to diagnose -- you'd have to post the solve-time or run-time error.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1175715270
https://github.com/psi4/psi4/issues/2614#issuecomment-1175773574:100,Availability,error,errors,100,"> heya it says 40 passed, 51 skipped, 4026 deselected, 1x failed in 283.19s (0:04:43). no failed or errors, so it seems to be working fine. https://docs.pytest.org/en/7.1.x/how-to/output.html?highlight=xpass#producing-a-detailed-summary-report. > also how do you copy paste i try the ctrl+shift+c but it doesn't look as it should. you'd have to look that up for your OS and terminal",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2614#issuecomment-1175773574
https://github.com/psi4/psi4/pull/2619#issuecomment-1162453607:4,Availability,failure,failure,4,"Eco failure is, quite predictably, because it breaks `v2rdm`.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2619#issuecomment-1162453607
https://github.com/psi4/psi4/pull/2619#issuecomment-1162453607:22,Safety,predict,predictably,22,"Eco failure is, quite predictably, because it breaks `v2rdm`.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2619#issuecomment-1162453607
https://github.com/psi4/psi4/pull/2619#issuecomment-1163433170:116,Modifiability,plugin,plugin,116,"After discussion with Lori, work on getting this PR through will resume after MQM. We also have a plan to deal with plugin incompatibilities. Feel free to review earlier if you wish.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2619#issuecomment-1163433170
https://github.com/psi4/psi4/pull/2619#issuecomment-1163433170:65,Usability,resume,resume,65,"After discussion with Lori, work on getting this PR through will resume after MQM. We also have a plan to deal with plugin incompatibilities. Feel free to review earlier if you wish.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2619#issuecomment-1163433170
https://github.com/psi4/psi4/pull/2619#issuecomment-1208292542:27,Testability,test,testing,27,All comments except FockCI testing addressed.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2619#issuecomment-1208292542
https://github.com/psi4/psi4/pull/2619#issuecomment-1210703774:64,Testability,test,test,64,"> LGTM, thanks for working on this. Any reason for not adding a test or two?. No tests came to mind as worth adding. If you have suggestions, I'll probably take them.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2619#issuecomment-1210703774
https://github.com/psi4/psi4/pull/2619#issuecomment-1210703774:81,Testability,test,tests,81,"> LGTM, thanks for working on this. Any reason for not adding a test or two?. No tests came to mind as worth adding. If you have suggestions, I'll probably take them.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2619#issuecomment-1210703774
https://github.com/psi4/psi4/pull/2619#issuecomment-1212029957:66,Testability,test,test,66,"> > LGTM, thanks for working on this. Any reason for not adding a test or two?; > ; > No tests came to mind as worth adding. If you have suggestions, I'll probably take them. Any one of the various failing SCF calculations where occupations break old invalid assumptions?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2619#issuecomment-1212029957
https://github.com/psi4/psi4/pull/2619#issuecomment-1212029957:89,Testability,test,tests,89,"> > LGTM, thanks for working on this. Any reason for not adding a test or two?; > ; > No tests came to mind as worth adding. If you have suggestions, I'll probably take them. Any one of the various failing SCF calculations where occupations break old invalid assumptions?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2619#issuecomment-1212029957
https://github.com/psi4/psi4/pull/2619#issuecomment-1212032494:87,Testability,test,test,87,"> A subsequent PR will fix the linked issues (if not fixed by this PR) and add them as test cases once the fix is confirmed. On my to-do list, I just wasn't confident those would already be fixed by this PR. Thanks for the reminder.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2619#issuecomment-1212032494
https://github.com/psi4/psi4/issues/2621#issuecomment-1164880108:208,Availability,error,error,208,"Psi4 is really only safe to install with a defaults base, not a c-f base, on Linux. If you added `defaults` to the channel list or `anaconda::intel-openmp`, it'd likely solve, but I think you'd get a runtime error related to symbols and/or mkl- vs openblas-based environment. It's possible to get it working through a careful install order (iirc) or to run two conda envs at once (one defaults-based with psi4 and one c-f based with others) as the ecosystem GHA does. But on the whole, Linux psi4 in c-f env is not suggested.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2621#issuecomment-1164880108
https://github.com/psi4/psi4/issues/2621#issuecomment-1164880108:28,Deployability,install,install,28,"Psi4 is really only safe to install with a defaults base, not a c-f base, on Linux. If you added `defaults` to the channel list or `anaconda::intel-openmp`, it'd likely solve, but I think you'd get a runtime error related to symbols and/or mkl- vs openblas-based environment. It's possible to get it working through a careful install order (iirc) or to run two conda envs at once (one defaults-based with psi4 and one c-f based with others) as the ecosystem GHA does. But on the whole, Linux psi4 in c-f env is not suggested.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2621#issuecomment-1164880108
https://github.com/psi4/psi4/issues/2621#issuecomment-1164880108:326,Deployability,install,install,326,"Psi4 is really only safe to install with a defaults base, not a c-f base, on Linux. If you added `defaults` to the channel list or `anaconda::intel-openmp`, it'd likely solve, but I think you'd get a runtime error related to symbols and/or mkl- vs openblas-based environment. It's possible to get it working through a careful install order (iirc) or to run two conda envs at once (one defaults-based with psi4 and one c-f based with others) as the ecosystem GHA does. But on the whole, Linux psi4 in c-f env is not suggested.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2621#issuecomment-1164880108
https://github.com/psi4/psi4/issues/2621#issuecomment-1164880108:20,Safety,safe,safe,20,"Psi4 is really only safe to install with a defaults base, not a c-f base, on Linux. If you added `defaults` to the channel list or `anaconda::intel-openmp`, it'd likely solve, but I think you'd get a runtime error related to symbols and/or mkl- vs openblas-based environment. It's possible to get it working through a careful install order (iirc) or to run two conda envs at once (one defaults-based with psi4 and one c-f based with others) as the ecosystem GHA does. But on the whole, Linux psi4 in c-f env is not suggested.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2621#issuecomment-1164880108
https://github.com/psi4/psi4/issues/2621#issuecomment-1164884983:228,Availability,error,errors,228,"Thanks for the quick answer that is helpful. We recently switched all our internal codebase to conda-forge only since mixing default/anaconda and conda-forge were creating an infinite list of either dep solving issues or symbol errors. I still tried to add `anaconda::intel-openmp` or simply the `anaconda` channel to see if I could get it to work for this simple env at least but I got another dep issue: `package psi4-1.6+77475b5-py39hceaf722_0 requires libxc 5.1.5 h84b9e52_1, but none of the providers can be installed`. If you haven't built psi4 from conda-forge but with defaults I am not surprised I am having this kind of issues. Hopefully psi4 will hit conda forge soon xD. Thanks again (feel free to close)",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2621#issuecomment-1164884983
https://github.com/psi4/psi4/issues/2621#issuecomment-1164884983:513,Deployability,install,installed,513,"Thanks for the quick answer that is helpful. We recently switched all our internal codebase to conda-forge only since mixing default/anaconda and conda-forge were creating an infinite list of either dep solving issues or symbol errors. I still tried to add `anaconda::intel-openmp` or simply the `anaconda` channel to see if I could get it to work for this simple env at least but I got another dep issue: `package psi4-1.6+77475b5-py39hceaf722_0 requires libxc 5.1.5 h84b9e52_1, but none of the providers can be installed`. If you haven't built psi4 from conda-forge but with defaults I am not surprised I am having this kind of issues. Hopefully psi4 will hit conda forge soon xD. Thanks again (feel free to close)",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2621#issuecomment-1164884983
https://github.com/psi4/psi4/issues/2621#issuecomment-1164884983:285,Usability,simpl,simply,285,"Thanks for the quick answer that is helpful. We recently switched all our internal codebase to conda-forge only since mixing default/anaconda and conda-forge were creating an infinite list of either dep solving issues or symbol errors. I still tried to add `anaconda::intel-openmp` or simply the `anaconda` channel to see if I could get it to work for this simple env at least but I got another dep issue: `package psi4-1.6+77475b5-py39hceaf722_0 requires libxc 5.1.5 h84b9e52_1, but none of the providers can be installed`. If you haven't built psi4 from conda-forge but with defaults I am not surprised I am having this kind of issues. Hopefully psi4 will hit conda forge soon xD. Thanks again (feel free to close)",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2621#issuecomment-1164884983
https://github.com/psi4/psi4/issues/2621#issuecomment-1164884983:357,Usability,simpl,simple,357,"Thanks for the quick answer that is helpful. We recently switched all our internal codebase to conda-forge only since mixing default/anaconda and conda-forge were creating an infinite list of either dep solving issues or symbol errors. I still tried to add `anaconda::intel-openmp` or simply the `anaconda` channel to see if I could get it to work for this simple env at least but I got another dep issue: `package psi4-1.6+77475b5-py39hceaf722_0 requires libxc 5.1.5 h84b9e52_1, but none of the providers can be installed`. If you haven't built psi4 from conda-forge but with defaults I am not surprised I am having this kind of issues. Hopefully psi4 will hit conda forge soon xD. Thanks again (feel free to close)",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2621#issuecomment-1164884983
https://github.com/psi4/psi4/issues/2621#issuecomment-1164966523:458,Integrability,depend,dependency,458,"I'm surprised at the libxc problem, as that build number is at the top of the list here, https://anaconda.org/psi4/libxc/files, and you've got psi4 in the channels list. Perhaps you've got strict channel priority active? Psi4 _can't_ use the c-f libxc (another symbols issue) so it pins to the psi4 one. Perhaps `psi4::libxc` could get you a step deeper into the rabbit hole. :-). > Hopefully psi4 will hit conda forge soon. Agreed. There's some conflicting dependency issues to work out beforehand.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2621#issuecomment-1164966523
https://github.com/psi4/psi4/issues/2621#issuecomment-1164977280:185,Deployability,install,install,185,"> Perhaps you've got strict channel priority active?. I would suspect this is the case, if the channel order is changed to ; ```; channels:; - psi4; - conda-forge; ```; , I was able to install on linux and the tests were also passing.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2621#issuecomment-1164977280
https://github.com/psi4/psi4/issues/2621#issuecomment-1164977280:210,Testability,test,tests,210,"> Perhaps you've got strict channel priority active?. I would suspect this is the case, if the channel order is changed to ; ```; channels:; - psi4; - conda-forge; ```; , I was able to install on linux and the tests were also passing.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2621#issuecomment-1164977280
https://github.com/psi4/psi4/issues/2621#issuecomment-1165034257:293,Availability,mainten,maintenance,293,"> > Hopefully psi4 will hit conda forge soon; > ; > Agreed. There's some conflicting dependency issues to work out beforehand. More specifically, #2537 is the next step, AFAIK. We'd love to work on this, but a few other things (SCF cleanup and a new feature, double-checking ECPs, and overdue maintenance of `dfocc`) are higher priority for Lori and I.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2621#issuecomment-1165034257
https://github.com/psi4/psi4/issues/2621#issuecomment-1165034257:85,Integrability,depend,dependency,85,"> > Hopefully psi4 will hit conda forge soon; > ; > Agreed. There's some conflicting dependency issues to work out beforehand. More specifically, #2537 is the next step, AFAIK. We'd love to work on this, but a few other things (SCF cleanup and a new feature, double-checking ECPs, and overdue maintenance of `dfocc`) are higher priority for Lori and I.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2621#issuecomment-1165034257
https://github.com/psi4/psi4/issues/2621#issuecomment-1336507776:345,Performance,optimiz,optimization,345,"Yes, the move to c-f-based is still planned (indeed, one of our build machines just quit, so it has special urgency). #2791 was as far as I got this cycle. It was needed to use more c-f packages instead of psi-specialized ones, and because those are the most popular non-required deps. Are there particular packages you'd need besides required, optimization, and dispersion? Or is simply a c-f-based psi4 package that solves your primary goal?. Many of the deps are compiled or psi is using a slight fork or need windows work. do you have specialties? :-). Roughly, my plan is to start compiling psi4 locally with c-f conditions and the very basic deps and post them to a `psi4/label/cf` channel. Libint2 must still pull from psi4 channel for the forseeable future. Glad to talk strategy, esp. after 12 Dec.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2621#issuecomment-1336507776
https://github.com/psi4/psi4/issues/2621#issuecomment-1336507776:381,Usability,simpl,simply,381,"Yes, the move to c-f-based is still planned (indeed, one of our build machines just quit, so it has special urgency). #2791 was as far as I got this cycle. It was needed to use more c-f packages instead of psi-specialized ones, and because those are the most popular non-required deps. Are there particular packages you'd need besides required, optimization, and dispersion? Or is simply a c-f-based psi4 package that solves your primary goal?. Many of the deps are compiled or psi is using a slight fork or need windows work. do you have specialties? :-). Roughly, my plan is to start compiling psi4 locally with c-f conditions and the very basic deps and post them to a `psi4/label/cf` channel. Libint2 must still pull from psi4 channel for the forseeable future. Glad to talk strategy, esp. after 12 Dec.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2621#issuecomment-1336507776
https://github.com/psi4/psi4/issues/2621#issuecomment-1337307605:1318,Availability,avail,available,1318,"> Are there particular packages you'd need besides required, optimization, and dispersion?. No, so far, I am just exploring a few ideas/experiments (using qcengine mostly) and only require `psi4`. I can get `psi4` running, but integration with other internal packages is very challenging (if not impossible) without a binary-compatible c-f package. > Many of the deps are compiled or psi is using a slight fork or need windows work. do you have specialties? :-). I can only develop a package on my Linux machine. No problem to also build on the CI for osx/windows, but debugging is much harder on those platforms. I have experience building CMake based C/C++ packages on c-f (as long as it does not require diving too deep in the C/C++ code). > Roughly, my plan is to start compiling psi4 locally with c-f conditions and the very basic deps and post them to a psi4/label/cf channel. Libint2 must still pull from psi4 channel for the forseeable future. Glad to talk strategy, esp. after 12 Dec. Beside libint2, it looks like you are quite close here. I don't know if you are aware of it but you can easily run a c-f build (almost identical to the ones on the CI) using the `build_locally.py` script. See https://conda-forge.org/docs/maintainer/updating_pkgs.html#testing-changes-locally for the details. That script is available in the feedstock repo but also in the `staged-recipes` repo for package that does not yet exist.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2621#issuecomment-1337307605
https://github.com/psi4/psi4/issues/2621#issuecomment-1337307605:227,Deployability,integrat,integration,227,"> Are there particular packages you'd need besides required, optimization, and dispersion?. No, so far, I am just exploring a few ideas/experiments (using qcengine mostly) and only require `psi4`. I can get `psi4` running, but integration with other internal packages is very challenging (if not impossible) without a binary-compatible c-f package. > Many of the deps are compiled or psi is using a slight fork or need windows work. do you have specialties? :-). I can only develop a package on my Linux machine. No problem to also build on the CI for osx/windows, but debugging is much harder on those platforms. I have experience building CMake based C/C++ packages on c-f (as long as it does not require diving too deep in the C/C++ code). > Roughly, my plan is to start compiling psi4 locally with c-f conditions and the very basic deps and post them to a psi4/label/cf channel. Libint2 must still pull from psi4 channel for the forseeable future. Glad to talk strategy, esp. after 12 Dec. Beside libint2, it looks like you are quite close here. I don't know if you are aware of it but you can easily run a c-f build (almost identical to the ones on the CI) using the `build_locally.py` script. See https://conda-forge.org/docs/maintainer/updating_pkgs.html#testing-changes-locally for the details. That script is available in the feedstock repo but also in the `staged-recipes` repo for package that does not yet exist.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2621#issuecomment-1337307605
https://github.com/psi4/psi4/issues/2621#issuecomment-1337307605:227,Integrability,integrat,integration,227,"> Are there particular packages you'd need besides required, optimization, and dispersion?. No, so far, I am just exploring a few ideas/experiments (using qcengine mostly) and only require `psi4`. I can get `psi4` running, but integration with other internal packages is very challenging (if not impossible) without a binary-compatible c-f package. > Many of the deps are compiled or psi is using a slight fork or need windows work. do you have specialties? :-). I can only develop a package on my Linux machine. No problem to also build on the CI for osx/windows, but debugging is much harder on those platforms. I have experience building CMake based C/C++ packages on c-f (as long as it does not require diving too deep in the C/C++ code). > Roughly, my plan is to start compiling psi4 locally with c-f conditions and the very basic deps and post them to a psi4/label/cf channel. Libint2 must still pull from psi4 channel for the forseeable future. Glad to talk strategy, esp. after 12 Dec. Beside libint2, it looks like you are quite close here. I don't know if you are aware of it but you can easily run a c-f build (almost identical to the ones on the CI) using the `build_locally.py` script. See https://conda-forge.org/docs/maintainer/updating_pkgs.html#testing-changes-locally for the details. That script is available in the feedstock repo but also in the `staged-recipes` repo for package that does not yet exist.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2621#issuecomment-1337307605
https://github.com/psi4/psi4/issues/2621#issuecomment-1337307605:61,Performance,optimiz,optimization,61,"> Are there particular packages you'd need besides required, optimization, and dispersion?. No, so far, I am just exploring a few ideas/experiments (using qcengine mostly) and only require `psi4`. I can get `psi4` running, but integration with other internal packages is very challenging (if not impossible) without a binary-compatible c-f package. > Many of the deps are compiled or psi is using a slight fork or need windows work. do you have specialties? :-). I can only develop a package on my Linux machine. No problem to also build on the CI for osx/windows, but debugging is much harder on those platforms. I have experience building CMake based C/C++ packages on c-f (as long as it does not require diving too deep in the C/C++ code). > Roughly, my plan is to start compiling psi4 locally with c-f conditions and the very basic deps and post them to a psi4/label/cf channel. Libint2 must still pull from psi4 channel for the forseeable future. Glad to talk strategy, esp. after 12 Dec. Beside libint2, it looks like you are quite close here. I don't know if you are aware of it but you can easily run a c-f build (almost identical to the ones on the CI) using the `build_locally.py` script. See https://conda-forge.org/docs/maintainer/updating_pkgs.html#testing-changes-locally for the details. That script is available in the feedstock repo but also in the `staged-recipes` repo for package that does not yet exist.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2621#issuecomment-1337307605
https://github.com/psi4/psi4/issues/2621#issuecomment-1337307605:1262,Testability,test,testing-changes-locally,1262,"> Are there particular packages you'd need besides required, optimization, and dispersion?. No, so far, I am just exploring a few ideas/experiments (using qcengine mostly) and only require `psi4`. I can get `psi4` running, but integration with other internal packages is very challenging (if not impossible) without a binary-compatible c-f package. > Many of the deps are compiled or psi is using a slight fork or need windows work. do you have specialties? :-). I can only develop a package on my Linux machine. No problem to also build on the CI for osx/windows, but debugging is much harder on those platforms. I have experience building CMake based C/C++ packages on c-f (as long as it does not require diving too deep in the C/C++ code). > Roughly, my plan is to start compiling psi4 locally with c-f conditions and the very basic deps and post them to a psi4/label/cf channel. Libint2 must still pull from psi4 channel for the forseeable future. Glad to talk strategy, esp. after 12 Dec. Beside libint2, it looks like you are quite close here. I don't know if you are aware of it but you can easily run a c-f build (almost identical to the ones on the CI) using the `build_locally.py` script. See https://conda-forge.org/docs/maintainer/updating_pkgs.html#testing-changes-locally for the details. That script is available in the feedstock repo but also in the `staged-recipes` repo for package that does not yet exist.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2621#issuecomment-1337307605
https://github.com/psi4/psi4/issues/2627#issuecomment-1179213167:148,Availability,error,error,148,"Given the reporter, the geometry they input is probably garbage. While I agree attempts to optimize from this are in vain, there should be a proper error message instead of just crashing with an obscure C error code.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2627#issuecomment-1179213167
https://github.com/psi4/psi4/issues/2627#issuecomment-1179213167:205,Availability,error,error,205,"Given the reporter, the geometry they input is probably garbage. While I agree attempts to optimize from this are in vain, there should be a proper error message instead of just crashing with an obscure C error code.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2627#issuecomment-1179213167
https://github.com/psi4/psi4/issues/2627#issuecomment-1179213167:154,Integrability,message,message,154,"Given the reporter, the geometry they input is probably garbage. While I agree attempts to optimize from this are in vain, there should be a proper error message instead of just crashing with an obscure C error code.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2627#issuecomment-1179213167
https://github.com/psi4/psi4/issues/2627#issuecomment-1179213167:91,Performance,optimiz,optimize,91,"Given the reporter, the geometry they input is probably garbage. While I agree attempts to optimize from this are in vain, there should be a proper error message instead of just crashing with an obscure C error code.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2627#issuecomment-1179213167
https://github.com/psi4/psi4/issues/2627#issuecomment-1179416978:396,Availability,error,error,396,"I agree, but not going to debug this bizarre case in the C++ code. And if; you're going to catch the absurd geometry, then psi4 should never compute; the gradient. On Fri, Jul 8, 2022 at 12:24 PM Jonathon Misiewicz ***@***.***>; wrote:. > Given the reporter, the geometry they input is probably garbage.; >; > While I agree attempts to optimize from this are in vain, there should be; > a proper error message instead of just crashing with an obscure C error; > code.; >; > ; > Reply to this email directly, view it on GitHub; > <https://github.com/psi4/psi4/issues/2627#issuecomment-1179213167>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AA4C4TAGYFNA3TVUXXSR7DLVTBP4VANCNFSM53A6YHNQ>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2627#issuecomment-1179416978
https://github.com/psi4/psi4/issues/2627#issuecomment-1179416978:453,Availability,error,error,453,"I agree, but not going to debug this bizarre case in the C++ code. And if; you're going to catch the absurd geometry, then psi4 should never compute; the gradient. On Fri, Jul 8, 2022 at 12:24 PM Jonathon Misiewicz ***@***.***>; wrote:. > Given the reporter, the geometry they input is probably garbage.; >; > While I agree attempts to optimize from this are in vain, there should be; > a proper error message instead of just crashing with an obscure C error; > code.; >; > ; > Reply to this email directly, view it on GitHub; > <https://github.com/psi4/psi4/issues/2627#issuecomment-1179213167>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AA4C4TAGYFNA3TVUXXSR7DLVTBP4VANCNFSM53A6YHNQ>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2627#issuecomment-1179416978
https://github.com/psi4/psi4/issues/2627#issuecomment-1179416978:402,Integrability,message,message,402,"I agree, but not going to debug this bizarre case in the C++ code. And if; you're going to catch the absurd geometry, then psi4 should never compute; the gradient. On Fri, Jul 8, 2022 at 12:24 PM Jonathon Misiewicz ***@***.***>; wrote:. > Given the reporter, the geometry they input is probably garbage.; >; > While I agree attempts to optimize from this are in vain, there should be; > a proper error message instead of just crashing with an obscure C error; > code.; >; > ; > Reply to this email directly, view it on GitHub; > <https://github.com/psi4/psi4/issues/2627#issuecomment-1179213167>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AA4C4TAGYFNA3TVUXXSR7DLVTBP4VANCNFSM53A6YHNQ>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2627#issuecomment-1179416978
https://github.com/psi4/psi4/issues/2627#issuecomment-1179416978:774,Integrability,Message,Message,774,"I agree, but not going to debug this bizarre case in the C++ code. And if; you're going to catch the absurd geometry, then psi4 should never compute; the gradient. On Fri, Jul 8, 2022 at 12:24 PM Jonathon Misiewicz ***@***.***>; wrote:. > Given the reporter, the geometry they input is probably garbage.; >; > While I agree attempts to optimize from this are in vain, there should be; > a proper error message instead of just crashing with an obscure C error; > code.; >; > ; > Reply to this email directly, view it on GitHub; > <https://github.com/psi4/psi4/issues/2627#issuecomment-1179213167>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AA4C4TAGYFNA3TVUXXSR7DLVTBP4VANCNFSM53A6YHNQ>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2627#issuecomment-1179416978
https://github.com/psi4/psi4/issues/2627#issuecomment-1179416978:336,Performance,optimiz,optimize,336,"I agree, but not going to debug this bizarre case in the C++ code. And if; you're going to catch the absurd geometry, then psi4 should never compute; the gradient. On Fri, Jul 8, 2022 at 12:24 PM Jonathon Misiewicz ***@***.***>; wrote:. > Given the reporter, the geometry they input is probably garbage.; >; > While I agree attempts to optimize from this are in vain, there should be; > a proper error message instead of just crashing with an obscure C error; > code.; >; > ; > Reply to this email directly, view it on GitHub; > <https://github.com/psi4/psi4/issues/2627#issuecomment-1179213167>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AA4C4TAGYFNA3TVUXXSR7DLVTBP4VANCNFSM53A6YHNQ>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2627#issuecomment-1179416978
https://github.com/psi4/psi4/issues/2631#issuecomment-1182482578:443,Deployability,patch,patch,443,"Thanks for the detailed report. I can reproduce the segfault, though for the benefit of other developers, I'll point out that this can be reproduced with `scf` instead of `wb97m-d3bj`. Sophisticated DFT functionality is not the issue here. This looks like a missing option validation at runtime. I'll add that my advisor is _also_ unhappy with the way Psi4 assumes options for precisely situations like these, but I have a few other things to patch before I touch options passing.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1182482578
https://github.com/psi4/psi4/issues/2631#issuecomment-1182482578:273,Security,validat,validation,273,"Thanks for the detailed report. I can reproduce the segfault, though for the benefit of other developers, I'll point out that this can be reproduced with `scf` instead of `wb97m-d3bj`. Sophisticated DFT functionality is not the issue here. This looks like a missing option validation at runtime. I'll add that my advisor is _also_ unhappy with the way Psi4 assumes options for precisely situations like these, but I have a few other things to patch before I touch options passing.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1182482578
https://github.com/psi4/psi4/issues/2631#issuecomment-1182560668:206,Testability,test,tests,206,"would a `psi4.core.clean_options()` between the two work sessions be helpful in the meantime?. a more targeted but confusing way would be with the ""revoke"" commands https://github.com/psi4/psi4/blob/master/tests/pywrap-checkrun-convcrit/input.dat#L53-L55 but not recommended.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1182560668
https://github.com/psi4/psi4/issues/2631#issuecomment-1193156348:175,Availability,error,error,175,"Independent of the options issues -- should something be patched/changed such that if the user/a program/etc passes a nonsense `num_frozen_docc`, the program gives a sensible error rather than segfaulting?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1193156348
https://github.com/psi4/psi4/issues/2631#issuecomment-1193156348:57,Deployability,patch,patched,57,"Independent of the options issues -- should something be patched/changed such that if the user/a program/etc passes a nonsense `num_frozen_docc`, the program gives a sensible error rather than segfaulting?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1193156348
https://github.com/psi4/psi4/issues/2631#issuecomment-1193180818:177,Availability,error,error,177,"> Independent of the options issues -- should something be patched/changed such that if the user/a program/etc passes a nonsense `num_frozen_docc`, the program gives a sensible error rather than segfaulting?. Yes. Lori's comment was ""trick you can use to prevent accidentally stumbling into this again,"" not a fix. `scf::HF::compute_fcpi` probably needs a validation check...",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1193180818
https://github.com/psi4/psi4/issues/2631#issuecomment-1193180818:59,Deployability,patch,patched,59,"> Independent of the options issues -- should something be patched/changed such that if the user/a program/etc passes a nonsense `num_frozen_docc`, the program gives a sensible error rather than segfaulting?. Yes. Lori's comment was ""trick you can use to prevent accidentally stumbling into this again,"" not a fix. `scf::HF::compute_fcpi` probably needs a validation check...",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1193180818
https://github.com/psi4/psi4/issues/2631#issuecomment-1193180818:356,Security,validat,validation,356,"> Independent of the options issues -- should something be patched/changed such that if the user/a program/etc passes a nonsense `num_frozen_docc`, the program gives a sensible error rather than segfaulting?. Yes. Lori's comment was ""trick you can use to prevent accidentally stumbling into this again,"" not a fix. `scf::HF::compute_fcpi` probably needs a validation check...",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1193180818
https://github.com/psi4/psi4/issues/2631#issuecomment-1207127647:828,Energy Efficiency,Energy,Energy,828,"I've turned up some much nastier behavior then a segfault -- incorrect QM... Take the attached input file [run.txt](https://github.com/psi4/psi4/files/9274229/run.txt) and note that `set num_frozen_docc 6` at the top there should potentially cause issues for the water molecule in the dimer. The alkane is perfectly OK with this, however, but should num_frozen_docc even be coming into play in a HF-level calc? I thought not, isn't it just for correlated calculations? . Anyway, in the run, the first SAPT0 step runs just fine -- really, the HF Is what we're looking at, and we get sensible numbers for the interaction:; ```; Total HF -0.10898644 [mEh] -0.06839003 [kcal/mol] -0.28614386 [kJ/mol]; Total SAPT0 -0.27387960 [mEh] -0.17186205 [kcal/mol] -0.71907080 [kJ/mol]; ```; ; And the underlying HF energies are:; ```; Total Energy = -272.3598217308123139; Total Energy = -196.3248586337326458; Total Energy = -76.0348541106373688; ```. But something goes Very Wrong in the second calculation. The water has _moved_, sure, but it's not done anything dramatic, really. It's still a water. The alkane hasn't moved at all. And yet... ```; Total HF -510.71908624 [mEh] -320.48106505 [kcal/mol] -1340.89277619 [kJ/mol]; Total SAPT0 -512.45472131 [mEh] -321.57019251 [kcal/mol] -1345.44968545 [kJ/mol]; ```. That's no good. Where did we go wrong?. In the water monomer energy, in fact:; ```; Total Energy = -272.3599706292600899; Total Energy = -196.3248586336976587; Total Energy = -75.5243929093220743; ```. Note that the water there seems to be 1 _hartree_ too ""unstable"". . If we instead take the second geometry and run it stand-alone, _with the incorrect num_frozen_docc_, we get a perfectly cromulent result:. ```; Total HF -0.25751717 [mEh] -0.16159446 [kcal/mol] -0.67611123 [kJ/mol]; Total SAPT0 -0.62788646 [mEh] -0.39400470 [kcal/mol] -1.64851567 [kJ/mol]; ```. So something strange is going on here -- I'd expect either the incorrect num_frozen_docc to break everything, or to break nothing ",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1207127647
https://github.com/psi4/psi4/issues/2631#issuecomment-1207127647:866,Energy Efficiency,Energy,Energy,866,"I've turned up some much nastier behavior then a segfault -- incorrect QM... Take the attached input file [run.txt](https://github.com/psi4/psi4/files/9274229/run.txt) and note that `set num_frozen_docc 6` at the top there should potentially cause issues for the water molecule in the dimer. The alkane is perfectly OK with this, however, but should num_frozen_docc even be coming into play in a HF-level calc? I thought not, isn't it just for correlated calculations? . Anyway, in the run, the first SAPT0 step runs just fine -- really, the HF Is what we're looking at, and we get sensible numbers for the interaction:; ```; Total HF -0.10898644 [mEh] -0.06839003 [kcal/mol] -0.28614386 [kJ/mol]; Total SAPT0 -0.27387960 [mEh] -0.17186205 [kcal/mol] -0.71907080 [kJ/mol]; ```; ; And the underlying HF energies are:; ```; Total Energy = -272.3598217308123139; Total Energy = -196.3248586337326458; Total Energy = -76.0348541106373688; ```. But something goes Very Wrong in the second calculation. The water has _moved_, sure, but it's not done anything dramatic, really. It's still a water. The alkane hasn't moved at all. And yet... ```; Total HF -510.71908624 [mEh] -320.48106505 [kcal/mol] -1340.89277619 [kJ/mol]; Total SAPT0 -512.45472131 [mEh] -321.57019251 [kcal/mol] -1345.44968545 [kJ/mol]; ```. That's no good. Where did we go wrong?. In the water monomer energy, in fact:; ```; Total Energy = -272.3599706292600899; Total Energy = -196.3248586336976587; Total Energy = -75.5243929093220743; ```. Note that the water there seems to be 1 _hartree_ too ""unstable"". . If we instead take the second geometry and run it stand-alone, _with the incorrect num_frozen_docc_, we get a perfectly cromulent result:. ```; Total HF -0.25751717 [mEh] -0.16159446 [kcal/mol] -0.67611123 [kJ/mol]; Total SAPT0 -0.62788646 [mEh] -0.39400470 [kcal/mol] -1.64851567 [kJ/mol]; ```. So something strange is going on here -- I'd expect either the incorrect num_frozen_docc to break everything, or to break nothing ",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1207127647
https://github.com/psi4/psi4/issues/2631#issuecomment-1207127647:904,Energy Efficiency,Energy,Energy,904,"I've turned up some much nastier behavior then a segfault -- incorrect QM... Take the attached input file [run.txt](https://github.com/psi4/psi4/files/9274229/run.txt) and note that `set num_frozen_docc 6` at the top there should potentially cause issues for the water molecule in the dimer. The alkane is perfectly OK with this, however, but should num_frozen_docc even be coming into play in a HF-level calc? I thought not, isn't it just for correlated calculations? . Anyway, in the run, the first SAPT0 step runs just fine -- really, the HF Is what we're looking at, and we get sensible numbers for the interaction:; ```; Total HF -0.10898644 [mEh] -0.06839003 [kcal/mol] -0.28614386 [kJ/mol]; Total SAPT0 -0.27387960 [mEh] -0.17186205 [kcal/mol] -0.71907080 [kJ/mol]; ```; ; And the underlying HF energies are:; ```; Total Energy = -272.3598217308123139; Total Energy = -196.3248586337326458; Total Energy = -76.0348541106373688; ```. But something goes Very Wrong in the second calculation. The water has _moved_, sure, but it's not done anything dramatic, really. It's still a water. The alkane hasn't moved at all. And yet... ```; Total HF -510.71908624 [mEh] -320.48106505 [kcal/mol] -1340.89277619 [kJ/mol]; Total SAPT0 -512.45472131 [mEh] -321.57019251 [kcal/mol] -1345.44968545 [kJ/mol]; ```. That's no good. Where did we go wrong?. In the water monomer energy, in fact:; ```; Total Energy = -272.3599706292600899; Total Energy = -196.3248586336976587; Total Energy = -75.5243929093220743; ```. Note that the water there seems to be 1 _hartree_ too ""unstable"". . If we instead take the second geometry and run it stand-alone, _with the incorrect num_frozen_docc_, we get a perfectly cromulent result:. ```; Total HF -0.25751717 [mEh] -0.16159446 [kcal/mol] -0.67611123 [kJ/mol]; Total SAPT0 -0.62788646 [mEh] -0.39400470 [kcal/mol] -1.64851567 [kJ/mol]; ```. So something strange is going on here -- I'd expect either the incorrect num_frozen_docc to break everything, or to break nothing ",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1207127647
https://github.com/psi4/psi4/issues/2631#issuecomment-1207127647:1366,Energy Efficiency,energy,energy,1366," `set num_frozen_docc 6` at the top there should potentially cause issues for the water molecule in the dimer. The alkane is perfectly OK with this, however, but should num_frozen_docc even be coming into play in a HF-level calc? I thought not, isn't it just for correlated calculations? . Anyway, in the run, the first SAPT0 step runs just fine -- really, the HF Is what we're looking at, and we get sensible numbers for the interaction:; ```; Total HF -0.10898644 [mEh] -0.06839003 [kcal/mol] -0.28614386 [kJ/mol]; Total SAPT0 -0.27387960 [mEh] -0.17186205 [kcal/mol] -0.71907080 [kJ/mol]; ```; ; And the underlying HF energies are:; ```; Total Energy = -272.3598217308123139; Total Energy = -196.3248586337326458; Total Energy = -76.0348541106373688; ```. But something goes Very Wrong in the second calculation. The water has _moved_, sure, but it's not done anything dramatic, really. It's still a water. The alkane hasn't moved at all. And yet... ```; Total HF -510.71908624 [mEh] -320.48106505 [kcal/mol] -1340.89277619 [kJ/mol]; Total SAPT0 -512.45472131 [mEh] -321.57019251 [kcal/mol] -1345.44968545 [kJ/mol]; ```. That's no good. Where did we go wrong?. In the water monomer energy, in fact:; ```; Total Energy = -272.3599706292600899; Total Energy = -196.3248586336976587; Total Energy = -75.5243929093220743; ```. Note that the water there seems to be 1 _hartree_ too ""unstable"". . If we instead take the second geometry and run it stand-alone, _with the incorrect num_frozen_docc_, we get a perfectly cromulent result:. ```; Total HF -0.25751717 [mEh] -0.16159446 [kcal/mol] -0.67611123 [kJ/mol]; Total SAPT0 -0.62788646 [mEh] -0.39400470 [kcal/mol] -1.64851567 [kJ/mol]; ```. So something strange is going on here -- I'd expect either the incorrect num_frozen_docc to break everything, or to break nothing (or to break SAPT0 only, but not the HF calc, at least!). Given the segfault at sufficiently bad num_frozen_docc, and the out-of-bounds array reach, I'm guessing memory corruption?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1207127647
https://github.com/psi4/psi4/issues/2631#issuecomment-1207127647:1395,Energy Efficiency,Energy,Energy,1395," `set num_frozen_docc 6` at the top there should potentially cause issues for the water molecule in the dimer. The alkane is perfectly OK with this, however, but should num_frozen_docc even be coming into play in a HF-level calc? I thought not, isn't it just for correlated calculations? . Anyway, in the run, the first SAPT0 step runs just fine -- really, the HF Is what we're looking at, and we get sensible numbers for the interaction:; ```; Total HF -0.10898644 [mEh] -0.06839003 [kcal/mol] -0.28614386 [kJ/mol]; Total SAPT0 -0.27387960 [mEh] -0.17186205 [kcal/mol] -0.71907080 [kJ/mol]; ```; ; And the underlying HF energies are:; ```; Total Energy = -272.3598217308123139; Total Energy = -196.3248586337326458; Total Energy = -76.0348541106373688; ```. But something goes Very Wrong in the second calculation. The water has _moved_, sure, but it's not done anything dramatic, really. It's still a water. The alkane hasn't moved at all. And yet... ```; Total HF -510.71908624 [mEh] -320.48106505 [kcal/mol] -1340.89277619 [kJ/mol]; Total SAPT0 -512.45472131 [mEh] -321.57019251 [kcal/mol] -1345.44968545 [kJ/mol]; ```. That's no good. Where did we go wrong?. In the water monomer energy, in fact:; ```; Total Energy = -272.3599706292600899; Total Energy = -196.3248586336976587; Total Energy = -75.5243929093220743; ```. Note that the water there seems to be 1 _hartree_ too ""unstable"". . If we instead take the second geometry and run it stand-alone, _with the incorrect num_frozen_docc_, we get a perfectly cromulent result:. ```; Total HF -0.25751717 [mEh] -0.16159446 [kcal/mol] -0.67611123 [kJ/mol]; Total SAPT0 -0.62788646 [mEh] -0.39400470 [kcal/mol] -1.64851567 [kJ/mol]; ```. So something strange is going on here -- I'd expect either the incorrect num_frozen_docc to break everything, or to break nothing (or to break SAPT0 only, but not the HF calc, at least!). Given the segfault at sufficiently bad num_frozen_docc, and the out-of-bounds array reach, I'm guessing memory corruption?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1207127647
https://github.com/psi4/psi4/issues/2631#issuecomment-1207127647:1433,Energy Efficiency,Energy,Energy,1433," `set num_frozen_docc 6` at the top there should potentially cause issues for the water molecule in the dimer. The alkane is perfectly OK with this, however, but should num_frozen_docc even be coming into play in a HF-level calc? I thought not, isn't it just for correlated calculations? . Anyway, in the run, the first SAPT0 step runs just fine -- really, the HF Is what we're looking at, and we get sensible numbers for the interaction:; ```; Total HF -0.10898644 [mEh] -0.06839003 [kcal/mol] -0.28614386 [kJ/mol]; Total SAPT0 -0.27387960 [mEh] -0.17186205 [kcal/mol] -0.71907080 [kJ/mol]; ```; ; And the underlying HF energies are:; ```; Total Energy = -272.3598217308123139; Total Energy = -196.3248586337326458; Total Energy = -76.0348541106373688; ```. But something goes Very Wrong in the second calculation. The water has _moved_, sure, but it's not done anything dramatic, really. It's still a water. The alkane hasn't moved at all. And yet... ```; Total HF -510.71908624 [mEh] -320.48106505 [kcal/mol] -1340.89277619 [kJ/mol]; Total SAPT0 -512.45472131 [mEh] -321.57019251 [kcal/mol] -1345.44968545 [kJ/mol]; ```. That's no good. Where did we go wrong?. In the water monomer energy, in fact:; ```; Total Energy = -272.3599706292600899; Total Energy = -196.3248586336976587; Total Energy = -75.5243929093220743; ```. Note that the water there seems to be 1 _hartree_ too ""unstable"". . If we instead take the second geometry and run it stand-alone, _with the incorrect num_frozen_docc_, we get a perfectly cromulent result:. ```; Total HF -0.25751717 [mEh] -0.16159446 [kcal/mol] -0.67611123 [kJ/mol]; Total SAPT0 -0.62788646 [mEh] -0.39400470 [kcal/mol] -1.64851567 [kJ/mol]; ```. So something strange is going on here -- I'd expect either the incorrect num_frozen_docc to break everything, or to break nothing (or to break SAPT0 only, but not the HF calc, at least!). Given the segfault at sufficiently bad num_frozen_docc, and the out-of-bounds array reach, I'm guessing memory corruption?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1207127647
https://github.com/psi4/psi4/issues/2631#issuecomment-1207127647:1471,Energy Efficiency,Energy,Energy,1471," `set num_frozen_docc 6` at the top there should potentially cause issues for the water molecule in the dimer. The alkane is perfectly OK with this, however, but should num_frozen_docc even be coming into play in a HF-level calc? I thought not, isn't it just for correlated calculations? . Anyway, in the run, the first SAPT0 step runs just fine -- really, the HF Is what we're looking at, and we get sensible numbers for the interaction:; ```; Total HF -0.10898644 [mEh] -0.06839003 [kcal/mol] -0.28614386 [kJ/mol]; Total SAPT0 -0.27387960 [mEh] -0.17186205 [kcal/mol] -0.71907080 [kJ/mol]; ```; ; And the underlying HF energies are:; ```; Total Energy = -272.3598217308123139; Total Energy = -196.3248586337326458; Total Energy = -76.0348541106373688; ```. But something goes Very Wrong in the second calculation. The water has _moved_, sure, but it's not done anything dramatic, really. It's still a water. The alkane hasn't moved at all. And yet... ```; Total HF -510.71908624 [mEh] -320.48106505 [kcal/mol] -1340.89277619 [kJ/mol]; Total SAPT0 -512.45472131 [mEh] -321.57019251 [kcal/mol] -1345.44968545 [kJ/mol]; ```. That's no good. Where did we go wrong?. In the water monomer energy, in fact:; ```; Total Energy = -272.3599706292600899; Total Energy = -196.3248586336976587; Total Energy = -75.5243929093220743; ```. Note that the water there seems to be 1 _hartree_ too ""unstable"". . If we instead take the second geometry and run it stand-alone, _with the incorrect num_frozen_docc_, we get a perfectly cromulent result:. ```; Total HF -0.25751717 [mEh] -0.16159446 [kcal/mol] -0.67611123 [kJ/mol]; Total SAPT0 -0.62788646 [mEh] -0.39400470 [kcal/mol] -1.64851567 [kJ/mol]; ```. So something strange is going on here -- I'd expect either the incorrect num_frozen_docc to break everything, or to break nothing (or to break SAPT0 only, but not the HF calc, at least!). Given the segfault at sufficiently bad num_frozen_docc, and the out-of-bounds array reach, I'm guessing memory corruption?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1207127647
https://github.com/psi4/psi4/issues/2631#issuecomment-1207141235:471,Energy Efficiency,Energy,Energy,471,"I see your results, too. What's the overall intent of the `num_frozen_docc` here? Are you wanting plain frozen core or is this preparation for something more complex? Note that we did address frozen core in sapt fairly recently, https://github.com/psi4/psi4/pull/2271, and that solution in itself is making use of `num_frozen_docc`. When I switch your first line to `set freeze_core true`, water is reasonable again. ```; > grep -e ""Final E"" lizsapt2.out ; @DF-RHF Final Energy: -272.35982173084625; @DF-RHF Final Energy: -196.32485863378869; @DF-RHF Final Energy: -76.03485411063548; @DF-RHF Final Energy: -272.35997062909757; @DF-RHF Final Energy: -196.32485863377360; @DF-RHF Final Energy: -76.03485447822362; ```. In SAPT, frozen-core will influence a delta-MP2 correction (irrelevant here) and possibly (I'm not sure if there are conditions) dispersion https://github.com/psi4/psi4/blob/master/tests/sapt10/input.dat#L59-L63 since those are mp2-like terms. You're right that HF energies themselves should be indifferent. Without experimenting much, I venture that the presence of the sapt fc correction and all the wfn passing w/i sapt is causing the bad QC. Possibly `num_frozen_docc` should be disabled for SAPT, if newly fixed `freeze_core=True` works for you. Or else `num_frozen_docc` needs a separate fix.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1207141235
https://github.com/psi4/psi4/issues/2631#issuecomment-1207141235:514,Energy Efficiency,Energy,Energy,514,"I see your results, too. What's the overall intent of the `num_frozen_docc` here? Are you wanting plain frozen core or is this preparation for something more complex? Note that we did address frozen core in sapt fairly recently, https://github.com/psi4/psi4/pull/2271, and that solution in itself is making use of `num_frozen_docc`. When I switch your first line to `set freeze_core true`, water is reasonable again. ```; > grep -e ""Final E"" lizsapt2.out ; @DF-RHF Final Energy: -272.35982173084625; @DF-RHF Final Energy: -196.32485863378869; @DF-RHF Final Energy: -76.03485411063548; @DF-RHF Final Energy: -272.35997062909757; @DF-RHF Final Energy: -196.32485863377360; @DF-RHF Final Energy: -76.03485447822362; ```. In SAPT, frozen-core will influence a delta-MP2 correction (irrelevant here) and possibly (I'm not sure if there are conditions) dispersion https://github.com/psi4/psi4/blob/master/tests/sapt10/input.dat#L59-L63 since those are mp2-like terms. You're right that HF energies themselves should be indifferent. Without experimenting much, I venture that the presence of the sapt fc correction and all the wfn passing w/i sapt is causing the bad QC. Possibly `num_frozen_docc` should be disabled for SAPT, if newly fixed `freeze_core=True` works for you. Or else `num_frozen_docc` needs a separate fix.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1207141235
https://github.com/psi4/psi4/issues/2631#issuecomment-1207141235:557,Energy Efficiency,Energy,Energy,557,"I see your results, too. What's the overall intent of the `num_frozen_docc` here? Are you wanting plain frozen core or is this preparation for something more complex? Note that we did address frozen core in sapt fairly recently, https://github.com/psi4/psi4/pull/2271, and that solution in itself is making use of `num_frozen_docc`. When I switch your first line to `set freeze_core true`, water is reasonable again. ```; > grep -e ""Final E"" lizsapt2.out ; @DF-RHF Final Energy: -272.35982173084625; @DF-RHF Final Energy: -196.32485863378869; @DF-RHF Final Energy: -76.03485411063548; @DF-RHF Final Energy: -272.35997062909757; @DF-RHF Final Energy: -196.32485863377360; @DF-RHF Final Energy: -76.03485447822362; ```. In SAPT, frozen-core will influence a delta-MP2 correction (irrelevant here) and possibly (I'm not sure if there are conditions) dispersion https://github.com/psi4/psi4/blob/master/tests/sapt10/input.dat#L59-L63 since those are mp2-like terms. You're right that HF energies themselves should be indifferent. Without experimenting much, I venture that the presence of the sapt fc correction and all the wfn passing w/i sapt is causing the bad QC. Possibly `num_frozen_docc` should be disabled for SAPT, if newly fixed `freeze_core=True` works for you. Or else `num_frozen_docc` needs a separate fix.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1207141235
https://github.com/psi4/psi4/issues/2631#issuecomment-1207141235:599,Energy Efficiency,Energy,Energy,599,"I see your results, too. What's the overall intent of the `num_frozen_docc` here? Are you wanting plain frozen core or is this preparation for something more complex? Note that we did address frozen core in sapt fairly recently, https://github.com/psi4/psi4/pull/2271, and that solution in itself is making use of `num_frozen_docc`. When I switch your first line to `set freeze_core true`, water is reasonable again. ```; > grep -e ""Final E"" lizsapt2.out ; @DF-RHF Final Energy: -272.35982173084625; @DF-RHF Final Energy: -196.32485863378869; @DF-RHF Final Energy: -76.03485411063548; @DF-RHF Final Energy: -272.35997062909757; @DF-RHF Final Energy: -196.32485863377360; @DF-RHF Final Energy: -76.03485447822362; ```. In SAPT, frozen-core will influence a delta-MP2 correction (irrelevant here) and possibly (I'm not sure if there are conditions) dispersion https://github.com/psi4/psi4/blob/master/tests/sapt10/input.dat#L59-L63 since those are mp2-like terms. You're right that HF energies themselves should be indifferent. Without experimenting much, I venture that the presence of the sapt fc correction and all the wfn passing w/i sapt is causing the bad QC. Possibly `num_frozen_docc` should be disabled for SAPT, if newly fixed `freeze_core=True` works for you. Or else `num_frozen_docc` needs a separate fix.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1207141235
https://github.com/psi4/psi4/issues/2631#issuecomment-1207141235:642,Energy Efficiency,Energy,Energy,642,"I see your results, too. What's the overall intent of the `num_frozen_docc` here? Are you wanting plain frozen core or is this preparation for something more complex? Note that we did address frozen core in sapt fairly recently, https://github.com/psi4/psi4/pull/2271, and that solution in itself is making use of `num_frozen_docc`. When I switch your first line to `set freeze_core true`, water is reasonable again. ```; > grep -e ""Final E"" lizsapt2.out ; @DF-RHF Final Energy: -272.35982173084625; @DF-RHF Final Energy: -196.32485863378869; @DF-RHF Final Energy: -76.03485411063548; @DF-RHF Final Energy: -272.35997062909757; @DF-RHF Final Energy: -196.32485863377360; @DF-RHF Final Energy: -76.03485447822362; ```. In SAPT, frozen-core will influence a delta-MP2 correction (irrelevant here) and possibly (I'm not sure if there are conditions) dispersion https://github.com/psi4/psi4/blob/master/tests/sapt10/input.dat#L59-L63 since those are mp2-like terms. You're right that HF energies themselves should be indifferent. Without experimenting much, I venture that the presence of the sapt fc correction and all the wfn passing w/i sapt is causing the bad QC. Possibly `num_frozen_docc` should be disabled for SAPT, if newly fixed `freeze_core=True` works for you. Or else `num_frozen_docc` needs a separate fix.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1207141235
https://github.com/psi4/psi4/issues/2631#issuecomment-1207141235:685,Energy Efficiency,Energy,Energy,685,"I see your results, too. What's the overall intent of the `num_frozen_docc` here? Are you wanting plain frozen core or is this preparation for something more complex? Note that we did address frozen core in sapt fairly recently, https://github.com/psi4/psi4/pull/2271, and that solution in itself is making use of `num_frozen_docc`. When I switch your first line to `set freeze_core true`, water is reasonable again. ```; > grep -e ""Final E"" lizsapt2.out ; @DF-RHF Final Energy: -272.35982173084625; @DF-RHF Final Energy: -196.32485863378869; @DF-RHF Final Energy: -76.03485411063548; @DF-RHF Final Energy: -272.35997062909757; @DF-RHF Final Energy: -196.32485863377360; @DF-RHF Final Energy: -76.03485447822362; ```. In SAPT, frozen-core will influence a delta-MP2 correction (irrelevant here) and possibly (I'm not sure if there are conditions) dispersion https://github.com/psi4/psi4/blob/master/tests/sapt10/input.dat#L59-L63 since those are mp2-like terms. You're right that HF energies themselves should be indifferent. Without experimenting much, I venture that the presence of the sapt fc correction and all the wfn passing w/i sapt is causing the bad QC. Possibly `num_frozen_docc` should be disabled for SAPT, if newly fixed `freeze_core=True` works for you. Or else `num_frozen_docc` needs a separate fix.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1207141235
https://github.com/psi4/psi4/issues/2631#issuecomment-1207141235:899,Testability,test,tests,899,"I see your results, too. What's the overall intent of the `num_frozen_docc` here? Are you wanting plain frozen core or is this preparation for something more complex? Note that we did address frozen core in sapt fairly recently, https://github.com/psi4/psi4/pull/2271, and that solution in itself is making use of `num_frozen_docc`. When I switch your first line to `set freeze_core true`, water is reasonable again. ```; > grep -e ""Final E"" lizsapt2.out ; @DF-RHF Final Energy: -272.35982173084625; @DF-RHF Final Energy: -196.32485863378869; @DF-RHF Final Energy: -76.03485411063548; @DF-RHF Final Energy: -272.35997062909757; @DF-RHF Final Energy: -196.32485863377360; @DF-RHF Final Energy: -76.03485447822362; ```. In SAPT, frozen-core will influence a delta-MP2 correction (irrelevant here) and possibly (I'm not sure if there are conditions) dispersion https://github.com/psi4/psi4/blob/master/tests/sapt10/input.dat#L59-L63 since those are mp2-like terms. You're right that HF energies themselves should be indifferent. Without experimenting much, I venture that the presence of the sapt fc correction and all the wfn passing w/i sapt is causing the bad QC. Possibly `num_frozen_docc` should be disabled for SAPT, if newly fixed `freeze_core=True` works for you. Or else `num_frozen_docc` needs a separate fix.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1207141235
https://github.com/psi4/psi4/issues/2631#issuecomment-1207254380:3185,Deployability,patch,patch,3185,"ements (transition metals), so for now my solution is to just use `freeze_core true` for all SAPT0 calcs and go about my life. And when I thought the bad setting _just_ caused segfaults, I was fine to assume that all calculations that ran to completion were obviously OK. Now seeing that there's some shade of undefined behavior leading to memory corruption possibly going on, I'd like to understand what is going wrong so I can figure out what's likely impacted... cases where the energy is obviously and egregiously wrong (like above) are easy, but I'm worried more about subtle incorrectness. As for the general fix -- if `num_frozen_docc` is disabled for SAPT0, then it becomes impossible for a user to impose their own beliefs about frozen orbitals in tricky cases like transition metals, which seems... bad. Since it does impact the dispersion portion of the calc, it needs to be user-mutable. This setting *shouldn't* be actually impacting the HF energies, and fixing that strange interaction seems like most of the battle. I'm less sure of what to do in the MP2 case, since it does seem relevant that the user should be able to specify their own core policy as required... At the risk of further complication, would it make sense to implement either:; 1. The ability for `num_frozen_docc` to take in a tuple the same length of the number of fragments in the active `Molecule` (such that correct behavior can be inferred in cases like SAPT where both monomer and dimer calcs are run in a global context); 2. The ability to define, via a list(?), a custom policy on a per-element basis that can be fed to `freeze_core`? . Both of these would allow both for the user to handle cases like custom frozen thresholds in multi-calc situations and keep things consistent. At the same time, these are... possibly a lot of work. I'm prototyping a solution of type (2) but I'm not sure if it'll be too clunky for others to use -- assuming I haven't messed up horribly, I'll propose the patch later today.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1207254380
https://github.com/psi4/psi4/issues/2631#issuecomment-1207254380:109,Energy Efficiency,energy,energy,109,"The overall intent is that we usually run psi4 from an outside workflow that runs exactly _one_ single-point energy per infile (or a scan of geometrically-related single point energies, e.g., a dimer being pulled apart). Usually, each of these calculations represents ONLY a monomer, or the dimer. We have a lookup table of how many orbitals we want to freeze in post-HF calculations, and the most visible way to apply that setting was to just set `num_frozen_docc`. For example, if we wanted to calculate the interaction energy of a water-alkane dimer at the MP2 level, we'd have three calculations:; - A in the AB basis with `num_frozen_docc` set accordingly for A; - B in the AB basis with `num_frozen_docc` set accordingly for B; - AB in the AB basis with `num_frozen_docc` set accordingly for AB. This scheme worked very well, until it came time to run SAPT0 calcs. As I admittedly hadn't thought through the effect of an incorrect `n_frozen_docc` on the monomer calcs done within the SAPT0 dimer calc (and presumed them to be at the HF level anyway), I didn't think to check for correct behavior. . The only place where our frozen-core lookup table disagrees with psi4's is for some more exotic elements (transition metals), so for now my solution is to just use `freeze_core true` for all SAPT0 calcs and go about my life. And when I thought the bad setting _just_ caused segfaults, I was fine to assume that all calculations that ran to completion were obviously OK. Now seeing that there's some shade of undefined behavior leading to memory corruption possibly going on, I'd like to understand what is going wrong so I can figure out what's likely impacted... cases where the energy is obviously and egregiously wrong (like above) are easy, but I'm worried more about subtle incorrectness. As for the general fix -- if `num_frozen_docc` is disabled for SAPT0, then it becomes impossible for a user to impose their own beliefs about frozen orbitals in tricky cases like transition metals, whic",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1207254380
https://github.com/psi4/psi4/issues/2631#issuecomment-1207254380:522,Energy Efficiency,energy,energy,522,"The overall intent is that we usually run psi4 from an outside workflow that runs exactly _one_ single-point energy per infile (or a scan of geometrically-related single point energies, e.g., a dimer being pulled apart). Usually, each of these calculations represents ONLY a monomer, or the dimer. We have a lookup table of how many orbitals we want to freeze in post-HF calculations, and the most visible way to apply that setting was to just set `num_frozen_docc`. For example, if we wanted to calculate the interaction energy of a water-alkane dimer at the MP2 level, we'd have three calculations:; - A in the AB basis with `num_frozen_docc` set accordingly for A; - B in the AB basis with `num_frozen_docc` set accordingly for B; - AB in the AB basis with `num_frozen_docc` set accordingly for AB. This scheme worked very well, until it came time to run SAPT0 calcs. As I admittedly hadn't thought through the effect of an incorrect `n_frozen_docc` on the monomer calcs done within the SAPT0 dimer calc (and presumed them to be at the HF level anyway), I didn't think to check for correct behavior. . The only place where our frozen-core lookup table disagrees with psi4's is for some more exotic elements (transition metals), so for now my solution is to just use `freeze_core true` for all SAPT0 calcs and go about my life. And when I thought the bad setting _just_ caused segfaults, I was fine to assume that all calculations that ran to completion were obviously OK. Now seeing that there's some shade of undefined behavior leading to memory corruption possibly going on, I'd like to understand what is going wrong so I can figure out what's likely impacted... cases where the energy is obviously and egregiously wrong (like above) are easy, but I'm worried more about subtle incorrectness. As for the general fix -- if `num_frozen_docc` is disabled for SAPT0, then it becomes impossible for a user to impose their own beliefs about frozen orbitals in tricky cases like transition metals, whic",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1207254380
https://github.com/psi4/psi4/issues/2631#issuecomment-1207254380:1685,Energy Efficiency,energy,energy,1685," - AB in the AB basis with `num_frozen_docc` set accordingly for AB. This scheme worked very well, until it came time to run SAPT0 calcs. As I admittedly hadn't thought through the effect of an incorrect `n_frozen_docc` on the monomer calcs done within the SAPT0 dimer calc (and presumed them to be at the HF level anyway), I didn't think to check for correct behavior. . The only place where our frozen-core lookup table disagrees with psi4's is for some more exotic elements (transition metals), so for now my solution is to just use `freeze_core true` for all SAPT0 calcs and go about my life. And when I thought the bad setting _just_ caused segfaults, I was fine to assume that all calculations that ran to completion were obviously OK. Now seeing that there's some shade of undefined behavior leading to memory corruption possibly going on, I'd like to understand what is going wrong so I can figure out what's likely impacted... cases where the energy is obviously and egregiously wrong (like above) are easy, but I'm worried more about subtle incorrectness. As for the general fix -- if `num_frozen_docc` is disabled for SAPT0, then it becomes impossible for a user to impose their own beliefs about frozen orbitals in tricky cases like transition metals, which seems... bad. Since it does impact the dispersion portion of the calc, it needs to be user-mutable. This setting *shouldn't* be actually impacting the HF energies, and fixing that strange interaction seems like most of the battle. I'm less sure of what to do in the MP2 case, since it does seem relevant that the user should be able to specify their own core policy as required... At the risk of further complication, would it make sense to implement either:; 1. The ability for `num_frozen_docc` to take in a tuple the same length of the number of fragments in the active `Molecule` (such that correct behavior can be inferred in cases like SAPT where both monomer and dimer calcs are run in a global context); 2. The ability to ",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1207254380
https://github.com/psi4/psi4/issues/2631#issuecomment-1207254380:2391,Safety,risk,risk,2391,"ements (transition metals), so for now my solution is to just use `freeze_core true` for all SAPT0 calcs and go about my life. And when I thought the bad setting _just_ caused segfaults, I was fine to assume that all calculations that ran to completion were obviously OK. Now seeing that there's some shade of undefined behavior leading to memory corruption possibly going on, I'd like to understand what is going wrong so I can figure out what's likely impacted... cases where the energy is obviously and egregiously wrong (like above) are easy, but I'm worried more about subtle incorrectness. As for the general fix -- if `num_frozen_docc` is disabled for SAPT0, then it becomes impossible for a user to impose their own beliefs about frozen orbitals in tricky cases like transition metals, which seems... bad. Since it does impact the dispersion portion of the calc, it needs to be user-mutable. This setting *shouldn't* be actually impacting the HF energies, and fixing that strange interaction seems like most of the battle. I'm less sure of what to do in the MP2 case, since it does seem relevant that the user should be able to specify their own core policy as required... At the risk of further complication, would it make sense to implement either:; 1. The ability for `num_frozen_docc` to take in a tuple the same length of the number of fragments in the active `Molecule` (such that correct behavior can be inferred in cases like SAPT where both monomer and dimer calcs are run in a global context); 2. The ability to define, via a list(?), a custom policy on a per-element basis that can be fed to `freeze_core`? . Both of these would allow both for the user to handle cases like custom frozen thresholds in multi-calc situations and keep things consistent. At the same time, these are... possibly a lot of work. I'm prototyping a solution of type (2) but I'm not sure if it'll be too clunky for others to use -- assuming I haven't messed up horribly, I'll propose the patch later today.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1207254380
https://github.com/psi4/psi4/issues/2631#issuecomment-1208404402:15,Deployability,patch,patch,15,"I've written a patch to allow for a custom frozen policy that is a bit clunky but safer than `num_frozen_docc` (because it applies per-atom rules, so works properly for cases like SAPT, MBIS_VOLUME_RATIOS, etc) -- once I can be sure this builds in vanilla psi4 (trying now) I will re-run my test jobs and submit the patch. . Still not sure what to do about `scf::HF::compute_fcpi` because I'm still a newbie to the code base (and this patch does NOT fix that issue).",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1208404402
https://github.com/psi4/psi4/issues/2631#issuecomment-1208404402:316,Deployability,patch,patch,316,"I've written a patch to allow for a custom frozen policy that is a bit clunky but safer than `num_frozen_docc` (because it applies per-atom rules, so works properly for cases like SAPT, MBIS_VOLUME_RATIOS, etc) -- once I can be sure this builds in vanilla psi4 (trying now) I will re-run my test jobs and submit the patch. . Still not sure what to do about `scf::HF::compute_fcpi` because I'm still a newbie to the code base (and this patch does NOT fix that issue).",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1208404402
https://github.com/psi4/psi4/issues/2631#issuecomment-1208404402:435,Deployability,patch,patch,435,"I've written a patch to allow for a custom frozen policy that is a bit clunky but safer than `num_frozen_docc` (because it applies per-atom rules, so works properly for cases like SAPT, MBIS_VOLUME_RATIOS, etc) -- once I can be sure this builds in vanilla psi4 (trying now) I will re-run my test jobs and submit the patch. . Still not sure what to do about `scf::HF::compute_fcpi` because I'm still a newbie to the code base (and this patch does NOT fix that issue).",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1208404402
https://github.com/psi4/psi4/issues/2631#issuecomment-1208404402:82,Safety,safe,safer,82,"I've written a patch to allow for a custom frozen policy that is a bit clunky but safer than `num_frozen_docc` (because it applies per-atom rules, so works properly for cases like SAPT, MBIS_VOLUME_RATIOS, etc) -- once I can be sure this builds in vanilla psi4 (trying now) I will re-run my test jobs and submit the patch. . Still not sure what to do about `scf::HF::compute_fcpi` because I'm still a newbie to the code base (and this patch does NOT fix that issue).",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1208404402
https://github.com/psi4/psi4/issues/2631#issuecomment-1208404402:291,Testability,test,test,291,"I've written a patch to allow for a custom frozen policy that is a bit clunky but safer than `num_frozen_docc` (because it applies per-atom rules, so works properly for cases like SAPT, MBIS_VOLUME_RATIOS, etc) -- once I can be sure this builds in vanilla psi4 (trying now) I will re-run my test jobs and submit the patch. . Still not sure what to do about `scf::HF::compute_fcpi` because I'm still a newbie to the code base (and this patch does NOT fix that issue).",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1208404402
https://github.com/psi4/psi4/issues/2631#issuecomment-1209829933:311,Energy Efficiency,energy,energy,311,"Just to make sure I understand the issues here:; The first one is clear. A segfault occurs if `num_frozen_docc` is ""too large."" What exactly ""too large"" means is unclear, but more frozen docc pairs than electron pairs is sufficient.; The second one is less clear. Obviously, the QC variables controlling the HF energy are getting grabbed incorrectly, but are these two geometries supposed to be different?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1209829933
https://github.com/psi4/psi4/issues/2631#issuecomment-1209829933:282,Modifiability,variab,variables,282,"Just to make sure I understand the issues here:; The first one is clear. A segfault occurs if `num_frozen_docc` is ""too large."" What exactly ""too large"" means is unclear, but more frozen docc pairs than electron pairs is sufficient.; The second one is less clear. Obviously, the QC variables controlling the HF energy are getting grabbed incorrectly, but are these two geometries supposed to be different?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1209829933
https://github.com/psi4/psi4/issues/2631#issuecomment-1209829933:66,Usability,clear,clear,66,"Just to make sure I understand the issues here:; The first one is clear. A segfault occurs if `num_frozen_docc` is ""too large."" What exactly ""too large"" means is unclear, but more frozen docc pairs than electron pairs is sufficient.; The second one is less clear. Obviously, the QC variables controlling the HF energy are getting grabbed incorrectly, but are these two geometries supposed to be different?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1209829933
https://github.com/psi4/psi4/issues/2631#issuecomment-1209829933:257,Usability,clear,clear,257,"Just to make sure I understand the issues here:; The first one is clear. A segfault occurs if `num_frozen_docc` is ""too large."" What exactly ""too large"" means is unclear, but more frozen docc pairs than electron pairs is sufficient.; The second one is less clear. Obviously, the QC variables controlling the HF energy are getting grabbed incorrectly, but are these two geometries supposed to be different?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1209829933
https://github.com/psi4/psi4/issues/2631#issuecomment-1209917224:450,Modifiability,flexible,flexible,450,"Okay, so there are three different issues here:; 1. A segfault occurs if `num_frozen_docc` is ""too large."" What exactly ""too large"" means is unclear, but more frozen docc pairs than electron pairs is sufficient.; 2. Under certain conditions, `num_frozen_docc` causes very bad HF energies in the SAPT printout. The mechanism for this is unclear, but the individual HF computations themselves seem fine.; 3. The handling of frozen core orbitals is not flexible enough for your purposes. #2667 fixes this issue but not the other two. Do I have all that right? Any other issues I've missed?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1209917224
https://github.com/psi4/psi4/issues/2631#issuecomment-1209922063:279,Usability,simpl,simple,279,"No, it looks like in (2) you're actually getting a bad HF calculation -- even in the HF calculation part, the numbers are Wrong (for the lone water in this case). . (1) and (3) look fine in terms of Bad Behavior I've seen. (and with (3)/freeze_core=True when my element sets are simple I've pretty much moved away from the issue anyway)",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1209922063
https://github.com/psi4/psi4/issues/2631#issuecomment-1209930732:229,Energy Efficiency,Charge,Charge,229,"Based on the output file, `nalpha` and `nbeta` are obviously wrong (up from 5 to 6 for this computation), presumably due to `num_frozen_docc` handling. I doubt this second issue is related to the `num_frozen_docc` segfault. ```; Charge = 0; Multiplicity = 1; Electrons = 10; Nalpha = 5; Nbeta = 5. ... ==> Pre-Iterations <==. SCF Guess: Orbitals guess was supplied from a previous computation. -------------------------------------------------------; Irrep Nso Nmo Nalpha Nbeta Ndocc Nsocc; -------------------------------------------------------; A 28 28 6 6 6 0; -------------------------------------------------------; Total 28 28 6 6 6 0; -------------------------------------------------------; ```. I can look into what's contaminating the occupation count for (2), but #2619 needs to come in first. Is there anything _else_ that's wrong in my summary?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1209930732
https://github.com/psi4/psi4/issues/2631#issuecomment-1211894195:821,Energy Efficiency,energy,energy,821,"What's happening on (2) is as follows:; * For the supersystem computation, #2271 means that the supersystem frozen core is the sum of monomer A and monomer B frozen core. Both of those are set to zero right now, which is bad, but not the direct cause of the issue.; * **For both monomers, `num_frozen_docc 6` means Psi thinks there are 6 frozen orbitals when those monomer computations run**. That doesn't affect energies, but that does contaminate the wavefunction.; * All three wavefunctions are saved; * After reading the monomer B wavefunction, Psi asks monomer B for its occupied orbitals; * When computing its occupied orbitals, monomer B realizes it has 6 frozen orbitals, so it must be at least 6 and therefore returns 6 occupied orbitals; * With a garbage number of occupied orbitals, Psi computes a garbage SCF energy. The primary issue here is that for SAPT supersystem computations, Psi doesn't split `num_frozen_docc` into Monomer A frozen docc and Monomer B frozen docc. (nbody may well have the same problem.). Idea 1:; For _reasonable_ frozen cores, we could plausibly do the supersystem computation, assume the core orbitals are localized on monomers, see which monomers the core orbitals are localized on, and use that to work out the docc per subsystem. This is not distributed and will fail for large frozen cores, where the localization assumption fails. Idea 2:; `num_frozen_docc` simply should not be used for supersystem computations. We need a different keyword that has the user specify this for each elementary system. just like they do charges and spin multiplicities.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1211894195
https://github.com/psi4/psi4/issues/2631#issuecomment-1211894195:1564,Energy Efficiency,charge,charges,1564,"What's happening on (2) is as follows:; * For the supersystem computation, #2271 means that the supersystem frozen core is the sum of monomer A and monomer B frozen core. Both of those are set to zero right now, which is bad, but not the direct cause of the issue.; * **For both monomers, `num_frozen_docc 6` means Psi thinks there are 6 frozen orbitals when those monomer computations run**. That doesn't affect energies, but that does contaminate the wavefunction.; * All three wavefunctions are saved; * After reading the monomer B wavefunction, Psi asks monomer B for its occupied orbitals; * When computing its occupied orbitals, monomer B realizes it has 6 frozen orbitals, so it must be at least 6 and therefore returns 6 occupied orbitals; * With a garbage number of occupied orbitals, Psi computes a garbage SCF energy. The primary issue here is that for SAPT supersystem computations, Psi doesn't split `num_frozen_docc` into Monomer A frozen docc and Monomer B frozen docc. (nbody may well have the same problem.). Idea 1:; For _reasonable_ frozen cores, we could plausibly do the supersystem computation, assume the core orbitals are localized on monomers, see which monomers the core orbitals are localized on, and use that to work out the docc per subsystem. This is not distributed and will fail for large frozen cores, where the localization assumption fails. Idea 2:; `num_frozen_docc` simply should not be used for supersystem computations. We need a different keyword that has the user specify this for each elementary system. just like they do charges and spin multiplicities.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1211894195
https://github.com/psi4/psi4/issues/2631#issuecomment-1211894195:1403,Usability,simpl,simply,1403,"What's happening on (2) is as follows:; * For the supersystem computation, #2271 means that the supersystem frozen core is the sum of monomer A and monomer B frozen core. Both of those are set to zero right now, which is bad, but not the direct cause of the issue.; * **For both monomers, `num_frozen_docc 6` means Psi thinks there are 6 frozen orbitals when those monomer computations run**. That doesn't affect energies, but that does contaminate the wavefunction.; * All three wavefunctions are saved; * After reading the monomer B wavefunction, Psi asks monomer B for its occupied orbitals; * When computing its occupied orbitals, monomer B realizes it has 6 frozen orbitals, so it must be at least 6 and therefore returns 6 occupied orbitals; * With a garbage number of occupied orbitals, Psi computes a garbage SCF energy. The primary issue here is that for SAPT supersystem computations, Psi doesn't split `num_frozen_docc` into Monomer A frozen docc and Monomer B frozen docc. (nbody may well have the same problem.). Idea 1:; For _reasonable_ frozen cores, we could plausibly do the supersystem computation, assume the core orbitals are localized on monomers, see which monomers the core orbitals are localized on, and use that to work out the docc per subsystem. This is not distributed and will fail for large frozen cores, where the localization assumption fails. Idea 2:; `num_frozen_docc` simply should not be used for supersystem computations. We need a different keyword that has the user specify this for each elementary system. just like they do charges and spin multiplicities.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1211894195
https://github.com/psi4/psi4/issues/2631#issuecomment-1212141916:617,Availability,down,down-stream,617,"On the one hand, for cases like SAPT/auto-CP/etc, I'd be fine with just disabling `num_frozen_docc` -- it's clearly inappropriate in any supersystem calculation where the user knows at the `energy` call that it's going to run sub-systems. But going upthread back to the original issue, there's use-cases like `MBIS_VOLUME_RATIOS` that are an add-on to what would otherwise be a valid standalone calculation to use `num_frozen_docc` with (a monomer calc), and there's still the question of what should happen there. You can't just guess based on calc name, because you don't know if the user is going to call `oeprop` down-stream. Disabling `num_frozen_docc` for any calculation where this *could* happen would effectively ban the keyword. . A reasonableness check, or a good guess, could be inserted before any calculation done on a new mol if `num_frozen_docc` is set in the global scope -- with a warning. Or simply error out if a new mol is calculated without `num_frozen_docc` having been updated (not sure how reasonable that is?). . This is but one user's thoughts, of course.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1212141916
https://github.com/psi4/psi4/issues/2631#issuecomment-1212141916:918,Availability,error,error,918,"On the one hand, for cases like SAPT/auto-CP/etc, I'd be fine with just disabling `num_frozen_docc` -- it's clearly inappropriate in any supersystem calculation where the user knows at the `energy` call that it's going to run sub-systems. But going upthread back to the original issue, there's use-cases like `MBIS_VOLUME_RATIOS` that are an add-on to what would otherwise be a valid standalone calculation to use `num_frozen_docc` with (a monomer calc), and there's still the question of what should happen there. You can't just guess based on calc name, because you don't know if the user is going to call `oeprop` down-stream. Disabling `num_frozen_docc` for any calculation where this *could* happen would effectively ban the keyword. . A reasonableness check, or a good guess, could be inserted before any calculation done on a new mol if `num_frozen_docc` is set in the global scope -- with a warning. Or simply error out if a new mol is calculated without `num_frozen_docc` having been updated (not sure how reasonable that is?). . This is but one user's thoughts, of course.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1212141916
https://github.com/psi4/psi4/issues/2631#issuecomment-1212141916:993,Deployability,update,updated,993,"On the one hand, for cases like SAPT/auto-CP/etc, I'd be fine with just disabling `num_frozen_docc` -- it's clearly inappropriate in any supersystem calculation where the user knows at the `energy` call that it's going to run sub-systems. But going upthread back to the original issue, there's use-cases like `MBIS_VOLUME_RATIOS` that are an add-on to what would otherwise be a valid standalone calculation to use `num_frozen_docc` with (a monomer calc), and there's still the question of what should happen there. You can't just guess based on calc name, because you don't know if the user is going to call `oeprop` down-stream. Disabling `num_frozen_docc` for any calculation where this *could* happen would effectively ban the keyword. . A reasonableness check, or a good guess, could be inserted before any calculation done on a new mol if `num_frozen_docc` is set in the global scope -- with a warning. Or simply error out if a new mol is calculated without `num_frozen_docc` having been updated (not sure how reasonable that is?). . This is but one user's thoughts, of course.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1212141916
https://github.com/psi4/psi4/issues/2631#issuecomment-1212141916:190,Energy Efficiency,energy,energy,190,"On the one hand, for cases like SAPT/auto-CP/etc, I'd be fine with just disabling `num_frozen_docc` -- it's clearly inappropriate in any supersystem calculation where the user knows at the `energy` call that it's going to run sub-systems. But going upthread back to the original issue, there's use-cases like `MBIS_VOLUME_RATIOS` that are an add-on to what would otherwise be a valid standalone calculation to use `num_frozen_docc` with (a monomer calc), and there's still the question of what should happen there. You can't just guess based on calc name, because you don't know if the user is going to call `oeprop` down-stream. Disabling `num_frozen_docc` for any calculation where this *could* happen would effectively ban the keyword. . A reasonableness check, or a good guess, could be inserted before any calculation done on a new mol if `num_frozen_docc` is set in the global scope -- with a warning. Or simply error out if a new mol is calculated without `num_frozen_docc` having been updated (not sure how reasonable that is?). . This is but one user's thoughts, of course.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1212141916
https://github.com/psi4/psi4/issues/2631#issuecomment-1212141916:108,Usability,clear,clearly,108,"On the one hand, for cases like SAPT/auto-CP/etc, I'd be fine with just disabling `num_frozen_docc` -- it's clearly inappropriate in any supersystem calculation where the user knows at the `energy` call that it's going to run sub-systems. But going upthread back to the original issue, there's use-cases like `MBIS_VOLUME_RATIOS` that are an add-on to what would otherwise be a valid standalone calculation to use `num_frozen_docc` with (a monomer calc), and there's still the question of what should happen there. You can't just guess based on calc name, because you don't know if the user is going to call `oeprop` down-stream. Disabling `num_frozen_docc` for any calculation where this *could* happen would effectively ban the keyword. . A reasonableness check, or a good guess, could be inserted before any calculation done on a new mol if `num_frozen_docc` is set in the global scope -- with a warning. Or simply error out if a new mol is calculated without `num_frozen_docc` having been updated (not sure how reasonable that is?). . This is but one user's thoughts, of course.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1212141916
https://github.com/psi4/psi4/issues/2631#issuecomment-1212141916:911,Usability,simpl,simply,911,"On the one hand, for cases like SAPT/auto-CP/etc, I'd be fine with just disabling `num_frozen_docc` -- it's clearly inappropriate in any supersystem calculation where the user knows at the `energy` call that it's going to run sub-systems. But going upthread back to the original issue, there's use-cases like `MBIS_VOLUME_RATIOS` that are an add-on to what would otherwise be a valid standalone calculation to use `num_frozen_docc` with (a monomer calc), and there's still the question of what should happen there. You can't just guess based on calc name, because you don't know if the user is going to call `oeprop` down-stream. Disabling `num_frozen_docc` for any calculation where this *could* happen would effectively ban the keyword. . A reasonableness check, or a good guess, could be inserted before any calculation done on a new mol if `num_frozen_docc` is set in the global scope -- with a warning. Or simply error out if a new mol is calculated without `num_frozen_docc` having been updated (not sure how reasonable that is?). . This is but one user's thoughts, of course.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2631#issuecomment-1212141916
https://github.com/psi4/psi4/pull/2633#issuecomment-1197787105:211,Availability,avail,available,211,"Thank you very much, @loriab. Is there a rough schedule whether and if yes, when this will make it into the master? We are currently preparing a paper which makes use of this code and it would be nice if it was available publicly in the not-too-far future :innocent:. Is there anything i can do for speeding up this progress?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2633#issuecomment-1197787105
https://github.com/psi4/psi4/pull/2633#issuecomment-1197787105:47,Energy Efficiency,schedul,schedule,47,"Thank you very much, @loriab. Is there a rough schedule whether and if yes, when this will make it into the master? We are currently preparing a paper which makes use of this code and it would be nice if it was available publicly in the not-too-far future :innocent:. Is there anything i can do for speeding up this progress?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2633#issuecomment-1197787105
https://github.com/psi4/psi4/pull/2633#issuecomment-1198423231:75,Availability,reliab,reliable,75,"We definitely plan to get this into master, but Lori would be the one with reliable time estimates.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2633#issuecomment-1198423231
https://github.com/psi4/psi4/pull/2633#issuecomment-1198695727:120,Availability,toler,tolerance,120,"I've got all the parts that affect REMP ready. Final stage is to persuade dfocc to converge simple molecules to default tolerance under default conditions :-) . I'll update this PR as the amalgamation, then break off just `occ` changes for you and other to look over, @behnle. A couple easy questions:; * Do you want REMP controlled by `mp_type` (covers all MPn > 2 and ZAPT) or `cc_type` (covers CEPA and CC)? Either is sensible, so your call.; * Any need to future-proof QCVariables with `REMP2` (or `REMP2,3`!)?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2633#issuecomment-1198695727
https://github.com/psi4/psi4/pull/2633#issuecomment-1198695727:166,Deployability,update,update,166,"I've got all the parts that affect REMP ready. Final stage is to persuade dfocc to converge simple molecules to default tolerance under default conditions :-) . I'll update this PR as the amalgamation, then break off just `occ` changes for you and other to look over, @behnle. A couple easy questions:; * Do you want REMP controlled by `mp_type` (covers all MPn > 2 and ZAPT) or `cc_type` (covers CEPA and CC)? Either is sensible, so your call.; * Any need to future-proof QCVariables with `REMP2` (or `REMP2,3`!)?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2633#issuecomment-1198695727
https://github.com/psi4/psi4/pull/2633#issuecomment-1198695727:92,Usability,simpl,simple,92,"I've got all the parts that affect REMP ready. Final stage is to persuade dfocc to converge simple molecules to default tolerance under default conditions :-) . I'll update this PR as the amalgamation, then break off just `occ` changes for you and other to look over, @behnle. A couple easy questions:; * Do you want REMP controlled by `mp_type` (covers all MPn > 2 and ZAPT) or `cc_type` (covers CEPA and CC)? Either is sensible, so your call.; * Any need to future-proof QCVariables with `REMP2` (or `REMP2,3`!)?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2633#issuecomment-1198695727
https://github.com/psi4/psi4/pull/2633#issuecomment-1198920727:414,Usability,clear,clear,414,"Thanks for your work.; > * Do you want REMP controlled by `mp_type` (covers all MPn > 2 and ZAPT) or `cc_type` (covers CEPA and CC)? Either is sensible, so your call. Actually not so easy :smile:, as it is a blend of MP and CEPA. But as it is in the occ/dfocc module, i'll vote for `cc_type` for the moment. > * Any need to future-proof QCVariables with `REMP2` (or `REMP2,3`!)?. Currently not, it is not entirely clear whether and how this project is continued. 3rd order might come, but there are no concrete plans.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2633#issuecomment-1198920727
https://github.com/psi4/psi4/pull/2633#issuecomment-1200053455:37,Testability,test,tests,37,"Hooray, we finally have clean CI and tests on this combo dfocc+remp PR!. Now, I'll break off `occ` as the first piece for review. . I think I favor `REMP` to `REMP2` in QCVariables, just to be specific.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2633#issuecomment-1200053455
https://github.com/psi4/psi4/pull/2633#issuecomment-1200063040:121,Energy Efficiency,energy,energy,121,"> I think I favor REMP to REMP2 in QCVariables, just to be specific. Hmm, that means the the calls change also to e.g., `energy(""oremp2"")`. That's consistent with `energy(""mp2"")`, so fine by me. But others can weigh in before I start a grand search-and-replace.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2633#issuecomment-1200063040
https://github.com/psi4/psi4/pull/2633#issuecomment-1200063040:164,Energy Efficiency,energy,energy,164,"> I think I favor REMP to REMP2 in QCVariables, just to be specific. Hmm, that means the the calls change also to e.g., `energy(""oremp2"")`. That's consistent with `energy(""mp2"")`, so fine by me. But others can weigh in before I start a grand search-and-replace.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2633#issuecomment-1200063040
https://github.com/psi4/psi4/pull/2633#issuecomment-1200115598:144,Energy Efficiency,energy,energy,144,"Wow, thanks for your work.; I'm completely fine with changing `REMP`/`OREMP` to `REMP2`/`OREMP2`.; (with the limitation that it's the 2nd order energy/1st order wavefunction, but this is equivalent in the case of MP2)",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2633#issuecomment-1200115598
https://github.com/psi4/psi4/pull/2633#issuecomment-1540498326:43,Integrability,wrap,wrapped,43,@loriab Can we close this? I think this is wrapped up by now.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2633#issuecomment-1540498326
https://github.com/psi4/psi4/pull/2633#issuecomment-1540502506:45,Integrability,wrap,wrapped,45,"> @loriab Can we close this? I think this is wrapped up by now. Sure, go ahead. I think I was using it to track a snapshot of file, but it's outlived its usefulness. And certainly REMP is wrapped up.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2633#issuecomment-1540502506
https://github.com/psi4/psi4/pull/2633#issuecomment-1540502506:188,Integrability,wrap,wrapped,188,"> @loriab Can we close this? I think this is wrapped up by now. Sure, go ahead. I think I was using it to track a snapshot of file, but it's outlived its usefulness. And certainly REMP is wrapped up.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2633#issuecomment-1540502506
https://github.com/psi4/psi4/issues/2635#issuecomment-1190423470:133,Testability,test,tested,133,"`driver/procrouting/mcscf/mcscf_solver.py` indicates that there was also supposed to be a possible value ""OS"". This certainly is not tested now, and I don't know if it was tested at the time. @dgasmith, do you have any memory of this?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2635#issuecomment-1190423470
https://github.com/psi4/psi4/issues/2635#issuecomment-1190423470:172,Testability,test,tested,172,"`driver/procrouting/mcscf/mcscf_solver.py` indicates that there was also supposed to be a possible value ""OS"". This certainly is not tested now, and I don't know if it was tested at the time. @dgasmith, do you have any memory of this?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2635#issuecomment-1190423470
https://github.com/psi4/psi4/issues/2635#issuecomment-1190895392:55,Availability,robust,robust,55,`OS` is for one-step which I couldn't get to work in a robust manner. Please simply remove.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2635#issuecomment-1190895392
https://github.com/psi4/psi4/issues/2635#issuecomment-1190895392:77,Usability,simpl,simply,77,`OS` is for one-step which I couldn't get to work in a robust manner. Please simply remove.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2635#issuecomment-1190895392
https://github.com/psi4/psi4/pull/2637#issuecomment-1332534709:116,Deployability,release,released,116,"This PR has largely become obsolete, sq_rsp and rsp has been deprecated, and should end up deleted **after** 1.7 is released.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2637#issuecomment-1332534709
https://github.com/psi4/psi4/issues/2641#issuecomment-1192851164:122,Energy Efficiency,energy,energy,122,"Thanks for the report. I've been able to reproduce the crash. (I observe a fifth decimal place disagreement in DF-RKS SAD energy and a third decimal place disagreement in all iteration energies.) There are two things that worry me here:. 1. The crash itself. I struggle to imagine why the ADIIS optimization problem is so difficult to solve here.; 2. The abhorrent SCF energies. The energy jumps 138 hartrees after the guess! If I remember correctly, the SAD energy isn't the energy corresponding to a particular set of orbitals, but this is still astounding. @susilehtola may have some insight on this. I can poke on this, but the first step will be to try and reproduce this with a smaller system. I don't have access to 14 threads, so I'll have trouble running this repeatedly.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2641#issuecomment-1192851164
https://github.com/psi4/psi4/issues/2641#issuecomment-1192851164:383,Energy Efficiency,energy,energy,383,"Thanks for the report. I've been able to reproduce the crash. (I observe a fifth decimal place disagreement in DF-RKS SAD energy and a third decimal place disagreement in all iteration energies.) There are two things that worry me here:. 1. The crash itself. I struggle to imagine why the ADIIS optimization problem is so difficult to solve here.; 2. The abhorrent SCF energies. The energy jumps 138 hartrees after the guess! If I remember correctly, the SAD energy isn't the energy corresponding to a particular set of orbitals, but this is still astounding. @susilehtola may have some insight on this. I can poke on this, but the first step will be to try and reproduce this with a smaller system. I don't have access to 14 threads, so I'll have trouble running this repeatedly.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2641#issuecomment-1192851164
https://github.com/psi4/psi4/issues/2641#issuecomment-1192851164:459,Energy Efficiency,energy,energy,459,"Thanks for the report. I've been able to reproduce the crash. (I observe a fifth decimal place disagreement in DF-RKS SAD energy and a third decimal place disagreement in all iteration energies.) There are two things that worry me here:. 1. The crash itself. I struggle to imagine why the ADIIS optimization problem is so difficult to solve here.; 2. The abhorrent SCF energies. The energy jumps 138 hartrees after the guess! If I remember correctly, the SAD energy isn't the energy corresponding to a particular set of orbitals, but this is still astounding. @susilehtola may have some insight on this. I can poke on this, but the first step will be to try and reproduce this with a smaller system. I don't have access to 14 threads, so I'll have trouble running this repeatedly.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2641#issuecomment-1192851164
https://github.com/psi4/psi4/issues/2641#issuecomment-1192851164:476,Energy Efficiency,energy,energy,476,"Thanks for the report. I've been able to reproduce the crash. (I observe a fifth decimal place disagreement in DF-RKS SAD energy and a third decimal place disagreement in all iteration energies.) There are two things that worry me here:. 1. The crash itself. I struggle to imagine why the ADIIS optimization problem is so difficult to solve here.; 2. The abhorrent SCF energies. The energy jumps 138 hartrees after the guess! If I remember correctly, the SAD energy isn't the energy corresponding to a particular set of orbitals, but this is still astounding. @susilehtola may have some insight on this. I can poke on this, but the first step will be to try and reproduce this with a smaller system. I don't have access to 14 threads, so I'll have trouble running this repeatedly.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2641#issuecomment-1192851164
https://github.com/psi4/psi4/issues/2641#issuecomment-1192851164:295,Performance,optimiz,optimization,295,"Thanks for the report. I've been able to reproduce the crash. (I observe a fifth decimal place disagreement in DF-RKS SAD energy and a third decimal place disagreement in all iteration energies.) There are two things that worry me here:. 1. The crash itself. I struggle to imagine why the ADIIS optimization problem is so difficult to solve here.; 2. The abhorrent SCF energies. The energy jumps 138 hartrees after the guess! If I remember correctly, the SAD energy isn't the energy corresponding to a particular set of orbitals, but this is still astounding. @susilehtola may have some insight on this. I can poke on this, but the first step will be to try and reproduce this with a smaller system. I don't have access to 14 threads, so I'll have trouble running this repeatedly.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2641#issuecomment-1192851164
https://github.com/psi4/psi4/issues/2641#issuecomment-1192851164:713,Security,access,access,713,"Thanks for the report. I've been able to reproduce the crash. (I observe a fifth decimal place disagreement in DF-RKS SAD energy and a third decimal place disagreement in all iteration energies.) There are two things that worry me here:. 1. The crash itself. I struggle to imagine why the ADIIS optimization problem is so difficult to solve here.; 2. The abhorrent SCF energies. The energy jumps 138 hartrees after the guess! If I remember correctly, the SAD energy isn't the energy corresponding to a particular set of orbitals, but this is still astounding. @susilehtola may have some insight on this. I can poke on this, but the first step will be to try and reproduce this with a smaller system. I don't have access to 14 threads, so I'll have trouble running this repeatedly.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2641#issuecomment-1192851164
https://github.com/psi4/psi4/issues/2641#issuecomment-1192972026:58,Availability,fault,fault,58,"It seems that the process of creating the geometry was at faultin particular, in a production run, I created molecules with the ""units angstrom"" tag, and then called `molecule.set_full_geometry(xyzs)` on each of them. This seems to have had the effect of assuming that the coordinates were in bohr, then converting them to angstroms (dividing by 1.889). This, I think, produces the rough factor of 2 difference observed. I had missed that set_full_geometry assumes that the coordinates are in Bohr. I will try rerunning the fixed version in production to see if I end up with any similar errors. It takes a rather long time to converge (currently at 35 iterations; it's not converged yet), and it is quite low in energycurrently, -905 Hartree.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2641#issuecomment-1192972026
https://github.com/psi4/psi4/issues/2641#issuecomment-1192972026:589,Availability,error,errors,589,"It seems that the process of creating the geometry was at faultin particular, in a production run, I created molecules with the ""units angstrom"" tag, and then called `molecule.set_full_geometry(xyzs)` on each of them. This seems to have had the effect of assuming that the coordinates were in bohr, then converting them to angstroms (dividing by 1.889). This, I think, produces the rough factor of 2 difference observed. I had missed that set_full_geometry assumes that the coordinates are in Bohr. I will try rerunning the fixed version in production to see if I end up with any similar errors. It takes a rather long time to converge (currently at 35 iterations; it's not converged yet), and it is quite low in energycurrently, -905 Hartree.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2641#issuecomment-1192972026
https://github.com/psi4/psi4/issues/2641#issuecomment-1192972026:714,Energy Efficiency,energy,energy,714,"It seems that the process of creating the geometry was at faultin particular, in a production run, I created molecules with the ""units angstrom"" tag, and then called `molecule.set_full_geometry(xyzs)` on each of them. This seems to have had the effect of assuming that the coordinates were in bohr, then converting them to angstroms (dividing by 1.889). This, I think, produces the rough factor of 2 difference observed. I had missed that set_full_geometry assumes that the coordinates are in Bohr. I will try rerunning the fixed version in production to see if I end up with any similar errors. It takes a rather long time to converge (currently at 35 iterations; it's not converged yet), and it is quite low in energycurrently, -905 Hartree.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2641#issuecomment-1192972026
https://github.com/psi4/psi4/issues/2641#issuecomment-1192984871:63,Availability,error,error,63,"It is still possible to create the ""ADIIS minimization failed"" error with the input file below (only changes to the above are correcting the coordinates' units and changing VV10 parameters), but I imagine this is because the values for (b,c) are now so extreme that it's no longer physical. . ```; set num_frozen_docc 12; set {; dft_vv10_b 0.01; dft_vv10_c 0.01; }; set {; basis def2-tzvppd; guess sad; dft_nuclear_scheme SBECKE; dft_radial_scheme EM; dft_radial_points 99; dft_spherical_points 590; dft_vv10_radial_points 50; dft_vv10_spherical_points 194; dft_pruning_scheme robust; }; set {; wcombine False; }; molecule mol {; 0 1; C -0.49280516 -1.34928891 1.93251153; C 0.84810575 -1.10523761 2.10967679; C 1.26836829 0.29972931 2.0863085 ; C 0.33631373 1.28766879 2.06605249; C -1.0593442 1.02559068 1.99570094; C -1.46753033 -0.25217665 2.08599284; H -0.8366212 -2.3512709 1.85597882; H 1.65258993 -1.81487491 2.11488685; H 2.30066607 0.63566923 1.9769963 ; H 0.6336208 2.42220895 1.85607739; H -1.79244121 1.74937993 2.11242291; H -2.68362171 -0.43063144 2.07823169; C -0.8151077 -1.09341082 -1.9012646 ; C -1.16492239 0.31096713 -2.00016775; C -0.29873999 1.38082172 -1.68134071; C 0.91640784 1.08513712 -1.22645142; C 1.30080416 -0.26891269 -1.09865272; C 0.4588141 -1.39278819 -1.38251659; H -1.3834194 -1.9058937 -2.16792859; H -2.20012949 0.38972302 -2.19448924; H -0.48864896 2.51613661 -1.54574084; H 1.66750317 1.87858355 -1.04866167; H 2.23050409 -0.51844162 -0.70388782; H 0.9799473 -2.25156744 -1.27023577; units angstrom; no_reorient; no_com; symmetry c1; }; mol.update_geometry(); e, wf = energy('wb97m-v',return_wfn=True,); ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2641#issuecomment-1192984871
https://github.com/psi4/psi4/issues/2641#issuecomment-1192984871:577,Availability,robust,robust,577,"It is still possible to create the ""ADIIS minimization failed"" error with the input file below (only changes to the above are correcting the coordinates' units and changing VV10 parameters), but I imagine this is because the values for (b,c) are now so extreme that it's no longer physical. . ```; set num_frozen_docc 12; set {; dft_vv10_b 0.01; dft_vv10_c 0.01; }; set {; basis def2-tzvppd; guess sad; dft_nuclear_scheme SBECKE; dft_radial_scheme EM; dft_radial_points 99; dft_spherical_points 590; dft_vv10_radial_points 50; dft_vv10_spherical_points 194; dft_pruning_scheme robust; }; set {; wcombine False; }; molecule mol {; 0 1; C -0.49280516 -1.34928891 1.93251153; C 0.84810575 -1.10523761 2.10967679; C 1.26836829 0.29972931 2.0863085 ; C 0.33631373 1.28766879 2.06605249; C -1.0593442 1.02559068 1.99570094; C -1.46753033 -0.25217665 2.08599284; H -0.8366212 -2.3512709 1.85597882; H 1.65258993 -1.81487491 2.11488685; H 2.30066607 0.63566923 1.9769963 ; H 0.6336208 2.42220895 1.85607739; H -1.79244121 1.74937993 2.11242291; H -2.68362171 -0.43063144 2.07823169; C -0.8151077 -1.09341082 -1.9012646 ; C -1.16492239 0.31096713 -2.00016775; C -0.29873999 1.38082172 -1.68134071; C 0.91640784 1.08513712 -1.22645142; C 1.30080416 -0.26891269 -1.09865272; C 0.4588141 -1.39278819 -1.38251659; H -1.3834194 -1.9058937 -2.16792859; H -2.20012949 0.38972302 -2.19448924; H -0.48864896 2.51613661 -1.54574084; H 1.66750317 1.87858355 -1.04866167; H 2.23050409 -0.51844162 -0.70388782; H 0.9799473 -2.25156744 -1.27023577; units angstrom; no_reorient; no_com; symmetry c1; }; mol.update_geometry(); e, wf = energy('wb97m-v',return_wfn=True,); ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2641#issuecomment-1192984871
https://github.com/psi4/psi4/issues/2641#issuecomment-1192984871:1610,Energy Efficiency,energy,energy,1610,"It is still possible to create the ""ADIIS minimization failed"" error with the input file below (only changes to the above are correcting the coordinates' units and changing VV10 parameters), but I imagine this is because the values for (b,c) are now so extreme that it's no longer physical. . ```; set num_frozen_docc 12; set {; dft_vv10_b 0.01; dft_vv10_c 0.01; }; set {; basis def2-tzvppd; guess sad; dft_nuclear_scheme SBECKE; dft_radial_scheme EM; dft_radial_points 99; dft_spherical_points 590; dft_vv10_radial_points 50; dft_vv10_spherical_points 194; dft_pruning_scheme robust; }; set {; wcombine False; }; molecule mol {; 0 1; C -0.49280516 -1.34928891 1.93251153; C 0.84810575 -1.10523761 2.10967679; C 1.26836829 0.29972931 2.0863085 ; C 0.33631373 1.28766879 2.06605249; C -1.0593442 1.02559068 1.99570094; C -1.46753033 -0.25217665 2.08599284; H -0.8366212 -2.3512709 1.85597882; H 1.65258993 -1.81487491 2.11488685; H 2.30066607 0.63566923 1.9769963 ; H 0.6336208 2.42220895 1.85607739; H -1.79244121 1.74937993 2.11242291; H -2.68362171 -0.43063144 2.07823169; C -0.8151077 -1.09341082 -1.9012646 ; C -1.16492239 0.31096713 -2.00016775; C -0.29873999 1.38082172 -1.68134071; C 0.91640784 1.08513712 -1.22645142; C 1.30080416 -0.26891269 -1.09865272; C 0.4588141 -1.39278819 -1.38251659; H -1.3834194 -1.9058937 -2.16792859; H -2.20012949 0.38972302 -2.19448924; H -0.48864896 2.51613661 -1.54574084; H 1.66750317 1.87858355 -1.04866167; H 2.23050409 -0.51844162 -0.70388782; H 0.9799473 -2.25156744 -1.27023577; units angstrom; no_reorient; no_com; symmetry c1; }; mol.update_geometry(); e, wf = energy('wb97m-v',return_wfn=True,); ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2641#issuecomment-1192984871
https://github.com/psi4/psi4/issues/2641#issuecomment-1194129799:449,Availability,failure,failure,449,"To sum up the discussion so far:; * The original geometry was malformed. Not a Psi4 problem.; * We've noticed large changes in energy in the early iterations, with the malformed geometry and a SAD guess. Not a Psi4 problem. (See https://github.com/psi4/psi4/issues/2641#issuecomment-1192909620); * There's been some discussion over how appropriate custom setting DFT VV10 c parameters is. Not a Psi4 problem.; * It's still possible to cause A/EDIIS failure with a sufficiently non-physical Hamiltonian, whether due to DFT VV10 parameters or a compressed geometry. **This is a Psi4 problem.**. I'll see what I can do about the last one, but I suspect that my options will be very limited.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2641#issuecomment-1194129799
https://github.com/psi4/psi4/issues/2641#issuecomment-1194129799:127,Energy Efficiency,energy,energy,127,"To sum up the discussion so far:; * The original geometry was malformed. Not a Psi4 problem.; * We've noticed large changes in energy in the early iterations, with the malformed geometry and a SAD guess. Not a Psi4 problem. (See https://github.com/psi4/psi4/issues/2641#issuecomment-1192909620); * There's been some discussion over how appropriate custom setting DFT VV10 c parameters is. Not a Psi4 problem.; * It's still possible to cause A/EDIIS failure with a sufficiently non-physical Hamiltonian, whether due to DFT VV10 parameters or a compressed geometry. **This is a Psi4 problem.**. I'll see what I can do about the last one, but I suspect that my options will be very limited.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2641#issuecomment-1194129799
https://github.com/psi4/psi4/issues/2641#issuecomment-1194156054:542,Energy Efficiency,energy,energy,542,"@hokru For B97M-V, it doesn't seem to be possible to change the  parameter directly from the psithon interfacethere's a check at https://github.com/psi4/psi4/blob/d9093c75c71c2b33fbe86f32b25d138675ac22eb/psi4/src/psi4/libfunctional/LibXCfunctional.cc#L218 that disallows it. I want to be on the safe side and not manually change it without knowing why the limitation is put in place. . As for DFT_VV10_POSTSCFit does make things faster by quite a bit, but when I move to nonstandard values of (b,c), it yields deviations  0.1 Hartree in energy calculations (e.g. using the above geometry with b = 0.5 and c unchanged, I go from -456.38 to -456.17 when I turn on DFT_VV10_POSTSCF).",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2641#issuecomment-1194156054
https://github.com/psi4/psi4/issues/2641#issuecomment-1194156054:103,Integrability,interface,interface,103,"@hokru For B97M-V, it doesn't seem to be possible to change the  parameter directly from the psithon interfacethere's a check at https://github.com/psi4/psi4/blob/d9093c75c71c2b33fbe86f32b25d138675ac22eb/psi4/src/psi4/libfunctional/LibXCfunctional.cc#L218 that disallows it. I want to be on the safe side and not manually change it without knowing why the limitation is put in place. . As for DFT_VV10_POSTSCFit does make things faster by quite a bit, but when I move to nonstandard values of (b,c), it yields deviations  0.1 Hartree in energy calculations (e.g. using the above geometry with b = 0.5 and c unchanged, I go from -456.38 to -456.17 when I turn on DFT_VV10_POSTSCF).",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2641#issuecomment-1194156054
https://github.com/psi4/psi4/issues/2641#issuecomment-1194156054:298,Safety,safe,safe,298,"@hokru For B97M-V, it doesn't seem to be possible to change the  parameter directly from the psithon interfacethere's a check at https://github.com/psi4/psi4/blob/d9093c75c71c2b33fbe86f32b25d138675ac22eb/psi4/src/psi4/libfunctional/LibXCfunctional.cc#L218 that disallows it. I want to be on the safe side and not manually change it without knowing why the limitation is put in place. . As for DFT_VV10_POSTSCFit does make things faster by quite a bit, but when I move to nonstandard values of (b,c), it yields deviations  0.1 Hartree in energy calculations (e.g. using the above geometry with b = 0.5 and c unchanged, I go from -456.38 to -456.17 when I turn on DFT_VV10_POSTSCF).",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2641#issuecomment-1194156054
https://github.com/psi4/psi4/issues/2641#issuecomment-1194172697:105,Integrability,interface,interface,105,"> @hokru For B97M-V, it doesn't seem to be possible to change the  parameter directly from the psithon interfacethere's a check at; > ; > https://github.com/psi4/psi4/blob/d9093c75c71c2b33fbe86f32b25d138675ac22eb/psi4/src/psi4/libfunctional/LibXCfunctional.cc#L218; > that disallows it. I want to be on the safe side and not manually change it without knowing why the limitation is put in place. @susilehtola? It looks like this code was added as part of Psi adopting LIbXC in May 2017, so this may be as simple as ""it's perfectly legitimate to change omega here; the code needs to be modernized already.""",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2641#issuecomment-1194172697
https://github.com/psi4/psi4/issues/2641#issuecomment-1194172697:310,Safety,safe,safe,310,"> @hokru For B97M-V, it doesn't seem to be possible to change the  parameter directly from the psithon interfacethere's a check at; > ; > https://github.com/psi4/psi4/blob/d9093c75c71c2b33fbe86f32b25d138675ac22eb/psi4/src/psi4/libfunctional/LibXCfunctional.cc#L218; > that disallows it. I want to be on the safe side and not manually change it without knowing why the limitation is put in place. @susilehtola? It looks like this code was added as part of Psi adopting LIbXC in May 2017, so this may be as simple as ""it's perfectly legitimate to change omega here; the code needs to be modernized already.""",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2641#issuecomment-1194172697
https://github.com/psi4/psi4/issues/2641#issuecomment-1194172697:508,Usability,simpl,simple,508,"> @hokru For B97M-V, it doesn't seem to be possible to change the  parameter directly from the psithon interfacethere's a check at; > ; > https://github.com/psi4/psi4/blob/d9093c75c71c2b33fbe86f32b25d138675ac22eb/psi4/src/psi4/libfunctional/LibXCfunctional.cc#L218; > that disallows it. I want to be on the safe side and not manually change it without knowing why the limitation is put in place. @susilehtola? It looks like this code was added as part of Psi adopting LIbXC in May 2017, so this may be as simple as ""it's perfectly legitimate to change omega here; the code needs to be modernized already.""",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2641#issuecomment-1194172697
https://github.com/psi4/psi4/issues/2641#issuecomment-1194210633:660,Deployability,patch,patch,660,"> > @hokru For B97M-V, it doesn't seem to be possible to change the  parameter directly from the psithon interfacethere's a check at; > > https://github.com/psi4/psi4/blob/d9093c75c71c2b33fbe86f32b25d138675ac22eb/psi4/src/psi4/libfunctional/LibXCfunctional.cc#L218; > > ; > > that disallows it. I want to be on the safe side and not manually change it without knowing why the limitation is put in place.; > ; > @susilehtola? It looks like this code was added as part of Psi adopting LIbXC in May 2017, so this may be as simple as ""it's perfectly legitimate to change omega here; the code needs to be modernized already."". Looks like hacky code. I'll send a patch",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2641#issuecomment-1194210633
https://github.com/psi4/psi4/issues/2641#issuecomment-1194210633:107,Integrability,interface,interface,107,"> > @hokru For B97M-V, it doesn't seem to be possible to change the  parameter directly from the psithon interfacethere's a check at; > > https://github.com/psi4/psi4/blob/d9093c75c71c2b33fbe86f32b25d138675ac22eb/psi4/src/psi4/libfunctional/LibXCfunctional.cc#L218; > > ; > > that disallows it. I want to be on the safe side and not manually change it without knowing why the limitation is put in place.; > ; > @susilehtola? It looks like this code was added as part of Psi adopting LIbXC in May 2017, so this may be as simple as ""it's perfectly legitimate to change omega here; the code needs to be modernized already."". Looks like hacky code. I'll send a patch",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2641#issuecomment-1194210633
https://github.com/psi4/psi4/issues/2641#issuecomment-1194210633:318,Safety,safe,safe,318,"> > @hokru For B97M-V, it doesn't seem to be possible to change the  parameter directly from the psithon interfacethere's a check at; > > https://github.com/psi4/psi4/blob/d9093c75c71c2b33fbe86f32b25d138675ac22eb/psi4/src/psi4/libfunctional/LibXCfunctional.cc#L218; > > ; > > that disallows it. I want to be on the safe side and not manually change it without knowing why the limitation is put in place.; > ; > @susilehtola? It looks like this code was added as part of Psi adopting LIbXC in May 2017, so this may be as simple as ""it's perfectly legitimate to change omega here; the code needs to be modernized already."". Looks like hacky code. I'll send a patch",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2641#issuecomment-1194210633
https://github.com/psi4/psi4/issues/2641#issuecomment-1194210633:523,Usability,simpl,simple,523,"> > @hokru For B97M-V, it doesn't seem to be possible to change the  parameter directly from the psithon interfacethere's a check at; > > https://github.com/psi4/psi4/blob/d9093c75c71c2b33fbe86f32b25d138675ac22eb/psi4/src/psi4/libfunctional/LibXCfunctional.cc#L218; > > ; > > that disallows it. I want to be on the safe side and not manually change it without knowing why the limitation is put in place.; > ; > @susilehtola? It looks like this code was added as part of Psi adopting LIbXC in May 2017, so this may be as simple as ""it's perfectly legitimate to change omega here; the code needs to be modernized already."". Looks like hacky code. I'll send a patch",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2641#issuecomment-1194210633
https://github.com/psi4/psi4/issues/2641#issuecomment-1198448773:282,Deployability,patch,patches,282,"Hey there! I've been working with @averyparr and wanted to chime in on the _specific_ issue of omega in wb97m-v. I'm don't think this is worth promoting to a bigger issue, but at least so if someone else is searching and finds this issue, there's some context. In _addition_ to the patches made in #2643, there's another change that needs to happen to enable one to set `omega` in wb97m-v. Specifically, the version of libxc that psi4 pulls in is 5.1.5 (https://github.com/psi4/psi4/blob/master/external/upstream/libxc/CMakeLists.txt#L18) . This version is old enough that the C file for wb97m-v is missing a _lot_ of content compared to it's other wb97 cousins (see https://gitlab.com/libxc/libxc/-/blob/5.1.5/src/hyb_mgga_xc_wb97mv.c#L38 and compare to, e.g., https://gitlab.com/libxc/libxc/-/blob/5.1.5/src/hyb_gga_xc_wb97.c#L145). Because `xc_func_info_get_n_ext_params` ends up returning 0 (since it's not properly set in wb97m-v), psi4 thinks there's nothing it can set (`NPAR` is 0 and the names are NULL). . Unfortunately this isn't fixed until version 5.3 (https://gitlab.com/libxc/libxc/-/blob/release-5.3.0/src/hyb_mgga_xc_wb97mv.c), which isn't yet a stable release. It's pretty easy to monkey-patch your own libxc 5.2.3+, which _seems_ to work just fine with psi4, but I haven't run any tests besides the basic ones that run during installation.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2641#issuecomment-1198448773
https://github.com/psi4/psi4/issues/2641#issuecomment-1198448773:1104,Deployability,release,release-,1104,"Hey there! I've been working with @averyparr and wanted to chime in on the _specific_ issue of omega in wb97m-v. I'm don't think this is worth promoting to a bigger issue, but at least so if someone else is searching and finds this issue, there's some context. In _addition_ to the patches made in #2643, there's another change that needs to happen to enable one to set `omega` in wb97m-v. Specifically, the version of libxc that psi4 pulls in is 5.1.5 (https://github.com/psi4/psi4/blob/master/external/upstream/libxc/CMakeLists.txt#L18) . This version is old enough that the C file for wb97m-v is missing a _lot_ of content compared to it's other wb97 cousins (see https://gitlab.com/libxc/libxc/-/blob/5.1.5/src/hyb_mgga_xc_wb97mv.c#L38 and compare to, e.g., https://gitlab.com/libxc/libxc/-/blob/5.1.5/src/hyb_gga_xc_wb97.c#L145). Because `xc_func_info_get_n_ext_params` ends up returning 0 (since it's not properly set in wb97m-v), psi4 thinks there's nothing it can set (`NPAR` is 0 and the names are NULL). . Unfortunately this isn't fixed until version 5.3 (https://gitlab.com/libxc/libxc/-/blob/release-5.3.0/src/hyb_mgga_xc_wb97mv.c), which isn't yet a stable release. It's pretty easy to monkey-patch your own libxc 5.2.3+, which _seems_ to work just fine with psi4, but I haven't run any tests besides the basic ones that run during installation.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2641#issuecomment-1198448773
https://github.com/psi4/psi4/issues/2641#issuecomment-1198448773:1170,Deployability,release,release,1170,"Hey there! I've been working with @averyparr and wanted to chime in on the _specific_ issue of omega in wb97m-v. I'm don't think this is worth promoting to a bigger issue, but at least so if someone else is searching and finds this issue, there's some context. In _addition_ to the patches made in #2643, there's another change that needs to happen to enable one to set `omega` in wb97m-v. Specifically, the version of libxc that psi4 pulls in is 5.1.5 (https://github.com/psi4/psi4/blob/master/external/upstream/libxc/CMakeLists.txt#L18) . This version is old enough that the C file for wb97m-v is missing a _lot_ of content compared to it's other wb97 cousins (see https://gitlab.com/libxc/libxc/-/blob/5.1.5/src/hyb_mgga_xc_wb97mv.c#L38 and compare to, e.g., https://gitlab.com/libxc/libxc/-/blob/5.1.5/src/hyb_gga_xc_wb97.c#L145). Because `xc_func_info_get_n_ext_params` ends up returning 0 (since it's not properly set in wb97m-v), psi4 thinks there's nothing it can set (`NPAR` is 0 and the names are NULL). . Unfortunately this isn't fixed until version 5.3 (https://gitlab.com/libxc/libxc/-/blob/release-5.3.0/src/hyb_mgga_xc_wb97mv.c), which isn't yet a stable release. It's pretty easy to monkey-patch your own libxc 5.2.3+, which _seems_ to work just fine with psi4, but I haven't run any tests besides the basic ones that run during installation.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2641#issuecomment-1198448773
https://github.com/psi4/psi4/issues/2641#issuecomment-1198448773:1206,Deployability,patch,patch,1206,"Hey there! I've been working with @averyparr and wanted to chime in on the _specific_ issue of omega in wb97m-v. I'm don't think this is worth promoting to a bigger issue, but at least so if someone else is searching and finds this issue, there's some context. In _addition_ to the patches made in #2643, there's another change that needs to happen to enable one to set `omega` in wb97m-v. Specifically, the version of libxc that psi4 pulls in is 5.1.5 (https://github.com/psi4/psi4/blob/master/external/upstream/libxc/CMakeLists.txt#L18) . This version is old enough that the C file for wb97m-v is missing a _lot_ of content compared to it's other wb97 cousins (see https://gitlab.com/libxc/libxc/-/blob/5.1.5/src/hyb_mgga_xc_wb97mv.c#L38 and compare to, e.g., https://gitlab.com/libxc/libxc/-/blob/5.1.5/src/hyb_gga_xc_wb97.c#L145). Because `xc_func_info_get_n_ext_params` ends up returning 0 (since it's not properly set in wb97m-v), psi4 thinks there's nothing it can set (`NPAR` is 0 and the names are NULL). . Unfortunately this isn't fixed until version 5.3 (https://gitlab.com/libxc/libxc/-/blob/release-5.3.0/src/hyb_mgga_xc_wb97mv.c), which isn't yet a stable release. It's pretty easy to monkey-patch your own libxc 5.2.3+, which _seems_ to work just fine with psi4, but I haven't run any tests besides the basic ones that run during installation.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2641#issuecomment-1198448773
https://github.com/psi4/psi4/issues/2641#issuecomment-1198448773:1345,Deployability,install,installation,1345,"Hey there! I've been working with @averyparr and wanted to chime in on the _specific_ issue of omega in wb97m-v. I'm don't think this is worth promoting to a bigger issue, but at least so if someone else is searching and finds this issue, there's some context. In _addition_ to the patches made in #2643, there's another change that needs to happen to enable one to set `omega` in wb97m-v. Specifically, the version of libxc that psi4 pulls in is 5.1.5 (https://github.com/psi4/psi4/blob/master/external/upstream/libxc/CMakeLists.txt#L18) . This version is old enough that the C file for wb97m-v is missing a _lot_ of content compared to it's other wb97 cousins (see https://gitlab.com/libxc/libxc/-/blob/5.1.5/src/hyb_mgga_xc_wb97mv.c#L38 and compare to, e.g., https://gitlab.com/libxc/libxc/-/blob/5.1.5/src/hyb_gga_xc_wb97.c#L145). Because `xc_func_info_get_n_ext_params` ends up returning 0 (since it's not properly set in wb97m-v), psi4 thinks there's nothing it can set (`NPAR` is 0 and the names are NULL). . Unfortunately this isn't fixed until version 5.3 (https://gitlab.com/libxc/libxc/-/blob/release-5.3.0/src/hyb_mgga_xc_wb97mv.c), which isn't yet a stable release. It's pretty easy to monkey-patch your own libxc 5.2.3+, which _seems_ to work just fine with psi4, but I haven't run any tests besides the basic ones that run during installation.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2641#issuecomment-1198448773
https://github.com/psi4/psi4/issues/2641#issuecomment-1198448773:1300,Testability,test,tests,1300,"Hey there! I've been working with @averyparr and wanted to chime in on the _specific_ issue of omega in wb97m-v. I'm don't think this is worth promoting to a bigger issue, but at least so if someone else is searching and finds this issue, there's some context. In _addition_ to the patches made in #2643, there's another change that needs to happen to enable one to set `omega` in wb97m-v. Specifically, the version of libxc that psi4 pulls in is 5.1.5 (https://github.com/psi4/psi4/blob/master/external/upstream/libxc/CMakeLists.txt#L18) . This version is old enough that the C file for wb97m-v is missing a _lot_ of content compared to it's other wb97 cousins (see https://gitlab.com/libxc/libxc/-/blob/5.1.5/src/hyb_mgga_xc_wb97mv.c#L38 and compare to, e.g., https://gitlab.com/libxc/libxc/-/blob/5.1.5/src/hyb_gga_xc_wb97.c#L145). Because `xc_func_info_get_n_ext_params` ends up returning 0 (since it's not properly set in wb97m-v), psi4 thinks there's nothing it can set (`NPAR` is 0 and the names are NULL). . Unfortunately this isn't fixed until version 5.3 (https://gitlab.com/libxc/libxc/-/blob/release-5.3.0/src/hyb_mgga_xc_wb97mv.c), which isn't yet a stable release. It's pretty easy to monkey-patch your own libxc 5.2.3+, which _seems_ to work just fine with psi4, but I haven't run any tests besides the basic ones that run during installation.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2641#issuecomment-1198448773
https://github.com/psi4/psi4/pull/2644#issuecomment-1194434738:152,Deployability,pipeline,pipeline,152,"For future reference, the commented out test is causing Ecosystem build fails. We don't understand why, but it's holding up the rest of the development pipeline, so we're commenting it out temporarily. This should be fixed by the next full release.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2644#issuecomment-1194434738
https://github.com/psi4/psi4/pull/2644#issuecomment-1194434738:240,Deployability,release,release,240,"For future reference, the commented out test is causing Ecosystem build fails. We don't understand why, but it's holding up the rest of the development pipeline, so we're commenting it out temporarily. This should be fixed by the next full release.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2644#issuecomment-1194434738
https://github.com/psi4/psi4/pull/2644#issuecomment-1194434738:40,Testability,test,test,40,"For future reference, the commented out test is causing Ecosystem build fails. We don't understand why, but it's holding up the rest of the development pipeline, so we're commenting it out temporarily. This should be fixed by the next full release.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2644#issuecomment-1194434738
https://github.com/psi4/psi4/pull/2645#issuecomment-1199824123:47,Deployability,update,update,47,"> I see that this PR passes without needing to update any tests. Do you think some QCFractal tests would be helpful to have, especially now that we have the distributed driver? I know psi4 has tests that use QCSchema, QCElemental, and QCEngine. Yeah, I think a QCFractal Snowflake test on each of findif, manybody, composite would good, provided solving the dependency env isn't too painful, since a database, etc. are needed. There's unlikely to be a conda pkg for the `next` qcf until September at least.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2645#issuecomment-1199824123
https://github.com/psi4/psi4/pull/2645#issuecomment-1199824123:358,Integrability,depend,dependency,358,"> I see that this PR passes without needing to update any tests. Do you think some QCFractal tests would be helpful to have, especially now that we have the distributed driver? I know psi4 has tests that use QCSchema, QCElemental, and QCEngine. Yeah, I think a QCFractal Snowflake test on each of findif, manybody, composite would good, provided solving the dependency env isn't too painful, since a database, etc. are needed. There's unlikely to be a conda pkg for the `next` qcf until September at least.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2645#issuecomment-1199824123
https://github.com/psi4/psi4/pull/2645#issuecomment-1199824123:58,Testability,test,tests,58,"> I see that this PR passes without needing to update any tests. Do you think some QCFractal tests would be helpful to have, especially now that we have the distributed driver? I know psi4 has tests that use QCSchema, QCElemental, and QCEngine. Yeah, I think a QCFractal Snowflake test on each of findif, manybody, composite would good, provided solving the dependency env isn't too painful, since a database, etc. are needed. There's unlikely to be a conda pkg for the `next` qcf until September at least.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2645#issuecomment-1199824123
https://github.com/psi4/psi4/pull/2645#issuecomment-1199824123:93,Testability,test,tests,93,"> I see that this PR passes without needing to update any tests. Do you think some QCFractal tests would be helpful to have, especially now that we have the distributed driver? I know psi4 has tests that use QCSchema, QCElemental, and QCEngine. Yeah, I think a QCFractal Snowflake test on each of findif, manybody, composite would good, provided solving the dependency env isn't too painful, since a database, etc. are needed. There's unlikely to be a conda pkg for the `next` qcf until September at least.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2645#issuecomment-1199824123
https://github.com/psi4/psi4/pull/2645#issuecomment-1199824123:193,Testability,test,tests,193,"> I see that this PR passes without needing to update any tests. Do you think some QCFractal tests would be helpful to have, especially now that we have the distributed driver? I know psi4 has tests that use QCSchema, QCElemental, and QCEngine. Yeah, I think a QCFractal Snowflake test on each of findif, manybody, composite would good, provided solving the dependency env isn't too painful, since a database, etc. are needed. There's unlikely to be a conda pkg for the `next` qcf until September at least.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2645#issuecomment-1199824123
https://github.com/psi4/psi4/pull/2645#issuecomment-1199824123:281,Testability,test,test,281,"> I see that this PR passes without needing to update any tests. Do you think some QCFractal tests would be helpful to have, especially now that we have the distributed driver? I know psi4 has tests that use QCSchema, QCElemental, and QCEngine. Yeah, I think a QCFractal Snowflake test on each of findif, manybody, composite would good, provided solving the dependency env isn't too painful, since a database, etc. are needed. There's unlikely to be a conda pkg for the `next` qcf until September at least.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2645#issuecomment-1199824123
https://github.com/psi4/psi4/pull/2645#issuecomment-1201423497:193,Availability,avail,available,193,"This PR is good prep, but let's hold off on merge.; * In practice, qcf `master` is working as expected and `next` has quirks, so let's keep `master` option open.; * qcf `next` packages not yet available.; * anyone who wants to experiment with `next` need only copy the `task_base.py` file from this PR. (Other PR changes are docs/cosmetic.)",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2645#issuecomment-1201423497
https://github.com/psi4/psi4/pull/2645#issuecomment-1230387732:25,Deployability,update,updates,25,"Thanks for warning. Some updates:; * there _are_ conda packages now for `next` off `-c qcarchive` channel; * I still need to look into next+dask+queuing, so leaving psi4 as qcf-master-based for now still good. that is, no rush to polish up and merge this PR",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2645#issuecomment-1230387732
https://github.com/psi4/psi4/issues/2647#issuecomment-1196968300:193,Availability,error,error,193,I admit i always skipped the orientation/symmetry handling in the cubature code. The warning is here:; https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libfock/cubature.cc#L3505. Such an error in concerning.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2647#issuecomment-1196968300
https://github.com/psi4/psi4/issues/2647#issuecomment-1202360002:728,Testability,benchmark,benchmarking,728,"The issue is somewhere in the orientation of the molecule. I am still trying to understand what exactly the DFT code's `OrientationMgr` does and why.; If I force it to give back the identity matrix as rotation matrix, I get the correct results, regardless of the `no_reorient` option being set. As a workaround, _not_ using the `no_com no_reorient` option will sufficiently improve the results (Eint = 0.00 kcal/mol) but I get less of a match with ORCA's `Eint` when compared to turning off the `OrientationMgr`. For a closer comparison with ORCA one should switch from COSX to RIJK (`! PBEh3c DEFGRID3 TightSCF RIJK def2/JK`). TightSCF sets both a tighter SCF convergence as well as tighter integral screening, both needed for benchmarking.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2647#issuecomment-1202360002
https://github.com/psi4/psi4/issues/2652#issuecomment-1199856872:71,Integrability,rout,routines,71,"Also, I would replace all the inverse functions with calls to the same routines in `orthog.cc`",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2652#issuecomment-1199856872
https://github.com/psi4/psi4/pull/2653#issuecomment-1200911089:196,Availability,avail,available,196,"Excellent, thanks for your tremendous effort.; Given that my test cases were not modified and still seem to work, i do not have any complaints. > * sometimes the non-OO value (e.g., MP2, LCCD) is available as an early byproduct of the OO calc (e.g., OMP2, OLCCD). this wasn't the case with REMP, and some QCVariables that stored a purported non-OO REMP had to be removed. MP2 should also be available from the guess. But it is of course better to not print/store something than to print something wrong. I might be mistaken, but given that `occ` does coupled DIIS for amplitudes and orbitals, the canonical LCCD enery should not be available from an OLCCD calculation (lccd is never iterated on canonical orbitals). The same holds for REMP2. So yes, if there are variables pretending to be canonical results from an orbital-optimized calculation, these should probably be removed.; No problem, it was mostly my fault to put way too many changes into a single pull request based on an ancient master branch.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2653#issuecomment-1200911089
https://github.com/psi4/psi4/pull/2653#issuecomment-1200911089:391,Availability,avail,available,391,"Excellent, thanks for your tremendous effort.; Given that my test cases were not modified and still seem to work, i do not have any complaints. > * sometimes the non-OO value (e.g., MP2, LCCD) is available as an early byproduct of the OO calc (e.g., OMP2, OLCCD). this wasn't the case with REMP, and some QCVariables that stored a purported non-OO REMP had to be removed. MP2 should also be available from the guess. But it is of course better to not print/store something than to print something wrong. I might be mistaken, but given that `occ` does coupled DIIS for amplitudes and orbitals, the canonical LCCD enery should not be available from an OLCCD calculation (lccd is never iterated on canonical orbitals). The same holds for REMP2. So yes, if there are variables pretending to be canonical results from an orbital-optimized calculation, these should probably be removed.; No problem, it was mostly my fault to put way too many changes into a single pull request based on an ancient master branch.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2653#issuecomment-1200911089
https://github.com/psi4/psi4/pull/2653#issuecomment-1200911089:632,Availability,avail,available,632,"Excellent, thanks for your tremendous effort.; Given that my test cases were not modified and still seem to work, i do not have any complaints. > * sometimes the non-OO value (e.g., MP2, LCCD) is available as an early byproduct of the OO calc (e.g., OMP2, OLCCD). this wasn't the case with REMP, and some QCVariables that stored a purported non-OO REMP had to be removed. MP2 should also be available from the guess. But it is of course better to not print/store something than to print something wrong. I might be mistaken, but given that `occ` does coupled DIIS for amplitudes and orbitals, the canonical LCCD enery should not be available from an OLCCD calculation (lccd is never iterated on canonical orbitals). The same holds for REMP2. So yes, if there are variables pretending to be canonical results from an orbital-optimized calculation, these should probably be removed.; No problem, it was mostly my fault to put way too many changes into a single pull request based on an ancient master branch.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2653#issuecomment-1200911089
https://github.com/psi4/psi4/pull/2653#issuecomment-1200911089:911,Availability,fault,fault,911,"Excellent, thanks for your tremendous effort.; Given that my test cases were not modified and still seem to work, i do not have any complaints. > * sometimes the non-OO value (e.g., MP2, LCCD) is available as an early byproduct of the OO calc (e.g., OMP2, OLCCD). this wasn't the case with REMP, and some QCVariables that stored a purported non-OO REMP had to be removed. MP2 should also be available from the guess. But it is of course better to not print/store something than to print something wrong. I might be mistaken, but given that `occ` does coupled DIIS for amplitudes and orbitals, the canonical LCCD enery should not be available from an OLCCD calculation (lccd is never iterated on canonical orbitals). The same holds for REMP2. So yes, if there are variables pretending to be canonical results from an orbital-optimized calculation, these should probably be removed.; No problem, it was mostly my fault to put way too many changes into a single pull request based on an ancient master branch.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2653#issuecomment-1200911089
https://github.com/psi4/psi4/pull/2653#issuecomment-1200911089:763,Modifiability,variab,variables,763,"Excellent, thanks for your tremendous effort.; Given that my test cases were not modified and still seem to work, i do not have any complaints. > * sometimes the non-OO value (e.g., MP2, LCCD) is available as an early byproduct of the OO calc (e.g., OMP2, OLCCD). this wasn't the case with REMP, and some QCVariables that stored a purported non-OO REMP had to be removed. MP2 should also be available from the guess. But it is of course better to not print/store something than to print something wrong. I might be mistaken, but given that `occ` does coupled DIIS for amplitudes and orbitals, the canonical LCCD enery should not be available from an OLCCD calculation (lccd is never iterated on canonical orbitals). The same holds for REMP2. So yes, if there are variables pretending to be canonical results from an orbital-optimized calculation, these should probably be removed.; No problem, it was mostly my fault to put way too many changes into a single pull request based on an ancient master branch.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2653#issuecomment-1200911089
https://github.com/psi4/psi4/pull/2653#issuecomment-1200911089:824,Performance,optimiz,optimized,824,"Excellent, thanks for your tremendous effort.; Given that my test cases were not modified and still seem to work, i do not have any complaints. > * sometimes the non-OO value (e.g., MP2, LCCD) is available as an early byproduct of the OO calc (e.g., OMP2, OLCCD). this wasn't the case with REMP, and some QCVariables that stored a purported non-OO REMP had to be removed. MP2 should also be available from the guess. But it is of course better to not print/store something than to print something wrong. I might be mistaken, but given that `occ` does coupled DIIS for amplitudes and orbitals, the canonical LCCD enery should not be available from an OLCCD calculation (lccd is never iterated on canonical orbitals). The same holds for REMP2. So yes, if there are variables pretending to be canonical results from an orbital-optimized calculation, these should probably be removed.; No problem, it was mostly my fault to put way too many changes into a single pull request based on an ancient master branch.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2653#issuecomment-1200911089
https://github.com/psi4/psi4/pull/2653#issuecomment-1200911089:61,Testability,test,test,61,"Excellent, thanks for your tremendous effort.; Given that my test cases were not modified and still seem to work, i do not have any complaints. > * sometimes the non-OO value (e.g., MP2, LCCD) is available as an early byproduct of the OO calc (e.g., OMP2, OLCCD). this wasn't the case with REMP, and some QCVariables that stored a purported non-OO REMP had to be removed. MP2 should also be available from the guess. But it is of course better to not print/store something than to print something wrong. I might be mistaken, but given that `occ` does coupled DIIS for amplitudes and orbitals, the canonical LCCD enery should not be available from an OLCCD calculation (lccd is never iterated on canonical orbitals). The same holds for REMP2. So yes, if there are variables pretending to be canonical results from an orbital-optimized calculation, these should probably be removed.; No problem, it was mostly my fault to put way too many changes into a single pull request based on an ancient master branch.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2653#issuecomment-1200911089
https://github.com/psi4/psi4/pull/2653#issuecomment-1201136739:54,Availability,avail,available,54,"> > * sometimes the non-OO value (e.g., MP2, LCCD) is available as an early byproduct of the OO calc (e.g., OMP2, OLCCD). this wasn't the case with REMP, and some QCVariables that stored a purported non-OO REMP had to be removed.; > ; > MP2 should also be available from the guess. But it is of course better to not print/store something than to print something wrong. I might be mistaken, but given that `occ` does coupled DIIS for amplitudes and orbitals, the canonical LCCD enery should not be available from an OLCCD calculation (lccd is never iterated on canonical orbitals). The same holds for REMP2. So yes, if there are variables pretending to be canonical results from an orbital-optimized calculation, these should probably be removed. No problem, it was mostly my fault to put way too many changes into a single pull request based on an ancient master branch. This is completely correct. The lone OLCCD algorithm in `occ` does not compute LCCD with the input orbitals.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2653#issuecomment-1201136739
https://github.com/psi4/psi4/pull/2653#issuecomment-1201136739:256,Availability,avail,available,256,"> > * sometimes the non-OO value (e.g., MP2, LCCD) is available as an early byproduct of the OO calc (e.g., OMP2, OLCCD). this wasn't the case with REMP, and some QCVariables that stored a purported non-OO REMP had to be removed.; > ; > MP2 should also be available from the guess. But it is of course better to not print/store something than to print something wrong. I might be mistaken, but given that `occ` does coupled DIIS for amplitudes and orbitals, the canonical LCCD enery should not be available from an OLCCD calculation (lccd is never iterated on canonical orbitals). The same holds for REMP2. So yes, if there are variables pretending to be canonical results from an orbital-optimized calculation, these should probably be removed. No problem, it was mostly my fault to put way too many changes into a single pull request based on an ancient master branch. This is completely correct. The lone OLCCD algorithm in `occ` does not compute LCCD with the input orbitals.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2653#issuecomment-1201136739
https://github.com/psi4/psi4/pull/2653#issuecomment-1201136739:497,Availability,avail,available,497,"> > * sometimes the non-OO value (e.g., MP2, LCCD) is available as an early byproduct of the OO calc (e.g., OMP2, OLCCD). this wasn't the case with REMP, and some QCVariables that stored a purported non-OO REMP had to be removed.; > ; > MP2 should also be available from the guess. But it is of course better to not print/store something than to print something wrong. I might be mistaken, but given that `occ` does coupled DIIS for amplitudes and orbitals, the canonical LCCD enery should not be available from an OLCCD calculation (lccd is never iterated on canonical orbitals). The same holds for REMP2. So yes, if there are variables pretending to be canonical results from an orbital-optimized calculation, these should probably be removed. No problem, it was mostly my fault to put way too many changes into a single pull request based on an ancient master branch. This is completely correct. The lone OLCCD algorithm in `occ` does not compute LCCD with the input orbitals.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2653#issuecomment-1201136739
https://github.com/psi4/psi4/pull/2653#issuecomment-1201136739:775,Availability,fault,fault,775,"> > * sometimes the non-OO value (e.g., MP2, LCCD) is available as an early byproduct of the OO calc (e.g., OMP2, OLCCD). this wasn't the case with REMP, and some QCVariables that stored a purported non-OO REMP had to be removed.; > ; > MP2 should also be available from the guess. But it is of course better to not print/store something than to print something wrong. I might be mistaken, but given that `occ` does coupled DIIS for amplitudes and orbitals, the canonical LCCD enery should not be available from an OLCCD calculation (lccd is never iterated on canonical orbitals). The same holds for REMP2. So yes, if there are variables pretending to be canonical results from an orbital-optimized calculation, these should probably be removed. No problem, it was mostly my fault to put way too many changes into a single pull request based on an ancient master branch. This is completely correct. The lone OLCCD algorithm in `occ` does not compute LCCD with the input orbitals.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2653#issuecomment-1201136739
https://github.com/psi4/psi4/pull/2653#issuecomment-1201136739:628,Modifiability,variab,variables,628,"> > * sometimes the non-OO value (e.g., MP2, LCCD) is available as an early byproduct of the OO calc (e.g., OMP2, OLCCD). this wasn't the case with REMP, and some QCVariables that stored a purported non-OO REMP had to be removed.; > ; > MP2 should also be available from the guess. But it is of course better to not print/store something than to print something wrong. I might be mistaken, but given that `occ` does coupled DIIS for amplitudes and orbitals, the canonical LCCD enery should not be available from an OLCCD calculation (lccd is never iterated on canonical orbitals). The same holds for REMP2. So yes, if there are variables pretending to be canonical results from an orbital-optimized calculation, these should probably be removed. No problem, it was mostly my fault to put way too many changes into a single pull request based on an ancient master branch. This is completely correct. The lone OLCCD algorithm in `occ` does not compute LCCD with the input orbitals.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2653#issuecomment-1201136739
https://github.com/psi4/psi4/pull/2653#issuecomment-1201136739:689,Performance,optimiz,optimized,689,"> > * sometimes the non-OO value (e.g., MP2, LCCD) is available as an early byproduct of the OO calc (e.g., OMP2, OLCCD). this wasn't the case with REMP, and some QCVariables that stored a purported non-OO REMP had to be removed.; > ; > MP2 should also be available from the guess. But it is of course better to not print/store something than to print something wrong. I might be mistaken, but given that `occ` does coupled DIIS for amplitudes and orbitals, the canonical LCCD enery should not be available from an OLCCD calculation (lccd is never iterated on canonical orbitals). The same holds for REMP2. So yes, if there are variables pretending to be canonical results from an orbital-optimized calculation, these should probably be removed. No problem, it was mostly my fault to put way too many changes into a single pull request based on an ancient master branch. This is completely correct. The lone OLCCD algorithm in `occ` does not compute LCCD with the input orbitals.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2653#issuecomment-1201136739
https://github.com/psi4/psi4/pull/2653#issuecomment-1201257770:52,Availability,avail,available,52,">>> sometimes the non-OO value (e.g., MP2, LCCD) is available as an early byproduct of the OO calc (e.g., OMP2, OLCCD). this wasn't the case with REMP, and some QCVariables that stored a purported non-OO REMP had to be removed. >> MP2 should also be available from the guess. But it is of course better to not print/store something than to print something wrong. I might be mistaken, but given that occ does coupled DIIS for amplitudes and orbitals, the canonical LCCD enery should not be available from an OLCCD calculation (lccd is never iterated on canonical orbitals). The same holds for REMP2. So yes, if there are variables pretending to be canonical results from an orbital-optimized calculation, these should probably be removed. No problem, it was mostly my fault to put way too many changes into a single pull request based on an ancient master branch. > This is completely correct. The lone OLCCD algorithm in occ does not compute LCCD with the input orbitals. Great, thanks. `oremp2` is in good shape, then, and I'll add negative assertions for `olccd`. Here's the summary of what gets checked (details are at QCEngine): https://github.com/psi4/psi4/pull/2653/files#diff-e2cf14f98c8e885f5abc7385ca737bfeba9f2f62caead630129e6d7cd9678e71R193-R203",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2653#issuecomment-1201257770
https://github.com/psi4/psi4/pull/2653#issuecomment-1201257770:250,Availability,avail,available,250,">>> sometimes the non-OO value (e.g., MP2, LCCD) is available as an early byproduct of the OO calc (e.g., OMP2, OLCCD). this wasn't the case with REMP, and some QCVariables that stored a purported non-OO REMP had to be removed. >> MP2 should also be available from the guess. But it is of course better to not print/store something than to print something wrong. I might be mistaken, but given that occ does coupled DIIS for amplitudes and orbitals, the canonical LCCD enery should not be available from an OLCCD calculation (lccd is never iterated on canonical orbitals). The same holds for REMP2. So yes, if there are variables pretending to be canonical results from an orbital-optimized calculation, these should probably be removed. No problem, it was mostly my fault to put way too many changes into a single pull request based on an ancient master branch. > This is completely correct. The lone OLCCD algorithm in occ does not compute LCCD with the input orbitals. Great, thanks. `oremp2` is in good shape, then, and I'll add negative assertions for `olccd`. Here's the summary of what gets checked (details are at QCEngine): https://github.com/psi4/psi4/pull/2653/files#diff-e2cf14f98c8e885f5abc7385ca737bfeba9f2f62caead630129e6d7cd9678e71R193-R203",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2653#issuecomment-1201257770
https://github.com/psi4/psi4/pull/2653#issuecomment-1201257770:489,Availability,avail,available,489,">>> sometimes the non-OO value (e.g., MP2, LCCD) is available as an early byproduct of the OO calc (e.g., OMP2, OLCCD). this wasn't the case with REMP, and some QCVariables that stored a purported non-OO REMP had to be removed. >> MP2 should also be available from the guess. But it is of course better to not print/store something than to print something wrong. I might be mistaken, but given that occ does coupled DIIS for amplitudes and orbitals, the canonical LCCD enery should not be available from an OLCCD calculation (lccd is never iterated on canonical orbitals). The same holds for REMP2. So yes, if there are variables pretending to be canonical results from an orbital-optimized calculation, these should probably be removed. No problem, it was mostly my fault to put way too many changes into a single pull request based on an ancient master branch. > This is completely correct. The lone OLCCD algorithm in occ does not compute LCCD with the input orbitals. Great, thanks. `oremp2` is in good shape, then, and I'll add negative assertions for `olccd`. Here's the summary of what gets checked (details are at QCEngine): https://github.com/psi4/psi4/pull/2653/files#diff-e2cf14f98c8e885f5abc7385ca737bfeba9f2f62caead630129e6d7cd9678e71R193-R203",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2653#issuecomment-1201257770
https://github.com/psi4/psi4/pull/2653#issuecomment-1201257770:767,Availability,fault,fault,767,">>> sometimes the non-OO value (e.g., MP2, LCCD) is available as an early byproduct of the OO calc (e.g., OMP2, OLCCD). this wasn't the case with REMP, and some QCVariables that stored a purported non-OO REMP had to be removed. >> MP2 should also be available from the guess. But it is of course better to not print/store something than to print something wrong. I might be mistaken, but given that occ does coupled DIIS for amplitudes and orbitals, the canonical LCCD enery should not be available from an OLCCD calculation (lccd is never iterated on canonical orbitals). The same holds for REMP2. So yes, if there are variables pretending to be canonical results from an orbital-optimized calculation, these should probably be removed. No problem, it was mostly my fault to put way too many changes into a single pull request based on an ancient master branch. > This is completely correct. The lone OLCCD algorithm in occ does not compute LCCD with the input orbitals. Great, thanks. `oremp2` is in good shape, then, and I'll add negative assertions for `olccd`. Here's the summary of what gets checked (details are at QCEngine): https://github.com/psi4/psi4/pull/2653/files#diff-e2cf14f98c8e885f5abc7385ca737bfeba9f2f62caead630129e6d7cd9678e71R193-R203",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2653#issuecomment-1201257770
https://github.com/psi4/psi4/pull/2653#issuecomment-1201257770:620,Modifiability,variab,variables,620,">>> sometimes the non-OO value (e.g., MP2, LCCD) is available as an early byproduct of the OO calc (e.g., OMP2, OLCCD). this wasn't the case with REMP, and some QCVariables that stored a purported non-OO REMP had to be removed. >> MP2 should also be available from the guess. But it is of course better to not print/store something than to print something wrong. I might be mistaken, but given that occ does coupled DIIS for amplitudes and orbitals, the canonical LCCD enery should not be available from an OLCCD calculation (lccd is never iterated on canonical orbitals). The same holds for REMP2. So yes, if there are variables pretending to be canonical results from an orbital-optimized calculation, these should probably be removed. No problem, it was mostly my fault to put way too many changes into a single pull request based on an ancient master branch. > This is completely correct. The lone OLCCD algorithm in occ does not compute LCCD with the input orbitals. Great, thanks. `oremp2` is in good shape, then, and I'll add negative assertions for `olccd`. Here's the summary of what gets checked (details are at QCEngine): https://github.com/psi4/psi4/pull/2653/files#diff-e2cf14f98c8e885f5abc7385ca737bfeba9f2f62caead630129e6d7cd9678e71R193-R203",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2653#issuecomment-1201257770
https://github.com/psi4/psi4/pull/2653#issuecomment-1201257770:681,Performance,optimiz,optimized,681,">>> sometimes the non-OO value (e.g., MP2, LCCD) is available as an early byproduct of the OO calc (e.g., OMP2, OLCCD). this wasn't the case with REMP, and some QCVariables that stored a purported non-OO REMP had to be removed. >> MP2 should also be available from the guess. But it is of course better to not print/store something than to print something wrong. I might be mistaken, but given that occ does coupled DIIS for amplitudes and orbitals, the canonical LCCD enery should not be available from an OLCCD calculation (lccd is never iterated on canonical orbitals). The same holds for REMP2. So yes, if there are variables pretending to be canonical results from an orbital-optimized calculation, these should probably be removed. No problem, it was mostly my fault to put way too many changes into a single pull request based on an ancient master branch. > This is completely correct. The lone OLCCD algorithm in occ does not compute LCCD with the input orbitals. Great, thanks. `oremp2` is in good shape, then, and I'll add negative assertions for `olccd`. Here's the summary of what gets checked (details are at QCEngine): https://github.com/psi4/psi4/pull/2653/files#diff-e2cf14f98c8e885f5abc7385ca737bfeba9f2f62caead630129e6d7cd9678e71R193-R203",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2653#issuecomment-1201257770
https://github.com/psi4/psi4/pull/2653#issuecomment-1201257770:1042,Testability,assert,assertions,1042,">>> sometimes the non-OO value (e.g., MP2, LCCD) is available as an early byproduct of the OO calc (e.g., OMP2, OLCCD). this wasn't the case with REMP, and some QCVariables that stored a purported non-OO REMP had to be removed. >> MP2 should also be available from the guess. But it is of course better to not print/store something than to print something wrong. I might be mistaken, but given that occ does coupled DIIS for amplitudes and orbitals, the canonical LCCD enery should not be available from an OLCCD calculation (lccd is never iterated on canonical orbitals). The same holds for REMP2. So yes, if there are variables pretending to be canonical results from an orbital-optimized calculation, these should probably be removed. No problem, it was mostly my fault to put way too many changes into a single pull request based on an ancient master branch. > This is completely correct. The lone OLCCD algorithm in occ does not compute LCCD with the input orbitals. Great, thanks. `oremp2` is in good shape, then, and I'll add negative assertions for `olccd`. Here's the summary of what gets checked (details are at QCEngine): https://github.com/psi4/psi4/pull/2653/files#diff-e2cf14f98c8e885f5abc7385ca737bfeba9f2f62caead630129e6d7cd9678e71R193-R203",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2653#issuecomment-1201257770
https://github.com/psi4/psi4/pull/2655#issuecomment-1203146735:20,Testability,test,test,20,"For every duplicate test, I want to know where the duplicate is.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2655#issuecomment-1203146735
https://github.com/psi4/psi4/pull/2655#issuecomment-1203164328:156,Energy Efficiency,energy,energy-large,156,`cc5` is a near duplicate of `cc5a`. The latter uses a smaller basis set as `cc5` is very slow.; `scf11-freq-from-energies` is a near duplicate of `fd-freq-energy-large` with a slightly different geometry. The former does not pass without adjusting findif stepsize settings.; `dft-pbe0-2` is duplicated verbatim in `dft-custom-dhdf`; `dft-dsd` is duplicated in `dft-custom-dhdf` with corrected reference values. Former does not pass.; `dft-dldf` is duplicated in `dft-custom-mgga` with corrected reference values. Former does not pass.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2655#issuecomment-1203164328
https://github.com/psi4/psi4/pull/2655#issuecomment-1203201750:40,Deployability,update,update,40,Okay. Please rename `cc5a` to `cc5` and update `tests/cc_index`.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2655#issuecomment-1203201750
https://github.com/psi4/psi4/pull/2655#issuecomment-1203201750:48,Testability,test,tests,48,Okay. Please rename `cc5a` to `cc5` and update `tests/cc_index`.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2655#issuecomment-1203201750
https://github.com/psi4/psi4/issues/2656#issuecomment-1203208847:85,Availability,error,errors,85,"The psi4 code unchanged since May 2019 has suddenly started throwing circular import errors?. Any changes to the dependency list? Particularly, is qcengine present?. Python 3.11 only? I've never tried a 3.11 prerelease.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2656#issuecomment-1203208847
https://github.com/psi4/psi4/issues/2656#issuecomment-1203208847:113,Integrability,depend,dependency,113,"The psi4 code unchanged since May 2019 has suddenly started throwing circular import errors?. Any changes to the dependency list? Particularly, is qcengine present?. Python 3.11 only? I've never tried a 3.11 prerelease.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2656#issuecomment-1203208847
https://github.com/psi4/psi4/issues/2656#issuecomment-1203221687:23,Integrability,depend,dependency,23,"Yup. And no changes to dependency lists either; no qcengine. And yes, this is with Python 3.11 in Fedora rawhide.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2656#issuecomment-1203221687
https://github.com/psi4/psi4/issues/2656#issuecomment-1203229833:340,Availability,down,down,340,"> Maybe it's a pybind11 issue?. Worth a try. Looks like we were at `v2.2.3` in that era: (2nd col of https://github.com/psi4/psi4meta/blob/master/conda-recipes/conda_build_config.yaml#L103-L104). > Yup. And no changes to dependency lists either; no qcengine. aggh. > And yes, this is with Python 3.11 in Fedora rawhide. Can you dial Python down a bit? Psi 1.3 was only knowingly build for 3.6 and 3.7. --------. This long life of v1.3 is all because of Libint2 issues, right? Can L2 be vendored with (internal build distributed with) Psi4? Must it be static?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2656#issuecomment-1203229833
https://github.com/psi4/psi4/issues/2656#issuecomment-1203229833:221,Integrability,depend,dependency,221,"> Maybe it's a pybind11 issue?. Worth a try. Looks like we were at `v2.2.3` in that era: (2nd col of https://github.com/psi4/psi4meta/blob/master/conda-recipes/conda_build_config.yaml#L103-L104). > Yup. And no changes to dependency lists either; no qcengine. aggh. > And yes, this is with Python 3.11 in Fedora rawhide. Can you dial Python down a bit? Psi 1.3 was only knowingly build for 3.6 and 3.7. --------. This long life of v1.3 is all because of Libint2 issues, right? Can L2 be vendored with (internal build distributed with) Psi4? Must it be static?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2656#issuecomment-1203229833
https://github.com/psi4/psi4/issues/2656#issuecomment-1203246662:410,Deployability,release,release,410,"> Yes, this is all due to the switch to L2. L2 can't be bundled with Psi4 since it doesn't come bundled with Psi4 in the first place. All libraries are dynamic in Fedora, and everything has to be compiled from pristine sources. Caveat: my current L2 knowledge is the equivalent of on-a-tape-drive-in-a-basement-archive, so don't hold me to anything. I think Psi4 could be built against pristine source, latest release L2 with a little cmake patching psi4-side. But producing and hosting two variants (gss/sss) isn't something you/Fedora want to get into, I expect.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2656#issuecomment-1203246662
https://github.com/psi4/psi4/issues/2656#issuecomment-1203246662:441,Deployability,patch,patching,441,"> Yes, this is all due to the switch to L2. L2 can't be bundled with Psi4 since it doesn't come bundled with Psi4 in the first place. All libraries are dynamic in Fedora, and everything has to be compiled from pristine sources. Caveat: my current L2 knowledge is the equivalent of on-a-tape-drive-in-a-basement-archive, so don't hold me to anything. I think Psi4 could be built against pristine source, latest release L2 with a little cmake patching psi4-side. But producing and hosting two variants (gss/sss) isn't something you/Fedora want to get into, I expect.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2656#issuecomment-1203246662
https://github.com/psi4/psi4/issues/2656#issuecomment-1203302540:132,Testability,log,logs,132,"I was thinking _downgrading_ pb11, not _updating_ it, but ok (2.10 mentions py311 compatibility anyways). I looked through the deps logs from the last good one to this one, and I don't see any red flags.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2656#issuecomment-1203302540
https://github.com/psi4/psi4/issues/2656#issuecomment-1235824357:40,Deployability,update,update,40,"> Have you tried with Python 3.11 yet?. update, I've built python 3.11 rc and numpy from source (first time ever). I did have to use the most recent v2.10.0 pb11. By turning off some diis (see below), I can get the variant on test tu1 to run through 6 SCF iterations (not to convergence) before segfaulting. major things still to investigate -- installing scipy, what lapack libraries for numpy is pip hiding from me, are the timer files closing cleanly when it throws the install-scipy-or-disable-accelerator message. and, of course, all this is on master, not the 1.3.2 of interest to you. . ```; memory 600 mb. molecule h2o {; O ; H 1 0.96; H 1 0.96 2 104.5; }. set basis cc-pVDZ; set scf scf_initial_accelerator none; set diis off; energy('scf'). compare_values(-76.0266327341067125, variable('SCF TOTAL ENERGY'), 6, 'SCF energy') #TEST; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2656#issuecomment-1235824357
https://github.com/psi4/psi4/issues/2656#issuecomment-1235824357:345,Deployability,install,installing,345,"> Have you tried with Python 3.11 yet?. update, I've built python 3.11 rc and numpy from source (first time ever). I did have to use the most recent v2.10.0 pb11. By turning off some diis (see below), I can get the variant on test tu1 to run through 6 SCF iterations (not to convergence) before segfaulting. major things still to investigate -- installing scipy, what lapack libraries for numpy is pip hiding from me, are the timer files closing cleanly when it throws the install-scipy-or-disable-accelerator message. and, of course, all this is on master, not the 1.3.2 of interest to you. . ```; memory 600 mb. molecule h2o {; O ; H 1 0.96; H 1 0.96 2 104.5; }. set basis cc-pVDZ; set scf scf_initial_accelerator none; set diis off; energy('scf'). compare_values(-76.0266327341067125, variable('SCF TOTAL ENERGY'), 6, 'SCF energy') #TEST; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2656#issuecomment-1235824357
https://github.com/psi4/psi4/issues/2656#issuecomment-1235824357:473,Deployability,install,install-scipy-or-disable-accelerator,473,"> Have you tried with Python 3.11 yet?. update, I've built python 3.11 rc and numpy from source (first time ever). I did have to use the most recent v2.10.0 pb11. By turning off some diis (see below), I can get the variant on test tu1 to run through 6 SCF iterations (not to convergence) before segfaulting. major things still to investigate -- installing scipy, what lapack libraries for numpy is pip hiding from me, are the timer files closing cleanly when it throws the install-scipy-or-disable-accelerator message. and, of course, all this is on master, not the 1.3.2 of interest to you. . ```; memory 600 mb. molecule h2o {; O ; H 1 0.96; H 1 0.96 2 104.5; }. set basis cc-pVDZ; set scf scf_initial_accelerator none; set diis off; energy('scf'). compare_values(-76.0266327341067125, variable('SCF TOTAL ENERGY'), 6, 'SCF energy') #TEST; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2656#issuecomment-1235824357
https://github.com/psi4/psi4/issues/2656#issuecomment-1235824357:736,Energy Efficiency,energy,energy,736,"> Have you tried with Python 3.11 yet?. update, I've built python 3.11 rc and numpy from source (first time ever). I did have to use the most recent v2.10.0 pb11. By turning off some diis (see below), I can get the variant on test tu1 to run through 6 SCF iterations (not to convergence) before segfaulting. major things still to investigate -- installing scipy, what lapack libraries for numpy is pip hiding from me, are the timer files closing cleanly when it throws the install-scipy-or-disable-accelerator message. and, of course, all this is on master, not the 1.3.2 of interest to you. . ```; memory 600 mb. molecule h2o {; O ; H 1 0.96; H 1 0.96 2 104.5; }. set basis cc-pVDZ; set scf scf_initial_accelerator none; set diis off; energy('scf'). compare_values(-76.0266327341067125, variable('SCF TOTAL ENERGY'), 6, 'SCF energy') #TEST; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2656#issuecomment-1235824357
https://github.com/psi4/psi4/issues/2656#issuecomment-1235824357:808,Energy Efficiency,ENERGY,ENERGY,808,"> Have you tried with Python 3.11 yet?. update, I've built python 3.11 rc and numpy from source (first time ever). I did have to use the most recent v2.10.0 pb11. By turning off some diis (see below), I can get the variant on test tu1 to run through 6 SCF iterations (not to convergence) before segfaulting. major things still to investigate -- installing scipy, what lapack libraries for numpy is pip hiding from me, are the timer files closing cleanly when it throws the install-scipy-or-disable-accelerator message. and, of course, all this is on master, not the 1.3.2 of interest to you. . ```; memory 600 mb. molecule h2o {; O ; H 1 0.96; H 1 0.96 2 104.5; }. set basis cc-pVDZ; set scf scf_initial_accelerator none; set diis off; energy('scf'). compare_values(-76.0266327341067125, variable('SCF TOTAL ENERGY'), 6, 'SCF energy') #TEST; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2656#issuecomment-1235824357
https://github.com/psi4/psi4/issues/2656#issuecomment-1235824357:826,Energy Efficiency,energy,energy,826,"> Have you tried with Python 3.11 yet?. update, I've built python 3.11 rc and numpy from source (first time ever). I did have to use the most recent v2.10.0 pb11. By turning off some diis (see below), I can get the variant on test tu1 to run through 6 SCF iterations (not to convergence) before segfaulting. major things still to investigate -- installing scipy, what lapack libraries for numpy is pip hiding from me, are the timer files closing cleanly when it throws the install-scipy-or-disable-accelerator message. and, of course, all this is on master, not the 1.3.2 of interest to you. . ```; memory 600 mb. molecule h2o {; O ; H 1 0.96; H 1 0.96 2 104.5; }. set basis cc-pVDZ; set scf scf_initial_accelerator none; set diis off; energy('scf'). compare_values(-76.0266327341067125, variable('SCF TOTAL ENERGY'), 6, 'SCF energy') #TEST; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2656#issuecomment-1235824357
https://github.com/psi4/psi4/issues/2656#issuecomment-1235824357:510,Integrability,message,message,510,"> Have you tried with Python 3.11 yet?. update, I've built python 3.11 rc and numpy from source (first time ever). I did have to use the most recent v2.10.0 pb11. By turning off some diis (see below), I can get the variant on test tu1 to run through 6 SCF iterations (not to convergence) before segfaulting. major things still to investigate -- installing scipy, what lapack libraries for numpy is pip hiding from me, are the timer files closing cleanly when it throws the install-scipy-or-disable-accelerator message. and, of course, all this is on master, not the 1.3.2 of interest to you. . ```; memory 600 mb. molecule h2o {; O ; H 1 0.96; H 1 0.96 2 104.5; }. set basis cc-pVDZ; set scf scf_initial_accelerator none; set diis off; energy('scf'). compare_values(-76.0266327341067125, variable('SCF TOTAL ENERGY'), 6, 'SCF energy') #TEST; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2656#issuecomment-1235824357
https://github.com/psi4/psi4/issues/2656#issuecomment-1235824357:788,Modifiability,variab,variable,788,"> Have you tried with Python 3.11 yet?. update, I've built python 3.11 rc and numpy from source (first time ever). I did have to use the most recent v2.10.0 pb11. By turning off some diis (see below), I can get the variant on test tu1 to run through 6 SCF iterations (not to convergence) before segfaulting. major things still to investigate -- installing scipy, what lapack libraries for numpy is pip hiding from me, are the timer files closing cleanly when it throws the install-scipy-or-disable-accelerator message. and, of course, all this is on master, not the 1.3.2 of interest to you. . ```; memory 600 mb. molecule h2o {; O ; H 1 0.96; H 1 0.96 2 104.5; }. set basis cc-pVDZ; set scf scf_initial_accelerator none; set diis off; energy('scf'). compare_values(-76.0266327341067125, variable('SCF TOTAL ENERGY'), 6, 'SCF energy') #TEST; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2656#issuecomment-1235824357
https://github.com/psi4/psi4/issues/2656#issuecomment-1235824357:226,Testability,test,test,226,"> Have you tried with Python 3.11 yet?. update, I've built python 3.11 rc and numpy from source (first time ever). I did have to use the most recent v2.10.0 pb11. By turning off some diis (see below), I can get the variant on test tu1 to run through 6 SCF iterations (not to convergence) before segfaulting. major things still to investigate -- installing scipy, what lapack libraries for numpy is pip hiding from me, are the timer files closing cleanly when it throws the install-scipy-or-disable-accelerator message. and, of course, all this is on master, not the 1.3.2 of interest to you. . ```; memory 600 mb. molecule h2o {; O ; H 1 0.96; H 1 0.96 2 104.5; }. set basis cc-pVDZ; set scf scf_initial_accelerator none; set diis off; energy('scf'). compare_values(-76.0266327341067125, variable('SCF TOTAL ENERGY'), 6, 'SCF energy') #TEST; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2656#issuecomment-1235824357
https://github.com/psi4/psi4/issues/2656#issuecomment-1235824357:836,Testability,TEST,TEST,836,"> Have you tried with Python 3.11 yet?. update, I've built python 3.11 rc and numpy from source (first time ever). I did have to use the most recent v2.10.0 pb11. By turning off some diis (see below), I can get the variant on test tu1 to run through 6 SCF iterations (not to convergence) before segfaulting. major things still to investigate -- installing scipy, what lapack libraries for numpy is pip hiding from me, are the timer files closing cleanly when it throws the install-scipy-or-disable-accelerator message. and, of course, all this is on master, not the 1.3.2 of interest to you. . ```; memory 600 mb. molecule h2o {; O ; H 1 0.96; H 1 0.96 2 104.5; }. set basis cc-pVDZ; set scf scf_initial_accelerator none; set diis off; energy('scf'). compare_values(-76.0266327341067125, variable('SCF TOTAL ENERGY'), 6, 'SCF energy') #TEST; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2656#issuecomment-1235824357
https://github.com/psi4/psi4/issues/2656#issuecomment-1299103719:558,Availability,error,error,558,"ok, I have built psi4 v1.3.2 with python v3.11 from conda-forge. I had to make one src modification to get it to compile:. ```; (py311cf_L1) psilocaluser@bash:psinet:/psi/gits/hrw-v132/objdir_py311cf_L1: (1.3.x) git diff; diff --git a/psi4/src/create_new_plugin.cc b/psi4/src/create_new_plugin.cc; index 3734a7b..6f2bde2 100644; --- a/psi4/src/create_new_plugin.cc; +++ b/psi4/src/create_new_plugin.cc; @@ -32,6 +32,7 @@; #include <regex>; #include <sstream>; #include <string>; +#include <iterator>; ; #include ""psi4/psi4-dec.h"". ```. After that, I get the error, just like you reported: `ImportError: cannot import name 'core' from partially initialized module 'psi4' (most likely due to a circular import)`. However, the suffix for the `core<stuff>.so` library is badly formed, so it's `coreNone`. When I add a symlink to a proper name, it works just fine. ```; (py311cf_L1) psilocaluser@bash:psinet:/psi/gits/hrw-v132/objdir_py311cf_L1: (1.3.x) ll stage/lib/psi4/; total 25704; lrwxrwxrwx. 1 psilocaluser psilocaluser 8 Nov 1 15:57 core.cpython-311-x86_64-linux-gnu.so -> coreNone; -rwxr-xr-x. 1 psilocaluser psilocaluser 26286096 Nov 1 16:14 coreNone; drwxr-xr-x. 7 psilocaluser psilocaluser 4096 Nov 1 15:58 driver; -rw-r--r--. 1 psilocaluser psilocaluser 5898 Nov 1 15:08 extras.py; -rw-r--r--. 1 psilocaluser psilocaluser 2934 Nov 1 14:50 header.py; -rw-r--r--. 1 psilocaluser psilocaluser 3693 Nov 1 15:08 __init__.py; -rw-r--r--. 1 psilocaluser psilocaluser 1144 Nov 1 16:14 metadata.py; drwxrwxr-x. 2 psilocaluser psilocaluser 4096 Nov 1 16:14 __pycache__; drwxrwxr-x. 2 psilocaluser psilocaluser 4096 Nov 1 15:20 tests; ```; ```; (py311cf_L1) psilocaluser@bash:psinet:/psi/gits/hrw-v132/objdir_py311cf_L1: (1.3.x) stage/bin/psi4 ../tests/tu1-h2o-energy/input.dat ; 	SCF energy........................................................PASSED; ```. Full conda env is this:. ```; (py311cf_L1) psilocaluser@bash:psinet:/psi/gits/hrw-v132/objdir_py311cf_L1: (1.3.x) conda list; # packages in envi",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2656#issuecomment-1299103719
https://github.com/psi4/psi4/issues/2656#issuecomment-1299103719:5372,Deployability,patch,patch,5372,"rge; libnghttp2 1.47.0 hff17c54_1 conda-forge; libnsl 2.0.0 h7f98852_0 conda-forge; libsanitizer 12.2.0 h46fd767_19 conda-forge; libsqlite 3.39.4 h753d276_0 conda-forge; libssh2 1.10.0 hf14f497_3 conda-forge; libstdcxx-devel_linux-64 12.2.0 h3b97bd3_19 conda-forge; libstdcxx-ng 12.2.0 h46fd767_19 conda-forge; libuuid 2.32.1 h7f98852_1000 conda-forge; libuv 1.44.2 h166bdaf_0 conda-forge; libzlib 1.2.13 h166bdaf_4 conda-forge; llvm-openmp 14.0.4 he0ac6c6_0 conda-forge; mkl 2022.1.0 h84fe81f_915 conda-forge; mkl-devel 2022.1.0 ha770c72_916 conda-forge; mkl-include 2022.1.0 h84fe81f_915 conda-forge; ncurses 6.3 h27087fc_1 conda-forge; numpy 1.23.4 pypi_0 pypi; openssl 3.0.7 h166bdaf_0 conda-forge; ordered-set 4.1.0 pyhd8ed1ab_0 conda-forge; pint 0.20.1 pyhd8ed1ab_0 conda-forge; pip 22.3 pyhd8ed1ab_0 conda-forge; pybind11 2.10.1 pypi_0 pypi; pybind11-global 2.10.1 pypi_0 pypi; pydantic 1.10.2 pypi_0 pypi; python 3.11.0 ha86cf86_0_cpython conda-forge; python_abi 3.11 2_cp311 conda-forge; readline 8.1.2 h0f457ee_0 conda-forge; rhash 1.4.3 h166bdaf_0 conda-forge; setuptools 65.5.0 pyhd8ed1ab_0 conda-forge; sysroot_linux-64 2.12 he073ed8_15 conda-forge; tbb 2021.6.0 h924138e_1 conda-forge; tk 8.6.12 h27826a3_0 conda-forge; typing-extensions 4.4.0 hd8ed1ab_0 conda-forge; typing_extensions 4.4.0 pyha770c72_0 conda-forge; tzdata 2022f h191b570_0 conda-forge; wheel 0.37.1 pyhd8ed1ab_0 conda-forge; xz 5.2.6 h166bdaf_0 conda-forge; zlib 1.2.13 h166bdaf_4 conda-forge; zstd 1.5.2 h6239696_4 conda-forge; ```. Could it be this library file name issue you were hitting in Fedora?. Note that I let the environment use latest pint (v0.20.1) and internal build qcelemental (v0.4.0). In that combination, certain tests like `tu4-h2o-freq/input.dat` will give `AttributeError: module 'pint' has no attribute 'quantity'`. That's a pretty easy patch to qcel (I just minted it in v0.25.1) or you can constrain pint<0.20 . If you hit this, lmk what your constraints are, and I can suggest a combination.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2656#issuecomment-1299103719
https://github.com/psi4/psi4/issues/2656#issuecomment-1299103719:1758,Energy Efficiency,energy,energy,1758,"ibrary is badly formed, so it's `coreNone`. When I add a symlink to a proper name, it works just fine. ```; (py311cf_L1) psilocaluser@bash:psinet:/psi/gits/hrw-v132/objdir_py311cf_L1: (1.3.x) ll stage/lib/psi4/; total 25704; lrwxrwxrwx. 1 psilocaluser psilocaluser 8 Nov 1 15:57 core.cpython-311-x86_64-linux-gnu.so -> coreNone; -rwxr-xr-x. 1 psilocaluser psilocaluser 26286096 Nov 1 16:14 coreNone; drwxr-xr-x. 7 psilocaluser psilocaluser 4096 Nov 1 15:58 driver; -rw-r--r--. 1 psilocaluser psilocaluser 5898 Nov 1 15:08 extras.py; -rw-r--r--. 1 psilocaluser psilocaluser 2934 Nov 1 14:50 header.py; -rw-r--r--. 1 psilocaluser psilocaluser 3693 Nov 1 15:08 __init__.py; -rw-r--r--. 1 psilocaluser psilocaluser 1144 Nov 1 16:14 metadata.py; drwxrwxr-x. 2 psilocaluser psilocaluser 4096 Nov 1 16:14 __pycache__; drwxrwxr-x. 2 psilocaluser psilocaluser 4096 Nov 1 15:20 tests; ```; ```; (py311cf_L1) psilocaluser@bash:psinet:/psi/gits/hrw-v132/objdir_py311cf_L1: (1.3.x) stage/bin/psi4 ../tests/tu1-h2o-energy/input.dat ; 	SCF energy........................................................PASSED; ```. Full conda env is this:. ```; (py311cf_L1) psilocaluser@bash:psinet:/psi/gits/hrw-v132/objdir_py311cf_L1: (1.3.x) conda list; # packages in environment at /psi/toolchainconda/envs/py311cf_L1:; #; # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 2_kmp_llvm conda-forge; binutils_impl_linux-64 2.39 h6ceecb4_0 conda-forge; binutils_linux-64 2.39 h5fc0e48_11 conda-forge; blas 2.116 mkl conda-forge; blas-devel 3.9.0 16_linux64_mkl conda-forge; bzip2 1.0.8 h7f98852_4 conda-forge; c-ares 1.18.1 h7f98852_0 conda-forge; ca-certificates 2022.9.24 ha878542_0 conda-forge; cmake 3.24.2 h5432695_0 conda-forge; deepdiff 6.2.1 pyhd8ed1ab_0 conda-forge; expat 2.5.0 h27087fc_0 conda-forge; gcc_impl_linux-64 12.2.0 hcc96c02_19 conda-forge; gcc_linux-64 12.2.0 h4798a0e_11 conda-forge; gxx_impl_linux-64 12.2.0 hcc96c02_19 conda-forge; gxx_linux-64 12.2.0 hb41e900_11 c",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2656#issuecomment-1299103719
https://github.com/psi4/psi4/issues/2656#issuecomment-1299103719:1782,Energy Efficiency,energy,energy,1782," so it's `coreNone`. When I add a symlink to a proper name, it works just fine. ```; (py311cf_L1) psilocaluser@bash:psinet:/psi/gits/hrw-v132/objdir_py311cf_L1: (1.3.x) ll stage/lib/psi4/; total 25704; lrwxrwxrwx. 1 psilocaluser psilocaluser 8 Nov 1 15:57 core.cpython-311-x86_64-linux-gnu.so -> coreNone; -rwxr-xr-x. 1 psilocaluser psilocaluser 26286096 Nov 1 16:14 coreNone; drwxr-xr-x. 7 psilocaluser psilocaluser 4096 Nov 1 15:58 driver; -rw-r--r--. 1 psilocaluser psilocaluser 5898 Nov 1 15:08 extras.py; -rw-r--r--. 1 psilocaluser psilocaluser 2934 Nov 1 14:50 header.py; -rw-r--r--. 1 psilocaluser psilocaluser 3693 Nov 1 15:08 __init__.py; -rw-r--r--. 1 psilocaluser psilocaluser 1144 Nov 1 16:14 metadata.py; drwxrwxr-x. 2 psilocaluser psilocaluser 4096 Nov 1 16:14 __pycache__; drwxrwxr-x. 2 psilocaluser psilocaluser 4096 Nov 1 15:20 tests; ```; ```; (py311cf_L1) psilocaluser@bash:psinet:/psi/gits/hrw-v132/objdir_py311cf_L1: (1.3.x) stage/bin/psi4 ../tests/tu1-h2o-energy/input.dat ; 	SCF energy........................................................PASSED; ```. Full conda env is this:. ```; (py311cf_L1) psilocaluser@bash:psinet:/psi/gits/hrw-v132/objdir_py311cf_L1: (1.3.x) conda list; # packages in environment at /psi/toolchainconda/envs/py311cf_L1:; #; # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 2_kmp_llvm conda-forge; binutils_impl_linux-64 2.39 h6ceecb4_0 conda-forge; binutils_linux-64 2.39 h5fc0e48_11 conda-forge; blas 2.116 mkl conda-forge; blas-devel 3.9.0 16_linux64_mkl conda-forge; bzip2 1.0.8 h7f98852_4 conda-forge; c-ares 1.18.1 h7f98852_0 conda-forge; ca-certificates 2022.9.24 ha878542_0 conda-forge; cmake 3.24.2 h5432695_0 conda-forge; deepdiff 6.2.1 pyhd8ed1ab_0 conda-forge; expat 2.5.0 h27087fc_0 conda-forge; gcc_impl_linux-64 12.2.0 hcc96c02_19 conda-forge; gcc_linux-64 12.2.0 h4798a0e_11 conda-forge; gxx_impl_linux-64 12.2.0 hcc96c02_19 conda-forge; gxx_linux-64 12.2.0 hb41e900_11 conda-forge; kernel-head",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2656#issuecomment-1299103719
https://github.com/psi4/psi4/issues/2656#issuecomment-1299103719:2418,Security,certificate,certificates,2418,08 __init__.py; -rw-r--r--. 1 psilocaluser psilocaluser 1144 Nov 1 16:14 metadata.py; drwxrwxr-x. 2 psilocaluser psilocaluser 4096 Nov 1 16:14 __pycache__; drwxrwxr-x. 2 psilocaluser psilocaluser 4096 Nov 1 15:20 tests; ```; ```; (py311cf_L1) psilocaluser@bash:psinet:/psi/gits/hrw-v132/objdir_py311cf_L1: (1.3.x) stage/bin/psi4 ../tests/tu1-h2o-energy/input.dat ; 	SCF energy........................................................PASSED; ```. Full conda env is this:. ```; (py311cf_L1) psilocaluser@bash:psinet:/psi/gits/hrw-v132/objdir_py311cf_L1: (1.3.x) conda list; # packages in environment at /psi/toolchainconda/envs/py311cf_L1:; #; # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 2_kmp_llvm conda-forge; binutils_impl_linux-64 2.39 h6ceecb4_0 conda-forge; binutils_linux-64 2.39 h5fc0e48_11 conda-forge; blas 2.116 mkl conda-forge; blas-devel 3.9.0 16_linux64_mkl conda-forge; bzip2 1.0.8 h7f98852_4 conda-forge; c-ares 1.18.1 h7f98852_0 conda-forge; ca-certificates 2022.9.24 ha878542_0 conda-forge; cmake 3.24.2 h5432695_0 conda-forge; deepdiff 6.2.1 pyhd8ed1ab_0 conda-forge; expat 2.5.0 h27087fc_0 conda-forge; gcc_impl_linux-64 12.2.0 hcc96c02_19 conda-forge; gcc_linux-64 12.2.0 h4798a0e_11 conda-forge; gxx_impl_linux-64 12.2.0 hcc96c02_19 conda-forge; gxx_linux-64 12.2.0 hb41e900_11 conda-forge; kernel-headers_linux-64 2.6.32 he073ed8_15 conda-forge; keyutils 1.6.1 h166bdaf_0 conda-forge; krb5 1.19.3 h08a2579_0 conda-forge; ld_impl_linux-64 2.39 hc81fddc_0 conda-forge; libblas 3.9.0 16_linux64_mkl conda-forge; libcblas 3.9.0 16_linux64_mkl conda-forge; libcurl 7.86.0 h2283fc2_0 conda-forge; libedit 3.1.20191231 he28a2e2_2 conda-forge; libev 4.33 h516909a_1 conda-forge; libffi 3.4.2 h7f98852_5 conda-forge; libgcc-devel_linux-64 12.2.0 h3b97bd3_19 conda-forge; libgcc-ng 12.2.0 h65d4601_19 conda-forge; libgfortran-ng 12.2.0 h69a702a_19 conda-forge; libgfortran5 12.2.0 h337968e_19 conda-forge; libgomp 12.2.0 h65d4601_19 conda-forge,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2656#issuecomment-1299103719
https://github.com/psi4/psi4/issues/2656#issuecomment-1299103719:1625,Testability,test,tests,1625,"lized module 'psi4' (most likely due to a circular import)`. However, the suffix for the `core<stuff>.so` library is badly formed, so it's `coreNone`. When I add a symlink to a proper name, it works just fine. ```; (py311cf_L1) psilocaluser@bash:psinet:/psi/gits/hrw-v132/objdir_py311cf_L1: (1.3.x) ll stage/lib/psi4/; total 25704; lrwxrwxrwx. 1 psilocaluser psilocaluser 8 Nov 1 15:57 core.cpython-311-x86_64-linux-gnu.so -> coreNone; -rwxr-xr-x. 1 psilocaluser psilocaluser 26286096 Nov 1 16:14 coreNone; drwxr-xr-x. 7 psilocaluser psilocaluser 4096 Nov 1 15:58 driver; -rw-r--r--. 1 psilocaluser psilocaluser 5898 Nov 1 15:08 extras.py; -rw-r--r--. 1 psilocaluser psilocaluser 2934 Nov 1 14:50 header.py; -rw-r--r--. 1 psilocaluser psilocaluser 3693 Nov 1 15:08 __init__.py; -rw-r--r--. 1 psilocaluser psilocaluser 1144 Nov 1 16:14 metadata.py; drwxrwxr-x. 2 psilocaluser psilocaluser 4096 Nov 1 16:14 __pycache__; drwxrwxr-x. 2 psilocaluser psilocaluser 4096 Nov 1 15:20 tests; ```; ```; (py311cf_L1) psilocaluser@bash:psinet:/psi/gits/hrw-v132/objdir_py311cf_L1: (1.3.x) stage/bin/psi4 ../tests/tu1-h2o-energy/input.dat ; 	SCF energy........................................................PASSED; ```. Full conda env is this:. ```; (py311cf_L1) psilocaluser@bash:psinet:/psi/gits/hrw-v132/objdir_py311cf_L1: (1.3.x) conda list; # packages in environment at /psi/toolchainconda/envs/py311cf_L1:; #; # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 2_kmp_llvm conda-forge; binutils_impl_linux-64 2.39 h6ceecb4_0 conda-forge; binutils_linux-64 2.39 h5fc0e48_11 conda-forge; blas 2.116 mkl conda-forge; blas-devel 3.9.0 16_linux64_mkl conda-forge; bzip2 1.0.8 h7f98852_4 conda-forge; c-ares 1.18.1 h7f98852_0 conda-forge; ca-certificates 2022.9.24 ha878542_0 conda-forge; cmake 3.24.2 h5432695_0 conda-forge; deepdiff 6.2.1 pyhd8ed1ab_0 conda-forge; expat 2.5.0 h27087fc_0 conda-forge; gcc_impl_linux-64 12.2.0 hcc96c02_19 conda-forge; gcc_linux-64 12.2.0 h",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2656#issuecomment-1299103719
https://github.com/psi4/psi4/issues/2656#issuecomment-1299103719:1744,Testability,test,tests,1744,"ibrary is badly formed, so it's `coreNone`. When I add a symlink to a proper name, it works just fine. ```; (py311cf_L1) psilocaluser@bash:psinet:/psi/gits/hrw-v132/objdir_py311cf_L1: (1.3.x) ll stage/lib/psi4/; total 25704; lrwxrwxrwx. 1 psilocaluser psilocaluser 8 Nov 1 15:57 core.cpython-311-x86_64-linux-gnu.so -> coreNone; -rwxr-xr-x. 1 psilocaluser psilocaluser 26286096 Nov 1 16:14 coreNone; drwxr-xr-x. 7 psilocaluser psilocaluser 4096 Nov 1 15:58 driver; -rw-r--r--. 1 psilocaluser psilocaluser 5898 Nov 1 15:08 extras.py; -rw-r--r--. 1 psilocaluser psilocaluser 2934 Nov 1 14:50 header.py; -rw-r--r--. 1 psilocaluser psilocaluser 3693 Nov 1 15:08 __init__.py; -rw-r--r--. 1 psilocaluser psilocaluser 1144 Nov 1 16:14 metadata.py; drwxrwxr-x. 2 psilocaluser psilocaluser 4096 Nov 1 16:14 __pycache__; drwxrwxr-x. 2 psilocaluser psilocaluser 4096 Nov 1 15:20 tests; ```; ```; (py311cf_L1) psilocaluser@bash:psinet:/psi/gits/hrw-v132/objdir_py311cf_L1: (1.3.x) stage/bin/psi4 ../tests/tu1-h2o-energy/input.dat ; 	SCF energy........................................................PASSED; ```. Full conda env is this:. ```; (py311cf_L1) psilocaluser@bash:psinet:/psi/gits/hrw-v132/objdir_py311cf_L1: (1.3.x) conda list; # packages in environment at /psi/toolchainconda/envs/py311cf_L1:; #; # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 2_kmp_llvm conda-forge; binutils_impl_linux-64 2.39 h6ceecb4_0 conda-forge; binutils_linux-64 2.39 h5fc0e48_11 conda-forge; blas 2.116 mkl conda-forge; blas-devel 3.9.0 16_linux64_mkl conda-forge; bzip2 1.0.8 h7f98852_4 conda-forge; c-ares 1.18.1 h7f98852_0 conda-forge; ca-certificates 2022.9.24 ha878542_0 conda-forge; cmake 3.24.2 h5432695_0 conda-forge; deepdiff 6.2.1 pyhd8ed1ab_0 conda-forge; expat 2.5.0 h27087fc_0 conda-forge; gcc_impl_linux-64 12.2.0 hcc96c02_19 conda-forge; gcc_linux-64 12.2.0 h4798a0e_11 conda-forge; gxx_impl_linux-64 12.2.0 hcc96c02_19 conda-forge; gxx_linux-64 12.2.0 hb41e900_11 c",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2656#issuecomment-1299103719
https://github.com/psi4/psi4/issues/2656#issuecomment-1299103719:5244,Testability,test,tests,5244,"rge; libnghttp2 1.47.0 hff17c54_1 conda-forge; libnsl 2.0.0 h7f98852_0 conda-forge; libsanitizer 12.2.0 h46fd767_19 conda-forge; libsqlite 3.39.4 h753d276_0 conda-forge; libssh2 1.10.0 hf14f497_3 conda-forge; libstdcxx-devel_linux-64 12.2.0 h3b97bd3_19 conda-forge; libstdcxx-ng 12.2.0 h46fd767_19 conda-forge; libuuid 2.32.1 h7f98852_1000 conda-forge; libuv 1.44.2 h166bdaf_0 conda-forge; libzlib 1.2.13 h166bdaf_4 conda-forge; llvm-openmp 14.0.4 he0ac6c6_0 conda-forge; mkl 2022.1.0 h84fe81f_915 conda-forge; mkl-devel 2022.1.0 ha770c72_916 conda-forge; mkl-include 2022.1.0 h84fe81f_915 conda-forge; ncurses 6.3 h27087fc_1 conda-forge; numpy 1.23.4 pypi_0 pypi; openssl 3.0.7 h166bdaf_0 conda-forge; ordered-set 4.1.0 pyhd8ed1ab_0 conda-forge; pint 0.20.1 pyhd8ed1ab_0 conda-forge; pip 22.3 pyhd8ed1ab_0 conda-forge; pybind11 2.10.1 pypi_0 pypi; pybind11-global 2.10.1 pypi_0 pypi; pydantic 1.10.2 pypi_0 pypi; python 3.11.0 ha86cf86_0_cpython conda-forge; python_abi 3.11 2_cp311 conda-forge; readline 8.1.2 h0f457ee_0 conda-forge; rhash 1.4.3 h166bdaf_0 conda-forge; setuptools 65.5.0 pyhd8ed1ab_0 conda-forge; sysroot_linux-64 2.12 he073ed8_15 conda-forge; tbb 2021.6.0 h924138e_1 conda-forge; tk 8.6.12 h27826a3_0 conda-forge; typing-extensions 4.4.0 hd8ed1ab_0 conda-forge; typing_extensions 4.4.0 pyha770c72_0 conda-forge; tzdata 2022f h191b570_0 conda-forge; wheel 0.37.1 pyhd8ed1ab_0 conda-forge; xz 5.2.6 h166bdaf_0 conda-forge; zlib 1.2.13 h166bdaf_4 conda-forge; zstd 1.5.2 h6239696_4 conda-forge; ```. Could it be this library file name issue you were hitting in Fedora?. Note that I let the environment use latest pint (v0.20.1) and internal build qcelemental (v0.4.0). In that combination, certain tests like `tu4-h2o-freq/input.dat` will give `AttributeError: module 'pint' has no attribute 'quantity'`. That's a pretty easy patch to qcel (I just minted it in v0.25.1) or you can constrain pint<0.20 . If you hit this, lmk what your constraints are, and I can suggest a combination.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2656#issuecomment-1299103719
https://github.com/psi4/psi4/issues/2656#issuecomment-1299120848:737,Energy Efficiency,energy,energy,737,"Commenting out an extra cmake line fixes the `coreNone` to `core.so`. Basic, but works. ```; >>> (1.3.x) ll stage/lib/psi4/; total 25704; -rwxr-xr-x. 1 psilocaluser psilocaluser 26286096 Nov 1 16:43 core.so; drwxr-xr-x. 7 psilocaluser psilocaluser 4096 Nov 1 15:58 driver; -rw-r--r--. 1 psilocaluser psilocaluser 5898 Nov 1 15:08 extras.py; -rw-r--r--. 1 psilocaluser psilocaluser 2934 Nov 1 14:50 header.py; -rw-r--r--. 1 psilocaluser psilocaluser 3693 Nov 1 15:08 __init__.py; -rw-r--r--. 1 psilocaluser psilocaluser 1144 Nov 1 16:43 metadata.py; drwxrwxr-x. 2 psilocaluser psilocaluser 4096 Nov 1 16:14 __pycache__; drwxrwxr-x. 2 psilocaluser psilocaluser 4096 Nov 1 15:20 tests; ```; ```; >>> (1.3.x) stage/bin/psi4 ../tests/tu1-h2o-energy/input.dat ; 	SCF energy........................................................PASSED; ```; ```; >>> (1.3.x) git diff; diff --git a/psi4/src/CMakeLists.txt b/psi4/src/CMakeLists.txt; index da11518..b287b0d 100644; --- a/psi4/src/CMakeLists.txt; +++ b/psi4/src/CMakeLists.txt; @@ -134,6 +134,6 @@ message(STATUS ""Psi4 rpath: ${psi4_RPATH}""); set_target_properties(core PROPERTIES PREFIX ""${PYTHON_MODULE_PREFIX}"" # for python module; OUTPUT_NAME core; EXPORT_NAME core; - SUFFIX ""${PYTHON_MODULE_EXTENSION}"" # for python module; + #SUFFIX ""${PYTHON_MODULE_EXTENSION}"" # for python module; INSTALL_RPATH ""${psi4_RPATH}""; BUILD_WITH_INSTALL_RPATH ON); diff --git a/psi4/src/create_new_plugin.cc b/psi4/src/create_new_plugin.cc; index 3734a7b..6f2bde2 100644; --- a/psi4/src/create_new_plugin.cc; +++ b/psi4/src/create_new_plugin.cc; @@ -32,6 +32,7 @@; #include <regex>; #include <sstream>; #include <string>; +#include <iterator>; ; #include ""psi4/psi4-dec.h""; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2656#issuecomment-1299120848
https://github.com/psi4/psi4/issues/2656#issuecomment-1299120848:761,Energy Efficiency,energy,energy,761,"Commenting out an extra cmake line fixes the `coreNone` to `core.so`. Basic, but works. ```; >>> (1.3.x) ll stage/lib/psi4/; total 25704; -rwxr-xr-x. 1 psilocaluser psilocaluser 26286096 Nov 1 16:43 core.so; drwxr-xr-x. 7 psilocaluser psilocaluser 4096 Nov 1 15:58 driver; -rw-r--r--. 1 psilocaluser psilocaluser 5898 Nov 1 15:08 extras.py; -rw-r--r--. 1 psilocaluser psilocaluser 2934 Nov 1 14:50 header.py; -rw-r--r--. 1 psilocaluser psilocaluser 3693 Nov 1 15:08 __init__.py; -rw-r--r--. 1 psilocaluser psilocaluser 1144 Nov 1 16:43 metadata.py; drwxrwxr-x. 2 psilocaluser psilocaluser 4096 Nov 1 16:14 __pycache__; drwxrwxr-x. 2 psilocaluser psilocaluser 4096 Nov 1 15:20 tests; ```; ```; >>> (1.3.x) stage/bin/psi4 ../tests/tu1-h2o-energy/input.dat ; 	SCF energy........................................................PASSED; ```; ```; >>> (1.3.x) git diff; diff --git a/psi4/src/CMakeLists.txt b/psi4/src/CMakeLists.txt; index da11518..b287b0d 100644; --- a/psi4/src/CMakeLists.txt; +++ b/psi4/src/CMakeLists.txt; @@ -134,6 +134,6 @@ message(STATUS ""Psi4 rpath: ${psi4_RPATH}""); set_target_properties(core PROPERTIES PREFIX ""${PYTHON_MODULE_PREFIX}"" # for python module; OUTPUT_NAME core; EXPORT_NAME core; - SUFFIX ""${PYTHON_MODULE_EXTENSION}"" # for python module; + #SUFFIX ""${PYTHON_MODULE_EXTENSION}"" # for python module; INSTALL_RPATH ""${psi4_RPATH}""; BUILD_WITH_INSTALL_RPATH ON); diff --git a/psi4/src/create_new_plugin.cc b/psi4/src/create_new_plugin.cc; index 3734a7b..6f2bde2 100644; --- a/psi4/src/create_new_plugin.cc; +++ b/psi4/src/create_new_plugin.cc; @@ -32,6 +32,7 @@; #include <regex>; #include <sstream>; #include <string>; +#include <iterator>; ; #include ""psi4/psi4-dec.h""; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2656#issuecomment-1299120848
https://github.com/psi4/psi4/issues/2656#issuecomment-1299120848:1040,Integrability,message,message,1040,"Commenting out an extra cmake line fixes the `coreNone` to `core.so`. Basic, but works. ```; >>> (1.3.x) ll stage/lib/psi4/; total 25704; -rwxr-xr-x. 1 psilocaluser psilocaluser 26286096 Nov 1 16:43 core.so; drwxr-xr-x. 7 psilocaluser psilocaluser 4096 Nov 1 15:58 driver; -rw-r--r--. 1 psilocaluser psilocaluser 5898 Nov 1 15:08 extras.py; -rw-r--r--. 1 psilocaluser psilocaluser 2934 Nov 1 14:50 header.py; -rw-r--r--. 1 psilocaluser psilocaluser 3693 Nov 1 15:08 __init__.py; -rw-r--r--. 1 psilocaluser psilocaluser 1144 Nov 1 16:43 metadata.py; drwxrwxr-x. 2 psilocaluser psilocaluser 4096 Nov 1 16:14 __pycache__; drwxrwxr-x. 2 psilocaluser psilocaluser 4096 Nov 1 15:20 tests; ```; ```; >>> (1.3.x) stage/bin/psi4 ../tests/tu1-h2o-energy/input.dat ; 	SCF energy........................................................PASSED; ```; ```; >>> (1.3.x) git diff; diff --git a/psi4/src/CMakeLists.txt b/psi4/src/CMakeLists.txt; index da11518..b287b0d 100644; --- a/psi4/src/CMakeLists.txt; +++ b/psi4/src/CMakeLists.txt; @@ -134,6 +134,6 @@ message(STATUS ""Psi4 rpath: ${psi4_RPATH}""); set_target_properties(core PROPERTIES PREFIX ""${PYTHON_MODULE_PREFIX}"" # for python module; OUTPUT_NAME core; EXPORT_NAME core; - SUFFIX ""${PYTHON_MODULE_EXTENSION}"" # for python module; + #SUFFIX ""${PYTHON_MODULE_EXTENSION}"" # for python module; INSTALL_RPATH ""${psi4_RPATH}""; BUILD_WITH_INSTALL_RPATH ON); diff --git a/psi4/src/create_new_plugin.cc b/psi4/src/create_new_plugin.cc; index 3734a7b..6f2bde2 100644; --- a/psi4/src/create_new_plugin.cc; +++ b/psi4/src/create_new_plugin.cc; @@ -32,6 +32,7 @@; #include <regex>; #include <sstream>; #include <string>; +#include <iterator>; ; #include ""psi4/psi4-dec.h""; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2656#issuecomment-1299120848
https://github.com/psi4/psi4/issues/2656#issuecomment-1299120848:676,Testability,test,tests,676,"Commenting out an extra cmake line fixes the `coreNone` to `core.so`. Basic, but works. ```; >>> (1.3.x) ll stage/lib/psi4/; total 25704; -rwxr-xr-x. 1 psilocaluser psilocaluser 26286096 Nov 1 16:43 core.so; drwxr-xr-x. 7 psilocaluser psilocaluser 4096 Nov 1 15:58 driver; -rw-r--r--. 1 psilocaluser psilocaluser 5898 Nov 1 15:08 extras.py; -rw-r--r--. 1 psilocaluser psilocaluser 2934 Nov 1 14:50 header.py; -rw-r--r--. 1 psilocaluser psilocaluser 3693 Nov 1 15:08 __init__.py; -rw-r--r--. 1 psilocaluser psilocaluser 1144 Nov 1 16:43 metadata.py; drwxrwxr-x. 2 psilocaluser psilocaluser 4096 Nov 1 16:14 __pycache__; drwxrwxr-x. 2 psilocaluser psilocaluser 4096 Nov 1 15:20 tests; ```; ```; >>> (1.3.x) stage/bin/psi4 ../tests/tu1-h2o-energy/input.dat ; 	SCF energy........................................................PASSED; ```; ```; >>> (1.3.x) git diff; diff --git a/psi4/src/CMakeLists.txt b/psi4/src/CMakeLists.txt; index da11518..b287b0d 100644; --- a/psi4/src/CMakeLists.txt; +++ b/psi4/src/CMakeLists.txt; @@ -134,6 +134,6 @@ message(STATUS ""Psi4 rpath: ${psi4_RPATH}""); set_target_properties(core PROPERTIES PREFIX ""${PYTHON_MODULE_PREFIX}"" # for python module; OUTPUT_NAME core; EXPORT_NAME core; - SUFFIX ""${PYTHON_MODULE_EXTENSION}"" # for python module; + #SUFFIX ""${PYTHON_MODULE_EXTENSION}"" # for python module; INSTALL_RPATH ""${psi4_RPATH}""; BUILD_WITH_INSTALL_RPATH ON); diff --git a/psi4/src/create_new_plugin.cc b/psi4/src/create_new_plugin.cc; index 3734a7b..6f2bde2 100644; --- a/psi4/src/create_new_plugin.cc; +++ b/psi4/src/create_new_plugin.cc; @@ -32,6 +32,7 @@; #include <regex>; #include <sstream>; #include <string>; +#include <iterator>; ; #include ""psi4/psi4-dec.h""; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2656#issuecomment-1299120848
https://github.com/psi4/psi4/issues/2656#issuecomment-1299120848:723,Testability,test,tests,723,"Commenting out an extra cmake line fixes the `coreNone` to `core.so`. Basic, but works. ```; >>> (1.3.x) ll stage/lib/psi4/; total 25704; -rwxr-xr-x. 1 psilocaluser psilocaluser 26286096 Nov 1 16:43 core.so; drwxr-xr-x. 7 psilocaluser psilocaluser 4096 Nov 1 15:58 driver; -rw-r--r--. 1 psilocaluser psilocaluser 5898 Nov 1 15:08 extras.py; -rw-r--r--. 1 psilocaluser psilocaluser 2934 Nov 1 14:50 header.py; -rw-r--r--. 1 psilocaluser psilocaluser 3693 Nov 1 15:08 __init__.py; -rw-r--r--. 1 psilocaluser psilocaluser 1144 Nov 1 16:43 metadata.py; drwxrwxr-x. 2 psilocaluser psilocaluser 4096 Nov 1 16:14 __pycache__; drwxrwxr-x. 2 psilocaluser psilocaluser 4096 Nov 1 15:20 tests; ```; ```; >>> (1.3.x) stage/bin/psi4 ../tests/tu1-h2o-energy/input.dat ; 	SCF energy........................................................PASSED; ```; ```; >>> (1.3.x) git diff; diff --git a/psi4/src/CMakeLists.txt b/psi4/src/CMakeLists.txt; index da11518..b287b0d 100644; --- a/psi4/src/CMakeLists.txt; +++ b/psi4/src/CMakeLists.txt; @@ -134,6 +134,6 @@ message(STATUS ""Psi4 rpath: ${psi4_RPATH}""); set_target_properties(core PROPERTIES PREFIX ""${PYTHON_MODULE_PREFIX}"" # for python module; OUTPUT_NAME core; EXPORT_NAME core; - SUFFIX ""${PYTHON_MODULE_EXTENSION}"" # for python module; + #SUFFIX ""${PYTHON_MODULE_EXTENSION}"" # for python module; INSTALL_RPATH ""${psi4_RPATH}""; BUILD_WITH_INSTALL_RPATH ON); diff --git a/psi4/src/create_new_plugin.cc b/psi4/src/create_new_plugin.cc; index 3734a7b..6f2bde2 100644; --- a/psi4/src/create_new_plugin.cc; +++ b/psi4/src/create_new_plugin.cc; @@ -32,6 +32,7 @@; #include <regex>; #include <sstream>; #include <string>; +#include <iterator>; ; #include ""psi4/psi4-dec.h""; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2656#issuecomment-1299120848
https://github.com/psi4/psi4/issues/2656#issuecomment-1300242009:69,Deployability,patch,patched,69,Thank you!! That fixed it. The `<iterator>` modification was already patched in in June.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2656#issuecomment-1300242009
https://github.com/psi4/psi4/issues/2656#issuecomment-1407774402:120,Deployability,patch,patches,120,"For reference, Debian fixed this slightly differently: https://salsa.debian.org/debichem-team/psi4/-/blob/master/debian/patches/cmake_pymodulesuffix.patch. ```; --- a/cmake/FindPythonLibsNew.cmake; +++ b/cmake/FindPythonLibsNew.cmake; @@ -78,7 +78,7 @@; print(sys.prefix);; print(s.get_python_inc(plat_specific=True));; print(s.get_python_lib(plat_specific=True));; -print(s.get_config_var('SO'));; +print(s.get_config_var('SO') or s.get_config_var('EXT_SUFFIX'));; print(hasattr(sys, 'gettotalrefcount')+0);; print(struct.calcsize('@P'));; print(s.get_config_var('LDVERSION') or s.get_config_var('VERSION'));; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2656#issuecomment-1407774402
https://github.com/psi4/psi4/issues/2656#issuecomment-1407774402:149,Deployability,patch,patch,149,"For reference, Debian fixed this slightly differently: https://salsa.debian.org/debichem-team/psi4/-/blob/master/debian/patches/cmake_pymodulesuffix.patch. ```; --- a/cmake/FindPythonLibsNew.cmake; +++ b/cmake/FindPythonLibsNew.cmake; @@ -78,7 +78,7 @@; print(sys.prefix);; print(s.get_python_inc(plat_specific=True));; print(s.get_python_lib(plat_specific=True));; -print(s.get_config_var('SO'));; +print(s.get_config_var('SO') or s.get_config_var('EXT_SUFFIX'));; print(hasattr(sys, 'gettotalrefcount')+0);; print(struct.calcsize('@P'));; print(s.get_config_var('LDVERSION') or s.get_config_var('VERSION'));; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2656#issuecomment-1407774402
https://github.com/psi4/psi4/pull/2659#issuecomment-1208156516:75,Modifiability,variab,variable,75,"Just to give some context for this PR, I'm removing an unused class member variable and constructor argument. Aside from a simpler constructor, there is no behavior change.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2659#issuecomment-1208156516
https://github.com/psi4/psi4/pull/2659#issuecomment-1208156516:123,Usability,simpl,simpler,123,"Just to give some context for this PR, I'm removing an unused class member variable and constructor argument. Aside from a simpler constructor, there is no behavior change.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2659#issuecomment-1208156516
https://github.com/psi4/psi4/issues/2661#issuecomment-1207143526:118,Deployability,install,install,118,"Thanks for the report. I have been warned about a numpy version issue on Mac. If you haven't already, do try a `conda install numpy=1.22` in your environment and try Psi4 again. I'd have to rebuild the Psiv 1.6.1 packages or rewrite their metadata to fix this at `conda create -n p4env psi4 -c psi4` -time. Hopefully, SciPy and Numpy will have reconciled before I get around to that.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2661#issuecomment-1207143526
https://github.com/psi4/psi4/issues/2661#issuecomment-1207143526:225,Modifiability,rewrite,rewrite,225,"Thanks for the report. I have been warned about a numpy version issue on Mac. If you haven't already, do try a `conda install numpy=1.22` in your environment and try Psi4 again. I'd have to rebuild the Psiv 1.6.1 packages or rewrite their metadata to fix this at `conda create -n p4env psi4 -c psi4` -time. Hopefully, SciPy and Numpy will have reconciled before I get around to that.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2661#issuecomment-1207143526
https://github.com/psi4/psi4/pull/2665#issuecomment-1208366769:107,Modifiability,refactor,refactoring,107,"Immediate questions:; @davpoolechem - Is JK stable enough for this PR, or do you need a hold on this while refactoring?; @jturney - Does this sound more like a new library of its own, or something that belongs in `libmints`?; @andyj10224 - Can you comment on what the difference is between `libffm` and `fmm tree`?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2665#issuecomment-1208366769
https://github.com/psi4/psi4/pull/2665#issuecomment-1208368845:108,Modifiability,refactor,refactoring,108,"> Immediate questions: @davpoolechem - Is JK stable enough for this PR, or do you need a hold on this while refactoring? @jturney - Does this sound more like a new library of its own, or something that belongs in `libmints`? @andyj10224 - Can you comment on what the difference is between `libffm` and `fmm tree`?. CFMM requires two parts: Multipole operations, as well as an octree structure.; FMMTree implements the octree structure needed for CFMM, and there is a lot of code there, so I am splitting this into three parts to aid the review process and to avoid too large a PR. The `FMMTree` class will be in `libfmm` as well. For the record, this PR will not affect `libfock` or any `JK` classes. That will happen in Part 3 (when JK is more stable)",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2665#issuecomment-1208368845
https://github.com/psi4/psi4/pull/2665#issuecomment-1208368845:559,Safety,avoid,avoid,559,"> Immediate questions: @davpoolechem - Is JK stable enough for this PR, or do you need a hold on this while refactoring? @jturney - Does this sound more like a new library of its own, or something that belongs in `libmints`? @andyj10224 - Can you comment on what the difference is between `libffm` and `fmm tree`?. CFMM requires two parts: Multipole operations, as well as an octree structure.; FMMTree implements the octree structure needed for CFMM, and there is a lot of code there, so I am splitting this into three parts to aid the review process and to avoid too large a PR. The `FMMTree` class will be in `libfmm` as well. For the record, this PR will not affect `libfock` or any `JK` classes. That will happen in Part 3 (when JK is more stable)",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2665#issuecomment-1208368845
https://github.com/psi4/psi4/pull/2665#issuecomment-1208484833:199,Security,access,accessible,199,"Per the last Psi4 call, I'd like to challenge you to think about how much of libcfmm could be factored out of Psi4. Many other codes might be interested in this functionality, too, if it can be made accessible through a simple API.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2665#issuecomment-1208484833
https://github.com/psi4/psi4/pull/2665#issuecomment-1208484833:220,Usability,simpl,simple,220,"Per the last Psi4 call, I'd like to challenge you to think about how much of libcfmm could be factored out of Psi4. Many other codes might be interested in this functionality, too, if it can be made accessible through a simple API.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2665#issuecomment-1208484833
https://github.com/psi4/psi4/pull/2665#issuecomment-1208511310:201,Security,access,accessible,201,"> Per the last Psi4 call, I'd like to challenge you to think about how much of libcfmm could be factored out of Psi4. Many other codes might be interested in this functionality, too, if it can be made accessible through a simple API. I like your idea, but I think that is something to think about in the future because the rest of `libfmm` is currently entangled with Psi functionalities (like `IntegralFactory`).",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2665#issuecomment-1208511310
https://github.com/psi4/psi4/pull/2665#issuecomment-1208511310:222,Usability,simpl,simple,222,"> Per the last Psi4 call, I'd like to challenge you to think about how much of libcfmm could be factored out of Psi4. Many other codes might be interested in this functionality, too, if it can be made accessible through a simple API. I like your idea, but I think that is something to think about in the future because the rest of `libfmm` is currently entangled with Psi functionalities (like `IntegralFactory`).",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2665#issuecomment-1208511310
https://github.com/psi4/psi4/pull/2665#issuecomment-1209572192:434,Energy Efficiency,reduce,reduce,434,"> Iirc, @andysim said that the old libmints solidharmonics.cc code is outdated anyways, and the Helgaker recursions are better. Feel free to comment Andy. Both codes use regular solid harmonics with the exact same normalization (assuming that your Helgaker recursions match that code that I sent to you a while ago, Andy). The code in libmints is stuff that was taken from MPQC, but becomes painfully slow around L=9 or so. We had to reduce the default maximum L a while ago because it was dramatically slowing the Psi4 startup time. So I think that, if it turns out not to be a huge task, replacing the libmints code with smarter recursions is probably not a bad idea. Failing that, the Helgaker version is not really introducing any redundancy because the libmints version won't be able to support high enough a.m. efficiently.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2665#issuecomment-1209572192
https://github.com/psi4/psi4/pull/2665#issuecomment-1209572192:817,Energy Efficiency,efficient,efficiently,817,"> Iirc, @andysim said that the old libmints solidharmonics.cc code is outdated anyways, and the Helgaker recursions are better. Feel free to comment Andy. Both codes use regular solid harmonics with the exact same normalization (assuming that your Helgaker recursions match that code that I sent to you a while ago, Andy). The code in libmints is stuff that was taken from MPQC, but becomes painfully slow around L=9 or so. We had to reduce the default maximum L a while ago because it was dramatically slowing the Psi4 startup time. So I think that, if it turns out not to be a huge task, replacing the libmints code with smarter recursions is probably not a bad idea. Failing that, the Helgaker version is not really introducing any redundancy because the libmints version won't be able to support high enough a.m. efficiently.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2665#issuecomment-1209572192
https://github.com/psi4/psi4/pull/2665#issuecomment-1209572192:735,Safety,redund,redundancy,735,"> Iirc, @andysim said that the old libmints solidharmonics.cc code is outdated anyways, and the Helgaker recursions are better. Feel free to comment Andy. Both codes use regular solid harmonics with the exact same normalization (assuming that your Helgaker recursions match that code that I sent to you a while ago, Andy). The code in libmints is stuff that was taken from MPQC, but becomes painfully slow around L=9 or so. We had to reduce the default maximum L a while ago because it was dramatically slowing the Psi4 startup time. So I think that, if it turns out not to be a huge task, replacing the libmints code with smarter recursions is probably not a bad idea. Failing that, the Helgaker version is not really introducing any redundancy because the libmints version won't be able to support high enough a.m. efficiently.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2665#issuecomment-1209572192
https://github.com/psi4/psi4/pull/2665#issuecomment-1209579441:443,Energy Efficiency,reduce,reduce,443,"> > Iirc, @andysim said that the old libmints solidharmonics.cc code is outdated anyways, and the Helgaker recursions are better. Feel free to comment Andy.; > ; > Both codes use regular solid harmonics with the exact same normalization (assuming that your Helgaker recursions match that code that I sent to you a while ago, Andy). The code in libmints is stuff that was taken from MPQC, but becomes painfully slow around L=9 or so. We had to reduce the default maximum L a while ago because it was dramatically slowing the Psi4 startup time. So I think that, if it turns out not to be a huge task, replacing the libmints code with smarter recursions is probably not a bad idea. Failing that, the Helgaker version is not really introducing any redundancy because the libmints version won't be able to support high enough a.m. efficiently. Since the Helgaker code is more efficient, should I do that replacement in this PR or the next? Also, does that mean we need to just move everything in libfmm to libmints? @jturney thoughts?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2665#issuecomment-1209579441
https://github.com/psi4/psi4/pull/2665#issuecomment-1209579441:826,Energy Efficiency,efficient,efficiently,826,"> > Iirc, @andysim said that the old libmints solidharmonics.cc code is outdated anyways, and the Helgaker recursions are better. Feel free to comment Andy.; > ; > Both codes use regular solid harmonics with the exact same normalization (assuming that your Helgaker recursions match that code that I sent to you a while ago, Andy). The code in libmints is stuff that was taken from MPQC, but becomes painfully slow around L=9 or so. We had to reduce the default maximum L a while ago because it was dramatically slowing the Psi4 startup time. So I think that, if it turns out not to be a huge task, replacing the libmints code with smarter recursions is probably not a bad idea. Failing that, the Helgaker version is not really introducing any redundancy because the libmints version won't be able to support high enough a.m. efficiently. Since the Helgaker code is more efficient, should I do that replacement in this PR or the next? Also, does that mean we need to just move everything in libfmm to libmints? @jturney thoughts?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2665#issuecomment-1209579441
https://github.com/psi4/psi4/pull/2665#issuecomment-1209579441:871,Energy Efficiency,efficient,efficient,871,"> > Iirc, @andysim said that the old libmints solidharmonics.cc code is outdated anyways, and the Helgaker recursions are better. Feel free to comment Andy.; > ; > Both codes use regular solid harmonics with the exact same normalization (assuming that your Helgaker recursions match that code that I sent to you a while ago, Andy). The code in libmints is stuff that was taken from MPQC, but becomes painfully slow around L=9 or so. We had to reduce the default maximum L a while ago because it was dramatically slowing the Psi4 startup time. So I think that, if it turns out not to be a huge task, replacing the libmints code with smarter recursions is probably not a bad idea. Failing that, the Helgaker version is not really introducing any redundancy because the libmints version won't be able to support high enough a.m. efficiently. Since the Helgaker code is more efficient, should I do that replacement in this PR or the next? Also, does that mean we need to just move everything in libfmm to libmints? @jturney thoughts?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2665#issuecomment-1209579441
https://github.com/psi4/psi4/pull/2665#issuecomment-1209579441:744,Safety,redund,redundancy,744,"> > Iirc, @andysim said that the old libmints solidharmonics.cc code is outdated anyways, and the Helgaker recursions are better. Feel free to comment Andy.; > ; > Both codes use regular solid harmonics with the exact same normalization (assuming that your Helgaker recursions match that code that I sent to you a while ago, Andy). The code in libmints is stuff that was taken from MPQC, but becomes painfully slow around L=9 or so. We had to reduce the default maximum L a while ago because it was dramatically slowing the Psi4 startup time. So I think that, if it turns out not to be a huge task, replacing the libmints code with smarter recursions is probably not a bad idea. Failing that, the Helgaker version is not really introducing any redundancy because the libmints version won't be able to support high enough a.m. efficiently. Since the Helgaker code is more efficient, should I do that replacement in this PR or the next? Also, does that mean we need to just move everything in libfmm to libmints? @jturney thoughts?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2665#issuecomment-1209579441
https://github.com/psi4/psi4/pull/2665#issuecomment-1209829926:524,Modifiability,refactor,refactoring,524,"> > It appears that the current solidharmonics.cc is not used ANYWHERE in the Psi4 code.; > ; > Somehow solidharmonics.cc is getting used, because changing it changes the integral ordering (link is to the `gss` to `sss` PR: https://github.com/psi4/psi4/pull/2537/files#diff-76f4c1f378b6a48ede6c4f938378b54719f968680edca78453d9751e87cebbf9); > ; > EDIT: not necessarily a block on your plan, but that's not isolated code. Looks like I did a naive `grep -r ""solidharmonics.cc""` instead of its functions. My bad. In that case, refactoring solidharmonics.cc with my new code can serve as an effective test for my functions, but it does make it harder :)",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2665#issuecomment-1209829926
https://github.com/psi4/psi4/pull/2665#issuecomment-1209829926:597,Testability,test,test,597,"> > It appears that the current solidharmonics.cc is not used ANYWHERE in the Psi4 code.; > ; > Somehow solidharmonics.cc is getting used, because changing it changes the integral ordering (link is to the `gss` to `sss` PR: https://github.com/psi4/psi4/pull/2537/files#diff-76f4c1f378b6a48ede6c4f938378b54719f968680edca78453d9751e87cebbf9); > ; > EDIT: not necessarily a block on your plan, but that's not isolated code. Looks like I did a naive `grep -r ""solidharmonics.cc""` instead of its functions. My bad. In that case, refactoring solidharmonics.cc with my new code can serve as an effective test for my functions, but it does make it harder :)",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2665#issuecomment-1209829926
https://github.com/psi4/psi4/pull/2665#issuecomment-1209832732:40,Usability,pause,pause,40,"My vote is to either end or temporarily pause this PR and open a new PR just for swapping out the solid harmonics technology. Of course, @jturney's judgment overrides mine.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2665#issuecomment-1209832732
https://github.com/psi4/psi4/pull/2665#issuecomment-1209843989:385,Safety,avoid,avoid,385,"> My vote is to either end or temporarily pause this PR and open a new PR just for swapping out the solid harmonics technology. Of course, @jturney's judgment overrides mine. I do think we can essentially move the methods in the `HarmonicCoefficients` class to `libmints/solidharmonics.cc`. But I agree that would be 2 PRs. In that case, having a separate `libfmm` would be useful, to avoid the clutter already present in `libmints`. Of course, waiting for @jturney's judgement.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2665#issuecomment-1209843989
https://github.com/psi4/psi4/pull/2665#issuecomment-1209843989:42,Usability,pause,pause,42,"> My vote is to either end or temporarily pause this PR and open a new PR just for swapping out the solid harmonics technology. Of course, @jturney's judgment overrides mine. I do think we can essentially move the methods in the `HarmonicCoefficients` class to `libmints/solidharmonics.cc`. But I agree that would be 2 PRs. In that case, having a separate `libfmm` would be useful, to avoid the clutter already present in `libmints`. Of course, waiting for @jturney's judgement.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2665#issuecomment-1209843989
https://github.com/psi4/psi4/pull/2667#issuecomment-1209526104:515,Usability,clear,clear,515,This is a little confusing to me. It looks like basisset.cc line 240 accounts for Z = 0 but then the example array in the documentation at read_options.cc line 126 seems to have the Z = 0 in it. Or the example array could be mistyped (H-Be is just four atoms while five zeros are given). Then the example input file has the Sb atom (Z = 51) but `core_policy[50]` is used. I suspect users will be confused by this. I'm not saying whether or not including Z=0 in the array is correct but documentation should be very clear.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2667#issuecomment-1209526104
https://github.com/psi4/psi4/pull/2667#issuecomment-1209560924:344,Availability,avail,available,344,"Updated!. Tbh, for large elements the use starts to get real clunky, but I don't understand the codebase well enough to instead provide a dict vs an array. Someone savvier than me should probably eventually update that (so that a user doesn't need to set 0's for a bunch of elements they Just Don't Care About), but I didn't see a mapping type available in the relevant context (just an int vector) so I went with what was there.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2667#issuecomment-1209560924
https://github.com/psi4/psi4/pull/2667#issuecomment-1209560924:0,Deployability,Update,Updated,0,"Updated!. Tbh, for large elements the use starts to get real clunky, but I don't understand the codebase well enough to instead provide a dict vs an array. Someone savvier than me should probably eventually update that (so that a user doesn't need to set 0's for a bunch of elements they Just Don't Care About), but I didn't see a mapping type available in the relevant context (just an int vector) so I went with what was there.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2667#issuecomment-1209560924
https://github.com/psi4/psi4/pull/2667#issuecomment-1209560924:207,Deployability,update,update,207,"Updated!. Tbh, for large elements the use starts to get real clunky, but I don't understand the codebase well enough to instead provide a dict vs an array. Someone savvier than me should probably eventually update that (so that a user doesn't need to set 0's for a bunch of elements they Just Don't Care About), but I didn't see a mapping type available in the relevant context (just an int vector) so I went with what was there.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2667#issuecomment-1209560924
https://github.com/psi4/psi4/pull/2667#issuecomment-1212275829:5,Security,authoriz,authorized,5,"I've authorized the test suite to run. This is our way of confirming that nothing is obviously broken. If everything passes (as I expect it should), there's nothing on your end yet to do. If it fails, give it a quick look and flag Lori or I if you need assistance in identifying the issue.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2667#issuecomment-1212275829
https://github.com/psi4/psi4/pull/2667#issuecomment-1212275829:20,Testability,test,test,20,"I've authorized the test suite to run. This is our way of confirming that nothing is obviously broken. If everything passes (as I expect it should), there's nothing on your end yet to do. If it fails, give it a quick look and flag Lori or I if you need assistance in identifying the issue.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2667#issuecomment-1212275829
https://github.com/psi4/psi4/pull/2667#issuecomment-1212370317:153,Availability,Error,Error,153,"@JonathonMisiewicz looks like most things worked except one of the linux builds failed for an issue that I don't think is related to my patch:. ```CMake Error at /usr/local/share/cmake-3.24/Modules/FindPackageHandleStandardArgs.cmake:230 (message):; Could NOT find Python (missing: Python_NumPy_INCLUDE_DIRS Interpreter; NumPy) (found suitable version ""3.8.10"", minimum required is ""3.8""); ```. Not sure how to proceed here.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2667#issuecomment-1212370317
https://github.com/psi4/psi4/pull/2667#issuecomment-1212370317:136,Deployability,patch,patch,136,"@JonathonMisiewicz looks like most things worked except one of the linux builds failed for an issue that I don't think is related to my patch:. ```CMake Error at /usr/local/share/cmake-3.24/Modules/FindPackageHandleStandardArgs.cmake:230 (message):; Could NOT find Python (missing: Python_NumPy_INCLUDE_DIRS Interpreter; NumPy) (found suitable version ""3.8.10"", minimum required is ""3.8""); ```. Not sure how to proceed here.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2667#issuecomment-1212370317
https://github.com/psi4/psi4/pull/2667#issuecomment-1212370317:239,Integrability,message,message,239,"@JonathonMisiewicz looks like most things worked except one of the linux builds failed for an issue that I don't think is related to my patch:. ```CMake Error at /usr/local/share/cmake-3.24/Modules/FindPackageHandleStandardArgs.cmake:230 (message):; Could NOT find Python (missing: Python_NumPy_INCLUDE_DIRS Interpreter; NumPy) (found suitable version ""3.8.10"", minimum required is ""3.8""); ```. Not sure how to proceed here.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2667#issuecomment-1212370317
https://github.com/psi4/psi4/issues/2668#issuecomment-1209139255:21,Modifiability,variab,variable,21,"It's not an exported variable. Not sure where you got it from, but internally it is:; `psi4_io = psi4.core.IOManager.shared_object()`",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2668#issuecomment-1209139255
https://github.com/psi4/psi4/issues/2668#issuecomment-1209169955:135,Availability,error,error-psioutstream-failed-to-open-file,135,"Hi,; I cannot remember correctly as I have been digging through net in search of a [different issues](http://forum.psicode.org/t/fatal-error-psioutstream-failed-to-open-file/2572) and I came across this.; It worked your way, thanks for helping me out.; M",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2668#issuecomment-1209169955
https://github.com/psi4/psi4/pull/2669#issuecomment-1212073307:195,Deployability,update,update,195,"> long int? Why not just size_t which is quite literally the size type. No reason, I guess. Some modules used `long int` before we went on a `size_t` fest a few years ago. I can switch them (and update the printouts from M*B to G*B) if folks concur. It would be shorter.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2669#issuecomment-1212073307
https://github.com/psi4/psi4/pull/2669#issuecomment-1212096767:23,Modifiability,variab,variables,23,My one request is that variables that are obviously used for indexing/lengths be `size_t`.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2669#issuecomment-1212096767
https://github.com/psi4/psi4/pull/2669#issuecomment-1212111830:146,Integrability,wrap,wrap,146,"Just be super careful if there are any subtractions; the result of subtracting two unsigned quantities is itself unsigned and, if negative, it'll wrap around and give garbage. Therefore things like `if (A - B > tol)` should be `if (A > B + tol)`. Probably not relevant for this case, but keep in mind that OpenMP loop iteration variables must be signed.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2669#issuecomment-1212111830
https://github.com/psi4/psi4/pull/2669#issuecomment-1212111830:328,Modifiability,variab,variables,328,"Just be super careful if there are any subtractions; the result of subtracting two unsigned quantities is itself unsigned and, if negative, it'll wrap around and give garbage. Therefore things like `if (A - B > tol)` should be `if (A > B + tol)`. Probably not relevant for this case, but keep in mind that OpenMP loop iteration variables must be signed.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2669#issuecomment-1212111830
https://github.com/psi4/psi4/pull/2669#issuecomment-1212144203:24,Modifiability,variab,variables,24,"Ideally, I suppose, the variables should become `size_t` from the start. As already touched upon here https://github.com/psi4/psi4/issues/1764#issuecomment-562739051",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2669#issuecomment-1212144203
https://github.com/psi4/psi4/pull/2669#issuecomment-1212291824:27,Usability,guid,guidance,27,"After wading into `size_t` guidance, the dangers of mixed signed/unsigned, and the deeper troubles of #1764 that need changes to the tensor classes, not just the dfocc.h `int`s, and not just the memory estimates, I think the `long long int` serves nicely for now.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2669#issuecomment-1212291824
https://github.com/psi4/psi4/pull/2670#issuecomment-1220869733:0,Deployability,Update,Update,0,"Update: this is rebased and fit to review. @behnle, thanks for the comments on eqn numbers. I've added doi to the lines locally, but now they're all entangled with separate WIP.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2670#issuecomment-1220869733
https://github.com/psi4/psi4/pull/2670#issuecomment-1230399537:0,Availability,Ping,Ping,0,Ping me for review after merge conflict resolve.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2670#issuecomment-1230399537
https://github.com/psi4/psi4/pull/2670#issuecomment-1244156469:39,Testability,test,tested,39,"Eq numbers removed, rebased, and fully tested locally. Ready for review again.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2670#issuecomment-1244156469
https://github.com/psi4/psi4/issues/2674#issuecomment-1212032993:136,Testability,test,test,136,"i.e., confirm https://github.com/psi4/psi4/issues/2476 and https://github.com/psi4/psi4/issues/2594 are actually closed and then add as test cases",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2674#issuecomment-1212032993
https://github.com/psi4/psi4/issues/2674#issuecomment-1213448481:120,Integrability,depend,depends,120,"2594 is not an option for adding to the test suite, as the test takes too long tor un. 2476 _may_ be. Per @loriab, that depends on increasing the AM in the auto-build, which depends on some L2 development from Valeev.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2674#issuecomment-1213448481
https://github.com/psi4/psi4/issues/2674#issuecomment-1213448481:174,Integrability,depend,depends,174,"2594 is not an option for adding to the test suite, as the test takes too long tor un. 2476 _may_ be. Per @loriab, that depends on increasing the AM in the auto-build, which depends on some L2 development from Valeev.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2674#issuecomment-1213448481
https://github.com/psi4/psi4/issues/2674#issuecomment-1213448481:40,Testability,test,test,40,"2594 is not an option for adding to the test suite, as the test takes too long tor un. 2476 _may_ be. Per @loriab, that depends on increasing the AM in the auto-build, which depends on some L2 development from Valeev.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2674#issuecomment-1213448481
https://github.com/psi4/psi4/issues/2674#issuecomment-1213448481:59,Testability,test,test,59,"2594 is not an option for adding to the test suite, as the test takes too long tor un. 2476 _may_ be. Per @loriab, that depends on increasing the AM in the auto-build, which depends on some L2 development from Valeev.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2674#issuecomment-1213448481
https://github.com/psi4/psi4/issues/2675#issuecomment-1212521732:228,Deployability,install,install,228,"Psi4 uses an branch of L2 that hasn't been merged to master and uses CMake detection, not pkgconfig detection. While the detection scheme can be overcome, several build options need to be set for Psi4 such that if you have a L2 install that works with any other QC package, it probably doesn't work with Psi4. See https://github.com/evaleev/libint/issues/190. > Could NOT find Libint2 (missing: Libint2_DIR). I'd guess this is a red herring. Unless you've built from https://github.com/psi4/psi4/blob/master/external/upstream/libint2/CMakeLists.txt#L63 tarball, the Psi4 buildsys as-is won't succeed for L2.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2675#issuecomment-1212521732
https://github.com/psi4/psi4/issues/2675#issuecomment-1212521732:75,Safety,detect,detection,75,"Psi4 uses an branch of L2 that hasn't been merged to master and uses CMake detection, not pkgconfig detection. While the detection scheme can be overcome, several build options need to be set for Psi4 such that if you have a L2 install that works with any other QC package, it probably doesn't work with Psi4. See https://github.com/evaleev/libint/issues/190. > Could NOT find Libint2 (missing: Libint2_DIR). I'd guess this is a red herring. Unless you've built from https://github.com/psi4/psi4/blob/master/external/upstream/libint2/CMakeLists.txt#L63 tarball, the Psi4 buildsys as-is won't succeed for L2.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2675#issuecomment-1212521732
https://github.com/psi4/psi4/issues/2675#issuecomment-1212521732:100,Safety,detect,detection,100,"Psi4 uses an branch of L2 that hasn't been merged to master and uses CMake detection, not pkgconfig detection. While the detection scheme can be overcome, several build options need to be set for Psi4 such that if you have a L2 install that works with any other QC package, it probably doesn't work with Psi4. See https://github.com/evaleev/libint/issues/190. > Could NOT find Libint2 (missing: Libint2_DIR). I'd guess this is a red herring. Unless you've built from https://github.com/psi4/psi4/blob/master/external/upstream/libint2/CMakeLists.txt#L63 tarball, the Psi4 buildsys as-is won't succeed for L2.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2675#issuecomment-1212521732
https://github.com/psi4/psi4/issues/2675#issuecomment-1212521732:121,Safety,detect,detection,121,"Psi4 uses an branch of L2 that hasn't been merged to master and uses CMake detection, not pkgconfig detection. While the detection scheme can be overcome, several build options need to be set for Psi4 such that if you have a L2 install that works with any other QC package, it probably doesn't work with Psi4. See https://github.com/evaleev/libint/issues/190. > Could NOT find Libint2 (missing: Libint2_DIR). I'd guess this is a red herring. Unless you've built from https://github.com/psi4/psi4/blob/master/external/upstream/libint2/CMakeLists.txt#L63 tarball, the Psi4 buildsys as-is won't succeed for L2.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2675#issuecomment-1212521732
https://github.com/psi4/psi4/issues/2676#issuecomment-1212508760:114,Modifiability,config,configure-libxc-for-building-,114,cmake var `Libxc_DIR` can likely help https://psicode.org/psi4manual/master/libxc.html?highlight=libxc_dir#how-to-configure-libxc-for-building-psi4,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2676#issuecomment-1212508760
https://github.com/psi4/psi4/pull/2679#issuecomment-1215513953:206,Safety,Redund,Redundancy,206,> > The `Array2d` class needs to go. Happy to see even a bit of it be destroyed.; > ; > I'm not familiar with this class (or the `occ` module for that matter). What's the motivation for getting rid of it?. Redundancy. It's essentially a symmetry-less Matrix.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2679#issuecomment-1215513953
https://github.com/psi4/psi4/issues/2680#issuecomment-1213467412:156,Integrability,message,message,156,"```; execute_process(; COMMAND /bin/sh -c ""if test -t 1; then return 1; else return 0; fi""; RESULT_VARIABLE OUTPUT_IS_TERMINAL; OUTPUT_FILE /dev/stdout; ). message(""OUTPUT_IS_TERMINAL=${OUTPUT_IS_TERMINAL}""); ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2680#issuecomment-1213467412
https://github.com/psi4/psi4/issues/2680#issuecomment-1213467412:46,Testability,test,test,46,"```; execute_process(; COMMAND /bin/sh -c ""if test -t 1; then return 1; else return 0; fi""; RESULT_VARIABLE OUTPUT_IS_TERMINAL; OUTPUT_FILE /dev/stdout; ). message(""OUTPUT_IS_TERMINAL=${OUTPUT_IS_TERMINAL}""); ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2680#issuecomment-1213467412
https://github.com/psi4/psi4/issues/2681#issuecomment-1213362219:283,Safety,detect,detected-from-prebuilt-external,283,"I'm pretty sure those files are present only because you did an internal build of L2. That is, the files weren't provided by the Psi4 project, except as a build detail; they were provided by the Libint project. Placing them behind a namespace would hinder the easy equivalence of L2-detected-from-prebuilt-external and L2-internal-build. Also, if you have an external L2 package and it's the default-ordering v2.7.2 you mentioned yesterday, I think psi could get confused between them at runtime. Am I mis-analyzing this?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2681#issuecomment-1213362219
https://github.com/psi4/psi4/pull/2682#issuecomment-1215622859:318,Performance,perform,performed,318,"Yeah, for larger / more diffuse basis functions, it's often hard to converge w/ incremental fock. I've already mentioned this in the [docs](https://psicode.org/psi4manual/master/scf.html#cosx-exchange). In general, incremental fock gets you only a very small speedup with COSX. This is because the last SCF iteration (performed on a large grid) is much more expensive than the other iterations (performed on a small grid), and the last iteration can't be done with a difference density matrix. For this reason, I generally set the `COSX_INCFOCK` option to `FALSE` when I use the JK algorithm, and I had meant to make this the default behavior.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1215622859
https://github.com/psi4/psi4/pull/2682#issuecomment-1215622859:395,Performance,perform,performed,395,"Yeah, for larger / more diffuse basis functions, it's often hard to converge w/ incremental fock. I've already mentioned this in the [docs](https://psicode.org/psi4manual/master/scf.html#cosx-exchange). In general, incremental fock gets you only a very small speedup with COSX. This is because the last SCF iteration (performed on a large grid) is much more expensive than the other iterations (performed on a small grid), and the last iteration can't be done with a difference density matrix. For this reason, I generally set the `COSX_INCFOCK` option to `FALSE` when I use the JK algorithm, and I had meant to make this the default behavior.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1215622859
https://github.com/psi4/psi4/pull/2682#issuecomment-1215706579:327,Performance,perform,performed,327,"> Yeah, for larger / more diffuse basis functions, it's often hard to converge w/ incremental fock. I've already mentioned this in the [docs](https://psicode.org/psi4manual/master/scf.html#cosx-exchange).; > ; > In general, incremental fock gets you only a very small speedup with COSX. This is because the last SCF iteration (performed on a large grid) is much more expensive than the other iterations (performed on a small grid), and the last iteration can't be done with a difference density matrix. For this reason, I generally set the `COSX_INCFOCK` option to `FALSE` when I use the JK algorithm, and I had meant to make this the default behavior. In his timings of `COSX`, @davpoolechem found discrepancies between timings (on larger systems) for doing incfock every iteration (current policy in COSX) and not doing incfock every iteration (this PR), so I believe that `incfock` being ON vs OFF would lead to significant speedups, at least for larger systems.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1215706579
https://github.com/psi4/psi4/pull/2682#issuecomment-1215706579:404,Performance,perform,performed,404,"> Yeah, for larger / more diffuse basis functions, it's often hard to converge w/ incremental fock. I've already mentioned this in the [docs](https://psicode.org/psi4manual/master/scf.html#cosx-exchange).; > ; > In general, incremental fock gets you only a very small speedup with COSX. This is because the last SCF iteration (performed on a large grid) is much more expensive than the other iterations (performed on a small grid), and the last iteration can't be done with a difference density matrix. For this reason, I generally set the `COSX_INCFOCK` option to `FALSE` when I use the JK algorithm, and I had meant to make this the default behavior. In his timings of `COSX`, @davpoolechem found discrepancies between timings (on larger systems) for doing incfock every iteration (current policy in COSX) and not doing incfock every iteration (this PR), so I believe that `incfock` being ON vs OFF would lead to significant speedups, at least for larger systems.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1215706579
https://github.com/psi4/psi4/pull/2682#issuecomment-1219772523:656,Availability,down,down,656,"> > I'm slightly confused. So COSX and Direct have different ""versions"" of incremental Fock build, and this PR has them use the same incremental Fock code?; > ; > Yes this is correct. Yeah, what Andy said is correct. I've been doing some benchmarking of different J build methods with the COSX method. When doing benchmarks on the DFJCOSK code currently present in Psi4, it often to take a notably higher number of iterations then expected to converge many of the calculations, especially when diffuse functions are in the basis set. After modifying the COSX code to use the ""Direct"" version of Incfock, the number of SCF iterations needs to converge goes down noticeably. It was in these timing benchmarks that we found the different Incfock implementation in COSX, and this PR is meant to remedy that.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1219772523
https://github.com/psi4/psi4/pull/2682#issuecomment-1219772523:238,Testability,benchmark,benchmarking,238,"> > I'm slightly confused. So COSX and Direct have different ""versions"" of incremental Fock build, and this PR has them use the same incremental Fock code?; > ; > Yes this is correct. Yeah, what Andy said is correct. I've been doing some benchmarking of different J build methods with the COSX method. When doing benchmarks on the DFJCOSK code currently present in Psi4, it often to take a notably higher number of iterations then expected to converge many of the calculations, especially when diffuse functions are in the basis set. After modifying the COSX code to use the ""Direct"" version of Incfock, the number of SCF iterations needs to converge goes down noticeably. It was in these timing benchmarks that we found the different Incfock implementation in COSX, and this PR is meant to remedy that.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1219772523
https://github.com/psi4/psi4/pull/2682#issuecomment-1219772523:313,Testability,benchmark,benchmarks,313,"> > I'm slightly confused. So COSX and Direct have different ""versions"" of incremental Fock build, and this PR has them use the same incremental Fock code?; > ; > Yes this is correct. Yeah, what Andy said is correct. I've been doing some benchmarking of different J build methods with the COSX method. When doing benchmarks on the DFJCOSK code currently present in Psi4, it often to take a notably higher number of iterations then expected to converge many of the calculations, especially when diffuse functions are in the basis set. After modifying the COSX code to use the ""Direct"" version of Incfock, the number of SCF iterations needs to converge goes down noticeably. It was in these timing benchmarks that we found the different Incfock implementation in COSX, and this PR is meant to remedy that.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1219772523
https://github.com/psi4/psi4/pull/2682#issuecomment-1219772523:696,Testability,benchmark,benchmarks,696,"> > I'm slightly confused. So COSX and Direct have different ""versions"" of incremental Fock build, and this PR has them use the same incremental Fock code?; > ; > Yes this is correct. Yeah, what Andy said is correct. I've been doing some benchmarking of different J build methods with the COSX method. When doing benchmarks on the DFJCOSK code currently present in Psi4, it often to take a notably higher number of iterations then expected to converge many of the calculations, especially when diffuse functions are in the basis set. After modifying the COSX code to use the ""Direct"" version of Incfock, the number of SCF iterations needs to converge goes down noticeably. It was in these timing benchmarks that we found the different Incfock implementation in COSX, and this PR is meant to remedy that.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1219772523
https://github.com/psi4/psi4/pull/2682#issuecomment-1230790623:1952,Availability,down,down,1952,"class, it is important that the implementation be as efficient and maintainable as possible. In that respect, I think there are some general improvements to be made:; > ; > The way you've structured incremental Fock keeps eight lists of matrices attached to each `JK` object: copies of the previous `J`, `K`, `wK`, and `D` matrices, and differences between the last two iterations `J`, `K`, `wK`, `D`. In the interest of efficiency, I think it would be best to not store these matrices. Incremental Fock as implemented in the `DFJCOSK` class is a little better about this. That code adds the difference in `J`/`K`/`wK` to the appropriate buffer, which is not zeroed out between SCF iterations. This requires keeping only one list of matrices, the previous iteration `D`, which in my opinion is cleaner. (I have some thoughts on getting around storing the previous `D` matrix too.); > ; > Speaking more broadly about the design of the `JK` class, one valuable aspect of the `JK` class is that it is stateless and decoupled from the SCF procedure. `JK` classes have a well-defined [interface](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libfock/jk.h#L175-L209). The variables like `incfock_count_` that you've proposed adding to the `JK` class break this statelessness, and my opinion that kind of logic should be in the SCF driver, not the `JK` object.; > ; > Let me know if any of these thoughts are unclear. I agree with your points. However, making that change would require a refactor of `DirectJK` (which zero out the J/K matrices at the beginning of every iteration) as well, as well as an overhaul of the previous `INCFOCK` code that exists in the Psi4 code. For the sake of PR brevity, I suggest punting those changes down to a future PR. The scope of this PR is to fix the numerical instabilities of `incfock` in COSX. Per @davpoolechem, using `incfock` on COSX indeed leads to significant time savings on larger systems, even if it is always OFF by default for the last iteration.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1230790623
https://github.com/psi4/psi4/pull/2682#issuecomment-1230790623:269,Energy Efficiency,efficient,efficient,269,"> Good work Andy. I like the intent of this PR, which is to consolidate incremental Fock code between different derived `JK` classes. I think that if the incremental Fock feature is to be promoted to the parent `JK` class, it is important that the implementation be as efficient and maintainable as possible. In that respect, I think there are some general improvements to be made:; > ; > The way you've structured incremental Fock keeps eight lists of matrices attached to each `JK` object: copies of the previous `J`, `K`, `wK`, and `D` matrices, and differences between the last two iterations `J`, `K`, `wK`, `D`. In the interest of efficiency, I think it would be best to not store these matrices. Incremental Fock as implemented in the `DFJCOSK` class is a little better about this. That code adds the difference in `J`/`K`/`wK` to the appropriate buffer, which is not zeroed out between SCF iterations. This requires keeping only one list of matrices, the previous iteration `D`, which in my opinion is cleaner. (I have some thoughts on getting around storing the previous `D` matrix too.); > ; > Speaking more broadly about the design of the `JK` class, one valuable aspect of the `JK` class is that it is stateless and decoupled from the SCF procedure. `JK` classes have a well-defined [interface](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libfock/jk.h#L175-L209). The variables like `incfock_count_` that you've proposed adding to the `JK` class break this statelessness, and my opinion that kind of logic should be in the SCF driver, not the `JK` object.; > ; > Let me know if any of these thoughts are unclear. I agree with your points. However, making that change would require a refactor of `DirectJK` (which zero out the J/K matrices at the beginning of every iteration) as well, as well as an overhaul of the previous `INCFOCK` code that exists in the Psi4 code. For the sake of PR brevity, I suggest punting those changes down to a future PR. The scope of this PR is to f",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1230790623
https://github.com/psi4/psi4/pull/2682#issuecomment-1230790623:1296,Integrability,interface,interface,1296,"class, it is important that the implementation be as efficient and maintainable as possible. In that respect, I think there are some general improvements to be made:; > ; > The way you've structured incremental Fock keeps eight lists of matrices attached to each `JK` object: copies of the previous `J`, `K`, `wK`, and `D` matrices, and differences between the last two iterations `J`, `K`, `wK`, `D`. In the interest of efficiency, I think it would be best to not store these matrices. Incremental Fock as implemented in the `DFJCOSK` class is a little better about this. That code adds the difference in `J`/`K`/`wK` to the appropriate buffer, which is not zeroed out between SCF iterations. This requires keeping only one list of matrices, the previous iteration `D`, which in my opinion is cleaner. (I have some thoughts on getting around storing the previous `D` matrix too.); > ; > Speaking more broadly about the design of the `JK` class, one valuable aspect of the `JK` class is that it is stateless and decoupled from the SCF procedure. `JK` classes have a well-defined [interface](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libfock/jk.h#L175-L209). The variables like `incfock_count_` that you've proposed adding to the `JK` class break this statelessness, and my opinion that kind of logic should be in the SCF driver, not the `JK` object.; > ; > Let me know if any of these thoughts are unclear. I agree with your points. However, making that change would require a refactor of `DirectJK` (which zero out the J/K matrices at the beginning of every iteration) as well, as well as an overhaul of the previous `INCFOCK` code that exists in the Psi4 code. For the sake of PR brevity, I suggest punting those changes down to a future PR. The scope of this PR is to fix the numerical instabilities of `incfock` in COSX. Per @davpoolechem, using `incfock` on COSX indeed leads to significant time savings on larger systems, even if it is always OFF by default for the last iteration.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1230790623
https://github.com/psi4/psi4/pull/2682#issuecomment-1230790623:283,Modifiability,maintainab,maintainable,283,"> Good work Andy. I like the intent of this PR, which is to consolidate incremental Fock code between different derived `JK` classes. I think that if the incremental Fock feature is to be promoted to the parent `JK` class, it is important that the implementation be as efficient and maintainable as possible. In that respect, I think there are some general improvements to be made:; > ; > The way you've structured incremental Fock keeps eight lists of matrices attached to each `JK` object: copies of the previous `J`, `K`, `wK`, and `D` matrices, and differences between the last two iterations `J`, `K`, `wK`, `D`. In the interest of efficiency, I think it would be best to not store these matrices. Incremental Fock as implemented in the `DFJCOSK` class is a little better about this. That code adds the difference in `J`/`K`/`wK` to the appropriate buffer, which is not zeroed out between SCF iterations. This requires keeping only one list of matrices, the previous iteration `D`, which in my opinion is cleaner. (I have some thoughts on getting around storing the previous `D` matrix too.); > ; > Speaking more broadly about the design of the `JK` class, one valuable aspect of the `JK` class is that it is stateless and decoupled from the SCF procedure. `JK` classes have a well-defined [interface](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libfock/jk.h#L175-L209). The variables like `incfock_count_` that you've proposed adding to the `JK` class break this statelessness, and my opinion that kind of logic should be in the SCF driver, not the `JK` object.; > ; > Let me know if any of these thoughts are unclear. I agree with your points. However, making that change would require a refactor of `DirectJK` (which zero out the J/K matrices at the beginning of every iteration) as well, as well as an overhaul of the previous `INCFOCK` code that exists in the Psi4 code. For the sake of PR brevity, I suggest punting those changes down to a future PR. The scope of this PR is to f",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1230790623
https://github.com/psi4/psi4/pull/2682#issuecomment-1230790623:1391,Modifiability,variab,variables,1391,"class, it is important that the implementation be as efficient and maintainable as possible. In that respect, I think there are some general improvements to be made:; > ; > The way you've structured incremental Fock keeps eight lists of matrices attached to each `JK` object: copies of the previous `J`, `K`, `wK`, and `D` matrices, and differences between the last two iterations `J`, `K`, `wK`, `D`. In the interest of efficiency, I think it would be best to not store these matrices. Incremental Fock as implemented in the `DFJCOSK` class is a little better about this. That code adds the difference in `J`/`K`/`wK` to the appropriate buffer, which is not zeroed out between SCF iterations. This requires keeping only one list of matrices, the previous iteration `D`, which in my opinion is cleaner. (I have some thoughts on getting around storing the previous `D` matrix too.); > ; > Speaking more broadly about the design of the `JK` class, one valuable aspect of the `JK` class is that it is stateless and decoupled from the SCF procedure. `JK` classes have a well-defined [interface](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libfock/jk.h#L175-L209). The variables like `incfock_count_` that you've proposed adding to the `JK` class break this statelessness, and my opinion that kind of logic should be in the SCF driver, not the `JK` object.; > ; > Let me know if any of these thoughts are unclear. I agree with your points. However, making that change would require a refactor of `DirectJK` (which zero out the J/K matrices at the beginning of every iteration) as well, as well as an overhaul of the previous `INCFOCK` code that exists in the Psi4 code. For the sake of PR brevity, I suggest punting those changes down to a future PR. The scope of this PR is to fix the numerical instabilities of `incfock` in COSX. Per @davpoolechem, using `incfock` on COSX indeed leads to significant time savings on larger systems, even if it is always OFF by default for the last iteration.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1230790623
https://github.com/psi4/psi4/pull/2682#issuecomment-1230790623:1706,Modifiability,refactor,refactor,1706,"class, it is important that the implementation be as efficient and maintainable as possible. In that respect, I think there are some general improvements to be made:; > ; > The way you've structured incremental Fock keeps eight lists of matrices attached to each `JK` object: copies of the previous `J`, `K`, `wK`, and `D` matrices, and differences between the last two iterations `J`, `K`, `wK`, `D`. In the interest of efficiency, I think it would be best to not store these matrices. Incremental Fock as implemented in the `DFJCOSK` class is a little better about this. That code adds the difference in `J`/`K`/`wK` to the appropriate buffer, which is not zeroed out between SCF iterations. This requires keeping only one list of matrices, the previous iteration `D`, which in my opinion is cleaner. (I have some thoughts on getting around storing the previous `D` matrix too.); > ; > Speaking more broadly about the design of the `JK` class, one valuable aspect of the `JK` class is that it is stateless and decoupled from the SCF procedure. `JK` classes have a well-defined [interface](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libfock/jk.h#L175-L209). The variables like `incfock_count_` that you've proposed adding to the `JK` class break this statelessness, and my opinion that kind of logic should be in the SCF driver, not the `JK` object.; > ; > Let me know if any of these thoughts are unclear. I agree with your points. However, making that change would require a refactor of `DirectJK` (which zero out the J/K matrices at the beginning of every iteration) as well, as well as an overhaul of the previous `INCFOCK` code that exists in the Psi4 code. For the sake of PR brevity, I suggest punting those changes down to a future PR. The scope of this PR is to fix the numerical instabilities of `incfock` in COSX. Per @davpoolechem, using `incfock` on COSX indeed leads to significant time savings on larger systems, even if it is always OFF by default for the last iteration.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1230790623
https://github.com/psi4/psi4/pull/2682#issuecomment-1230790623:1523,Testability,log,logic,1523,"class, it is important that the implementation be as efficient and maintainable as possible. In that respect, I think there are some general improvements to be made:; > ; > The way you've structured incremental Fock keeps eight lists of matrices attached to each `JK` object: copies of the previous `J`, `K`, `wK`, and `D` matrices, and differences between the last two iterations `J`, `K`, `wK`, `D`. In the interest of efficiency, I think it would be best to not store these matrices. Incremental Fock as implemented in the `DFJCOSK` class is a little better about this. That code adds the difference in `J`/`K`/`wK` to the appropriate buffer, which is not zeroed out between SCF iterations. This requires keeping only one list of matrices, the previous iteration `D`, which in my opinion is cleaner. (I have some thoughts on getting around storing the previous `D` matrix too.); > ; > Speaking more broadly about the design of the `JK` class, one valuable aspect of the `JK` class is that it is stateless and decoupled from the SCF procedure. `JK` classes have a well-defined [interface](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libfock/jk.h#L175-L209). The variables like `incfock_count_` that you've proposed adding to the `JK` class break this statelessness, and my opinion that kind of logic should be in the SCF driver, not the `JK` object.; > ; > Let me know if any of these thoughts are unclear. I agree with your points. However, making that change would require a refactor of `DirectJK` (which zero out the J/K matrices at the beginning of every iteration) as well, as well as an overhaul of the previous `INCFOCK` code that exists in the Psi4 code. For the sake of PR brevity, I suggest punting those changes down to a future PR. The scope of this PR is to fix the numerical instabilities of `incfock` in COSX. Per @davpoolechem, using `incfock` on COSX indeed leads to significant time savings on larger systems, even if it is always OFF by default for the last iteration.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1230790623
https://github.com/psi4/psi4/pull/2682#issuecomment-1231694428:318,Availability,down,down,318,"> I agree with your points. However, making that change would require a refactor of `DirectJK` (which zero out the J/K matrices at the beginning of every iteration) as well, as well as an overhaul of the previous `INCFOCK` code that exists in the Psi4 code. For the sake of PR brevity, I suggest punting those changes down to a future PR. Is this a future PR you'll commit to doing, or a future PR you'll leave to somebody else?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1231694428
https://github.com/psi4/psi4/pull/2682#issuecomment-1231694428:72,Modifiability,refactor,refactor,72,"> I agree with your points. However, making that change would require a refactor of `DirectJK` (which zero out the J/K matrices at the beginning of every iteration) as well, as well as an overhaul of the previous `INCFOCK` code that exists in the Psi4 code. For the sake of PR brevity, I suggest punting those changes down to a future PR. Is this a future PR you'll commit to doing, or a future PR you'll leave to somebody else?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1231694428
https://github.com/psi4/psi4/pull/2682#issuecomment-1231718373:320,Availability,down,down,320,"> > I agree with your points. However, making that change would require a refactor of `DirectJK` (which zero out the J/K matrices at the beginning of every iteration) as well, as well as an overhaul of the previous `INCFOCK` code that exists in the Psi4 code. For the sake of PR brevity, I suggest punting those changes down to a future PR.; > ; > Is this a future PR you'll commit to doing, or a future PR you'll leave to somebody else?. I will commit to doing it. I will likely open it up within the next few days.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1231718373
https://github.com/psi4/psi4/pull/2682#issuecomment-1231718373:74,Modifiability,refactor,refactor,74,"> > I agree with your points. However, making that change would require a refactor of `DirectJK` (which zero out the J/K matrices at the beginning of every iteration) as well, as well as an overhaul of the previous `INCFOCK` code that exists in the Psi4 code. For the sake of PR brevity, I suggest punting those changes down to a future PR.; > ; > Is this a future PR you'll commit to doing, or a future PR you'll leave to somebody else?. I will commit to doing it. I will likely open it up within the next few days.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1231718373
https://github.com/psi4/psi4/pull/2682#issuecomment-1231764838:182,Energy Efficiency,efficient,efficient,182,"Yeah, it's perfectly fine to split things up into multiple PRs. One sensible order I can come up with is:. 1. Edit the incremental Fock in the derived `DirectJK` class so that it is efficient and maintainable (no SCF iteration counts associated with the object, minimal number of matrices cached on the object, etc.) [some other PR]; 2. Move this improved incremental Fock to the parent `JK` class. [this PR]. In a previous comment, I suggested doing away with the cached `J`/`K`/`wK`/`dJ`/`dK`/`dwK` matrices by changing the behavior of the `JK` object so that the buffers aren't cleared between SCF iterations. If you find that difficult to do, I think an acceptable compromise would be to retain those cached matrices, but initialize them in the SCF driver (rather than make them a property of the JK object).",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1231764838
https://github.com/psi4/psi4/pull/2682#issuecomment-1231764838:196,Modifiability,maintainab,maintainable,196,"Yeah, it's perfectly fine to split things up into multiple PRs. One sensible order I can come up with is:. 1. Edit the incremental Fock in the derived `DirectJK` class so that it is efficient and maintainable (no SCF iteration counts associated with the object, minimal number of matrices cached on the object, etc.) [some other PR]; 2. Move this improved incremental Fock to the parent `JK` class. [this PR]. In a previous comment, I suggested doing away with the cached `J`/`K`/`wK`/`dJ`/`dK`/`dwK` matrices by changing the behavior of the `JK` object so that the buffers aren't cleared between SCF iterations. If you find that difficult to do, I think an acceptable compromise would be to retain those cached matrices, but initialize them in the SCF driver (rather than make them a property of the JK object).",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1231764838
https://github.com/psi4/psi4/pull/2682#issuecomment-1231764838:289,Performance,cache,cached,289,"Yeah, it's perfectly fine to split things up into multiple PRs. One sensible order I can come up with is:. 1. Edit the incremental Fock in the derived `DirectJK` class so that it is efficient and maintainable (no SCF iteration counts associated with the object, minimal number of matrices cached on the object, etc.) [some other PR]; 2. Move this improved incremental Fock to the parent `JK` class. [this PR]. In a previous comment, I suggested doing away with the cached `J`/`K`/`wK`/`dJ`/`dK`/`dwK` matrices by changing the behavior of the `JK` object so that the buffers aren't cleared between SCF iterations. If you find that difficult to do, I think an acceptable compromise would be to retain those cached matrices, but initialize them in the SCF driver (rather than make them a property of the JK object).",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1231764838
https://github.com/psi4/psi4/pull/2682#issuecomment-1231764838:465,Performance,cache,cached,465,"Yeah, it's perfectly fine to split things up into multiple PRs. One sensible order I can come up with is:. 1. Edit the incremental Fock in the derived `DirectJK` class so that it is efficient and maintainable (no SCF iteration counts associated with the object, minimal number of matrices cached on the object, etc.) [some other PR]; 2. Move this improved incremental Fock to the parent `JK` class. [this PR]. In a previous comment, I suggested doing away with the cached `J`/`K`/`wK`/`dJ`/`dK`/`dwK` matrices by changing the behavior of the `JK` object so that the buffers aren't cleared between SCF iterations. If you find that difficult to do, I think an acceptable compromise would be to retain those cached matrices, but initialize them in the SCF driver (rather than make them a property of the JK object).",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1231764838
https://github.com/psi4/psi4/pull/2682#issuecomment-1231764838:705,Performance,cache,cached,705,"Yeah, it's perfectly fine to split things up into multiple PRs. One sensible order I can come up with is:. 1. Edit the incremental Fock in the derived `DirectJK` class so that it is efficient and maintainable (no SCF iteration counts associated with the object, minimal number of matrices cached on the object, etc.) [some other PR]; 2. Move this improved incremental Fock to the parent `JK` class. [this PR]. In a previous comment, I suggested doing away with the cached `J`/`K`/`wK`/`dJ`/`dK`/`dwK` matrices by changing the behavior of the `JK` object so that the buffers aren't cleared between SCF iterations. If you find that difficult to do, I think an acceptable compromise would be to retain those cached matrices, but initialize them in the SCF driver (rather than make them a property of the JK object).",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1231764838
https://github.com/psi4/psi4/pull/2682#issuecomment-1231764838:581,Usability,clear,cleared,581,"Yeah, it's perfectly fine to split things up into multiple PRs. One sensible order I can come up with is:. 1. Edit the incremental Fock in the derived `DirectJK` class so that it is efficient and maintainable (no SCF iteration counts associated with the object, minimal number of matrices cached on the object, etc.) [some other PR]; 2. Move this improved incremental Fock to the parent `JK` class. [this PR]. In a previous comment, I suggested doing away with the cached `J`/`K`/`wK`/`dJ`/`dK`/`dwK` matrices by changing the behavior of the `JK` object so that the buffers aren't cleared between SCF iterations. If you find that difficult to do, I think an acceptable compromise would be to retain those cached matrices, but initialize them in the SCF driver (rather than make them a property of the JK object).",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1231764838
https://github.com/psi4/psi4/pull/2682#issuecomment-1253878406:1147,Availability,down,down,1147,"> Yeah, it's perfectly fine to split things up into multiple PRs. One sensible order I can come up with is:; > ; > 1. Edit the incremental Fock in the derived `DirectJK` class so that it is efficient and maintainable (no SCF iteration counts associated with the object, minimal number of matrices cached on the object, etc.) [some other PR]; > 2. Move this improved incremental Fock to the parent `JK` class. [this PR]; > ; > In a previous comment, I suggested doing away with the cached `J`/`K`/`wK`/`dJ`/`dK`/`dwK` matrices by changing the behavior of the `JK` object so that the buffers aren't cleared between SCF iterations. If you find that difficult to do, I think an acceptable compromise would be to retain those cached matrices, but initialize them in the SCF driver (rather than make them a property of the JK object). Since this PR is already opened, I would actually prefer 2 before 1. I am slammed with my schedule right now, and I think 2 before 1 would be WAYYY easier for me. Is that okay with you @zachglick @JonathonMisiewicz? This PR also immediately fixes the `incfock` issues with `DFJCOSK`, as opposed to punting those fixes down to a future PR.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1253878406
https://github.com/psi4/psi4/pull/2682#issuecomment-1253878406:190,Energy Efficiency,efficient,efficient,190,"> Yeah, it's perfectly fine to split things up into multiple PRs. One sensible order I can come up with is:; > ; > 1. Edit the incremental Fock in the derived `DirectJK` class so that it is efficient and maintainable (no SCF iteration counts associated with the object, minimal number of matrices cached on the object, etc.) [some other PR]; > 2. Move this improved incremental Fock to the parent `JK` class. [this PR]; > ; > In a previous comment, I suggested doing away with the cached `J`/`K`/`wK`/`dJ`/`dK`/`dwK` matrices by changing the behavior of the `JK` object so that the buffers aren't cleared between SCF iterations. If you find that difficult to do, I think an acceptable compromise would be to retain those cached matrices, but initialize them in the SCF driver (rather than make them a property of the JK object). Since this PR is already opened, I would actually prefer 2 before 1. I am slammed with my schedule right now, and I think 2 before 1 would be WAYYY easier for me. Is that okay with you @zachglick @JonathonMisiewicz? This PR also immediately fixes the `incfock` issues with `DFJCOSK`, as opposed to punting those fixes down to a future PR.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1253878406
https://github.com/psi4/psi4/pull/2682#issuecomment-1253878406:919,Energy Efficiency,schedul,schedule,919,"> Yeah, it's perfectly fine to split things up into multiple PRs. One sensible order I can come up with is:; > ; > 1. Edit the incremental Fock in the derived `DirectJK` class so that it is efficient and maintainable (no SCF iteration counts associated with the object, minimal number of matrices cached on the object, etc.) [some other PR]; > 2. Move this improved incremental Fock to the parent `JK` class. [this PR]; > ; > In a previous comment, I suggested doing away with the cached `J`/`K`/`wK`/`dJ`/`dK`/`dwK` matrices by changing the behavior of the `JK` object so that the buffers aren't cleared between SCF iterations. If you find that difficult to do, I think an acceptable compromise would be to retain those cached matrices, but initialize them in the SCF driver (rather than make them a property of the JK object). Since this PR is already opened, I would actually prefer 2 before 1. I am slammed with my schedule right now, and I think 2 before 1 would be WAYYY easier for me. Is that okay with you @zachglick @JonathonMisiewicz? This PR also immediately fixes the `incfock` issues with `DFJCOSK`, as opposed to punting those fixes down to a future PR.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1253878406
https://github.com/psi4/psi4/pull/2682#issuecomment-1253878406:204,Modifiability,maintainab,maintainable,204,"> Yeah, it's perfectly fine to split things up into multiple PRs. One sensible order I can come up with is:; > ; > 1. Edit the incremental Fock in the derived `DirectJK` class so that it is efficient and maintainable (no SCF iteration counts associated with the object, minimal number of matrices cached on the object, etc.) [some other PR]; > 2. Move this improved incremental Fock to the parent `JK` class. [this PR]; > ; > In a previous comment, I suggested doing away with the cached `J`/`K`/`wK`/`dJ`/`dK`/`dwK` matrices by changing the behavior of the `JK` object so that the buffers aren't cleared between SCF iterations. If you find that difficult to do, I think an acceptable compromise would be to retain those cached matrices, but initialize them in the SCF driver (rather than make them a property of the JK object). Since this PR is already opened, I would actually prefer 2 before 1. I am slammed with my schedule right now, and I think 2 before 1 would be WAYYY easier for me. Is that okay with you @zachglick @JonathonMisiewicz? This PR also immediately fixes the `incfock` issues with `DFJCOSK`, as opposed to punting those fixes down to a future PR.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1253878406
https://github.com/psi4/psi4/pull/2682#issuecomment-1253878406:297,Performance,cache,cached,297,"> Yeah, it's perfectly fine to split things up into multiple PRs. One sensible order I can come up with is:; > ; > 1. Edit the incremental Fock in the derived `DirectJK` class so that it is efficient and maintainable (no SCF iteration counts associated with the object, minimal number of matrices cached on the object, etc.) [some other PR]; > 2. Move this improved incremental Fock to the parent `JK` class. [this PR]; > ; > In a previous comment, I suggested doing away with the cached `J`/`K`/`wK`/`dJ`/`dK`/`dwK` matrices by changing the behavior of the `JK` object so that the buffers aren't cleared between SCF iterations. If you find that difficult to do, I think an acceptable compromise would be to retain those cached matrices, but initialize them in the SCF driver (rather than make them a property of the JK object). Since this PR is already opened, I would actually prefer 2 before 1. I am slammed with my schedule right now, and I think 2 before 1 would be WAYYY easier for me. Is that okay with you @zachglick @JonathonMisiewicz? This PR also immediately fixes the `incfock` issues with `DFJCOSK`, as opposed to punting those fixes down to a future PR.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1253878406
https://github.com/psi4/psi4/pull/2682#issuecomment-1253878406:481,Performance,cache,cached,481,"> Yeah, it's perfectly fine to split things up into multiple PRs. One sensible order I can come up with is:; > ; > 1. Edit the incremental Fock in the derived `DirectJK` class so that it is efficient and maintainable (no SCF iteration counts associated with the object, minimal number of matrices cached on the object, etc.) [some other PR]; > 2. Move this improved incremental Fock to the parent `JK` class. [this PR]; > ; > In a previous comment, I suggested doing away with the cached `J`/`K`/`wK`/`dJ`/`dK`/`dwK` matrices by changing the behavior of the `JK` object so that the buffers aren't cleared between SCF iterations. If you find that difficult to do, I think an acceptable compromise would be to retain those cached matrices, but initialize them in the SCF driver (rather than make them a property of the JK object). Since this PR is already opened, I would actually prefer 2 before 1. I am slammed with my schedule right now, and I think 2 before 1 would be WAYYY easier for me. Is that okay with you @zachglick @JonathonMisiewicz? This PR also immediately fixes the `incfock` issues with `DFJCOSK`, as opposed to punting those fixes down to a future PR.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1253878406
https://github.com/psi4/psi4/pull/2682#issuecomment-1253878406:721,Performance,cache,cached,721,"> Yeah, it's perfectly fine to split things up into multiple PRs. One sensible order I can come up with is:; > ; > 1. Edit the incremental Fock in the derived `DirectJK` class so that it is efficient and maintainable (no SCF iteration counts associated with the object, minimal number of matrices cached on the object, etc.) [some other PR]; > 2. Move this improved incremental Fock to the parent `JK` class. [this PR]; > ; > In a previous comment, I suggested doing away with the cached `J`/`K`/`wK`/`dJ`/`dK`/`dwK` matrices by changing the behavior of the `JK` object so that the buffers aren't cleared between SCF iterations. If you find that difficult to do, I think an acceptable compromise would be to retain those cached matrices, but initialize them in the SCF driver (rather than make them a property of the JK object). Since this PR is already opened, I would actually prefer 2 before 1. I am slammed with my schedule right now, and I think 2 before 1 would be WAYYY easier for me. Is that okay with you @zachglick @JonathonMisiewicz? This PR also immediately fixes the `incfock` issues with `DFJCOSK`, as opposed to punting those fixes down to a future PR.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1253878406
https://github.com/psi4/psi4/pull/2682#issuecomment-1253878406:597,Usability,clear,cleared,597,"> Yeah, it's perfectly fine to split things up into multiple PRs. One sensible order I can come up with is:; > ; > 1. Edit the incremental Fock in the derived `DirectJK` class so that it is efficient and maintainable (no SCF iteration counts associated with the object, minimal number of matrices cached on the object, etc.) [some other PR]; > 2. Move this improved incremental Fock to the parent `JK` class. [this PR]; > ; > In a previous comment, I suggested doing away with the cached `J`/`K`/`wK`/`dJ`/`dK`/`dwK` matrices by changing the behavior of the `JK` object so that the buffers aren't cleared between SCF iterations. If you find that difficult to do, I think an acceptable compromise would be to retain those cached matrices, but initialize them in the SCF driver (rather than make them a property of the JK object). Since this PR is already opened, I would actually prefer 2 before 1. I am slammed with my schedule right now, and I think 2 before 1 would be WAYYY easier for me. Is that okay with you @zachglick @JonathonMisiewicz? This PR also immediately fixes the `incfock` issues with `DFJCOSK`, as opposed to punting those fixes down to a future PR.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1253878406
https://github.com/psi4/psi4/pull/2682#issuecomment-1253891035:1194,Availability,down,down,1194,"> > Yeah, it's perfectly fine to split things up into multiple PRs. One sensible order I can come up with is:; > ; > > ; > ; > > 1. Edit the incremental Fock in the derived `DirectJK` class so that it is efficient and maintainable (no SCF iteration counts associated with the object, minimal number of matrices cached on the object, etc.) [some other PR]; > ; > > 2. Move this improved incremental Fock to the parent `JK` class. [this PR]; > ; > > ; > ; > > In a previous comment, I suggested doing away with the cached `J`/`K`/`wK`/`dJ`/`dK`/`dwK` matrices by changing the behavior of the `JK` object so that the buffers aren't cleared between SCF iterations. If you find that difficult to do, I think an acceptable compromise would be to retain those cached matrices, but initialize them in the SCF driver (rather than make them a property of the JK object).; > ; > ; > ; > Since this PR is already opened, I would actually prefer 2 before 1. I am slammed with my schedule right now, and I think 2 before 1 would be WAYYY easier for me. Is that okay with you @zachglick @JonathonMisiewicz? This PR also immediately fixes the `incfock` issues with `DFJCOSK`, as opposed to punting those fixes down to a future PR. I could also do both 1 and 2 in this PR, if that makes things easier. Which do y'all prefer (2 then 1, or 1 and 2) @zachglick @JonathonMisiewicz ?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1253891035
https://github.com/psi4/psi4/pull/2682#issuecomment-1253891035:204,Energy Efficiency,efficient,efficient,204,"> > Yeah, it's perfectly fine to split things up into multiple PRs. One sensible order I can come up with is:; > ; > > ; > ; > > 1. Edit the incremental Fock in the derived `DirectJK` class so that it is efficient and maintainable (no SCF iteration counts associated with the object, minimal number of matrices cached on the object, etc.) [some other PR]; > ; > > 2. Move this improved incremental Fock to the parent `JK` class. [this PR]; > ; > > ; > ; > > In a previous comment, I suggested doing away with the cached `J`/`K`/`wK`/`dJ`/`dK`/`dwK` matrices by changing the behavior of the `JK` object so that the buffers aren't cleared between SCF iterations. If you find that difficult to do, I think an acceptable compromise would be to retain those cached matrices, but initialize them in the SCF driver (rather than make them a property of the JK object).; > ; > ; > ; > Since this PR is already opened, I would actually prefer 2 before 1. I am slammed with my schedule right now, and I think 2 before 1 would be WAYYY easier for me. Is that okay with you @zachglick @JonathonMisiewicz? This PR also immediately fixes the `incfock` issues with `DFJCOSK`, as opposed to punting those fixes down to a future PR. I could also do both 1 and 2 in this PR, if that makes things easier. Which do y'all prefer (2 then 1, or 1 and 2) @zachglick @JonathonMisiewicz ?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1253891035
https://github.com/psi4/psi4/pull/2682#issuecomment-1253891035:966,Energy Efficiency,schedul,schedule,966,"> > Yeah, it's perfectly fine to split things up into multiple PRs. One sensible order I can come up with is:; > ; > > ; > ; > > 1. Edit the incremental Fock in the derived `DirectJK` class so that it is efficient and maintainable (no SCF iteration counts associated with the object, minimal number of matrices cached on the object, etc.) [some other PR]; > ; > > 2. Move this improved incremental Fock to the parent `JK` class. [this PR]; > ; > > ; > ; > > In a previous comment, I suggested doing away with the cached `J`/`K`/`wK`/`dJ`/`dK`/`dwK` matrices by changing the behavior of the `JK` object so that the buffers aren't cleared between SCF iterations. If you find that difficult to do, I think an acceptable compromise would be to retain those cached matrices, but initialize them in the SCF driver (rather than make them a property of the JK object).; > ; > ; > ; > Since this PR is already opened, I would actually prefer 2 before 1. I am slammed with my schedule right now, and I think 2 before 1 would be WAYYY easier for me. Is that okay with you @zachglick @JonathonMisiewicz? This PR also immediately fixes the `incfock` issues with `DFJCOSK`, as opposed to punting those fixes down to a future PR. I could also do both 1 and 2 in this PR, if that makes things easier. Which do y'all prefer (2 then 1, or 1 and 2) @zachglick @JonathonMisiewicz ?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1253891035
https://github.com/psi4/psi4/pull/2682#issuecomment-1253891035:218,Modifiability,maintainab,maintainable,218,"> > Yeah, it's perfectly fine to split things up into multiple PRs. One sensible order I can come up with is:; > ; > > ; > ; > > 1. Edit the incremental Fock in the derived `DirectJK` class so that it is efficient and maintainable (no SCF iteration counts associated with the object, minimal number of matrices cached on the object, etc.) [some other PR]; > ; > > 2. Move this improved incremental Fock to the parent `JK` class. [this PR]; > ; > > ; > ; > > In a previous comment, I suggested doing away with the cached `J`/`K`/`wK`/`dJ`/`dK`/`dwK` matrices by changing the behavior of the `JK` object so that the buffers aren't cleared between SCF iterations. If you find that difficult to do, I think an acceptable compromise would be to retain those cached matrices, but initialize them in the SCF driver (rather than make them a property of the JK object).; > ; > ; > ; > Since this PR is already opened, I would actually prefer 2 before 1. I am slammed with my schedule right now, and I think 2 before 1 would be WAYYY easier for me. Is that okay with you @zachglick @JonathonMisiewicz? This PR also immediately fixes the `incfock` issues with `DFJCOSK`, as opposed to punting those fixes down to a future PR. I could also do both 1 and 2 in this PR, if that makes things easier. Which do y'all prefer (2 then 1, or 1 and 2) @zachglick @JonathonMisiewicz ?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1253891035
https://github.com/psi4/psi4/pull/2682#issuecomment-1253891035:311,Performance,cache,cached,311,"> > Yeah, it's perfectly fine to split things up into multiple PRs. One sensible order I can come up with is:; > ; > > ; > ; > > 1. Edit the incremental Fock in the derived `DirectJK` class so that it is efficient and maintainable (no SCF iteration counts associated with the object, minimal number of matrices cached on the object, etc.) [some other PR]; > ; > > 2. Move this improved incremental Fock to the parent `JK` class. [this PR]; > ; > > ; > ; > > In a previous comment, I suggested doing away with the cached `J`/`K`/`wK`/`dJ`/`dK`/`dwK` matrices by changing the behavior of the `JK` object so that the buffers aren't cleared between SCF iterations. If you find that difficult to do, I think an acceptable compromise would be to retain those cached matrices, but initialize them in the SCF driver (rather than make them a property of the JK object).; > ; > ; > ; > Since this PR is already opened, I would actually prefer 2 before 1. I am slammed with my schedule right now, and I think 2 before 1 would be WAYYY easier for me. Is that okay with you @zachglick @JonathonMisiewicz? This PR also immediately fixes the `incfock` issues with `DFJCOSK`, as opposed to punting those fixes down to a future PR. I could also do both 1 and 2 in this PR, if that makes things easier. Which do y'all prefer (2 then 1, or 1 and 2) @zachglick @JonathonMisiewicz ?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1253891035
https://github.com/psi4/psi4/pull/2682#issuecomment-1253891035:513,Performance,cache,cached,513,"> > Yeah, it's perfectly fine to split things up into multiple PRs. One sensible order I can come up with is:; > ; > > ; > ; > > 1. Edit the incremental Fock in the derived `DirectJK` class so that it is efficient and maintainable (no SCF iteration counts associated with the object, minimal number of matrices cached on the object, etc.) [some other PR]; > ; > > 2. Move this improved incremental Fock to the parent `JK` class. [this PR]; > ; > > ; > ; > > In a previous comment, I suggested doing away with the cached `J`/`K`/`wK`/`dJ`/`dK`/`dwK` matrices by changing the behavior of the `JK` object so that the buffers aren't cleared between SCF iterations. If you find that difficult to do, I think an acceptable compromise would be to retain those cached matrices, but initialize them in the SCF driver (rather than make them a property of the JK object).; > ; > ; > ; > Since this PR is already opened, I would actually prefer 2 before 1. I am slammed with my schedule right now, and I think 2 before 1 would be WAYYY easier for me. Is that okay with you @zachglick @JonathonMisiewicz? This PR also immediately fixes the `incfock` issues with `DFJCOSK`, as opposed to punting those fixes down to a future PR. I could also do both 1 and 2 in this PR, if that makes things easier. Which do y'all prefer (2 then 1, or 1 and 2) @zachglick @JonathonMisiewicz ?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1253891035
https://github.com/psi4/psi4/pull/2682#issuecomment-1253891035:753,Performance,cache,cached,753,"> > Yeah, it's perfectly fine to split things up into multiple PRs. One sensible order I can come up with is:; > ; > > ; > ; > > 1. Edit the incremental Fock in the derived `DirectJK` class so that it is efficient and maintainable (no SCF iteration counts associated with the object, minimal number of matrices cached on the object, etc.) [some other PR]; > ; > > 2. Move this improved incremental Fock to the parent `JK` class. [this PR]; > ; > > ; > ; > > In a previous comment, I suggested doing away with the cached `J`/`K`/`wK`/`dJ`/`dK`/`dwK` matrices by changing the behavior of the `JK` object so that the buffers aren't cleared between SCF iterations. If you find that difficult to do, I think an acceptable compromise would be to retain those cached matrices, but initialize them in the SCF driver (rather than make them a property of the JK object).; > ; > ; > ; > Since this PR is already opened, I would actually prefer 2 before 1. I am slammed with my schedule right now, and I think 2 before 1 would be WAYYY easier for me. Is that okay with you @zachglick @JonathonMisiewicz? This PR also immediately fixes the `incfock` issues with `DFJCOSK`, as opposed to punting those fixes down to a future PR. I could also do both 1 and 2 in this PR, if that makes things easier. Which do y'all prefer (2 then 1, or 1 and 2) @zachglick @JonathonMisiewicz ?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1253891035
https://github.com/psi4/psi4/pull/2682#issuecomment-1253891035:629,Usability,clear,cleared,629,"> > Yeah, it's perfectly fine to split things up into multiple PRs. One sensible order I can come up with is:; > ; > > ; > ; > > 1. Edit the incremental Fock in the derived `DirectJK` class so that it is efficient and maintainable (no SCF iteration counts associated with the object, minimal number of matrices cached on the object, etc.) [some other PR]; > ; > > 2. Move this improved incremental Fock to the parent `JK` class. [this PR]; > ; > > ; > ; > > In a previous comment, I suggested doing away with the cached `J`/`K`/`wK`/`dJ`/`dK`/`dwK` matrices by changing the behavior of the `JK` object so that the buffers aren't cleared between SCF iterations. If you find that difficult to do, I think an acceptable compromise would be to retain those cached matrices, but initialize them in the SCF driver (rather than make them a property of the JK object).; > ; > ; > ; > Since this PR is already opened, I would actually prefer 2 before 1. I am slammed with my schedule right now, and I think 2 before 1 would be WAYYY easier for me. Is that okay with you @zachglick @JonathonMisiewicz? This PR also immediately fixes the `incfock` issues with `DFJCOSK`, as opposed to punting those fixes down to a future PR. I could also do both 1 and 2 in this PR, if that makes things easier. Which do y'all prefer (2 then 1, or 1 and 2) @zachglick @JonathonMisiewicz ?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1253891035
https://github.com/psi4/psi4/pull/2682#issuecomment-1303625951:298,Integrability,rout,routine,298,"> @zachglick, thoughts? I strongly preferred your plan before, but it wasn't something I was going to insist on. I'll drop a comment on this matter for for an extra perspective. The original plan is quite fine, and many good points were made regarding improvements to efficiency within the Incfock routine. However, the original plan proposed completes the unified Incfock formalism over two PRs, and the impression I get is that the standardization of the Incfock process is really happening in Step 2. The CompositeJK pilot implementation (i.e., the unification of DFJCOSK and DFJLinK + CompositeJK front end) really only needs Step 2 to proceed, then, while Step 1 of the proposed Incfock work (i.e., the improvement of the Incfock process itself) could likely be done independently from CompositeJK. Basically, my thought is that, by switching Steps 1 and 2 of the original proposed plan for Incfock, that would allow the second CompositeJK PR to be put into Psi4 more quickly and allow parallel development of CompositeJK and the JK Incfock formalism. I am overall fine with either ordering for Incfock PR steps, but I figured I would at least bring this up.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1303625951
https://github.com/psi4/psi4/pull/2682#issuecomment-1303661796:307,Integrability,rout,routine,307,"> > @zachglick, thoughts? I strongly preferred your plan before, but it wasn't something I was going to insist on.; > ; > I'll drop a comment on this matter for for an extra perspective. The original plan is quite fine, and many good points were made regarding improvements to efficiency within the Incfock routine. However, the original plan proposed completes the unified Incfock formalism over two PRs, and the impression I get is that the standardization of the Incfock process is really happening in Step 2. The CompositeJK pilot implementation (i.e., the unification of DFJCOSK and DFJLinK + CompositeJK front end) really only needs Step 2 to proceed, then, while Step 1 of the proposed Incfock work (i.e., the improvement of the Incfock process itself) could likely be done independently from CompositeJK. Basically, my thought is that, by switching Steps 1 and 2 of the original proposed plan for Incfock, that would allow the second CompositeJK PR to be put into Psi4 more quickly and allow parallel development of CompositeJK and the JK Incfock formalism.; > ; > I am overall fine with either ordering for Incfock PR steps, but I figured I would at least bring this up. Thinking about this a little more, one may be able to do the Incfock development parallel to CompositeJK in the ordering suggested in Zach's original plan. Essentially, one would modify DFJLinK to use DFJCOSK's Incfock scheme, which gives the two a unified Incfock among themselves and would allow for continuation of CompositeJK. Then, the same Incfock used in DFJCOSK would be added to DirectJK. And finally, the Incfock could be added to the JK class. This adds an extra PR to the original plan (DFJLinK Incfock modification), but both maintains Zach's original PR ordering and allows for parallel development of CompositeJK with Incfock modifications. Thoughts?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1303661796
https://github.com/psi4/psi4/pull/2682#issuecomment-1503230492:486,Deployability,update,updated,486,"Taking another look at this PR, the IncFock used here, uses a large number of matrix variables - separate matrices for the previous, current, and difference matrices for all of D, J, K, and wK. This particular IncFock formalism was replaced in the PR line of https://github.com/psi4/psi4/pull/2792, https://github.com/psi4/psi4/pull/2808, and https://github.com/psi4/psi4/pull/2816. So before this PR gets merged in, the IncFock formalism moved into the JK class in this PR needs to be updated to match.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1503230492
https://github.com/psi4/psi4/pull/2682#issuecomment-1503230492:85,Modifiability,variab,variables,85,"Taking another look at this PR, the IncFock used here, uses a large number of matrix variables - separate matrices for the previous, current, and difference matrices for all of D, J, K, and wK. This particular IncFock formalism was replaced in the PR line of https://github.com/psi4/psi4/pull/2792, https://github.com/psi4/psi4/pull/2808, and https://github.com/psi4/psi4/pull/2816. So before this PR gets merged in, the IncFock formalism moved into the JK class in this PR needs to be updated to match.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2682#issuecomment-1503230492
https://github.com/psi4/psi4/issues/2683#issuecomment-1214284697:0,Deployability,Install,Installing,0,"Installing `share/` files into `<builddir>/stage` is normal from https://github.com/psi4/psi4/blob/master/psi4/CMakeLists.txt#L354-L358 . If the `%%DATADIR%%` is literal, could you be not getting `CMAKE_INSTALL_DATADIR` set correctly from `GNUInstallDirs`?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2683#issuecomment-1214284697
https://github.com/psi4/psi4/issues/2683#issuecomment-1214286601:82,Availability,error,error,82,"``` CMAKE_INSTALL_DATADIR=share```. %%DATADIR%% is not a literal, this is just an error message with substituted tokens. ```%%DATADIR%%=/usr/local/share/psi4```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2683#issuecomment-1214286601
https://github.com/psi4/psi4/issues/2683#issuecomment-1214286601:88,Integrability,message,message,88,"``` CMAKE_INSTALL_DATADIR=share```. %%DATADIR%% is not a literal, this is just an error message with substituted tokens. ```%%DATADIR%%=/usr/local/share/psi4```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2683#issuecomment-1214286601
https://github.com/psi4/psi4/issues/2683#issuecomment-1214289555:306,Availability,error,error,306,"Are you able to make the internal stage directory optional based on a cmake option?. The internal stage directory adds complexity without providing any benefit - with or without it the files should be installed into the real stage directory, but internal stage directory makes the process more complex and error prone.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2683#issuecomment-1214289555
https://github.com/psi4/psi4/issues/2683#issuecomment-1214289555:201,Deployability,install,installed,201,"Are you able to make the internal stage directory optional based on a cmake option?. The internal stage directory adds complexity without providing any benefit - with or without it the files should be installed into the real stage directory, but internal stage directory makes the process more complex and error prone.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2683#issuecomment-1214289555
https://github.com/psi4/psi4/issues/2683#issuecomment-1214291922:594,Deployability,install,installs,594,"> Your internal stage directory isn't copied properly into the real stage directory for some reason. That's strange -- it's a pretty straightforward copy, https://github.com/psi4/psi4/blob/master/CMakeLists.txt#L315-L318 from internal <builddir>/stage/ to final $PREFIX. Though Windows requires a little more https://github.com/psi4/psi4/blob/master/conda/win/meta.yaml#L32https://github.com/psi4/psi4/blob/master/conda/win/meta.yaml#L32. > Are you able to make the internal stage directory optional based on a cmake option?. Afraid not. In the CMake superbuild, that's where all the component installs accumulate. And devs like it because they never need install. The internal stage is defined here https://github.com/psi4/psi4/blob/master/CMakeLists.txt#L204 , and you could try manipulating that.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2683#issuecomment-1214291922
https://github.com/psi4/psi4/issues/2683#issuecomment-1214291922:656,Deployability,install,install,656,"> Your internal stage directory isn't copied properly into the real stage directory for some reason. That's strange -- it's a pretty straightforward copy, https://github.com/psi4/psi4/blob/master/CMakeLists.txt#L315-L318 from internal <builddir>/stage/ to final $PREFIX. Though Windows requires a little more https://github.com/psi4/psi4/blob/master/conda/win/meta.yaml#L32https://github.com/psi4/psi4/blob/master/conda/win/meta.yaml#L32. > Are you able to make the internal stage directory optional based on a cmake option?. Afraid not. In the CMake superbuild, that's where all the component installs accumulate. And devs like it because they never need install. The internal stage is defined here https://github.com/psi4/psi4/blob/master/CMakeLists.txt#L204 , and you could try manipulating that.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2683#issuecomment-1214291922
https://github.com/psi4/psi4/issues/2683#issuecomment-1214418655:140,Integrability,depend,dependencies,140,"> What version of cmake do you use?. Personally, I use a near-latest. The Psi4 minimum is 3.15. We could go higher, but at least one of the dependencies doesn't want to go beyond 3.16 until Ubuntu does. If you happen to be thinking of FetchContent instead of ExternalProject, I'm not keen on a rewrite, and we do have a couple deps (python ones) that aren't under CMake control. In what way is the copy from `<builddir>/objdir/stage` to `CMAKE_INSTALL_PREFIX` going awry?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2683#issuecomment-1214418655
https://github.com/psi4/psi4/issues/2683#issuecomment-1214418655:294,Modifiability,rewrite,rewrite,294,"> What version of cmake do you use?. Personally, I use a near-latest. The Psi4 minimum is 3.15. We could go higher, but at least one of the dependencies doesn't want to go beyond 3.16 until Ubuntu does. If you happen to be thinking of FetchContent instead of ExternalProject, I'm not keen on a rewrite, and we do have a couple deps (python ones) that aren't under CMake control. In what way is the copy from `<builddir>/objdir/stage` to `CMAKE_INSTALL_PREFIX` going awry?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2683#issuecomment-1214418655
https://github.com/psi4/psi4/issues/2683#issuecomment-1214425842:95,Deployability,install,installs,95,"> In what way is the copy from <builddir>/objdir/stage to CMAKE_INSTALL_PREFIX going awry?. It installs the files into the inner stage directory location, see above files that retained their directory ```/wrkdirs/usr/ports/science/psi4/work/.build/stage```.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2683#issuecomment-1214425842
https://github.com/psi4/psi4/issues/2683#issuecomment-1214426101:171,Deployability,install,installing,171,"The problem arises when build directory is not under $PREFIX (=/usr/local). Did you try building in some directory not under ```$PREFIX``` (for example in /tmp), and then installing into an external stage directory?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2683#issuecomment-1214426101
https://github.com/psi4/psi4/issues/2683#issuecomment-1215839867:162,Deployability,install,installs,162,"I've just tested the following:; * cloned to `/external_disk/gits/psi4`; * from there, configured to `/tmp` via `cmake -S. ... -DCMAKE_INSTALL_PREFIX=/home/auser/installs/psi4 -B/tmp/compile-psi4`; * build in `/tmp/compile-psi4` via `cmake --build .`; * test internal install via `/tmp/compile-psi4/stage/bin/psi4 --test`; * install via `cmake --build . --target install` to `/home/auser/installs/psi4`; * test external install via `/home/auser/installs/psi4/bin/psi4 --test`. That spans an external disk, an account home, and `/tmp/`, and I don't observe the mis-installed quadratures files you report. You are using CMake variables, not environment variables to configure this, right? Do you have a link to the recipe you're using? This is what I use for conda, if that's any help. https://github.com/psi4/psi4meta/blob/master/conda-recipes/psi4-multiout/build.sh#L120",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2683#issuecomment-1215839867
https://github.com/psi4/psi4/issues/2683#issuecomment-1215839867:268,Deployability,install,install,268,"I've just tested the following:; * cloned to `/external_disk/gits/psi4`; * from there, configured to `/tmp` via `cmake -S. ... -DCMAKE_INSTALL_PREFIX=/home/auser/installs/psi4 -B/tmp/compile-psi4`; * build in `/tmp/compile-psi4` via `cmake --build .`; * test internal install via `/tmp/compile-psi4/stage/bin/psi4 --test`; * install via `cmake --build . --target install` to `/home/auser/installs/psi4`; * test external install via `/home/auser/installs/psi4/bin/psi4 --test`. That spans an external disk, an account home, and `/tmp/`, and I don't observe the mis-installed quadratures files you report. You are using CMake variables, not environment variables to configure this, right? Do you have a link to the recipe you're using? This is what I use for conda, if that's any help. https://github.com/psi4/psi4meta/blob/master/conda-recipes/psi4-multiout/build.sh#L120",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2683#issuecomment-1215839867
https://github.com/psi4/psi4/issues/2683#issuecomment-1215839867:325,Deployability,install,install,325,"I've just tested the following:; * cloned to `/external_disk/gits/psi4`; * from there, configured to `/tmp` via `cmake -S. ... -DCMAKE_INSTALL_PREFIX=/home/auser/installs/psi4 -B/tmp/compile-psi4`; * build in `/tmp/compile-psi4` via `cmake --build .`; * test internal install via `/tmp/compile-psi4/stage/bin/psi4 --test`; * install via `cmake --build . --target install` to `/home/auser/installs/psi4`; * test external install via `/home/auser/installs/psi4/bin/psi4 --test`. That spans an external disk, an account home, and `/tmp/`, and I don't observe the mis-installed quadratures files you report. You are using CMake variables, not environment variables to configure this, right? Do you have a link to the recipe you're using? This is what I use for conda, if that's any help. https://github.com/psi4/psi4meta/blob/master/conda-recipes/psi4-multiout/build.sh#L120",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2683#issuecomment-1215839867
https://github.com/psi4/psi4/issues/2683#issuecomment-1215839867:363,Deployability,install,install,363,"I've just tested the following:; * cloned to `/external_disk/gits/psi4`; * from there, configured to `/tmp` via `cmake -S. ... -DCMAKE_INSTALL_PREFIX=/home/auser/installs/psi4 -B/tmp/compile-psi4`; * build in `/tmp/compile-psi4` via `cmake --build .`; * test internal install via `/tmp/compile-psi4/stage/bin/psi4 --test`; * install via `cmake --build . --target install` to `/home/auser/installs/psi4`; * test external install via `/home/auser/installs/psi4/bin/psi4 --test`. That spans an external disk, an account home, and `/tmp/`, and I don't observe the mis-installed quadratures files you report. You are using CMake variables, not environment variables to configure this, right? Do you have a link to the recipe you're using? This is what I use for conda, if that's any help. https://github.com/psi4/psi4meta/blob/master/conda-recipes/psi4-multiout/build.sh#L120",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2683#issuecomment-1215839867
https://github.com/psi4/psi4/issues/2683#issuecomment-1215839867:388,Deployability,install,installs,388,"I've just tested the following:; * cloned to `/external_disk/gits/psi4`; * from there, configured to `/tmp` via `cmake -S. ... -DCMAKE_INSTALL_PREFIX=/home/auser/installs/psi4 -B/tmp/compile-psi4`; * build in `/tmp/compile-psi4` via `cmake --build .`; * test internal install via `/tmp/compile-psi4/stage/bin/psi4 --test`; * install via `cmake --build . --target install` to `/home/auser/installs/psi4`; * test external install via `/home/auser/installs/psi4/bin/psi4 --test`. That spans an external disk, an account home, and `/tmp/`, and I don't observe the mis-installed quadratures files you report. You are using CMake variables, not environment variables to configure this, right? Do you have a link to the recipe you're using? This is what I use for conda, if that's any help. https://github.com/psi4/psi4meta/blob/master/conda-recipes/psi4-multiout/build.sh#L120",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2683#issuecomment-1215839867
https://github.com/psi4/psi4/issues/2683#issuecomment-1215839867:420,Deployability,install,install,420,"I've just tested the following:; * cloned to `/external_disk/gits/psi4`; * from there, configured to `/tmp` via `cmake -S. ... -DCMAKE_INSTALL_PREFIX=/home/auser/installs/psi4 -B/tmp/compile-psi4`; * build in `/tmp/compile-psi4` via `cmake --build .`; * test internal install via `/tmp/compile-psi4/stage/bin/psi4 --test`; * install via `cmake --build . --target install` to `/home/auser/installs/psi4`; * test external install via `/home/auser/installs/psi4/bin/psi4 --test`. That spans an external disk, an account home, and `/tmp/`, and I don't observe the mis-installed quadratures files you report. You are using CMake variables, not environment variables to configure this, right? Do you have a link to the recipe you're using? This is what I use for conda, if that's any help. https://github.com/psi4/psi4meta/blob/master/conda-recipes/psi4-multiout/build.sh#L120",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2683#issuecomment-1215839867
https://github.com/psi4/psi4/issues/2683#issuecomment-1215839867:445,Deployability,install,installs,445,"I've just tested the following:; * cloned to `/external_disk/gits/psi4`; * from there, configured to `/tmp` via `cmake -S. ... -DCMAKE_INSTALL_PREFIX=/home/auser/installs/psi4 -B/tmp/compile-psi4`; * build in `/tmp/compile-psi4` via `cmake --build .`; * test internal install via `/tmp/compile-psi4/stage/bin/psi4 --test`; * install via `cmake --build . --target install` to `/home/auser/installs/psi4`; * test external install via `/home/auser/installs/psi4/bin/psi4 --test`. That spans an external disk, an account home, and `/tmp/`, and I don't observe the mis-installed quadratures files you report. You are using CMake variables, not environment variables to configure this, right? Do you have a link to the recipe you're using? This is what I use for conda, if that's any help. https://github.com/psi4/psi4meta/blob/master/conda-recipes/psi4-multiout/build.sh#L120",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2683#issuecomment-1215839867
https://github.com/psi4/psi4/issues/2683#issuecomment-1215839867:564,Deployability,install,installed,564,"I've just tested the following:; * cloned to `/external_disk/gits/psi4`; * from there, configured to `/tmp` via `cmake -S. ... -DCMAKE_INSTALL_PREFIX=/home/auser/installs/psi4 -B/tmp/compile-psi4`; * build in `/tmp/compile-psi4` via `cmake --build .`; * test internal install via `/tmp/compile-psi4/stage/bin/psi4 --test`; * install via `cmake --build . --target install` to `/home/auser/installs/psi4`; * test external install via `/home/auser/installs/psi4/bin/psi4 --test`. That spans an external disk, an account home, and `/tmp/`, and I don't observe the mis-installed quadratures files you report. You are using CMake variables, not environment variables to configure this, right? Do you have a link to the recipe you're using? This is what I use for conda, if that's any help. https://github.com/psi4/psi4meta/blob/master/conda-recipes/psi4-multiout/build.sh#L120",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2683#issuecomment-1215839867
https://github.com/psi4/psi4/issues/2683#issuecomment-1215839867:87,Modifiability,config,configured,87,"I've just tested the following:; * cloned to `/external_disk/gits/psi4`; * from there, configured to `/tmp` via `cmake -S. ... -DCMAKE_INSTALL_PREFIX=/home/auser/installs/psi4 -B/tmp/compile-psi4`; * build in `/tmp/compile-psi4` via `cmake --build .`; * test internal install via `/tmp/compile-psi4/stage/bin/psi4 --test`; * install via `cmake --build . --target install` to `/home/auser/installs/psi4`; * test external install via `/home/auser/installs/psi4/bin/psi4 --test`. That spans an external disk, an account home, and `/tmp/`, and I don't observe the mis-installed quadratures files you report. You are using CMake variables, not environment variables to configure this, right? Do you have a link to the recipe you're using? This is what I use for conda, if that's any help. https://github.com/psi4/psi4meta/blob/master/conda-recipes/psi4-multiout/build.sh#L120",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2683#issuecomment-1215839867
https://github.com/psi4/psi4/issues/2683#issuecomment-1215839867:624,Modifiability,variab,variables,624,"I've just tested the following:; * cloned to `/external_disk/gits/psi4`; * from there, configured to `/tmp` via `cmake -S. ... -DCMAKE_INSTALL_PREFIX=/home/auser/installs/psi4 -B/tmp/compile-psi4`; * build in `/tmp/compile-psi4` via `cmake --build .`; * test internal install via `/tmp/compile-psi4/stage/bin/psi4 --test`; * install via `cmake --build . --target install` to `/home/auser/installs/psi4`; * test external install via `/home/auser/installs/psi4/bin/psi4 --test`. That spans an external disk, an account home, and `/tmp/`, and I don't observe the mis-installed quadratures files you report. You are using CMake variables, not environment variables to configure this, right? Do you have a link to the recipe you're using? This is what I use for conda, if that's any help. https://github.com/psi4/psi4meta/blob/master/conda-recipes/psi4-multiout/build.sh#L120",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2683#issuecomment-1215839867
https://github.com/psi4/psi4/issues/2683#issuecomment-1215839867:651,Modifiability,variab,variables,651,"I've just tested the following:; * cloned to `/external_disk/gits/psi4`; * from there, configured to `/tmp` via `cmake -S. ... -DCMAKE_INSTALL_PREFIX=/home/auser/installs/psi4 -B/tmp/compile-psi4`; * build in `/tmp/compile-psi4` via `cmake --build .`; * test internal install via `/tmp/compile-psi4/stage/bin/psi4 --test`; * install via `cmake --build . --target install` to `/home/auser/installs/psi4`; * test external install via `/home/auser/installs/psi4/bin/psi4 --test`. That spans an external disk, an account home, and `/tmp/`, and I don't observe the mis-installed quadratures files you report. You are using CMake variables, not environment variables to configure this, right? Do you have a link to the recipe you're using? This is what I use for conda, if that's any help. https://github.com/psi4/psi4meta/blob/master/conda-recipes/psi4-multiout/build.sh#L120",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2683#issuecomment-1215839867
https://github.com/psi4/psi4/issues/2683#issuecomment-1215839867:664,Modifiability,config,configure,664,"I've just tested the following:; * cloned to `/external_disk/gits/psi4`; * from there, configured to `/tmp` via `cmake -S. ... -DCMAKE_INSTALL_PREFIX=/home/auser/installs/psi4 -B/tmp/compile-psi4`; * build in `/tmp/compile-psi4` via `cmake --build .`; * test internal install via `/tmp/compile-psi4/stage/bin/psi4 --test`; * install via `cmake --build . --target install` to `/home/auser/installs/psi4`; * test external install via `/home/auser/installs/psi4/bin/psi4 --test`. That spans an external disk, an account home, and `/tmp/`, and I don't observe the mis-installed quadratures files you report. You are using CMake variables, not environment variables to configure this, right? Do you have a link to the recipe you're using? This is what I use for conda, if that's any help. https://github.com/psi4/psi4meta/blob/master/conda-recipes/psi4-multiout/build.sh#L120",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2683#issuecomment-1215839867
https://github.com/psi4/psi4/issues/2683#issuecomment-1215839867:10,Testability,test,tested,10,"I've just tested the following:; * cloned to `/external_disk/gits/psi4`; * from there, configured to `/tmp` via `cmake -S. ... -DCMAKE_INSTALL_PREFIX=/home/auser/installs/psi4 -B/tmp/compile-psi4`; * build in `/tmp/compile-psi4` via `cmake --build .`; * test internal install via `/tmp/compile-psi4/stage/bin/psi4 --test`; * install via `cmake --build . --target install` to `/home/auser/installs/psi4`; * test external install via `/home/auser/installs/psi4/bin/psi4 --test`. That spans an external disk, an account home, and `/tmp/`, and I don't observe the mis-installed quadratures files you report. You are using CMake variables, not environment variables to configure this, right? Do you have a link to the recipe you're using? This is what I use for conda, if that's any help. https://github.com/psi4/psi4meta/blob/master/conda-recipes/psi4-multiout/build.sh#L120",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2683#issuecomment-1215839867
https://github.com/psi4/psi4/issues/2683#issuecomment-1215839867:254,Testability,test,test,254,"I've just tested the following:; * cloned to `/external_disk/gits/psi4`; * from there, configured to `/tmp` via `cmake -S. ... -DCMAKE_INSTALL_PREFIX=/home/auser/installs/psi4 -B/tmp/compile-psi4`; * build in `/tmp/compile-psi4` via `cmake --build .`; * test internal install via `/tmp/compile-psi4/stage/bin/psi4 --test`; * install via `cmake --build . --target install` to `/home/auser/installs/psi4`; * test external install via `/home/auser/installs/psi4/bin/psi4 --test`. That spans an external disk, an account home, and `/tmp/`, and I don't observe the mis-installed quadratures files you report. You are using CMake variables, not environment variables to configure this, right? Do you have a link to the recipe you're using? This is what I use for conda, if that's any help. https://github.com/psi4/psi4meta/blob/master/conda-recipes/psi4-multiout/build.sh#L120",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2683#issuecomment-1215839867
https://github.com/psi4/psi4/issues/2683#issuecomment-1215839867:316,Testability,test,test,316,"I've just tested the following:; * cloned to `/external_disk/gits/psi4`; * from there, configured to `/tmp` via `cmake -S. ... -DCMAKE_INSTALL_PREFIX=/home/auser/installs/psi4 -B/tmp/compile-psi4`; * build in `/tmp/compile-psi4` via `cmake --build .`; * test internal install via `/tmp/compile-psi4/stage/bin/psi4 --test`; * install via `cmake --build . --target install` to `/home/auser/installs/psi4`; * test external install via `/home/auser/installs/psi4/bin/psi4 --test`. That spans an external disk, an account home, and `/tmp/`, and I don't observe the mis-installed quadratures files you report. You are using CMake variables, not environment variables to configure this, right? Do you have a link to the recipe you're using? This is what I use for conda, if that's any help. https://github.com/psi4/psi4meta/blob/master/conda-recipes/psi4-multiout/build.sh#L120",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2683#issuecomment-1215839867
https://github.com/psi4/psi4/issues/2683#issuecomment-1215839867:406,Testability,test,test,406,"I've just tested the following:; * cloned to `/external_disk/gits/psi4`; * from there, configured to `/tmp` via `cmake -S. ... -DCMAKE_INSTALL_PREFIX=/home/auser/installs/psi4 -B/tmp/compile-psi4`; * build in `/tmp/compile-psi4` via `cmake --build .`; * test internal install via `/tmp/compile-psi4/stage/bin/psi4 --test`; * install via `cmake --build . --target install` to `/home/auser/installs/psi4`; * test external install via `/home/auser/installs/psi4/bin/psi4 --test`. That spans an external disk, an account home, and `/tmp/`, and I don't observe the mis-installed quadratures files you report. You are using CMake variables, not environment variables to configure this, right? Do you have a link to the recipe you're using? This is what I use for conda, if that's any help. https://github.com/psi4/psi4meta/blob/master/conda-recipes/psi4-multiout/build.sh#L120",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2683#issuecomment-1215839867
https://github.com/psi4/psi4/issues/2683#issuecomment-1215839867:470,Testability,test,test,470,"I've just tested the following:; * cloned to `/external_disk/gits/psi4`; * from there, configured to `/tmp` via `cmake -S. ... -DCMAKE_INSTALL_PREFIX=/home/auser/installs/psi4 -B/tmp/compile-psi4`; * build in `/tmp/compile-psi4` via `cmake --build .`; * test internal install via `/tmp/compile-psi4/stage/bin/psi4 --test`; * install via `cmake --build . --target install` to `/home/auser/installs/psi4`; * test external install via `/home/auser/installs/psi4/bin/psi4 --test`. That spans an external disk, an account home, and `/tmp/`, and I don't observe the mis-installed quadratures files you report. You are using CMake variables, not environment variables to configure this, right? Do you have a link to the recipe you're using? This is what I use for conda, if that's any help. https://github.com/psi4/psi4meta/blob/master/conda-recipes/psi4-multiout/build.sh#L120",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2683#issuecomment-1215839867
https://github.com/psi4/psi4/pull/2684#issuecomment-1481668545:15,Testability,test,tests,15,"PR rebased, CI tests are passing.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2684#issuecomment-1481668545
https://github.com/psi4/psi4/pull/2684#issuecomment-1499733138:427,Deployability,release,release,427,"If I'm remembering where I left off and performing the diffs correctly, there's no more changes to be made to those 4 array/tensor files in the dfocc saga. And none of the yet-to-be-PRd code uses `davidson`, `cdsyev`, `cdgesv`, `lineq_flin`, or `lineq_pople`. There is new code with `diagonalize`, though, listed below. If the changes in this PR don't interfere with the calls below, or we can work around them, I think we can release the hold and merge this. Thanks for your patience, @TiborGY. ```; # HciA is Tensor2d (or sharedptr to it); cis.cc: HciA->diagonalize(CciA, EciA, cutoff);. # G is Tensor2d; davidson.cc: G->diagonalize(init_dim, alpha, lambda, 1e-12, true);; davidson.cc: G->diagonalize(L, alpha, lambda, 1e-12, true);; davidson.cc: G->diagonalize(init_dim, alpha, lambda, 1e-12, true);; davidson.cc: G->diagonalize(L, alpha, lambda, 1e-12, true);; davidson.cc: G->diagonalize(L, alpha, lambda, 1e-12, true);. # Gamma* and Fock* are Tensor2d; fno.cc: Gamma_->diagonalize(Tvv_, diag_n_, cutoff_, false);; fno.cc: FockfvA->diagonalize(UfvA, eigfvA, cutoff_);; fno.cc: FockvvA->diagonalize(UvvA, eigvvA, cutoff_);; fno.cc: GammaA_->diagonalize(TvvA_, diag_nA_, cutoff_, false);; fno.cc: GammaB_->diagonalize(TvvB_, diag_nB_, cutoff_, false);; fno.cc: FockfvA->diagonalize(UfvA, eigfvA, cutoff_);; fno.cc: FockvvA->diagonalize(UvvA, eigvvA, cutoff_);; fno.cc: FockfvB->diagonalize(UfvB, eigfvB, cutoff_);; fno.cc: FockvvB->diagonalize(UvvB, eigvvB, cutoff_);. # a_opdm, etc. are Matrix; occ_iterations.cc: a_opdm->diagonalize(aevecs, aevals, descending);; occ_iterations.cc: a_opdm->diagonalize(aevecs, aevals, descending);; occ_iterations.cc: b_opdm->diagonalize(bevecs, bevals, descending);. # FockooA, etc. are Tensor2d; semi_canonic.cc: FockooA->diagonalize(UooA, eigooA, cutoff);; semi_canonic.cc: FockvvA->diagonalize(UvvA, eigvvA, cutoff);; semi_canonic.cc: FockooB->diagonalize(UooB, eigooB, cutoff);; semi_canonic.cc: FockvvB->diagonalize(UvvB, eigvvB, cutoff);; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2684#issuecomment-1499733138
https://github.com/psi4/psi4/pull/2684#issuecomment-1499733138:40,Performance,perform,performing,40,"If I'm remembering where I left off and performing the diffs correctly, there's no more changes to be made to those 4 array/tensor files in the dfocc saga. And none of the yet-to-be-PRd code uses `davidson`, `cdsyev`, `cdgesv`, `lineq_flin`, or `lineq_pople`. There is new code with `diagonalize`, though, listed below. If the changes in this PR don't interfere with the calls below, or we can work around them, I think we can release the hold and merge this. Thanks for your patience, @TiborGY. ```; # HciA is Tensor2d (or sharedptr to it); cis.cc: HciA->diagonalize(CciA, EciA, cutoff);. # G is Tensor2d; davidson.cc: G->diagonalize(init_dim, alpha, lambda, 1e-12, true);; davidson.cc: G->diagonalize(L, alpha, lambda, 1e-12, true);; davidson.cc: G->diagonalize(init_dim, alpha, lambda, 1e-12, true);; davidson.cc: G->diagonalize(L, alpha, lambda, 1e-12, true);; davidson.cc: G->diagonalize(L, alpha, lambda, 1e-12, true);. # Gamma* and Fock* are Tensor2d; fno.cc: Gamma_->diagonalize(Tvv_, diag_n_, cutoff_, false);; fno.cc: FockfvA->diagonalize(UfvA, eigfvA, cutoff_);; fno.cc: FockvvA->diagonalize(UvvA, eigvvA, cutoff_);; fno.cc: GammaA_->diagonalize(TvvA_, diag_nA_, cutoff_, false);; fno.cc: GammaB_->diagonalize(TvvB_, diag_nB_, cutoff_, false);; fno.cc: FockfvA->diagonalize(UfvA, eigfvA, cutoff_);; fno.cc: FockvvA->diagonalize(UvvA, eigvvA, cutoff_);; fno.cc: FockfvB->diagonalize(UfvB, eigfvB, cutoff_);; fno.cc: FockvvB->diagonalize(UvvB, eigvvB, cutoff_);. # a_opdm, etc. are Matrix; occ_iterations.cc: a_opdm->diagonalize(aevecs, aevals, descending);; occ_iterations.cc: a_opdm->diagonalize(aevecs, aevals, descending);; occ_iterations.cc: b_opdm->diagonalize(bevecs, bevals, descending);. # FockooA, etc. are Tensor2d; semi_canonic.cc: FockooA->diagonalize(UooA, eigooA, cutoff);; semi_canonic.cc: FockvvA->diagonalize(UvvA, eigvvA, cutoff);; semi_canonic.cc: FockooB->diagonalize(UooB, eigooB, cutoff);; semi_canonic.cc: FockvvB->diagonalize(UvvB, eigvvB, cutoff);; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2684#issuecomment-1499733138
https://github.com/psi4/psi4/pull/2684#issuecomment-1500354378:677,Integrability,interface,interfaces,677,"Thanks for looking into it. It looks like none of these involve `Array2d::diagonalize`, so this PR is good on that front. This PR does not touch `Matrix::diagonalize`, so those calls are safe from it. But, some `Tensor2d::diagonalize` calls would indeed fail after this PR. I think the easiest option here is to back out the removal of `Tensor2d::diagonalize` overloads for now. FYI, my plan was to _eventually_ change the function signature of `Tensor2d::diagonalize` after this PR. The `init_dim` and `cutoff` arguments have been defunct (as in no-op, unused) for ages. But that can wait until dfocc is no longer in such flux, I can excise `sq_rsp` while keeping the current interfaces.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2684#issuecomment-1500354378
https://github.com/psi4/psi4/pull/2684#issuecomment-1500354378:187,Safety,safe,safe,187,"Thanks for looking into it. It looks like none of these involve `Array2d::diagonalize`, so this PR is good on that front. This PR does not touch `Matrix::diagonalize`, so those calls are safe from it. But, some `Tensor2d::diagonalize` calls would indeed fail after this PR. I think the easiest option here is to back out the removal of `Tensor2d::diagonalize` overloads for now. FYI, my plan was to _eventually_ change the function signature of `Tensor2d::diagonalize` after this PR. The `init_dim` and `cutoff` arguments have been defunct (as in no-op, unused) for ages. But that can wait until dfocc is no longer in such flux, I can excise `sq_rsp` while keeping the current interfaces.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2684#issuecomment-1500354378
https://github.com/psi4/psi4/issues/2685#issuecomment-1215181077:407,Deployability,patch,patched,407,"That's curious. Both the source and final files show up as executable to me on Linux (see below), and Mac hasn't had a problem. Are they not showing up as executable to you?. Also note that the CMake-detected python gets baked in to the psi4 shell script as a shebang (see below). This is very handy for development environments where one generally wants to avoid the system python, but maybe you need that patched?. (from builddir); ```; > ls -l stage/bin/psi4 ; -rwxr-xr-x. 1 user user 14865 Jul 30 21:21 stage/bin/psi4; > ls -l ../psi4/run_psi4.py ; -rwxrwxr-x. 1 user user 14861 Jul 30 21:14 ../psi4/run_psi4.py; > head -1 stage/bin/psi4 ; #!/psi/toolchainconda/envs/py310/bin/python; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2685#issuecomment-1215181077
https://github.com/psi4/psi4/issues/2685#issuecomment-1215181077:200,Safety,detect,detected,200,"That's curious. Both the source and final files show up as executable to me on Linux (see below), and Mac hasn't had a problem. Are they not showing up as executable to you?. Also note that the CMake-detected python gets baked in to the psi4 shell script as a shebang (see below). This is very handy for development environments where one generally wants to avoid the system python, but maybe you need that patched?. (from builddir); ```; > ls -l stage/bin/psi4 ; -rwxr-xr-x. 1 user user 14865 Jul 30 21:21 stage/bin/psi4; > ls -l ../psi4/run_psi4.py ; -rwxrwxr-x. 1 user user 14861 Jul 30 21:14 ../psi4/run_psi4.py; > head -1 stage/bin/psi4 ; #!/psi/toolchainconda/envs/py310/bin/python; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2685#issuecomment-1215181077
https://github.com/psi4/psi4/issues/2685#issuecomment-1215181077:358,Safety,avoid,avoid,358,"That's curious. Both the source and final files show up as executable to me on Linux (see below), and Mac hasn't had a problem. Are they not showing up as executable to you?. Also note that the CMake-detected python gets baked in to the psi4 shell script as a shebang (see below). This is very handy for development environments where one generally wants to avoid the system python, but maybe you need that patched?. (from builddir); ```; > ls -l stage/bin/psi4 ; -rwxr-xr-x. 1 user user 14865 Jul 30 21:21 stage/bin/psi4; > ls -l ../psi4/run_psi4.py ; -rwxrwxr-x. 1 user user 14861 Jul 30 21:14 ../psi4/run_psi4.py; > head -1 stage/bin/psi4 ; #!/psi/toolchainconda/envs/py310/bin/python; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2685#issuecomment-1215181077
https://github.com/psi4/psi4/issues/2685#issuecomment-1215469311:47,Testability,test,test,47,psi4 builds for over an hour so I can't easily test it.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2685#issuecomment-1215469311
https://github.com/psi4/psi4/pull/2686#issuecomment-1271795143:865,Integrability,Message,Message,865,"in cc/ccdensity/ael.cc; This code determines approximate excitation level. It used to work.; Apparently no longer called. I'm not sure why.; (I'm not on the very latest psi4, so it's possible it's been excised. On Thu, Oct 6, 2022 at 8:39 PM TiborGY ***@***.***> wrote:. > As an old-timer, I would say yes, libciomr is the place. At least as long; > as there is still a libciomr, that's where I would look. This is nice; > improvement!; >; > ccdensity has a sq_rsp too. did you miss that one?; >; > I ran a search and none of the remaining hits were from ccdensity.; >; > ; > Reply to this email directly, view it on GitHub; > <https://github.com/psi4/psi4/pull/2686#issuecomment-1270997653>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AA4C4TGYDX6IXCJ5SUMXZVLWB55NJANCNFSM56SE6U4Q>; > .; > You are receiving this because you commented.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2686#issuecomment-1271795143
https://github.com/psi4/psi4/pull/2686#issuecomment-1329579522:14,Testability,test,tests,14,"503/503 ctest tests are passing; [ctestlog.txt](https://github.com/psi4/psi4/files/10106557/ctestlog.txt); If that is judged to be sufficient coverage, this PR is ready for merge.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2686#issuecomment-1329579522
https://github.com/psi4/psi4/issues/2687#issuecomment-1358102176:9,Availability,down,downloaded,9,Tarballs downloaded from GitHub are not git repositories. We use them in FreeBSD ports.; Nothing important should be hard-wired to Git during build/tests.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358102176
https://github.com/psi4/psi4/issues/2687#issuecomment-1358102176:148,Testability,test,tests,148,Tarballs downloaded from GitHub are not git repositories. We use them in FreeBSD ports.; Nothing important should be hard-wired to Git during build/tests.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358102176
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:11,Availability,down,downloaded,11,"> Tarballs downloaded from GitHub are not git repositories. We use them in FreeBSD ports.; Nothing important should be hard-wired to Git during build/tests. I agree broadly, though I'd sacrifice it to get fine-grain versioning for cross-project communication if needed :-). The way psi is set up now, if the buildsys detects that it's not a git repo, it substitutes some generic most-recent-tag info and proceeds, so that one gets a working build. When I try, it works as planned:. acquire tarball; ```; > curl -L https://github.com/psi4/psi4/tarball/master -o psi4_v17.tgz; ```; configure and build -- it detects ""no git""; ```; # configure (all req'd deps detected except optking to be build from src); > cmake --build . -j12; ...; [ 88%] Performing build step for 'psi4-core'; [ 1%] Generating version info; [ 1%] Building CXX object src/psi4/lib3index/CMakeFiles/3index.dir/dftensor.cc.o; ...; [ 2%] Building CXX object src/CMakeFiles/l2export.dir/export_mints.cc.o; Blindly (no git) accepting release version: 1.7+6ce35a5 (recorded); 1.7 {} 6ce35a5 1.7.0.0 release 1.7 <-- 1.7+6ce35a5; [ 2%] Built target update_version; [ 2%] Building CXX object src/psi4/libciomr/CMakeFiles/ciomr.dir/dsyev_ascending.cc.o; ...; ```; version computes and simple test, distributed driver tests, and dftd3 addon tests work ok; ```; > stage/bin/psi4 --psiapi # execute results; >>> stage/bin/psi4 --version; 1.7; >>> ctest -R tu1; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 426: tu1-h2o-energy; 1/1 Test #426: tu1-h2o-energy ................... Passed 1.65 sec. 100% tests passed, 0 tests failed out of 1; >>> ctest -R ddd; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 479: ddd-deriv; 1/2 Test #479: ddd-deriv ........................ Passed 13.18 sec; Start 481: ddd-function-kwargs; 2/2 Test #481: ddd-function-kwargs .............. Passed 170.20 sec. 100% tests passed, 0 tests failed out of 2; >>> ctest -R dftd3; Test project /psi/gits/tarbuild/psi4-psi4-4d94",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:4448,Availability,down,down,4448,"s have stuff in src and built forms; ```; > cat ../psi4/metadata.py ; __version__ = '1.7'; __version_long = '1.7+6ce35a5'; __version_upcoming_annotated_v_tag = '1.8a1'. def version_formatter(dummy):; return '(inplace)'; > cat stage/lib/psi4/metadata.py ; __version__ = '1.7'; __version_branch_name = ''; __version_cmake = '1.7.0.0'; __version_is_clean = 'True'; __version_last_release = '1.7'; __version_long = '1.7+6ce35a5'; __version_prerelease = 'False'; __version_release = 'True'. def version_formatter(formatstring='{version}'):; if formatstring == 'all':; formatstring = '{version} {{{branch}}} {githash} {cmake} {clean} {release} {lastrel} <-- {versionlong}'. release = 'release' if (__version_release == 'True') else ('prerelease' if (__version_prerelease == 'True') else ''). ans = formatstring.format(version=__version__,; versionlong=__version_long,; githash=__version_long[len(__version__)+1:],; clean='' if __version_is_clean == 'True' else 'dirty',; branch=__version_branch_name,; lastrel=__version_last_release,; cmake=__version_cmake,; release=release); return ans. if __name__ == '__main__':; print(version_formatter(formatstring='all')); ```. So I think tarballs are roughly still working. But I can totally believe that either I'm working in an edge case or the two of you have found one. My closest suspects:; * perhaps you're in a repo that isn't the psi repo. I bet that'd defeat https://github.com/psi4/psi4/blob/master/psi4/versioner.py#L50 that switches the version logic from git to tarball; * that version logic is tested for release tarballs only, not tarballs of random commits; * the increasing dependency on qcengine (which arose long after the versioning system design) for finite difference and dispersion depends a lot on computing the psi4 (and other) versions. Hence the ""pull tags"" message. I can believe there's a way that communication breaks down. I'd suggest you compare commands and cat-ed files and see where the discrepancy in workflow/environment arises.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:997,Deployability,release,release,997,"> Tarballs downloaded from GitHub are not git repositories. We use them in FreeBSD ports.; Nothing important should be hard-wired to Git during build/tests. I agree broadly, though I'd sacrifice it to get fine-grain versioning for cross-project communication if needed :-). The way psi is set up now, if the buildsys detects that it's not a git repo, it substitutes some generic most-recent-tag info and proceeds, so that one gets a working build. When I try, it works as planned:. acquire tarball; ```; > curl -L https://github.com/psi4/psi4/tarball/master -o psi4_v17.tgz; ```; configure and build -- it detects ""no git""; ```; # configure (all req'd deps detected except optking to be build from src); > cmake --build . -j12; ...; [ 88%] Performing build step for 'psi4-core'; [ 1%] Generating version info; [ 1%] Building CXX object src/psi4/lib3index/CMakeFiles/3index.dir/dftensor.cc.o; ...; [ 2%] Building CXX object src/CMakeFiles/l2export.dir/export_mints.cc.o; Blindly (no git) accepting release version: 1.7+6ce35a5 (recorded); 1.7 {} 6ce35a5 1.7.0.0 release 1.7 <-- 1.7+6ce35a5; [ 2%] Built target update_version; [ 2%] Building CXX object src/psi4/libciomr/CMakeFiles/ciomr.dir/dsyev_ascending.cc.o; ...; ```; version computes and simple test, distributed driver tests, and dftd3 addon tests work ok; ```; > stage/bin/psi4 --psiapi # execute results; >>> stage/bin/psi4 --version; 1.7; >>> ctest -R tu1; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 426: tu1-h2o-energy; 1/1 Test #426: tu1-h2o-energy ................... Passed 1.65 sec. 100% tests passed, 0 tests failed out of 1; >>> ctest -R ddd; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 479: ddd-deriv; 1/2 Test #479: ddd-deriv ........................ Passed 13.18 sec; Start 481: ddd-function-kwargs; 2/2 Test #481: ddd-function-kwargs .............. Passed 170.20 sec. 100% tests passed, 0 tests failed out of 2; >>> ctest -R dftd3; Test project /psi/gits/tarbuild/psi4-psi4-4d94",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:1061,Deployability,release,release,1061,"e them in FreeBSD ports.; Nothing important should be hard-wired to Git during build/tests. I agree broadly, though I'd sacrifice it to get fine-grain versioning for cross-project communication if needed :-). The way psi is set up now, if the buildsys detects that it's not a git repo, it substitutes some generic most-recent-tag info and proceeds, so that one gets a working build. When I try, it works as planned:. acquire tarball; ```; > curl -L https://github.com/psi4/psi4/tarball/master -o psi4_v17.tgz; ```; configure and build -- it detects ""no git""; ```; # configure (all req'd deps detected except optking to be build from src); > cmake --build . -j12; ...; [ 88%] Performing build step for 'psi4-core'; [ 1%] Generating version info; [ 1%] Building CXX object src/psi4/lib3index/CMakeFiles/3index.dir/dftensor.cc.o; ...; [ 2%] Building CXX object src/CMakeFiles/l2export.dir/export_mints.cc.o; Blindly (no git) accepting release version: 1.7+6ce35a5 (recorded); 1.7 {} 6ce35a5 1.7.0.0 release 1.7 <-- 1.7+6ce35a5; [ 2%] Built target update_version; [ 2%] Building CXX object src/psi4/libciomr/CMakeFiles/ciomr.dir/dsyev_ascending.cc.o; ...; ```; version computes and simple test, distributed driver tests, and dftd3 addon tests work ok; ```; > stage/bin/psi4 --psiapi # execute results; >>> stage/bin/psi4 --version; 1.7; >>> ctest -R tu1; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 426: tu1-h2o-energy; 1/1 Test #426: tu1-h2o-energy ................... Passed 1.65 sec. 100% tests passed, 0 tests failed out of 1; >>> ctest -R ddd; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 479: ddd-deriv; 1/2 Test #479: ddd-deriv ........................ Passed 13.18 sec; Start 481: ddd-function-kwargs; 2/2 Test #481: ddd-function-kwargs .............. Passed 170.20 sec. 100% tests passed, 0 tests failed out of 2; >>> ctest -R dftd3; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 510: dftd3-energy; 1/5 Test #510: dftd3-",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:3194,Deployability,release,release,3194,"st #511: dftd3-grad ....................... Passed 11.33 sec; Start 512: dftd3-psithon2; 3/5 Test #512: dftd3-psithon2 ................... Passed 13.39 sec; Start 513: dftd3-version; 4/5 Test #513: dftd3-version .................... Passed 27.06 sec; Start 514: dftd3-nbody-cp-gradient; 5/5 Test #514: dftd3-nbody-cp-gradient .......... Passed 33.83 sec. 100% tests passed, 0 tests failed out of 5; ```; version control files have stuff in src and built forms; ```; > cat ../psi4/metadata.py ; __version__ = '1.7'; __version_long = '1.7+6ce35a5'; __version_upcoming_annotated_v_tag = '1.8a1'. def version_formatter(dummy):; return '(inplace)'; > cat stage/lib/psi4/metadata.py ; __version__ = '1.7'; __version_branch_name = ''; __version_cmake = '1.7.0.0'; __version_is_clean = 'True'; __version_last_release = '1.7'; __version_long = '1.7+6ce35a5'; __version_prerelease = 'False'; __version_release = 'True'. def version_formatter(formatstring='{version}'):; if formatstring == 'all':; formatstring = '{version} {{{branch}}} {githash} {cmake} {clean} {release} {lastrel} <-- {versionlong}'. release = 'release' if (__version_release == 'True') else ('prerelease' if (__version_prerelease == 'True') else ''). ans = formatstring.format(version=__version__,; versionlong=__version_long,; githash=__version_long[len(__version__)+1:],; clean='' if __version_is_clean == 'True' else 'dirty',; branch=__version_branch_name,; lastrel=__version_last_release,; cmake=__version_cmake,; release=release); return ans. if __name__ == '__main__':; print(version_formatter(formatstring='all')); ```. So I think tarballs are roughly still working. But I can totally believe that either I'm working in an edge case or the two of you have found one. My closest suspects:; * perhaps you're in a repo that isn't the psi repo. I bet that'd defeat https://github.com/psi4/psi4/blob/master/psi4/versioner.py#L50 that switches the version logic from git to tarball; * that version logic is tested for release tarballs only,",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:3233,Deployability,release,release,3233,"9 sec; Start 513: dftd3-version; 4/5 Test #513: dftd3-version .................... Passed 27.06 sec; Start 514: dftd3-nbody-cp-gradient; 5/5 Test #514: dftd3-nbody-cp-gradient .......... Passed 33.83 sec. 100% tests passed, 0 tests failed out of 5; ```; version control files have stuff in src and built forms; ```; > cat ../psi4/metadata.py ; __version__ = '1.7'; __version_long = '1.7+6ce35a5'; __version_upcoming_annotated_v_tag = '1.8a1'. def version_formatter(dummy):; return '(inplace)'; > cat stage/lib/psi4/metadata.py ; __version__ = '1.7'; __version_branch_name = ''; __version_cmake = '1.7.0.0'; __version_is_clean = 'True'; __version_last_release = '1.7'; __version_long = '1.7+6ce35a5'; __version_prerelease = 'False'; __version_release = 'True'. def version_formatter(formatstring='{version}'):; if formatstring == 'all':; formatstring = '{version} {{{branch}}} {githash} {cmake} {clean} {release} {lastrel} <-- {versionlong}'. release = 'release' if (__version_release == 'True') else ('prerelease' if (__version_prerelease == 'True') else ''). ans = formatstring.format(version=__version__,; versionlong=__version_long,; githash=__version_long[len(__version__)+1:],; clean='' if __version_is_clean == 'True' else 'dirty',; branch=__version_branch_name,; lastrel=__version_last_release,; cmake=__version_cmake,; release=release); return ans. if __name__ == '__main__':; print(version_formatter(formatstring='all')); ```. So I think tarballs are roughly still working. But I can totally believe that either I'm working in an edge case or the two of you have found one. My closest suspects:; * perhaps you're in a repo that isn't the psi repo. I bet that'd defeat https://github.com/psi4/psi4/blob/master/psi4/versioner.py#L50 that switches the version logic from git to tarball; * that version logic is tested for release tarballs only, not tarballs of random commits; * the increasing dependency on qcengine (which arose long after the versioning system design) for finite difference a",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:3244,Deployability,release,release,3244,"9 sec; Start 513: dftd3-version; 4/5 Test #513: dftd3-version .................... Passed 27.06 sec; Start 514: dftd3-nbody-cp-gradient; 5/5 Test #514: dftd3-nbody-cp-gradient .......... Passed 33.83 sec. 100% tests passed, 0 tests failed out of 5; ```; version control files have stuff in src and built forms; ```; > cat ../psi4/metadata.py ; __version__ = '1.7'; __version_long = '1.7+6ce35a5'; __version_upcoming_annotated_v_tag = '1.8a1'. def version_formatter(dummy):; return '(inplace)'; > cat stage/lib/psi4/metadata.py ; __version__ = '1.7'; __version_branch_name = ''; __version_cmake = '1.7.0.0'; __version_is_clean = 'True'; __version_last_release = '1.7'; __version_long = '1.7+6ce35a5'; __version_prerelease = 'False'; __version_release = 'True'. def version_formatter(formatstring='{version}'):; if formatstring == 'all':; formatstring = '{version} {{{branch}}} {githash} {cmake} {clean} {release} {lastrel} <-- {versionlong}'. release = 'release' if (__version_release == 'True') else ('prerelease' if (__version_prerelease == 'True') else ''). ans = formatstring.format(version=__version__,; versionlong=__version_long,; githash=__version_long[len(__version__)+1:],; clean='' if __version_is_clean == 'True' else 'dirty',; branch=__version_branch_name,; lastrel=__version_last_release,; cmake=__version_cmake,; release=release); return ans. if __name__ == '__main__':; print(version_formatter(formatstring='all')); ```. So I think tarballs are roughly still working. But I can totally believe that either I'm working in an edge case or the two of you have found one. My closest suspects:; * perhaps you're in a repo that isn't the psi repo. I bet that'd defeat https://github.com/psi4/psi4/blob/master/psi4/versioner.py#L50 that switches the version logic from git to tarball; * that version logic is tested for release tarballs only, not tarballs of random commits; * the increasing dependency on qcengine (which arose long after the versioning system design) for finite difference a",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:3618,Deployability,release,release,3618,"assed, 0 tests failed out of 5; ```; version control files have stuff in src and built forms; ```; > cat ../psi4/metadata.py ; __version__ = '1.7'; __version_long = '1.7+6ce35a5'; __version_upcoming_annotated_v_tag = '1.8a1'. def version_formatter(dummy):; return '(inplace)'; > cat stage/lib/psi4/metadata.py ; __version__ = '1.7'; __version_branch_name = ''; __version_cmake = '1.7.0.0'; __version_is_clean = 'True'; __version_last_release = '1.7'; __version_long = '1.7+6ce35a5'; __version_prerelease = 'False'; __version_release = 'True'. def version_formatter(formatstring='{version}'):; if formatstring == 'all':; formatstring = '{version} {{{branch}}} {githash} {cmake} {clean} {release} {lastrel} <-- {versionlong}'. release = 'release' if (__version_release == 'True') else ('prerelease' if (__version_prerelease == 'True') else ''). ans = formatstring.format(version=__version__,; versionlong=__version_long,; githash=__version_long[len(__version__)+1:],; clean='' if __version_is_clean == 'True' else 'dirty',; branch=__version_branch_name,; lastrel=__version_last_release,; cmake=__version_cmake,; release=release); return ans. if __name__ == '__main__':; print(version_formatter(formatstring='all')); ```. So I think tarballs are roughly still working. But I can totally believe that either I'm working in an edge case or the two of you have found one. My closest suspects:; * perhaps you're in a repo that isn't the psi repo. I bet that'd defeat https://github.com/psi4/psi4/blob/master/psi4/versioner.py#L50 that switches the version logic from git to tarball; * that version logic is tested for release tarballs only, not tarballs of random commits; * the increasing dependency on qcengine (which arose long after the versioning system design) for finite difference and dispersion depends a lot on computing the psi4 (and other) versions. Hence the ""pull tags"" message. I can believe there's a way that communication breaks down. I'd suggest you compare commands and cat-ed files and s",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:3626,Deployability,release,release,3626,"assed, 0 tests failed out of 5; ```; version control files have stuff in src and built forms; ```; > cat ../psi4/metadata.py ; __version__ = '1.7'; __version_long = '1.7+6ce35a5'; __version_upcoming_annotated_v_tag = '1.8a1'. def version_formatter(dummy):; return '(inplace)'; > cat stage/lib/psi4/metadata.py ; __version__ = '1.7'; __version_branch_name = ''; __version_cmake = '1.7.0.0'; __version_is_clean = 'True'; __version_last_release = '1.7'; __version_long = '1.7+6ce35a5'; __version_prerelease = 'False'; __version_release = 'True'. def version_formatter(formatstring='{version}'):; if formatstring == 'all':; formatstring = '{version} {{{branch}}} {githash} {cmake} {clean} {release} {lastrel} <-- {versionlong}'. release = 'release' if (__version_release == 'True') else ('prerelease' if (__version_prerelease == 'True') else ''). ans = formatstring.format(version=__version__,; versionlong=__version_long,; githash=__version_long[len(__version__)+1:],; clean='' if __version_is_clean == 'True' else 'dirty',; branch=__version_branch_name,; lastrel=__version_last_release,; cmake=__version_cmake,; release=release); return ans. if __name__ == '__main__':; print(version_formatter(formatstring='all')); ```. So I think tarballs are roughly still working. But I can totally believe that either I'm working in an edge case or the two of you have found one. My closest suspects:; * perhaps you're in a repo that isn't the psi repo. I bet that'd defeat https://github.com/psi4/psi4/blob/master/psi4/versioner.py#L50 that switches the version logic from git to tarball; * that version logic is tested for release tarballs only, not tarballs of random commits; * the increasing dependency on qcengine (which arose long after the versioning system design) for finite difference and dispersion depends a lot on computing the psi4 (and other) versions. Hence the ""pull tags"" message. I can believe there's a way that communication breaks down. I'd suggest you compare commands and cat-ed files and s",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:4119,Deployability,release,release,4119,"s have stuff in src and built forms; ```; > cat ../psi4/metadata.py ; __version__ = '1.7'; __version_long = '1.7+6ce35a5'; __version_upcoming_annotated_v_tag = '1.8a1'. def version_formatter(dummy):; return '(inplace)'; > cat stage/lib/psi4/metadata.py ; __version__ = '1.7'; __version_branch_name = ''; __version_cmake = '1.7.0.0'; __version_is_clean = 'True'; __version_last_release = '1.7'; __version_long = '1.7+6ce35a5'; __version_prerelease = 'False'; __version_release = 'True'. def version_formatter(formatstring='{version}'):; if formatstring == 'all':; formatstring = '{version} {{{branch}}} {githash} {cmake} {clean} {release} {lastrel} <-- {versionlong}'. release = 'release' if (__version_release == 'True') else ('prerelease' if (__version_prerelease == 'True') else ''). ans = formatstring.format(version=__version__,; versionlong=__version_long,; githash=__version_long[len(__version__)+1:],; clean='' if __version_is_clean == 'True' else 'dirty',; branch=__version_branch_name,; lastrel=__version_last_release,; cmake=__version_cmake,; release=release); return ans. if __name__ == '__main__':; print(version_formatter(formatstring='all')); ```. So I think tarballs are roughly still working. But I can totally believe that either I'm working in an edge case or the two of you have found one. My closest suspects:; * perhaps you're in a repo that isn't the psi repo. I bet that'd defeat https://github.com/psi4/psi4/blob/master/psi4/versioner.py#L50 that switches the version logic from git to tarball; * that version logic is tested for release tarballs only, not tarballs of random commits; * the increasing dependency on qcengine (which arose long after the versioning system design) for finite difference and dispersion depends a lot on computing the psi4 (and other) versions. Hence the ""pull tags"" message. I can believe there's a way that communication breaks down. I'd suggest you compare commands and cat-ed files and see where the discrepancy in workflow/environment arises.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:1499,Energy Efficiency,energy,energy,1499,"ks as planned:. acquire tarball; ```; > curl -L https://github.com/psi4/psi4/tarball/master -o psi4_v17.tgz; ```; configure and build -- it detects ""no git""; ```; # configure (all req'd deps detected except optking to be build from src); > cmake --build . -j12; ...; [ 88%] Performing build step for 'psi4-core'; [ 1%] Generating version info; [ 1%] Building CXX object src/psi4/lib3index/CMakeFiles/3index.dir/dftensor.cc.o; ...; [ 2%] Building CXX object src/CMakeFiles/l2export.dir/export_mints.cc.o; Blindly (no git) accepting release version: 1.7+6ce35a5 (recorded); 1.7 {} 6ce35a5 1.7.0.0 release 1.7 <-- 1.7+6ce35a5; [ 2%] Built target update_version; [ 2%] Building CXX object src/psi4/libciomr/CMakeFiles/ciomr.dir/dsyev_ascending.cc.o; ...; ```; version computes and simple test, distributed driver tests, and dftd3 addon tests work ok; ```; > stage/bin/psi4 --psiapi # execute results; >>> stage/bin/psi4 --version; 1.7; >>> ctest -R tu1; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 426: tu1-h2o-energy; 1/1 Test #426: tu1-h2o-energy ................... Passed 1.65 sec. 100% tests passed, 0 tests failed out of 1; >>> ctest -R ddd; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 479: ddd-deriv; 1/2 Test #479: ddd-deriv ........................ Passed 13.18 sec; Start 481: ddd-function-kwargs; 2/2 Test #481: ddd-function-kwargs .............. Passed 170.20 sec. 100% tests passed, 0 tests failed out of 2; >>> ctest -R dftd3; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 510: dftd3-energy; 1/5 Test #510: dftd3-energy ..................... Passed 24.64 sec; Start 511: dftd3-grad; 2/5 Test #511: dftd3-grad ....................... Passed 11.33 sec; Start 512: dftd3-psithon2; 3/5 Test #512: dftd3-psithon2 ................... Passed 13.39 sec; Start 513: dftd3-version; 4/5 Test #513: dftd3-version .................... Passed 27.06 sec; Start 514: dftd3-nbody-cp-gradient; 5/5 Test #514: dftd3-nbody-cp-gradient ",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:1530,Energy Efficiency,energy,energy,1530,"ks as planned:. acquire tarball; ```; > curl -L https://github.com/psi4/psi4/tarball/master -o psi4_v17.tgz; ```; configure and build -- it detects ""no git""; ```; # configure (all req'd deps detected except optking to be build from src); > cmake --build . -j12; ...; [ 88%] Performing build step for 'psi4-core'; [ 1%] Generating version info; [ 1%] Building CXX object src/psi4/lib3index/CMakeFiles/3index.dir/dftensor.cc.o; ...; [ 2%] Building CXX object src/CMakeFiles/l2export.dir/export_mints.cc.o; Blindly (no git) accepting release version: 1.7+6ce35a5 (recorded); 1.7 {} 6ce35a5 1.7.0.0 release 1.7 <-- 1.7+6ce35a5; [ 2%] Built target update_version; [ 2%] Building CXX object src/psi4/libciomr/CMakeFiles/ciomr.dir/dsyev_ascending.cc.o; ...; ```; version computes and simple test, distributed driver tests, and dftd3 addon tests work ok; ```; > stage/bin/psi4 --psiapi # execute results; >>> stage/bin/psi4 --version; 1.7; >>> ctest -R tu1; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 426: tu1-h2o-energy; 1/1 Test #426: tu1-h2o-energy ................... Passed 1.65 sec. 100% tests passed, 0 tests failed out of 1; >>> ctest -R ddd; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 479: ddd-deriv; 1/2 Test #479: ddd-deriv ........................ Passed 13.18 sec; Start 481: ddd-function-kwargs; 2/2 Test #481: ddd-function-kwargs .............. Passed 170.20 sec. 100% tests passed, 0 tests failed out of 2; >>> ctest -R dftd3; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 510: dftd3-energy; 1/5 Test #510: dftd3-energy ..................... Passed 24.64 sec; Start 511: dftd3-grad; 2/5 Test #511: dftd3-grad ....................... Passed 11.33 sec; Start 512: dftd3-psithon2; 3/5 Test #512: dftd3-psithon2 ................... Passed 13.39 sec; Start 513: dftd3-version; 4/5 Test #513: dftd3-version .................... Passed 27.06 sec; Start 514: dftd3-nbody-cp-gradient; 5/5 Test #514: dftd3-nbody-cp-gradient ",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:2036,Energy Efficiency,energy,energy,2036," git) accepting release version: 1.7+6ce35a5 (recorded); 1.7 {} 6ce35a5 1.7.0.0 release 1.7 <-- 1.7+6ce35a5; [ 2%] Built target update_version; [ 2%] Building CXX object src/psi4/libciomr/CMakeFiles/ciomr.dir/dsyev_ascending.cc.o; ...; ```; version computes and simple test, distributed driver tests, and dftd3 addon tests work ok; ```; > stage/bin/psi4 --psiapi # execute results; >>> stage/bin/psi4 --version; 1.7; >>> ctest -R tu1; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 426: tu1-h2o-energy; 1/1 Test #426: tu1-h2o-energy ................... Passed 1.65 sec. 100% tests passed, 0 tests failed out of 1; >>> ctest -R ddd; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 479: ddd-deriv; 1/2 Test #479: ddd-deriv ........................ Passed 13.18 sec; Start 481: ddd-function-kwargs; 2/2 Test #481: ddd-function-kwargs .............. Passed 170.20 sec. 100% tests passed, 0 tests failed out of 2; >>> ctest -R dftd3; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 510: dftd3-energy; 1/5 Test #510: dftd3-energy ..................... Passed 24.64 sec; Start 511: dftd3-grad; 2/5 Test #511: dftd3-grad ....................... Passed 11.33 sec; Start 512: dftd3-psithon2; 3/5 Test #512: dftd3-psithon2 ................... Passed 13.39 sec; Start 513: dftd3-version; 4/5 Test #513: dftd3-version .................... Passed 27.06 sec; Start 514: dftd3-nbody-cp-gradient; 5/5 Test #514: dftd3-nbody-cp-gradient .......... Passed 33.83 sec. 100% tests passed, 0 tests failed out of 5; ```; version control files have stuff in src and built forms; ```; > cat ../psi4/metadata.py ; __version__ = '1.7'; __version_long = '1.7+6ce35a5'; __version_upcoming_annotated_v_tag = '1.8a1'. def version_formatter(dummy):; return '(inplace)'; > cat stage/lib/psi4/metadata.py ; __version__ = '1.7'; __version_branch_name = ''; __version_cmake = '1.7.0.0'; __version_is_clean = 'True'; __version_last_release = '1.7'; __version_long = '1.7+6",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:2065,Energy Efficiency,energy,energy,2065," git) accepting release version: 1.7+6ce35a5 (recorded); 1.7 {} 6ce35a5 1.7.0.0 release 1.7 <-- 1.7+6ce35a5; [ 2%] Built target update_version; [ 2%] Building CXX object src/psi4/libciomr/CMakeFiles/ciomr.dir/dsyev_ascending.cc.o; ...; ```; version computes and simple test, distributed driver tests, and dftd3 addon tests work ok; ```; > stage/bin/psi4 --psiapi # execute results; >>> stage/bin/psi4 --version; 1.7; >>> ctest -R tu1; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 426: tu1-h2o-energy; 1/1 Test #426: tu1-h2o-energy ................... Passed 1.65 sec. 100% tests passed, 0 tests failed out of 1; >>> ctest -R ddd; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 479: ddd-deriv; 1/2 Test #479: ddd-deriv ........................ Passed 13.18 sec; Start 481: ddd-function-kwargs; 2/2 Test #481: ddd-function-kwargs .............. Passed 170.20 sec. 100% tests passed, 0 tests failed out of 2; >>> ctest -R dftd3; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 510: dftd3-energy; 1/5 Test #510: dftd3-energy ..................... Passed 24.64 sec; Start 511: dftd3-grad; 2/5 Test #511: dftd3-grad ....................... Passed 11.33 sec; Start 512: dftd3-psithon2; 3/5 Test #512: dftd3-psithon2 ................... Passed 13.39 sec; Start 513: dftd3-version; 4/5 Test #513: dftd3-version .................... Passed 27.06 sec; Start 514: dftd3-nbody-cp-gradient; 5/5 Test #514: dftd3-nbody-cp-gradient .......... Passed 33.83 sec. 100% tests passed, 0 tests failed out of 5; ```; version control files have stuff in src and built forms; ```; > cat ../psi4/metadata.py ; __version__ = '1.7'; __version_long = '1.7+6ce35a5'; __version_upcoming_annotated_v_tag = '1.8a1'. def version_formatter(dummy):; return '(inplace)'; > cat stage/lib/psi4/metadata.py ; __version__ = '1.7'; __version_branch_name = ''; __version_cmake = '1.7.0.0'; __version_is_clean = 'True'; __version_last_release = '1.7'; __version_long = '1.7+6",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:4191,Integrability,depend,dependency,4191,"s have stuff in src and built forms; ```; > cat ../psi4/metadata.py ; __version__ = '1.7'; __version_long = '1.7+6ce35a5'; __version_upcoming_annotated_v_tag = '1.8a1'. def version_formatter(dummy):; return '(inplace)'; > cat stage/lib/psi4/metadata.py ; __version__ = '1.7'; __version_branch_name = ''; __version_cmake = '1.7.0.0'; __version_is_clean = 'True'; __version_last_release = '1.7'; __version_long = '1.7+6ce35a5'; __version_prerelease = 'False'; __version_release = 'True'. def version_formatter(formatstring='{version}'):; if formatstring == 'all':; formatstring = '{version} {{{branch}}} {githash} {cmake} {clean} {release} {lastrel} <-- {versionlong}'. release = 'release' if (__version_release == 'True') else ('prerelease' if (__version_prerelease == 'True') else ''). ans = formatstring.format(version=__version__,; versionlong=__version_long,; githash=__version_long[len(__version__)+1:],; clean='' if __version_is_clean == 'True' else 'dirty',; branch=__version_branch_name,; lastrel=__version_last_release,; cmake=__version_cmake,; release=release); return ans. if __name__ == '__main__':; print(version_formatter(formatstring='all')); ```. So I think tarballs are roughly still working. But I can totally believe that either I'm working in an edge case or the two of you have found one. My closest suspects:; * perhaps you're in a repo that isn't the psi repo. I bet that'd defeat https://github.com/psi4/psi4/blob/master/psi4/versioner.py#L50 that switches the version logic from git to tarball; * that version logic is tested for release tarballs only, not tarballs of random commits; * the increasing dependency on qcengine (which arose long after the versioning system design) for finite difference and dispersion depends a lot on computing the psi4 (and other) versions. Hence the ""pull tags"" message. I can believe there's a way that communication breaks down. I'd suggest you compare commands and cat-ed files and see where the discrepancy in workflow/environment arises.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:4305,Integrability,depend,depends,4305,"s have stuff in src and built forms; ```; > cat ../psi4/metadata.py ; __version__ = '1.7'; __version_long = '1.7+6ce35a5'; __version_upcoming_annotated_v_tag = '1.8a1'. def version_formatter(dummy):; return '(inplace)'; > cat stage/lib/psi4/metadata.py ; __version__ = '1.7'; __version_branch_name = ''; __version_cmake = '1.7.0.0'; __version_is_clean = 'True'; __version_last_release = '1.7'; __version_long = '1.7+6ce35a5'; __version_prerelease = 'False'; __version_release = 'True'. def version_formatter(formatstring='{version}'):; if formatstring == 'all':; formatstring = '{version} {{{branch}}} {githash} {cmake} {clean} {release} {lastrel} <-- {versionlong}'. release = 'release' if (__version_release == 'True') else ('prerelease' if (__version_prerelease == 'True') else ''). ans = formatstring.format(version=__version__,; versionlong=__version_long,; githash=__version_long[len(__version__)+1:],; clean='' if __version_is_clean == 'True' else 'dirty',; branch=__version_branch_name,; lastrel=__version_last_release,; cmake=__version_cmake,; release=release); return ans. if __name__ == '__main__':; print(version_formatter(formatstring='all')); ```. So I think tarballs are roughly still working. But I can totally believe that either I'm working in an edge case or the two of you have found one. My closest suspects:; * perhaps you're in a repo that isn't the psi repo. I bet that'd defeat https://github.com/psi4/psi4/blob/master/psi4/versioner.py#L50 that switches the version logic from git to tarball; * that version logic is tested for release tarballs only, not tarballs of random commits; * the increasing dependency on qcengine (which arose long after the versioning system design) for finite difference and dispersion depends a lot on computing the psi4 (and other) versions. Hence the ""pull tags"" message. I can believe there's a way that communication breaks down. I'd suggest you compare commands and cat-ed files and see where the discrepancy in workflow/environment arises.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:4385,Integrability,message,message,4385,"s have stuff in src and built forms; ```; > cat ../psi4/metadata.py ; __version__ = '1.7'; __version_long = '1.7+6ce35a5'; __version_upcoming_annotated_v_tag = '1.8a1'. def version_formatter(dummy):; return '(inplace)'; > cat stage/lib/psi4/metadata.py ; __version__ = '1.7'; __version_branch_name = ''; __version_cmake = '1.7.0.0'; __version_is_clean = 'True'; __version_last_release = '1.7'; __version_long = '1.7+6ce35a5'; __version_prerelease = 'False'; __version_release = 'True'. def version_formatter(formatstring='{version}'):; if formatstring == 'all':; formatstring = '{version} {{{branch}}} {githash} {cmake} {clean} {release} {lastrel} <-- {versionlong}'. release = 'release' if (__version_release == 'True') else ('prerelease' if (__version_prerelease == 'True') else ''). ans = formatstring.format(version=__version__,; versionlong=__version_long,; githash=__version_long[len(__version__)+1:],; clean='' if __version_is_clean == 'True' else 'dirty',; branch=__version_branch_name,; lastrel=__version_last_release,; cmake=__version_cmake,; release=release); return ans. if __name__ == '__main__':; print(version_formatter(formatstring='all')); ```. So I think tarballs are roughly still working. But I can totally believe that either I'm working in an edge case or the two of you have found one. My closest suspects:; * perhaps you're in a repo that isn't the psi repo. I bet that'd defeat https://github.com/psi4/psi4/blob/master/psi4/versioner.py#L50 that switches the version logic from git to tarball; * that version logic is tested for release tarballs only, not tarballs of random commits; * the increasing dependency on qcengine (which arose long after the versioning system design) for finite difference and dispersion depends a lot on computing the psi4 (and other) versions. Hence the ""pull tags"" message. I can believe there's a way that communication breaks down. I'd suggest you compare commands and cat-ed files and see where the discrepancy in workflow/environment arises.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:580,Modifiability,config,configure,580,"> Tarballs downloaded from GitHub are not git repositories. We use them in FreeBSD ports.; Nothing important should be hard-wired to Git during build/tests. I agree broadly, though I'd sacrifice it to get fine-grain versioning for cross-project communication if needed :-). The way psi is set up now, if the buildsys detects that it's not a git repo, it substitutes some generic most-recent-tag info and proceeds, so that one gets a working build. When I try, it works as planned:. acquire tarball; ```; > curl -L https://github.com/psi4/psi4/tarball/master -o psi4_v17.tgz; ```; configure and build -- it detects ""no git""; ```; # configure (all req'd deps detected except optking to be build from src); > cmake --build . -j12; ...; [ 88%] Performing build step for 'psi4-core'; [ 1%] Generating version info; [ 1%] Building CXX object src/psi4/lib3index/CMakeFiles/3index.dir/dftensor.cc.o; ...; [ 2%] Building CXX object src/CMakeFiles/l2export.dir/export_mints.cc.o; Blindly (no git) accepting release version: 1.7+6ce35a5 (recorded); 1.7 {} 6ce35a5 1.7.0.0 release 1.7 <-- 1.7+6ce35a5; [ 2%] Built target update_version; [ 2%] Building CXX object src/psi4/libciomr/CMakeFiles/ciomr.dir/dsyev_ascending.cc.o; ...; ```; version computes and simple test, distributed driver tests, and dftd3 addon tests work ok; ```; > stage/bin/psi4 --psiapi # execute results; >>> stage/bin/psi4 --version; 1.7; >>> ctest -R tu1; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 426: tu1-h2o-energy; 1/1 Test #426: tu1-h2o-energy ................... Passed 1.65 sec. 100% tests passed, 0 tests failed out of 1; >>> ctest -R ddd; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 479: ddd-deriv; 1/2 Test #479: ddd-deriv ........................ Passed 13.18 sec; Start 481: ddd-function-kwargs; 2/2 Test #481: ddd-function-kwargs .............. Passed 170.20 sec. 100% tests passed, 0 tests failed out of 2; >>> ctest -R dftd3; Test project /psi/gits/tarbuild/psi4-psi4-4d94",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:631,Modifiability,config,configure,631,"> Tarballs downloaded from GitHub are not git repositories. We use them in FreeBSD ports.; Nothing important should be hard-wired to Git during build/tests. I agree broadly, though I'd sacrifice it to get fine-grain versioning for cross-project communication if needed :-). The way psi is set up now, if the buildsys detects that it's not a git repo, it substitutes some generic most-recent-tag info and proceeds, so that one gets a working build. When I try, it works as planned:. acquire tarball; ```; > curl -L https://github.com/psi4/psi4/tarball/master -o psi4_v17.tgz; ```; configure and build -- it detects ""no git""; ```; # configure (all req'd deps detected except optking to be build from src); > cmake --build . -j12; ...; [ 88%] Performing build step for 'psi4-core'; [ 1%] Generating version info; [ 1%] Building CXX object src/psi4/lib3index/CMakeFiles/3index.dir/dftensor.cc.o; ...; [ 2%] Building CXX object src/CMakeFiles/l2export.dir/export_mints.cc.o; Blindly (no git) accepting release version: 1.7+6ce35a5 (recorded); 1.7 {} 6ce35a5 1.7.0.0 release 1.7 <-- 1.7+6ce35a5; [ 2%] Built target update_version; [ 2%] Building CXX object src/psi4/libciomr/CMakeFiles/ciomr.dir/dsyev_ascending.cc.o; ...; ```; version computes and simple test, distributed driver tests, and dftd3 addon tests work ok; ```; > stage/bin/psi4 --psiapi # execute results; >>> stage/bin/psi4 --version; 1.7; >>> ctest -R tu1; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 426: tu1-h2o-energy; 1/1 Test #426: tu1-h2o-energy ................... Passed 1.65 sec. 100% tests passed, 0 tests failed out of 1; >>> ctest -R ddd; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 479: ddd-deriv; 1/2 Test #479: ddd-deriv ........................ Passed 13.18 sec; Start 481: ddd-function-kwargs; 2/2 Test #481: ddd-function-kwargs .............. Passed 170.20 sec. 100% tests passed, 0 tests failed out of 2; >>> ctest -R dftd3; Test project /psi/gits/tarbuild/psi4-psi4-4d94",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:740,Performance,Perform,Performing,740,"> Tarballs downloaded from GitHub are not git repositories. We use them in FreeBSD ports.; Nothing important should be hard-wired to Git during build/tests. I agree broadly, though I'd sacrifice it to get fine-grain versioning for cross-project communication if needed :-). The way psi is set up now, if the buildsys detects that it's not a git repo, it substitutes some generic most-recent-tag info and proceeds, so that one gets a working build. When I try, it works as planned:. acquire tarball; ```; > curl -L https://github.com/psi4/psi4/tarball/master -o psi4_v17.tgz; ```; configure and build -- it detects ""no git""; ```; # configure (all req'd deps detected except optking to be build from src); > cmake --build . -j12; ...; [ 88%] Performing build step for 'psi4-core'; [ 1%] Generating version info; [ 1%] Building CXX object src/psi4/lib3index/CMakeFiles/3index.dir/dftensor.cc.o; ...; [ 2%] Building CXX object src/CMakeFiles/l2export.dir/export_mints.cc.o; Blindly (no git) accepting release version: 1.7+6ce35a5 (recorded); 1.7 {} 6ce35a5 1.7.0.0 release 1.7 <-- 1.7+6ce35a5; [ 2%] Built target update_version; [ 2%] Building CXX object src/psi4/libciomr/CMakeFiles/ciomr.dir/dsyev_ascending.cc.o; ...; ```; version computes and simple test, distributed driver tests, and dftd3 addon tests work ok; ```; > stage/bin/psi4 --psiapi # execute results; >>> stage/bin/psi4 --version; 1.7; >>> ctest -R tu1; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 426: tu1-h2o-energy; 1/1 Test #426: tu1-h2o-energy ................... Passed 1.65 sec. 100% tests passed, 0 tests failed out of 1; >>> ctest -R ddd; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 479: ddd-deriv; 1/2 Test #479: ddd-deriv ........................ Passed 13.18 sec; Start 481: ddd-function-kwargs; 2/2 Test #481: ddd-function-kwargs .............. Passed 170.20 sec. 100% tests passed, 0 tests failed out of 2; >>> ctest -R dftd3; Test project /psi/gits/tarbuild/psi4-psi4-4d94",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:317,Safety,detect,detects,317,"> Tarballs downloaded from GitHub are not git repositories. We use them in FreeBSD ports.; Nothing important should be hard-wired to Git during build/tests. I agree broadly, though I'd sacrifice it to get fine-grain versioning for cross-project communication if needed :-). The way psi is set up now, if the buildsys detects that it's not a git repo, it substitutes some generic most-recent-tag info and proceeds, so that one gets a working build. When I try, it works as planned:. acquire tarball; ```; > curl -L https://github.com/psi4/psi4/tarball/master -o psi4_v17.tgz; ```; configure and build -- it detects ""no git""; ```; # configure (all req'd deps detected except optking to be build from src); > cmake --build . -j12; ...; [ 88%] Performing build step for 'psi4-core'; [ 1%] Generating version info; [ 1%] Building CXX object src/psi4/lib3index/CMakeFiles/3index.dir/dftensor.cc.o; ...; [ 2%] Building CXX object src/CMakeFiles/l2export.dir/export_mints.cc.o; Blindly (no git) accepting release version: 1.7+6ce35a5 (recorded); 1.7 {} 6ce35a5 1.7.0.0 release 1.7 <-- 1.7+6ce35a5; [ 2%] Built target update_version; [ 2%] Building CXX object src/psi4/libciomr/CMakeFiles/ciomr.dir/dsyev_ascending.cc.o; ...; ```; version computes and simple test, distributed driver tests, and dftd3 addon tests work ok; ```; > stage/bin/psi4 --psiapi # execute results; >>> stage/bin/psi4 --version; 1.7; >>> ctest -R tu1; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 426: tu1-h2o-energy; 1/1 Test #426: tu1-h2o-energy ................... Passed 1.65 sec. 100% tests passed, 0 tests failed out of 1; >>> ctest -R ddd; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 479: ddd-deriv; 1/2 Test #479: ddd-deriv ........................ Passed 13.18 sec; Start 481: ddd-function-kwargs; 2/2 Test #481: ddd-function-kwargs .............. Passed 170.20 sec. 100% tests passed, 0 tests failed out of 2; >>> ctest -R dftd3; Test project /psi/gits/tarbuild/psi4-psi4-4d94",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:606,Safety,detect,detects,606,"> Tarballs downloaded from GitHub are not git repositories. We use them in FreeBSD ports.; Nothing important should be hard-wired to Git during build/tests. I agree broadly, though I'd sacrifice it to get fine-grain versioning for cross-project communication if needed :-). The way psi is set up now, if the buildsys detects that it's not a git repo, it substitutes some generic most-recent-tag info and proceeds, so that one gets a working build. When I try, it works as planned:. acquire tarball; ```; > curl -L https://github.com/psi4/psi4/tarball/master -o psi4_v17.tgz; ```; configure and build -- it detects ""no git""; ```; # configure (all req'd deps detected except optking to be build from src); > cmake --build . -j12; ...; [ 88%] Performing build step for 'psi4-core'; [ 1%] Generating version info; [ 1%] Building CXX object src/psi4/lib3index/CMakeFiles/3index.dir/dftensor.cc.o; ...; [ 2%] Building CXX object src/CMakeFiles/l2export.dir/export_mints.cc.o; Blindly (no git) accepting release version: 1.7+6ce35a5 (recorded); 1.7 {} 6ce35a5 1.7.0.0 release 1.7 <-- 1.7+6ce35a5; [ 2%] Built target update_version; [ 2%] Building CXX object src/psi4/libciomr/CMakeFiles/ciomr.dir/dsyev_ascending.cc.o; ...; ```; version computes and simple test, distributed driver tests, and dftd3 addon tests work ok; ```; > stage/bin/psi4 --psiapi # execute results; >>> stage/bin/psi4 --version; 1.7; >>> ctest -R tu1; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 426: tu1-h2o-energy; 1/1 Test #426: tu1-h2o-energy ................... Passed 1.65 sec. 100% tests passed, 0 tests failed out of 1; >>> ctest -R ddd; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 479: ddd-deriv; 1/2 Test #479: ddd-deriv ........................ Passed 13.18 sec; Start 481: ddd-function-kwargs; 2/2 Test #481: ddd-function-kwargs .............. Passed 170.20 sec. 100% tests passed, 0 tests failed out of 2; >>> ctest -R dftd3; Test project /psi/gits/tarbuild/psi4-psi4-4d94",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:657,Safety,detect,detected,657,"> Tarballs downloaded from GitHub are not git repositories. We use them in FreeBSD ports.; Nothing important should be hard-wired to Git during build/tests. I agree broadly, though I'd sacrifice it to get fine-grain versioning for cross-project communication if needed :-). The way psi is set up now, if the buildsys detects that it's not a git repo, it substitutes some generic most-recent-tag info and proceeds, so that one gets a working build. When I try, it works as planned:. acquire tarball; ```; > curl -L https://github.com/psi4/psi4/tarball/master -o psi4_v17.tgz; ```; configure and build -- it detects ""no git""; ```; # configure (all req'd deps detected except optking to be build from src); > cmake --build . -j12; ...; [ 88%] Performing build step for 'psi4-core'; [ 1%] Generating version info; [ 1%] Building CXX object src/psi4/lib3index/CMakeFiles/3index.dir/dftensor.cc.o; ...; [ 2%] Building CXX object src/CMakeFiles/l2export.dir/export_mints.cc.o; Blindly (no git) accepting release version: 1.7+6ce35a5 (recorded); 1.7 {} 6ce35a5 1.7.0.0 release 1.7 <-- 1.7+6ce35a5; [ 2%] Built target update_version; [ 2%] Building CXX object src/psi4/libciomr/CMakeFiles/ciomr.dir/dsyev_ascending.cc.o; ...; ```; version computes and simple test, distributed driver tests, and dftd3 addon tests work ok; ```; > stage/bin/psi4 --psiapi # execute results; >>> stage/bin/psi4 --version; 1.7; >>> ctest -R tu1; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 426: tu1-h2o-energy; 1/1 Test #426: tu1-h2o-energy ................... Passed 1.65 sec. 100% tests passed, 0 tests failed out of 1; >>> ctest -R ddd; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 479: ddd-deriv; 1/2 Test #479: ddd-deriv ........................ Passed 13.18 sec; Start 481: ddd-function-kwargs; 2/2 Test #481: ddd-function-kwargs .............. Passed 170.20 sec. 100% tests passed, 0 tests failed out of 2; >>> ctest -R dftd3; Test project /psi/gits/tarbuild/psi4-psi4-4d94",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:150,Testability,test,tests,150,"> Tarballs downloaded from GitHub are not git repositories. We use them in FreeBSD ports.; Nothing important should be hard-wired to Git during build/tests. I agree broadly, though I'd sacrifice it to get fine-grain versioning for cross-project communication if needed :-). The way psi is set up now, if the buildsys detects that it's not a git repo, it substitutes some generic most-recent-tag info and proceeds, so that one gets a working build. When I try, it works as planned:. acquire tarball; ```; > curl -L https://github.com/psi4/psi4/tarball/master -o psi4_v17.tgz; ```; configure and build -- it detects ""no git""; ```; # configure (all req'd deps detected except optking to be build from src); > cmake --build . -j12; ...; [ 88%] Performing build step for 'psi4-core'; [ 1%] Generating version info; [ 1%] Building CXX object src/psi4/lib3index/CMakeFiles/3index.dir/dftensor.cc.o; ...; [ 2%] Building CXX object src/CMakeFiles/l2export.dir/export_mints.cc.o; Blindly (no git) accepting release version: 1.7+6ce35a5 (recorded); 1.7 {} 6ce35a5 1.7.0.0 release 1.7 <-- 1.7+6ce35a5; [ 2%] Built target update_version; [ 2%] Building CXX object src/psi4/libciomr/CMakeFiles/ciomr.dir/dsyev_ascending.cc.o; ...; ```; version computes and simple test, distributed driver tests, and dftd3 addon tests work ok; ```; > stage/bin/psi4 --psiapi # execute results; >>> stage/bin/psi4 --version; 1.7; >>> ctest -R tu1; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 426: tu1-h2o-energy; 1/1 Test #426: tu1-h2o-energy ................... Passed 1.65 sec. 100% tests passed, 0 tests failed out of 1; >>> ctest -R ddd; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 479: ddd-deriv; 1/2 Test #479: ddd-deriv ........................ Passed 13.18 sec; Start 481: ddd-function-kwargs; 2/2 Test #481: ddd-function-kwargs .............. Passed 170.20 sec. 100% tests passed, 0 tests failed out of 2; >>> ctest -R dftd3; Test project /psi/gits/tarbuild/psi4-psi4-4d94",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:1250,Testability,test,test,1250,"he buildsys detects that it's not a git repo, it substitutes some generic most-recent-tag info and proceeds, so that one gets a working build. When I try, it works as planned:. acquire tarball; ```; > curl -L https://github.com/psi4/psi4/tarball/master -o psi4_v17.tgz; ```; configure and build -- it detects ""no git""; ```; # configure (all req'd deps detected except optking to be build from src); > cmake --build . -j12; ...; [ 88%] Performing build step for 'psi4-core'; [ 1%] Generating version info; [ 1%] Building CXX object src/psi4/lib3index/CMakeFiles/3index.dir/dftensor.cc.o; ...; [ 2%] Building CXX object src/CMakeFiles/l2export.dir/export_mints.cc.o; Blindly (no git) accepting release version: 1.7+6ce35a5 (recorded); 1.7 {} 6ce35a5 1.7.0.0 release 1.7 <-- 1.7+6ce35a5; [ 2%] Built target update_version; [ 2%] Building CXX object src/psi4/libciomr/CMakeFiles/ciomr.dir/dsyev_ascending.cc.o; ...; ```; version computes and simple test, distributed driver tests, and dftd3 addon tests work ok; ```; > stage/bin/psi4 --psiapi # execute results; >>> stage/bin/psi4 --version; 1.7; >>> ctest -R tu1; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 426: tu1-h2o-energy; 1/1 Test #426: tu1-h2o-energy ................... Passed 1.65 sec. 100% tests passed, 0 tests failed out of 1; >>> ctest -R ddd; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 479: ddd-deriv; 1/2 Test #479: ddd-deriv ........................ Passed 13.18 sec; Start 481: ddd-function-kwargs; 2/2 Test #481: ddd-function-kwargs .............. Passed 170.20 sec. 100% tests passed, 0 tests failed out of 2; >>> ctest -R dftd3; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 510: dftd3-energy; 1/5 Test #510: dftd3-energy ..................... Passed 24.64 sec; Start 511: dftd3-grad; 2/5 Test #511: dftd3-grad ....................... Passed 11.33 sec; Start 512: dftd3-psithon2; 3/5 Test #512: dftd3-psithon2 ................... Passed 13.39 sec; Start 5",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:1275,Testability,test,tests,1275,"he buildsys detects that it's not a git repo, it substitutes some generic most-recent-tag info and proceeds, so that one gets a working build. When I try, it works as planned:. acquire tarball; ```; > curl -L https://github.com/psi4/psi4/tarball/master -o psi4_v17.tgz; ```; configure and build -- it detects ""no git""; ```; # configure (all req'd deps detected except optking to be build from src); > cmake --build . -j12; ...; [ 88%] Performing build step for 'psi4-core'; [ 1%] Generating version info; [ 1%] Building CXX object src/psi4/lib3index/CMakeFiles/3index.dir/dftensor.cc.o; ...; [ 2%] Building CXX object src/CMakeFiles/l2export.dir/export_mints.cc.o; Blindly (no git) accepting release version: 1.7+6ce35a5 (recorded); 1.7 {} 6ce35a5 1.7.0.0 release 1.7 <-- 1.7+6ce35a5; [ 2%] Built target update_version; [ 2%] Building CXX object src/psi4/libciomr/CMakeFiles/ciomr.dir/dsyev_ascending.cc.o; ...; ```; version computes and simple test, distributed driver tests, and dftd3 addon tests work ok; ```; > stage/bin/psi4 --psiapi # execute results; >>> stage/bin/psi4 --version; 1.7; >>> ctest -R tu1; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 426: tu1-h2o-energy; 1/1 Test #426: tu1-h2o-energy ................... Passed 1.65 sec. 100% tests passed, 0 tests failed out of 1; >>> ctest -R ddd; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 479: ddd-deriv; 1/2 Test #479: ddd-deriv ........................ Passed 13.18 sec; Start 481: ddd-function-kwargs; 2/2 Test #481: ddd-function-kwargs .............. Passed 170.20 sec. 100% tests passed, 0 tests failed out of 2; >>> ctest -R dftd3; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 510: dftd3-energy; 1/5 Test #510: dftd3-energy ..................... Passed 24.64 sec; Start 511: dftd3-grad; 2/5 Test #511: dftd3-grad ....................... Passed 11.33 sec; Start 512: dftd3-psithon2; 3/5 Test #512: dftd3-psithon2 ................... Passed 13.39 sec; Start 5",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:1298,Testability,test,tests,1298,"he buildsys detects that it's not a git repo, it substitutes some generic most-recent-tag info and proceeds, so that one gets a working build. When I try, it works as planned:. acquire tarball; ```; > curl -L https://github.com/psi4/psi4/tarball/master -o psi4_v17.tgz; ```; configure and build -- it detects ""no git""; ```; # configure (all req'd deps detected except optking to be build from src); > cmake --build . -j12; ...; [ 88%] Performing build step for 'psi4-core'; [ 1%] Generating version info; [ 1%] Building CXX object src/psi4/lib3index/CMakeFiles/3index.dir/dftensor.cc.o; ...; [ 2%] Building CXX object src/CMakeFiles/l2export.dir/export_mints.cc.o; Blindly (no git) accepting release version: 1.7+6ce35a5 (recorded); 1.7 {} 6ce35a5 1.7.0.0 release 1.7 <-- 1.7+6ce35a5; [ 2%] Built target update_version; [ 2%] Building CXX object src/psi4/libciomr/CMakeFiles/ciomr.dir/dsyev_ascending.cc.o; ...; ```; version computes and simple test, distributed driver tests, and dftd3 addon tests work ok; ```; > stage/bin/psi4 --psiapi # execute results; >>> stage/bin/psi4 --version; 1.7; >>> ctest -R tu1; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 426: tu1-h2o-energy; 1/1 Test #426: tu1-h2o-energy ................... Passed 1.65 sec. 100% tests passed, 0 tests failed out of 1; >>> ctest -R ddd; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 479: ddd-deriv; 1/2 Test #479: ddd-deriv ........................ Passed 13.18 sec; Start 481: ddd-function-kwargs; 2/2 Test #481: ddd-function-kwargs .............. Passed 170.20 sec. 100% tests passed, 0 tests failed out of 2; >>> ctest -R dftd3; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 510: dftd3-energy; 1/5 Test #510: dftd3-energy ..................... Passed 24.64 sec; Start 511: dftd3-grad; 2/5 Test #511: dftd3-grad ....................... Passed 11.33 sec; Start 512: dftd3-psithon2; 3/5 Test #512: dftd3-psithon2 ................... Passed 13.39 sec; Start 5",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:1416,Testability,Test,Test,1416,"ks as planned:. acquire tarball; ```; > curl -L https://github.com/psi4/psi4/tarball/master -o psi4_v17.tgz; ```; configure and build -- it detects ""no git""; ```; # configure (all req'd deps detected except optking to be build from src); > cmake --build . -j12; ...; [ 88%] Performing build step for 'psi4-core'; [ 1%] Generating version info; [ 1%] Building CXX object src/psi4/lib3index/CMakeFiles/3index.dir/dftensor.cc.o; ...; [ 2%] Building CXX object src/CMakeFiles/l2export.dir/export_mints.cc.o; Blindly (no git) accepting release version: 1.7+6ce35a5 (recorded); 1.7 {} 6ce35a5 1.7.0.0 release 1.7 <-- 1.7+6ce35a5; [ 2%] Built target update_version; [ 2%] Building CXX object src/psi4/libciomr/CMakeFiles/ciomr.dir/dsyev_ascending.cc.o; ...; ```; version computes and simple test, distributed driver tests, and dftd3 addon tests work ok; ```; > stage/bin/psi4 --psiapi # execute results; >>> stage/bin/psi4 --version; 1.7; >>> ctest -R tu1; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 426: tu1-h2o-energy; 1/1 Test #426: tu1-h2o-energy ................... Passed 1.65 sec. 100% tests passed, 0 tests failed out of 1; >>> ctest -R ddd; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 479: ddd-deriv; 1/2 Test #479: ddd-deriv ........................ Passed 13.18 sec; Start 481: ddd-function-kwargs; 2/2 Test #481: ddd-function-kwargs .............. Passed 170.20 sec. 100% tests passed, 0 tests failed out of 2; >>> ctest -R dftd3; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 510: dftd3-energy; 1/5 Test #510: dftd3-energy ..................... Passed 24.64 sec; Start 511: dftd3-grad; 2/5 Test #511: dftd3-grad ....................... Passed 11.33 sec; Start 512: dftd3-psithon2; 3/5 Test #512: dftd3-psithon2 ................... Passed 13.39 sec; Start 513: dftd3-version; 4/5 Test #513: dftd3-version .................... Passed 27.06 sec; Start 514: dftd3-nbody-cp-gradient; 5/5 Test #514: dftd3-nbody-cp-gradient ",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:1511,Testability,Test,Test,1511,"ks as planned:. acquire tarball; ```; > curl -L https://github.com/psi4/psi4/tarball/master -o psi4_v17.tgz; ```; configure and build -- it detects ""no git""; ```; # configure (all req'd deps detected except optking to be build from src); > cmake --build . -j12; ...; [ 88%] Performing build step for 'psi4-core'; [ 1%] Generating version info; [ 1%] Building CXX object src/psi4/lib3index/CMakeFiles/3index.dir/dftensor.cc.o; ...; [ 2%] Building CXX object src/CMakeFiles/l2export.dir/export_mints.cc.o; Blindly (no git) accepting release version: 1.7+6ce35a5 (recorded); 1.7 {} 6ce35a5 1.7.0.0 release 1.7 <-- 1.7+6ce35a5; [ 2%] Built target update_version; [ 2%] Building CXX object src/psi4/libciomr/CMakeFiles/ciomr.dir/dsyev_ascending.cc.o; ...; ```; version computes and simple test, distributed driver tests, and dftd3 addon tests work ok; ```; > stage/bin/psi4 --psiapi # execute results; >>> stage/bin/psi4 --version; 1.7; >>> ctest -R tu1; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 426: tu1-h2o-energy; 1/1 Test #426: tu1-h2o-energy ................... Passed 1.65 sec. 100% tests passed, 0 tests failed out of 1; >>> ctest -R ddd; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 479: ddd-deriv; 1/2 Test #479: ddd-deriv ........................ Passed 13.18 sec; Start 481: ddd-function-kwargs; 2/2 Test #481: ddd-function-kwargs .............. Passed 170.20 sec. 100% tests passed, 0 tests failed out of 2; >>> ctest -R dftd3; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 510: dftd3-energy; 1/5 Test #510: dftd3-energy ..................... Passed 24.64 sec; Start 511: dftd3-grad; 2/5 Test #511: dftd3-grad ....................... Passed 11.33 sec; Start 512: dftd3-psithon2; 3/5 Test #512: dftd3-psithon2 ................... Passed 13.39 sec; Start 513: dftd3-version; 4/5 Test #513: dftd3-version .................... Passed 27.06 sec; Start 514: dftd3-nbody-cp-gradient; 5/5 Test #514: dftd3-nbody-cp-gradient ",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:1579,Testability,test,tests,1579,"ected except optking to be build from src); > cmake --build . -j12; ...; [ 88%] Performing build step for 'psi4-core'; [ 1%] Generating version info; [ 1%] Building CXX object src/psi4/lib3index/CMakeFiles/3index.dir/dftensor.cc.o; ...; [ 2%] Building CXX object src/CMakeFiles/l2export.dir/export_mints.cc.o; Blindly (no git) accepting release version: 1.7+6ce35a5 (recorded); 1.7 {} 6ce35a5 1.7.0.0 release 1.7 <-- 1.7+6ce35a5; [ 2%] Built target update_version; [ 2%] Building CXX object src/psi4/libciomr/CMakeFiles/ciomr.dir/dsyev_ascending.cc.o; ...; ```; version computes and simple test, distributed driver tests, and dftd3 addon tests work ok; ```; > stage/bin/psi4 --psiapi # execute results; >>> stage/bin/psi4 --version; 1.7; >>> ctest -R tu1; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 426: tu1-h2o-energy; 1/1 Test #426: tu1-h2o-energy ................... Passed 1.65 sec. 100% tests passed, 0 tests failed out of 1; >>> ctest -R ddd; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 479: ddd-deriv; 1/2 Test #479: ddd-deriv ........................ Passed 13.18 sec; Start 481: ddd-function-kwargs; 2/2 Test #481: ddd-function-kwargs .............. Passed 170.20 sec. 100% tests passed, 0 tests failed out of 2; >>> ctest -R dftd3; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 510: dftd3-energy; 1/5 Test #510: dftd3-energy ..................... Passed 24.64 sec; Start 511: dftd3-grad; 2/5 Test #511: dftd3-grad ....................... Passed 11.33 sec; Start 512: dftd3-psithon2; 3/5 Test #512: dftd3-psithon2 ................... Passed 13.39 sec; Start 513: dftd3-version; 4/5 Test #513: dftd3-version .................... Passed 27.06 sec; Start 514: dftd3-nbody-cp-gradient; 5/5 Test #514: dftd3-nbody-cp-gradient .......... Passed 33.83 sec. 100% tests passed, 0 tests failed out of 5; ```; version control files have stuff in src and built forms; ```; > cat ../psi4/metadata.py ; __version__ = '1.7'; __ver",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:1595,Testability,test,tests,1595,"ected except optking to be build from src); > cmake --build . -j12; ...; [ 88%] Performing build step for 'psi4-core'; [ 1%] Generating version info; [ 1%] Building CXX object src/psi4/lib3index/CMakeFiles/3index.dir/dftensor.cc.o; ...; [ 2%] Building CXX object src/CMakeFiles/l2export.dir/export_mints.cc.o; Blindly (no git) accepting release version: 1.7+6ce35a5 (recorded); 1.7 {} 6ce35a5 1.7.0.0 release 1.7 <-- 1.7+6ce35a5; [ 2%] Built target update_version; [ 2%] Building CXX object src/psi4/libciomr/CMakeFiles/ciomr.dir/dsyev_ascending.cc.o; ...; ```; version computes and simple test, distributed driver tests, and dftd3 addon tests work ok; ```; > stage/bin/psi4 --psiapi # execute results; >>> stage/bin/psi4 --version; 1.7; >>> ctest -R tu1; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 426: tu1-h2o-energy; 1/1 Test #426: tu1-h2o-energy ................... Passed 1.65 sec. 100% tests passed, 0 tests failed out of 1; >>> ctest -R ddd; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 479: ddd-deriv; 1/2 Test #479: ddd-deriv ........................ Passed 13.18 sec; Start 481: ddd-function-kwargs; 2/2 Test #481: ddd-function-kwargs .............. Passed 170.20 sec. 100% tests passed, 0 tests failed out of 2; >>> ctest -R dftd3; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 510: dftd3-energy; 1/5 Test #510: dftd3-energy ..................... Passed 24.64 sec; Start 511: dftd3-grad; 2/5 Test #511: dftd3-grad ....................... Passed 11.33 sec; Start 512: dftd3-psithon2; 3/5 Test #512: dftd3-psithon2 ................... Passed 13.39 sec; Start 513: dftd3-version; 4/5 Test #513: dftd3-version .................... Passed 27.06 sec; Start 514: dftd3-nbody-cp-gradient; 5/5 Test #514: dftd3-nbody-cp-gradient .......... Passed 33.83 sec. 100% tests passed, 0 tests failed out of 5; ```; version control files have stuff in src and built forms; ```; > cat ../psi4/metadata.py ; __version__ = '1.7'; __ver",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:1636,Testability,Test,Test,1636,"ected except optking to be build from src); > cmake --build . -j12; ...; [ 88%] Performing build step for 'psi4-core'; [ 1%] Generating version info; [ 1%] Building CXX object src/psi4/lib3index/CMakeFiles/3index.dir/dftensor.cc.o; ...; [ 2%] Building CXX object src/CMakeFiles/l2export.dir/export_mints.cc.o; Blindly (no git) accepting release version: 1.7+6ce35a5 (recorded); 1.7 {} 6ce35a5 1.7.0.0 release 1.7 <-- 1.7+6ce35a5; [ 2%] Built target update_version; [ 2%] Building CXX object src/psi4/libciomr/CMakeFiles/ciomr.dir/dsyev_ascending.cc.o; ...; ```; version computes and simple test, distributed driver tests, and dftd3 addon tests work ok; ```; > stage/bin/psi4 --psiapi # execute results; >>> stage/bin/psi4 --version; 1.7; >>> ctest -R tu1; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 426: tu1-h2o-energy; 1/1 Test #426: tu1-h2o-energy ................... Passed 1.65 sec. 100% tests passed, 0 tests failed out of 1; >>> ctest -R ddd; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 479: ddd-deriv; 1/2 Test #479: ddd-deriv ........................ Passed 13.18 sec; Start 481: ddd-function-kwargs; 2/2 Test #481: ddd-function-kwargs .............. Passed 170.20 sec. 100% tests passed, 0 tests failed out of 2; >>> ctest -R dftd3; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 510: dftd3-energy; 1/5 Test #510: dftd3-energy ..................... Passed 24.64 sec; Start 511: dftd3-grad; 2/5 Test #511: dftd3-grad ....................... Passed 11.33 sec; Start 512: dftd3-psithon2; 3/5 Test #512: dftd3-psithon2 ................... Passed 13.39 sec; Start 513: dftd3-version; 4/5 Test #513: dftd3-version .................... Passed 27.06 sec; Start 514: dftd3-nbody-cp-gradient; 5/5 Test #514: dftd3-nbody-cp-gradient .......... Passed 33.83 sec. 100% tests passed, 0 tests failed out of 5; ```; version control files have stuff in src and built forms; ```; > cat ../psi4/metadata.py ; __version__ = '1.7'; __ver",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:1726,Testability,Test,Test,1726,"ected except optking to be build from src); > cmake --build . -j12; ...; [ 88%] Performing build step for 'psi4-core'; [ 1%] Generating version info; [ 1%] Building CXX object src/psi4/lib3index/CMakeFiles/3index.dir/dftensor.cc.o; ...; [ 2%] Building CXX object src/CMakeFiles/l2export.dir/export_mints.cc.o; Blindly (no git) accepting release version: 1.7+6ce35a5 (recorded); 1.7 {} 6ce35a5 1.7.0.0 release 1.7 <-- 1.7+6ce35a5; [ 2%] Built target update_version; [ 2%] Building CXX object src/psi4/libciomr/CMakeFiles/ciomr.dir/dsyev_ascending.cc.o; ...; ```; version computes and simple test, distributed driver tests, and dftd3 addon tests work ok; ```; > stage/bin/psi4 --psiapi # execute results; >>> stage/bin/psi4 --version; 1.7; >>> ctest -R tu1; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 426: tu1-h2o-energy; 1/1 Test #426: tu1-h2o-energy ................... Passed 1.65 sec. 100% tests passed, 0 tests failed out of 1; >>> ctest -R ddd; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 479: ddd-deriv; 1/2 Test #479: ddd-deriv ........................ Passed 13.18 sec; Start 481: ddd-function-kwargs; 2/2 Test #481: ddd-function-kwargs .............. Passed 170.20 sec. 100% tests passed, 0 tests failed out of 2; >>> ctest -R dftd3; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 510: dftd3-energy; 1/5 Test #510: dftd3-energy ..................... Passed 24.64 sec; Start 511: dftd3-grad; 2/5 Test #511: dftd3-grad ....................... Passed 11.33 sec; Start 512: dftd3-psithon2; 3/5 Test #512: dftd3-psithon2 ................... Passed 13.39 sec; Start 513: dftd3-version; 4/5 Test #513: dftd3-version .................... Passed 27.06 sec; Start 514: dftd3-nbody-cp-gradient; 5/5 Test #514: dftd3-nbody-cp-gradient .......... Passed 33.83 sec. 100% tests passed, 0 tests failed out of 5; ```; version control files have stuff in src and built forms; ```; > cat ../psi4/metadata.py ; __version__ = '1.7'; __ver",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:1826,Testability,Test,Test,1826,"ding CXX object src/psi4/lib3index/CMakeFiles/3index.dir/dftensor.cc.o; ...; [ 2%] Building CXX object src/CMakeFiles/l2export.dir/export_mints.cc.o; Blindly (no git) accepting release version: 1.7+6ce35a5 (recorded); 1.7 {} 6ce35a5 1.7.0.0 release 1.7 <-- 1.7+6ce35a5; [ 2%] Built target update_version; [ 2%] Building CXX object src/psi4/libciomr/CMakeFiles/ciomr.dir/dsyev_ascending.cc.o; ...; ```; version computes and simple test, distributed driver tests, and dftd3 addon tests work ok; ```; > stage/bin/psi4 --psiapi # execute results; >>> stage/bin/psi4 --version; 1.7; >>> ctest -R tu1; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 426: tu1-h2o-energy; 1/1 Test #426: tu1-h2o-energy ................... Passed 1.65 sec. 100% tests passed, 0 tests failed out of 1; >>> ctest -R ddd; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 479: ddd-deriv; 1/2 Test #479: ddd-deriv ........................ Passed 13.18 sec; Start 481: ddd-function-kwargs; 2/2 Test #481: ddd-function-kwargs .............. Passed 170.20 sec. 100% tests passed, 0 tests failed out of 2; >>> ctest -R dftd3; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 510: dftd3-energy; 1/5 Test #510: dftd3-energy ..................... Passed 24.64 sec; Start 511: dftd3-grad; 2/5 Test #511: dftd3-grad ....................... Passed 11.33 sec; Start 512: dftd3-psithon2; 3/5 Test #512: dftd3-psithon2 ................... Passed 13.39 sec; Start 513: dftd3-version; 4/5 Test #513: dftd3-version .................... Passed 27.06 sec; Start 514: dftd3-nbody-cp-gradient; 5/5 Test #514: dftd3-nbody-cp-gradient .......... Passed 33.83 sec. 100% tests passed, 0 tests failed out of 5; ```; version control files have stuff in src and built forms; ```; > cat ../psi4/metadata.py ; __version__ = '1.7'; __version_long = '1.7+6ce35a5'; __version_upcoming_annotated_v_tag = '1.8a1'. def version_formatter(dummy):; return '(inplace)'; > cat stage/lib/psi4/metadata.py ; ",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:1896,Testability,test,tests,1896," git) accepting release version: 1.7+6ce35a5 (recorded); 1.7 {} 6ce35a5 1.7.0.0 release 1.7 <-- 1.7+6ce35a5; [ 2%] Built target update_version; [ 2%] Building CXX object src/psi4/libciomr/CMakeFiles/ciomr.dir/dsyev_ascending.cc.o; ...; ```; version computes and simple test, distributed driver tests, and dftd3 addon tests work ok; ```; > stage/bin/psi4 --psiapi # execute results; >>> stage/bin/psi4 --version; 1.7; >>> ctest -R tu1; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 426: tu1-h2o-energy; 1/1 Test #426: tu1-h2o-energy ................... Passed 1.65 sec. 100% tests passed, 0 tests failed out of 1; >>> ctest -R ddd; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 479: ddd-deriv; 1/2 Test #479: ddd-deriv ........................ Passed 13.18 sec; Start 481: ddd-function-kwargs; 2/2 Test #481: ddd-function-kwargs .............. Passed 170.20 sec. 100% tests passed, 0 tests failed out of 2; >>> ctest -R dftd3; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 510: dftd3-energy; 1/5 Test #510: dftd3-energy ..................... Passed 24.64 sec; Start 511: dftd3-grad; 2/5 Test #511: dftd3-grad ....................... Passed 11.33 sec; Start 512: dftd3-psithon2; 3/5 Test #512: dftd3-psithon2 ................... Passed 13.39 sec; Start 513: dftd3-version; 4/5 Test #513: dftd3-version .................... Passed 27.06 sec; Start 514: dftd3-nbody-cp-gradient; 5/5 Test #514: dftd3-nbody-cp-gradient .......... Passed 33.83 sec. 100% tests passed, 0 tests failed out of 5; ```; version control files have stuff in src and built forms; ```; > cat ../psi4/metadata.py ; __version__ = '1.7'; __version_long = '1.7+6ce35a5'; __version_upcoming_annotated_v_tag = '1.8a1'. def version_formatter(dummy):; return '(inplace)'; > cat stage/lib/psi4/metadata.py ; __version__ = '1.7'; __version_branch_name = ''; __version_cmake = '1.7.0.0'; __version_is_clean = 'True'; __version_last_release = '1.7'; __version_long = '1.7+6",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:1912,Testability,test,tests,1912," git) accepting release version: 1.7+6ce35a5 (recorded); 1.7 {} 6ce35a5 1.7.0.0 release 1.7 <-- 1.7+6ce35a5; [ 2%] Built target update_version; [ 2%] Building CXX object src/psi4/libciomr/CMakeFiles/ciomr.dir/dsyev_ascending.cc.o; ...; ```; version computes and simple test, distributed driver tests, and dftd3 addon tests work ok; ```; > stage/bin/psi4 --psiapi # execute results; >>> stage/bin/psi4 --version; 1.7; >>> ctest -R tu1; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 426: tu1-h2o-energy; 1/1 Test #426: tu1-h2o-energy ................... Passed 1.65 sec. 100% tests passed, 0 tests failed out of 1; >>> ctest -R ddd; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 479: ddd-deriv; 1/2 Test #479: ddd-deriv ........................ Passed 13.18 sec; Start 481: ddd-function-kwargs; 2/2 Test #481: ddd-function-kwargs .............. Passed 170.20 sec. 100% tests passed, 0 tests failed out of 2; >>> ctest -R dftd3; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 510: dftd3-energy; 1/5 Test #510: dftd3-energy ..................... Passed 24.64 sec; Start 511: dftd3-grad; 2/5 Test #511: dftd3-grad ....................... Passed 11.33 sec; Start 512: dftd3-psithon2; 3/5 Test #512: dftd3-psithon2 ................... Passed 13.39 sec; Start 513: dftd3-version; 4/5 Test #513: dftd3-version .................... Passed 27.06 sec; Start 514: dftd3-nbody-cp-gradient; 5/5 Test #514: dftd3-nbody-cp-gradient .......... Passed 33.83 sec. 100% tests passed, 0 tests failed out of 5; ```; version control files have stuff in src and built forms; ```; > cat ../psi4/metadata.py ; __version__ = '1.7'; __version_long = '1.7+6ce35a5'; __version_upcoming_annotated_v_tag = '1.8a1'. def version_formatter(dummy):; return '(inplace)'; > cat stage/lib/psi4/metadata.py ; __version__ = '1.7'; __version_branch_name = ''; __version_cmake = '1.7.0.0'; __version_is_clean = 'True'; __version_last_release = '1.7'; __version_long = '1.7+6",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:1955,Testability,Test,Test,1955," git) accepting release version: 1.7+6ce35a5 (recorded); 1.7 {} 6ce35a5 1.7.0.0 release 1.7 <-- 1.7+6ce35a5; [ 2%] Built target update_version; [ 2%] Building CXX object src/psi4/libciomr/CMakeFiles/ciomr.dir/dsyev_ascending.cc.o; ...; ```; version computes and simple test, distributed driver tests, and dftd3 addon tests work ok; ```; > stage/bin/psi4 --psiapi # execute results; >>> stage/bin/psi4 --version; 1.7; >>> ctest -R tu1; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 426: tu1-h2o-energy; 1/1 Test #426: tu1-h2o-energy ................... Passed 1.65 sec. 100% tests passed, 0 tests failed out of 1; >>> ctest -R ddd; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 479: ddd-deriv; 1/2 Test #479: ddd-deriv ........................ Passed 13.18 sec; Start 481: ddd-function-kwargs; 2/2 Test #481: ddd-function-kwargs .............. Passed 170.20 sec. 100% tests passed, 0 tests failed out of 2; >>> ctest -R dftd3; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 510: dftd3-energy; 1/5 Test #510: dftd3-energy ..................... Passed 24.64 sec; Start 511: dftd3-grad; 2/5 Test #511: dftd3-grad ....................... Passed 11.33 sec; Start 512: dftd3-psithon2; 3/5 Test #512: dftd3-psithon2 ................... Passed 13.39 sec; Start 513: dftd3-version; 4/5 Test #513: dftd3-version .................... Passed 27.06 sec; Start 514: dftd3-nbody-cp-gradient; 5/5 Test #514: dftd3-nbody-cp-gradient .......... Passed 33.83 sec. 100% tests passed, 0 tests failed out of 5; ```; version control files have stuff in src and built forms; ```; > cat ../psi4/metadata.py ; __version__ = '1.7'; __version_long = '1.7+6ce35a5'; __version_upcoming_annotated_v_tag = '1.8a1'. def version_formatter(dummy):; return '(inplace)'; > cat stage/lib/psi4/metadata.py ; __version__ = '1.7'; __version_branch_name = ''; __version_cmake = '1.7.0.0'; __version_is_clean = 'True'; __version_last_release = '1.7'; __version_long = '1.7+6",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:2048,Testability,Test,Test,2048," git) accepting release version: 1.7+6ce35a5 (recorded); 1.7 {} 6ce35a5 1.7.0.0 release 1.7 <-- 1.7+6ce35a5; [ 2%] Built target update_version; [ 2%] Building CXX object src/psi4/libciomr/CMakeFiles/ciomr.dir/dsyev_ascending.cc.o; ...; ```; version computes and simple test, distributed driver tests, and dftd3 addon tests work ok; ```; > stage/bin/psi4 --psiapi # execute results; >>> stage/bin/psi4 --version; 1.7; >>> ctest -R tu1; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 426: tu1-h2o-energy; 1/1 Test #426: tu1-h2o-energy ................... Passed 1.65 sec. 100% tests passed, 0 tests failed out of 1; >>> ctest -R ddd; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 479: ddd-deriv; 1/2 Test #479: ddd-deriv ........................ Passed 13.18 sec; Start 481: ddd-function-kwargs; 2/2 Test #481: ddd-function-kwargs .............. Passed 170.20 sec. 100% tests passed, 0 tests failed out of 2; >>> ctest -R dftd3; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 510: dftd3-energy; 1/5 Test #510: dftd3-energy ..................... Passed 24.64 sec; Start 511: dftd3-grad; 2/5 Test #511: dftd3-grad ....................... Passed 11.33 sec; Start 512: dftd3-psithon2; 3/5 Test #512: dftd3-psithon2 ................... Passed 13.39 sec; Start 513: dftd3-version; 4/5 Test #513: dftd3-version .................... Passed 27.06 sec; Start 514: dftd3-nbody-cp-gradient; 5/5 Test #514: dftd3-nbody-cp-gradient .......... Passed 33.83 sec. 100% tests passed, 0 tests failed out of 5; ```; version control files have stuff in src and built forms; ```; > cat ../psi4/metadata.py ; __version__ = '1.7'; __version_long = '1.7+6ce35a5'; __version_upcoming_annotated_v_tag = '1.8a1'. def version_formatter(dummy):; return '(inplace)'; > cat stage/lib/psi4/metadata.py ; __version__ = '1.7'; __version_branch_name = ''; __version_cmake = '1.7.0.0'; __version_is_clean = 'True'; __version_last_release = '1.7'; __version_long = '1.7+6",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:2139,Testability,Test,Test,2139,"ilding CXX object src/psi4/libciomr/CMakeFiles/ciomr.dir/dsyev_ascending.cc.o; ...; ```; version computes and simple test, distributed driver tests, and dftd3 addon tests work ok; ```; > stage/bin/psi4 --psiapi # execute results; >>> stage/bin/psi4 --version; 1.7; >>> ctest -R tu1; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 426: tu1-h2o-energy; 1/1 Test #426: tu1-h2o-energy ................... Passed 1.65 sec. 100% tests passed, 0 tests failed out of 1; >>> ctest -R ddd; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 479: ddd-deriv; 1/2 Test #479: ddd-deriv ........................ Passed 13.18 sec; Start 481: ddd-function-kwargs; 2/2 Test #481: ddd-function-kwargs .............. Passed 170.20 sec. 100% tests passed, 0 tests failed out of 2; >>> ctest -R dftd3; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 510: dftd3-energy; 1/5 Test #510: dftd3-energy ..................... Passed 24.64 sec; Start 511: dftd3-grad; 2/5 Test #511: dftd3-grad ....................... Passed 11.33 sec; Start 512: dftd3-psithon2; 3/5 Test #512: dftd3-psithon2 ................... Passed 13.39 sec; Start 513: dftd3-version; 4/5 Test #513: dftd3-version .................... Passed 27.06 sec; Start 514: dftd3-nbody-cp-gradient; 5/5 Test #514: dftd3-nbody-cp-gradient .......... Passed 33.83 sec. 100% tests passed, 0 tests failed out of 5; ```; version control files have stuff in src and built forms; ```; > cat ../psi4/metadata.py ; __version__ = '1.7'; __version_long = '1.7+6ce35a5'; __version_upcoming_annotated_v_tag = '1.8a1'. def version_formatter(dummy):; return '(inplace)'; > cat stage/lib/psi4/metadata.py ; __version__ = '1.7'; __version_branch_name = ''; __version_cmake = '1.7.0.0'; __version_is_clean = 'True'; __version_last_release = '1.7'; __version_long = '1.7+6ce35a5'; __version_prerelease = 'False'; __version_release = 'True'. def version_formatter(formatstring='{version}'):; if formatstring == 'all':; forma",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:2234,Testability,Test,Test,2234,"n computes and simple test, distributed driver tests, and dftd3 addon tests work ok; ```; > stage/bin/psi4 --psiapi # execute results; >>> stage/bin/psi4 --version; 1.7; >>> ctest -R tu1; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 426: tu1-h2o-energy; 1/1 Test #426: tu1-h2o-energy ................... Passed 1.65 sec. 100% tests passed, 0 tests failed out of 1; >>> ctest -R ddd; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 479: ddd-deriv; 1/2 Test #479: ddd-deriv ........................ Passed 13.18 sec; Start 481: ddd-function-kwargs; 2/2 Test #481: ddd-function-kwargs .............. Passed 170.20 sec. 100% tests passed, 0 tests failed out of 2; >>> ctest -R dftd3; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 510: dftd3-energy; 1/5 Test #510: dftd3-energy ..................... Passed 24.64 sec; Start 511: dftd3-grad; 2/5 Test #511: dftd3-grad ....................... Passed 11.33 sec; Start 512: dftd3-psithon2; 3/5 Test #512: dftd3-psithon2 ................... Passed 13.39 sec; Start 513: dftd3-version; 4/5 Test #513: dftd3-version .................... Passed 27.06 sec; Start 514: dftd3-nbody-cp-gradient; 5/5 Test #514: dftd3-nbody-cp-gradient .......... Passed 33.83 sec. 100% tests passed, 0 tests failed out of 5; ```; version control files have stuff in src and built forms; ```; > cat ../psi4/metadata.py ; __version__ = '1.7'; __version_long = '1.7+6ce35a5'; __version_upcoming_annotated_v_tag = '1.8a1'. def version_formatter(dummy):; return '(inplace)'; > cat stage/lib/psi4/metadata.py ; __version__ = '1.7'; __version_branch_name = ''; __version_cmake = '1.7.0.0'; __version_is_clean = 'True'; __version_last_release = '1.7'; __version_long = '1.7+6ce35a5'; __version_prerelease = 'False'; __version_release = 'True'. def version_formatter(formatstring='{version}'):; if formatstring == 'all':; formatstring = '{version} {{{branch}}} {githash} {cmake} {clean} {release} {lastrel} <-- {versionlon",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:2328,Testability,Test,Test,2328,"age/bin/psi4 --psiapi # execute results; >>> stage/bin/psi4 --version; 1.7; >>> ctest -R tu1; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 426: tu1-h2o-energy; 1/1 Test #426: tu1-h2o-energy ................... Passed 1.65 sec. 100% tests passed, 0 tests failed out of 1; >>> ctest -R ddd; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 479: ddd-deriv; 1/2 Test #479: ddd-deriv ........................ Passed 13.18 sec; Start 481: ddd-function-kwargs; 2/2 Test #481: ddd-function-kwargs .............. Passed 170.20 sec. 100% tests passed, 0 tests failed out of 2; >>> ctest -R dftd3; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 510: dftd3-energy; 1/5 Test #510: dftd3-energy ..................... Passed 24.64 sec; Start 511: dftd3-grad; 2/5 Test #511: dftd3-grad ....................... Passed 11.33 sec; Start 512: dftd3-psithon2; 3/5 Test #512: dftd3-psithon2 ................... Passed 13.39 sec; Start 513: dftd3-version; 4/5 Test #513: dftd3-version .................... Passed 27.06 sec; Start 514: dftd3-nbody-cp-gradient; 5/5 Test #514: dftd3-nbody-cp-gradient .......... Passed 33.83 sec. 100% tests passed, 0 tests failed out of 5; ```; version control files have stuff in src and built forms; ```; > cat ../psi4/metadata.py ; __version__ = '1.7'; __version_long = '1.7+6ce35a5'; __version_upcoming_annotated_v_tag = '1.8a1'. def version_formatter(dummy):; return '(inplace)'; > cat stage/lib/psi4/metadata.py ; __version__ = '1.7'; __version_branch_name = ''; __version_cmake = '1.7.0.0'; __version_is_clean = 'True'; __version_last_release = '1.7'; __version_long = '1.7+6ce35a5'; __version_prerelease = 'False'; __version_release = 'True'. def version_formatter(formatstring='{version}'):; if formatstring == 'all':; formatstring = '{version} {{{branch}}} {githash} {cmake} {clean} {release} {lastrel} <-- {versionlong}'. release = 'release' if (__version_release == 'True') else ('prerelease' if (__version_pre",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:2432,Testability,Test,Test,2432,"ct /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 426: tu1-h2o-energy; 1/1 Test #426: tu1-h2o-energy ................... Passed 1.65 sec. 100% tests passed, 0 tests failed out of 1; >>> ctest -R ddd; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 479: ddd-deriv; 1/2 Test #479: ddd-deriv ........................ Passed 13.18 sec; Start 481: ddd-function-kwargs; 2/2 Test #481: ddd-function-kwargs .............. Passed 170.20 sec. 100% tests passed, 0 tests failed out of 2; >>> ctest -R dftd3; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 510: dftd3-energy; 1/5 Test #510: dftd3-energy ..................... Passed 24.64 sec; Start 511: dftd3-grad; 2/5 Test #511: dftd3-grad ....................... Passed 11.33 sec; Start 512: dftd3-psithon2; 3/5 Test #512: dftd3-psithon2 ................... Passed 13.39 sec; Start 513: dftd3-version; 4/5 Test #513: dftd3-version .................... Passed 27.06 sec; Start 514: dftd3-nbody-cp-gradient; 5/5 Test #514: dftd3-nbody-cp-gradient .......... Passed 33.83 sec. 100% tests passed, 0 tests failed out of 5; ```; version control files have stuff in src and built forms; ```; > cat ../psi4/metadata.py ; __version__ = '1.7'; __version_long = '1.7+6ce35a5'; __version_upcoming_annotated_v_tag = '1.8a1'. def version_formatter(dummy):; return '(inplace)'; > cat stage/lib/psi4/metadata.py ; __version__ = '1.7'; __version_branch_name = ''; __version_cmake = '1.7.0.0'; __version_is_clean = 'True'; __version_last_release = '1.7'; __version_long = '1.7+6ce35a5'; __version_prerelease = 'False'; __version_release = 'True'. def version_formatter(formatstring='{version}'):; if formatstring == 'all':; formatstring = '{version} {{{branch}}} {githash} {cmake} {clean} {release} {lastrel} <-- {versionlong}'. release = 'release' if (__version_release == 'True') else ('prerelease' if (__version_prerelease == 'True') else ''). ans = formatstring.format(version=__version__,; versionlong=__version_long,",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:2501,Testability,test,tests,2501,".. Passed 1.65 sec. 100% tests passed, 0 tests failed out of 1; >>> ctest -R ddd; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 479: ddd-deriv; 1/2 Test #479: ddd-deriv ........................ Passed 13.18 sec; Start 481: ddd-function-kwargs; 2/2 Test #481: ddd-function-kwargs .............. Passed 170.20 sec. 100% tests passed, 0 tests failed out of 2; >>> ctest -R dftd3; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 510: dftd3-energy; 1/5 Test #510: dftd3-energy ..................... Passed 24.64 sec; Start 511: dftd3-grad; 2/5 Test #511: dftd3-grad ....................... Passed 11.33 sec; Start 512: dftd3-psithon2; 3/5 Test #512: dftd3-psithon2 ................... Passed 13.39 sec; Start 513: dftd3-version; 4/5 Test #513: dftd3-version .................... Passed 27.06 sec; Start 514: dftd3-nbody-cp-gradient; 5/5 Test #514: dftd3-nbody-cp-gradient .......... Passed 33.83 sec. 100% tests passed, 0 tests failed out of 5; ```; version control files have stuff in src and built forms; ```; > cat ../psi4/metadata.py ; __version__ = '1.7'; __version_long = '1.7+6ce35a5'; __version_upcoming_annotated_v_tag = '1.8a1'. def version_formatter(dummy):; return '(inplace)'; > cat stage/lib/psi4/metadata.py ; __version__ = '1.7'; __version_branch_name = ''; __version_cmake = '1.7.0.0'; __version_is_clean = 'True'; __version_last_release = '1.7'; __version_long = '1.7+6ce35a5'; __version_prerelease = 'False'; __version_release = 'True'. def version_formatter(formatstring='{version}'):; if formatstring == 'all':; formatstring = '{version} {{{branch}}} {githash} {cmake} {clean} {release} {lastrel} <-- {versionlong}'. release = 'release' if (__version_release == 'True') else ('prerelease' if (__version_prerelease == 'True') else ''). ans = formatstring.format(version=__version__,; versionlong=__version_long,; githash=__version_long[len(__version__)+1:],; clean='' if __version_is_clean == 'True' else 'dirty',; branch=__version_branch_n",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:2517,Testability,test,tests,2517,".. Passed 1.65 sec. 100% tests passed, 0 tests failed out of 1; >>> ctest -R ddd; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 479: ddd-deriv; 1/2 Test #479: ddd-deriv ........................ Passed 13.18 sec; Start 481: ddd-function-kwargs; 2/2 Test #481: ddd-function-kwargs .............. Passed 170.20 sec. 100% tests passed, 0 tests failed out of 2; >>> ctest -R dftd3; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 510: dftd3-energy; 1/5 Test #510: dftd3-energy ..................... Passed 24.64 sec; Start 511: dftd3-grad; 2/5 Test #511: dftd3-grad ....................... Passed 11.33 sec; Start 512: dftd3-psithon2; 3/5 Test #512: dftd3-psithon2 ................... Passed 13.39 sec; Start 513: dftd3-version; 4/5 Test #513: dftd3-version .................... Passed 27.06 sec; Start 514: dftd3-nbody-cp-gradient; 5/5 Test #514: dftd3-nbody-cp-gradient .......... Passed 33.83 sec. 100% tests passed, 0 tests failed out of 5; ```; version control files have stuff in src and built forms; ```; > cat ../psi4/metadata.py ; __version__ = '1.7'; __version_long = '1.7+6ce35a5'; __version_upcoming_annotated_v_tag = '1.8a1'. def version_formatter(dummy):; return '(inplace)'; > cat stage/lib/psi4/metadata.py ; __version__ = '1.7'; __version_branch_name = ''; __version_cmake = '1.7.0.0'; __version_is_clean = 'True'; __version_last_release = '1.7'; __version_long = '1.7+6ce35a5'; __version_prerelease = 'False'; __version_release = 'True'. def version_formatter(formatstring='{version}'):; if formatstring == 'all':; formatstring = '{version} {{{branch}}} {githash} {cmake} {clean} {release} {lastrel} <-- {versionlong}'. release = 'release' if (__version_release == 'True') else ('prerelease' if (__version_prerelease == 'True') else ''). ans = formatstring.format(version=__version__,; versionlong=__version_long,; githash=__version_long[len(__version__)+1:],; clean='' if __version_is_clean == 'True' else 'dirty',; branch=__version_branch_n",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:4057,Testability,log,logic,4057,"s have stuff in src and built forms; ```; > cat ../psi4/metadata.py ; __version__ = '1.7'; __version_long = '1.7+6ce35a5'; __version_upcoming_annotated_v_tag = '1.8a1'. def version_formatter(dummy):; return '(inplace)'; > cat stage/lib/psi4/metadata.py ; __version__ = '1.7'; __version_branch_name = ''; __version_cmake = '1.7.0.0'; __version_is_clean = 'True'; __version_last_release = '1.7'; __version_long = '1.7+6ce35a5'; __version_prerelease = 'False'; __version_release = 'True'. def version_formatter(formatstring='{version}'):; if formatstring == 'all':; formatstring = '{version} {{{branch}}} {githash} {cmake} {clean} {release} {lastrel} <-- {versionlong}'. release = 'release' if (__version_release == 'True') else ('prerelease' if (__version_prerelease == 'True') else ''). ans = formatstring.format(version=__version__,; versionlong=__version_long,; githash=__version_long[len(__version__)+1:],; clean='' if __version_is_clean == 'True' else 'dirty',; branch=__version_branch_name,; lastrel=__version_last_release,; cmake=__version_cmake,; release=release); return ans. if __name__ == '__main__':; print(version_formatter(formatstring='all')); ```. So I think tarballs are roughly still working. But I can totally believe that either I'm working in an edge case or the two of you have found one. My closest suspects:; * perhaps you're in a repo that isn't the psi repo. I bet that'd defeat https://github.com/psi4/psi4/blob/master/psi4/versioner.py#L50 that switches the version logic from git to tarball; * that version logic is tested for release tarballs only, not tarballs of random commits; * the increasing dependency on qcengine (which arose long after the versioning system design) for finite difference and dispersion depends a lot on computing the psi4 (and other) versions. Hence the ""pull tags"" message. I can believe there's a way that communication breaks down. I'd suggest you compare commands and cat-ed files and see where the discrepancy in workflow/environment arises.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:4099,Testability,log,logic,4099,"s have stuff in src and built forms; ```; > cat ../psi4/metadata.py ; __version__ = '1.7'; __version_long = '1.7+6ce35a5'; __version_upcoming_annotated_v_tag = '1.8a1'. def version_formatter(dummy):; return '(inplace)'; > cat stage/lib/psi4/metadata.py ; __version__ = '1.7'; __version_branch_name = ''; __version_cmake = '1.7.0.0'; __version_is_clean = 'True'; __version_last_release = '1.7'; __version_long = '1.7+6ce35a5'; __version_prerelease = 'False'; __version_release = 'True'. def version_formatter(formatstring='{version}'):; if formatstring == 'all':; formatstring = '{version} {{{branch}}} {githash} {cmake} {clean} {release} {lastrel} <-- {versionlong}'. release = 'release' if (__version_release == 'True') else ('prerelease' if (__version_prerelease == 'True') else ''). ans = formatstring.format(version=__version__,; versionlong=__version_long,; githash=__version_long[len(__version__)+1:],; clean='' if __version_is_clean == 'True' else 'dirty',; branch=__version_branch_name,; lastrel=__version_last_release,; cmake=__version_cmake,; release=release); return ans. if __name__ == '__main__':; print(version_formatter(formatstring='all')); ```. So I think tarballs are roughly still working. But I can totally believe that either I'm working in an edge case or the two of you have found one. My closest suspects:; * perhaps you're in a repo that isn't the psi repo. I bet that'd defeat https://github.com/psi4/psi4/blob/master/psi4/versioner.py#L50 that switches the version logic from git to tarball; * that version logic is tested for release tarballs only, not tarballs of random commits; * the increasing dependency on qcengine (which arose long after the versioning system design) for finite difference and dispersion depends a lot on computing the psi4 (and other) versions. Hence the ""pull tags"" message. I can believe there's a way that communication breaks down. I'd suggest you compare commands and cat-ed files and see where the discrepancy in workflow/environment arises.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:4108,Testability,test,tested,4108,"s have stuff in src and built forms; ```; > cat ../psi4/metadata.py ; __version__ = '1.7'; __version_long = '1.7+6ce35a5'; __version_upcoming_annotated_v_tag = '1.8a1'. def version_formatter(dummy):; return '(inplace)'; > cat stage/lib/psi4/metadata.py ; __version__ = '1.7'; __version_branch_name = ''; __version_cmake = '1.7.0.0'; __version_is_clean = 'True'; __version_last_release = '1.7'; __version_long = '1.7+6ce35a5'; __version_prerelease = 'False'; __version_release = 'True'. def version_formatter(formatstring='{version}'):; if formatstring == 'all':; formatstring = '{version} {{{branch}}} {githash} {cmake} {clean} {release} {lastrel} <-- {versionlong}'. release = 'release' if (__version_release == 'True') else ('prerelease' if (__version_prerelease == 'True') else ''). ans = formatstring.format(version=__version__,; versionlong=__version_long,; githash=__version_long[len(__version__)+1:],; clean='' if __version_is_clean == 'True' else 'dirty',; branch=__version_branch_name,; lastrel=__version_last_release,; cmake=__version_cmake,; release=release); return ans. if __name__ == '__main__':; print(version_formatter(formatstring='all')); ```. So I think tarballs are roughly still working. But I can totally believe that either I'm working in an edge case or the two of you have found one. My closest suspects:; * perhaps you're in a repo that isn't the psi repo. I bet that'd defeat https://github.com/psi4/psi4/blob/master/psi4/versioner.py#L50 that switches the version logic from git to tarball; * that version logic is tested for release tarballs only, not tarballs of random commits; * the increasing dependency on qcengine (which arose long after the versioning system design) for finite difference and dispersion depends a lot on computing the psi4 (and other) versions. Hence the ""pull tags"" message. I can believe there's a way that communication breaks down. I'd suggest you compare commands and cat-ed files and see where the discrepancy in workflow/environment arises.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826:1243,Usability,simpl,simple,1243,"he buildsys detects that it's not a git repo, it substitutes some generic most-recent-tag info and proceeds, so that one gets a working build. When I try, it works as planned:. acquire tarball; ```; > curl -L https://github.com/psi4/psi4/tarball/master -o psi4_v17.tgz; ```; configure and build -- it detects ""no git""; ```; # configure (all req'd deps detected except optking to be build from src); > cmake --build . -j12; ...; [ 88%] Performing build step for 'psi4-core'; [ 1%] Generating version info; [ 1%] Building CXX object src/psi4/lib3index/CMakeFiles/3index.dir/dftensor.cc.o; ...; [ 2%] Building CXX object src/CMakeFiles/l2export.dir/export_mints.cc.o; Blindly (no git) accepting release version: 1.7+6ce35a5 (recorded); 1.7 {} 6ce35a5 1.7.0.0 release 1.7 <-- 1.7+6ce35a5; [ 2%] Built target update_version; [ 2%] Building CXX object src/psi4/libciomr/CMakeFiles/ciomr.dir/dsyev_ascending.cc.o; ...; ```; version computes and simple test, distributed driver tests, and dftd3 addon tests work ok; ```; > stage/bin/psi4 --psiapi # execute results; >>> stage/bin/psi4 --version; 1.7; >>> ctest -R tu1; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 426: tu1-h2o-energy; 1/1 Test #426: tu1-h2o-energy ................... Passed 1.65 sec. 100% tests passed, 0 tests failed out of 1; >>> ctest -R ddd; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 479: ddd-deriv; 1/2 Test #479: ddd-deriv ........................ Passed 13.18 sec; Start 481: ddd-function-kwargs; 2/2 Test #481: ddd-function-kwargs .............. Passed 170.20 sec. 100% tests passed, 0 tests failed out of 2; >>> ctest -R dftd3; Test project /psi/gits/tarbuild/psi4-psi4-4d94910/objdir-py310; Start 510: dftd3-energy; 1/5 Test #510: dftd3-energy ..................... Passed 24.64 sec; Start 511: dftd3-grad; 2/5 Test #511: dftd3-grad ....................... Passed 11.33 sec; Start 512: dftd3-psithon2; 3/5 Test #512: dftd3-psithon2 ................... Passed 13.39 sec; Start 5",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2687#issuecomment-1358169826
https://github.com/psi4/psi4/issues/2690#issuecomment-1215857373:186,Deployability,install,installs,186,"Possibly you're looking in `stage/lib/pythonx.x/site-packages/psi4/` for the `core.*so`. Note that without this var https://github.com/psi4/psi4/blob/master/CMakeLists.txt#L94-L95, psi4 installs to generic `stage/lib/psi4`.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2690#issuecomment-1215857373
https://github.com/psi4/psi4/pull/2693#issuecomment-1256461715:224,Deployability,release,release,224,> I'm having second thoughts about this PR now. Should we deprecate the old constructors first? This PR will require changes in Forte as well. options as I see them. I do think we should try to get the changes into one psi4 release cycle. * (n/c) leave convenience fns as-is; * (deprecate) leave convenience fns operable but add deprecation message; * (upgradehelper) leave convenience fn header in place but have it print a message with necessary changes; * (remove) remove convenience fn header and body,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2693#issuecomment-1256461715
https://github.com/psi4/psi4/pull/2693#issuecomment-1256461715:353,Deployability,upgrade,upgradehelper,353,> I'm having second thoughts about this PR now. Should we deprecate the old constructors first? This PR will require changes in Forte as well. options as I see them. I do think we should try to get the changes into one psi4 release cycle. * (n/c) leave convenience fns as-is; * (deprecate) leave convenience fns operable but add deprecation message; * (upgradehelper) leave convenience fn header in place but have it print a message with necessary changes; * (remove) remove convenience fn header and body,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2693#issuecomment-1256461715
https://github.com/psi4/psi4/pull/2693#issuecomment-1256461715:341,Integrability,message,message,341,> I'm having second thoughts about this PR now. Should we deprecate the old constructors first? This PR will require changes in Forte as well. options as I see them. I do think we should try to get the changes into one psi4 release cycle. * (n/c) leave convenience fns as-is; * (deprecate) leave convenience fns operable but add deprecation message; * (upgradehelper) leave convenience fn header in place but have it print a message with necessary changes; * (remove) remove convenience fn header and body,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2693#issuecomment-1256461715
https://github.com/psi4/psi4/pull/2693#issuecomment-1256461715:425,Integrability,message,message,425,> I'm having second thoughts about this PR now. Should we deprecate the old constructors first? This PR will require changes in Forte as well. options as I see them. I do think we should try to get the changes into one psi4 release cycle. * (n/c) leave convenience fns as-is; * (deprecate) leave convenience fns operable but add deprecation message; * (upgradehelper) leave convenience fn header in place but have it print a message with necessary changes; * (remove) remove convenience fn header and body,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2693#issuecomment-1256461715
https://github.com/psi4/psi4/pull/2693#issuecomment-1256964070:60,Deployability,release,release,60,> I do think we should try to get the changes into one psi4 release cycle. Regarding the deprecation message/schedule: do you mean that they should be deprecated now and then removed before 1.7 RC1?,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2693#issuecomment-1256964070
https://github.com/psi4/psi4/pull/2693#issuecomment-1256964070:109,Energy Efficiency,schedul,schedule,109,> I do think we should try to get the changes into one psi4 release cycle. Regarding the deprecation message/schedule: do you mean that they should be deprecated now and then removed before 1.7 RC1?,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2693#issuecomment-1256964070
https://github.com/psi4/psi4/pull/2693#issuecomment-1256964070:101,Integrability,message,message,101,> I do think we should try to get the changes into one psi4 release cycle. Regarding the deprecation message/schedule: do you mean that they should be deprecated now and then removed before 1.7 RC1?,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2693#issuecomment-1256964070
https://github.com/psi4/psi4/pull/2693#issuecomment-1259615160:534,Availability,down,downstream,534,">> I do think we should try to get the changes into one psi4 release cycle. > Regarding the deprecation message/schedule: do you mean that they should be deprecated now and then removed before 1.7 RC1?. I think deprecation warnings (with code still functional) need to be in at least one release. So the code can be broken as soon as ~Dec (after 1.7.0 release). But what I was meaning to say with ""get the changes into one psi4 release cycle"" was let's aim to get all the immediate-breaks and/or notifications in before 1.7.0 so that downstream users have the info to do a single overhaul after 1.7.0. Keep pinging me if this doesn't make sense :-)",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2693#issuecomment-1259615160
https://github.com/psi4/psi4/pull/2693#issuecomment-1259615160:607,Availability,ping,pinging,607,">> I do think we should try to get the changes into one psi4 release cycle. > Regarding the deprecation message/schedule: do you mean that they should be deprecated now and then removed before 1.7 RC1?. I think deprecation warnings (with code still functional) need to be in at least one release. So the code can be broken as soon as ~Dec (after 1.7.0 release). But what I was meaning to say with ""get the changes into one psi4 release cycle"" was let's aim to get all the immediate-breaks and/or notifications in before 1.7.0 so that downstream users have the info to do a single overhaul after 1.7.0. Keep pinging me if this doesn't make sense :-)",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2693#issuecomment-1259615160
https://github.com/psi4/psi4/pull/2693#issuecomment-1259615160:61,Deployability,release,release,61,">> I do think we should try to get the changes into one psi4 release cycle. > Regarding the deprecation message/schedule: do you mean that they should be deprecated now and then removed before 1.7 RC1?. I think deprecation warnings (with code still functional) need to be in at least one release. So the code can be broken as soon as ~Dec (after 1.7.0 release). But what I was meaning to say with ""get the changes into one psi4 release cycle"" was let's aim to get all the immediate-breaks and/or notifications in before 1.7.0 so that downstream users have the info to do a single overhaul after 1.7.0. Keep pinging me if this doesn't make sense :-)",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2693#issuecomment-1259615160
https://github.com/psi4/psi4/pull/2693#issuecomment-1259615160:288,Deployability,release,release,288,">> I do think we should try to get the changes into one psi4 release cycle. > Regarding the deprecation message/schedule: do you mean that they should be deprecated now and then removed before 1.7 RC1?. I think deprecation warnings (with code still functional) need to be in at least one release. So the code can be broken as soon as ~Dec (after 1.7.0 release). But what I was meaning to say with ""get the changes into one psi4 release cycle"" was let's aim to get all the immediate-breaks and/or notifications in before 1.7.0 so that downstream users have the info to do a single overhaul after 1.7.0. Keep pinging me if this doesn't make sense :-)",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2693#issuecomment-1259615160
https://github.com/psi4/psi4/pull/2693#issuecomment-1259615160:352,Deployability,release,release,352,">> I do think we should try to get the changes into one psi4 release cycle. > Regarding the deprecation message/schedule: do you mean that they should be deprecated now and then removed before 1.7 RC1?. I think deprecation warnings (with code still functional) need to be in at least one release. So the code can be broken as soon as ~Dec (after 1.7.0 release). But what I was meaning to say with ""get the changes into one psi4 release cycle"" was let's aim to get all the immediate-breaks and/or notifications in before 1.7.0 so that downstream users have the info to do a single overhaul after 1.7.0. Keep pinging me if this doesn't make sense :-)",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2693#issuecomment-1259615160
https://github.com/psi4/psi4/pull/2693#issuecomment-1259615160:428,Deployability,release,release,428,">> I do think we should try to get the changes into one psi4 release cycle. > Regarding the deprecation message/schedule: do you mean that they should be deprecated now and then removed before 1.7 RC1?. I think deprecation warnings (with code still functional) need to be in at least one release. So the code can be broken as soon as ~Dec (after 1.7.0 release). But what I was meaning to say with ""get the changes into one psi4 release cycle"" was let's aim to get all the immediate-breaks and/or notifications in before 1.7.0 so that downstream users have the info to do a single overhaul after 1.7.0. Keep pinging me if this doesn't make sense :-)",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2693#issuecomment-1259615160
https://github.com/psi4/psi4/pull/2693#issuecomment-1259615160:112,Energy Efficiency,schedul,schedule,112,">> I do think we should try to get the changes into one psi4 release cycle. > Regarding the deprecation message/schedule: do you mean that they should be deprecated now and then removed before 1.7 RC1?. I think deprecation warnings (with code still functional) need to be in at least one release. So the code can be broken as soon as ~Dec (after 1.7.0 release). But what I was meaning to say with ""get the changes into one psi4 release cycle"" was let's aim to get all the immediate-breaks and/or notifications in before 1.7.0 so that downstream users have the info to do a single overhaul after 1.7.0. Keep pinging me if this doesn't make sense :-)",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2693#issuecomment-1259615160
https://github.com/psi4/psi4/pull/2693#issuecomment-1259615160:104,Integrability,message,message,104,">> I do think we should try to get the changes into one psi4 release cycle. > Regarding the deprecation message/schedule: do you mean that they should be deprecated now and then removed before 1.7 RC1?. I think deprecation warnings (with code still functional) need to be in at least one release. So the code can be broken as soon as ~Dec (after 1.7.0 release). But what I was meaning to say with ""get the changes into one psi4 release cycle"" was let's aim to get all the immediate-breaks and/or notifications in before 1.7.0 so that downstream users have the info to do a single overhaul after 1.7.0. Keep pinging me if this doesn't make sense :-)",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2693#issuecomment-1259615160
https://github.com/psi4/psi4/pull/2695#issuecomment-1221095832:819,Usability,clear,clearer,819,"> Looks good, I left some comments. Namely, my biggest concern is about removing the `screening density` keyword and moving `update_density` away from `TwoBodyAOInt`. I think it would make more sense to get it all done in one PR, but that is my personal opinion. Thank you very much for the comments! I do appreciate it. As for your points, my thought was to implement both of these changes in future PRs, maybe as a single future PR, maybe as their own separate ones. I think there's a good argument to be made for making a separate option for density screening in this PR, and I'd be quite willing to do that. But, I do believe that removing update_density should be its own PR, as that PR would consist of removing ALL references to the density matrix from TwoBodyAOInt, and I think it would be easier to review and clearer intent if update_density was separated out in its own PR.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2695#issuecomment-1221095832
https://github.com/psi4/psi4/pull/2695#issuecomment-1231698481:32,Usability,pause,pause,32,"FTR, David and I have agreed to pause this PR until after #2682 and #2665 come in.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2695#issuecomment-1231698481
https://github.com/psi4/psi4/pull/2695#issuecomment-1345254017:173,Deployability,update,update,173,"> Blocking this PR until we can resolve the question of ""is `TwoBodyAOInt` responsible for sieving, or is `ERISieve`""? Happy to talk about this after ACS Chicago. To add an update to this, some of us (Jonathan, I, and others) discussed this issue at PsiCon 2022. We came to the conclusion that TwoBodyAOInt would be responsible for sieving, and that ERISieve will be removed from Psi4. As use of ERISieve is seemingly localized to the PKJK algorithm, I will be the one responsible for its removal. Until then, this PR will likely be further delayed.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2695#issuecomment-1345254017
https://github.com/psi4/psi4/issues/2697#issuecomment-1259166197:166,Availability,avail,available,166,"The basis sets are specifically matched to ECPs, which is the appropriate ECPXXMDF for whichever row of the periodic table. I also note that these basis sets **are** available for alkali and alkaline earth too.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2697#issuecomment-1259166197
https://github.com/psi4/psi4/issues/2698#issuecomment-1225919509:214,Availability,avail,available,214,"1. Psi doesn't tabulate these, and I've mostly seen them for DFT. Scaling factors handy for getting oriented with a vib spectrum, but they're not uniquely determined for a method/basis.; 2. Yes, IR intensities are available as of psi4 1.6 in late May provided analytic gradients are available (as opposed to Hessian by finite difference of energies).; 3. I'm not sure what ""mode"" you were looking at. I can clarify if you post a link. Once upon a time, there was a `frequency(..., mode=(continuous|sow|reap))` but that had to do with farming out finite difference jobs and is now defunct anyways. There's `irrep` https://github.com/psi4/psi4/blob/master/psi4/driver/driver.py#L1511-L1517 that allows a partial frequency job for only a symmetry subset. Example here https://github.com/psi4/psi4/blob/master/tests/fd-freq-gradient/input.dat#L75 . There's no singling out of particular modes.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2698#issuecomment-1225919509
https://github.com/psi4/psi4/issues/2698#issuecomment-1225919509:283,Availability,avail,available,283,"1. Psi doesn't tabulate these, and I've mostly seen them for DFT. Scaling factors handy for getting oriented with a vib spectrum, but they're not uniquely determined for a method/basis.; 2. Yes, IR intensities are available as of psi4 1.6 in late May provided analytic gradients are available (as opposed to Hessian by finite difference of energies).; 3. I'm not sure what ""mode"" you were looking at. I can clarify if you post a link. Once upon a time, there was a `frequency(..., mode=(continuous|sow|reap))` but that had to do with farming out finite difference jobs and is now defunct anyways. There's `irrep` https://github.com/psi4/psi4/blob/master/psi4/driver/driver.py#L1511-L1517 that allows a partial frequency job for only a symmetry subset. Example here https://github.com/psi4/psi4/blob/master/tests/fd-freq-gradient/input.dat#L75 . There's no singling out of particular modes.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2698#issuecomment-1225919509
https://github.com/psi4/psi4/issues/2698#issuecomment-1225919509:487,Deployability,continuous,continuous,487,"1. Psi doesn't tabulate these, and I've mostly seen them for DFT. Scaling factors handy for getting oriented with a vib spectrum, but they're not uniquely determined for a method/basis.; 2. Yes, IR intensities are available as of psi4 1.6 in late May provided analytic gradients are available (as opposed to Hessian by finite difference of energies).; 3. I'm not sure what ""mode"" you were looking at. I can clarify if you post a link. Once upon a time, there was a `frequency(..., mode=(continuous|sow|reap))` but that had to do with farming out finite difference jobs and is now defunct anyways. There's `irrep` https://github.com/psi4/psi4/blob/master/psi4/driver/driver.py#L1511-L1517 that allows a partial frequency job for only a symmetry subset. Example here https://github.com/psi4/psi4/blob/master/tests/fd-freq-gradient/input.dat#L75 . There's no singling out of particular modes.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2698#issuecomment-1225919509
https://github.com/psi4/psi4/issues/2698#issuecomment-1225919509:806,Testability,test,tests,806,"1. Psi doesn't tabulate these, and I've mostly seen them for DFT. Scaling factors handy for getting oriented with a vib spectrum, but they're not uniquely determined for a method/basis.; 2. Yes, IR intensities are available as of psi4 1.6 in late May provided analytic gradients are available (as opposed to Hessian by finite difference of energies).; 3. I'm not sure what ""mode"" you were looking at. I can clarify if you post a link. Once upon a time, there was a `frequency(..., mode=(continuous|sow|reap))` but that had to do with farming out finite difference jobs and is now defunct anyways. There's `irrep` https://github.com/psi4/psi4/blob/master/psi4/driver/driver.py#L1511-L1517 that allows a partial frequency job for only a symmetry subset. Example here https://github.com/psi4/psi4/blob/master/tests/fd-freq-gradient/input.dat#L75 . There's no singling out of particular modes.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2698#issuecomment-1225919509
https://github.com/psi4/psi4/issues/2698#issuecomment-1226074577:292,Deployability,continuous,continuous,292,"1.) Thank you, I read it from a graduate student thesis I remember summarizing it with different levels of basis sets and theories but definitely needed some validation on that front. . 2.) Awesome I will give it a shot and check it out, let you know if I run into any problems. . 3.) `mode=(continuous|sow|reap))` ah I think I got confused on the parameter meant. I thought it was a way to single out individual modes. . This is great and moves me a long! Thank you!",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2698#issuecomment-1226074577
https://github.com/psi4/psi4/issues/2698#issuecomment-1226074577:158,Security,validat,validation,158,"1.) Thank you, I read it from a graduate student thesis I remember summarizing it with different levels of basis sets and theories but definitely needed some validation on that front. . 2.) Awesome I will give it a shot and check it out, let you know if I run into any problems. . 3.) `mode=(continuous|sow|reap))` ah I think I got confused on the parameter meant. I thought it was a way to single out individual modes. . This is great and moves me a long! Thank you!",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2698#issuecomment-1226074577
https://github.com/psi4/psi4/issues/2698#issuecomment-1226632650:832,Energy Efficiency,energy,energy,832,"Would you mind teaching me if I have this right because I don't actually know and this is how far I got, I still can't seem to get intensities out. . ```python. import psi4; import textwrap; import numpy as np. psi4.core.set_num_threads(8); psi4.set_memory('30000mb'). psi4.set_options({; 'scf_type': 'df',; 'g_convergence': 'gau_tight',; 'reference': 'rhf',; 'freeze_core': 'true',; }). psi4.core.set_output_file('water.out', False). def run_calculation(molecule):; ; universe = psi4.geometry(molecule); universe.update_geometry(); mass = np.asarray([16.01, 1.0, 1.0]); geometry = np.asarray(universe.geometry()); irrep_labels = universe.irrep_labels(); dipole_derivatives = None; project_translation = True; project_rotation = True; symbols = [universe.symbol(at) for at in range(universe.natom())]; theory = 'mp2/aug-cc-pvdz'; ; energy, wave_function = psi4.optimize(; 'hf/6-31g*',; return_wfn = 'yes',; molecule=universe; ). hessian, wave_function_2 = psi4.hessian(; theory,; ref_gradient=wave_function.gradient(),; return_wfn= True; ). basisset = wave_function_2.basisset(). wave_function_2.hessian().print_out(). vibinfo, vibtext = psi4.driver.qcdb.vib.harmonic_analysis(; np.array(hessian),; geometry,; mass,; basisset,; irrep_labels,; dipole_derivatives,; project_translation,; project_rotation; ). print(vibtext); print(psi4.driver.qcdb.vib.print_vibs(vibinfo, shortlong=True, normco='q', atom_lbl=symbols)). if __name__ == '__main__':. water_zmatrix = '''\; O; H 1 0.9894093; H 1 0.9894093 2 100.02688; '''; run_calculation(textwrap.dedent(water_zmatrix)). ```. The output from the script for water is:. ```python. Vibration 7 8 9 ; Freq [cm^-1] 1563.0797 4068.4404 4208.3554 ; Irrep ; Reduced mass [u] 1.0740 1.0365 1.0684 ; Force const [mDyne/A] 1.5461 10.1080 11.1487 ; Turning point v=0 [a0] 0.2678 0.1690 0.1636 ; RMS dev v=0 [a0 u^1/2] 0.1962 0.1216 0.1196 ; Char temp [K] 2248.9237 5853.5800 6054.8864 ; --------------------------------------------------------------------------------",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2698#issuecomment-1226632650
https://github.com/psi4/psi4/issues/2698#issuecomment-1226632650:1696,Energy Efficiency,Reduce,Reduced,1696,"um_threads(8); psi4.set_memory('30000mb'). psi4.set_options({; 'scf_type': 'df',; 'g_convergence': 'gau_tight',; 'reference': 'rhf',; 'freeze_core': 'true',; }). psi4.core.set_output_file('water.out', False). def run_calculation(molecule):; ; universe = psi4.geometry(molecule); universe.update_geometry(); mass = np.asarray([16.01, 1.0, 1.0]); geometry = np.asarray(universe.geometry()); irrep_labels = universe.irrep_labels(); dipole_derivatives = None; project_translation = True; project_rotation = True; symbols = [universe.symbol(at) for at in range(universe.natom())]; theory = 'mp2/aug-cc-pvdz'; ; energy, wave_function = psi4.optimize(; 'hf/6-31g*',; return_wfn = 'yes',; molecule=universe; ). hessian, wave_function_2 = psi4.hessian(; theory,; ref_gradient=wave_function.gradient(),; return_wfn= True; ). basisset = wave_function_2.basisset(). wave_function_2.hessian().print_out(). vibinfo, vibtext = psi4.driver.qcdb.vib.harmonic_analysis(; np.array(hessian),; geometry,; mass,; basisset,; irrep_labels,; dipole_derivatives,; project_translation,; project_rotation; ). print(vibtext); print(psi4.driver.qcdb.vib.print_vibs(vibinfo, shortlong=True, normco='q', atom_lbl=symbols)). if __name__ == '__main__':. water_zmatrix = '''\; O; H 1 0.9894093; H 1 0.9894093 2 100.02688; '''; run_calculation(textwrap.dedent(water_zmatrix)). ```. The output from the script for water is:. ```python. Vibration 7 8 9 ; Freq [cm^-1] 1563.0797 4068.4404 4208.3554 ; Irrep ; Reduced mass [u] 1.0740 1.0365 1.0684 ; Force const [mDyne/A] 1.5461 10.1080 11.1487 ; Turning point v=0 [a0] 0.2678 0.1690 0.1636 ; RMS dev v=0 [a0 u^1/2] 0.1962 0.1216 0.1196 ; Char temp [K] 2248.9237 5853.5800 6054.8864 ; ----------------------------------------------------------------------------------; 1 O 0.00 0.00 -0.27 0.00 0.00 0.19 -0.00 -0.26 0.00 ; 2 H -0.00 0.41 0.54 0.00 0.58 -0.39 -0.00 0.52 -0.44 ; 3 H -0.00 -0.41 0.54 -0.00 -0.58 -0.39 0.00 0.52 0.44 ; ```. Everything else but that, what am I missing so far?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2698#issuecomment-1226632650
https://github.com/psi4/psi4/issues/2698#issuecomment-1226632650:861,Performance,optimiz,optimize,861,"Would you mind teaching me if I have this right because I don't actually know and this is how far I got, I still can't seem to get intensities out. . ```python. import psi4; import textwrap; import numpy as np. psi4.core.set_num_threads(8); psi4.set_memory('30000mb'). psi4.set_options({; 'scf_type': 'df',; 'g_convergence': 'gau_tight',; 'reference': 'rhf',; 'freeze_core': 'true',; }). psi4.core.set_output_file('water.out', False). def run_calculation(molecule):; ; universe = psi4.geometry(molecule); universe.update_geometry(); mass = np.asarray([16.01, 1.0, 1.0]); geometry = np.asarray(universe.geometry()); irrep_labels = universe.irrep_labels(); dipole_derivatives = None; project_translation = True; project_rotation = True; symbols = [universe.symbol(at) for at in range(universe.natom())]; theory = 'mp2/aug-cc-pvdz'; ; energy, wave_function = psi4.optimize(; 'hf/6-31g*',; return_wfn = 'yes',; molecule=universe; ). hessian, wave_function_2 = psi4.hessian(; theory,; ref_gradient=wave_function.gradient(),; return_wfn= True; ). basisset = wave_function_2.basisset(). wave_function_2.hessian().print_out(). vibinfo, vibtext = psi4.driver.qcdb.vib.harmonic_analysis(; np.array(hessian),; geometry,; mass,; basisset,; irrep_labels,; dipole_derivatives,; project_translation,; project_rotation; ). print(vibtext); print(psi4.driver.qcdb.vib.print_vibs(vibinfo, shortlong=True, normco='q', atom_lbl=symbols)). if __name__ == '__main__':. water_zmatrix = '''\; O; H 1 0.9894093; H 1 0.9894093 2 100.02688; '''; run_calculation(textwrap.dedent(water_zmatrix)). ```. The output from the script for water is:. ```python. Vibration 7 8 9 ; Freq [cm^-1] 1563.0797 4068.4404 4208.3554 ; Irrep ; Reduced mass [u] 1.0740 1.0365 1.0684 ; Force const [mDyne/A] 1.5461 10.1080 11.1487 ; Turning point v=0 [a0] 0.2678 0.1690 0.1636 ; RMS dev v=0 [a0 u^1/2] 0.1962 0.1216 0.1196 ; Char temp [K] 2248.9237 5853.5800 6054.8864 ; --------------------------------------------------------------------------------",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2698#issuecomment-1226632650
https://github.com/psi4/psi4/issues/2698#issuecomment-1226646111:376,Performance,optimiz,optimization,376,"At first read-through, that looks reasonable. What are your goals, though? I ask because all the `hessian` ... `print_vibs` section can accomplished by replacing the `hessian()` call with a `frequency()` call. IR intensities are absent because `dipole_derivatives=None`. `frequency()` will pass the data around behind the scenes. Also, there's good physical reasons to do the optimization and frequency at exactly the same level of theory (mtd + basis). Hessian is more expensive than opt, so if anything, the freq is the cheaper level of theory.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2698#issuecomment-1226646111
https://github.com/psi4/psi4/issues/2698#issuecomment-1227099808:155,Availability,down,down,155,"I'm looking for anharmonic modes of vibration of complexes. Good point on the optimization and frequency, for testing purposes I bring the level of theory down to hartree-fock just to make it go faster. On production code runs, the level of theory and basis set are consistent. . I have been playing around with both `frequency()` and `hessian()`. I chose the hessian last night because of this:. https://psicode.org/psi4manual/master/api/psi4.driver.qcdb.vib.harmonic_analysis.html#psi4.driver.qcdb.vib.harmonic_analysis. https://psicode.org/psi4manual/master/freq.html. Where the harmonic analysis is documented showing the IR intensities. The first parameter was a hessian matrix so I went back to go look at how to produce that. Maybe I went down a different rabbit hole. . https://github.com/psi4/psi4/blob/821134f62396ba27f9bcb8fbfa93ea2c370b7616/tests/pytests/test_vibanalysis.py. Line 17-40 I kind of copied your guys test to get the code running. I was actually confused with dipole derivatives and how to produce them and pass them in appropriately. . Ah okay! the frequency has it built in and I can see it. I got confused on the docs. . ```python; theory = 'hf/6-31g*'; ; energy, wave_function = psi4.optimize(; theory,; return_wfn = 'yes',; molecule=universe; ). frequencies = psi4.frequencies(; theory,; ref_gradient=wave_function.gradient(),; molecule=universe. ); ```. Ouput:. ```python; Freq [cm^-1] 1557.5017 4053.2831 4197.9898 ; Irrep A1 A1 B2 ; Reduced mass [u] 1.0830 1.0449 1.0829 ; Force const [mDyne/A] 1.5478 10.1143 11.2435 ; Turning point v=0 [a0] 0.2672 0.1686 0.1627 ; RMS dev v=0 [a0 u^1/2] 0.1966 0.1219 0.1198 ; IR activ [km/mol] 92.6794 13.8599 85.5429 ; Char temp [K] 2240.8982 5831.7720 6039.9727 ; ----------------------------------------------------------------------------------; 1 O 0.00 -0.00 -0.07 0.00 -0.00 0.05 0.00 -0.07 -0.00 ; 2 H -0.00 0.43 0.56 0.00 0.59 -0.39 0.00 0.56 -0.43 ; 3 H 0.00 -0.43 0.56 0.00 -0.59 -0.39 0.00 0.56 0.43 ; ```. So I want to ",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2698#issuecomment-1227099808
https://github.com/psi4/psi4/issues/2698#issuecomment-1227099808:746,Availability,down,down,746,"I'm looking for anharmonic modes of vibration of complexes. Good point on the optimization and frequency, for testing purposes I bring the level of theory down to hartree-fock just to make it go faster. On production code runs, the level of theory and basis set are consistent. . I have been playing around with both `frequency()` and `hessian()`. I chose the hessian last night because of this:. https://psicode.org/psi4manual/master/api/psi4.driver.qcdb.vib.harmonic_analysis.html#psi4.driver.qcdb.vib.harmonic_analysis. https://psicode.org/psi4manual/master/freq.html. Where the harmonic analysis is documented showing the IR intensities. The first parameter was a hessian matrix so I went back to go look at how to produce that. Maybe I went down a different rabbit hole. . https://github.com/psi4/psi4/blob/821134f62396ba27f9bcb8fbfa93ea2c370b7616/tests/pytests/test_vibanalysis.py. Line 17-40 I kind of copied your guys test to get the code running. I was actually confused with dipole derivatives and how to produce them and pass them in appropriately. . Ah okay! the frequency has it built in and I can see it. I got confused on the docs. . ```python; theory = 'hf/6-31g*'; ; energy, wave_function = psi4.optimize(; theory,; return_wfn = 'yes',; molecule=universe; ). frequencies = psi4.frequencies(; theory,; ref_gradient=wave_function.gradient(),; molecule=universe. ); ```. Ouput:. ```python; Freq [cm^-1] 1557.5017 4053.2831 4197.9898 ; Irrep A1 A1 B2 ; Reduced mass [u] 1.0830 1.0449 1.0829 ; Force const [mDyne/A] 1.5478 10.1143 11.2435 ; Turning point v=0 [a0] 0.2672 0.1686 0.1627 ; RMS dev v=0 [a0 u^1/2] 0.1966 0.1219 0.1198 ; IR activ [km/mol] 92.6794 13.8599 85.5429 ; Char temp [K] 2240.8982 5831.7720 6039.9727 ; ----------------------------------------------------------------------------------; 1 O 0.00 -0.00 -0.07 0.00 -0.00 0.05 0.00 -0.07 -0.00 ; 2 H -0.00 0.43 0.56 0.00 0.59 -0.39 0.00 0.56 -0.43 ; 3 H 0.00 -0.43 0.56 0.00 -0.59 -0.39 0.00 0.56 0.43 ; ```. So I want to ",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2698#issuecomment-1227099808
https://github.com/psi4/psi4/issues/2698#issuecomment-1227099808:1184,Energy Efficiency,energy,energy,1184," to make it go faster. On production code runs, the level of theory and basis set are consistent. . I have been playing around with both `frequency()` and `hessian()`. I chose the hessian last night because of this:. https://psicode.org/psi4manual/master/api/psi4.driver.qcdb.vib.harmonic_analysis.html#psi4.driver.qcdb.vib.harmonic_analysis. https://psicode.org/psi4manual/master/freq.html. Where the harmonic analysis is documented showing the IR intensities. The first parameter was a hessian matrix so I went back to go look at how to produce that. Maybe I went down a different rabbit hole. . https://github.com/psi4/psi4/blob/821134f62396ba27f9bcb8fbfa93ea2c370b7616/tests/pytests/test_vibanalysis.py. Line 17-40 I kind of copied your guys test to get the code running. I was actually confused with dipole derivatives and how to produce them and pass them in appropriately. . Ah okay! the frequency has it built in and I can see it. I got confused on the docs. . ```python; theory = 'hf/6-31g*'; ; energy, wave_function = psi4.optimize(; theory,; return_wfn = 'yes',; molecule=universe; ). frequencies = psi4.frequencies(; theory,; ref_gradient=wave_function.gradient(),; molecule=universe. ); ```. Ouput:. ```python; Freq [cm^-1] 1557.5017 4053.2831 4197.9898 ; Irrep A1 A1 B2 ; Reduced mass [u] 1.0830 1.0449 1.0829 ; Force const [mDyne/A] 1.5478 10.1143 11.2435 ; Turning point v=0 [a0] 0.2672 0.1686 0.1627 ; RMS dev v=0 [a0 u^1/2] 0.1966 0.1219 0.1198 ; IR activ [km/mol] 92.6794 13.8599 85.5429 ; Char temp [K] 2240.8982 5831.7720 6039.9727 ; ----------------------------------------------------------------------------------; 1 O 0.00 -0.00 -0.07 0.00 -0.00 0.05 0.00 -0.07 -0.00 ; 2 H -0.00 0.43 0.56 0.00 0.59 -0.39 0.00 0.56 -0.43 ; 3 H 0.00 -0.43 0.56 0.00 -0.59 -0.39 0.00 0.56 0.43 ; ```. So I want to make sure I understand this correctly, the IR active means it is my epsilon in beer-lambert's law and all I would need to do to get absorbance is times it by the path length of my ",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2698#issuecomment-1227099808
https://github.com/psi4/psi4/issues/2698#issuecomment-1227099808:1466,Energy Efficiency,Reduce,Reduced,1466,"oth `frequency()` and `hessian()`. I chose the hessian last night because of this:. https://psicode.org/psi4manual/master/api/psi4.driver.qcdb.vib.harmonic_analysis.html#psi4.driver.qcdb.vib.harmonic_analysis. https://psicode.org/psi4manual/master/freq.html. Where the harmonic analysis is documented showing the IR intensities. The first parameter was a hessian matrix so I went back to go look at how to produce that. Maybe I went down a different rabbit hole. . https://github.com/psi4/psi4/blob/821134f62396ba27f9bcb8fbfa93ea2c370b7616/tests/pytests/test_vibanalysis.py. Line 17-40 I kind of copied your guys test to get the code running. I was actually confused with dipole derivatives and how to produce them and pass them in appropriately. . Ah okay! the frequency has it built in and I can see it. I got confused on the docs. . ```python; theory = 'hf/6-31g*'; ; energy, wave_function = psi4.optimize(; theory,; return_wfn = 'yes',; molecule=universe; ). frequencies = psi4.frequencies(; theory,; ref_gradient=wave_function.gradient(),; molecule=universe. ); ```. Ouput:. ```python; Freq [cm^-1] 1557.5017 4053.2831 4197.9898 ; Irrep A1 A1 B2 ; Reduced mass [u] 1.0830 1.0449 1.0829 ; Force const [mDyne/A] 1.5478 10.1143 11.2435 ; Turning point v=0 [a0] 0.2672 0.1686 0.1627 ; RMS dev v=0 [a0 u^1/2] 0.1966 0.1219 0.1198 ; IR activ [km/mol] 92.6794 13.8599 85.5429 ; Char temp [K] 2240.8982 5831.7720 6039.9727 ; ----------------------------------------------------------------------------------; 1 O 0.00 -0.00 -0.07 0.00 -0.00 0.05 0.00 -0.07 -0.00 ; 2 H -0.00 0.43 0.56 0.00 0.59 -0.39 0.00 0.56 -0.43 ; 3 H 0.00 -0.43 0.56 0.00 -0.59 -0.39 0.00 0.56 0.43 ; ```. So I want to make sure I understand this correctly, the IR active means it is my epsilon in beer-lambert's law and all I would need to do to get absorbance is times it by the path length of my cell, and the concentration of my sample. And then calculate transmittance from how much was absorbed to how much light was emitted?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2698#issuecomment-1227099808
https://github.com/psi4/psi4/issues/2698#issuecomment-1227099808:78,Performance,optimiz,optimization,78,"I'm looking for anharmonic modes of vibration of complexes. Good point on the optimization and frequency, for testing purposes I bring the level of theory down to hartree-fock just to make it go faster. On production code runs, the level of theory and basis set are consistent. . I have been playing around with both `frequency()` and `hessian()`. I chose the hessian last night because of this:. https://psicode.org/psi4manual/master/api/psi4.driver.qcdb.vib.harmonic_analysis.html#psi4.driver.qcdb.vib.harmonic_analysis. https://psicode.org/psi4manual/master/freq.html. Where the harmonic analysis is documented showing the IR intensities. The first parameter was a hessian matrix so I went back to go look at how to produce that. Maybe I went down a different rabbit hole. . https://github.com/psi4/psi4/blob/821134f62396ba27f9bcb8fbfa93ea2c370b7616/tests/pytests/test_vibanalysis.py. Line 17-40 I kind of copied your guys test to get the code running. I was actually confused with dipole derivatives and how to produce them and pass them in appropriately. . Ah okay! the frequency has it built in and I can see it. I got confused on the docs. . ```python; theory = 'hf/6-31g*'; ; energy, wave_function = psi4.optimize(; theory,; return_wfn = 'yes',; molecule=universe; ). frequencies = psi4.frequencies(; theory,; ref_gradient=wave_function.gradient(),; molecule=universe. ); ```. Ouput:. ```python; Freq [cm^-1] 1557.5017 4053.2831 4197.9898 ; Irrep A1 A1 B2 ; Reduced mass [u] 1.0830 1.0449 1.0829 ; Force const [mDyne/A] 1.5478 10.1143 11.2435 ; Turning point v=0 [a0] 0.2672 0.1686 0.1627 ; RMS dev v=0 [a0 u^1/2] 0.1966 0.1219 0.1198 ; IR activ [km/mol] 92.6794 13.8599 85.5429 ; Char temp [K] 2240.8982 5831.7720 6039.9727 ; ----------------------------------------------------------------------------------; 1 O 0.00 -0.00 -0.07 0.00 -0.00 0.05 0.00 -0.07 -0.00 ; 2 H -0.00 0.43 0.56 0.00 0.59 -0.39 0.00 0.56 -0.43 ; 3 H 0.00 -0.43 0.56 0.00 -0.59 -0.39 0.00 0.56 0.43 ; ```. So I want to ",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2698#issuecomment-1227099808
https://github.com/psi4/psi4/issues/2698#issuecomment-1227099808:1213,Performance,optimiz,optimize,1213,"ory and basis set are consistent. . I have been playing around with both `frequency()` and `hessian()`. I chose the hessian last night because of this:. https://psicode.org/psi4manual/master/api/psi4.driver.qcdb.vib.harmonic_analysis.html#psi4.driver.qcdb.vib.harmonic_analysis. https://psicode.org/psi4manual/master/freq.html. Where the harmonic analysis is documented showing the IR intensities. The first parameter was a hessian matrix so I went back to go look at how to produce that. Maybe I went down a different rabbit hole. . https://github.com/psi4/psi4/blob/821134f62396ba27f9bcb8fbfa93ea2c370b7616/tests/pytests/test_vibanalysis.py. Line 17-40 I kind of copied your guys test to get the code running. I was actually confused with dipole derivatives and how to produce them and pass them in appropriately. . Ah okay! the frequency has it built in and I can see it. I got confused on the docs. . ```python; theory = 'hf/6-31g*'; ; energy, wave_function = psi4.optimize(; theory,; return_wfn = 'yes',; molecule=universe; ). frequencies = psi4.frequencies(; theory,; ref_gradient=wave_function.gradient(),; molecule=universe. ); ```. Ouput:. ```python; Freq [cm^-1] 1557.5017 4053.2831 4197.9898 ; Irrep A1 A1 B2 ; Reduced mass [u] 1.0830 1.0449 1.0829 ; Force const [mDyne/A] 1.5478 10.1143 11.2435 ; Turning point v=0 [a0] 0.2672 0.1686 0.1627 ; RMS dev v=0 [a0 u^1/2] 0.1966 0.1219 0.1198 ; IR activ [km/mol] 92.6794 13.8599 85.5429 ; Char temp [K] 2240.8982 5831.7720 6039.9727 ; ----------------------------------------------------------------------------------; 1 O 0.00 -0.00 -0.07 0.00 -0.00 0.05 0.00 -0.07 -0.00 ; 2 H -0.00 0.43 0.56 0.00 0.59 -0.39 0.00 0.56 -0.43 ; 3 H 0.00 -0.43 0.56 0.00 -0.59 -0.39 0.00 0.56 0.43 ; ```. So I want to make sure I understand this correctly, the IR active means it is my epsilon in beer-lambert's law and all I would need to do to get absorbance is times it by the path length of my cell, and the concentration of my sample. And then calculate tr",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2698#issuecomment-1227099808
https://github.com/psi4/psi4/issues/2698#issuecomment-1227099808:110,Testability,test,testing,110,"I'm looking for anharmonic modes of vibration of complexes. Good point on the optimization and frequency, for testing purposes I bring the level of theory down to hartree-fock just to make it go faster. On production code runs, the level of theory and basis set are consistent. . I have been playing around with both `frequency()` and `hessian()`. I chose the hessian last night because of this:. https://psicode.org/psi4manual/master/api/psi4.driver.qcdb.vib.harmonic_analysis.html#psi4.driver.qcdb.vib.harmonic_analysis. https://psicode.org/psi4manual/master/freq.html. Where the harmonic analysis is documented showing the IR intensities. The first parameter was a hessian matrix so I went back to go look at how to produce that. Maybe I went down a different rabbit hole. . https://github.com/psi4/psi4/blob/821134f62396ba27f9bcb8fbfa93ea2c370b7616/tests/pytests/test_vibanalysis.py. Line 17-40 I kind of copied your guys test to get the code running. I was actually confused with dipole derivatives and how to produce them and pass them in appropriately. . Ah okay! the frequency has it built in and I can see it. I got confused on the docs. . ```python; theory = 'hf/6-31g*'; ; energy, wave_function = psi4.optimize(; theory,; return_wfn = 'yes',; molecule=universe; ). frequencies = psi4.frequencies(; theory,; ref_gradient=wave_function.gradient(),; molecule=universe. ); ```. Ouput:. ```python; Freq [cm^-1] 1557.5017 4053.2831 4197.9898 ; Irrep A1 A1 B2 ; Reduced mass [u] 1.0830 1.0449 1.0829 ; Force const [mDyne/A] 1.5478 10.1143 11.2435 ; Turning point v=0 [a0] 0.2672 0.1686 0.1627 ; RMS dev v=0 [a0 u^1/2] 0.1966 0.1219 0.1198 ; IR activ [km/mol] 92.6794 13.8599 85.5429 ; Char temp [K] 2240.8982 5831.7720 6039.9727 ; ----------------------------------------------------------------------------------; 1 O 0.00 -0.00 -0.07 0.00 -0.00 0.05 0.00 -0.07 -0.00 ; 2 H -0.00 0.43 0.56 0.00 0.59 -0.39 0.00 0.56 -0.43 ; 3 H 0.00 -0.43 0.56 0.00 -0.59 -0.39 0.00 0.56 0.43 ; ```. So I want to ",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2698#issuecomment-1227099808
https://github.com/psi4/psi4/issues/2698#issuecomment-1227099808:853,Testability,test,tests,853,"I'm looking for anharmonic modes of vibration of complexes. Good point on the optimization and frequency, for testing purposes I bring the level of theory down to hartree-fock just to make it go faster. On production code runs, the level of theory and basis set are consistent. . I have been playing around with both `frequency()` and `hessian()`. I chose the hessian last night because of this:. https://psicode.org/psi4manual/master/api/psi4.driver.qcdb.vib.harmonic_analysis.html#psi4.driver.qcdb.vib.harmonic_analysis. https://psicode.org/psi4manual/master/freq.html. Where the harmonic analysis is documented showing the IR intensities. The first parameter was a hessian matrix so I went back to go look at how to produce that. Maybe I went down a different rabbit hole. . https://github.com/psi4/psi4/blob/821134f62396ba27f9bcb8fbfa93ea2c370b7616/tests/pytests/test_vibanalysis.py. Line 17-40 I kind of copied your guys test to get the code running. I was actually confused with dipole derivatives and how to produce them and pass them in appropriately. . Ah okay! the frequency has it built in and I can see it. I got confused on the docs. . ```python; theory = 'hf/6-31g*'; ; energy, wave_function = psi4.optimize(; theory,; return_wfn = 'yes',; molecule=universe; ). frequencies = psi4.frequencies(; theory,; ref_gradient=wave_function.gradient(),; molecule=universe. ); ```. Ouput:. ```python; Freq [cm^-1] 1557.5017 4053.2831 4197.9898 ; Irrep A1 A1 B2 ; Reduced mass [u] 1.0830 1.0449 1.0829 ; Force const [mDyne/A] 1.5478 10.1143 11.2435 ; Turning point v=0 [a0] 0.2672 0.1686 0.1627 ; RMS dev v=0 [a0 u^1/2] 0.1966 0.1219 0.1198 ; IR activ [km/mol] 92.6794 13.8599 85.5429 ; Char temp [K] 2240.8982 5831.7720 6039.9727 ; ----------------------------------------------------------------------------------; 1 O 0.00 -0.00 -0.07 0.00 -0.00 0.05 0.00 -0.07 -0.00 ; 2 H -0.00 0.43 0.56 0.00 0.59 -0.39 0.00 0.56 -0.43 ; 3 H 0.00 -0.43 0.56 0.00 -0.59 -0.39 0.00 0.56 0.43 ; ```. So I want to ",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2698#issuecomment-1227099808
https://github.com/psi4/psi4/issues/2698#issuecomment-1227099808:926,Testability,test,test,926,"I'm looking for anharmonic modes of vibration of complexes. Good point on the optimization and frequency, for testing purposes I bring the level of theory down to hartree-fock just to make it go faster. On production code runs, the level of theory and basis set are consistent. . I have been playing around with both `frequency()` and `hessian()`. I chose the hessian last night because of this:. https://psicode.org/psi4manual/master/api/psi4.driver.qcdb.vib.harmonic_analysis.html#psi4.driver.qcdb.vib.harmonic_analysis. https://psicode.org/psi4manual/master/freq.html. Where the harmonic analysis is documented showing the IR intensities. The first parameter was a hessian matrix so I went back to go look at how to produce that. Maybe I went down a different rabbit hole. . https://github.com/psi4/psi4/blob/821134f62396ba27f9bcb8fbfa93ea2c370b7616/tests/pytests/test_vibanalysis.py. Line 17-40 I kind of copied your guys test to get the code running. I was actually confused with dipole derivatives and how to produce them and pass them in appropriately. . Ah okay! the frequency has it built in and I can see it. I got confused on the docs. . ```python; theory = 'hf/6-31g*'; ; energy, wave_function = psi4.optimize(; theory,; return_wfn = 'yes',; molecule=universe; ). frequencies = psi4.frequencies(; theory,; ref_gradient=wave_function.gradient(),; molecule=universe. ); ```. Ouput:. ```python; Freq [cm^-1] 1557.5017 4053.2831 4197.9898 ; Irrep A1 A1 B2 ; Reduced mass [u] 1.0830 1.0449 1.0829 ; Force const [mDyne/A] 1.5478 10.1143 11.2435 ; Turning point v=0 [a0] 0.2672 0.1686 0.1627 ; RMS dev v=0 [a0 u^1/2] 0.1966 0.1219 0.1198 ; IR activ [km/mol] 92.6794 13.8599 85.5429 ; Char temp [K] 2240.8982 5831.7720 6039.9727 ; ----------------------------------------------------------------------------------; 1 O 0.00 -0.00 -0.07 0.00 -0.00 0.05 0.00 -0.07 -0.00 ; 2 H -0.00 0.43 0.56 0.00 0.59 -0.39 0.00 0.56 -0.43 ; 3 H 0.00 -0.43 0.56 0.00 -0.59 -0.39 0.00 0.56 0.43 ; ```. So I want to ",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2698#issuecomment-1227099808
https://github.com/psi4/psi4/pull/2699#issuecomment-1225899078:299,Usability,learn,learned,299,"It's a [colon dash](https://en.wikipedia.org/wiki/Compound_point) (well, it has a more amusing name but, to keep things family friendly, I'll allow you to look that up in the Wiki article). I was taught that it should be used for lists when I was young, and it wasn't until I moved to the US that I learned that it's *very* outdated.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2699#issuecomment-1225899078
https://github.com/psi4/psi4/pull/2699#issuecomment-1225905701:301,Usability,learn,learned,301,"> It's a [colon dash](https://en.wikipedia.org/wiki/Compound_point) (well, it has a more amusing name but, to keep things family friendly, I'll allow you to look that up in the Wiki article). I was taught that it should be used for lists when I was young, and it wasn't until I moved to the US that I learned that it's very outdated. Oh yeah, that wiki article is familiar, maybe we've had this conversation at the uhf file, the rohf file, and now the rhf file. ",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2699#issuecomment-1225905701
https://github.com/psi4/psi4/pull/2700#issuecomment-1226880838:13,Availability,error,error,13,"All relevant error information should end up in the error box, not just `stderr`",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2700#issuecomment-1226880838
https://github.com/psi4/psi4/pull/2700#issuecomment-1226880838:52,Availability,error,error,52,"All relevant error information should end up in the error box, not just `stderr`",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2700#issuecomment-1226880838
https://github.com/psi4/psi4/pull/2700#issuecomment-1230376809:126,Deployability,update,updated,126,"Holger's comment stands. Build fail is due to an environment, not this PR, and will be automatically fixed once the commit is updated.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2700#issuecomment-1230376809
https://github.com/psi4/psi4/pull/2700#issuecomment-1236139536:15,Availability,error,error,15,"> All relevant error information should end up in the error box, not just `stderr`. OK. Would the inverse be acceptable? ie. nothing going to `stderr`, only to the error box",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2700#issuecomment-1236139536
https://github.com/psi4/psi4/pull/2700#issuecomment-1236139536:54,Availability,error,error,54,"> All relevant error information should end up in the error box, not just `stderr`. OK. Would the inverse be acceptable? ie. nothing going to `stderr`, only to the error box",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2700#issuecomment-1236139536
https://github.com/psi4/psi4/pull/2700#issuecomment-1236139536:164,Availability,error,error,164,"> All relevant error information should end up in the error box, not just `stderr`. OK. Would the inverse be acceptable? ie. nothing going to `stderr`, only to the error box",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2700#issuecomment-1236139536
https://github.com/psi4/psi4/pull/2700#issuecomment-1236169643:16,Availability,error,error,16,">> All relevant error information should end up in the error box, not just stderr. > OK. Would the inverse be acceptable? ie. nothing going to stderr, only to the error box. Haven't investigated, but my first thought is that error box only would work",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2700#issuecomment-1236169643
https://github.com/psi4/psi4/pull/2700#issuecomment-1236169643:55,Availability,error,error,55,">> All relevant error information should end up in the error box, not just stderr. > OK. Would the inverse be acceptable? ie. nothing going to stderr, only to the error box. Haven't investigated, but my first thought is that error box only would work",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2700#issuecomment-1236169643
https://github.com/psi4/psi4/pull/2700#issuecomment-1236169643:163,Availability,error,error,163,">> All relevant error information should end up in the error box, not just stderr. > OK. Would the inverse be acceptable? ie. nothing going to stderr, only to the error box. Haven't investigated, but my first thought is that error box only would work",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2700#issuecomment-1236169643
https://github.com/psi4/psi4/pull/2700#issuecomment-1236169643:225,Availability,error,error,225,">> All relevant error information should end up in the error box, not just stderr. > OK. Would the inverse be acceptable? ie. nothing going to stderr, only to the error box. Haven't investigated, but my first thought is that error box only would work",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2700#issuecomment-1236169643
https://github.com/psi4/psi4/pull/2700#issuecomment-1250060587:68,Availability,error,errors,68,"I have reworked this PR to a general renovation of `toclen.cc`. All errors are now handled by calling `psio_error()`, OS-provided messages are decoded by a new fn that may be useful elsewhere later and the toclen fns now first check if the stream is ought to be open and error out early with a more specific error message.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2700#issuecomment-1250060587
https://github.com/psi4/psi4/pull/2700#issuecomment-1250060587:271,Availability,error,error,271,"I have reworked this PR to a general renovation of `toclen.cc`. All errors are now handled by calling `psio_error()`, OS-provided messages are decoded by a new fn that may be useful elsewhere later and the toclen fns now first check if the stream is ought to be open and error out early with a more specific error message.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2700#issuecomment-1250060587
https://github.com/psi4/psi4/pull/2700#issuecomment-1250060587:308,Availability,error,error,308,"I have reworked this PR to a general renovation of `toclen.cc`. All errors are now handled by calling `psio_error()`, OS-provided messages are decoded by a new fn that may be useful elsewhere later and the toclen fns now first check if the stream is ought to be open and error out early with a more specific error message.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2700#issuecomment-1250060587
https://github.com/psi4/psi4/pull/2700#issuecomment-1250060587:130,Integrability,message,messages,130,"I have reworked this PR to a general renovation of `toclen.cc`. All errors are now handled by calling `psio_error()`, OS-provided messages are decoded by a new fn that may be useful elsewhere later and the toclen fns now first check if the stream is ought to be open and error out early with a more specific error message.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2700#issuecomment-1250060587
https://github.com/psi4/psi4/pull/2700#issuecomment-1250060587:314,Integrability,message,message,314,"I have reworked this PR to a general renovation of `toclen.cc`. All errors are now handled by calling `psio_error()`, OS-provided messages are decoded by a new fn that may be useful elsewhere later and the toclen fns now first check if the stream is ought to be open and error out early with a more specific error message.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2700#issuecomment-1250060587
https://github.com/psi4/psi4/pull/2700#issuecomment-1251226972:70,Availability,error,error,70,"Incidentally, an independent PR of mine just ran into this particular error message. I'm eager to get this in.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2700#issuecomment-1251226972
https://github.com/psi4/psi4/pull/2700#issuecomment-1251226972:76,Integrability,message,message,76,"Incidentally, an independent PR of mine just ran into this particular error message. I'm eager to get this in.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2700#issuecomment-1251226972
https://github.com/psi4/psi4/pull/2700#issuecomment-1252900992:37,Deployability,update,update,37,"I have made one final commit here to update the comment, this should be OK to merge unless someone else wants to chime in. The tests run by the CI are passing, here is hoping there will no surprises the next time someone runs the full test suite.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2700#issuecomment-1252900992
https://github.com/psi4/psi4/pull/2700#issuecomment-1252900992:127,Testability,test,tests,127,"I have made one final commit here to update the comment, this should be OK to merge unless someone else wants to chime in. The tests run by the CI are passing, here is hoping there will no surprises the next time someone runs the full test suite.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2700#issuecomment-1252900992
https://github.com/psi4/psi4/pull/2700#issuecomment-1252900992:235,Testability,test,test,235,"I have made one final commit here to update the comment, this should be OK to merge unless someone else wants to chime in. The tests run by the CI are passing, here is hoping there will no surprises the next time someone runs the full test suite.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2700#issuecomment-1252900992
https://github.com/psi4/psi4/pull/2702#issuecomment-1227384055:162,Availability,error,error,162,"It looks like the numpy/scipy issue on Azure has healed with upstream packages without intervention here, so closing. otoh, GHA Linux just hit our old friend CFI error during compile ...",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2702#issuecomment-1227384055
https://github.com/psi4/psi4/pull/2703#issuecomment-1227086053:157,Deployability,patch,patch,157,"> Are you also zeroing out the diagonal for FMI in the UHF case? I looks like only the Fmi matrix is cleared there. Yes, on lines 75-77. Look for the little patch of green _between_ the red.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2703#issuecomment-1227086053
https://github.com/psi4/psi4/pull/2703#issuecomment-1227086053:166,Energy Efficiency,green,green,166,"> Are you also zeroing out the diagonal for FMI in the UHF case? I looks like only the Fmi matrix is cleared there. Yes, on lines 75-77. Look for the little patch of green _between_ the red.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2703#issuecomment-1227086053
https://github.com/psi4/psi4/pull/2703#issuecomment-1227086053:101,Usability,clear,cleared,101,"> Are you also zeroing out the diagonal for FMI in the UHF case? I looks like only the Fmi matrix is cleared there. Yes, on lines 75-77. Look for the little patch of green _between_ the red.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2703#issuecomment-1227086053
https://github.com/psi4/psi4/pull/2703#issuecomment-1227100111:166,Deployability,patch,patch,166,"> > Are you also zeroing out the diagonal for FMI in the UHF case? I looks like only the Fmi matrix is cleared there.; > ; > Yes, on lines 75-77. Look for the little patch of green _between_ the red. OK, now I see what you're doing. My only suggestion is that you modify the comment under RHF to read:. // This is because the amplitude update in RHF uses the full residual while the ROHF and UHF updates separate out the diagonal contributions from the Fock matrix [cf. Eqs. (1) and (2) of Stanton et al., J. Chem. Phys. 94, 4334-4345 (1991)].",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2703#issuecomment-1227100111
https://github.com/psi4/psi4/pull/2703#issuecomment-1227100111:336,Deployability,update,update,336,"> > Are you also zeroing out the diagonal for FMI in the UHF case? I looks like only the Fmi matrix is cleared there.; > ; > Yes, on lines 75-77. Look for the little patch of green _between_ the red. OK, now I see what you're doing. My only suggestion is that you modify the comment under RHF to read:. // This is because the amplitude update in RHF uses the full residual while the ROHF and UHF updates separate out the diagonal contributions from the Fock matrix [cf. Eqs. (1) and (2) of Stanton et al., J. Chem. Phys. 94, 4334-4345 (1991)].",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2703#issuecomment-1227100111
https://github.com/psi4/psi4/pull/2703#issuecomment-1227100111:396,Deployability,update,updates,396,"> > Are you also zeroing out the diagonal for FMI in the UHF case? I looks like only the Fmi matrix is cleared there.; > ; > Yes, on lines 75-77. Look for the little patch of green _between_ the red. OK, now I see what you're doing. My only suggestion is that you modify the comment under RHF to read:. // This is because the amplitude update in RHF uses the full residual while the ROHF and UHF updates separate out the diagonal contributions from the Fock matrix [cf. Eqs. (1) and (2) of Stanton et al., J. Chem. Phys. 94, 4334-4345 (1991)].",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2703#issuecomment-1227100111
https://github.com/psi4/psi4/pull/2703#issuecomment-1227100111:175,Energy Efficiency,green,green,175,"> > Are you also zeroing out the diagonal for FMI in the UHF case? I looks like only the Fmi matrix is cleared there.; > ; > Yes, on lines 75-77. Look for the little patch of green _between_ the red. OK, now I see what you're doing. My only suggestion is that you modify the comment under RHF to read:. // This is because the amplitude update in RHF uses the full residual while the ROHF and UHF updates separate out the diagonal contributions from the Fock matrix [cf. Eqs. (1) and (2) of Stanton et al., J. Chem. Phys. 94, 4334-4345 (1991)].",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2703#issuecomment-1227100111
https://github.com/psi4/psi4/pull/2703#issuecomment-1227100111:103,Usability,clear,cleared,103,"> > Are you also zeroing out the diagonal for FMI in the UHF case? I looks like only the Fmi matrix is cleared there.; > ; > Yes, on lines 75-77. Look for the little patch of green _between_ the red. OK, now I see what you're doing. My only suggestion is that you modify the comment under RHF to read:. // This is because the amplitude update in RHF uses the full residual while the ROHF and UHF updates separate out the diagonal contributions from the Fock matrix [cf. Eqs. (1) and (2) of Stanton et al., J. Chem. Phys. 94, 4334-4345 (1991)].",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2703#issuecomment-1227100111
https://github.com/psi4/psi4/issues/2706#issuecomment-1228625767:162,Integrability,interface,interface,162,"I think I have a partial understanding of why the python snippet works with the psi4 executable, but not psi4's python api. I suspect something about psi4's GDMA interface requires/assumes that there is an output file. When you run psi4 as an executable, the results are written to an output file, so everything is fine. When you run psi4 through the python api, the results are by default printed to your terminal and there is no output file, so you run into this problem. Here's a workaround. Add the following line to the python snippet, immediately after the `import psi4` line:; ```; psi4.core.set_output_file('output.dat', False); ```; This line changes the default output of psi4's python api (from the terminal to a file ""output.dat""). When I insert this line, the python snippet runs successfully. Someone more familiar with the GDMA interface than myself should look into how to fix psi4 so that this workaround isn't necessary.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2706#issuecomment-1228625767
https://github.com/psi4/psi4/issues/2706#issuecomment-1228625767:843,Integrability,interface,interface,843,"I think I have a partial understanding of why the python snippet works with the psi4 executable, but not psi4's python api. I suspect something about psi4's GDMA interface requires/assumes that there is an output file. When you run psi4 as an executable, the results are written to an output file, so everything is fine. When you run psi4 through the python api, the results are by default printed to your terminal and there is no output file, so you run into this problem. Here's a workaround. Add the following line to the python snippet, immediately after the `import psi4` line:; ```; psi4.core.set_output_file('output.dat', False); ```; This line changes the default output of psi4's python api (from the terminal to a file ""output.dat""). When I insert this line, the python snippet runs successfully. Someone more familiar with the GDMA interface than myself should look into how to fix psi4 so that this workaround isn't necessary.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2706#issuecomment-1228625767
https://github.com/psi4/psi4/issues/2706#issuecomment-1228661577:57,Integrability,interface,interface,57,Reopening because; > Someone more familiar with the GDMA interface than myself should look into how to fix psi4 so that this workaround isn't necessary.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2706#issuecomment-1228661577
https://github.com/psi4/psi4/issues/2706#issuecomment-1228698239:154,Deployability,install,installation,154,The gmda interface seems pretty straightforward. I could look into this since I'm using it daily. . Is there any documentation on how to keep an isolated installation of psi4 for development? Any tips would be appreciated!,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2706#issuecomment-1228698239
https://github.com/psi4/psi4/issues/2706#issuecomment-1228698239:9,Integrability,interface,interface,9,The gmda interface seems pretty straightforward. I could look into this since I'm using it daily. . Is there any documentation on how to keep an isolated installation of psi4 for development? Any tips would be appreciated!,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2706#issuecomment-1228698239
https://github.com/psi4/psi4/issues/2706#issuecomment-1228746448:212,Deployability,install,installation,212,"Wow, looks like @hokru solved this 4 years ago in #1334. I've merged the PR to psi4/gdma but will need to rebuild the stack before you see any improvement. > Is there any documentation on how to keep an isolated installation of psi4 for development? Any tips would be appreciated!. It doesn't look like you need to do any investigation for this problem, but I'm glad to help on this in general. I'm not sure what you mean by ""isolated installation of psi4 for development"". I manage everything with conda envs. One might have an env with a psi4 conda package installed to use at runtime and another env with psi4-dev conda package installed to supply deps for a psi4 source repository with a compile directory.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2706#issuecomment-1228746448
https://github.com/psi4/psi4/issues/2706#issuecomment-1228746448:435,Deployability,install,installation,435,"Wow, looks like @hokru solved this 4 years ago in #1334. I've merged the PR to psi4/gdma but will need to rebuild the stack before you see any improvement. > Is there any documentation on how to keep an isolated installation of psi4 for development? Any tips would be appreciated!. It doesn't look like you need to do any investigation for this problem, but I'm glad to help on this in general. I'm not sure what you mean by ""isolated installation of psi4 for development"". I manage everything with conda envs. One might have an env with a psi4 conda package installed to use at runtime and another env with psi4-dev conda package installed to supply deps for a psi4 source repository with a compile directory.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2706#issuecomment-1228746448
https://github.com/psi4/psi4/issues/2706#issuecomment-1228746448:559,Deployability,install,installed,559,"Wow, looks like @hokru solved this 4 years ago in #1334. I've merged the PR to psi4/gdma but will need to rebuild the stack before you see any improvement. > Is there any documentation on how to keep an isolated installation of psi4 for development? Any tips would be appreciated!. It doesn't look like you need to do any investigation for this problem, but I'm glad to help on this in general. I'm not sure what you mean by ""isolated installation of psi4 for development"". I manage everything with conda envs. One might have an env with a psi4 conda package installed to use at runtime and another env with psi4-dev conda package installed to supply deps for a psi4 source repository with a compile directory.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2706#issuecomment-1228746448
https://github.com/psi4/psi4/issues/2706#issuecomment-1228746448:631,Deployability,install,installed,631,"Wow, looks like @hokru solved this 4 years ago in #1334. I've merged the PR to psi4/gdma but will need to rebuild the stack before you see any improvement. > Is there any documentation on how to keep an isolated installation of psi4 for development? Any tips would be appreciated!. It doesn't look like you need to do any investigation for this problem, but I'm glad to help on this in general. I'm not sure what you mean by ""isolated installation of psi4 for development"". I manage everything with conda envs. One might have an env with a psi4 conda package installed to use at runtime and another env with psi4-dev conda package installed to supply deps for a psi4 source repository with a compile directory.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2706#issuecomment-1228746448
https://github.com/psi4/psi4/pull/2708#issuecomment-1232380915:110,Energy Efficiency,energy,energy,110,"Hi, Lori. I've written and re-written a response to this out of concern for the definition of the correlation energy, but ultimately I've decided that the existing standard is reasonable (if not perfect, but I guess nothing is in this case). I also agree with your tightening of convergence criteria and the improvement of the docs, which look correct to me.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2708#issuecomment-1232380915
https://github.com/psi4/psi4/pull/2708#issuecomment-1243038562:449,Testability,test,test,449,"> Also it would be nice to have it documented exactly which flavor of ROHF-BCCD is implemented. Is it [_J. Chem. Phys. 107, 9980 (1997)_](https://doi.org/10.1063/1.475302) or something else?. No, but that was on my to-do list for a long time. The ""ROHF""-BCCD implemented should actually give the same results as a UHF-based BCCD (assuming no frozen core orbitals), but it's been a long time since I looked at that code. I don't even think we have a test case for it.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2708#issuecomment-1243038562
https://github.com/psi4/psi4/pull/2708#issuecomment-1243111522:375,Availability,error,error,375,"There is a rohf-bccd test at https://github.com/psi4/psi4/blob/master/tests/cc16/input.dat#L28 . If it's any help, bccd and bccd(t) all-electron in psi4 match that in cfour. (Though I did have to turn on orbitals=1 for cfour bccd(t) for rhf/uhf to allow it to match psi4. After moderate effort, I couldn't get cfour bccd to run with frozen-core, but I wouldn't rule out user error.). > Would taking a look at https://psicode.org/psi4manual/master/cc.html be also in-scope for this PR? I think that page never mentions that gradients are restricted to all-electron. I agree documenting capability exceptions is weak across modules at the moment. I was hoping to fix that with the table above, which is autogenerated from calcs, not hand-assembled. Do you think more is needed?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2708#issuecomment-1243111522
https://github.com/psi4/psi4/pull/2708#issuecomment-1243111522:21,Testability,test,test,21,"There is a rohf-bccd test at https://github.com/psi4/psi4/blob/master/tests/cc16/input.dat#L28 . If it's any help, bccd and bccd(t) all-electron in psi4 match that in cfour. (Though I did have to turn on orbitals=1 for cfour bccd(t) for rhf/uhf to allow it to match psi4. After moderate effort, I couldn't get cfour bccd to run with frozen-core, but I wouldn't rule out user error.). > Would taking a look at https://psicode.org/psi4manual/master/cc.html be also in-scope for this PR? I think that page never mentions that gradients are restricted to all-electron. I agree documenting capability exceptions is weak across modules at the moment. I was hoping to fix that with the table above, which is autogenerated from calcs, not hand-assembled. Do you think more is needed?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2708#issuecomment-1243111522
https://github.com/psi4/psi4/pull/2708#issuecomment-1243111522:70,Testability,test,tests,70,"There is a rohf-bccd test at https://github.com/psi4/psi4/blob/master/tests/cc16/input.dat#L28 . If it's any help, bccd and bccd(t) all-electron in psi4 match that in cfour. (Though I did have to turn on orbitals=1 for cfour bccd(t) for rhf/uhf to allow it to match psi4. After moderate effort, I couldn't get cfour bccd to run with frozen-core, but I wouldn't rule out user error.). > Would taking a look at https://psicode.org/psi4manual/master/cc.html be also in-scope for this PR? I think that page never mentions that gradients are restricted to all-electron. I agree documenting capability exceptions is weak across modules at the moment. I was hoping to fix that with the table above, which is autogenerated from calcs, not hand-assembled. Do you think more is needed?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2708#issuecomment-1243111522
https://github.com/psi4/psi4/pull/2708#issuecomment-1243114814:381,Availability,error,error,381,"> . > There is a rohf-bccd test at https://github.com/psi4/psi4/blob/master/tests/cc16/input.dat#L28 . If it's any help, bccd and bccd(t) all-electron in psi4 match that in cfour. (Though I did have to turn on orbitals=1 for cfour bccd(t) for rhf/uhf to allow it to match psi4. After moderate effort, I couldn't get cfour bccd to run with frozen-core, but I wouldn't rule out user error.); > ; > > Would taking a look at https://psicode.org/psi4manual/master/cc.html be also in-scope for this PR? I think that page never mentions that gradients are restricted to all-electron.; > ; > I agree documenting capability exceptions is weak across modules at the moment. I was hoping to fix that with the table above, which is autogenerated from calcs, not hand-assembled. Do you think more is needed?. Hmmm...the `cc_index` file refers to `cc16` as ""UHF-B-CCD(T)"", but the input file in that test appears to execute ROHF-B-CCD(T) twice. The `output.ref` file, on the other hand starts with a UHF initial guess, and then switches to ROHF. Strange that it still passes.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2708#issuecomment-1243114814
https://github.com/psi4/psi4/pull/2708#issuecomment-1243114814:27,Testability,test,test,27,"> . > There is a rohf-bccd test at https://github.com/psi4/psi4/blob/master/tests/cc16/input.dat#L28 . If it's any help, bccd and bccd(t) all-electron in psi4 match that in cfour. (Though I did have to turn on orbitals=1 for cfour bccd(t) for rhf/uhf to allow it to match psi4. After moderate effort, I couldn't get cfour bccd to run with frozen-core, but I wouldn't rule out user error.); > ; > > Would taking a look at https://psicode.org/psi4manual/master/cc.html be also in-scope for this PR? I think that page never mentions that gradients are restricted to all-electron.; > ; > I agree documenting capability exceptions is weak across modules at the moment. I was hoping to fix that with the table above, which is autogenerated from calcs, not hand-assembled. Do you think more is needed?. Hmmm...the `cc_index` file refers to `cc16` as ""UHF-B-CCD(T)"", but the input file in that test appears to execute ROHF-B-CCD(T) twice. The `output.ref` file, on the other hand starts with a UHF initial guess, and then switches to ROHF. Strange that it still passes.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2708#issuecomment-1243114814
https://github.com/psi4/psi4/pull/2708#issuecomment-1243114814:76,Testability,test,tests,76,"> . > There is a rohf-bccd test at https://github.com/psi4/psi4/blob/master/tests/cc16/input.dat#L28 . If it's any help, bccd and bccd(t) all-electron in psi4 match that in cfour. (Though I did have to turn on orbitals=1 for cfour bccd(t) for rhf/uhf to allow it to match psi4. After moderate effort, I couldn't get cfour bccd to run with frozen-core, but I wouldn't rule out user error.); > ; > > Would taking a look at https://psicode.org/psi4manual/master/cc.html be also in-scope for this PR? I think that page never mentions that gradients are restricted to all-electron.; > ; > I agree documenting capability exceptions is weak across modules at the moment. I was hoping to fix that with the table above, which is autogenerated from calcs, not hand-assembled. Do you think more is needed?. Hmmm...the `cc_index` file refers to `cc16` as ""UHF-B-CCD(T)"", but the input file in that test appears to execute ROHF-B-CCD(T) twice. The `output.ref` file, on the other hand starts with a UHF initial guess, and then switches to ROHF. Strange that it still passes.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2708#issuecomment-1243114814
https://github.com/psi4/psi4/pull/2708#issuecomment-1243114814:886,Testability,test,test,886,"> . > There is a rohf-bccd test at https://github.com/psi4/psi4/blob/master/tests/cc16/input.dat#L28 . If it's any help, bccd and bccd(t) all-electron in psi4 match that in cfour. (Though I did have to turn on orbitals=1 for cfour bccd(t) for rhf/uhf to allow it to match psi4. After moderate effort, I couldn't get cfour bccd to run with frozen-core, but I wouldn't rule out user error.); > ; > > Would taking a look at https://psicode.org/psi4manual/master/cc.html be also in-scope for this PR? I think that page never mentions that gradients are restricted to all-electron.; > ; > I agree documenting capability exceptions is weak across modules at the moment. I was hoping to fix that with the table above, which is autogenerated from calcs, not hand-assembled. Do you think more is needed?. Hmmm...the `cc_index` file refers to `cc16` as ""UHF-B-CCD(T)"", but the input file in that test appears to execute ROHF-B-CCD(T) twice. The `output.ref` file, on the other hand starts with a UHF initial guess, and then switches to ROHF. Strange that it still passes.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2708#issuecomment-1243114814
https://github.com/psi4/psi4/pull/2708#issuecomment-1243123504:623,Energy Efficiency,energy,energy,623,"> Hmmm...the cc_index file refers to cc16 as ""UHF-B-CCD(T)"", but the input file in that test appears to execute ROHF-B-CCD(T) twice. The output.ref file, on the other hand starts with a UHF initial guess, and then switches to ROHF. Strange that it still passes. I'm not quite following that, and I'm seeing both halves of cc16 pass independently. Below is my grep from a current run (albeit with this PR implemented). Looks like UHF executed twice, consistent with your explanation above. ```; >>> grep -e ""CCENERGY"" -e ""UHF"" -e ""ROHF"" ../tests/cc16/input.out ; #! ROHF and UHF-B-CCD(T)/cc-pVDZ $^{3}B@@1$ CH2 single-point energy (fzc, MO-basis $\langle ab|cd \rangle$ ); UHF Reference; SCF Guess: Superposition of Atomic Densities via on-the-fly atomic UHF (no occupation information).; @UHF iter SAD: -38.17324740294831 -3.81732e+01 0.00000e+00 ; @UHF iter 1: -38.90234369081286 -7.29096e-01 9.18281e-03 DIIS/ADIIS; @UHF iter 2: -38.91513874101264 -1.27951e-02 2.96594e-03 DIIS/ADIIS; @UHF iter 3: -38.91704192221893 -1.90318e-03 9.12227e-04 DIIS/ADIIS; @UHF iter 4: -38.91728769227936 -2.45770e-04 4.46390e-04 DIIS/ADIIS; @UHF iter 5: -38.91736714064817 -7.94484e-05 1.57015e-04 DIIS/ADIIS; @UHF iter 6: -38.91737800453875 -1.08639e-05 3.99078e-05 DIIS; @UHF iter 7: -38.91737866710707 -6.62568e-07 8.99030e-06 DIIS; @UHF iter 8: -38.91737869146961 -2.43625e-08 1.73779e-06 DIIS; @UHF iter 9: -38.91737869233113 -8.61519e-10 4.12144e-07 DIIS; @UHF iter 10: -38.91737869238197 -5.08393e-11 6.23767e-08 DIIS; @UHF iter 11: -38.91737869238317 -1.20082e-12 1.38186e-08 DIIS; @UHF iter 12: -38.91737869238320 -3.55271e-14 2.41469e-09 DIIS; @UHF Final Energy: -38.91737869238320; UHF NO Occupations:; 	Reference = UHF; * CCENERGY *; Reference wfn = UHF; 	Reference = UHF; * CCENERGY *; Reference wfn = UHF; 	Reference = UHF; * CCENERGY *; Reference wfn = UHF; 	Reference = UHF; * CCENERGY *; Reference wfn = UHF; Reference wfn = UHF; ROHF Reference; SCF Guess: Superposition of Atomic Densities via on-th",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2708#issuecomment-1243123504
https://github.com/psi4/psi4/pull/2708#issuecomment-1243123504:1649,Energy Efficiency,Energy,Energy,1649,sis $\langle ab|cd \rangle$ ); UHF Reference; SCF Guess: Superposition of Atomic Densities via on-the-fly atomic UHF (no occupation information).; @UHF iter SAD: -38.17324740294831 -3.81732e+01 0.00000e+00 ; @UHF iter 1: -38.90234369081286 -7.29096e-01 9.18281e-03 DIIS/ADIIS; @UHF iter 2: -38.91513874101264 -1.27951e-02 2.96594e-03 DIIS/ADIIS; @UHF iter 3: -38.91704192221893 -1.90318e-03 9.12227e-04 DIIS/ADIIS; @UHF iter 4: -38.91728769227936 -2.45770e-04 4.46390e-04 DIIS/ADIIS; @UHF iter 5: -38.91736714064817 -7.94484e-05 1.57015e-04 DIIS/ADIIS; @UHF iter 6: -38.91737800453875 -1.08639e-05 3.99078e-05 DIIS; @UHF iter 7: -38.91737866710707 -6.62568e-07 8.99030e-06 DIIS; @UHF iter 8: -38.91737869146961 -2.43625e-08 1.73779e-06 DIIS; @UHF iter 9: -38.91737869233113 -8.61519e-10 4.12144e-07 DIIS; @UHF iter 10: -38.91737869238197 -5.08393e-11 6.23767e-08 DIIS; @UHF iter 11: -38.91737869238317 -1.20082e-12 1.38186e-08 DIIS; @UHF iter 12: -38.91737869238320 -3.55271e-14 2.41469e-09 DIIS; @UHF Final Energy: -38.91737869238320; UHF NO Occupations:; 	Reference = UHF; * CCENERGY *; Reference wfn = UHF; 	Reference = UHF; * CCENERGY *; Reference wfn = UHF; 	Reference = UHF; * CCENERGY *; Reference wfn = UHF; 	Reference = UHF; * CCENERGY *; Reference wfn = UHF; Reference wfn = UHF; ROHF Reference; SCF Guess: Superposition of Atomic Densities via on-the-fly atomic UHF (no occupation information).; @ROHF iter SAD: -38.17324740294831 -3.81732e+01 0.00000e+00 ; @ROHF iter 1: -38.90234369081286 -7.29096e-01 6.50261e-03 DIIS; @ROHF iter 2: -38.91242369713282 -1.00800e-02 1.83961e-03 DIIS; @ROHF iter 3: -38.91339017288891 -9.66476e-04 2.69689e-04 DIIS; @ROHF iter 4: -38.91341456819070 -2.43953e-05 8.81475e-05 DIIS; @ROHF iter 5: -38.91341661898142 -2.05079e-06 1.51310e-05 DIIS; @ROHF iter 6: -38.91341670674457 -8.77632e-08 3.07520e-06 DIIS; @ROHF iter 7: -38.91341670984617 -3.10160e-09 4.33292e-07 DIIS; @ROHF iter 8: -38.91341670989266 -4.64837e-11 7.04761e-08 DIIS; @ROHF iter 9: -38.91,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2708#issuecomment-1243123504
https://github.com/psi4/psi4/pull/2708#issuecomment-1243123504:2763,Energy Efficiency,Energy,Energy,2763, -8.61519e-10 4.12144e-07 DIIS; @UHF iter 10: -38.91737869238197 -5.08393e-11 6.23767e-08 DIIS; @UHF iter 11: -38.91737869238317 -1.20082e-12 1.38186e-08 DIIS; @UHF iter 12: -38.91737869238320 -3.55271e-14 2.41469e-09 DIIS; @UHF Final Energy: -38.91737869238320; UHF NO Occupations:; 	Reference = UHF; * CCENERGY *; Reference wfn = UHF; 	Reference = UHF; * CCENERGY *; Reference wfn = UHF; 	Reference = UHF; * CCENERGY *; Reference wfn = UHF; 	Reference = UHF; * CCENERGY *; Reference wfn = UHF; Reference wfn = UHF; ROHF Reference; SCF Guess: Superposition of Atomic Densities via on-the-fly atomic UHF (no occupation information).; @ROHF iter SAD: -38.17324740294831 -3.81732e+01 0.00000e+00 ; @ROHF iter 1: -38.90234369081286 -7.29096e-01 6.50261e-03 DIIS; @ROHF iter 2: -38.91242369713282 -1.00800e-02 1.83961e-03 DIIS; @ROHF iter 3: -38.91339017288891 -9.66476e-04 2.69689e-04 DIIS; @ROHF iter 4: -38.91341456819070 -2.43953e-05 8.81475e-05 DIIS; @ROHF iter 5: -38.91341661898142 -2.05079e-06 1.51310e-05 DIIS; @ROHF iter 6: -38.91341670674457 -8.77632e-08 3.07520e-06 DIIS; @ROHF iter 7: -38.91341670984617 -3.10160e-09 4.33292e-07 DIIS; @ROHF iter 8: -38.91341670989266 -4.64837e-11 7.04761e-08 DIIS; @ROHF iter 9: -38.91341670989408 -1.42109e-12 1.28167e-08 DIIS; @ROHF iter 10: -38.91341670989415 -7.10543e-14 1.60731e-09 DIIS; @ROHF Final Energy: -38.91341670989415; 	Reference = ROHF changed to UHF for semicanonical orbitals; * CCENERGY *; Reference wfn = ROHF changed to UHF for Semicanonical Orbitals; 	Reference = ROHF changed to UHF for semicanonical orbitals; * CCENERGY *; Reference wfn = ROHF changed to UHF for Semicanonical Orbitals; 	Reference = ROHF changed to UHF for semicanonical orbitals; * CCENERGY *; Reference wfn = ROHF changed to UHF for Semicanonical Orbitals; 	Reference = ROHF changed to UHF for semicanonical orbitals; * CCENERGY *; Reference wfn = ROHF changed to UHF for Semicanonical Orbitals; Reference wfn = ROHF changed to UHF for Semicanonical Orbitals; ```,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2708#issuecomment-1243123504
https://github.com/psi4/psi4/pull/2708#issuecomment-1243123504:88,Testability,test,test,88,"> Hmmm...the cc_index file refers to cc16 as ""UHF-B-CCD(T)"", but the input file in that test appears to execute ROHF-B-CCD(T) twice. The output.ref file, on the other hand starts with a UHF initial guess, and then switches to ROHF. Strange that it still passes. I'm not quite following that, and I'm seeing both halves of cc16 pass independently. Below is my grep from a current run (albeit with this PR implemented). Looks like UHF executed twice, consistent with your explanation above. ```; >>> grep -e ""CCENERGY"" -e ""UHF"" -e ""ROHF"" ../tests/cc16/input.out ; #! ROHF and UHF-B-CCD(T)/cc-pVDZ $^{3}B@@1$ CH2 single-point energy (fzc, MO-basis $\langle ab|cd \rangle$ ); UHF Reference; SCF Guess: Superposition of Atomic Densities via on-the-fly atomic UHF (no occupation information).; @UHF iter SAD: -38.17324740294831 -3.81732e+01 0.00000e+00 ; @UHF iter 1: -38.90234369081286 -7.29096e-01 9.18281e-03 DIIS/ADIIS; @UHF iter 2: -38.91513874101264 -1.27951e-02 2.96594e-03 DIIS/ADIIS; @UHF iter 3: -38.91704192221893 -1.90318e-03 9.12227e-04 DIIS/ADIIS; @UHF iter 4: -38.91728769227936 -2.45770e-04 4.46390e-04 DIIS/ADIIS; @UHF iter 5: -38.91736714064817 -7.94484e-05 1.57015e-04 DIIS/ADIIS; @UHF iter 6: -38.91737800453875 -1.08639e-05 3.99078e-05 DIIS; @UHF iter 7: -38.91737866710707 -6.62568e-07 8.99030e-06 DIIS; @UHF iter 8: -38.91737869146961 -2.43625e-08 1.73779e-06 DIIS; @UHF iter 9: -38.91737869233113 -8.61519e-10 4.12144e-07 DIIS; @UHF iter 10: -38.91737869238197 -5.08393e-11 6.23767e-08 DIIS; @UHF iter 11: -38.91737869238317 -1.20082e-12 1.38186e-08 DIIS; @UHF iter 12: -38.91737869238320 -3.55271e-14 2.41469e-09 DIIS; @UHF Final Energy: -38.91737869238320; UHF NO Occupations:; 	Reference = UHF; * CCENERGY *; Reference wfn = UHF; 	Reference = UHF; * CCENERGY *; Reference wfn = UHF; 	Reference = UHF; * CCENERGY *; Reference wfn = UHF; 	Reference = UHF; * CCENERGY *; Reference wfn = UHF; Reference wfn = UHF; ROHF Reference; SCF Guess: Superposition of Atomic Densities via on-th",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2708#issuecomment-1243123504
https://github.com/psi4/psi4/pull/2708#issuecomment-1243123504:539,Testability,test,tests,539,"> Hmmm...the cc_index file refers to cc16 as ""UHF-B-CCD(T)"", but the input file in that test appears to execute ROHF-B-CCD(T) twice. The output.ref file, on the other hand starts with a UHF initial guess, and then switches to ROHF. Strange that it still passes. I'm not quite following that, and I'm seeing both halves of cc16 pass independently. Below is my grep from a current run (albeit with this PR implemented). Looks like UHF executed twice, consistent with your explanation above. ```; >>> grep -e ""CCENERGY"" -e ""UHF"" -e ""ROHF"" ../tests/cc16/input.out ; #! ROHF and UHF-B-CCD(T)/cc-pVDZ $^{3}B@@1$ CH2 single-point energy (fzc, MO-basis $\langle ab|cd \rangle$ ); UHF Reference; SCF Guess: Superposition of Atomic Densities via on-the-fly atomic UHF (no occupation information).; @UHF iter SAD: -38.17324740294831 -3.81732e+01 0.00000e+00 ; @UHF iter 1: -38.90234369081286 -7.29096e-01 9.18281e-03 DIIS/ADIIS; @UHF iter 2: -38.91513874101264 -1.27951e-02 2.96594e-03 DIIS/ADIIS; @UHF iter 3: -38.91704192221893 -1.90318e-03 9.12227e-04 DIIS/ADIIS; @UHF iter 4: -38.91728769227936 -2.45770e-04 4.46390e-04 DIIS/ADIIS; @UHF iter 5: -38.91736714064817 -7.94484e-05 1.57015e-04 DIIS/ADIIS; @UHF iter 6: -38.91737800453875 -1.08639e-05 3.99078e-05 DIIS; @UHF iter 7: -38.91737866710707 -6.62568e-07 8.99030e-06 DIIS; @UHF iter 8: -38.91737869146961 -2.43625e-08 1.73779e-06 DIIS; @UHF iter 9: -38.91737869233113 -8.61519e-10 4.12144e-07 DIIS; @UHF iter 10: -38.91737869238197 -5.08393e-11 6.23767e-08 DIIS; @UHF iter 11: -38.91737869238317 -1.20082e-12 1.38186e-08 DIIS; @UHF iter 12: -38.91737869238320 -3.55271e-14 2.41469e-09 DIIS; @UHF Final Energy: -38.91737869238320; UHF NO Occupations:; 	Reference = UHF; * CCENERGY *; Reference wfn = UHF; 	Reference = UHF; * CCENERGY *; Reference wfn = UHF; 	Reference = UHF; * CCENERGY *; Reference wfn = UHF; 	Reference = UHF; * CCENERGY *; Reference wfn = UHF; Reference wfn = UHF; ROHF Reference; SCF Guess: Superposition of Atomic Densities via on-th",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2708#issuecomment-1243123504
https://github.com/psi4/psi4/issues/2709#issuecomment-1232961209:121,Energy Efficiency,charge,charges,121,You also need to put the 2nd layer into the molecule section to have it enter the calculation.; Adding surrounding point charges in place of Na Cl atoms from missing layers/edges is a common way to do slabs in molecular codes (point charge embedding). Stabilises the electrostatics and reduces edge effects. Should help to converge the SCF as well. I'd suggest trying def2-SVP and a (meta)GGA and first see if you can converge the SCF before doing a geometry optimisation.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2709#issuecomment-1232961209
https://github.com/psi4/psi4/issues/2709#issuecomment-1232961209:233,Energy Efficiency,charge,charge,233,You also need to put the 2nd layer into the molecule section to have it enter the calculation.; Adding surrounding point charges in place of Na Cl atoms from missing layers/edges is a common way to do slabs in molecular codes (point charge embedding). Stabilises the electrostatics and reduces edge effects. Should help to converge the SCF as well. I'd suggest trying def2-SVP and a (meta)GGA and first see if you can converge the SCF before doing a geometry optimisation.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2709#issuecomment-1232961209
https://github.com/psi4/psi4/issues/2709#issuecomment-1232961209:286,Energy Efficiency,reduce,reduces,286,You also need to put the 2nd layer into the molecule section to have it enter the calculation.; Adding surrounding point charges in place of Na Cl atoms from missing layers/edges is a common way to do slabs in molecular codes (point charge embedding). Stabilises the electrostatics and reduces edge effects. Should help to converge the SCF as well. I'd suggest trying def2-SVP and a (meta)GGA and first see if you can converge the SCF before doing a geometry optimisation.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2709#issuecomment-1232961209
https://github.com/psi4/psi4/issues/2709#issuecomment-1232961209:166,Modifiability,layers,layers,166,You also need to put the 2nd layer into the molecule section to have it enter the calculation.; Adding surrounding point charges in place of Na Cl atoms from missing layers/edges is a common way to do slabs in molecular codes (point charge embedding). Stabilises the electrostatics and reduces edge effects. Should help to converge the SCF as well. I'd suggest trying def2-SVP and a (meta)GGA and first see if you can converge the SCF before doing a geometry optimisation.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2709#issuecomment-1232961209
https://github.com/psi4/psi4/issues/2709#issuecomment-1233101316:201,Energy Efficiency,charge,charge,201,"Thanks a lot @hokru! ; I will fix the mistake first and then see about the basis set and functional change. Can you provide me with some literature where I can read up on those things? Also this point charge embedding is new to me. This would only work if I was not interested in the shifted lattice positions, but how much cheaper would that be?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2709#issuecomment-1233101316
https://github.com/psi4/psi4/issues/2709#issuecomment-1234106730:95,Energy Efficiency,charge,charge,95,> Can you provide me with some literature where I can read up on those things? Also this point charge embedding is new to me. No sorry. Need to look for yourself. I know this from talking to people and watching conference talks. No first hand experience,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2709#issuecomment-1234106730
https://github.com/psi4/psi4/issues/2712#issuecomment-1240798091:130,Safety,unsafe,unsafe,130,"The problem is [this](https://github.com/psi4/psi4/blob/master/psi4/src/psi4/scfgrad/scf_grad.cc#L81) line of code, which does an unsafe cast from a *Wavefunction to a *HF. The first call passes in an HF object and is fine. The second call does not pass in an HF object and is not fine. I think there are two separate issues here:; 1. The SCF gradient machinery should not allow non-HF wavefunctions.; 2. We may want to consider adding a way to serialize Wavefunction subclasses. To close this issue, it suffices to satisfy (1). Item (2) should be a separate issue, IMO.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2712#issuecomment-1240798091
https://github.com/psi4/psi4/issues/2713#issuecomment-1239555559:61,Energy Efficiency,energy,energy,61,"And in this special case, we can probably bypass most of the energy computation, except for some integral generation.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2713#issuecomment-1239555559
https://github.com/psi4/psi4/issues/2713#issuecomment-1240833143:159,Energy Efficiency,energy,energy,159,"One ugly way around this issue:. ```; set {; fail_on_maxiter false; maxiter 0; }. # Note: my_wfn.npy is a locally saved, previously written wfn file; e, wfn = energy('scf', return_wfn=True, restart_file='my_wfn') ; gradient('scf', ref_wfn=wfn); ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2713#issuecomment-1240833143
https://github.com/psi4/psi4/pull/2717#issuecomment-1243470370:517,Energy Efficiency,power,power-of-two,517,"Certainly. Polluted might have been too harsh, cluttered may be a more appropriate word for it. All variables are currently declared at the beginning of the function. Depending on the type of sort requested, some of them may never be initialized/used, but because they are declared at the top they are always visible and mutable inside the switch cases, loops, etc. This makes debugging more challenging than it has to be, as it is not possible to tell at a glance which of the variables with suspicious (negative or power-of-two) values are just uninitialized, as seen in the stack trace in https://github.com/psi4/psi4/issues/2261#issuecomment-1227164277 . In general variables should enter scope when they are needed and go out of scope when they are no longer required, and be `const` if they are never modified.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2717#issuecomment-1243470370
https://github.com/psi4/psi4/pull/2717#issuecomment-1243470370:167,Integrability,Depend,Depending,167,"Certainly. Polluted might have been too harsh, cluttered may be a more appropriate word for it. All variables are currently declared at the beginning of the function. Depending on the type of sort requested, some of them may never be initialized/used, but because they are declared at the top they are always visible and mutable inside the switch cases, loops, etc. This makes debugging more challenging than it has to be, as it is not possible to tell at a glance which of the variables with suspicious (negative or power-of-two) values are just uninitialized, as seen in the stack trace in https://github.com/psi4/psi4/issues/2261#issuecomment-1227164277 . In general variables should enter scope when they are needed and go out of scope when they are no longer required, and be `const` if they are never modified.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2717#issuecomment-1243470370
https://github.com/psi4/psi4/pull/2717#issuecomment-1243470370:100,Modifiability,variab,variables,100,"Certainly. Polluted might have been too harsh, cluttered may be a more appropriate word for it. All variables are currently declared at the beginning of the function. Depending on the type of sort requested, some of them may never be initialized/used, but because they are declared at the top they are always visible and mutable inside the switch cases, loops, etc. This makes debugging more challenging than it has to be, as it is not possible to tell at a glance which of the variables with suspicious (negative or power-of-two) values are just uninitialized, as seen in the stack trace in https://github.com/psi4/psi4/issues/2261#issuecomment-1227164277 . In general variables should enter scope when they are needed and go out of scope when they are no longer required, and be `const` if they are never modified.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2717#issuecomment-1243470370
https://github.com/psi4/psi4/pull/2717#issuecomment-1243470370:478,Modifiability,variab,variables,478,"Certainly. Polluted might have been too harsh, cluttered may be a more appropriate word for it. All variables are currently declared at the beginning of the function. Depending on the type of sort requested, some of them may never be initialized/used, but because they are declared at the top they are always visible and mutable inside the switch cases, loops, etc. This makes debugging more challenging than it has to be, as it is not possible to tell at a glance which of the variables with suspicious (negative or power-of-two) values are just uninitialized, as seen in the stack trace in https://github.com/psi4/psi4/issues/2261#issuecomment-1227164277 . In general variables should enter scope when they are needed and go out of scope when they are no longer required, and be `const` if they are never modified.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2717#issuecomment-1243470370
https://github.com/psi4/psi4/pull/2717#issuecomment-1243470370:670,Modifiability,variab,variables,670,"Certainly. Polluted might have been too harsh, cluttered may be a more appropriate word for it. All variables are currently declared at the beginning of the function. Depending on the type of sort requested, some of them may never be initialized/used, but because they are declared at the top they are always visible and mutable inside the switch cases, loops, etc. This makes debugging more challenging than it has to be, as it is not possible to tell at a glance which of the variables with suspicious (negative or power-of-two) values are just uninitialized, as seen in the stack trace in https://github.com/psi4/psi4/issues/2261#issuecomment-1227164277 . In general variables should enter scope when they are needed and go out of scope when they are no longer required, and be `const` if they are never modified.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2717#issuecomment-1243470370
https://github.com/psi4/psi4/pull/2717#issuecomment-1244241467:533,Energy Efficiency,power,power-of-two,533,"> Certainly. Polluted might have been too harsh, cluttered may be a more appropriate word for it.; > ; > All variables are currently declared at the beginning of the function. Depending on the type of sort requested, some of them may never be initialized/used, but because they are declared at the top they are always visible and mutable inside the switch cases, loops, etc.; > ; > This makes debugging more challenging than it has to be, as it is not possible to tell at a glance which of the variables with suspicious (negative or power-of-two) values are just uninitialized, as seen in the stack trace in [#2261 (comment)](https://github.com/psi4/psi4/issues/2261#issuecomment-1227164277); > ; > In general variables should enter scope when they are needed and go out of scope when they are no longer required, and be `const` if they are never modified. All fair criticisms, and that clears it up. The code was originally pure C and later modified to fit (nominally) within a C++ framework, hence the structure of the variable declarations.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2717#issuecomment-1244241467
https://github.com/psi4/psi4/pull/2717#issuecomment-1244241467:176,Integrability,Depend,Depending,176,"> Certainly. Polluted might have been too harsh, cluttered may be a more appropriate word for it.; > ; > All variables are currently declared at the beginning of the function. Depending on the type of sort requested, some of them may never be initialized/used, but because they are declared at the top they are always visible and mutable inside the switch cases, loops, etc.; > ; > This makes debugging more challenging than it has to be, as it is not possible to tell at a glance which of the variables with suspicious (negative or power-of-two) values are just uninitialized, as seen in the stack trace in [#2261 (comment)](https://github.com/psi4/psi4/issues/2261#issuecomment-1227164277); > ; > In general variables should enter scope when they are needed and go out of scope when they are no longer required, and be `const` if they are never modified. All fair criticisms, and that clears it up. The code was originally pure C and later modified to fit (nominally) within a C++ framework, hence the structure of the variable declarations.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2717#issuecomment-1244241467
https://github.com/psi4/psi4/pull/2717#issuecomment-1244241467:109,Modifiability,variab,variables,109,"> Certainly. Polluted might have been too harsh, cluttered may be a more appropriate word for it.; > ; > All variables are currently declared at the beginning of the function. Depending on the type of sort requested, some of them may never be initialized/used, but because they are declared at the top they are always visible and mutable inside the switch cases, loops, etc.; > ; > This makes debugging more challenging than it has to be, as it is not possible to tell at a glance which of the variables with suspicious (negative or power-of-two) values are just uninitialized, as seen in the stack trace in [#2261 (comment)](https://github.com/psi4/psi4/issues/2261#issuecomment-1227164277); > ; > In general variables should enter scope when they are needed and go out of scope when they are no longer required, and be `const` if they are never modified. All fair criticisms, and that clears it up. The code was originally pure C and later modified to fit (nominally) within a C++ framework, hence the structure of the variable declarations.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2717#issuecomment-1244241467
https://github.com/psi4/psi4/pull/2717#issuecomment-1244241467:494,Modifiability,variab,variables,494,"> Certainly. Polluted might have been too harsh, cluttered may be a more appropriate word for it.; > ; > All variables are currently declared at the beginning of the function. Depending on the type of sort requested, some of them may never be initialized/used, but because they are declared at the top they are always visible and mutable inside the switch cases, loops, etc.; > ; > This makes debugging more challenging than it has to be, as it is not possible to tell at a glance which of the variables with suspicious (negative or power-of-two) values are just uninitialized, as seen in the stack trace in [#2261 (comment)](https://github.com/psi4/psi4/issues/2261#issuecomment-1227164277); > ; > In general variables should enter scope when they are needed and go out of scope when they are no longer required, and be `const` if they are never modified. All fair criticisms, and that clears it up. The code was originally pure C and later modified to fit (nominally) within a C++ framework, hence the structure of the variable declarations.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2717#issuecomment-1244241467
https://github.com/psi4/psi4/pull/2717#issuecomment-1244241467:710,Modifiability,variab,variables,710,"> Certainly. Polluted might have been too harsh, cluttered may be a more appropriate word for it.; > ; > All variables are currently declared at the beginning of the function. Depending on the type of sort requested, some of them may never be initialized/used, but because they are declared at the top they are always visible and mutable inside the switch cases, loops, etc.; > ; > This makes debugging more challenging than it has to be, as it is not possible to tell at a glance which of the variables with suspicious (negative or power-of-two) values are just uninitialized, as seen in the stack trace in [#2261 (comment)](https://github.com/psi4/psi4/issues/2261#issuecomment-1227164277); > ; > In general variables should enter scope when they are needed and go out of scope when they are no longer required, and be `const` if they are never modified. All fair criticisms, and that clears it up. The code was originally pure C and later modified to fit (nominally) within a C++ framework, hence the structure of the variable declarations.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2717#issuecomment-1244241467
https://github.com/psi4/psi4/pull/2717#issuecomment-1244241467:1021,Modifiability,variab,variable,1021,"> Certainly. Polluted might have been too harsh, cluttered may be a more appropriate word for it.; > ; > All variables are currently declared at the beginning of the function. Depending on the type of sort requested, some of them may never be initialized/used, but because they are declared at the top they are always visible and mutable inside the switch cases, loops, etc.; > ; > This makes debugging more challenging than it has to be, as it is not possible to tell at a glance which of the variables with suspicious (negative or power-of-two) values are just uninitialized, as seen in the stack trace in [#2261 (comment)](https://github.com/psi4/psi4/issues/2261#issuecomment-1227164277); > ; > In general variables should enter scope when they are needed and go out of scope when they are no longer required, and be `const` if they are never modified. All fair criticisms, and that clears it up. The code was originally pure C and later modified to fit (nominally) within a C++ framework, hence the structure of the variable declarations.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2717#issuecomment-1244241467
https://github.com/psi4/psi4/pull/2717#issuecomment-1244241467:887,Usability,clear,clears,887,"> Certainly. Polluted might have been too harsh, cluttered may be a more appropriate word for it.; > ; > All variables are currently declared at the beginning of the function. Depending on the type of sort requested, some of them may never be initialized/used, but because they are declared at the top they are always visible and mutable inside the switch cases, loops, etc.; > ; > This makes debugging more challenging than it has to be, as it is not possible to tell at a glance which of the variables with suspicious (negative or power-of-two) values are just uninitialized, as seen in the stack trace in [#2261 (comment)](https://github.com/psi4/psi4/issues/2261#issuecomment-1227164277); > ; > In general variables should enter scope when they are needed and go out of scope when they are no longer required, and be `const` if they are never modified. All fair criticisms, and that clears it up. The code was originally pure C and later modified to fit (nominally) within a C++ framework, hence the structure of the variable declarations.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2717#issuecomment-1244241467
https://github.com/psi4/psi4/pull/2718#issuecomment-1244232466:133,Deployability,release,release,133,"```; ## User-Facing Notes; <!-- A bullet-point format description of how this PR affects the user. This will be copy-pasted into the release notes. May be empty. -->; - [ ] Note 1; - [ ] Note 2. ## Dev-Facing Notes; <!-- A bullet-point format description of what this PR does ""at a glance."" Target audience is code reviewers and other devs skimming PRs. Should be more technical than user notes. Should never be empty. -->; - [ ] Note 1; - [ ] Note 2; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2718#issuecomment-1244232466
https://github.com/psi4/psi4/pull/2723#issuecomment-1252577899:20,Availability,down,down,20,"I'm all for locking down permissions at top-level and specifying them per-job. Are the proposed edits taking into account that the write permission is needed not for this repo but for the docs one `psi4/psi4docs` that's governed by its own token, not the `GITHUB_TOKEN`? So perhaps only `read` needed for the per-job permissions. I don't understand tokens too well, so I'm wondering how specialized an analysis is behind the PR? Thanks for proposing it!",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2723#issuecomment-1252577899
https://github.com/psi4/psi4/pull/2724#issuecomment-1257070240:147,Integrability,wrap,wrappers,147,"> Given how difficult PSIO is to use for non-experts (which is anybody who is going to be using it nowadays), I'd rather keep thin but descriptive wrappers. Very well. The two functions in question are now preserved.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2724#issuecomment-1257070240
https://github.com/psi4/psi4/pull/2724#issuecomment-1265862039:66,Integrability,wrap,wrapper,66,"Just to confirm: these are almost all just removal of the C-based wrapper functions, correct?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2724#issuecomment-1265862039
https://github.com/psi4/psi4/pull/2724#issuecomment-1265942890:68,Integrability,wrap,wrapper,68,"> Just to confirm: these are almost all just removal of the C-based wrapper functions, correct?. Yes. As far as I can tell different modules seem to be using PSIO in slightly different ways. The newer modules tend to create their own PSIO object and then call its member functions, but older modules seem to be more reliant on global state. To satisfy this, there is a ""global PSIO object"", and some wrapper functions have been written that usually do the same thing as the corresponding PSIO member functions, except they are regular functions and they manipulate the ""global PSIO object"". This PR removes the unused ones.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2724#issuecomment-1265942890
https://github.com/psi4/psi4/pull/2724#issuecomment-1265942890:400,Integrability,wrap,wrapper,400,"> Just to confirm: these are almost all just removal of the C-based wrapper functions, correct?. Yes. As far as I can tell different modules seem to be using PSIO in slightly different ways. The newer modules tend to create their own PSIO object and then call its member functions, but older modules seem to be more reliant on global state. To satisfy this, there is a ""global PSIO object"", and some wrapper functions have been written that usually do the same thing as the corresponding PSIO member functions, except they are regular functions and they manipulate the ""global PSIO object"". This PR removes the unused ones.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2724#issuecomment-1265942890
https://github.com/psi4/psi4/issues/2725#issuecomment-1257288803:173,Performance,perform,performance,173,"Yes, I wrote the original version of `libpsio`, and this I/O structure was an important part of its use for many years. Indeed, it was intended to replicate some of the key performance features of an earlier I/O library (long since removed) contained within the old `libciomr` that have infrastructure for about four different types of I/O. However, at some point in the development of Psi4, someone wrote the new, much more complicated code for building the file paths, they broke this capability. Chesterton's fence strikes again.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2725#issuecomment-1257288803
https://github.com/psi4/psi4/issues/2725#issuecomment-1271996309:239,Integrability,interface,interface,239,"> The ""correct"" solution is probably to replace PSIO with hdf5. I'd like to talk about that at PsiCon. Q5Cost ?; I have seen some evidence of Q5Cost support in the MRCC codebase, so that could maybe replace the currently very fragile MRCC interface.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2725#issuecomment-1271996309
https://github.com/psi4/psi4/issues/2725#issuecomment-1272030427:468,Integrability,interoperab,interoperability,468,"Further discussion of replacing `libpsio` should be moved to a new issue. As for your specific proposal:. I'm not familiar with Q5Cost, and a quick Google search gives me a 14-year-old manual with so many out-of-date links that I doubt Q5Cost is actively maintained. That's a compelling argument against adopting it. Q5Cost was a proposed standard format for tensors-with-metadata. If MRCC is the only other major user and we have no reason to believe in other users, interoperability is not a compelling reason.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2725#issuecomment-1272030427
https://github.com/psi4/psi4/pull/2727#issuecomment-1259849511:702,Deployability,update,updated,702,"The test that is currently failing is a test in `gcp/pbeh3c/`. This is due to an optking side issue where the `CustomHelper` class being used by optking is not accepting a `psi4.core.Molecule` the type checking was looking for `qcdb.Molecule`. As a backup optking defaulted to psi4's active molecule. This is the call.; `E = optimize('pbeh3c/def2-msvp', molecule=unopethene)`. optking takes the molecule here in the driver and uses a default fallback instead: ; ` opt_object = optking.opt_helper.CustomHelper(molecule, params=optimizer_params)`. The type check will get changed in optking to include `core.Molecule`. An alternative question this raises for me is whether the active_molecule should get updated at some point in the optimization. Updating the active molecule patches the issue but is that desired?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1259849511
https://github.com/psi4/psi4/pull/2727#issuecomment-1259849511:774,Deployability,patch,patches,774,"The test that is currently failing is a test in `gcp/pbeh3c/`. This is due to an optking side issue where the `CustomHelper` class being used by optking is not accepting a `psi4.core.Molecule` the type checking was looking for `qcdb.Molecule`. As a backup optking defaulted to psi4's active molecule. This is the call.; `E = optimize('pbeh3c/def2-msvp', molecule=unopethene)`. optking takes the molecule here in the driver and uses a default fallback instead: ; ` opt_object = optking.opt_helper.CustomHelper(molecule, params=optimizer_params)`. The type check will get changed in optking to include `core.Molecule`. An alternative question this raises for me is whether the active_molecule should get updated at some point in the optimization. Updating the active molecule patches the issue but is that desired?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1259849511
https://github.com/psi4/psi4/pull/2727#issuecomment-1259849511:325,Performance,optimiz,optimize,325,"The test that is currently failing is a test in `gcp/pbeh3c/`. This is due to an optking side issue where the `CustomHelper` class being used by optking is not accepting a `psi4.core.Molecule` the type checking was looking for `qcdb.Molecule`. As a backup optking defaulted to psi4's active molecule. This is the call.; `E = optimize('pbeh3c/def2-msvp', molecule=unopethene)`. optking takes the molecule here in the driver and uses a default fallback instead: ; ` opt_object = optking.opt_helper.CustomHelper(molecule, params=optimizer_params)`. The type check will get changed in optking to include `core.Molecule`. An alternative question this raises for me is whether the active_molecule should get updated at some point in the optimization. Updating the active molecule patches the issue but is that desired?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1259849511
https://github.com/psi4/psi4/pull/2727#issuecomment-1259849511:731,Performance,optimiz,optimization,731,"The test that is currently failing is a test in `gcp/pbeh3c/`. This is due to an optking side issue where the `CustomHelper` class being used by optking is not accepting a `psi4.core.Molecule` the type checking was looking for `qcdb.Molecule`. As a backup optking defaulted to psi4's active molecule. This is the call.; `E = optimize('pbeh3c/def2-msvp', molecule=unopethene)`. optking takes the molecule here in the driver and uses a default fallback instead: ; ` opt_object = optking.opt_helper.CustomHelper(molecule, params=optimizer_params)`. The type check will get changed in optking to include `core.Molecule`. An alternative question this raises for me is whether the active_molecule should get updated at some point in the optimization. Updating the active molecule patches the issue but is that desired?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1259849511
https://github.com/psi4/psi4/pull/2727#issuecomment-1259849511:4,Testability,test,test,4,"The test that is currently failing is a test in `gcp/pbeh3c/`. This is due to an optking side issue where the `CustomHelper` class being used by optking is not accepting a `psi4.core.Molecule` the type checking was looking for `qcdb.Molecule`. As a backup optking defaulted to psi4's active molecule. This is the call.; `E = optimize('pbeh3c/def2-msvp', molecule=unopethene)`. optking takes the molecule here in the driver and uses a default fallback instead: ; ` opt_object = optking.opt_helper.CustomHelper(molecule, params=optimizer_params)`. The type check will get changed in optking to include `core.Molecule`. An alternative question this raises for me is whether the active_molecule should get updated at some point in the optimization. Updating the active molecule patches the issue but is that desired?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1259849511
https://github.com/psi4/psi4/pull/2727#issuecomment-1259849511:40,Testability,test,test,40,"The test that is currently failing is a test in `gcp/pbeh3c/`. This is due to an optking side issue where the `CustomHelper` class being used by optking is not accepting a `psi4.core.Molecule` the type checking was looking for `qcdb.Molecule`. As a backup optking defaulted to psi4's active molecule. This is the call.; `E = optimize('pbeh3c/def2-msvp', molecule=unopethene)`. optking takes the molecule here in the driver and uses a default fallback instead: ; ` opt_object = optking.opt_helper.CustomHelper(molecule, params=optimizer_params)`. The type check will get changed in optking to include `core.Molecule`. An alternative question this raises for me is whether the active_molecule should get updated at some point in the optimization. Updating the active molecule patches the issue but is that desired?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1259849511
https://github.com/psi4/psi4/pull/2727#issuecomment-1260048655:720,Deployability,update,updated,720,"> The test that is currently failing is a test in `gcp/pbeh3c/`. This is due to an optking side issue where the `CustomHelper` class being used by optking is not accepting a `psi4.core.Molecule` the type checking was looking for `qcdb.Molecule`. As a backup optking defaulted to psi4's active molecule.; > ; > This is the call. `E = optimize('pbeh3c/def2-msvp', molecule=unopethene)`; > ; > optking takes the molecule here in the driver and uses a default fallback instead: ` opt_object = optking.opt_helper.CustomHelper(molecule, params=optimizer_params)`; > ; > The type check will get changed in optking to include `core.Molecule`. An alternative question this raises for me is whether the active_molecule should get updated at some point in the optimization. Updating the active molecule patches the issue but is that desired?. My vote would be ""no""; it's too much like changing the input. However, I do think that some users would expect the final active molecule to be updated for them. And workflows inside the python input may seem more intuitive that way.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1260048655
https://github.com/psi4/psi4/pull/2727#issuecomment-1260048655:792,Deployability,patch,patches,792,"> The test that is currently failing is a test in `gcp/pbeh3c/`. This is due to an optking side issue where the `CustomHelper` class being used by optking is not accepting a `psi4.core.Molecule` the type checking was looking for `qcdb.Molecule`. As a backup optking defaulted to psi4's active molecule.; > ; > This is the call. `E = optimize('pbeh3c/def2-msvp', molecule=unopethene)`; > ; > optking takes the molecule here in the driver and uses a default fallback instead: ` opt_object = optking.opt_helper.CustomHelper(molecule, params=optimizer_params)`; > ; > The type check will get changed in optking to include `core.Molecule`. An alternative question this raises for me is whether the active_molecule should get updated at some point in the optimization. Updating the active molecule patches the issue but is that desired?. My vote would be ""no""; it's too much like changing the input. However, I do think that some users would expect the final active molecule to be updated for them. And workflows inside the python input may seem more intuitive that way.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1260048655
https://github.com/psi4/psi4/pull/2727#issuecomment-1260048655:975,Deployability,update,updated,975,"> The test that is currently failing is a test in `gcp/pbeh3c/`. This is due to an optking side issue where the `CustomHelper` class being used by optking is not accepting a `psi4.core.Molecule` the type checking was looking for `qcdb.Molecule`. As a backup optking defaulted to psi4's active molecule.; > ; > This is the call. `E = optimize('pbeh3c/def2-msvp', molecule=unopethene)`; > ; > optking takes the molecule here in the driver and uses a default fallback instead: ` opt_object = optking.opt_helper.CustomHelper(molecule, params=optimizer_params)`; > ; > The type check will get changed in optking to include `core.Molecule`. An alternative question this raises for me is whether the active_molecule should get updated at some point in the optimization. Updating the active molecule patches the issue but is that desired?. My vote would be ""no""; it's too much like changing the input. However, I do think that some users would expect the final active molecule to be updated for them. And workflows inside the python input may seem more intuitive that way.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1260048655
https://github.com/psi4/psi4/pull/2727#issuecomment-1260048655:333,Performance,optimiz,optimize,333,"> The test that is currently failing is a test in `gcp/pbeh3c/`. This is due to an optking side issue where the `CustomHelper` class being used by optking is not accepting a `psi4.core.Molecule` the type checking was looking for `qcdb.Molecule`. As a backup optking defaulted to psi4's active molecule.; > ; > This is the call. `E = optimize('pbeh3c/def2-msvp', molecule=unopethene)`; > ; > optking takes the molecule here in the driver and uses a default fallback instead: ` opt_object = optking.opt_helper.CustomHelper(molecule, params=optimizer_params)`; > ; > The type check will get changed in optking to include `core.Molecule`. An alternative question this raises for me is whether the active_molecule should get updated at some point in the optimization. Updating the active molecule patches the issue but is that desired?. My vote would be ""no""; it's too much like changing the input. However, I do think that some users would expect the final active molecule to be updated for them. And workflows inside the python input may seem more intuitive that way.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1260048655
https://github.com/psi4/psi4/pull/2727#issuecomment-1260048655:749,Performance,optimiz,optimization,749,"> The test that is currently failing is a test in `gcp/pbeh3c/`. This is due to an optking side issue where the `CustomHelper` class being used by optking is not accepting a `psi4.core.Molecule` the type checking was looking for `qcdb.Molecule`. As a backup optking defaulted to psi4's active molecule.; > ; > This is the call. `E = optimize('pbeh3c/def2-msvp', molecule=unopethene)`; > ; > optking takes the molecule here in the driver and uses a default fallback instead: ` opt_object = optking.opt_helper.CustomHelper(molecule, params=optimizer_params)`; > ; > The type check will get changed in optking to include `core.Molecule`. An alternative question this raises for me is whether the active_molecule should get updated at some point in the optimization. Updating the active molecule patches the issue but is that desired?. My vote would be ""no""; it's too much like changing the input. However, I do think that some users would expect the final active molecule to be updated for them. And workflows inside the python input may seem more intuitive that way.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1260048655
https://github.com/psi4/psi4/pull/2727#issuecomment-1260048655:6,Testability,test,test,6,"> The test that is currently failing is a test in `gcp/pbeh3c/`. This is due to an optking side issue where the `CustomHelper` class being used by optking is not accepting a `psi4.core.Molecule` the type checking was looking for `qcdb.Molecule`. As a backup optking defaulted to psi4's active molecule.; > ; > This is the call. `E = optimize('pbeh3c/def2-msvp', molecule=unopethene)`; > ; > optking takes the molecule here in the driver and uses a default fallback instead: ` opt_object = optking.opt_helper.CustomHelper(molecule, params=optimizer_params)`; > ; > The type check will get changed in optking to include `core.Molecule`. An alternative question this raises for me is whether the active_molecule should get updated at some point in the optimization. Updating the active molecule patches the issue but is that desired?. My vote would be ""no""; it's too much like changing the input. However, I do think that some users would expect the final active molecule to be updated for them. And workflows inside the python input may seem more intuitive that way.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1260048655
https://github.com/psi4/psi4/pull/2727#issuecomment-1260048655:42,Testability,test,test,42,"> The test that is currently failing is a test in `gcp/pbeh3c/`. This is due to an optking side issue where the `CustomHelper` class being used by optking is not accepting a `psi4.core.Molecule` the type checking was looking for `qcdb.Molecule`. As a backup optking defaulted to psi4's active molecule.; > ; > This is the call. `E = optimize('pbeh3c/def2-msvp', molecule=unopethene)`; > ; > optking takes the molecule here in the driver and uses a default fallback instead: ` opt_object = optking.opt_helper.CustomHelper(molecule, params=optimizer_params)`; > ; > The type check will get changed in optking to include `core.Molecule`. An alternative question this raises for me is whether the active_molecule should get updated at some point in the optimization. Updating the active molecule patches the issue but is that desired?. My vote would be ""no""; it's too much like changing the input. However, I do think that some users would expect the final active molecule to be updated for them. And workflows inside the python input may seem more intuitive that way.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1260048655
https://github.com/psi4/psi4/pull/2727#issuecomment-1260048655:1045,Usability,intuit,intuitive,1045,"> The test that is currently failing is a test in `gcp/pbeh3c/`. This is due to an optking side issue where the `CustomHelper` class being used by optking is not accepting a `psi4.core.Molecule` the type checking was looking for `qcdb.Molecule`. As a backup optking defaulted to psi4's active molecule.; > ; > This is the call. `E = optimize('pbeh3c/def2-msvp', molecule=unopethene)`; > ; > optking takes the molecule here in the driver and uses a default fallback instead: ` opt_object = optking.opt_helper.CustomHelper(molecule, params=optimizer_params)`; > ; > The type check will get changed in optking to include `core.Molecule`. An alternative question this raises for me is whether the active_molecule should get updated at some point in the optimization. Updating the active molecule patches the issue but is that desired?. My vote would be ""no""; it's too much like changing the input. However, I do think that some users would expect the final active molecule to be updated for them. And workflows inside the python input may seem more intuitive that way.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1260048655
https://github.com/psi4/psi4/pull/2727#issuecomment-1260073808:88,Deployability,update,updated,88,">> An alternative question this raises for me is whether the active_molecule should get updated at some point in the optimization. Updating the active molecule patches the issue but is that desired?. > My vote would be ""no""; it's too much like changing the input. However, I do think that some users would expect the final active molecule to be updated for them. And workflows inside the python input may seem more intuitive that way. I may not be following this right. I'd say the state of the psi4 active mol _during_ an optimization is arbitrary -- whatever works for you. In cpp-optking, I think the communication was through legacymolecule anyways. The molecule optking is acting on _should_ be updated by the time control returns to the user at the end of the opt. I thought this was already happening through https://github.com/psi4/psi4/pull/2727/files#diff-acf663ccea13592c4c656cf89c7b62e6f5bd3b2e8b4f12ba354129bd39d096f8R1296-R1297 . That's consistent with cpp-optking, and I think that must be happening b/c many of the tests check NRE before and after opt.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1260073808
https://github.com/psi4/psi4/pull/2727#issuecomment-1260073808:160,Deployability,patch,patches,160,">> An alternative question this raises for me is whether the active_molecule should get updated at some point in the optimization. Updating the active molecule patches the issue but is that desired?. > My vote would be ""no""; it's too much like changing the input. However, I do think that some users would expect the final active molecule to be updated for them. And workflows inside the python input may seem more intuitive that way. I may not be following this right. I'd say the state of the psi4 active mol _during_ an optimization is arbitrary -- whatever works for you. In cpp-optking, I think the communication was through legacymolecule anyways. The molecule optking is acting on _should_ be updated by the time control returns to the user at the end of the opt. I thought this was already happening through https://github.com/psi4/psi4/pull/2727/files#diff-acf663ccea13592c4c656cf89c7b62e6f5bd3b2e8b4f12ba354129bd39d096f8R1296-R1297 . That's consistent with cpp-optking, and I think that must be happening b/c many of the tests check NRE before and after opt.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1260073808
https://github.com/psi4/psi4/pull/2727#issuecomment-1260073808:345,Deployability,update,updated,345,">> An alternative question this raises for me is whether the active_molecule should get updated at some point in the optimization. Updating the active molecule patches the issue but is that desired?. > My vote would be ""no""; it's too much like changing the input. However, I do think that some users would expect the final active molecule to be updated for them. And workflows inside the python input may seem more intuitive that way. I may not be following this right. I'd say the state of the psi4 active mol _during_ an optimization is arbitrary -- whatever works for you. In cpp-optking, I think the communication was through legacymolecule anyways. The molecule optking is acting on _should_ be updated by the time control returns to the user at the end of the opt. I thought this was already happening through https://github.com/psi4/psi4/pull/2727/files#diff-acf663ccea13592c4c656cf89c7b62e6f5bd3b2e8b4f12ba354129bd39d096f8R1296-R1297 . That's consistent with cpp-optking, and I think that must be happening b/c many of the tests check NRE before and after opt.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1260073808
https://github.com/psi4/psi4/pull/2727#issuecomment-1260073808:700,Deployability,update,updated,700,">> An alternative question this raises for me is whether the active_molecule should get updated at some point in the optimization. Updating the active molecule patches the issue but is that desired?. > My vote would be ""no""; it's too much like changing the input. However, I do think that some users would expect the final active molecule to be updated for them. And workflows inside the python input may seem more intuitive that way. I may not be following this right. I'd say the state of the psi4 active mol _during_ an optimization is arbitrary -- whatever works for you. In cpp-optking, I think the communication was through legacymolecule anyways. The molecule optking is acting on _should_ be updated by the time control returns to the user at the end of the opt. I thought this was already happening through https://github.com/psi4/psi4/pull/2727/files#diff-acf663ccea13592c4c656cf89c7b62e6f5bd3b2e8b4f12ba354129bd39d096f8R1296-R1297 . That's consistent with cpp-optking, and I think that must be happening b/c many of the tests check NRE before and after opt.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1260073808
https://github.com/psi4/psi4/pull/2727#issuecomment-1260073808:117,Performance,optimiz,optimization,117,">> An alternative question this raises for me is whether the active_molecule should get updated at some point in the optimization. Updating the active molecule patches the issue but is that desired?. > My vote would be ""no""; it's too much like changing the input. However, I do think that some users would expect the final active molecule to be updated for them. And workflows inside the python input may seem more intuitive that way. I may not be following this right. I'd say the state of the psi4 active mol _during_ an optimization is arbitrary -- whatever works for you. In cpp-optking, I think the communication was through legacymolecule anyways. The molecule optking is acting on _should_ be updated by the time control returns to the user at the end of the opt. I thought this was already happening through https://github.com/psi4/psi4/pull/2727/files#diff-acf663ccea13592c4c656cf89c7b62e6f5bd3b2e8b4f12ba354129bd39d096f8R1296-R1297 . That's consistent with cpp-optking, and I think that must be happening b/c many of the tests check NRE before and after opt.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1260073808
https://github.com/psi4/psi4/pull/2727#issuecomment-1260073808:523,Performance,optimiz,optimization,523,">> An alternative question this raises for me is whether the active_molecule should get updated at some point in the optimization. Updating the active molecule patches the issue but is that desired?. > My vote would be ""no""; it's too much like changing the input. However, I do think that some users would expect the final active molecule to be updated for them. And workflows inside the python input may seem more intuitive that way. I may not be following this right. I'd say the state of the psi4 active mol _during_ an optimization is arbitrary -- whatever works for you. In cpp-optking, I think the communication was through legacymolecule anyways. The molecule optking is acting on _should_ be updated by the time control returns to the user at the end of the opt. I thought this was already happening through https://github.com/psi4/psi4/pull/2727/files#diff-acf663ccea13592c4c656cf89c7b62e6f5bd3b2e8b4f12ba354129bd39d096f8R1296-R1297 . That's consistent with cpp-optking, and I think that must be happening b/c many of the tests check NRE before and after opt.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1260073808
https://github.com/psi4/psi4/pull/2727#issuecomment-1260073808:1031,Testability,test,tests,1031,">> An alternative question this raises for me is whether the active_molecule should get updated at some point in the optimization. Updating the active molecule patches the issue but is that desired?. > My vote would be ""no""; it's too much like changing the input. However, I do think that some users would expect the final active molecule to be updated for them. And workflows inside the python input may seem more intuitive that way. I may not be following this right. I'd say the state of the psi4 active mol _during_ an optimization is arbitrary -- whatever works for you. In cpp-optking, I think the communication was through legacymolecule anyways. The molecule optking is acting on _should_ be updated by the time control returns to the user at the end of the opt. I thought this was already happening through https://github.com/psi4/psi4/pull/2727/files#diff-acf663ccea13592c4c656cf89c7b62e6f5bd3b2e8b4f12ba354129bd39d096f8R1296-R1297 . That's consistent with cpp-optking, and I think that must be happening b/c many of the tests check NRE before and after opt.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1260073808
https://github.com/psi4/psi4/pull/2727#issuecomment-1260073808:415,Usability,intuit,intuitive,415,">> An alternative question this raises for me is whether the active_molecule should get updated at some point in the optimization. Updating the active molecule patches the issue but is that desired?. > My vote would be ""no""; it's too much like changing the input. However, I do think that some users would expect the final active molecule to be updated for them. And workflows inside the python input may seem more intuitive that way. I may not be following this right. I'd say the state of the psi4 active mol _during_ an optimization is arbitrary -- whatever works for you. In cpp-optking, I think the communication was through legacymolecule anyways. The molecule optking is acting on _should_ be updated by the time control returns to the user at the end of the opt. I thought this was already happening through https://github.com/psi4/psi4/pull/2727/files#diff-acf663ccea13592c4c656cf89c7b62e6f5bd3b2e8b4f12ba354129bd39d096f8R1296-R1297 . That's consistent with cpp-optking, and I think that must be happening b/c many of the tests check NRE before and after opt.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1260073808
https://github.com/psi4/psi4/pull/2727#issuecomment-1260085584:91,Deployability,update,updated,91,"> > > An alternative question this raises for me is whether the active_molecule should get updated at some point in the optimization. Updating the active molecule patches the issue but is that desired?; > ; > > My vote would be ""no""; it's too much like changing the input. However, I do think that some users would expect the final active molecule to be updated for them. And workflows inside the python input may seem more intuitive that way.; > ; > I may not be following this right. I'd say the state of the psi4 active mol _during_ an optimization is arbitrary -- whatever works for you. In cpp-optking, I think the communication was through legacymolecule anyways. The molecule optking is acting on _should_ be updated by the time control returns to the user at the end of the opt. I thought this was already happening through https://github.com/psi4/psi4/pull/2727/files#diff-acf663ccea13592c4c656cf89c7b62e6f5bd3b2e8b4f12ba354129bd39d096f8R1296-R1297 . That's consistent with cpp-optking, and I think that must be happening b/c many of the tests check NRE before and after opt. OK, you changed my hasty mind on that. What concerns me is that the user may, in some instances, not realize that the default active molecule is the one that optking is acting on and changing. But the upside convenience wins, I agree.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1260085584
https://github.com/psi4/psi4/pull/2727#issuecomment-1260085584:163,Deployability,patch,patches,163,"> > > An alternative question this raises for me is whether the active_molecule should get updated at some point in the optimization. Updating the active molecule patches the issue but is that desired?; > ; > > My vote would be ""no""; it's too much like changing the input. However, I do think that some users would expect the final active molecule to be updated for them. And workflows inside the python input may seem more intuitive that way.; > ; > I may not be following this right. I'd say the state of the psi4 active mol _during_ an optimization is arbitrary -- whatever works for you. In cpp-optking, I think the communication was through legacymolecule anyways. The molecule optking is acting on _should_ be updated by the time control returns to the user at the end of the opt. I thought this was already happening through https://github.com/psi4/psi4/pull/2727/files#diff-acf663ccea13592c4c656cf89c7b62e6f5bd3b2e8b4f12ba354129bd39d096f8R1296-R1297 . That's consistent with cpp-optking, and I think that must be happening b/c many of the tests check NRE before and after opt. OK, you changed my hasty mind on that. What concerns me is that the user may, in some instances, not realize that the default active molecule is the one that optking is acting on and changing. But the upside convenience wins, I agree.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1260085584
https://github.com/psi4/psi4/pull/2727#issuecomment-1260085584:354,Deployability,update,updated,354,"> > > An alternative question this raises for me is whether the active_molecule should get updated at some point in the optimization. Updating the active molecule patches the issue but is that desired?; > ; > > My vote would be ""no""; it's too much like changing the input. However, I do think that some users would expect the final active molecule to be updated for them. And workflows inside the python input may seem more intuitive that way.; > ; > I may not be following this right. I'd say the state of the psi4 active mol _during_ an optimization is arbitrary -- whatever works for you. In cpp-optking, I think the communication was through legacymolecule anyways. The molecule optking is acting on _should_ be updated by the time control returns to the user at the end of the opt. I thought this was already happening through https://github.com/psi4/psi4/pull/2727/files#diff-acf663ccea13592c4c656cf89c7b62e6f5bd3b2e8b4f12ba354129bd39d096f8R1296-R1297 . That's consistent with cpp-optking, and I think that must be happening b/c many of the tests check NRE before and after opt. OK, you changed my hasty mind on that. What concerns me is that the user may, in some instances, not realize that the default active molecule is the one that optking is acting on and changing. But the upside convenience wins, I agree.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1260085584
https://github.com/psi4/psi4/pull/2727#issuecomment-1260085584:716,Deployability,update,updated,716,"> > > An alternative question this raises for me is whether the active_molecule should get updated at some point in the optimization. Updating the active molecule patches the issue but is that desired?; > ; > > My vote would be ""no""; it's too much like changing the input. However, I do think that some users would expect the final active molecule to be updated for them. And workflows inside the python input may seem more intuitive that way.; > ; > I may not be following this right. I'd say the state of the psi4 active mol _during_ an optimization is arbitrary -- whatever works for you. In cpp-optking, I think the communication was through legacymolecule anyways. The molecule optking is acting on _should_ be updated by the time control returns to the user at the end of the opt. I thought this was already happening through https://github.com/psi4/psi4/pull/2727/files#diff-acf663ccea13592c4c656cf89c7b62e6f5bd3b2e8b4f12ba354129bd39d096f8R1296-R1297 . That's consistent with cpp-optking, and I think that must be happening b/c many of the tests check NRE before and after opt. OK, you changed my hasty mind on that. What concerns me is that the user may, in some instances, not realize that the default active molecule is the one that optking is acting on and changing. But the upside convenience wins, I agree.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1260085584
https://github.com/psi4/psi4/pull/2727#issuecomment-1260085584:120,Performance,optimiz,optimization,120,"> > > An alternative question this raises for me is whether the active_molecule should get updated at some point in the optimization. Updating the active molecule patches the issue but is that desired?; > ; > > My vote would be ""no""; it's too much like changing the input. However, I do think that some users would expect the final active molecule to be updated for them. And workflows inside the python input may seem more intuitive that way.; > ; > I may not be following this right. I'd say the state of the psi4 active mol _during_ an optimization is arbitrary -- whatever works for you. In cpp-optking, I think the communication was through legacymolecule anyways. The molecule optking is acting on _should_ be updated by the time control returns to the user at the end of the opt. I thought this was already happening through https://github.com/psi4/psi4/pull/2727/files#diff-acf663ccea13592c4c656cf89c7b62e6f5bd3b2e8b4f12ba354129bd39d096f8R1296-R1297 . That's consistent with cpp-optking, and I think that must be happening b/c many of the tests check NRE before and after opt. OK, you changed my hasty mind on that. What concerns me is that the user may, in some instances, not realize that the default active molecule is the one that optking is acting on and changing. But the upside convenience wins, I agree.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1260085584
https://github.com/psi4/psi4/pull/2727#issuecomment-1260085584:539,Performance,optimiz,optimization,539,"> > > An alternative question this raises for me is whether the active_molecule should get updated at some point in the optimization. Updating the active molecule patches the issue but is that desired?; > ; > > My vote would be ""no""; it's too much like changing the input. However, I do think that some users would expect the final active molecule to be updated for them. And workflows inside the python input may seem more intuitive that way.; > ; > I may not be following this right. I'd say the state of the psi4 active mol _during_ an optimization is arbitrary -- whatever works for you. In cpp-optking, I think the communication was through legacymolecule anyways. The molecule optking is acting on _should_ be updated by the time control returns to the user at the end of the opt. I thought this was already happening through https://github.com/psi4/psi4/pull/2727/files#diff-acf663ccea13592c4c656cf89c7b62e6f5bd3b2e8b4f12ba354129bd39d096f8R1296-R1297 . That's consistent with cpp-optking, and I think that must be happening b/c many of the tests check NRE before and after opt. OK, you changed my hasty mind on that. What concerns me is that the user may, in some instances, not realize that the default active molecule is the one that optking is acting on and changing. But the upside convenience wins, I agree.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1260085584
https://github.com/psi4/psi4/pull/2727#issuecomment-1260085584:1047,Testability,test,tests,1047,"> > > An alternative question this raises for me is whether the active_molecule should get updated at some point in the optimization. Updating the active molecule patches the issue but is that desired?; > ; > > My vote would be ""no""; it's too much like changing the input. However, I do think that some users would expect the final active molecule to be updated for them. And workflows inside the python input may seem more intuitive that way.; > ; > I may not be following this right. I'd say the state of the psi4 active mol _during_ an optimization is arbitrary -- whatever works for you. In cpp-optking, I think the communication was through legacymolecule anyways. The molecule optking is acting on _should_ be updated by the time control returns to the user at the end of the opt. I thought this was already happening through https://github.com/psi4/psi4/pull/2727/files#diff-acf663ccea13592c4c656cf89c7b62e6f5bd3b2e8b4f12ba354129bd39d096f8R1296-R1297 . That's consistent with cpp-optking, and I think that must be happening b/c many of the tests check NRE before and after opt. OK, you changed my hasty mind on that. What concerns me is that the user may, in some instances, not realize that the default active molecule is the one that optking is acting on and changing. But the upside convenience wins, I agree.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1260085584
https://github.com/psi4/psi4/pull/2727#issuecomment-1260085584:424,Usability,intuit,intuitive,424,"> > > An alternative question this raises for me is whether the active_molecule should get updated at some point in the optimization. Updating the active molecule patches the issue but is that desired?; > ; > > My vote would be ""no""; it's too much like changing the input. However, I do think that some users would expect the final active molecule to be updated for them. And workflows inside the python input may seem more intuitive that way.; > ; > I may not be following this right. I'd say the state of the psi4 active mol _during_ an optimization is arbitrary -- whatever works for you. In cpp-optking, I think the communication was through legacymolecule anyways. The molecule optking is acting on _should_ be updated by the time control returns to the user at the end of the opt. I thought this was already happening through https://github.com/psi4/psi4/pull/2727/files#diff-acf663ccea13592c4c656cf89c7b62e6f5bd3b2e8b4f12ba354129bd39d096f8R1296-R1297 . That's consistent with cpp-optking, and I think that must be happening b/c many of the tests check NRE before and after opt. OK, you changed my hasty mind on that. What concerns me is that the user may, in some instances, not realize that the default active molecule is the one that optking is acting on and changing. But the upside convenience wins, I agree.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1260085584
https://github.com/psi4/psi4/pull/2727#issuecomment-1261118004:7,Availability,ping,ping,7,Please ping me for review once Lori approves. She knows this part of the code better than I do.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1261118004
https://github.com/psi4/psi4/pull/2727#issuecomment-1262512828:126,Deployability,update,update,126,"In cases where reference values are not matched perfectly (but the test should pass) is it better to loosen the comparison or update the reference value. I assume updating the reference value is the way to go but I want to have some record of asking before I start slightly changing reference values. Secondarily, should the reference values be updated in general at some point so that users don't stumble across an instance where the value is slightly off and wonder why?. Explanation:; I've expanded the number of tests I'm running since I started cleaning up core.cc. In the opt specific tests the convergence is usually tight enough that the nuclear repulsion energies match the reference values just fine for both optimizers. There are some tests like cc1-3 that are failing due to being just above threshold. `atol = 0.001` the difference is `~ 0.0017`. These tests are using the default `qchem` convergence criteria ~ `3e-4` max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. Geometries are the same. There are around 5 or 6 tests failing like this.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262512828
https://github.com/psi4/psi4/pull/2727#issuecomment-1262512828:345,Deployability,update,updated,345,"In cases where reference values are not matched perfectly (but the test should pass) is it better to loosen the comparison or update the reference value. I assume updating the reference value is the way to go but I want to have some record of asking before I start slightly changing reference values. Secondarily, should the reference values be updated in general at some point so that users don't stumble across an instance where the value is slightly off and wonder why?. Explanation:; I've expanded the number of tests I'm running since I started cleaning up core.cc. In the opt specific tests the convergence is usually tight enough that the nuclear repulsion energies match the reference values just fine for both optimizers. There are some tests like cc1-3 that are failing due to being just above threshold. `atol = 0.001` the difference is `~ 0.0017`. These tests are using the default `qchem` convergence criteria ~ `3e-4` max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. Geometries are the same. There are around 5 or 6 tests failing like this.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262512828
https://github.com/psi4/psi4/pull/2727#issuecomment-1262512828:719,Performance,optimiz,optimizers,719,"In cases where reference values are not matched perfectly (but the test should pass) is it better to loosen the comparison or update the reference value. I assume updating the reference value is the way to go but I want to have some record of asking before I start slightly changing reference values. Secondarily, should the reference values be updated in general at some point so that users don't stumble across an instance where the value is slightly off and wonder why?. Explanation:; I've expanded the number of tests I'm running since I started cleaning up core.cc. In the opt specific tests the convergence is usually tight enough that the nuclear repulsion energies match the reference values just fine for both optimizers. There are some tests like cc1-3 that are failing due to being just above threshold. `atol = 0.001` the difference is `~ 0.0017`. These tests are using the default `qchem` convergence criteria ~ `3e-4` max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. Geometries are the same. There are around 5 or 6 tests failing like this.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262512828
https://github.com/psi4/psi4/pull/2727#issuecomment-1262512828:948,Performance,optimiz,optimizers,948,"In cases where reference values are not matched perfectly (but the test should pass) is it better to loosen the comparison or update the reference value. I assume updating the reference value is the way to go but I want to have some record of asking before I start slightly changing reference values. Secondarily, should the reference values be updated in general at some point so that users don't stumble across an instance where the value is slightly off and wonder why?. Explanation:; I've expanded the number of tests I'm running since I started cleaning up core.cc. In the opt specific tests the convergence is usually tight enough that the nuclear repulsion energies match the reference values just fine for both optimizers. There are some tests like cc1-3 that are failing due to being just above threshold. `atol = 0.001` the difference is `~ 0.0017`. These tests are using the default `qchem` convergence criteria ~ `3e-4` max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. Geometries are the same. There are around 5 or 6 tests failing like this.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262512828
https://github.com/psi4/psi4/pull/2727#issuecomment-1262512828:67,Testability,test,test,67,"In cases where reference values are not matched perfectly (but the test should pass) is it better to loosen the comparison or update the reference value. I assume updating the reference value is the way to go but I want to have some record of asking before I start slightly changing reference values. Secondarily, should the reference values be updated in general at some point so that users don't stumble across an instance where the value is slightly off and wonder why?. Explanation:; I've expanded the number of tests I'm running since I started cleaning up core.cc. In the opt specific tests the convergence is usually tight enough that the nuclear repulsion energies match the reference values just fine for both optimizers. There are some tests like cc1-3 that are failing due to being just above threshold. `atol = 0.001` the difference is `~ 0.0017`. These tests are using the default `qchem` convergence criteria ~ `3e-4` max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. Geometries are the same. There are around 5 or 6 tests failing like this.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262512828
https://github.com/psi4/psi4/pull/2727#issuecomment-1262512828:516,Testability,test,tests,516,"In cases where reference values are not matched perfectly (but the test should pass) is it better to loosen the comparison or update the reference value. I assume updating the reference value is the way to go but I want to have some record of asking before I start slightly changing reference values. Secondarily, should the reference values be updated in general at some point so that users don't stumble across an instance where the value is slightly off and wonder why?. Explanation:; I've expanded the number of tests I'm running since I started cleaning up core.cc. In the opt specific tests the convergence is usually tight enough that the nuclear repulsion energies match the reference values just fine for both optimizers. There are some tests like cc1-3 that are failing due to being just above threshold. `atol = 0.001` the difference is `~ 0.0017`. These tests are using the default `qchem` convergence criteria ~ `3e-4` max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. Geometries are the same. There are around 5 or 6 tests failing like this.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262512828
https://github.com/psi4/psi4/pull/2727#issuecomment-1262512828:591,Testability,test,tests,591,"In cases where reference values are not matched perfectly (but the test should pass) is it better to loosen the comparison or update the reference value. I assume updating the reference value is the way to go but I want to have some record of asking before I start slightly changing reference values. Secondarily, should the reference values be updated in general at some point so that users don't stumble across an instance where the value is slightly off and wonder why?. Explanation:; I've expanded the number of tests I'm running since I started cleaning up core.cc. In the opt specific tests the convergence is usually tight enough that the nuclear repulsion energies match the reference values just fine for both optimizers. There are some tests like cc1-3 that are failing due to being just above threshold. `atol = 0.001` the difference is `~ 0.0017`. These tests are using the default `qchem` convergence criteria ~ `3e-4` max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. Geometries are the same. There are around 5 or 6 tests failing like this.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262512828
https://github.com/psi4/psi4/pull/2727#issuecomment-1262512828:746,Testability,test,tests,746,"In cases where reference values are not matched perfectly (but the test should pass) is it better to loosen the comparison or update the reference value. I assume updating the reference value is the way to go but I want to have some record of asking before I start slightly changing reference values. Secondarily, should the reference values be updated in general at some point so that users don't stumble across an instance where the value is slightly off and wonder why?. Explanation:; I've expanded the number of tests I'm running since I started cleaning up core.cc. In the opt specific tests the convergence is usually tight enough that the nuclear repulsion energies match the reference values just fine for both optimizers. There are some tests like cc1-3 that are failing due to being just above threshold. `atol = 0.001` the difference is `~ 0.0017`. These tests are using the default `qchem` convergence criteria ~ `3e-4` max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. Geometries are the same. There are around 5 or 6 tests failing like this.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262512828
https://github.com/psi4/psi4/pull/2727#issuecomment-1262512828:866,Testability,test,tests,866,"In cases where reference values are not matched perfectly (but the test should pass) is it better to loosen the comparison or update the reference value. I assume updating the reference value is the way to go but I want to have some record of asking before I start slightly changing reference values. Secondarily, should the reference values be updated in general at some point so that users don't stumble across an instance where the value is slightly off and wonder why?. Explanation:; I've expanded the number of tests I'm running since I started cleaning up core.cc. In the opt specific tests the convergence is usually tight enough that the nuclear repulsion energies match the reference values just fine for both optimizers. There are some tests like cc1-3 that are failing due to being just above threshold. `atol = 0.001` the difference is `~ 0.0017`. These tests are using the default `qchem` convergence criteria ~ `3e-4` max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. Geometries are the same. There are around 5 or 6 tests failing like this.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262512828
https://github.com/psi4/psi4/pull/2727#issuecomment-1262512828:1097,Testability,test,tests,1097,"In cases where reference values are not matched perfectly (but the test should pass) is it better to loosen the comparison or update the reference value. I assume updating the reference value is the way to go but I want to have some record of asking before I start slightly changing reference values. Secondarily, should the reference values be updated in general at some point so that users don't stumble across an instance where the value is slightly off and wonder why?. Explanation:; I've expanded the number of tests I'm running since I started cleaning up core.cc. In the opt specific tests the convergence is usually tight enough that the nuclear repulsion energies match the reference values just fine for both optimizers. There are some tests like cc1-3 that are failing due to being just above threshold. `atol = 0.001` the difference is `~ 0.0017`. These tests are using the default `qchem` convergence criteria ~ `3e-4` max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. Geometries are the same. There are around 5 or 6 tests failing like this.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262512828
https://github.com/psi4/psi4/pull/2727#issuecomment-1262515081:36,Deployability,update,updated,36,"Would y'all like this PR to include updated output.ref files for the tests or would a separate test updating PR be better? I don't see anything in the"" adding tests documentation"" about reference log files. I can include those as well if desired. It will just greatly increase the number of lines changed in this PR.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262515081
https://github.com/psi4/psi4/pull/2727#issuecomment-1262515081:69,Testability,test,tests,69,"Would y'all like this PR to include updated output.ref files for the tests or would a separate test updating PR be better? I don't see anything in the"" adding tests documentation"" about reference log files. I can include those as well if desired. It will just greatly increase the number of lines changed in this PR.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262515081
https://github.com/psi4/psi4/pull/2727#issuecomment-1262515081:95,Testability,test,test,95,"Would y'all like this PR to include updated output.ref files for the tests or would a separate test updating PR be better? I don't see anything in the"" adding tests documentation"" about reference log files. I can include those as well if desired. It will just greatly increase the number of lines changed in this PR.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262515081
https://github.com/psi4/psi4/pull/2727#issuecomment-1262515081:159,Testability,test,tests,159,"Would y'all like this PR to include updated output.ref files for the tests or would a separate test updating PR be better? I don't see anything in the"" adding tests documentation"" about reference log files. I can include those as well if desired. It will just greatly increase the number of lines changed in this PR.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262515081
https://github.com/psi4/psi4/pull/2727#issuecomment-1262515081:196,Testability,log,log,196,"Would y'all like this PR to include updated output.ref files for the tests or would a separate test updating PR be better? I don't see anything in the"" adding tests documentation"" about reference log files. I can include those as well if desired. It will just greatly increase the number of lines changed in this PR.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262515081
https://github.com/psi4/psi4/pull/2727#issuecomment-1262531318:38,Deployability,update,updated,38,"> Would y'all like this PR to include updated output.ref files for the tests or would a separate test updating PR be better? I don't see anything in the"" adding tests documentation"" about reference log files. I can include those as well if desired. It will just greatly increase the number of lines changed in this PR. Please update `.ref` files. Probably not worth adding `.log` files, but that's a @loriab question. > There are some tests like cc1-3 that are failing due to being just above threshold. `atol = 0.001` the difference is `~ 0.0017`. These tests are using the default `qchem` convergence criteria ~ `3e-4` max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. . Could you elaborate on why tests are failing at all, and what numbers are differing? Are these Cartesian coordinates?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262531318
https://github.com/psi4/psi4/pull/2727#issuecomment-1262531318:326,Deployability,update,update,326,"> Would y'all like this PR to include updated output.ref files for the tests or would a separate test updating PR be better? I don't see anything in the"" adding tests documentation"" about reference log files. I can include those as well if desired. It will just greatly increase the number of lines changed in this PR. Please update `.ref` files. Probably not worth adding `.log` files, but that's a @loriab question. > There are some tests like cc1-3 that are failing due to being just above threshold. `atol = 0.001` the difference is `~ 0.0017`. These tests are using the default `qchem` convergence criteria ~ `3e-4` max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. . Could you elaborate on why tests are failing at all, and what numbers are differing? Are these Cartesian coordinates?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262531318
https://github.com/psi4/psi4/pull/2727#issuecomment-1262531318:637,Performance,optimiz,optimizers,637,"> Would y'all like this PR to include updated output.ref files for the tests or would a separate test updating PR be better? I don't see anything in the"" adding tests documentation"" about reference log files. I can include those as well if desired. It will just greatly increase the number of lines changed in this PR. Please update `.ref` files. Probably not worth adding `.log` files, but that's a @loriab question. > There are some tests like cc1-3 that are failing due to being just above threshold. `atol = 0.001` the difference is `~ 0.0017`. These tests are using the default `qchem` convergence criteria ~ `3e-4` max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. . Could you elaborate on why tests are failing at all, and what numbers are differing? Are these Cartesian coordinates?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262531318
https://github.com/psi4/psi4/pull/2727#issuecomment-1262531318:71,Testability,test,tests,71,"> Would y'all like this PR to include updated output.ref files for the tests or would a separate test updating PR be better? I don't see anything in the"" adding tests documentation"" about reference log files. I can include those as well if desired. It will just greatly increase the number of lines changed in this PR. Please update `.ref` files. Probably not worth adding `.log` files, but that's a @loriab question. > There are some tests like cc1-3 that are failing due to being just above threshold. `atol = 0.001` the difference is `~ 0.0017`. These tests are using the default `qchem` convergence criteria ~ `3e-4` max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. . Could you elaborate on why tests are failing at all, and what numbers are differing? Are these Cartesian coordinates?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262531318
https://github.com/psi4/psi4/pull/2727#issuecomment-1262531318:97,Testability,test,test,97,"> Would y'all like this PR to include updated output.ref files for the tests or would a separate test updating PR be better? I don't see anything in the"" adding tests documentation"" about reference log files. I can include those as well if desired. It will just greatly increase the number of lines changed in this PR. Please update `.ref` files. Probably not worth adding `.log` files, but that's a @loriab question. > There are some tests like cc1-3 that are failing due to being just above threshold. `atol = 0.001` the difference is `~ 0.0017`. These tests are using the default `qchem` convergence criteria ~ `3e-4` max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. . Could you elaborate on why tests are failing at all, and what numbers are differing? Are these Cartesian coordinates?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262531318
https://github.com/psi4/psi4/pull/2727#issuecomment-1262531318:161,Testability,test,tests,161,"> Would y'all like this PR to include updated output.ref files for the tests or would a separate test updating PR be better? I don't see anything in the"" adding tests documentation"" about reference log files. I can include those as well if desired. It will just greatly increase the number of lines changed in this PR. Please update `.ref` files. Probably not worth adding `.log` files, but that's a @loriab question. > There are some tests like cc1-3 that are failing due to being just above threshold. `atol = 0.001` the difference is `~ 0.0017`. These tests are using the default `qchem` convergence criteria ~ `3e-4` max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. . Could you elaborate on why tests are failing at all, and what numbers are differing? Are these Cartesian coordinates?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262531318
https://github.com/psi4/psi4/pull/2727#issuecomment-1262531318:198,Testability,log,log,198,"> Would y'all like this PR to include updated output.ref files for the tests or would a separate test updating PR be better? I don't see anything in the"" adding tests documentation"" about reference log files. I can include those as well if desired. It will just greatly increase the number of lines changed in this PR. Please update `.ref` files. Probably not worth adding `.log` files, but that's a @loriab question. > There are some tests like cc1-3 that are failing due to being just above threshold. `atol = 0.001` the difference is `~ 0.0017`. These tests are using the default `qchem` convergence criteria ~ `3e-4` max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. . Could you elaborate on why tests are failing at all, and what numbers are differing? Are these Cartesian coordinates?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262531318
https://github.com/psi4/psi4/pull/2727#issuecomment-1262531318:375,Testability,log,log,375,"> Would y'all like this PR to include updated output.ref files for the tests or would a separate test updating PR be better? I don't see anything in the"" adding tests documentation"" about reference log files. I can include those as well if desired. It will just greatly increase the number of lines changed in this PR. Please update `.ref` files. Probably not worth adding `.log` files, but that's a @loriab question. > There are some tests like cc1-3 that are failing due to being just above threshold. `atol = 0.001` the difference is `~ 0.0017`. These tests are using the default `qchem` convergence criteria ~ `3e-4` max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. . Could you elaborate on why tests are failing at all, and what numbers are differing? Are these Cartesian coordinates?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262531318
https://github.com/psi4/psi4/pull/2727#issuecomment-1262531318:435,Testability,test,tests,435,"> Would y'all like this PR to include updated output.ref files for the tests or would a separate test updating PR be better? I don't see anything in the"" adding tests documentation"" about reference log files. I can include those as well if desired. It will just greatly increase the number of lines changed in this PR. Please update `.ref` files. Probably not worth adding `.log` files, but that's a @loriab question. > There are some tests like cc1-3 that are failing due to being just above threshold. `atol = 0.001` the difference is `~ 0.0017`. These tests are using the default `qchem` convergence criteria ~ `3e-4` max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. . Could you elaborate on why tests are failing at all, and what numbers are differing? Are these Cartesian coordinates?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262531318
https://github.com/psi4/psi4/pull/2727#issuecomment-1262531318:555,Testability,test,tests,555,"> Would y'all like this PR to include updated output.ref files for the tests or would a separate test updating PR be better? I don't see anything in the"" adding tests documentation"" about reference log files. I can include those as well if desired. It will just greatly increase the number of lines changed in this PR. Please update `.ref` files. Probably not worth adding `.log` files, but that's a @loriab question. > There are some tests like cc1-3 that are failing due to being just above threshold. `atol = 0.001` the difference is `~ 0.0017`. These tests are using the default `qchem` convergence criteria ~ `3e-4` max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. . Could you elaborate on why tests are failing at all, and what numbers are differing? Are these Cartesian coordinates?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262531318
https://github.com/psi4/psi4/pull/2727#issuecomment-1262531318:766,Testability,test,tests,766,"> Would y'all like this PR to include updated output.ref files for the tests or would a separate test updating PR be better? I don't see anything in the"" adding tests documentation"" about reference log files. I can include those as well if desired. It will just greatly increase the number of lines changed in this PR. Please update `.ref` files. Probably not worth adding `.log` files, but that's a @loriab question. > There are some tests like cc1-3 that are failing due to being just above threshold. `atol = 0.001` the difference is `~ 0.0017`. These tests are using the default `qchem` convergence criteria ~ `3e-4` max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. . Could you elaborate on why tests are failing at all, and what numbers are differing? Are these Cartesian coordinates?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262531318
https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464:128,Deployability,update,update,128,"> In cases where reference values are not matched perfectly (but the test should pass) is it better to loosen the comparison or update the reference value. I assume updating the reference value is the way to go but I want to have some record of asking before I start slightly changing reference values. > Secondarily, should the reference values be updated in general at some point so that users don't stumble across an instance where the value is slightly off and wonder why?. General guidance to for ref values to be from a tightly converged/optimized calc, then loosen the comparison check to accommodate the default/existing conv crit (https://psicode.org/psi4manual/master/add_tests.html#test-contents). Tests checking opt status at a certain cycle exempt of course. That's the principle, but do feel free to change as you see fit --- the reference values (agreed, preferred thing to change if the ref is the culprit) or the comparison crit (if it's the optimizer behavior that's the instigator). > Explanation:; I've expanded the number of tests I'm running since I started cleaning up core.cc. In the opt specific tests the convergence is usually tight enough that the nuclear repulsion energies match the reference values just fine for both optimizers. There are some tests like cc1-3 that are failing due to being just above threshold. atol = 0.001 the difference is ~ 0.0017. These tests are using the default qchem convergence criteria ~ 3e-4 max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. Geometries are the same. There are around 5 or 6 tests failing like this. Thanks for the explanation. I'd view reference NRE values as less venerable. For one thing, only those that caused trouble were even updated when physical constants changed, iirc. > Would y'all like this PR to include updated output.ref files for the tests or would a separate test updating PR be better? I don't see anything in the"" adding tests documentat",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464
https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464:349,Deployability,update,updated,349,"> In cases where reference values are not matched perfectly (but the test should pass) is it better to loosen the comparison or update the reference value. I assume updating the reference value is the way to go but I want to have some record of asking before I start slightly changing reference values. > Secondarily, should the reference values be updated in general at some point so that users don't stumble across an instance where the value is slightly off and wonder why?. General guidance to for ref values to be from a tightly converged/optimized calc, then loosen the comparison check to accommodate the default/existing conv crit (https://psicode.org/psi4manual/master/add_tests.html#test-contents). Tests checking opt status at a certain cycle exempt of course. That's the principle, but do feel free to change as you see fit --- the reference values (agreed, preferred thing to change if the ref is the culprit) or the comparison crit (if it's the optimizer behavior that's the instigator). > Explanation:; I've expanded the number of tests I'm running since I started cleaning up core.cc. In the opt specific tests the convergence is usually tight enough that the nuclear repulsion energies match the reference values just fine for both optimizers. There are some tests like cc1-3 that are failing due to being just above threshold. atol = 0.001 the difference is ~ 0.0017. These tests are using the default qchem convergence criteria ~ 3e-4 max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. Geometries are the same. There are around 5 or 6 tests failing like this. Thanks for the explanation. I'd view reference NRE values as less venerable. For one thing, only those that caused trouble were even updated when physical constants changed, iirc. > Would y'all like this PR to include updated output.ref files for the tests or would a separate test updating PR be better? I don't see anything in the"" adding tests documentat",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464
https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464:1777,Deployability,update,updated,1777,"n check to accommodate the default/existing conv crit (https://psicode.org/psi4manual/master/add_tests.html#test-contents). Tests checking opt status at a certain cycle exempt of course. That's the principle, but do feel free to change as you see fit --- the reference values (agreed, preferred thing to change if the ref is the culprit) or the comparison crit (if it's the optimizer behavior that's the instigator). > Explanation:; I've expanded the number of tests I'm running since I started cleaning up core.cc. In the opt specific tests the convergence is usually tight enough that the nuclear repulsion energies match the reference values just fine for both optimizers. There are some tests like cc1-3 that are failing due to being just above threshold. atol = 0.001 the difference is ~ 0.0017. These tests are using the default qchem convergence criteria ~ 3e-4 max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. Geometries are the same. There are around 5 or 6 tests failing like this. Thanks for the explanation. I'd view reference NRE values as less venerable. For one thing, only those that caused trouble were even updated when physical constants changed, iirc. > Would y'all like this PR to include updated output.ref files for the tests or would a separate test updating PR be better? I don't see anything in the"" adding tests documentation"" about reference log files. I can include those as well if desired. It will just greatly increase the number of lines changed in this PR. Separate, please. Like updating `samples/`, better to keep the not-for-visual-inspection changes aside. Update: I see Jonathon thinks differently. Including is ok with me, now that GH allows files to be folded up rather than scrolled through. Is `.log` where all the optking detailed output goes now? I guess we ought to start collecting them. `output.log`, perhaps. But this can also be deferred to a grand regenerate-the-refs script and PR.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464
https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464:1862,Deployability,update,updated,1862,"n check to accommodate the default/existing conv crit (https://psicode.org/psi4manual/master/add_tests.html#test-contents). Tests checking opt status at a certain cycle exempt of course. That's the principle, but do feel free to change as you see fit --- the reference values (agreed, preferred thing to change if the ref is the culprit) or the comparison crit (if it's the optimizer behavior that's the instigator). > Explanation:; I've expanded the number of tests I'm running since I started cleaning up core.cc. In the opt specific tests the convergence is usually tight enough that the nuclear repulsion energies match the reference values just fine for both optimizers. There are some tests like cc1-3 that are failing due to being just above threshold. atol = 0.001 the difference is ~ 0.0017. These tests are using the default qchem convergence criteria ~ 3e-4 max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. Geometries are the same. There are around 5 or 6 tests failing like this. Thanks for the explanation. I'd view reference NRE values as less venerable. For one thing, only those that caused trouble were even updated when physical constants changed, iirc. > Would y'all like this PR to include updated output.ref files for the tests or would a separate test updating PR be better? I don't see anything in the"" adding tests documentation"" about reference log files. I can include those as well if desired. It will just greatly increase the number of lines changed in this PR. Separate, please. Like updating `samples/`, better to keep the not-for-visual-inspection changes aside. Update: I see Jonathon thinks differently. Including is ok with me, now that GH allows files to be folded up rather than scrolled through. Is `.log` where all the optking detailed output goes now? I guess we ought to start collecting them. `output.log`, perhaps. But this can also be deferred to a grand regenerate-the-refs script and PR.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464
https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464:2247,Deployability,Update,Update,2247,"n check to accommodate the default/existing conv crit (https://psicode.org/psi4manual/master/add_tests.html#test-contents). Tests checking opt status at a certain cycle exempt of course. That's the principle, but do feel free to change as you see fit --- the reference values (agreed, preferred thing to change if the ref is the culprit) or the comparison crit (if it's the optimizer behavior that's the instigator). > Explanation:; I've expanded the number of tests I'm running since I started cleaning up core.cc. In the opt specific tests the convergence is usually tight enough that the nuclear repulsion energies match the reference values just fine for both optimizers. There are some tests like cc1-3 that are failing due to being just above threshold. atol = 0.001 the difference is ~ 0.0017. These tests are using the default qchem convergence criteria ~ 3e-4 max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. Geometries are the same. There are around 5 or 6 tests failing like this. Thanks for the explanation. I'd view reference NRE values as less venerable. For one thing, only those that caused trouble were even updated when physical constants changed, iirc. > Would y'all like this PR to include updated output.ref files for the tests or would a separate test updating PR be better? I don't see anything in the"" adding tests documentation"" about reference log files. I can include those as well if desired. It will just greatly increase the number of lines changed in this PR. Separate, please. Like updating `samples/`, better to keep the not-for-visual-inspection changes aside. Update: I see Jonathon thinks differently. Including is ok with me, now that GH allows files to be folded up rather than scrolled through. Is `.log` where all the optking detailed output goes now? I guess we ought to start collecting them. `output.log`, perhaps. But this can also be deferred to a grand regenerate-the-refs script and PR.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464
https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464:544,Performance,optimiz,optimized,544,"> In cases where reference values are not matched perfectly (but the test should pass) is it better to loosen the comparison or update the reference value. I assume updating the reference value is the way to go but I want to have some record of asking before I start slightly changing reference values. > Secondarily, should the reference values be updated in general at some point so that users don't stumble across an instance where the value is slightly off and wonder why?. General guidance to for ref values to be from a tightly converged/optimized calc, then loosen the comparison check to accommodate the default/existing conv crit (https://psicode.org/psi4manual/master/add_tests.html#test-contents). Tests checking opt status at a certain cycle exempt of course. That's the principle, but do feel free to change as you see fit --- the reference values (agreed, preferred thing to change if the ref is the culprit) or the comparison crit (if it's the optimizer behavior that's the instigator). > Explanation:; I've expanded the number of tests I'm running since I started cleaning up core.cc. In the opt specific tests the convergence is usually tight enough that the nuclear repulsion energies match the reference values just fine for both optimizers. There are some tests like cc1-3 that are failing due to being just above threshold. atol = 0.001 the difference is ~ 0.0017. These tests are using the default qchem convergence criteria ~ 3e-4 max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. Geometries are the same. There are around 5 or 6 tests failing like this. Thanks for the explanation. I'd view reference NRE values as less venerable. For one thing, only those that caused trouble were even updated when physical constants changed, iirc. > Would y'all like this PR to include updated output.ref files for the tests or would a separate test updating PR be better? I don't see anything in the"" adding tests documentat",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464
https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464:959,Performance,optimiz,optimizer,959,"> In cases where reference values are not matched perfectly (but the test should pass) is it better to loosen the comparison or update the reference value. I assume updating the reference value is the way to go but I want to have some record of asking before I start slightly changing reference values. > Secondarily, should the reference values be updated in general at some point so that users don't stumble across an instance where the value is slightly off and wonder why?. General guidance to for ref values to be from a tightly converged/optimized calc, then loosen the comparison check to accommodate the default/existing conv crit (https://psicode.org/psi4manual/master/add_tests.html#test-contents). Tests checking opt status at a certain cycle exempt of course. That's the principle, but do feel free to change as you see fit --- the reference values (agreed, preferred thing to change if the ref is the culprit) or the comparison crit (if it's the optimizer behavior that's the instigator). > Explanation:; I've expanded the number of tests I'm running since I started cleaning up core.cc. In the opt specific tests the convergence is usually tight enough that the nuclear repulsion energies match the reference values just fine for both optimizers. There are some tests like cc1-3 that are failing due to being just above threshold. atol = 0.001 the difference is ~ 0.0017. These tests are using the default qchem convergence criteria ~ 3e-4 max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. Geometries are the same. There are around 5 or 6 tests failing like this. Thanks for the explanation. I'd view reference NRE values as less venerable. For one thing, only those that caused trouble were even updated when physical constants changed, iirc. > Would y'all like this PR to include updated output.ref files for the tests or would a separate test updating PR be better? I don't see anything in the"" adding tests documentat",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464
https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464:1249,Performance,optimiz,optimizers,1249,"ference value is the way to go but I want to have some record of asking before I start slightly changing reference values. > Secondarily, should the reference values be updated in general at some point so that users don't stumble across an instance where the value is slightly off and wonder why?. General guidance to for ref values to be from a tightly converged/optimized calc, then loosen the comparison check to accommodate the default/existing conv crit (https://psicode.org/psi4manual/master/add_tests.html#test-contents). Tests checking opt status at a certain cycle exempt of course. That's the principle, but do feel free to change as you see fit --- the reference values (agreed, preferred thing to change if the ref is the culprit) or the comparison crit (if it's the optimizer behavior that's the instigator). > Explanation:; I've expanded the number of tests I'm running since I started cleaning up core.cc. In the opt specific tests the convergence is usually tight enough that the nuclear repulsion energies match the reference values just fine for both optimizers. There are some tests like cc1-3 that are failing due to being just above threshold. atol = 0.001 the difference is ~ 0.0017. These tests are using the default qchem convergence criteria ~ 3e-4 max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. Geometries are the same. There are around 5 or 6 tests failing like this. Thanks for the explanation. I'd view reference NRE values as less venerable. For one thing, only those that caused trouble were even updated when physical constants changed, iirc. > Would y'all like this PR to include updated output.ref files for the tests or would a separate test updating PR be better? I don't see anything in the"" adding tests documentation"" about reference log files. I can include those as well if desired. It will just greatly increase the number of lines changed in this PR. Separate, please. Like updating `samp",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464
https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464:1470,Performance,optimiz,optimizers,1470,"es to be from a tightly converged/optimized calc, then loosen the comparison check to accommodate the default/existing conv crit (https://psicode.org/psi4manual/master/add_tests.html#test-contents). Tests checking opt status at a certain cycle exempt of course. That's the principle, but do feel free to change as you see fit --- the reference values (agreed, preferred thing to change if the ref is the culprit) or the comparison crit (if it's the optimizer behavior that's the instigator). > Explanation:; I've expanded the number of tests I'm running since I started cleaning up core.cc. In the opt specific tests the convergence is usually tight enough that the nuclear repulsion energies match the reference values just fine for both optimizers. There are some tests like cc1-3 that are failing due to being just above threshold. atol = 0.001 the difference is ~ 0.0017. These tests are using the default qchem convergence criteria ~ 3e-4 max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. Geometries are the same. There are around 5 or 6 tests failing like this. Thanks for the explanation. I'd view reference NRE values as less venerable. For one thing, only those that caused trouble were even updated when physical constants changed, iirc. > Would y'all like this PR to include updated output.ref files for the tests or would a separate test updating PR be better? I don't see anything in the"" adding tests documentation"" about reference log files. I can include those as well if desired. It will just greatly increase the number of lines changed in this PR. Separate, please. Like updating `samples/`, better to keep the not-for-visual-inspection changes aside. Update: I see Jonathon thinks differently. Including is ok with me, now that GH allows files to be folded up rather than scrolled through. Is `.log` where all the optking detailed output goes now? I guess we ought to start collecting them. `output.log`, perhaps. B",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464
https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464:69,Testability,test,test,69,"> In cases where reference values are not matched perfectly (but the test should pass) is it better to loosen the comparison or update the reference value. I assume updating the reference value is the way to go but I want to have some record of asking before I start slightly changing reference values. > Secondarily, should the reference values be updated in general at some point so that users don't stumble across an instance where the value is slightly off and wonder why?. General guidance to for ref values to be from a tightly converged/optimized calc, then loosen the comparison check to accommodate the default/existing conv crit (https://psicode.org/psi4manual/master/add_tests.html#test-contents). Tests checking opt status at a certain cycle exempt of course. That's the principle, but do feel free to change as you see fit --- the reference values (agreed, preferred thing to change if the ref is the culprit) or the comparison crit (if it's the optimizer behavior that's the instigator). > Explanation:; I've expanded the number of tests I'm running since I started cleaning up core.cc. In the opt specific tests the convergence is usually tight enough that the nuclear repulsion energies match the reference values just fine for both optimizers. There are some tests like cc1-3 that are failing due to being just above threshold. atol = 0.001 the difference is ~ 0.0017. These tests are using the default qchem convergence criteria ~ 3e-4 max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. Geometries are the same. There are around 5 or 6 tests failing like this. Thanks for the explanation. I'd view reference NRE values as less venerable. For one thing, only those that caused trouble were even updated when physical constants changed, iirc. > Would y'all like this PR to include updated output.ref files for the tests or would a separate test updating PR be better? I don't see anything in the"" adding tests documentat",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464
https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464:693,Testability,test,test-contents,693,"> In cases where reference values are not matched perfectly (but the test should pass) is it better to loosen the comparison or update the reference value. I assume updating the reference value is the way to go but I want to have some record of asking before I start slightly changing reference values. > Secondarily, should the reference values be updated in general at some point so that users don't stumble across an instance where the value is slightly off and wonder why?. General guidance to for ref values to be from a tightly converged/optimized calc, then loosen the comparison check to accommodate the default/existing conv crit (https://psicode.org/psi4manual/master/add_tests.html#test-contents). Tests checking opt status at a certain cycle exempt of course. That's the principle, but do feel free to change as you see fit --- the reference values (agreed, preferred thing to change if the ref is the culprit) or the comparison crit (if it's the optimizer behavior that's the instigator). > Explanation:; I've expanded the number of tests I'm running since I started cleaning up core.cc. In the opt specific tests the convergence is usually tight enough that the nuclear repulsion energies match the reference values just fine for both optimizers. There are some tests like cc1-3 that are failing due to being just above threshold. atol = 0.001 the difference is ~ 0.0017. These tests are using the default qchem convergence criteria ~ 3e-4 max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. Geometries are the same. There are around 5 or 6 tests failing like this. Thanks for the explanation. I'd view reference NRE values as less venerable. For one thing, only those that caused trouble were even updated when physical constants changed, iirc. > Would y'all like this PR to include updated output.ref files for the tests or would a separate test updating PR be better? I don't see anything in the"" adding tests documentat",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464
https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464:709,Testability,Test,Tests,709,"> In cases where reference values are not matched perfectly (but the test should pass) is it better to loosen the comparison or update the reference value. I assume updating the reference value is the way to go but I want to have some record of asking before I start slightly changing reference values. > Secondarily, should the reference values be updated in general at some point so that users don't stumble across an instance where the value is slightly off and wonder why?. General guidance to for ref values to be from a tightly converged/optimized calc, then loosen the comparison check to accommodate the default/existing conv crit (https://psicode.org/psi4manual/master/add_tests.html#test-contents). Tests checking opt status at a certain cycle exempt of course. That's the principle, but do feel free to change as you see fit --- the reference values (agreed, preferred thing to change if the ref is the culprit) or the comparison crit (if it's the optimizer behavior that's the instigator). > Explanation:; I've expanded the number of tests I'm running since I started cleaning up core.cc. In the opt specific tests the convergence is usually tight enough that the nuclear repulsion energies match the reference values just fine for both optimizers. There are some tests like cc1-3 that are failing due to being just above threshold. atol = 0.001 the difference is ~ 0.0017. These tests are using the default qchem convergence criteria ~ 3e-4 max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. Geometries are the same. There are around 5 or 6 tests failing like this. Thanks for the explanation. I'd view reference NRE values as less venerable. For one thing, only those that caused trouble were even updated when physical constants changed, iirc. > Would y'all like this PR to include updated output.ref files for the tests or would a separate test updating PR be better? I don't see anything in the"" adding tests documentat",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464
https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464:1046,Testability,test,tests,1046," perfectly (but the test should pass) is it better to loosen the comparison or update the reference value. I assume updating the reference value is the way to go but I want to have some record of asking before I start slightly changing reference values. > Secondarily, should the reference values be updated in general at some point so that users don't stumble across an instance where the value is slightly off and wonder why?. General guidance to for ref values to be from a tightly converged/optimized calc, then loosen the comparison check to accommodate the default/existing conv crit (https://psicode.org/psi4manual/master/add_tests.html#test-contents). Tests checking opt status at a certain cycle exempt of course. That's the principle, but do feel free to change as you see fit --- the reference values (agreed, preferred thing to change if the ref is the culprit) or the comparison crit (if it's the optimizer behavior that's the instigator). > Explanation:; I've expanded the number of tests I'm running since I started cleaning up core.cc. In the opt specific tests the convergence is usually tight enough that the nuclear repulsion energies match the reference values just fine for both optimizers. There are some tests like cc1-3 that are failing due to being just above threshold. atol = 0.001 the difference is ~ 0.0017. These tests are using the default qchem convergence criteria ~ 3e-4 max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. Geometries are the same. There are around 5 or 6 tests failing like this. Thanks for the explanation. I'd view reference NRE values as less venerable. For one thing, only those that caused trouble were even updated when physical constants changed, iirc. > Would y'all like this PR to include updated output.ref files for the tests or would a separate test updating PR be better? I don't see anything in the"" adding tests documentation"" about reference log files. I can include th",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464
https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464:1121,Testability,test,tests,1121,"ference value is the way to go but I want to have some record of asking before I start slightly changing reference values. > Secondarily, should the reference values be updated in general at some point so that users don't stumble across an instance where the value is slightly off and wonder why?. General guidance to for ref values to be from a tightly converged/optimized calc, then loosen the comparison check to accommodate the default/existing conv crit (https://psicode.org/psi4manual/master/add_tests.html#test-contents). Tests checking opt status at a certain cycle exempt of course. That's the principle, but do feel free to change as you see fit --- the reference values (agreed, preferred thing to change if the ref is the culprit) or the comparison crit (if it's the optimizer behavior that's the instigator). > Explanation:; I've expanded the number of tests I'm running since I started cleaning up core.cc. In the opt specific tests the convergence is usually tight enough that the nuclear repulsion energies match the reference values just fine for both optimizers. There are some tests like cc1-3 that are failing due to being just above threshold. atol = 0.001 the difference is ~ 0.0017. These tests are using the default qchem convergence criteria ~ 3e-4 max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. Geometries are the same. There are around 5 or 6 tests failing like this. Thanks for the explanation. I'd view reference NRE values as less venerable. For one thing, only those that caused trouble were even updated when physical constants changed, iirc. > Would y'all like this PR to include updated output.ref files for the tests or would a separate test updating PR be better? I don't see anything in the"" adding tests documentation"" about reference log files. I can include those as well if desired. It will just greatly increase the number of lines changed in this PR. Separate, please. Like updating `samp",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464
https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464:1276,Testability,test,tests,1276," > Secondarily, should the reference values be updated in general at some point so that users don't stumble across an instance where the value is slightly off and wonder why?. General guidance to for ref values to be from a tightly converged/optimized calc, then loosen the comparison check to accommodate the default/existing conv crit (https://psicode.org/psi4manual/master/add_tests.html#test-contents). Tests checking opt status at a certain cycle exempt of course. That's the principle, but do feel free to change as you see fit --- the reference values (agreed, preferred thing to change if the ref is the culprit) or the comparison crit (if it's the optimizer behavior that's the instigator). > Explanation:; I've expanded the number of tests I'm running since I started cleaning up core.cc. In the opt specific tests the convergence is usually tight enough that the nuclear repulsion energies match the reference values just fine for both optimizers. There are some tests like cc1-3 that are failing due to being just above threshold. atol = 0.001 the difference is ~ 0.0017. These tests are using the default qchem convergence criteria ~ 3e-4 max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. Geometries are the same. There are around 5 or 6 tests failing like this. Thanks for the explanation. I'd view reference NRE values as less venerable. For one thing, only those that caused trouble were even updated when physical constants changed, iirc. > Would y'all like this PR to include updated output.ref files for the tests or would a separate test updating PR be better? I don't see anything in the"" adding tests documentation"" about reference log files. I can include those as well if desired. It will just greatly increase the number of lines changed in this PR. Separate, please. Like updating `samples/`, better to keep the not-for-visual-inspection changes aside. Update: I see Jonathon thinks differently. Including is",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464
https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464:1392,Testability,test,tests,1392,"ance where the value is slightly off and wonder why?. General guidance to for ref values to be from a tightly converged/optimized calc, then loosen the comparison check to accommodate the default/existing conv crit (https://psicode.org/psi4manual/master/add_tests.html#test-contents). Tests checking opt status at a certain cycle exempt of course. That's the principle, but do feel free to change as you see fit --- the reference values (agreed, preferred thing to change if the ref is the culprit) or the comparison crit (if it's the optimizer behavior that's the instigator). > Explanation:; I've expanded the number of tests I'm running since I started cleaning up core.cc. In the opt specific tests the convergence is usually tight enough that the nuclear repulsion energies match the reference values just fine for both optimizers. There are some tests like cc1-3 that are failing due to being just above threshold. atol = 0.001 the difference is ~ 0.0017. These tests are using the default qchem convergence criteria ~ 3e-4 max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. Geometries are the same. There are around 5 or 6 tests failing like this. Thanks for the explanation. I'd view reference NRE values as less venerable. For one thing, only those that caused trouble were even updated when physical constants changed, iirc. > Would y'all like this PR to include updated output.ref files for the tests or would a separate test updating PR be better? I don't see anything in the"" adding tests documentation"" about reference log files. I can include those as well if desired. It will just greatly increase the number of lines changed in this PR. Separate, please. Like updating `samples/`, better to keep the not-for-visual-inspection changes aside. Update: I see Jonathon thinks differently. Including is ok with me, now that GH allows files to be folded up rather than scrolled through. Is `.log` where all the optking detaile",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464
https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464:1619,Testability,test,tests,1619,"n check to accommodate the default/existing conv crit (https://psicode.org/psi4manual/master/add_tests.html#test-contents). Tests checking opt status at a certain cycle exempt of course. That's the principle, but do feel free to change as you see fit --- the reference values (agreed, preferred thing to change if the ref is the culprit) or the comparison crit (if it's the optimizer behavior that's the instigator). > Explanation:; I've expanded the number of tests I'm running since I started cleaning up core.cc. In the opt specific tests the convergence is usually tight enough that the nuclear repulsion energies match the reference values just fine for both optimizers. There are some tests like cc1-3 that are failing due to being just above threshold. atol = 0.001 the difference is ~ 0.0017. These tests are using the default qchem convergence criteria ~ 3e-4 max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. Geometries are the same. There are around 5 or 6 tests failing like this. Thanks for the explanation. I'd view reference NRE values as less venerable. For one thing, only those that caused trouble were even updated when physical constants changed, iirc. > Would y'all like this PR to include updated output.ref files for the tests or would a separate test updating PR be better? I don't see anything in the"" adding tests documentation"" about reference log files. I can include those as well if desired. It will just greatly increase the number of lines changed in this PR. Separate, please. Like updating `samples/`, better to keep the not-for-visual-inspection changes aside. Update: I see Jonathon thinks differently. Including is ok with me, now that GH allows files to be folded up rather than scrolled through. Is `.log` where all the optking detailed output goes now? I guess we ought to start collecting them. `output.log`, perhaps. But this can also be deferred to a grand regenerate-the-refs script and PR.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464
https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464:1895,Testability,test,tests,1895,"n check to accommodate the default/existing conv crit (https://psicode.org/psi4manual/master/add_tests.html#test-contents). Tests checking opt status at a certain cycle exempt of course. That's the principle, but do feel free to change as you see fit --- the reference values (agreed, preferred thing to change if the ref is the culprit) or the comparison crit (if it's the optimizer behavior that's the instigator). > Explanation:; I've expanded the number of tests I'm running since I started cleaning up core.cc. In the opt specific tests the convergence is usually tight enough that the nuclear repulsion energies match the reference values just fine for both optimizers. There are some tests like cc1-3 that are failing due to being just above threshold. atol = 0.001 the difference is ~ 0.0017. These tests are using the default qchem convergence criteria ~ 3e-4 max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. Geometries are the same. There are around 5 or 6 tests failing like this. Thanks for the explanation. I'd view reference NRE values as less venerable. For one thing, only those that caused trouble were even updated when physical constants changed, iirc. > Would y'all like this PR to include updated output.ref files for the tests or would a separate test updating PR be better? I don't see anything in the"" adding tests documentation"" about reference log files. I can include those as well if desired. It will just greatly increase the number of lines changed in this PR. Separate, please. Like updating `samples/`, better to keep the not-for-visual-inspection changes aside. Update: I see Jonathon thinks differently. Including is ok with me, now that GH allows files to be folded up rather than scrolled through. Is `.log` where all the optking detailed output goes now? I guess we ought to start collecting them. `output.log`, perhaps. But this can also be deferred to a grand regenerate-the-refs script and PR.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464
https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464:1921,Testability,test,test,1921,"n check to accommodate the default/existing conv crit (https://psicode.org/psi4manual/master/add_tests.html#test-contents). Tests checking opt status at a certain cycle exempt of course. That's the principle, but do feel free to change as you see fit --- the reference values (agreed, preferred thing to change if the ref is the culprit) or the comparison crit (if it's the optimizer behavior that's the instigator). > Explanation:; I've expanded the number of tests I'm running since I started cleaning up core.cc. In the opt specific tests the convergence is usually tight enough that the nuclear repulsion energies match the reference values just fine for both optimizers. There are some tests like cc1-3 that are failing due to being just above threshold. atol = 0.001 the difference is ~ 0.0017. These tests are using the default qchem convergence criteria ~ 3e-4 max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. Geometries are the same. There are around 5 or 6 tests failing like this. Thanks for the explanation. I'd view reference NRE values as less venerable. For one thing, only those that caused trouble were even updated when physical constants changed, iirc. > Would y'all like this PR to include updated output.ref files for the tests or would a separate test updating PR be better? I don't see anything in the"" adding tests documentation"" about reference log files. I can include those as well if desired. It will just greatly increase the number of lines changed in this PR. Separate, please. Like updating `samples/`, better to keep the not-for-visual-inspection changes aside. Update: I see Jonathon thinks differently. Including is ok with me, now that GH allows files to be folded up rather than scrolled through. Is `.log` where all the optking detailed output goes now? I guess we ought to start collecting them. `output.log`, perhaps. But this can also be deferred to a grand regenerate-the-refs script and PR.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464
https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464:1985,Testability,test,tests,1985,"n check to accommodate the default/existing conv crit (https://psicode.org/psi4manual/master/add_tests.html#test-contents). Tests checking opt status at a certain cycle exempt of course. That's the principle, but do feel free to change as you see fit --- the reference values (agreed, preferred thing to change if the ref is the culprit) or the comparison crit (if it's the optimizer behavior that's the instigator). > Explanation:; I've expanded the number of tests I'm running since I started cleaning up core.cc. In the opt specific tests the convergence is usually tight enough that the nuclear repulsion energies match the reference values just fine for both optimizers. There are some tests like cc1-3 that are failing due to being just above threshold. atol = 0.001 the difference is ~ 0.0017. These tests are using the default qchem convergence criteria ~ 3e-4 max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. Geometries are the same. There are around 5 or 6 tests failing like this. Thanks for the explanation. I'd view reference NRE values as less venerable. For one thing, only those that caused trouble were even updated when physical constants changed, iirc. > Would y'all like this PR to include updated output.ref files for the tests or would a separate test updating PR be better? I don't see anything in the"" adding tests documentation"" about reference log files. I can include those as well if desired. It will just greatly increase the number of lines changed in this PR. Separate, please. Like updating `samples/`, better to keep the not-for-visual-inspection changes aside. Update: I see Jonathon thinks differently. Including is ok with me, now that GH allows files to be folded up rather than scrolled through. Is `.log` where all the optking detailed output goes now? I guess we ought to start collecting them. `output.log`, perhaps. But this can also be deferred to a grand regenerate-the-refs script and PR.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464
https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464:2022,Testability,log,log,2022,"n check to accommodate the default/existing conv crit (https://psicode.org/psi4manual/master/add_tests.html#test-contents). Tests checking opt status at a certain cycle exempt of course. That's the principle, but do feel free to change as you see fit --- the reference values (agreed, preferred thing to change if the ref is the culprit) or the comparison crit (if it's the optimizer behavior that's the instigator). > Explanation:; I've expanded the number of tests I'm running since I started cleaning up core.cc. In the opt specific tests the convergence is usually tight enough that the nuclear repulsion energies match the reference values just fine for both optimizers. There are some tests like cc1-3 that are failing due to being just above threshold. atol = 0.001 the difference is ~ 0.0017. These tests are using the default qchem convergence criteria ~ 3e-4 max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. Geometries are the same. There are around 5 or 6 tests failing like this. Thanks for the explanation. I'd view reference NRE values as less venerable. For one thing, only those that caused trouble were even updated when physical constants changed, iirc. > Would y'all like this PR to include updated output.ref files for the tests or would a separate test updating PR be better? I don't see anything in the"" adding tests documentation"" about reference log files. I can include those as well if desired. It will just greatly increase the number of lines changed in this PR. Separate, please. Like updating `samples/`, better to keep the not-for-visual-inspection changes aside. Update: I see Jonathon thinks differently. Including is ok with me, now that GH allows files to be folded up rather than scrolled through. Is `.log` where all the optking detailed output goes now? I guess we ought to start collecting them. `output.log`, perhaps. But this can also be deferred to a grand regenerate-the-refs script and PR.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464
https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464:2391,Testability,log,log,2391,"n check to accommodate the default/existing conv crit (https://psicode.org/psi4manual/master/add_tests.html#test-contents). Tests checking opt status at a certain cycle exempt of course. That's the principle, but do feel free to change as you see fit --- the reference values (agreed, preferred thing to change if the ref is the culprit) or the comparison crit (if it's the optimizer behavior that's the instigator). > Explanation:; I've expanded the number of tests I'm running since I started cleaning up core.cc. In the opt specific tests the convergence is usually tight enough that the nuclear repulsion energies match the reference values just fine for both optimizers. There are some tests like cc1-3 that are failing due to being just above threshold. atol = 0.001 the difference is ~ 0.0017. These tests are using the default qchem convergence criteria ~ 3e-4 max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. Geometries are the same. There are around 5 or 6 tests failing like this. Thanks for the explanation. I'd view reference NRE values as less venerable. For one thing, only those that caused trouble were even updated when physical constants changed, iirc. > Would y'all like this PR to include updated output.ref files for the tests or would a separate test updating PR be better? I don't see anything in the"" adding tests documentation"" about reference log files. I can include those as well if desired. It will just greatly increase the number of lines changed in this PR. Separate, please. Like updating `samples/`, better to keep the not-for-visual-inspection changes aside. Update: I see Jonathon thinks differently. Including is ok with me, now that GH allows files to be folded up rather than scrolled through. Is `.log` where all the optking detailed output goes now? I guess we ought to start collecting them. `output.log`, perhaps. But this can also be deferred to a grand regenerate-the-refs script and PR.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464
https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464:2495,Testability,log,log,2495,"n check to accommodate the default/existing conv crit (https://psicode.org/psi4manual/master/add_tests.html#test-contents). Tests checking opt status at a certain cycle exempt of course. That's the principle, but do feel free to change as you see fit --- the reference values (agreed, preferred thing to change if the ref is the culprit) or the comparison crit (if it's the optimizer behavior that's the instigator). > Explanation:; I've expanded the number of tests I'm running since I started cleaning up core.cc. In the opt specific tests the convergence is usually tight enough that the nuclear repulsion energies match the reference values just fine for both optimizers. There are some tests like cc1-3 that are failing due to being just above threshold. atol = 0.001 the difference is ~ 0.0017. These tests are using the default qchem convergence criteria ~ 3e-4 max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. Geometries are the same. There are around 5 or 6 tests failing like this. Thanks for the explanation. I'd view reference NRE values as less venerable. For one thing, only those that caused trouble were even updated when physical constants changed, iirc. > Would y'all like this PR to include updated output.ref files for the tests or would a separate test updating PR be better? I don't see anything in the"" adding tests documentation"" about reference log files. I can include those as well if desired. It will just greatly increase the number of lines changed in this PR. Separate, please. Like updating `samples/`, better to keep the not-for-visual-inspection changes aside. Update: I see Jonathon thinks differently. Including is ok with me, now that GH allows files to be folded up rather than scrolled through. Is `.log` where all the optking detailed output goes now? I guess we ought to start collecting them. `output.log`, perhaps. But this can also be deferred to a grand regenerate-the-refs script and PR.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464
https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464:486,Usability,guid,guidance,486,"> In cases where reference values are not matched perfectly (but the test should pass) is it better to loosen the comparison or update the reference value. I assume updating the reference value is the way to go but I want to have some record of asking before I start slightly changing reference values. > Secondarily, should the reference values be updated in general at some point so that users don't stumble across an instance where the value is slightly off and wonder why?. General guidance to for ref values to be from a tightly converged/optimized calc, then loosen the comparison check to accommodate the default/existing conv crit (https://psicode.org/psi4manual/master/add_tests.html#test-contents). Tests checking opt status at a certain cycle exempt of course. That's the principle, but do feel free to change as you see fit --- the reference values (agreed, preferred thing to change if the ref is the culprit) or the comparison crit (if it's the optimizer behavior that's the instigator). > Explanation:; I've expanded the number of tests I'm running since I started cleaning up core.cc. In the opt specific tests the convergence is usually tight enough that the nuclear repulsion energies match the reference values just fine for both optimizers. There are some tests like cc1-3 that are failing due to being just above threshold. atol = 0.001 the difference is ~ 0.0017. These tests are using the default qchem convergence criteria ~ 3e-4 max_force. Both optimizers finish well below the criteria and geometries match to 1e-4 Angstroms and 0.001 degrees. Geometries are the same. There are around 5 or 6 tests failing like this. Thanks for the explanation. I'd view reference NRE values as less venerable. For one thing, only those that caused trouble were even updated when physical constants changed, iirc. > Would y'all like this PR to include updated output.ref files for the tests or would a separate test updating PR be better? I don't see anything in the"" adding tests documentat",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262549464
https://github.com/psi4/psi4/pull/2727#issuecomment-1262591435:1298,Availability,fault,fault,1298,"> Could you elaborate on why tests are failing at all, and what numbers are differing? Are these Cartesian coordinates?. I poorly worded my explanation. I was attempting to say that the geometries are virtually the same but not numerically, they are both well converged. I assumed the discrepancy was just a numeric difference and there have been various tweaks as well over the last few years to the algorithm. There is 1 algorithmic difference I'd be concerned about, from looking at the two outputs. New optking doesn't consider the most recent step in the hessian updating procedure - cpp-optking did. I've found three pieces of logic that explicitly or implicitly prevent updating with the most recent step in all or specific cases. I'd have to ask @psi-rking if this is a bug or was changed due to some stability concern. > Is .log where all the optking detailed output goes now? I guess we ought to start collecting them. output.log, perhaps. But this can also be deferred to a grand regenerate-the-refs script and PR. Yes optking's detailed output goes to `.log` but it isn't strictly speaking necessary for the user to see the detailed logs I would say. However, if the test is failing it might be nice to have a more detailed optimization record to compare against if the optimizer is at fault.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262591435
https://github.com/psi4/psi4/pull/2727#issuecomment-1262591435:1236,Performance,optimiz,optimization,1236,"> Could you elaborate on why tests are failing at all, and what numbers are differing? Are these Cartesian coordinates?. I poorly worded my explanation. I was attempting to say that the geometries are virtually the same but not numerically, they are both well converged. I assumed the discrepancy was just a numeric difference and there have been various tweaks as well over the last few years to the algorithm. There is 1 algorithmic difference I'd be concerned about, from looking at the two outputs. New optking doesn't consider the most recent step in the hessian updating procedure - cpp-optking did. I've found three pieces of logic that explicitly or implicitly prevent updating with the most recent step in all or specific cases. I'd have to ask @psi-rking if this is a bug or was changed due to some stability concern. > Is .log where all the optking detailed output goes now? I guess we ought to start collecting them. output.log, perhaps. But this can also be deferred to a grand regenerate-the-refs script and PR. Yes optking's detailed output goes to `.log` but it isn't strictly speaking necessary for the user to see the detailed logs I would say. However, if the test is failing it might be nice to have a more detailed optimization record to compare against if the optimizer is at fault.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262591435
https://github.com/psi4/psi4/pull/2727#issuecomment-1262591435:1282,Performance,optimiz,optimizer,1282,"> Could you elaborate on why tests are failing at all, and what numbers are differing? Are these Cartesian coordinates?. I poorly worded my explanation. I was attempting to say that the geometries are virtually the same but not numerically, they are both well converged. I assumed the discrepancy was just a numeric difference and there have been various tweaks as well over the last few years to the algorithm. There is 1 algorithmic difference I'd be concerned about, from looking at the two outputs. New optking doesn't consider the most recent step in the hessian updating procedure - cpp-optking did. I've found three pieces of logic that explicitly or implicitly prevent updating with the most recent step in all or specific cases. I'd have to ask @psi-rking if this is a bug or was changed due to some stability concern. > Is .log where all the optking detailed output goes now? I guess we ought to start collecting them. output.log, perhaps. But this can also be deferred to a grand regenerate-the-refs script and PR. Yes optking's detailed output goes to `.log` but it isn't strictly speaking necessary for the user to see the detailed logs I would say. However, if the test is failing it might be nice to have a more detailed optimization record to compare against if the optimizer is at fault.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262591435
https://github.com/psi4/psi4/pull/2727#issuecomment-1262591435:29,Testability,test,tests,29,"> Could you elaborate on why tests are failing at all, and what numbers are differing? Are these Cartesian coordinates?. I poorly worded my explanation. I was attempting to say that the geometries are virtually the same but not numerically, they are both well converged. I assumed the discrepancy was just a numeric difference and there have been various tweaks as well over the last few years to the algorithm. There is 1 algorithmic difference I'd be concerned about, from looking at the two outputs. New optking doesn't consider the most recent step in the hessian updating procedure - cpp-optking did. I've found three pieces of logic that explicitly or implicitly prevent updating with the most recent step in all or specific cases. I'd have to ask @psi-rking if this is a bug or was changed due to some stability concern. > Is .log where all the optking detailed output goes now? I guess we ought to start collecting them. output.log, perhaps. But this can also be deferred to a grand regenerate-the-refs script and PR. Yes optking's detailed output goes to `.log` but it isn't strictly speaking necessary for the user to see the detailed logs I would say. However, if the test is failing it might be nice to have a more detailed optimization record to compare against if the optimizer is at fault.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262591435
https://github.com/psi4/psi4/pull/2727#issuecomment-1262591435:633,Testability,log,logic,633,"> Could you elaborate on why tests are failing at all, and what numbers are differing? Are these Cartesian coordinates?. I poorly worded my explanation. I was attempting to say that the geometries are virtually the same but not numerically, they are both well converged. I assumed the discrepancy was just a numeric difference and there have been various tweaks as well over the last few years to the algorithm. There is 1 algorithmic difference I'd be concerned about, from looking at the two outputs. New optking doesn't consider the most recent step in the hessian updating procedure - cpp-optking did. I've found three pieces of logic that explicitly or implicitly prevent updating with the most recent step in all or specific cases. I'd have to ask @psi-rking if this is a bug or was changed due to some stability concern. > Is .log where all the optking detailed output goes now? I guess we ought to start collecting them. output.log, perhaps. But this can also be deferred to a grand regenerate-the-refs script and PR. Yes optking's detailed output goes to `.log` but it isn't strictly speaking necessary for the user to see the detailed logs I would say. However, if the test is failing it might be nice to have a more detailed optimization record to compare against if the optimizer is at fault.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262591435
https://github.com/psi4/psi4/pull/2727#issuecomment-1262591435:834,Testability,log,log,834,"> Could you elaborate on why tests are failing at all, and what numbers are differing? Are these Cartesian coordinates?. I poorly worded my explanation. I was attempting to say that the geometries are virtually the same but not numerically, they are both well converged. I assumed the discrepancy was just a numeric difference and there have been various tweaks as well over the last few years to the algorithm. There is 1 algorithmic difference I'd be concerned about, from looking at the two outputs. New optking doesn't consider the most recent step in the hessian updating procedure - cpp-optking did. I've found three pieces of logic that explicitly or implicitly prevent updating with the most recent step in all or specific cases. I'd have to ask @psi-rking if this is a bug or was changed due to some stability concern. > Is .log where all the optking detailed output goes now? I guess we ought to start collecting them. output.log, perhaps. But this can also be deferred to a grand regenerate-the-refs script and PR. Yes optking's detailed output goes to `.log` but it isn't strictly speaking necessary for the user to see the detailed logs I would say. However, if the test is failing it might be nice to have a more detailed optimization record to compare against if the optimizer is at fault.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262591435
https://github.com/psi4/psi4/pull/2727#issuecomment-1262591435:936,Testability,log,log,936,"> Could you elaborate on why tests are failing at all, and what numbers are differing? Are these Cartesian coordinates?. I poorly worded my explanation. I was attempting to say that the geometries are virtually the same but not numerically, they are both well converged. I assumed the discrepancy was just a numeric difference and there have been various tweaks as well over the last few years to the algorithm. There is 1 algorithmic difference I'd be concerned about, from looking at the two outputs. New optking doesn't consider the most recent step in the hessian updating procedure - cpp-optking did. I've found three pieces of logic that explicitly or implicitly prevent updating with the most recent step in all or specific cases. I'd have to ask @psi-rking if this is a bug or was changed due to some stability concern. > Is .log where all the optking detailed output goes now? I guess we ought to start collecting them. output.log, perhaps. But this can also be deferred to a grand regenerate-the-refs script and PR. Yes optking's detailed output goes to `.log` but it isn't strictly speaking necessary for the user to see the detailed logs I would say. However, if the test is failing it might be nice to have a more detailed optimization record to compare against if the optimizer is at fault.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262591435
https://github.com/psi4/psi4/pull/2727#issuecomment-1262591435:1066,Testability,log,log,1066,"> Could you elaborate on why tests are failing at all, and what numbers are differing? Are these Cartesian coordinates?. I poorly worded my explanation. I was attempting to say that the geometries are virtually the same but not numerically, they are both well converged. I assumed the discrepancy was just a numeric difference and there have been various tweaks as well over the last few years to the algorithm. There is 1 algorithmic difference I'd be concerned about, from looking at the two outputs. New optking doesn't consider the most recent step in the hessian updating procedure - cpp-optking did. I've found three pieces of logic that explicitly or implicitly prevent updating with the most recent step in all or specific cases. I'd have to ask @psi-rking if this is a bug or was changed due to some stability concern. > Is .log where all the optking detailed output goes now? I guess we ought to start collecting them. output.log, perhaps. But this can also be deferred to a grand regenerate-the-refs script and PR. Yes optking's detailed output goes to `.log` but it isn't strictly speaking necessary for the user to see the detailed logs I would say. However, if the test is failing it might be nice to have a more detailed optimization record to compare against if the optimizer is at fault.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262591435
https://github.com/psi4/psi4/pull/2727#issuecomment-1262591435:1145,Testability,log,logs,1145,"> Could you elaborate on why tests are failing at all, and what numbers are differing? Are these Cartesian coordinates?. I poorly worded my explanation. I was attempting to say that the geometries are virtually the same but not numerically, they are both well converged. I assumed the discrepancy was just a numeric difference and there have been various tweaks as well over the last few years to the algorithm. There is 1 algorithmic difference I'd be concerned about, from looking at the two outputs. New optking doesn't consider the most recent step in the hessian updating procedure - cpp-optking did. I've found three pieces of logic that explicitly or implicitly prevent updating with the most recent step in all or specific cases. I'd have to ask @psi-rking if this is a bug or was changed due to some stability concern. > Is .log where all the optking detailed output goes now? I guess we ought to start collecting them. output.log, perhaps. But this can also be deferred to a grand regenerate-the-refs script and PR. Yes optking's detailed output goes to `.log` but it isn't strictly speaking necessary for the user to see the detailed logs I would say. However, if the test is failing it might be nice to have a more detailed optimization record to compare against if the optimizer is at fault.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262591435
https://github.com/psi4/psi4/pull/2727#issuecomment-1262591435:1179,Testability,test,test,1179,"> Could you elaborate on why tests are failing at all, and what numbers are differing? Are these Cartesian coordinates?. I poorly worded my explanation. I was attempting to say that the geometries are virtually the same but not numerically, they are both well converged. I assumed the discrepancy was just a numeric difference and there have been various tweaks as well over the last few years to the algorithm. There is 1 algorithmic difference I'd be concerned about, from looking at the two outputs. New optking doesn't consider the most recent step in the hessian updating procedure - cpp-optking did. I've found three pieces of logic that explicitly or implicitly prevent updating with the most recent step in all or specific cases. I'd have to ask @psi-rking if this is a bug or was changed due to some stability concern. > Is .log where all the optking detailed output goes now? I guess we ought to start collecting them. output.log, perhaps. But this can also be deferred to a grand regenerate-the-refs script and PR. Yes optking's detailed output goes to `.log` but it isn't strictly speaking necessary for the user to see the detailed logs I would say. However, if the test is failing it might be nice to have a more detailed optimization record to compare against if the optimizer is at fault.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262591435
https://github.com/psi4/psi4/pull/2727#issuecomment-1262708139:566,Deployability,update,update,566,"> There is 1 algorithmic difference I'd be concerned about, from looking at the two outputs. New optking doesn't consider the most recent step in the hessian updating procedure - cpp-optking did. I've found three pieces of logic that explicitly or implicitly prevent updating with the most recent step in all or specific cases. I'd have to ask @psi-rking if this is a bug or was changed due to some stability concern. Interesting. This does not ring a bell for me. I take the question to be ""given a hessian and the current forces (beyond the first step) should you update the hessian with those forces before using them to calculate the step?"" Can you point to the code? IDK, probably best answer is whatever works better in practice and doesn't cause problems. Actually, it's possible I did this because I learned to avoid hessian updating when displacements are very small (or the geometries are very close). Perhaps I didn't want to update hessian until I knew the step size.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262708139
https://github.com/psi4/psi4/pull/2727#issuecomment-1262708139:937,Deployability,update,update,937,"> There is 1 algorithmic difference I'd be concerned about, from looking at the two outputs. New optking doesn't consider the most recent step in the hessian updating procedure - cpp-optking did. I've found three pieces of logic that explicitly or implicitly prevent updating with the most recent step in all or specific cases. I'd have to ask @psi-rking if this is a bug or was changed due to some stability concern. Interesting. This does not ring a bell for me. I take the question to be ""given a hessian and the current forces (beyond the first step) should you update the hessian with those forces before using them to calculate the step?"" Can you point to the code? IDK, probably best answer is whatever works better in practice and doesn't cause problems. Actually, it's possible I did this because I learned to avoid hessian updating when displacements are very small (or the geometries are very close). Perhaps I didn't want to update hessian until I knew the step size.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262708139
https://github.com/psi4/psi4/pull/2727#issuecomment-1262708139:819,Safety,avoid,avoid,819,"> There is 1 algorithmic difference I'd be concerned about, from looking at the two outputs. New optking doesn't consider the most recent step in the hessian updating procedure - cpp-optking did. I've found three pieces of logic that explicitly or implicitly prevent updating with the most recent step in all or specific cases. I'd have to ask @psi-rking if this is a bug or was changed due to some stability concern. Interesting. This does not ring a bell for me. I take the question to be ""given a hessian and the current forces (beyond the first step) should you update the hessian with those forces before using them to calculate the step?"" Can you point to the code? IDK, probably best answer is whatever works better in practice and doesn't cause problems. Actually, it's possible I did this because I learned to avoid hessian updating when displacements are very small (or the geometries are very close). Perhaps I didn't want to update hessian until I knew the step size.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262708139
https://github.com/psi4/psi4/pull/2727#issuecomment-1262708139:223,Testability,log,logic,223,"> There is 1 algorithmic difference I'd be concerned about, from looking at the two outputs. New optking doesn't consider the most recent step in the hessian updating procedure - cpp-optking did. I've found three pieces of logic that explicitly or implicitly prevent updating with the most recent step in all or specific cases. I'd have to ask @psi-rking if this is a bug or was changed due to some stability concern. Interesting. This does not ring a bell for me. I take the question to be ""given a hessian and the current forces (beyond the first step) should you update the hessian with those forces before using them to calculate the step?"" Can you point to the code? IDK, probably best answer is whatever works better in practice and doesn't cause problems. Actually, it's possible I did this because I learned to avoid hessian updating when displacements are very small (or the geometries are very close). Perhaps I didn't want to update hessian until I knew the step size.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262708139
https://github.com/psi4/psi4/pull/2727#issuecomment-1262708139:808,Usability,learn,learned,808,"> There is 1 algorithmic difference I'd be concerned about, from looking at the two outputs. New optking doesn't consider the most recent step in the hessian updating procedure - cpp-optking did. I've found three pieces of logic that explicitly or implicitly prevent updating with the most recent step in all or specific cases. I'd have to ask @psi-rking if this is a bug or was changed due to some stability concern. Interesting. This does not ring a bell for me. I take the question to be ""given a hessian and the current forces (beyond the first step) should you update the hessian with those forces before using them to calculate the step?"" Can you point to the code? IDK, probably best answer is whatever works better in practice and doesn't cause problems. Actually, it's possible I did this because I learned to avoid hessian updating when displacements are very small (or the geometries are very close). Perhaps I didn't want to update hessian until I knew the step size.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262708139
https://github.com/psi4/psi4/pull/2727#issuecomment-1262796555:263,Deployability,update,updated,263,"> I may not be following this right. I'd say the state of the psi4 active mol during an optimization is arbitrary -- whatever works for you. In cpp-optking, I think the communication was through legacymolecule anyways. The molecule optking is acting on should be updated by the time control returns to the user at the end of the opt. I thought this was already happening through https://github.com/psi4/psi4/pull/2727/files#diff-acf663ccea13592c4c656cf89c7b62e6f5bd3b2e8b4f12ba354129bd39d096f8R1296-R1297 . That's consistent with cpp-optking, and I think that must be happening b/c many of the tests check NRE before and after opt. I want to make sure that the active molecule behavior is as expected. Whatever molecule the driver uses will be updated. This will be either the active molecule OR the passed molecule. If the molecule is passed the active molecule is not updated in any way. All the asserts pass here. ```python; import math. molecule h2o {; pubchem:water; }. molecule h2o2 {; pubchem:hydrogen peroxide; }. # quick comparison. h2o2 is active molecule; h2o2_nre = h2o2.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_nre, active_nre). # optimize h2o2 (active molecule) expect repulsion energy to match; E = optimize(""scf/sto-3g""); h2o2_opt_nre = h2o2.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_opt_nre, active_nre). # optimize h2o. nuclear repulsion does not match. active molecule is still h2o2; # Currently (next commit will fix) h2o2 would be optimized by this call. (optking side issue); E = optimize(""scf/sto-3g"", molecule=h2o); h2o_opt_nre = h2o.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_opt_nre, active_nre); ```; The whole wrong molecule being optimized thing is an optking side issue that is fixed on optking/master.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262796555
https://github.com/psi4/psi4/pull/2727#issuecomment-1262796555:744,Deployability,update,updated,744,"> I may not be following this right. I'd say the state of the psi4 active mol during an optimization is arbitrary -- whatever works for you. In cpp-optking, I think the communication was through legacymolecule anyways. The molecule optking is acting on should be updated by the time control returns to the user at the end of the opt. I thought this was already happening through https://github.com/psi4/psi4/pull/2727/files#diff-acf663ccea13592c4c656cf89c7b62e6f5bd3b2e8b4f12ba354129bd39d096f8R1296-R1297 . That's consistent with cpp-optking, and I think that must be happening b/c many of the tests check NRE before and after opt. I want to make sure that the active molecule behavior is as expected. Whatever molecule the driver uses will be updated. This will be either the active molecule OR the passed molecule. If the molecule is passed the active molecule is not updated in any way. All the asserts pass here. ```python; import math. molecule h2o {; pubchem:water; }. molecule h2o2 {; pubchem:hydrogen peroxide; }. # quick comparison. h2o2 is active molecule; h2o2_nre = h2o2.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_nre, active_nre). # optimize h2o2 (active molecule) expect repulsion energy to match; E = optimize(""scf/sto-3g""); h2o2_opt_nre = h2o2.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_opt_nre, active_nre). # optimize h2o. nuclear repulsion does not match. active molecule is still h2o2; # Currently (next commit will fix) h2o2 would be optimized by this call. (optking side issue); E = optimize(""scf/sto-3g"", molecule=h2o); h2o_opt_nre = h2o.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_opt_nre, active_nre); ```; The whole wrong molecule being optimized thing is an optking side issue that is fixed on optking/master.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262796555
https://github.com/psi4/psi4/pull/2727#issuecomment-1262796555:870,Deployability,update,updated,870,"> I may not be following this right. I'd say the state of the psi4 active mol during an optimization is arbitrary -- whatever works for you. In cpp-optking, I think the communication was through legacymolecule anyways. The molecule optking is acting on should be updated by the time control returns to the user at the end of the opt. I thought this was already happening through https://github.com/psi4/psi4/pull/2727/files#diff-acf663ccea13592c4c656cf89c7b62e6f5bd3b2e8b4f12ba354129bd39d096f8R1296-R1297 . That's consistent with cpp-optking, and I think that must be happening b/c many of the tests check NRE before and after opt. I want to make sure that the active molecule behavior is as expected. Whatever molecule the driver uses will be updated. This will be either the active molecule OR the passed molecule. If the molecule is passed the active molecule is not updated in any way. All the asserts pass here. ```python; import math. molecule h2o {; pubchem:water; }. molecule h2o2 {; pubchem:hydrogen peroxide; }. # quick comparison. h2o2 is active molecule; h2o2_nre = h2o2.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_nre, active_nre). # optimize h2o2 (active molecule) expect repulsion energy to match; E = optimize(""scf/sto-3g""); h2o2_opt_nre = h2o2.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_opt_nre, active_nre). # optimize h2o. nuclear repulsion does not match. active molecule is still h2o2; # Currently (next commit will fix) h2o2 would be optimized by this call. (optking side issue); E = optimize(""scf/sto-3g"", molecule=h2o); h2o_opt_nre = h2o.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_opt_nre, active_nre); ```; The whole wrong molecule being optimized thing is an optking side issue that is fixed on optking/master.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262796555
https://github.com/psi4/psi4/pull/2727#issuecomment-1262796555:1273,Energy Efficiency,energy,energy,1273,"> I may not be following this right. I'd say the state of the psi4 active mol during an optimization is arbitrary -- whatever works for you. In cpp-optking, I think the communication was through legacymolecule anyways. The molecule optking is acting on should be updated by the time control returns to the user at the end of the opt. I thought this was already happening through https://github.com/psi4/psi4/pull/2727/files#diff-acf663ccea13592c4c656cf89c7b62e6f5bd3b2e8b4f12ba354129bd39d096f8R1296-R1297 . That's consistent with cpp-optking, and I think that must be happening b/c many of the tests check NRE before and after opt. I want to make sure that the active molecule behavior is as expected. Whatever molecule the driver uses will be updated. This will be either the active molecule OR the passed molecule. If the molecule is passed the active molecule is not updated in any way. All the asserts pass here. ```python; import math. molecule h2o {; pubchem:water; }. molecule h2o2 {; pubchem:hydrogen peroxide; }. # quick comparison. h2o2 is active molecule; h2o2_nre = h2o2.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_nre, active_nre). # optimize h2o2 (active molecule) expect repulsion energy to match; E = optimize(""scf/sto-3g""); h2o2_opt_nre = h2o2.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_opt_nre, active_nre). # optimize h2o. nuclear repulsion does not match. active molecule is still h2o2; # Currently (next commit will fix) h2o2 would be optimized by this call. (optking side issue); E = optimize(""scf/sto-3g"", molecule=h2o); h2o_opt_nre = h2o.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_opt_nre, active_nre); ```; The whole wrong molecule being optimized thing is an optking side issue that is fixed on optking/master.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262796555
https://github.com/psi4/psi4/pull/2727#issuecomment-1262796555:88,Performance,optimiz,optimization,88,"> I may not be following this right. I'd say the state of the psi4 active mol during an optimization is arbitrary -- whatever works for you. In cpp-optking, I think the communication was through legacymolecule anyways. The molecule optking is acting on should be updated by the time control returns to the user at the end of the opt. I thought this was already happening through https://github.com/psi4/psi4/pull/2727/files#diff-acf663ccea13592c4c656cf89c7b62e6f5bd3b2e8b4f12ba354129bd39d096f8R1296-R1297 . That's consistent with cpp-optking, and I think that must be happening b/c many of the tests check NRE before and after opt. I want to make sure that the active molecule behavior is as expected. Whatever molecule the driver uses will be updated. This will be either the active molecule OR the passed molecule. If the molecule is passed the active molecule is not updated in any way. All the asserts pass here. ```python; import math. molecule h2o {; pubchem:water; }. molecule h2o2 {; pubchem:hydrogen peroxide; }. # quick comparison. h2o2 is active molecule; h2o2_nre = h2o2.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_nre, active_nre). # optimize h2o2 (active molecule) expect repulsion energy to match; E = optimize(""scf/sto-3g""); h2o2_opt_nre = h2o2.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_opt_nre, active_nre). # optimize h2o. nuclear repulsion does not match. active molecule is still h2o2; # Currently (next commit will fix) h2o2 would be optimized by this call. (optking side issue); E = optimize(""scf/sto-3g"", molecule=h2o); h2o_opt_nre = h2o.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_opt_nre, active_nre); ```; The whole wrong molecule being optimized thing is an optking side issue that is fixed on optking/master.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262796555
https://github.com/psi4/psi4/pull/2727#issuecomment-1262796555:1224,Performance,optimiz,optimize,1224,"> I may not be following this right. I'd say the state of the psi4 active mol during an optimization is arbitrary -- whatever works for you. In cpp-optking, I think the communication was through legacymolecule anyways. The molecule optking is acting on should be updated by the time control returns to the user at the end of the opt. I thought this was already happening through https://github.com/psi4/psi4/pull/2727/files#diff-acf663ccea13592c4c656cf89c7b62e6f5bd3b2e8b4f12ba354129bd39d096f8R1296-R1297 . That's consistent with cpp-optking, and I think that must be happening b/c many of the tests check NRE before and after opt. I want to make sure that the active molecule behavior is as expected. Whatever molecule the driver uses will be updated. This will be either the active molecule OR the passed molecule. If the molecule is passed the active molecule is not updated in any way. All the asserts pass here. ```python; import math. molecule h2o {; pubchem:water; }. molecule h2o2 {; pubchem:hydrogen peroxide; }. # quick comparison. h2o2 is active molecule; h2o2_nre = h2o2.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_nre, active_nre). # optimize h2o2 (active molecule) expect repulsion energy to match; E = optimize(""scf/sto-3g""); h2o2_opt_nre = h2o2.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_opt_nre, active_nre). # optimize h2o. nuclear repulsion does not match. active molecule is still h2o2; # Currently (next commit will fix) h2o2 would be optimized by this call. (optking side issue); E = optimize(""scf/sto-3g"", molecule=h2o); h2o_opt_nre = h2o.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_opt_nre, active_nre); ```; The whole wrong molecule being optimized thing is an optking side issue that is fixed on optking/master.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262796555
https://github.com/psi4/psi4/pull/2727#issuecomment-1262796555:1294,Performance,optimiz,optimize,1294,"> I may not be following this right. I'd say the state of the psi4 active mol during an optimization is arbitrary -- whatever works for you. In cpp-optking, I think the communication was through legacymolecule anyways. The molecule optking is acting on should be updated by the time control returns to the user at the end of the opt. I thought this was already happening through https://github.com/psi4/psi4/pull/2727/files#diff-acf663ccea13592c4c656cf89c7b62e6f5bd3b2e8b4f12ba354129bd39d096f8R1296-R1297 . That's consistent with cpp-optking, and I think that must be happening b/c many of the tests check NRE before and after opt. I want to make sure that the active molecule behavior is as expected. Whatever molecule the driver uses will be updated. This will be either the active molecule OR the passed molecule. If the molecule is passed the active molecule is not updated in any way. All the asserts pass here. ```python; import math. molecule h2o {; pubchem:water; }. molecule h2o2 {; pubchem:hydrogen peroxide; }. # quick comparison. h2o2 is active molecule; h2o2_nre = h2o2.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_nre, active_nre). # optimize h2o2 (active molecule) expect repulsion energy to match; E = optimize(""scf/sto-3g""); h2o2_opt_nre = h2o2.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_opt_nre, active_nre). # optimize h2o. nuclear repulsion does not match. active molecule is still h2o2; # Currently (next commit will fix) h2o2 would be optimized by this call. (optking side issue); E = optimize(""scf/sto-3g"", molecule=h2o); h2o_opt_nre = h2o.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_opt_nre, active_nre); ```; The whole wrong molecule being optimized thing is an optking side issue that is fixed on optking/master.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262796555
https://github.com/psi4/psi4/pull/2727#issuecomment-1262796555:1483,Performance,optimiz,optimize,1483,"> I may not be following this right. I'd say the state of the psi4 active mol during an optimization is arbitrary -- whatever works for you. In cpp-optking, I think the communication was through legacymolecule anyways. The molecule optking is acting on should be updated by the time control returns to the user at the end of the opt. I thought this was already happening through https://github.com/psi4/psi4/pull/2727/files#diff-acf663ccea13592c4c656cf89c7b62e6f5bd3b2e8b4f12ba354129bd39d096f8R1296-R1297 . That's consistent with cpp-optking, and I think that must be happening b/c many of the tests check NRE before and after opt. I want to make sure that the active molecule behavior is as expected. Whatever molecule the driver uses will be updated. This will be either the active molecule OR the passed molecule. If the molecule is passed the active molecule is not updated in any way. All the asserts pass here. ```python; import math. molecule h2o {; pubchem:water; }. molecule h2o2 {; pubchem:hydrogen peroxide; }. # quick comparison. h2o2 is active molecule; h2o2_nre = h2o2.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_nre, active_nre). # optimize h2o2 (active molecule) expect repulsion energy to match; E = optimize(""scf/sto-3g""); h2o2_opt_nre = h2o2.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_opt_nre, active_nre). # optimize h2o. nuclear repulsion does not match. active molecule is still h2o2; # Currently (next commit will fix) h2o2 would be optimized by this call. (optking side issue); E = optimize(""scf/sto-3g"", molecule=h2o); h2o_opt_nre = h2o.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_opt_nre, active_nre); ```; The whole wrong molecule being optimized thing is an optking side issue that is fixed on optking/master.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262796555
https://github.com/psi4/psi4/pull/2727#issuecomment-1262796555:1611,Performance,optimiz,optimized,1611,"> I may not be following this right. I'd say the state of the psi4 active mol during an optimization is arbitrary -- whatever works for you. In cpp-optking, I think the communication was through legacymolecule anyways. The molecule optking is acting on should be updated by the time control returns to the user at the end of the opt. I thought this was already happening through https://github.com/psi4/psi4/pull/2727/files#diff-acf663ccea13592c4c656cf89c7b62e6f5bd3b2e8b4f12ba354129bd39d096f8R1296-R1297 . That's consistent with cpp-optking, and I think that must be happening b/c many of the tests check NRE before and after opt. I want to make sure that the active molecule behavior is as expected. Whatever molecule the driver uses will be updated. This will be either the active molecule OR the passed molecule. If the molecule is passed the active molecule is not updated in any way. All the asserts pass here. ```python; import math. molecule h2o {; pubchem:water; }. molecule h2o2 {; pubchem:hydrogen peroxide; }. # quick comparison. h2o2 is active molecule; h2o2_nre = h2o2.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_nre, active_nre). # optimize h2o2 (active molecule) expect repulsion energy to match; E = optimize(""scf/sto-3g""); h2o2_opt_nre = h2o2.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_opt_nre, active_nre). # optimize h2o. nuclear repulsion does not match. active molecule is still h2o2; # Currently (next commit will fix) h2o2 would be optimized by this call. (optking side issue); E = optimize(""scf/sto-3g"", molecule=h2o); h2o_opt_nre = h2o.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_opt_nre, active_nre); ```; The whole wrong molecule being optimized thing is an optking side issue that is fixed on optking/master.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262796555
https://github.com/psi4/psi4/pull/2727#issuecomment-1262796555:1661,Performance,optimiz,optimize,1661,"> I may not be following this right. I'd say the state of the psi4 active mol during an optimization is arbitrary -- whatever works for you. In cpp-optking, I think the communication was through legacymolecule anyways. The molecule optking is acting on should be updated by the time control returns to the user at the end of the opt. I thought this was already happening through https://github.com/psi4/psi4/pull/2727/files#diff-acf663ccea13592c4c656cf89c7b62e6f5bd3b2e8b4f12ba354129bd39d096f8R1296-R1297 . That's consistent with cpp-optking, and I think that must be happening b/c many of the tests check NRE before and after opt. I want to make sure that the active molecule behavior is as expected. Whatever molecule the driver uses will be updated. This will be either the active molecule OR the passed molecule. If the molecule is passed the active molecule is not updated in any way. All the asserts pass here. ```python; import math. molecule h2o {; pubchem:water; }. molecule h2o2 {; pubchem:hydrogen peroxide; }. # quick comparison. h2o2 is active molecule; h2o2_nre = h2o2.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_nre, active_nre). # optimize h2o2 (active molecule) expect repulsion energy to match; E = optimize(""scf/sto-3g""); h2o2_opt_nre = h2o2.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_opt_nre, active_nre). # optimize h2o. nuclear repulsion does not match. active molecule is still h2o2; # Currently (next commit will fix) h2o2 would be optimized by this call. (optking side issue); E = optimize(""scf/sto-3g"", molecule=h2o); h2o_opt_nre = h2o.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_opt_nre, active_nre); ```; The whole wrong molecule being optimized thing is an optking side issue that is fixed on optking/master.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262796555
https://github.com/psi4/psi4/pull/2727#issuecomment-1262796555:1896,Performance,optimiz,optimized,1896,"> I may not be following this right. I'd say the state of the psi4 active mol during an optimization is arbitrary -- whatever works for you. In cpp-optking, I think the communication was through legacymolecule anyways. The molecule optking is acting on should be updated by the time control returns to the user at the end of the opt. I thought this was already happening through https://github.com/psi4/psi4/pull/2727/files#diff-acf663ccea13592c4c656cf89c7b62e6f5bd3b2e8b4f12ba354129bd39d096f8R1296-R1297 . That's consistent with cpp-optking, and I think that must be happening b/c many of the tests check NRE before and after opt. I want to make sure that the active molecule behavior is as expected. Whatever molecule the driver uses will be updated. This will be either the active molecule OR the passed molecule. If the molecule is passed the active molecule is not updated in any way. All the asserts pass here. ```python; import math. molecule h2o {; pubchem:water; }. molecule h2o2 {; pubchem:hydrogen peroxide; }. # quick comparison. h2o2 is active molecule; h2o2_nre = h2o2.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_nre, active_nre). # optimize h2o2 (active molecule) expect repulsion energy to match; E = optimize(""scf/sto-3g""); h2o2_opt_nre = h2o2.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_opt_nre, active_nre). # optimize h2o. nuclear repulsion does not match. active molecule is still h2o2; # Currently (next commit will fix) h2o2 would be optimized by this call. (optking side issue); E = optimize(""scf/sto-3g"", molecule=h2o); h2o_opt_nre = h2o.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_opt_nre, active_nre); ```; The whole wrong molecule being optimized thing is an optking side issue that is fixed on optking/master.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262796555
https://github.com/psi4/psi4/pull/2727#issuecomment-1262796555:594,Testability,test,tests,594,"> I may not be following this right. I'd say the state of the psi4 active mol during an optimization is arbitrary -- whatever works for you. In cpp-optking, I think the communication was through legacymolecule anyways. The molecule optking is acting on should be updated by the time control returns to the user at the end of the opt. I thought this was already happening through https://github.com/psi4/psi4/pull/2727/files#diff-acf663ccea13592c4c656cf89c7b62e6f5bd3b2e8b4f12ba354129bd39d096f8R1296-R1297 . That's consistent with cpp-optking, and I think that must be happening b/c many of the tests check NRE before and after opt. I want to make sure that the active molecule behavior is as expected. Whatever molecule the driver uses will be updated. This will be either the active molecule OR the passed molecule. If the molecule is passed the active molecule is not updated in any way. All the asserts pass here. ```python; import math. molecule h2o {; pubchem:water; }. molecule h2o2 {; pubchem:hydrogen peroxide; }. # quick comparison. h2o2 is active molecule; h2o2_nre = h2o2.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_nre, active_nre). # optimize h2o2 (active molecule) expect repulsion energy to match; E = optimize(""scf/sto-3g""); h2o2_opt_nre = h2o2.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_opt_nre, active_nre). # optimize h2o. nuclear repulsion does not match. active molecule is still h2o2; # Currently (next commit will fix) h2o2 would be optimized by this call. (optking side issue); E = optimize(""scf/sto-3g"", molecule=h2o); h2o_opt_nre = h2o.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_opt_nre, active_nre); ```; The whole wrong molecule being optimized thing is an optking side issue that is fixed on optking/master.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262796555
https://github.com/psi4/psi4/pull/2727#issuecomment-1262796555:898,Testability,assert,asserts,898,"> I may not be following this right. I'd say the state of the psi4 active mol during an optimization is arbitrary -- whatever works for you. In cpp-optking, I think the communication was through legacymolecule anyways. The molecule optking is acting on should be updated by the time control returns to the user at the end of the opt. I thought this was already happening through https://github.com/psi4/psi4/pull/2727/files#diff-acf663ccea13592c4c656cf89c7b62e6f5bd3b2e8b4f12ba354129bd39d096f8R1296-R1297 . That's consistent with cpp-optking, and I think that must be happening b/c many of the tests check NRE before and after opt. I want to make sure that the active molecule behavior is as expected. Whatever molecule the driver uses will be updated. This will be either the active molecule OR the passed molecule. If the molecule is passed the active molecule is not updated in any way. All the asserts pass here. ```python; import math. molecule h2o {; pubchem:water; }. molecule h2o2 {; pubchem:hydrogen peroxide; }. # quick comparison. h2o2 is active molecule; h2o2_nre = h2o2.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_nre, active_nre). # optimize h2o2 (active molecule) expect repulsion energy to match; E = optimize(""scf/sto-3g""); h2o2_opt_nre = h2o2.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_opt_nre, active_nre). # optimize h2o. nuclear repulsion does not match. active molecule is still h2o2; # Currently (next commit will fix) h2o2 would be optimized by this call. (optking side issue); E = optimize(""scf/sto-3g"", molecule=h2o); h2o_opt_nre = h2o.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_opt_nre, active_nre); ```; The whole wrong molecule being optimized thing is an optking side issue that is fixed on optking/master.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262796555
https://github.com/psi4/psi4/pull/2727#issuecomment-1262796555:1179,Testability,assert,assert,1179,"> I may not be following this right. I'd say the state of the psi4 active mol during an optimization is arbitrary -- whatever works for you. In cpp-optking, I think the communication was through legacymolecule anyways. The molecule optking is acting on should be updated by the time control returns to the user at the end of the opt. I thought this was already happening through https://github.com/psi4/psi4/pull/2727/files#diff-acf663ccea13592c4c656cf89c7b62e6f5bd3b2e8b4f12ba354129bd39d096f8R1296-R1297 . That's consistent with cpp-optking, and I think that must be happening b/c many of the tests check NRE before and after opt. I want to make sure that the active molecule behavior is as expected. Whatever molecule the driver uses will be updated. This will be either the active molecule OR the passed molecule. If the molecule is passed the active molecule is not updated in any way. All the asserts pass here. ```python; import math. molecule h2o {; pubchem:water; }. molecule h2o2 {; pubchem:hydrogen peroxide; }. # quick comparison. h2o2 is active molecule; h2o2_nre = h2o2.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_nre, active_nre). # optimize h2o2 (active molecule) expect repulsion energy to match; E = optimize(""scf/sto-3g""); h2o2_opt_nre = h2o2.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_opt_nre, active_nre). # optimize h2o. nuclear repulsion does not match. active molecule is still h2o2; # Currently (next commit will fix) h2o2 would be optimized by this call. (optking side issue); E = optimize(""scf/sto-3g"", molecule=h2o); h2o_opt_nre = h2o.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_opt_nre, active_nre); ```; The whole wrong molecule being optimized thing is an optking side issue that is fixed on optking/master.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262796555
https://github.com/psi4/psi4/pull/2727#issuecomment-1262796555:1434,Testability,assert,assert,1434,"> I may not be following this right. I'd say the state of the psi4 active mol during an optimization is arbitrary -- whatever works for you. In cpp-optking, I think the communication was through legacymolecule anyways. The molecule optking is acting on should be updated by the time control returns to the user at the end of the opt. I thought this was already happening through https://github.com/psi4/psi4/pull/2727/files#diff-acf663ccea13592c4c656cf89c7b62e6f5bd3b2e8b4f12ba354129bd39d096f8R1296-R1297 . That's consistent with cpp-optking, and I think that must be happening b/c many of the tests check NRE before and after opt. I want to make sure that the active molecule behavior is as expected. Whatever molecule the driver uses will be updated. This will be either the active molecule OR the passed molecule. If the molecule is passed the active molecule is not updated in any way. All the asserts pass here. ```python; import math. molecule h2o {; pubchem:water; }. molecule h2o2 {; pubchem:hydrogen peroxide; }. # quick comparison. h2o2 is active molecule; h2o2_nre = h2o2.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_nre, active_nre). # optimize h2o2 (active molecule) expect repulsion energy to match; E = optimize(""scf/sto-3g""); h2o2_opt_nre = h2o2.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_opt_nre, active_nre). # optimize h2o. nuclear repulsion does not match. active molecule is still h2o2; # Currently (next commit will fix) h2o2 would be optimized by this call. (optking side issue); E = optimize(""scf/sto-3g"", molecule=h2o); h2o_opt_nre = h2o.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_opt_nre, active_nre); ```; The whole wrong molecule being optimized thing is an optking side issue that is fixed on optking/master.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262796555
https://github.com/psi4/psi4/pull/2727#issuecomment-1262796555:1813,Testability,assert,assert,1813,"> I may not be following this right. I'd say the state of the psi4 active mol during an optimization is arbitrary -- whatever works for you. In cpp-optking, I think the communication was through legacymolecule anyways. The molecule optking is acting on should be updated by the time control returns to the user at the end of the opt. I thought this was already happening through https://github.com/psi4/psi4/pull/2727/files#diff-acf663ccea13592c4c656cf89c7b62e6f5bd3b2e8b4f12ba354129bd39d096f8R1296-R1297 . That's consistent with cpp-optking, and I think that must be happening b/c many of the tests check NRE before and after opt. I want to make sure that the active molecule behavior is as expected. Whatever molecule the driver uses will be updated. This will be either the active molecule OR the passed molecule. If the molecule is passed the active molecule is not updated in any way. All the asserts pass here. ```python; import math. molecule h2o {; pubchem:water; }. molecule h2o2 {; pubchem:hydrogen peroxide; }. # quick comparison. h2o2 is active molecule; h2o2_nre = h2o2.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_nre, active_nre). # optimize h2o2 (active molecule) expect repulsion energy to match; E = optimize(""scf/sto-3g""); h2o2_opt_nre = h2o2.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_opt_nre, active_nre). # optimize h2o. nuclear repulsion does not match. active molecule is still h2o2; # Currently (next commit will fix) h2o2 would be optimized by this call. (optking side issue); E = optimize(""scf/sto-3g"", molecule=h2o); h2o_opt_nre = h2o.nuclear_repulsion_energy(); active_nre = core.get_active_molecule().nuclear_repulsion_energy(). assert math.isclose(h2o2_opt_nre, active_nre); ```; The whole wrong molecule being optimized thing is an optking side issue that is fixed on optking/master.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1262796555
https://github.com/psi4/psi4/pull/2727#issuecomment-1332446099:147,Testability,test,testing,147,"Np. it looks like you removed legacy freq and wfn. I had removed legacy molcule, grad, and wfn. Legacy should be fully purged! :tada: Building and testing.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1332446099
https://github.com/psi4/psi4/pull/2727#issuecomment-1332578549:74,Energy Efficiency,energy,energy,74,"After rebase, `cookbook-manual-fd-hess-grad` and `cookbook-manual-fd-hess-energy` fail due to `set_frequencies` missing. Is there something I should replace those with? I don't see an alternative recommended in the deprecation notice.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1332578549
https://github.com/psi4/psi4/pull/2727#issuecomment-1332583820:76,Energy Efficiency,energy,energy,76,"> After rebase, `cookbook-manual-fd-hess-grad` and `cookbook-manual-fd-hess-energy` fail due to `set_frequencies` missing. Is there something I should replace those with? I don't see an alternative recommended in the deprecation notice. No. `wfn.frequencies()` will return the frequencies automagically thanks to `wfn.frequency_analysis = vibinfo`. @loriab can probably confirm.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1332583820
https://github.com/psi4/psi4/pull/2727#issuecomment-1332747375:12,Testability,test,test,12,"Can I get a test re-trigger? I'm not sure why mac failed, but I'm hoping it was a fluke.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1332747375
https://github.com/psi4/psi4/pull/2727#issuecomment-1332748782:26,Availability,fault,fault,26,"Not a fluke, but not your fault either. Ask again when [Lori's patch](https://github.com/psi4/psi4/pull/2815) is merged in.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1332748782
https://github.com/psi4/psi4/pull/2727#issuecomment-1332748782:63,Deployability,patch,patch,63,"Not a fluke, but not your fault either. Ask again when [Lori's patch](https://github.com/psi4/psi4/pull/2815) is merged in.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1332748782
https://github.com/psi4/psi4/pull/2727#issuecomment-1335593560:873,Integrability,Message,Message,873,"Do we have a figure in there yet illustrating the inter-fragment; definitions? I have no time to work on it today, but could tomorrow; (Saturday). On Fri, Dec 2, 2022 at 11:37 AM AlexHeide ***@***.***> wrote:. > @psi-rking <https://github.com/psi-rking> Can you give the optking docs; > another read through? Anything from your experiences with forum questions; > and such that we should add? If you have any thoughts on further clarifying; > the inter-fragment section that would also be super helpful. I'm printing; > the html now to make another editing pass.; >; > ; > Reply to this email directly, view it on GitHub; > <https://github.com/psi4/psi4/pull/2727#issuecomment-1335575353>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AA4C4TEDXN7A6CEYGZ32SO3WLIXWFANCNFSM6AAAAAAQWELJAU>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1335593560
https://github.com/psi4/psi4/pull/2727#issuecomment-1335779471:79,Availability,ERROR,ERROR,79,"`/home/runner/work/psi4/psi4/code/objdir/doc/sphinxman/source/optking.rst:346: ERROR: Undefined substitution referenced: ""optking_frag_mode"".`. docs error above. probably needs double underscore after optking. > Do we have a figure in there yet illustrating the inter-fragment; definitions? I have no time to work on it today, but could tomorrow; (Saturday). interfrag figure would be great. but if we get to the point where everything else is ready, I think that could be a separate PR.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1335779471
https://github.com/psi4/psi4/pull/2727#issuecomment-1335779471:149,Availability,error,error,149,"`/home/runner/work/psi4/psi4/code/objdir/doc/sphinxman/source/optking.rst:346: ERROR: Undefined substitution referenced: ""optking_frag_mode"".`. docs error above. probably needs double underscore after optking. > Do we have a figure in there yet illustrating the inter-fragment; definitions? I have no time to work on it today, but could tomorrow; (Saturday). interfrag figure would be great. but if we get to the point where everything else is ready, I think that could be a separate PR.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1335779471
https://github.com/psi4/psi4/pull/2727#issuecomment-1335896146:299,Availability,ERROR,ERROR,299,"Yes, I agree that details instructions and more demonstrations could be; added in separate PR, and not a reason to stall Alex's integration efforts. On Fri, Dec 2, 2022 at 2:04 PM Lori A. Burns ***@***.***>; wrote:. > /home/runner/work/psi4/psi4/code/objdir/doc/sphinxman/source/optking.rst:346:; > ERROR: Undefined substitution referenced: ""optking_frag_mode"".; >; > docs error above. probably needs double underscore after optking.; >; > Do we have a figure in there yet illustrating the inter-fragment; > definitions? I have no time to work on it today, but could tomorrow; > (Saturday).; >; > interfrag figure would be great. but if we get to the point where; > everything else is ready, I think that could be a separate PR.; >; > ; > Reply to this email directly, view it on GitHub; > <https://github.com/psi4/psi4/pull/2727#issuecomment-1335779471>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AA4C4TB764VCREPSYNXVVTTWLJI3HANCNFSM6AAAAAAQWELJAU>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1335896146
https://github.com/psi4/psi4/pull/2727#issuecomment-1335896146:373,Availability,error,error,373,"Yes, I agree that details instructions and more demonstrations could be; added in separate PR, and not a reason to stall Alex's integration efforts. On Fri, Dec 2, 2022 at 2:04 PM Lori A. Burns ***@***.***>; wrote:. > /home/runner/work/psi4/psi4/code/objdir/doc/sphinxman/source/optking.rst:346:; > ERROR: Undefined substitution referenced: ""optking_frag_mode"".; >; > docs error above. probably needs double underscore after optking.; >; > Do we have a figure in there yet illustrating the inter-fragment; > definitions? I have no time to work on it today, but could tomorrow; > (Saturday).; >; > interfrag figure would be great. but if we get to the point where; > everything else is ready, I think that could be a separate PR.; >; > ; > Reply to this email directly, view it on GitHub; > <https://github.com/psi4/psi4/pull/2727#issuecomment-1335779471>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AA4C4TB764VCREPSYNXVVTTWLJI3HANCNFSM6AAAAAAQWELJAU>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1335896146
https://github.com/psi4/psi4/pull/2727#issuecomment-1335896146:128,Deployability,integrat,integration,128,"Yes, I agree that details instructions and more demonstrations could be; added in separate PR, and not a reason to stall Alex's integration efforts. On Fri, Dec 2, 2022 at 2:04 PM Lori A. Burns ***@***.***>; wrote:. > /home/runner/work/psi4/psi4/code/objdir/doc/sphinxman/source/optking.rst:346:; > ERROR: Undefined substitution referenced: ""optking_frag_mode"".; >; > docs error above. probably needs double underscore after optking.; >; > Do we have a figure in there yet illustrating the inter-fragment; > definitions? I have no time to work on it today, but could tomorrow; > (Saturday).; >; > interfrag figure would be great. but if we get to the point where; > everything else is ready, I think that could be a separate PR.; >; > ; > Reply to this email directly, view it on GitHub; > <https://github.com/psi4/psi4/pull/2727#issuecomment-1335779471>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AA4C4TB764VCREPSYNXVVTTWLJI3HANCNFSM6AAAAAAQWELJAU>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1335896146
https://github.com/psi4/psi4/pull/2727#issuecomment-1335896146:128,Integrability,integrat,integration,128,"Yes, I agree that details instructions and more demonstrations could be; added in separate PR, and not a reason to stall Alex's integration efforts. On Fri, Dec 2, 2022 at 2:04 PM Lori A. Burns ***@***.***>; wrote:. > /home/runner/work/psi4/psi4/code/objdir/doc/sphinxman/source/optking.rst:346:; > ERROR: Undefined substitution referenced: ""optking_frag_mode"".; >; > docs error above. probably needs double underscore after optking.; >; > Do we have a figure in there yet illustrating the inter-fragment; > definitions? I have no time to work on it today, but could tomorrow; > (Saturday).; >; > interfrag figure would be great. but if we get to the point where; > everything else is ready, I think that could be a separate PR.; >; > ; > Reply to this email directly, view it on GitHub; > <https://github.com/psi4/psi4/pull/2727#issuecomment-1335779471>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AA4C4TB764VCREPSYNXVVTTWLJI3HANCNFSM6AAAAAAQWELJAU>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1335896146
https://github.com/psi4/psi4/pull/2727#issuecomment-1335896146:1039,Integrability,Message,Message,1039,"Yes, I agree that details instructions and more demonstrations could be; added in separate PR, and not a reason to stall Alex's integration efforts. On Fri, Dec 2, 2022 at 2:04 PM Lori A. Burns ***@***.***>; wrote:. > /home/runner/work/psi4/psi4/code/objdir/doc/sphinxman/source/optking.rst:346:; > ERROR: Undefined substitution referenced: ""optking_frag_mode"".; >; > docs error above. probably needs double underscore after optking.; >; > Do we have a figure in there yet illustrating the inter-fragment; > definitions? I have no time to work on it today, but could tomorrow; > (Saturday).; >; > interfrag figure would be great. but if we get to the point where; > everything else is ready, I think that could be a separate PR.; >; > ; > Reply to this email directly, view it on GitHub; > <https://github.com/psi4/psi4/pull/2727#issuecomment-1335779471>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AA4C4TB764VCREPSYNXVVTTWLJI3HANCNFSM6AAAAAAQWELJAU>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1335896146
https://github.com/psi4/psi4/pull/2727#issuecomment-1335924107:61,Performance,optimiz,optimizations,61,"Let me be more explicit about why I find the ""multi-fragment optimizations"" section confusing. * The first sentence talks about ""the metric for connecting atoms"" without explaining what ""connecting atoms"" means. Even worse, the first sentence is not obviously about dimers.; * It isn't clear to me what a ""reference point"" signifies. While I can tell whether something is an acceptable reference point, what are these used for? It looks like these are atoms used to define intermolecular internal coordinates.; * I don't know what it means to talk about a linear combination of atoms, or how to interpret `[[3], [1], [2]], [[1, 2, 3, 4, 5, 6], [2], [6]]` in your first example. The third point is crucial - I can't follow your examples. I won't insist on a figure, but I do insist on examples I can understand.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1335924107
https://github.com/psi4/psi4/pull/2727#issuecomment-1335924107:286,Usability,clear,clear,286,"Let me be more explicit about why I find the ""multi-fragment optimizations"" section confusing. * The first sentence talks about ""the metric for connecting atoms"" without explaining what ""connecting atoms"" means. Even worse, the first sentence is not obviously about dimers.; * It isn't clear to me what a ""reference point"" signifies. While I can tell whether something is an acceptable reference point, what are these used for? It looks like these are atoms used to define intermolecular internal coordinates.; * I don't know what it means to talk about a linear combination of atoms, or how to interpret `[[3], [1], [2]], [[1, 2, 3, 4, 5, 6], [2], [6]]` in your first example. The third point is crucial - I can't follow your examples. I won't insist on a figure, but I do insist on examples I can understand.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1335924107
https://github.com/psi4/psi4/pull/2727#issuecomment-1337727223:134,Availability,ERROR,ERROR,134,"looks like typos in options snagging up the docs:. ```; /home/runner/work/psi4/psi4/code/objdir/doc/sphinxman/source/optking.rst:359: ERROR: Undefined substitution referenced: ""optking_frag_ref_atoms"".; /home/runner/work/psi4/psi4/code/objdir/doc/sphinxman/source/optking.rst:359: ERROR: Undefined substitution referenced: ""otking__frag_ref_atoms"".; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1337727223
https://github.com/psi4/psi4/pull/2727#issuecomment-1337727223:281,Availability,ERROR,ERROR,281,"looks like typos in options snagging up the docs:. ```; /home/runner/work/psi4/psi4/code/objdir/doc/sphinxman/source/optking.rst:359: ERROR: Undefined substitution referenced: ""optking_frag_ref_atoms"".; /home/runner/work/psi4/psi4/code/objdir/doc/sphinxman/source/optking.rst:359: ERROR: Undefined substitution referenced: ""otking__frag_ref_atoms"".; ```",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2727#issuecomment-1337727223
https://github.com/psi4/psi4/issues/2728#issuecomment-1262298053:57,Availability,ping,ping,57,"MBIS is Georgia Tech's department, so obligatory @loriab ping - I'm not sure who has taken over MBIS now that Jeff has left. Is there a legitimate reason for us not to support MBIS for iodine? It looks to me like we just need to extend the `get_mbis_params` table one more row of the periodic table and then update the `mA` setting. If so, this is an easy project for one of your developers who is still learning Psi.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2728#issuecomment-1262298053
https://github.com/psi4/psi4/issues/2728#issuecomment-1262298053:308,Deployability,update,update,308,"MBIS is Georgia Tech's department, so obligatory @loriab ping - I'm not sure who has taken over MBIS now that Jeff has left. Is there a legitimate reason for us not to support MBIS for iodine? It looks to me like we just need to extend the `get_mbis_params` table one more row of the periodic table and then update the `mA` setting. If so, this is an easy project for one of your developers who is still learning Psi.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2728#issuecomment-1262298053
https://github.com/psi4/psi4/issues/2728#issuecomment-1262298053:229,Modifiability,extend,extend,229,"MBIS is Georgia Tech's department, so obligatory @loriab ping - I'm not sure who has taken over MBIS now that Jeff has left. Is there a legitimate reason for us not to support MBIS for iodine? It looks to me like we just need to extend the `get_mbis_params` table one more row of the periodic table and then update the `mA` setting. If so, this is an easy project for one of your developers who is still learning Psi.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2728#issuecomment-1262298053
https://github.com/psi4/psi4/issues/2728#issuecomment-1262298053:404,Usability,learn,learning,404,"MBIS is Georgia Tech's department, so obligatory @loriab ping - I'm not sure who has taken over MBIS now that Jeff has left. Is there a legitimate reason for us not to support MBIS for iodine? It looks to me like we just need to extend the `get_mbis_params` table one more row of the periodic table and then update the `mA` setting. If so, this is an easy project for one of your developers who is still learning Psi.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2728#issuecomment-1262298053
https://github.com/psi4/psi4/pull/2729#issuecomment-1260925688:1005,Performance,perform,performed,1005,"hat your background is, so I'm going to write this explanation at a level accessible for a first-year graduate student, though it will still be dense. Many matrices in electronic structure theory are indexed by two orbitals. Each orbital will change in a different way under symmetry operations of the molecule (like rotation, reflection), and we call each classification an irreducible representation (irrep). Now, our matrices further have the property that A_mn = 0 unless the symmetries of m and n are somehow related. Our matrix then only needs to store ""blocks"" where for all orbitals m of irreducible representation h, the only non-zero elements of A are A_mn where n is an orbital of irreducible representation i. Because we use this block structure, it isn't enough to make sure that the total dimensions of the matrix agree (what your code does). We need the dimensions of each symmetry block to agree on the three points mentioned in the original issue. This validation should be performed for each irreducible representation. For reference, the code that Susi linked does the following:; ```; for each irreducible representation of the first index of A, Ha:; 	Hb is the irreducible representation of the first index of the B block that can multiply with the A block; Hc is the irreducible representation of the first index of the new matrix (if we're multiplying by A, this is just Ha, otherwise this is the irreducible representation of the second index for the block with first index Ha); 	m is the number of orbitals with the irreducible representation for the first index in this block of the new matrix; 	n is the number of orbitals with the irreducible representation for the second index in this block of the new matrix; 	k is the number of orbitals with the irreducible representation for the second index in this block of A, which is also the number of orbitals with the irreducible representation for the first index in this block of B; 	lda is the number of columns of matrix A;",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2729#issuecomment-1260925688
https://github.com/psi4/psi4/pull/2729#issuecomment-1260925688:88,Security,access,accessible,88,"I don't know what your background is, so I'm going to write this explanation at a level accessible for a first-year graduate student, though it will still be dense. Many matrices in electronic structure theory are indexed by two orbitals. Each orbital will change in a different way under symmetry operations of the molecule (like rotation, reflection), and we call each classification an irreducible representation (irrep). Now, our matrices further have the property that A_mn = 0 unless the symmetries of m and n are somehow related. Our matrix then only needs to store ""blocks"" where for all orbitals m of irreducible representation h, the only non-zero elements of A are A_mn where n is an orbital of irreducible representation i. Because we use this block structure, it isn't enough to make sure that the total dimensions of the matrix agree (what your code does). We need the dimensions of each symmetry block to agree on the three points mentioned in the original issue. This validation should be performed for each irreducible representation. For reference, the code that Susi linked does the following:; ```; for each irreducible representation of the first index of A, Ha:; 	Hb is the irreducible representation of the first index of the B block that can multiply with the A block; Hc is the irreducible representation of the first index of the new matrix (if we're multiplying by A, this is just Ha, otherwise this is the irreducible representation of the second index for the block with first index Ha); 	m is the number of orbitals with the irreducible representation for the first index in this block of the new matrix; 	n is the number of orbitals with the irreducible representation for the second index in this block of the new matrix; 	k is the number of orbitals with the irreducible representation for the second index in this block of A, which is also the number of orbitals with the irreducible representation for the first index in this block of B; 	lda is the number of column",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2729#issuecomment-1260925688
https://github.com/psi4/psi4/pull/2729#issuecomment-1260925688:984,Security,validat,validation,984,"hat your background is, so I'm going to write this explanation at a level accessible for a first-year graduate student, though it will still be dense. Many matrices in electronic structure theory are indexed by two orbitals. Each orbital will change in a different way under symmetry operations of the molecule (like rotation, reflection), and we call each classification an irreducible representation (irrep). Now, our matrices further have the property that A_mn = 0 unless the symmetries of m and n are somehow related. Our matrix then only needs to store ""blocks"" where for all orbitals m of irreducible representation h, the only non-zero elements of A are A_mn where n is an orbital of irreducible representation i. Because we use this block structure, it isn't enough to make sure that the total dimensions of the matrix agree (what your code does). We need the dimensions of each symmetry block to agree on the three points mentioned in the original issue. This validation should be performed for each irreducible representation. For reference, the code that Susi linked does the following:; ```; for each irreducible representation of the first index of A, Ha:; 	Hb is the irreducible representation of the first index of the B block that can multiply with the A block; Hc is the irreducible representation of the first index of the new matrix (if we're multiplying by A, this is just Ha, otherwise this is the irreducible representation of the second index for the block with first index Ha); 	m is the number of orbitals with the irreducible representation for the first index in this block of the new matrix; 	n is the number of orbitals with the irreducible representation for the second index in this block of the new matrix; 	k is the number of orbitals with the irreducible representation for the second index in this block of A, which is also the number of orbitals with the irreducible representation for the first index in this block of B; 	lda is the number of columns of matrix A;",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2729#issuecomment-1260925688
https://github.com/psi4/psi4/pull/2729#issuecomment-1260925688:2177,Usability,simpl,simplified,2177,"fferent way under symmetry operations of the molecule (like rotation, reflection), and we call each classification an irreducible representation (irrep). Now, our matrices further have the property that A_mn = 0 unless the symmetries of m and n are somehow related. Our matrix then only needs to store ""blocks"" where for all orbitals m of irreducible representation h, the only non-zero elements of A are A_mn where n is an orbital of irreducible representation i. Because we use this block structure, it isn't enough to make sure that the total dimensions of the matrix agree (what your code does). We need the dimensions of each symmetry block to agree on the three points mentioned in the original issue. This validation should be performed for each irreducible representation. For reference, the code that Susi linked does the following:; ```; for each irreducible representation of the first index of A, Ha:; 	Hb is the irreducible representation of the first index of the B block that can multiply with the A block; Hc is the irreducible representation of the first index of the new matrix (if we're multiplying by A, this is just Ha, otherwise this is the irreducible representation of the second index for the block with first index Ha); 	m is the number of orbitals with the irreducible representation for the first index in this block of the new matrix; 	n is the number of orbitals with the irreducible representation for the second index in this block of the new matrix; 	k is the number of orbitals with the irreducible representation for the second index in this block of A, which is also the number of orbitals with the irreducible representation for the first index in this block of B; 	lda is the number of columns of matrix A; 	ldb is the number of columns of matrix B; 	ldc is the number of columns of matrix C; 	do the actual matrix multiplication; ```. BLAS savants will notice that I simplified the explanation of `lda`, `ldb`, and `ldc` because we can assume contiguous memory.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2729#issuecomment-1260925688
https://github.com/psi4/psi4/pull/2729#issuecomment-1261945010:2452,Modifiability,variab,variable,2452,"ix then only needs to store ""blocks"" where for all orbitals m of irreducible representation h, the only non-zero elements of A are A_mn where n is an orbital of irreducible representation i.; > ; > Because we use this block structure, it isn't enough to make sure that the total dimensions of the matrix agree (what your code does). We need the dimensions of each symmetry block to agree on the three points mentioned in the original issue. This validation should be performed for each irreducible representation.; > ; > For reference, the code that Susi linked does the following:; > ; > ```; > for each irreducible representation of the first index of A, Ha:; > 	Hb is the irreducible representation of the first index of the B block that can multiply with the A block; > Hc is the irreducible representation of the first index of the new matrix (if we're multiplying by A, this is just Ha, otherwise this is the irreducible representation of the second index for the block with first index Ha); > 	m is the number of orbitals with the irreducible representation for the first index in this block of the new matrix; > 	n is the number of orbitals with the irreducible representation for the second index in this block of the new matrix; > 	k is the number of orbitals with the irreducible representation for the second index in this block of A, which is also the number of orbitals with the irreducible representation for the first index in this block of B; > 	lda is the number of columns of matrix A; > 	ldb is the number of columns of matrix B; > 	ldc is the number of columns of matrix C; > 	do the actual matrix multiplication; > ```; > ; > BLAS savants will notice that I simplified the explanation of `lda`, `ldb`, and `ldc` because we can assume contiguous memory. Thanks for the explanation. I edited the program to check for each symmetry block. I'm not entirely sure how the symmetry_ variable works (and the xor involvement), but I mimicked how it was used in other parts of the method.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2729#issuecomment-1261945010
https://github.com/psi4/psi4/pull/2729#issuecomment-1261945010:1021,Performance,perform,performed,1021,"round is, so I'm going to write this explanation at a level accessible for a first-year graduate student, though it will still be dense.; > ; > Many matrices in electronic structure theory are indexed by two orbitals. Each orbital will change in a different way under symmetry operations of the molecule (like rotation, reflection), and we call each classification an irreducible representation (irrep). Now, our matrices further have the property that A_mn = 0 unless the symmetries of m and n are somehow related. Our matrix then only needs to store ""blocks"" where for all orbitals m of irreducible representation h, the only non-zero elements of A are A_mn where n is an orbital of irreducible representation i.; > ; > Because we use this block structure, it isn't enough to make sure that the total dimensions of the matrix agree (what your code does). We need the dimensions of each symmetry block to agree on the three points mentioned in the original issue. This validation should be performed for each irreducible representation.; > ; > For reference, the code that Susi linked does the following:; > ; > ```; > for each irreducible representation of the first index of A, Ha:; > 	Hb is the irreducible representation of the first index of the B block that can multiply with the A block; > Hc is the irreducible representation of the first index of the new matrix (if we're multiplying by A, this is just Ha, otherwise this is the irreducible representation of the second index for the block with first index Ha); > 	m is the number of orbitals with the irreducible representation for the first index in this block of the new matrix; > 	n is the number of orbitals with the irreducible representation for the second index in this block of the new matrix; > 	k is the number of orbitals with the irreducible representation for the second index in this block of A, which is also the number of orbitals with the irreducible representation for the first index in this block of B; > 	lda is the num",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2729#issuecomment-1261945010
https://github.com/psi4/psi4/pull/2729#issuecomment-1261945010:90,Security,access,accessible,90,"> I don't know what your background is, so I'm going to write this explanation at a level accessible for a first-year graduate student, though it will still be dense.; > ; > Many matrices in electronic structure theory are indexed by two orbitals. Each orbital will change in a different way under symmetry operations of the molecule (like rotation, reflection), and we call each classification an irreducible representation (irrep). Now, our matrices further have the property that A_mn = 0 unless the symmetries of m and n are somehow related. Our matrix then only needs to store ""blocks"" where for all orbitals m of irreducible representation h, the only non-zero elements of A are A_mn where n is an orbital of irreducible representation i.; > ; > Because we use this block structure, it isn't enough to make sure that the total dimensions of the matrix agree (what your code does). We need the dimensions of each symmetry block to agree on the three points mentioned in the original issue. This validation should be performed for each irreducible representation.; > ; > For reference, the code that Susi linked does the following:; > ; > ```; > for each irreducible representation of the first index of A, Ha:; > 	Hb is the irreducible representation of the first index of the B block that can multiply with the A block; > Hc is the irreducible representation of the first index of the new matrix (if we're multiplying by A, this is just Ha, otherwise this is the irreducible representation of the second index for the block with first index Ha); > 	m is the number of orbitals with the irreducible representation for the first index in this block of the new matrix; > 	n is the number of orbitals with the irreducible representation for the second index in this block of the new matrix; > 	k is the number of orbitals with the irreducible representation for the second index in this block of A, which is also the number of orbitals with the irreducible representation for the first index in this",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2729#issuecomment-1261945010
https://github.com/psi4/psi4/pull/2729#issuecomment-1261945010:1000,Security,validat,validation,1000,"round is, so I'm going to write this explanation at a level accessible for a first-year graduate student, though it will still be dense.; > ; > Many matrices in electronic structure theory are indexed by two orbitals. Each orbital will change in a different way under symmetry operations of the molecule (like rotation, reflection), and we call each classification an irreducible representation (irrep). Now, our matrices further have the property that A_mn = 0 unless the symmetries of m and n are somehow related. Our matrix then only needs to store ""blocks"" where for all orbitals m of irreducible representation h, the only non-zero elements of A are A_mn where n is an orbital of irreducible representation i.; > ; > Because we use this block structure, it isn't enough to make sure that the total dimensions of the matrix agree (what your code does). We need the dimensions of each symmetry block to agree on the three points mentioned in the original issue. This validation should be performed for each irreducible representation.; > ; > For reference, the code that Susi linked does the following:; > ; > ```; > for each irreducible representation of the first index of A, Ha:; > 	Hb is the irreducible representation of the first index of the B block that can multiply with the A block; > Hc is the irreducible representation of the first index of the new matrix (if we're multiplying by A, this is just Ha, otherwise this is the irreducible representation of the second index for the block with first index Ha); > 	m is the number of orbitals with the irreducible representation for the first index in this block of the new matrix; > 	n is the number of orbitals with the irreducible representation for the second index in this block of the new matrix; > 	k is the number of orbitals with the irreducible representation for the second index in this block of A, which is also the number of orbitals with the irreducible representation for the first index in this block of B; > 	lda is the num",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2729#issuecomment-1261945010
https://github.com/psi4/psi4/pull/2729#issuecomment-1261945010:2234,Usability,simpl,simplified,2234,"ix then only needs to store ""blocks"" where for all orbitals m of irreducible representation h, the only non-zero elements of A are A_mn where n is an orbital of irreducible representation i.; > ; > Because we use this block structure, it isn't enough to make sure that the total dimensions of the matrix agree (what your code does). We need the dimensions of each symmetry block to agree on the three points mentioned in the original issue. This validation should be performed for each irreducible representation.; > ; > For reference, the code that Susi linked does the following:; > ; > ```; > for each irreducible representation of the first index of A, Ha:; > 	Hb is the irreducible representation of the first index of the B block that can multiply with the A block; > Hc is the irreducible representation of the first index of the new matrix (if we're multiplying by A, this is just Ha, otherwise this is the irreducible representation of the second index for the block with first index Ha); > 	m is the number of orbitals with the irreducible representation for the first index in this block of the new matrix; > 	n is the number of orbitals with the irreducible representation for the second index in this block of the new matrix; > 	k is the number of orbitals with the irreducible representation for the second index in this block of A, which is also the number of orbitals with the irreducible representation for the first index in this block of B; > 	lda is the number of columns of matrix A; > 	ldb is the number of columns of matrix B; > 	ldc is the number of columns of matrix C; > 	do the actual matrix multiplication; > ```; > ; > BLAS savants will notice that I simplified the explanation of `lda`, `ldb`, and `ldc` because we can assume contiguous memory. Thanks for the explanation. I edited the program to check for each symmetry block. I'm not entirely sure how the symmetry_ variable works (and the xor involvement), but I mimicked how it was used in other parts of the method.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2729#issuecomment-1261945010
https://github.com/psi4/psi4/pull/2729#issuecomment-1262315350:480,Availability,error,error,480,"Thanks for this!. Mimicking is the right thing to do here. We encode irreducible representations into bitstring so that the nonzero blocks of our matrix are exactly those with the property `row_irrep ^ col_irrep ^ symmetry_ = 0`. As a consequence, `A ^ B = C`. The check itself looks correct to me, and this is a huge improvement. For the sake of debug information, I'm tempted to ask for calls to `rowspi().print()` and `colspi().print` on all three matrices involved before the error message appears. I'd also like if the error message included the symmetries of all three matrices and the particular Ha that created the problem. Susi, what do you think?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2729#issuecomment-1262315350
https://github.com/psi4/psi4/pull/2729#issuecomment-1262315350:524,Availability,error,error,524,"Thanks for this!. Mimicking is the right thing to do here. We encode irreducible representations into bitstring so that the nonzero blocks of our matrix are exactly those with the property `row_irrep ^ col_irrep ^ symmetry_ = 0`. As a consequence, `A ^ B = C`. The check itself looks correct to me, and this is a huge improvement. For the sake of debug information, I'm tempted to ask for calls to `rowspi().print()` and `colspi().print` on all three matrices involved before the error message appears. I'd also like if the error message included the symmetries of all three matrices and the particular Ha that created the problem. Susi, what do you think?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2729#issuecomment-1262315350
https://github.com/psi4/psi4/pull/2729#issuecomment-1262315350:486,Integrability,message,message,486,"Thanks for this!. Mimicking is the right thing to do here. We encode irreducible representations into bitstring so that the nonzero blocks of our matrix are exactly those with the property `row_irrep ^ col_irrep ^ symmetry_ = 0`. As a consequence, `A ^ B = C`. The check itself looks correct to me, and this is a huge improvement. For the sake of debug information, I'm tempted to ask for calls to `rowspi().print()` and `colspi().print` on all three matrices involved before the error message appears. I'd also like if the error message included the symmetries of all three matrices and the particular Ha that created the problem. Susi, what do you think?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2729#issuecomment-1262315350
https://github.com/psi4/psi4/pull/2729#issuecomment-1262315350:530,Integrability,message,message,530,"Thanks for this!. Mimicking is the right thing to do here. We encode irreducible representations into bitstring so that the nonzero blocks of our matrix are exactly those with the property `row_irrep ^ col_irrep ^ symmetry_ = 0`. As a consequence, `A ^ B = C`. The check itself looks correct to me, and this is a huge improvement. For the sake of debug information, I'm tempted to ask for calls to `rowspi().print()` and `colspi().print` on all three matrices involved before the error message appears. I'd also like if the error message included the symmetries of all three matrices and the particular Ha that created the problem. Susi, what do you think?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2729#issuecomment-1262315350
https://github.com/psi4/psi4/pull/2729#issuecomment-1262451178:377,Availability,error,error,377,"@JonathonMisiewicz please tag me next time ;). The check should be human readable. Please declare new variables for all of the results of the ternary operations. If I were to write a size check for a matrix multiply of `C(m,n) = A(m,k) B(k,n)`, I would write the check something along the lines of `if((m_in != m_out) || (n_in != n_out) || (k1 != k2))`. And yes, in case of an error, one should print out the dimensions of all three matrices.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2729#issuecomment-1262451178
https://github.com/psi4/psi4/pull/2729#issuecomment-1262451178:102,Modifiability,variab,variables,102,"@JonathonMisiewicz please tag me next time ;). The check should be human readable. Please declare new variables for all of the results of the ternary operations. If I were to write a size check for a matrix multiply of `C(m,n) = A(m,k) B(k,n)`, I would write the check something along the lines of `if((m_in != m_out) || (n_in != n_out) || (k1 != k2))`. And yes, in case of an error, one should print out the dimensions of all three matrices.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2729#issuecomment-1262451178
https://github.com/psi4/psi4/pull/2729#issuecomment-1267125697:253,Deployability,update,update,253,"> The pull has been corrupted with extraneous changes. You're welcome to heal the git history by whatever procedure seems best to you. But if you don't know what that might be, you could do a fresh clone from master locally, set up origin and upstream, update it to psi4/psi4:master (`git pull --rebase upstream master`), check out a new branch (`git checkout -b matsizecheck`), edit just your one function in `matrix.cc`, commit that, then *force push* to the branch associated with this PR. So assuming `git remote -v` has `origin` pointing to GH:aquaticseatard/psi4 and `upstream` pointing to GH:psi4/psi4, then you'd `git push origin matsizecheck:master --force`. That will return this PR to one commit of just your changes. (Note that if you did the previous command without the `--force`, git would complain about history and suggest you pull. Pulling here is fatal and the cause of the history contamination. You *want* to overwrite history. It's fine as it's only your own, not a shared, branch.)",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2729#issuecomment-1267125697
https://github.com/psi4/psi4/issues/2730#issuecomment-1261263392:77,Usability,clear,clear,77,"Can you include a minimal reproducible example, even a water dimer? It isn't clear to me what this code that is acting unexpectedly looks like.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2730#issuecomment-1261263392
https://github.com/psi4/psi4/pull/2731#issuecomment-1262298899:99,Testability,test,tests,99,"Is there anything in particular you wanted feedback on, or did you just want to see if this passed tests?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2731#issuecomment-1262298899
https://github.com/psi4/psi4/pull/2731#issuecomment-1262298899:43,Usability,feedback,feedback,43,"Is there anything in particular you wanted feedback on, or did you just want to see if this passed tests?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2731#issuecomment-1262298899
https://github.com/psi4/psi4/pull/2731#issuecomment-1271707869:33,Testability,test,tests,33,I can re-review when this passes tests.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2731#issuecomment-1271707869
https://github.com/psi4/psi4/pull/2731#issuecomment-1271737513:0,Testability,Test,Tests,0,Tests failing because a typing Any import missing. I was going to fix when other changes accumulate.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2731#issuecomment-1271737513
https://github.com/psi4/psi4/pull/2734#issuecomment-1268821483:1393,Integrability,Message,Message,1393,"Cool! I noticed ""The extension to higher symmetries does not seem; promising, however."" That looks pretty solid given that it's 2022 and we; still don't do it!. On Wed, Oct 5, 2022 at 1:37 PM Jonathon Misiewicz ***@***.***>; wrote:. > ***@***.**** commented on this pull request.; > ------------------------------; >; > In psi4/src/psi4/libmints/matrix.cc; > <https://github.com/psi4/psi4/pull/2734#discussion_r988229382>:; >; > > for (int p = 0; p < max_p; p++) {; > for (int q = 0; q < max_q; q++) {; > double value = block.get(h, p, q);; > - set(h, p + rows_begin[h], q + cols_begin[h], value);; > + set(h, p + rows_begin[h], q + cols_begin[h ^ symmetry_], value);; >; > That traces back to the MOLECULE code. See Section 4 of this report that; > TDC has saved; > <https://drive.google.com/file/d/1VtVpwvaleR1FF1hm2LchS2SQZ8_RHsJA/view>.; > Molecule - A Program System for Non-Empirical Calculation of the Electronic; > Structure of Molecules II. Integral Section. University of Stockholm; > Institute of Physics Report 74 - 29, December 1974.; >; > Hat tip to TDC for remembering this.; >; > ; > Reply to this email directly, view it on GitHub; > <https://github.com/psi4/psi4/pull/2734#discussion_r988229382>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AA4C4TBLGWXR5H5YZ7IKZATWBXDHRANCNFSM6AAAAAAQ32VGSQ>; > .; > You are receiving this because you commented.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2734#issuecomment-1268821483
https://github.com/psi4/psi4/issues/2735#issuecomment-1267612768:198,Security,access,accessed,198,"In the slightly modified codebase I work off of -- I flipped the `[]` to a `.at()` and tests now fail due to `std::out_of_range`, as expected, given that the map is starting and staying empty until accessed.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2735#issuecomment-1267612768
https://github.com/psi4/psi4/issues/2735#issuecomment-1267612768:87,Testability,test,tests,87,"In the slightly modified codebase I work off of -- I flipped the `[]` to a `.at()` and tests now fail due to `std::out_of_range`, as expected, given that the map is starting and staying empty until accessed.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2735#issuecomment-1267612768
https://github.com/psi4/psi4/issues/2735#issuecomment-1267804371:638,Deployability,patch,patch,638,"Building from ToT in conda at home, I can confirm that `initialize_lebedev` in fact is never called... it's optimized straight out of the code! (I couldn't find anywhere where it got called, so I am not surprised). ```; (base) liz@Gaston:~/Development/psi4/objdir/stage/tests$ nm ../lib/psi4/core.cpython-38-x86_64-linux-gnu.so | grep lebedev; 00000000020dbe80 b _ZN3psi13SphericalGrid16lebedev_mapping_E; ```. Doing the same breakpoint tests using the line-numbers in ToT cubature.cc, I can also see that `initialize_lebedev` is never called, and `lebedev_mapping_` ends up with no entries in it when it's first accessed. Will work on a patch now.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2735#issuecomment-1267804371
https://github.com/psi4/psi4/issues/2735#issuecomment-1267804371:108,Performance,optimiz,optimized,108,"Building from ToT in conda at home, I can confirm that `initialize_lebedev` in fact is never called... it's optimized straight out of the code! (I couldn't find anywhere where it got called, so I am not surprised). ```; (base) liz@Gaston:~/Development/psi4/objdir/stage/tests$ nm ../lib/psi4/core.cpython-38-x86_64-linux-gnu.so | grep lebedev; 00000000020dbe80 b _ZN3psi13SphericalGrid16lebedev_mapping_E; ```. Doing the same breakpoint tests using the line-numbers in ToT cubature.cc, I can also see that `initialize_lebedev` is never called, and `lebedev_mapping_` ends up with no entries in it when it's first accessed. Will work on a patch now.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2735#issuecomment-1267804371
https://github.com/psi4/psi4/issues/2735#issuecomment-1267804371:613,Security,access,accessed,613,"Building from ToT in conda at home, I can confirm that `initialize_lebedev` in fact is never called... it's optimized straight out of the code! (I couldn't find anywhere where it got called, so I am not surprised). ```; (base) liz@Gaston:~/Development/psi4/objdir/stage/tests$ nm ../lib/psi4/core.cpython-38-x86_64-linux-gnu.so | grep lebedev; 00000000020dbe80 b _ZN3psi13SphericalGrid16lebedev_mapping_E; ```. Doing the same breakpoint tests using the line-numbers in ToT cubature.cc, I can also see that `initialize_lebedev` is never called, and `lebedev_mapping_` ends up with no entries in it when it's first accessed. Will work on a patch now.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2735#issuecomment-1267804371
https://github.com/psi4/psi4/issues/2735#issuecomment-1267804371:270,Testability,test,tests,270,"Building from ToT in conda at home, I can confirm that `initialize_lebedev` in fact is never called... it's optimized straight out of the code! (I couldn't find anywhere where it got called, so I am not surprised). ```; (base) liz@Gaston:~/Development/psi4/objdir/stage/tests$ nm ../lib/psi4/core.cpython-38-x86_64-linux-gnu.so | grep lebedev; 00000000020dbe80 b _ZN3psi13SphericalGrid16lebedev_mapping_E; ```. Doing the same breakpoint tests using the line-numbers in ToT cubature.cc, I can also see that `initialize_lebedev` is never called, and `lebedev_mapping_` ends up with no entries in it when it's first accessed. Will work on a patch now.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2735#issuecomment-1267804371
https://github.com/psi4/psi4/issues/2735#issuecomment-1267804371:437,Testability,test,tests,437,"Building from ToT in conda at home, I can confirm that `initialize_lebedev` in fact is never called... it's optimized straight out of the code! (I couldn't find anywhere where it got called, so I am not surprised). ```; (base) liz@Gaston:~/Development/psi4/objdir/stage/tests$ nm ../lib/psi4/core.cpython-38-x86_64-linux-gnu.so | grep lebedev; 00000000020dbe80 b _ZN3psi13SphericalGrid16lebedev_mapping_E; ```. Doing the same breakpoint tests using the line-numbers in ToT cubature.cc, I can also see that `initialize_lebedev` is never called, and `lebedev_mapping_` ends up with no entries in it when it's first accessed. Will work on a patch now.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2735#issuecomment-1267804371
https://github.com/psi4/psi4/issues/2735#issuecomment-1267820055:9,Deployability,patch,patch,9,"I have a patch written -- I can see that `initialize_lebedev` actually gets called, and when I inspect `lebedev_mapping_`'s values at a breakpoint, things look reasonable. ...I also see no changes in the energy anywhere. In fact, I don't see any evidence of any use of `order_` at all, except in one printing function. Is this intentional? . Anyway, PR incoming. I am OK not understanding the mysteries of `order_`, as long as I no longer get 1/1000 hangs when trying to run large workflows.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2735#issuecomment-1267820055
https://github.com/psi4/psi4/issues/2735#issuecomment-1267820055:204,Energy Efficiency,energy,energy,204,"I have a patch written -- I can see that `initialize_lebedev` actually gets called, and when I inspect `lebedev_mapping_`'s values at a breakpoint, things look reasonable. ...I also see no changes in the energy anywhere. In fact, I don't see any evidence of any use of `order_` at all, except in one printing function. Is this intentional? . Anyway, PR incoming. I am OK not understanding the mysteries of `order_`, as long as I no longer get 1/1000 hangs when trying to run large workflows.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2735#issuecomment-1267820055
https://github.com/psi4/psi4/pull/2736#issuecomment-1268452077:220,Safety,avoid,avoid-c,220,"Thanks for the thorough report and fix. The seemingly extra declaration @susilehtola pointed out confused me, too, though perhaps https://stackoverflow.com/a/17392441 is the answer. The map looks to be from the boost-to-avoid-c++11-standard era, so it could be improved (https://github.com/psi4/psi4archive/blame/1.0.x/src/lib/libfock/cubature.h#L302).",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2736#issuecomment-1268452077
https://github.com/psi4/psi4/pull/2736#issuecomment-1268457086:481,Availability,down,downstream,481,"The ""other"" lebedev_mapping_: That's just the declaration for it. The problem is that `SphericalGrid::build` is a _static_ method so the; constructor isn't called when that happens. Someone might yank out the; `new` there and still statically access `lebedev_mapping_` and we are back; where we started. There's no guarantee of construction, so I stapled it; into the one place it's actually used. (And, again, I don't understand why it's used at all as it never seems to; show up downstream). Even if it was in the constructor though (which would fire on the _new_) it; would still need the mutex to ensure it's initialized once as; lebedev_mapping_ is also (purposefully) static. No sense doing the rebuild; of the map on every single object instantiation. On Wed, Oct 5, 2022, 4:59 AM Susi Lehtola ***@***.***> wrote:. > lebedev_mapping_ is a member of SphericalGrid, so initialize_lebedev(); > should be called in the constructor of SphericalGrid. No need to add; > mutexes etc.; >; > More worryingly, I also see another lebedev_mapping_ in cubature.cc; >; > https://github.com/psi4/psi4/blob/ac8f87a1dd3fdda2aabc3318713d6e5ce00e2c70/psi4/src/psi4/libfock/cubature.cc#L5065; >; > ; > Reply to this email directly, view it on GitHub; > <https://github.com/psi4/psi4/pull/2736#issuecomment-1268150804>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ABTN7JCEAMFQBY2H6OKMPYLWBU7NRANCNFSM6AAAAAAQ5DTWOY>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2736#issuecomment-1268457086
https://github.com/psi4/psi4/pull/2736#issuecomment-1268457086:1493,Integrability,Message,Message,1493,"The ""other"" lebedev_mapping_: That's just the declaration for it. The problem is that `SphericalGrid::build` is a _static_ method so the; constructor isn't called when that happens. Someone might yank out the; `new` there and still statically access `lebedev_mapping_` and we are back; where we started. There's no guarantee of construction, so I stapled it; into the one place it's actually used. (And, again, I don't understand why it's used at all as it never seems to; show up downstream). Even if it was in the constructor though (which would fire on the _new_) it; would still need the mutex to ensure it's initialized once as; lebedev_mapping_ is also (purposefully) static. No sense doing the rebuild; of the map on every single object instantiation. On Wed, Oct 5, 2022, 4:59 AM Susi Lehtola ***@***.***> wrote:. > lebedev_mapping_ is a member of SphericalGrid, so initialize_lebedev(); > should be called in the constructor of SphericalGrid. No need to add; > mutexes etc.; >; > More worryingly, I also see another lebedev_mapping_ in cubature.cc; >; > https://github.com/psi4/psi4/blob/ac8f87a1dd3fdda2aabc3318713d6e5ce00e2c70/psi4/src/psi4/libfock/cubature.cc#L5065; >; > ; > Reply to this email directly, view it on GitHub; > <https://github.com/psi4/psi4/pull/2736#issuecomment-1268150804>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ABTN7JCEAMFQBY2H6OKMPYLWBU7NRANCNFSM6AAAAAAQ5DTWOY>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2736#issuecomment-1268457086
https://github.com/psi4/psi4/pull/2736#issuecomment-1268457086:243,Security,access,access,243,"The ""other"" lebedev_mapping_: That's just the declaration for it. The problem is that `SphericalGrid::build` is a _static_ method so the; constructor isn't called when that happens. Someone might yank out the; `new` there and still statically access `lebedev_mapping_` and we are back; where we started. There's no guarantee of construction, so I stapled it; into the one place it's actually used. (And, again, I don't understand why it's used at all as it never seems to; show up downstream). Even if it was in the constructor though (which would fire on the _new_) it; would still need the mutex to ensure it's initialized once as; lebedev_mapping_ is also (purposefully) static. No sense doing the rebuild; of the map on every single object instantiation. On Wed, Oct 5, 2022, 4:59 AM Susi Lehtola ***@***.***> wrote:. > lebedev_mapping_ is a member of SphericalGrid, so initialize_lebedev(); > should be called in the constructor of SphericalGrid. No need to add; > mutexes etc.; >; > More worryingly, I also see another lebedev_mapping_ in cubature.cc; >; > https://github.com/psi4/psi4/blob/ac8f87a1dd3fdda2aabc3318713d6e5ce00e2c70/psi4/src/psi4/libfock/cubature.cc#L5065; >; > ; > Reply to this email directly, view it on GitHub; > <https://github.com/psi4/psi4/pull/2736#issuecomment-1268150804>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ABTN7JCEAMFQBY2H6OKMPYLWBU7NRANCNFSM6AAAAAAQ5DTWOY>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2736#issuecomment-1268457086
https://github.com/psi4/psi4/pull/2736#issuecomment-1268606002:266,Safety,avoid,avoid,266,"The initialization code is pretty simple, however. One could just replace the `initialize_lebedev` function by an initializer list in https://github.com/psi4/psi4/blob/ac8f87a1dd3fdda2aabc3318713d6e5ce00e2c70/psi4/src/psi4/libfock/cubature.cc#L5065; This would also avoid the need for the mutexes. . The code is hacky also elsewhere; `lebedev_error` duplicates the same information. For what it's worth, I will be developing a general C++ Becke quadrature library that would eliminate these parts of the code.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2736#issuecomment-1268606002
https://github.com/psi4/psi4/pull/2736#issuecomment-1268606002:34,Usability,simpl,simple,34,"The initialization code is pretty simple, however. One could just replace the `initialize_lebedev` function by an initializer list in https://github.com/psi4/psi4/blob/ac8f87a1dd3fdda2aabc3318713d6e5ce00e2c70/psi4/src/psi4/libfock/cubature.cc#L5065; This would also avoid the need for the mutexes. . The code is hacky also elsewhere; `lebedev_error` duplicates the same information. For what it's worth, I will be developing a general C++ Becke quadrature library that would eliminate these parts of the code.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2736#issuecomment-1268606002
https://github.com/psi4/psi4/pull/2736#issuecomment-1268644487:1452,Security,access,accessible,1452,"I will admit I considered that, then decided I didn't want to reformat the map into the initializer because it was long and I was lazy. My bigger concern is still: what was the consequence of `order_` being incorrectly 0 for so long, and who actually uses this property up-stream? The git commit where this was added says `Hack DFT grids to retain indexing data for ISA` but the only files touched were:. ```; src/lib/libfock/cubature.cc.REMOVED.git-id; src/lib/libfock/cubature.h; src/lib/libfock/gridblocker.h; ```. And I can't find anywhere that seems to use `order_` or the `order()` method of `SphericalGrid`. . Unfortunately, trying to look further back in the history of `cubature.cc` results in several instances of `psi4/src/psi4/libfock/cubature.cc.REMOVED.git-id` which (I think?) means things were stripped from the repo at some point, and the resulting commit stuff is all assigned to the wrong person (e.g., nearly `all` of `cubature.cc` is assigned to one commit 7e4ecf968e from dgasmith). `print_details` is the only place the `spherical_grids_` are ever apparently used, and I can comment out the block where they print nicely. _That_ function is only ever used in `v.cc` and only if `print_ > 2`. I don't think this is used much, and is creating unnecessary complexity, and doesn't feature in any tests I can find. I'm running through tests now to see if just... removing this entirely breaks anything. Short of `print_details` being accessible through some print settings, it doesn't appear that any of this is even exposed on the python side anyway?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2736#issuecomment-1268644487
https://github.com/psi4/psi4/pull/2736#issuecomment-1268644487:1535,Security,expose,exposed,1535,"I will admit I considered that, then decided I didn't want to reformat the map into the initializer because it was long and I was lazy. My bigger concern is still: what was the consequence of `order_` being incorrectly 0 for so long, and who actually uses this property up-stream? The git commit where this was added says `Hack DFT grids to retain indexing data for ISA` but the only files touched were:. ```; src/lib/libfock/cubature.cc.REMOVED.git-id; src/lib/libfock/cubature.h; src/lib/libfock/gridblocker.h; ```. And I can't find anywhere that seems to use `order_` or the `order()` method of `SphericalGrid`. . Unfortunately, trying to look further back in the history of `cubature.cc` results in several instances of `psi4/src/psi4/libfock/cubature.cc.REMOVED.git-id` which (I think?) means things were stripped from the repo at some point, and the resulting commit stuff is all assigned to the wrong person (e.g., nearly `all` of `cubature.cc` is assigned to one commit 7e4ecf968e from dgasmith). `print_details` is the only place the `spherical_grids_` are ever apparently used, and I can comment out the block where they print nicely. _That_ function is only ever used in `v.cc` and only if `print_ > 2`. I don't think this is used much, and is creating unnecessary complexity, and doesn't feature in any tests I can find. I'm running through tests now to see if just... removing this entirely breaks anything. Short of `print_details` being accessible through some print settings, it doesn't appear that any of this is even exposed on the python side anyway?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2736#issuecomment-1268644487
https://github.com/psi4/psi4/pull/2736#issuecomment-1268644487:1315,Testability,test,tests,1315,"I will admit I considered that, then decided I didn't want to reformat the map into the initializer because it was long and I was lazy. My bigger concern is still: what was the consequence of `order_` being incorrectly 0 for so long, and who actually uses this property up-stream? The git commit where this was added says `Hack DFT grids to retain indexing data for ISA` but the only files touched were:. ```; src/lib/libfock/cubature.cc.REMOVED.git-id; src/lib/libfock/cubature.h; src/lib/libfock/gridblocker.h; ```. And I can't find anywhere that seems to use `order_` or the `order()` method of `SphericalGrid`. . Unfortunately, trying to look further back in the history of `cubature.cc` results in several instances of `psi4/src/psi4/libfock/cubature.cc.REMOVED.git-id` which (I think?) means things were stripped from the repo at some point, and the resulting commit stuff is all assigned to the wrong person (e.g., nearly `all` of `cubature.cc` is assigned to one commit 7e4ecf968e from dgasmith). `print_details` is the only place the `spherical_grids_` are ever apparently used, and I can comment out the block where they print nicely. _That_ function is only ever used in `v.cc` and only if `print_ > 2`. I don't think this is used much, and is creating unnecessary complexity, and doesn't feature in any tests I can find. I'm running through tests now to see if just... removing this entirely breaks anything. Short of `print_details` being accessible through some print settings, it doesn't appear that any of this is even exposed on the python side anyway?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2736#issuecomment-1268644487
https://github.com/psi4/psi4/pull/2736#issuecomment-1268644487:1353,Testability,test,tests,1353,"I will admit I considered that, then decided I didn't want to reformat the map into the initializer because it was long and I was lazy. My bigger concern is still: what was the consequence of `order_` being incorrectly 0 for so long, and who actually uses this property up-stream? The git commit where this was added says `Hack DFT grids to retain indexing data for ISA` but the only files touched were:. ```; src/lib/libfock/cubature.cc.REMOVED.git-id; src/lib/libfock/cubature.h; src/lib/libfock/gridblocker.h; ```. And I can't find anywhere that seems to use `order_` or the `order()` method of `SphericalGrid`. . Unfortunately, trying to look further back in the history of `cubature.cc` results in several instances of `psi4/src/psi4/libfock/cubature.cc.REMOVED.git-id` which (I think?) means things were stripped from the repo at some point, and the resulting commit stuff is all assigned to the wrong person (e.g., nearly `all` of `cubature.cc` is assigned to one commit 7e4ecf968e from dgasmith). `print_details` is the only place the `spherical_grids_` are ever apparently used, and I can comment out the block where they print nicely. _That_ function is only ever used in `v.cc` and only if `print_ > 2`. I don't think this is used much, and is creating unnecessary complexity, and doesn't feature in any tests I can find. I'm running through tests now to see if just... removing this entirely breaks anything. Short of `print_details` being accessible through some print settings, it doesn't appear that any of this is even exposed on the python side anyway?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2736#issuecomment-1268644487
https://github.com/psi4/psi4/pull/2736#issuecomment-1268651045:121,Security,access,accessible,121,"> I'm running through tests now to see if just... removing this entirely breaks anything. Short of `print_details` being accessible through some print settings, it doesn't appear that any of this is even exposed on the python side anyway?. Haha yes spaghetti code!",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2736#issuecomment-1268651045
https://github.com/psi4/psi4/pull/2736#issuecomment-1268651045:204,Security,expose,exposed,204,"> I'm running through tests now to see if just... removing this entirely breaks anything. Short of `print_details` being accessible through some print settings, it doesn't appear that any of this is even exposed on the python side anyway?. Haha yes spaghetti code!",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2736#issuecomment-1268651045
https://github.com/psi4/psi4/pull/2736#issuecomment-1268651045:22,Testability,test,tests,22,"> I'm running through tests now to see if just... removing this entirely breaks anything. Short of `print_details` being accessible through some print settings, it doesn't appear that any of this is even exposed on the python side anyway?. Haha yes spaghetti code!",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2736#issuecomment-1268651045
https://github.com/psi4/psi4/pull/2736#issuecomment-1268675957:221,Deployability,Patch,Patch,221,"```; 100% tests passed, 0 tests failed out of 520; ```. > The original coder probably added it _anticipating_ it would be useful, but it seems to have never been used. I'm happy to see unused code burn. Burn, baby, burn. Patch incoming...",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2736#issuecomment-1268675957
https://github.com/psi4/psi4/pull/2736#issuecomment-1268675957:10,Testability,test,tests,10,"```; 100% tests passed, 0 tests failed out of 520; ```. > The original coder probably added it _anticipating_ it would be useful, but it seems to have never been used. I'm happy to see unused code burn. Burn, baby, burn. Patch incoming...",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2736#issuecomment-1268675957
https://github.com/psi4/psi4/pull/2736#issuecomment-1268675957:26,Testability,test,tests,26,"```; 100% tests passed, 0 tests failed out of 520; ```. > The original coder probably added it _anticipating_ it would be useful, but it seems to have never been used. I'm happy to see unused code burn. Burn, baby, burn. Patch incoming...",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2736#issuecomment-1268675957
https://github.com/psi4/psi4/pull/2736#issuecomment-1268691244:76,Testability,test,tests,76,"`RadialGrid` also looks ripe for burning -- smoketests passed, running full tests now.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2736#issuecomment-1268691244
https://github.com/psi4/psi4/pull/2736#issuecomment-1268757384:6,Testability,test,tests,6,"`100% tests passed, 0 tests failed out of 520`. Shipping it.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2736#issuecomment-1268757384
https://github.com/psi4/psi4/pull/2736#issuecomment-1268757384:22,Testability,test,tests,22,"`100% tests passed, 0 tests failed out of 520`. Shipping it.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2736#issuecomment-1268757384
https://github.com/psi4/psi4/pull/2736#issuecomment-1270690643:253,Testability,test,test,253,"I *think* I have a version that maintains the nice printing functionality (and shoves the necessary info into a struct, and actually uses the nicer `LebedevGridMgr::findOrderByNPoints` function and other `LebedevGridMgr` functions) but I can't actually test if this builds until I get home due to #reasons. I'll shove it upstream on my local branch and see if it breaks in the test builder.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2736#issuecomment-1270690643
https://github.com/psi4/psi4/pull/2736#issuecomment-1270690643:377,Testability,test,test,377,"I *think* I have a version that maintains the nice printing functionality (and shoves the necessary info into a struct, and actually uses the nicer `LebedevGridMgr::findOrderByNPoints` function and other `LebedevGridMgr` functions) but I can't actually test if this builds until I get home due to #reasons. I'll shove it upstream on my local branch and see if it breaks in the test builder.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2736#issuecomment-1270690643
https://github.com/psi4/psi4/pull/2736#issuecomment-1270784896:0,Usability,Clear,Clearly,0,Clearly I can't get this working right now and I won't be able to touch this from a useful computer until tomorrow. Sorry.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2736#issuecomment-1270784896
https://github.com/psi4/psi4/pull/2736#issuecomment-1271938459:92,Availability,error,error,92,"I now have a version that compiles at home, though I'm not getting the narrowing warning-as-error that the auto-builder is. Still I've patched for it. This *should work* now...",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2736#issuecomment-1271938459
https://github.com/psi4/psi4/pull/2736#issuecomment-1271938459:135,Deployability,patch,patched,135,"I now have a version that compiles at home, though I'm not getting the narrowing warning-as-error that the auto-builder is. Still I've patched for it. This *should work* now...",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2736#issuecomment-1271938459
https://github.com/psi4/psi4/pull/2736#issuecomment-1273725391:239,Availability,down,down,239,"I've made a new PR #2743 to JUST fix the hang bug, and then we can keep bikeshedding here on what we actually want to do about `RadialGrid` and `SphericalGrid` but have a fix in the codebase that actually stops the nasty hang that took me down this rabbit hole in the first place. - @susilehtola this initializes with an initializer list like you requested; - @hokru this loses NO information over the prior state-of-the-world like you suggested was desirable (if I was reading correctly); - @JonathonMisiewicz I guess you won't like it because spaghetti didn't go away but it's short and sweet, at least. Obviously this patch would undo all of that patch but I think the scope of this discussion exceeded the original PR statement.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2736#issuecomment-1273725391
https://github.com/psi4/psi4/pull/2736#issuecomment-1273725391:621,Deployability,patch,patch,621,"I've made a new PR #2743 to JUST fix the hang bug, and then we can keep bikeshedding here on what we actually want to do about `RadialGrid` and `SphericalGrid` but have a fix in the codebase that actually stops the nasty hang that took me down this rabbit hole in the first place. - @susilehtola this initializes with an initializer list like you requested; - @hokru this loses NO information over the prior state-of-the-world like you suggested was desirable (if I was reading correctly); - @JonathonMisiewicz I guess you won't like it because spaghetti didn't go away but it's short and sweet, at least. Obviously this patch would undo all of that patch but I think the scope of this discussion exceeded the original PR statement.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2736#issuecomment-1273725391
https://github.com/psi4/psi4/pull/2736#issuecomment-1273725391:650,Deployability,patch,patch,650,"I've made a new PR #2743 to JUST fix the hang bug, and then we can keep bikeshedding here on what we actually want to do about `RadialGrid` and `SphericalGrid` but have a fix in the codebase that actually stops the nasty hang that took me down this rabbit hole in the first place. - @susilehtola this initializes with an initializer list like you requested; - @hokru this loses NO information over the prior state-of-the-world like you suggested was desirable (if I was reading correctly); - @JonathonMisiewicz I guess you won't like it because spaghetti didn't go away but it's short and sweet, at least. Obviously this patch would undo all of that patch but I think the scope of this discussion exceeded the original PR statement.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2736#issuecomment-1273725391
https://github.com/psi4/psi4/pull/2736#issuecomment-1273725391:633,Usability,undo,undo,633,"I've made a new PR #2743 to JUST fix the hang bug, and then we can keep bikeshedding here on what we actually want to do about `RadialGrid` and `SphericalGrid` but have a fix in the codebase that actually stops the nasty hang that took me down this rabbit hole in the first place. - @susilehtola this initializes with an initializer list like you requested; - @hokru this loses NO information over the prior state-of-the-world like you suggested was desirable (if I was reading correctly); - @JonathonMisiewicz I guess you won't like it because spaghetti didn't go away but it's short and sweet, at least. Obviously this patch would undo all of that patch but I think the scope of this discussion exceeded the original PR statement.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2736#issuecomment-1273725391
https://github.com/psi4/psi4/pull/2736#issuecomment-1275079300:53,Usability,clear,cleared,53,"Thanks for getting the most important part of the PR cleared away. As far as I can see, the next steps are:; 1. Fix the merge conflicts (annoying rebase); 2. Determine what information in `print_details` is actually used. I want to retain print information that is actually used, but I can do away with the rest. Once we have that, we can assess if keeping a modified `RadialGrid` is the best way to keep the useful print information. (I think we've established that `r` and `wr` are used, but `order` is not?). This part of the code is not pretty, and I commend you for dealing with it at all.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2736#issuecomment-1275079300
https://github.com/psi4/psi4/pull/2736#issuecomment-1275116304:956,Availability,down,downstream,956,"> 1. Fix the merge conflicts (annoying rebase). I'm not sure how much rebasing you want to do, but I think things are back to the state-of-the-world that we were discussing prior to #2743 . > 2. Determine what information in `print_details` is actually used. I want to retain print information that is actually used, but I can do away with the rest. Once we have that, we can assess if keeping a modified `RadialGrid` is the best way to keep the useful print information. (I think we've established that `r` and `wr` are used, but `order` is not?). ""Used"" is a funny word here. No tests when this print is removed, so it's not _so_ important that someone wrote a test to preserve it. Furthermore, the `order_` was _always_ wrong. The other elements weren't, though, but you have to set a pretty high print level to actually see anything (`v.cc` requires `print_ > 2`). . If by ""used"" you mean that the piece of information represented in the print is used downstream: `r` and `wr` are the primary candidates here. That said, they aren't used as-is -- they're dotted through other elements found by a lookup in `LebedevGridMgr` and `RadialGridMgr` to make `MassPoints` (see https://github.com/psi4/psi4/blob/9db9100564eaef5d02c952817a73c397db9d657b/psi4/src/psi4/libfock/cubature.cc#L3814-L3822). I'm not sure if we care about diagnostic print info on the intermediaries (the radii of shells around atoms we care about, and the number of angular points we end up picking for each shell). Maybe we do? If so, a struct seems like the most reasonable solution. I suppose, all-in-all, it's not so much data to carry around. Appending that data onto every `MassPoint` however feels like overkill (and that's the only other place to put it). . But we definitely should clean up/remove the rest of the old `RadialGrid` and `SphericalGrid`, as these seem to only cause confusion about where changes should be made. `RadialGridMgr` and `LebedevGridMgr` are the classes of Actual Importance.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2736#issuecomment-1275116304
https://github.com/psi4/psi4/pull/2736#issuecomment-1275116304:581,Testability,test,tests,581,"> 1. Fix the merge conflicts (annoying rebase). I'm not sure how much rebasing you want to do, but I think things are back to the state-of-the-world that we were discussing prior to #2743 . > 2. Determine what information in `print_details` is actually used. I want to retain print information that is actually used, but I can do away with the rest. Once we have that, we can assess if keeping a modified `RadialGrid` is the best way to keep the useful print information. (I think we've established that `r` and `wr` are used, but `order` is not?). ""Used"" is a funny word here. No tests when this print is removed, so it's not _so_ important that someone wrote a test to preserve it. Furthermore, the `order_` was _always_ wrong. The other elements weren't, though, but you have to set a pretty high print level to actually see anything (`v.cc` requires `print_ > 2`). . If by ""used"" you mean that the piece of information represented in the print is used downstream: `r` and `wr` are the primary candidates here. That said, they aren't used as-is -- they're dotted through other elements found by a lookup in `LebedevGridMgr` and `RadialGridMgr` to make `MassPoints` (see https://github.com/psi4/psi4/blob/9db9100564eaef5d02c952817a73c397db9d657b/psi4/src/psi4/libfock/cubature.cc#L3814-L3822). I'm not sure if we care about diagnostic print info on the intermediaries (the radii of shells around atoms we care about, and the number of angular points we end up picking for each shell). Maybe we do? If so, a struct seems like the most reasonable solution. I suppose, all-in-all, it's not so much data to carry around. Appending that data onto every `MassPoint` however feels like overkill (and that's the only other place to put it). . But we definitely should clean up/remove the rest of the old `RadialGrid` and `SphericalGrid`, as these seem to only cause confusion about where changes should be made. `RadialGridMgr` and `LebedevGridMgr` are the classes of Actual Importance.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2736#issuecomment-1275116304
https://github.com/psi4/psi4/pull/2736#issuecomment-1275116304:663,Testability,test,test,663,"> 1. Fix the merge conflicts (annoying rebase). I'm not sure how much rebasing you want to do, but I think things are back to the state-of-the-world that we were discussing prior to #2743 . > 2. Determine what information in `print_details` is actually used. I want to retain print information that is actually used, but I can do away with the rest. Once we have that, we can assess if keeping a modified `RadialGrid` is the best way to keep the useful print information. (I think we've established that `r` and `wr` are used, but `order` is not?). ""Used"" is a funny word here. No tests when this print is removed, so it's not _so_ important that someone wrote a test to preserve it. Furthermore, the `order_` was _always_ wrong. The other elements weren't, though, but you have to set a pretty high print level to actually see anything (`v.cc` requires `print_ > 2`). . If by ""used"" you mean that the piece of information represented in the print is used downstream: `r` and `wr` are the primary candidates here. That said, they aren't used as-is -- they're dotted through other elements found by a lookup in `LebedevGridMgr` and `RadialGridMgr` to make `MassPoints` (see https://github.com/psi4/psi4/blob/9db9100564eaef5d02c952817a73c397db9d657b/psi4/src/psi4/libfock/cubature.cc#L3814-L3822). I'm not sure if we care about diagnostic print info on the intermediaries (the radii of shells around atoms we care about, and the number of angular points we end up picking for each shell). Maybe we do? If so, a struct seems like the most reasonable solution. I suppose, all-in-all, it's not so much data to carry around. Appending that data onto every `MassPoint` however feels like overkill (and that's the only other place to put it). . But we definitely should clean up/remove the rest of the old `RadialGrid` and `SphericalGrid`, as these seem to only cause confusion about where changes should be made. `RadialGridMgr` and `LebedevGridMgr` are the classes of Actual Importance.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2736#issuecomment-1275116304
https://github.com/psi4/psi4/pull/2736#issuecomment-1292378009:170,Usability,clear,clear,170,"> Are the `Grid` classes used for something other than printing?. `Grid` classes are *only* used for printing. Hence why I moved things to skinnier structs, so that it's clear to future devs that ""nothing goes here but storage"" (and maybe even with a big comment about ""THIS CONTENT IS NOT REFERENCED EXCEPT BY A PRINT"". There's no reasonable way I can see to migrate this into the `MassPoints`. I've been quiet b/c I am hoping the other primary devs will chime in here -- I'm not sure how to move forwards given conflicting desires (and given that the immediate urgency of ""this causes program hangs"" has been fixed).",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2736#issuecomment-1292378009
https://github.com/psi4/psi4/pull/2737#issuecomment-1268969031:81,Availability,avail,available,81,"For methods (or methods in certain circumstances, say reference or conv/df) only available through an external add-on, do we want those opt-in? That is, certainly the external must be (1) installed and detectable. But do we also want to (2) require the user to `set qc_module=mrcc|adcc|chemps2` ? CheMPS2 has a long history of not requiring (2). ADCC has a shorter history of being the preferred backend and automatic choice, if present. I just switched MRCC syntax in #2731 to yes require (2). That was in keeping with the user opt-ing in via `energy(""mrccsd"")`. I can go either way, and I guess I'm now leaning toward not requiring (2) and adjusting MRCC accordingly. But it seems like something to discuss and settle on a consistent treatment.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2737#issuecomment-1268969031
https://github.com/psi4/psi4/pull/2737#issuecomment-1268969031:188,Deployability,install,installed,188,"For methods (or methods in certain circumstances, say reference or conv/df) only available through an external add-on, do we want those opt-in? That is, certainly the external must be (1) installed and detectable. But do we also want to (2) require the user to `set qc_module=mrcc|adcc|chemps2` ? CheMPS2 has a long history of not requiring (2). ADCC has a shorter history of being the preferred backend and automatic choice, if present. I just switched MRCC syntax in #2731 to yes require (2). That was in keeping with the user opt-ing in via `energy(""mrccsd"")`. I can go either way, and I guess I'm now leaning toward not requiring (2) and adjusting MRCC accordingly. But it seems like something to discuss and settle on a consistent treatment.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2737#issuecomment-1268969031
https://github.com/psi4/psi4/pull/2737#issuecomment-1268969031:545,Energy Efficiency,energy,energy,545,"For methods (or methods in certain circumstances, say reference or conv/df) only available through an external add-on, do we want those opt-in? That is, certainly the external must be (1) installed and detectable. But do we also want to (2) require the user to `set qc_module=mrcc|adcc|chemps2` ? CheMPS2 has a long history of not requiring (2). ADCC has a shorter history of being the preferred backend and automatic choice, if present. I just switched MRCC syntax in #2731 to yes require (2). That was in keeping with the user opt-ing in via `energy(""mrccsd"")`. I can go either way, and I guess I'm now leaning toward not requiring (2) and adjusting MRCC accordingly. But it seems like something to discuss and settle on a consistent treatment.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2737#issuecomment-1268969031
https://github.com/psi4/psi4/pull/2737#issuecomment-1268969031:202,Safety,detect,detectable,202,"For methods (or methods in certain circumstances, say reference or conv/df) only available through an external add-on, do we want those opt-in? That is, certainly the external must be (1) installed and detectable. But do we also want to (2) require the user to `set qc_module=mrcc|adcc|chemps2` ? CheMPS2 has a long history of not requiring (2). ADCC has a shorter history of being the preferred backend and automatic choice, if present. I just switched MRCC syntax in #2731 to yes require (2). That was in keeping with the user opt-ing in via `energy(""mrccsd"")`. I can go either way, and I guess I'm now leaning toward not requiring (2) and adjusting MRCC accordingly. But it seems like something to discuss and settle on a consistent treatment.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2737#issuecomment-1268969031
https://github.com/psi4/psi4/pull/2737#issuecomment-1269567607:260,Availability,avail,available,260,"@loriab I removed the `MEMORY` option from the ADC section, but now some tests using `fnocc` are failing, because apparently, the option was *only* provided by the ADC part in `read_options.cc`... What should I do about this? `adcc` does not take any input on available memory, so where should the `MEMORY` option live from now on?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2737#issuecomment-1269567607
https://github.com/psi4/psi4/pull/2737#issuecomment-1269567607:73,Testability,test,tests,73,"@loriab I removed the `MEMORY` option from the ADC section, but now some tests using `fnocc` are failing, because apparently, the option was *only* provided by the ADC part in `read_options.cc`... What should I do about this? `adcc` does not take any input on available memory, so where should the `MEMORY` option live from now on?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2737#issuecomment-1269567607
https://github.com/psi4/psi4/pull/2737#issuecomment-1270159393:244,Availability,avail,available,244,"> I removed the MEMORY option from the ADC section, but now some tests using fnocc are failing, because apparently, the option was only provided by the ADC part in read_options.cc... What should I do about this? adcc does not take any input on available memory, so where should the MEMORY option live from now on?. My best guess at why fnocc is using MEMORY is so that it can get more memory under default conditions (1gb instead of 0.5gb). Better handling would probably be to have a `FNOCC_TRIPLES_FACTOR` to manipulate input memory. I think comment out those `MEMORY` blocks in triples and lowmemory_triples, and we'll put up an issue. Those aren't running by default, and fnocc doesn't own MEMORY (as you discovered).",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2737#issuecomment-1270159393
https://github.com/psi4/psi4/pull/2737#issuecomment-1270159393:65,Testability,test,tests,65,"> I removed the MEMORY option from the ADC section, but now some tests using fnocc are failing, because apparently, the option was only provided by the ADC part in read_options.cc... What should I do about this? adcc does not take any input on available memory, so where should the MEMORY option live from now on?. My best guess at why fnocc is using MEMORY is so that it can get more memory under default conditions (1gb instead of 0.5gb). Better handling would probably be to have a `FNOCC_TRIPLES_FACTOR` to manipulate input memory. I think comment out those `MEMORY` blocks in triples and lowmemory_triples, and we'll put up an issue. Those aren't running by default, and fnocc doesn't own MEMORY (as you discovered).",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2737#issuecomment-1270159393
https://github.com/psi4/psi4/pull/2744#issuecomment-1282959715:26,Deployability,update,updated,26,@JonathonMisiewicz I just updated the docstring. Thanks for the poke!,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2744#issuecomment-1282959715
https://github.com/psi4/psi4/issues/2747#issuecomment-1278199072:44,Energy Efficiency,energy,energy,44,"What method are you dealing with (that is, `energy(???)`)?. The aim is to have each job run max thread of node? That is, https://github.com/psi4/psi4/blob/master/tests/tu1-h2o-energy/output.ref#L67-L72 shows `Threads 48`? And the `-pe smp 64` is for one job running one Psi4 energy() call?. Were you setting `psi4.set_num_threads(1)` or `psi4.set_num_threads(64)`? I'd expect the latter if I'm reading your intentions right.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2747#issuecomment-1278199072
https://github.com/psi4/psi4/issues/2747#issuecomment-1278199072:176,Energy Efficiency,energy,energy,176,"What method are you dealing with (that is, `energy(???)`)?. The aim is to have each job run max thread of node? That is, https://github.com/psi4/psi4/blob/master/tests/tu1-h2o-energy/output.ref#L67-L72 shows `Threads 48`? And the `-pe smp 64` is for one job running one Psi4 energy() call?. Were you setting `psi4.set_num_threads(1)` or `psi4.set_num_threads(64)`? I'd expect the latter if I'm reading your intentions right.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2747#issuecomment-1278199072
https://github.com/psi4/psi4/issues/2747#issuecomment-1278199072:275,Energy Efficiency,energy,energy,275,"What method are you dealing with (that is, `energy(???)`)?. The aim is to have each job run max thread of node? That is, https://github.com/psi4/psi4/blob/master/tests/tu1-h2o-energy/output.ref#L67-L72 shows `Threads 48`? And the `-pe smp 64` is for one job running one Psi4 energy() call?. Were you setting `psi4.set_num_threads(1)` or `psi4.set_num_threads(64)`? I'd expect the latter if I'm reading your intentions right.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2747#issuecomment-1278199072
https://github.com/psi4/psi4/issues/2747#issuecomment-1278199072:162,Testability,test,tests,162,"What method are you dealing with (that is, `energy(???)`)?. The aim is to have each job run max thread of node? That is, https://github.com/psi4/psi4/blob/master/tests/tu1-h2o-energy/output.ref#L67-L72 shows `Threads 48`? And the `-pe smp 64` is for one job running one Psi4 energy() call?. Were you setting `psi4.set_num_threads(1)` or `psi4.set_num_threads(64)`? I'd expect the latter if I'm reading your intentions right.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2747#issuecomment-1278199072
https://github.com/psi4/psi4/issues/2747#issuecomment-1278373201:193,Availability,avail,available,193,"Ah, yes you are right. I have a class wrapper around psi4 that sets the initial configurations and that has the default value 64. That must be why I have the spikes. Because psi4 knows that is available to it because I requested it in the initial configurations. . Okay so I set up tests where I am generating an interaction energy surface scan for a dimer. I am using `mp2/cc-pvqz-ri`. I didn't know if the resolution identity error was implied like gaussian or if I had to explicitly state it. It's about 72 point single point energy scans. . **Test 1**. I reduced down the `64` to `16`. ```bash; -pe smp 16; ```. Reset the default where this is happening to set the thread to one. with the OMP and MKL flags set in the job submission script. . ```bash; export MKL_NUM_THREADS=12; export OMP_NUM_THREADS=12; ```; ```python. psi4.set_num_threads(1). ```; **Test 2**. Only rely on the flags in the job submission script. ```; export MKL_NUM_THREADS=12; export OMP_NUM_THREADS=12; ```. ```python. # psi4.set_num_threads(1); ```. It seems like so far the loads seem to be continuously used. I will get some graphs in the morning for you to look at.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2747#issuecomment-1278373201
https://github.com/psi4/psi4/issues/2747#issuecomment-1278373201:428,Availability,error,error,428,"Ah, yes you are right. I have a class wrapper around psi4 that sets the initial configurations and that has the default value 64. That must be why I have the spikes. Because psi4 knows that is available to it because I requested it in the initial configurations. . Okay so I set up tests where I am generating an interaction energy surface scan for a dimer. I am using `mp2/cc-pvqz-ri`. I didn't know if the resolution identity error was implied like gaussian or if I had to explicitly state it. It's about 72 point single point energy scans. . **Test 1**. I reduced down the `64` to `16`. ```bash; -pe smp 16; ```. Reset the default where this is happening to set the thread to one. with the OMP and MKL flags set in the job submission script. . ```bash; export MKL_NUM_THREADS=12; export OMP_NUM_THREADS=12; ```; ```python. psi4.set_num_threads(1). ```; **Test 2**. Only rely on the flags in the job submission script. ```; export MKL_NUM_THREADS=12; export OMP_NUM_THREADS=12; ```. ```python. # psi4.set_num_threads(1); ```. It seems like so far the loads seem to be continuously used. I will get some graphs in the morning for you to look at.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2747#issuecomment-1278373201
https://github.com/psi4/psi4/issues/2747#issuecomment-1278373201:567,Availability,down,down,567,"Ah, yes you are right. I have a class wrapper around psi4 that sets the initial configurations and that has the default value 64. That must be why I have the spikes. Because psi4 knows that is available to it because I requested it in the initial configurations. . Okay so I set up tests where I am generating an interaction energy surface scan for a dimer. I am using `mp2/cc-pvqz-ri`. I didn't know if the resolution identity error was implied like gaussian or if I had to explicitly state it. It's about 72 point single point energy scans. . **Test 1**. I reduced down the `64` to `16`. ```bash; -pe smp 16; ```. Reset the default where this is happening to set the thread to one. with the OMP and MKL flags set in the job submission script. . ```bash; export MKL_NUM_THREADS=12; export OMP_NUM_THREADS=12; ```; ```python. psi4.set_num_threads(1). ```; **Test 2**. Only rely on the flags in the job submission script. ```; export MKL_NUM_THREADS=12; export OMP_NUM_THREADS=12; ```. ```python. # psi4.set_num_threads(1); ```. It seems like so far the loads seem to be continuously used. I will get some graphs in the morning for you to look at.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2747#issuecomment-1278373201
https://github.com/psi4/psi4/issues/2747#issuecomment-1278373201:80,Deployability,configurat,configurations,80,"Ah, yes you are right. I have a class wrapper around psi4 that sets the initial configurations and that has the default value 64. That must be why I have the spikes. Because psi4 knows that is available to it because I requested it in the initial configurations. . Okay so I set up tests where I am generating an interaction energy surface scan for a dimer. I am using `mp2/cc-pvqz-ri`. I didn't know if the resolution identity error was implied like gaussian or if I had to explicitly state it. It's about 72 point single point energy scans. . **Test 1**. I reduced down the `64` to `16`. ```bash; -pe smp 16; ```. Reset the default where this is happening to set the thread to one. with the OMP and MKL flags set in the job submission script. . ```bash; export MKL_NUM_THREADS=12; export OMP_NUM_THREADS=12; ```; ```python. psi4.set_num_threads(1). ```; **Test 2**. Only rely on the flags in the job submission script. ```; export MKL_NUM_THREADS=12; export OMP_NUM_THREADS=12; ```. ```python. # psi4.set_num_threads(1); ```. It seems like so far the loads seem to be continuously used. I will get some graphs in the morning for you to look at.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2747#issuecomment-1278373201
https://github.com/psi4/psi4/issues/2747#issuecomment-1278373201:247,Deployability,configurat,configurations,247,"Ah, yes you are right. I have a class wrapper around psi4 that sets the initial configurations and that has the default value 64. That must be why I have the spikes. Because psi4 knows that is available to it because I requested it in the initial configurations. . Okay so I set up tests where I am generating an interaction energy surface scan for a dimer. I am using `mp2/cc-pvqz-ri`. I didn't know if the resolution identity error was implied like gaussian or if I had to explicitly state it. It's about 72 point single point energy scans. . **Test 1**. I reduced down the `64` to `16`. ```bash; -pe smp 16; ```. Reset the default where this is happening to set the thread to one. with the OMP and MKL flags set in the job submission script. . ```bash; export MKL_NUM_THREADS=12; export OMP_NUM_THREADS=12; ```; ```python. psi4.set_num_threads(1). ```; **Test 2**. Only rely on the flags in the job submission script. ```; export MKL_NUM_THREADS=12; export OMP_NUM_THREADS=12; ```. ```python. # psi4.set_num_threads(1); ```. It seems like so far the loads seem to be continuously used. I will get some graphs in the morning for you to look at.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2747#issuecomment-1278373201
https://github.com/psi4/psi4/issues/2747#issuecomment-1278373201:1070,Deployability,continuous,continuously,1070,"Ah, yes you are right. I have a class wrapper around psi4 that sets the initial configurations and that has the default value 64. That must be why I have the spikes. Because psi4 knows that is available to it because I requested it in the initial configurations. . Okay so I set up tests where I am generating an interaction energy surface scan for a dimer. I am using `mp2/cc-pvqz-ri`. I didn't know if the resolution identity error was implied like gaussian or if I had to explicitly state it. It's about 72 point single point energy scans. . **Test 1**. I reduced down the `64` to `16`. ```bash; -pe smp 16; ```. Reset the default where this is happening to set the thread to one. with the OMP and MKL flags set in the job submission script. . ```bash; export MKL_NUM_THREADS=12; export OMP_NUM_THREADS=12; ```; ```python. psi4.set_num_threads(1). ```; **Test 2**. Only rely on the flags in the job submission script. ```; export MKL_NUM_THREADS=12; export OMP_NUM_THREADS=12; ```. ```python. # psi4.set_num_threads(1); ```. It seems like so far the loads seem to be continuously used. I will get some graphs in the morning for you to look at.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2747#issuecomment-1278373201
https://github.com/psi4/psi4/issues/2747#issuecomment-1278373201:325,Energy Efficiency,energy,energy,325,"Ah, yes you are right. I have a class wrapper around psi4 that sets the initial configurations and that has the default value 64. That must be why I have the spikes. Because psi4 knows that is available to it because I requested it in the initial configurations. . Okay so I set up tests where I am generating an interaction energy surface scan for a dimer. I am using `mp2/cc-pvqz-ri`. I didn't know if the resolution identity error was implied like gaussian or if I had to explicitly state it. It's about 72 point single point energy scans. . **Test 1**. I reduced down the `64` to `16`. ```bash; -pe smp 16; ```. Reset the default where this is happening to set the thread to one. with the OMP and MKL flags set in the job submission script. . ```bash; export MKL_NUM_THREADS=12; export OMP_NUM_THREADS=12; ```; ```python. psi4.set_num_threads(1). ```; **Test 2**. Only rely on the flags in the job submission script. ```; export MKL_NUM_THREADS=12; export OMP_NUM_THREADS=12; ```. ```python. # psi4.set_num_threads(1); ```. It seems like so far the loads seem to be continuously used. I will get some graphs in the morning for you to look at.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2747#issuecomment-1278373201
https://github.com/psi4/psi4/issues/2747#issuecomment-1278373201:529,Energy Efficiency,energy,energy,529,"Ah, yes you are right. I have a class wrapper around psi4 that sets the initial configurations and that has the default value 64. That must be why I have the spikes. Because psi4 knows that is available to it because I requested it in the initial configurations. . Okay so I set up tests where I am generating an interaction energy surface scan for a dimer. I am using `mp2/cc-pvqz-ri`. I didn't know if the resolution identity error was implied like gaussian or if I had to explicitly state it. It's about 72 point single point energy scans. . **Test 1**. I reduced down the `64` to `16`. ```bash; -pe smp 16; ```. Reset the default where this is happening to set the thread to one. with the OMP and MKL flags set in the job submission script. . ```bash; export MKL_NUM_THREADS=12; export OMP_NUM_THREADS=12; ```; ```python. psi4.set_num_threads(1). ```; **Test 2**. Only rely on the flags in the job submission script. ```; export MKL_NUM_THREADS=12; export OMP_NUM_THREADS=12; ```. ```python. # psi4.set_num_threads(1); ```. It seems like so far the loads seem to be continuously used. I will get some graphs in the morning for you to look at.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2747#issuecomment-1278373201
https://github.com/psi4/psi4/issues/2747#issuecomment-1278373201:559,Energy Efficiency,reduce,reduced,559,"Ah, yes you are right. I have a class wrapper around psi4 that sets the initial configurations and that has the default value 64. That must be why I have the spikes. Because psi4 knows that is available to it because I requested it in the initial configurations. . Okay so I set up tests where I am generating an interaction energy surface scan for a dimer. I am using `mp2/cc-pvqz-ri`. I didn't know if the resolution identity error was implied like gaussian or if I had to explicitly state it. It's about 72 point single point energy scans. . **Test 1**. I reduced down the `64` to `16`. ```bash; -pe smp 16; ```. Reset the default where this is happening to set the thread to one. with the OMP and MKL flags set in the job submission script. . ```bash; export MKL_NUM_THREADS=12; export OMP_NUM_THREADS=12; ```; ```python. psi4.set_num_threads(1). ```; **Test 2**. Only rely on the flags in the job submission script. ```; export MKL_NUM_THREADS=12; export OMP_NUM_THREADS=12; ```. ```python. # psi4.set_num_threads(1); ```. It seems like so far the loads seem to be continuously used. I will get some graphs in the morning for you to look at.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2747#issuecomment-1278373201
https://github.com/psi4/psi4/issues/2747#issuecomment-1278373201:38,Integrability,wrap,wrapper,38,"Ah, yes you are right. I have a class wrapper around psi4 that sets the initial configurations and that has the default value 64. That must be why I have the spikes. Because psi4 knows that is available to it because I requested it in the initial configurations. . Okay so I set up tests where I am generating an interaction energy surface scan for a dimer. I am using `mp2/cc-pvqz-ri`. I didn't know if the resolution identity error was implied like gaussian or if I had to explicitly state it. It's about 72 point single point energy scans. . **Test 1**. I reduced down the `64` to `16`. ```bash; -pe smp 16; ```. Reset the default where this is happening to set the thread to one. with the OMP and MKL flags set in the job submission script. . ```bash; export MKL_NUM_THREADS=12; export OMP_NUM_THREADS=12; ```; ```python. psi4.set_num_threads(1). ```; **Test 2**. Only rely on the flags in the job submission script. ```; export MKL_NUM_THREADS=12; export OMP_NUM_THREADS=12; ```. ```python. # psi4.set_num_threads(1); ```. It seems like so far the loads seem to be continuously used. I will get some graphs in the morning for you to look at.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2747#issuecomment-1278373201
https://github.com/psi4/psi4/issues/2747#issuecomment-1278373201:80,Modifiability,config,configurations,80,"Ah, yes you are right. I have a class wrapper around psi4 that sets the initial configurations and that has the default value 64. That must be why I have the spikes. Because psi4 knows that is available to it because I requested it in the initial configurations. . Okay so I set up tests where I am generating an interaction energy surface scan for a dimer. I am using `mp2/cc-pvqz-ri`. I didn't know if the resolution identity error was implied like gaussian or if I had to explicitly state it. It's about 72 point single point energy scans. . **Test 1**. I reduced down the `64` to `16`. ```bash; -pe smp 16; ```. Reset the default where this is happening to set the thread to one. with the OMP and MKL flags set in the job submission script. . ```bash; export MKL_NUM_THREADS=12; export OMP_NUM_THREADS=12; ```; ```python. psi4.set_num_threads(1). ```; **Test 2**. Only rely on the flags in the job submission script. ```; export MKL_NUM_THREADS=12; export OMP_NUM_THREADS=12; ```. ```python. # psi4.set_num_threads(1); ```. It seems like so far the loads seem to be continuously used. I will get some graphs in the morning for you to look at.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2747#issuecomment-1278373201
https://github.com/psi4/psi4/issues/2747#issuecomment-1278373201:247,Modifiability,config,configurations,247,"Ah, yes you are right. I have a class wrapper around psi4 that sets the initial configurations and that has the default value 64. That must be why I have the spikes. Because psi4 knows that is available to it because I requested it in the initial configurations. . Okay so I set up tests where I am generating an interaction energy surface scan for a dimer. I am using `mp2/cc-pvqz-ri`. I didn't know if the resolution identity error was implied like gaussian or if I had to explicitly state it. It's about 72 point single point energy scans. . **Test 1**. I reduced down the `64` to `16`. ```bash; -pe smp 16; ```. Reset the default where this is happening to set the thread to one. with the OMP and MKL flags set in the job submission script. . ```bash; export MKL_NUM_THREADS=12; export OMP_NUM_THREADS=12; ```; ```python. psi4.set_num_threads(1). ```; **Test 2**. Only rely on the flags in the job submission script. ```; export MKL_NUM_THREADS=12; export OMP_NUM_THREADS=12; ```. ```python. # psi4.set_num_threads(1); ```. It seems like so far the loads seem to be continuously used. I will get some graphs in the morning for you to look at.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2747#issuecomment-1278373201
https://github.com/psi4/psi4/issues/2747#issuecomment-1278373201:1053,Performance,load,loads,1053,"Ah, yes you are right. I have a class wrapper around psi4 that sets the initial configurations and that has the default value 64. That must be why I have the spikes. Because psi4 knows that is available to it because I requested it in the initial configurations. . Okay so I set up tests where I am generating an interaction energy surface scan for a dimer. I am using `mp2/cc-pvqz-ri`. I didn't know if the resolution identity error was implied like gaussian or if I had to explicitly state it. It's about 72 point single point energy scans. . **Test 1**. I reduced down the `64` to `16`. ```bash; -pe smp 16; ```. Reset the default where this is happening to set the thread to one. with the OMP and MKL flags set in the job submission script. . ```bash; export MKL_NUM_THREADS=12; export OMP_NUM_THREADS=12; ```; ```python. psi4.set_num_threads(1). ```; **Test 2**. Only rely on the flags in the job submission script. ```; export MKL_NUM_THREADS=12; export OMP_NUM_THREADS=12; ```. ```python. # psi4.set_num_threads(1); ```. It seems like so far the loads seem to be continuously used. I will get some graphs in the morning for you to look at.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2747#issuecomment-1278373201
https://github.com/psi4/psi4/issues/2747#issuecomment-1278373201:282,Testability,test,tests,282,"Ah, yes you are right. I have a class wrapper around psi4 that sets the initial configurations and that has the default value 64. That must be why I have the spikes. Because psi4 knows that is available to it because I requested it in the initial configurations. . Okay so I set up tests where I am generating an interaction energy surface scan for a dimer. I am using `mp2/cc-pvqz-ri`. I didn't know if the resolution identity error was implied like gaussian or if I had to explicitly state it. It's about 72 point single point energy scans. . **Test 1**. I reduced down the `64` to `16`. ```bash; -pe smp 16; ```. Reset the default where this is happening to set the thread to one. with the OMP and MKL flags set in the job submission script. . ```bash; export MKL_NUM_THREADS=12; export OMP_NUM_THREADS=12; ```; ```python. psi4.set_num_threads(1). ```; **Test 2**. Only rely on the flags in the job submission script. ```; export MKL_NUM_THREADS=12; export OMP_NUM_THREADS=12; ```. ```python. # psi4.set_num_threads(1); ```. It seems like so far the loads seem to be continuously used. I will get some graphs in the morning for you to look at.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2747#issuecomment-1278373201
https://github.com/psi4/psi4/issues/2747#issuecomment-1278373201:547,Testability,Test,Test,547,"Ah, yes you are right. I have a class wrapper around psi4 that sets the initial configurations and that has the default value 64. That must be why I have the spikes. Because psi4 knows that is available to it because I requested it in the initial configurations. . Okay so I set up tests where I am generating an interaction energy surface scan for a dimer. I am using `mp2/cc-pvqz-ri`. I didn't know if the resolution identity error was implied like gaussian or if I had to explicitly state it. It's about 72 point single point energy scans. . **Test 1**. I reduced down the `64` to `16`. ```bash; -pe smp 16; ```. Reset the default where this is happening to set the thread to one. with the OMP and MKL flags set in the job submission script. . ```bash; export MKL_NUM_THREADS=12; export OMP_NUM_THREADS=12; ```; ```python. psi4.set_num_threads(1). ```; **Test 2**. Only rely on the flags in the job submission script. ```; export MKL_NUM_THREADS=12; export OMP_NUM_THREADS=12; ```. ```python. # psi4.set_num_threads(1); ```. It seems like so far the loads seem to be continuously used. I will get some graphs in the morning for you to look at.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2747#issuecomment-1278373201
https://github.com/psi4/psi4/issues/2747#issuecomment-1278373201:858,Testability,Test,Test,858,"Ah, yes you are right. I have a class wrapper around psi4 that sets the initial configurations and that has the default value 64. That must be why I have the spikes. Because psi4 knows that is available to it because I requested it in the initial configurations. . Okay so I set up tests where I am generating an interaction energy surface scan for a dimer. I am using `mp2/cc-pvqz-ri`. I didn't know if the resolution identity error was implied like gaussian or if I had to explicitly state it. It's about 72 point single point energy scans. . **Test 1**. I reduced down the `64` to `16`. ```bash; -pe smp 16; ```. Reset the default where this is happening to set the thread to one. with the OMP and MKL flags set in the job submission script. . ```bash; export MKL_NUM_THREADS=12; export OMP_NUM_THREADS=12; ```; ```python. psi4.set_num_threads(1). ```; **Test 2**. Only rely on the flags in the job submission script. ```; export MKL_NUM_THREADS=12; export OMP_NUM_THREADS=12; ```. ```python. # psi4.set_num_threads(1); ```. It seems like so far the loads seem to be continuously used. I will get some graphs in the morning for you to look at.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2747#issuecomment-1278373201
https://github.com/psi4/psi4/issues/2747#issuecomment-1279094276:105,Energy Efficiency,energy,energy,105,"Side issue, just checking that `mp2/cc-pvqz-ri` is your shorthand, and that you're not actually running `energy('mp2/cc-pvqz-ri')`? That would be bad b/c cc-pvqz-ri isn't designed as a primary/orbital basis. It will be used automatcally as an auxiliary/fitting basis in a calc like `energy('mp2/cc-pvqz')` [good].",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2747#issuecomment-1279094276
https://github.com/psi4/psi4/issues/2747#issuecomment-1279094276:283,Energy Efficiency,energy,energy,283,"Side issue, just checking that `mp2/cc-pvqz-ri` is your shorthand, and that you're not actually running `energy('mp2/cc-pvqz-ri')`? That would be bad b/c cc-pvqz-ri isn't designed as a primary/orbital basis. It will be used automatcally as an auxiliary/fitting basis in a calc like `energy('mp2/cc-pvqz')` [good].",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2747#issuecomment-1279094276
https://github.com/psi4/psi4/issues/2747#issuecomment-1279098432:205,Deployability,update,update,205,I was running `mp2/cc-pvqz-ri` and also `mp2/cc-pvqz` and saw the difference in the energy and was thinking I needed to explicitly set ri. . Thanks for clarifying that. Really helps before I scale. . Will update soon with some test results.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2747#issuecomment-1279098432
https://github.com/psi4/psi4/issues/2747#issuecomment-1279098432:84,Energy Efficiency,energy,energy,84,I was running `mp2/cc-pvqz-ri` and also `mp2/cc-pvqz` and saw the difference in the energy and was thinking I needed to explicitly set ri. . Thanks for clarifying that. Really helps before I scale. . Will update soon with some test results.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2747#issuecomment-1279098432
https://github.com/psi4/psi4/issues/2747#issuecomment-1279098432:227,Testability,test,test,227,I was running `mp2/cc-pvqz-ri` and also `mp2/cc-pvqz` and saw the difference in the energy and was thinking I needed to explicitly set ri. . Thanks for clarifying that. Really helps before I scale. . Will update soon with some test results.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2747#issuecomment-1279098432
https://github.com/psi4/psi4/pull/2748#issuecomment-1279252713:5,Availability,failure,failures,5,Test failures are expected until #2750 is merged in.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2748#issuecomment-1279252713
https://github.com/psi4/psi4/pull/2748#issuecomment-1279252713:0,Testability,Test,Test,0,Test failures are expected until #2750 is merged in.,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2748#issuecomment-1279252713
https://github.com/psi4/psi4/issues/2754#issuecomment-1292381264:317,Deployability,patch,patch,317,"I don't think the inferring of grid order from `lebedev_mapping` was *ever* correct, to be clear. I believe (but am not 100% sure) that the new way of gaining the information (using information from `LebedevGridMgr`) proposed in #2736 works?. I can test -- do you have a simple input I can test with my build of that patch?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2754#issuecomment-1292381264
https://github.com/psi4/psi4/issues/2754#issuecomment-1292381264:249,Testability,test,test,249,"I don't think the inferring of grid order from `lebedev_mapping` was *ever* correct, to be clear. I believe (but am not 100% sure) that the new way of gaining the information (using information from `LebedevGridMgr`) proposed in #2736 works?. I can test -- do you have a simple input I can test with my build of that patch?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2754#issuecomment-1292381264
https://github.com/psi4/psi4/issues/2754#issuecomment-1292381264:290,Testability,test,test,290,"I don't think the inferring of grid order from `lebedev_mapping` was *ever* correct, to be clear. I believe (but am not 100% sure) that the new way of gaining the information (using information from `LebedevGridMgr`) proposed in #2736 works?. I can test -- do you have a simple input I can test with my build of that patch?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2754#issuecomment-1292381264
https://github.com/psi4/psi4/issues/2754#issuecomment-1292381264:91,Usability,clear,clear,91,"I don't think the inferring of grid order from `lebedev_mapping` was *ever* correct, to be clear. I believe (but am not 100% sure) that the new way of gaining the information (using information from `LebedevGridMgr`) proposed in #2736 works?. I can test -- do you have a simple input I can test with my build of that patch?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2754#issuecomment-1292381264
https://github.com/psi4/psi4/issues/2754#issuecomment-1292381264:271,Usability,simpl,simple,271,"I don't think the inferring of grid order from `lebedev_mapping` was *ever* correct, to be clear. I believe (but am not 100% sure) that the new way of gaining the information (using information from `LebedevGridMgr`) proposed in #2736 works?. I can test -- do you have a simple input I can test with my build of that patch?",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2754#issuecomment-1292381264
https://github.com/psi4/psi4/issues/2754#issuecomment-1292454392:12,Testability,test,test,12,"The failing test is https://github.com/psi4/psi4/tree/master/tests/dft-pruning but also your changes won't help, the modified `npoints` do not fit any order since they were modified. One would need to try to find the closest order in the spirit of https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libfock/cubature.cc#L3645, which I do not find really helpful however.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2754#issuecomment-1292454392
https://github.com/psi4/psi4/issues/2754#issuecomment-1292454392:61,Testability,test,tests,61,"The failing test is https://github.com/psi4/psi4/tree/master/tests/dft-pruning but also your changes won't help, the modified `npoints` do not fit any order since they were modified. One would need to try to find the closest order in the spirit of https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libfock/cubature.cc#L3645, which I do not find really helpful however.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/issues/2754#issuecomment-1292454392
https://github.com/psi4/psi4/pull/2756#issuecomment-1291191371:51,Availability,error,error,51,Can you provide a before-and-after example of what error messages look like?,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2756#issuecomment-1291191371
https://github.com/psi4/psi4/pull/2756#issuecomment-1291191371:57,Integrability,message,messages,57,Can you provide a before-and-after example of what error messages look like?,MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2756#issuecomment-1291191371
https://github.com/psi4/psi4/pull/2756#issuecomment-1291906441:53,Availability,error,error,53,"> Can you provide a before-and-after example of what error messages look like?. Hmm, yes I reckon if I ran something with a ~50 MB ramdisk as the scratch drive, that should be a reliable way to trigger a write failure. My immediate-term schedule just got a lot busier, so I might not get around to doing this for a week or so.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2756#issuecomment-1291906441
https://github.com/psi4/psi4/pull/2756#issuecomment-1291906441:178,Availability,reliab,reliable,178,"> Can you provide a before-and-after example of what error messages look like?. Hmm, yes I reckon if I ran something with a ~50 MB ramdisk as the scratch drive, that should be a reliable way to trigger a write failure. My immediate-term schedule just got a lot busier, so I might not get around to doing this for a week or so.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2756#issuecomment-1291906441
https://github.com/psi4/psi4/pull/2756#issuecomment-1291906441:210,Availability,failure,failure,210,"> Can you provide a before-and-after example of what error messages look like?. Hmm, yes I reckon if I ran something with a ~50 MB ramdisk as the scratch drive, that should be a reliable way to trigger a write failure. My immediate-term schedule just got a lot busier, so I might not get around to doing this for a week or so.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2756#issuecomment-1291906441
https://github.com/psi4/psi4/pull/2756#issuecomment-1291906441:237,Energy Efficiency,schedul,schedule,237,"> Can you provide a before-and-after example of what error messages look like?. Hmm, yes I reckon if I ran something with a ~50 MB ramdisk as the scratch drive, that should be a reliable way to trigger a write failure. My immediate-term schedule just got a lot busier, so I might not get around to doing this for a week or so.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2756#issuecomment-1291906441
https://github.com/psi4/psi4/pull/2756#issuecomment-1291906441:59,Integrability,message,messages,59,"> Can you provide a before-and-after example of what error messages look like?. Hmm, yes I reckon if I ran something with a ~50 MB ramdisk as the scratch drive, that should be a reliable way to trigger a write failure. My immediate-term schedule just got a lot busier, so I might not get around to doing this for a week or so.",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2756#issuecomment-1291906441
https://github.com/psi4/psi4/pull/2756#issuecomment-1304827495:0,Deployability,Update,Update,0,"Update: testing is currently made very difficult by an issue with exception messages not propagating out of the threaded neighborhood of https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libpsio/aio_handler.cc ; But it was a good idea to actually try it, because I have found another corner case _even beyond this issue_",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2756#issuecomment-1304827495
https://github.com/psi4/psi4/pull/2756#issuecomment-1304827495:76,Integrability,message,messages,76,"Update: testing is currently made very difficult by an issue with exception messages not propagating out of the threaded neighborhood of https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libpsio/aio_handler.cc ; But it was a good idea to actually try it, because I have found another corner case _even beyond this issue_",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2756#issuecomment-1304827495
https://github.com/psi4/psi4/pull/2756#issuecomment-1304827495:8,Testability,test,testing,8,"Update: testing is currently made very difficult by an issue with exception messages not propagating out of the threaded neighborhood of https://github.com/psi4/psi4/blob/master/psi4/src/psi4/libpsio/aio_handler.cc ; But it was a good idea to actually try it, because I have found another corner case _even beyond this issue_",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2756#issuecomment-1304827495
https://github.com/psi4/psi4/pull/2756#issuecomment-1304899857:151,Availability,error,errors,151,"OK, I have finally managed to get a pair of builds (current master and this PR's branch) that do not entirely swallow the exception messages for write errors in the PK integral calculation. For me, it took building Psi4 entirely from source, with nothing from conda at all. stdout/stderr before this PR:. ```; PSIO_ERROR: unit = 34, errval = 12; terminate called after throwing an instance of 'psi::PsiException'; what():; Fatal Error: PSIO_ERROR: 12 (error writing to file). Error occurred in file: /home/gytibor/psi4/psi4/src/psi4/libpsio/error.cc on line: 131; The most recent 5 function calls were:. psi::PsiException::PsiException(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char const*, int); psi::PSIO::rw(unsigned long, char*, psi::psio_address, unsigned long, int); psi::PSIO::write(unsigned long, char const*, char*, unsigned long, psi::psio_address, psi::psio_address*). Aborted (core dumped); ```; stdout/stderr after this PR:; ```; PSIO_ERROR: unit = 34, errval = 12; terminate called after throwing an instance of 'psi::PsiException'; what():; Fatal Error: WRITE failed. Only some of the bytes were written!; Error writing the first partial page, unit 34.; PSIO_ERROR: 12 (error writing to file). Error occurred in file: /home/gytibor/psi4/psi4/src/psi4/libpsio/error.cc on line: 131; The most recent 5 function calls were:. psi::PsiException::PsiException(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char const*, int); psi::PSIO::rw(unsigned long, char*, psi::psio_address, unsigned long, int); psi::PSIO::write(unsigned long, char const*, char*, unsigned long, psi::psio_address, psi::psio_address*). Aborted (core dumped); ```; The reason why there is no ""disk is full"" error message, is because `SYSTEM_WRITE` only reports a failure and sets errno if the disk is already full when it is called. As long as it can write at least one out of _however many_ bytes it does not set errno. I both cases there is no e",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2756#issuecomment-1304899857
https://github.com/psi4/psi4/pull/2756#issuecomment-1304899857:429,Availability,Error,Error,429,"OK, I have finally managed to get a pair of builds (current master and this PR's branch) that do not entirely swallow the exception messages for write errors in the PK integral calculation. For me, it took building Psi4 entirely from source, with nothing from conda at all. stdout/stderr before this PR:. ```; PSIO_ERROR: unit = 34, errval = 12; terminate called after throwing an instance of 'psi::PsiException'; what():; Fatal Error: PSIO_ERROR: 12 (error writing to file). Error occurred in file: /home/gytibor/psi4/psi4/src/psi4/libpsio/error.cc on line: 131; The most recent 5 function calls were:. psi::PsiException::PsiException(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char const*, int); psi::PSIO::rw(unsigned long, char*, psi::psio_address, unsigned long, int); psi::PSIO::write(unsigned long, char const*, char*, unsigned long, psi::psio_address, psi::psio_address*). Aborted (core dumped); ```; stdout/stderr after this PR:; ```; PSIO_ERROR: unit = 34, errval = 12; terminate called after throwing an instance of 'psi::PsiException'; what():; Fatal Error: WRITE failed. Only some of the bytes were written!; Error writing the first partial page, unit 34.; PSIO_ERROR: 12 (error writing to file). Error occurred in file: /home/gytibor/psi4/psi4/src/psi4/libpsio/error.cc on line: 131; The most recent 5 function calls were:. psi::PsiException::PsiException(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char const*, int); psi::PSIO::rw(unsigned long, char*, psi::psio_address, unsigned long, int); psi::PSIO::write(unsigned long, char const*, char*, unsigned long, psi::psio_address, psi::psio_address*). Aborted (core dumped); ```; The reason why there is no ""disk is full"" error message, is because `SYSTEM_WRITE` only reports a failure and sets errno if the disk is already full when it is called. As long as it can write at least one out of _however many_ bytes it does not set errno. I both cases there is no e",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2756#issuecomment-1304899857
https://github.com/psi4/psi4/pull/2756#issuecomment-1304899857:452,Availability,error,error,452,"OK, I have finally managed to get a pair of builds (current master and this PR's branch) that do not entirely swallow the exception messages for write errors in the PK integral calculation. For me, it took building Psi4 entirely from source, with nothing from conda at all. stdout/stderr before this PR:. ```; PSIO_ERROR: unit = 34, errval = 12; terminate called after throwing an instance of 'psi::PsiException'; what():; Fatal Error: PSIO_ERROR: 12 (error writing to file). Error occurred in file: /home/gytibor/psi4/psi4/src/psi4/libpsio/error.cc on line: 131; The most recent 5 function calls were:. psi::PsiException::PsiException(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char const*, int); psi::PSIO::rw(unsigned long, char*, psi::psio_address, unsigned long, int); psi::PSIO::write(unsigned long, char const*, char*, unsigned long, psi::psio_address, psi::psio_address*). Aborted (core dumped); ```; stdout/stderr after this PR:; ```; PSIO_ERROR: unit = 34, errval = 12; terminate called after throwing an instance of 'psi::PsiException'; what():; Fatal Error: WRITE failed. Only some of the bytes were written!; Error writing the first partial page, unit 34.; PSIO_ERROR: 12 (error writing to file). Error occurred in file: /home/gytibor/psi4/psi4/src/psi4/libpsio/error.cc on line: 131; The most recent 5 function calls were:. psi::PsiException::PsiException(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char const*, int); psi::PSIO::rw(unsigned long, char*, psi::psio_address, unsigned long, int); psi::PSIO::write(unsigned long, char const*, char*, unsigned long, psi::psio_address, psi::psio_address*). Aborted (core dumped); ```; The reason why there is no ""disk is full"" error message, is because `SYSTEM_WRITE` only reports a failure and sets errno if the disk is already full when it is called. As long as it can write at least one out of _however many_ bytes it does not set errno. I both cases there is no e",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2756#issuecomment-1304899857
https://github.com/psi4/psi4/pull/2756#issuecomment-1304899857:476,Availability,Error,Error,476,"OK, I have finally managed to get a pair of builds (current master and this PR's branch) that do not entirely swallow the exception messages for write errors in the PK integral calculation. For me, it took building Psi4 entirely from source, with nothing from conda at all. stdout/stderr before this PR:. ```; PSIO_ERROR: unit = 34, errval = 12; terminate called after throwing an instance of 'psi::PsiException'; what():; Fatal Error: PSIO_ERROR: 12 (error writing to file). Error occurred in file: /home/gytibor/psi4/psi4/src/psi4/libpsio/error.cc on line: 131; The most recent 5 function calls were:. psi::PsiException::PsiException(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char const*, int); psi::PSIO::rw(unsigned long, char*, psi::psio_address, unsigned long, int); psi::PSIO::write(unsigned long, char const*, char*, unsigned long, psi::psio_address, psi::psio_address*). Aborted (core dumped); ```; stdout/stderr after this PR:; ```; PSIO_ERROR: unit = 34, errval = 12; terminate called after throwing an instance of 'psi::PsiException'; what():; Fatal Error: WRITE failed. Only some of the bytes were written!; Error writing the first partial page, unit 34.; PSIO_ERROR: 12 (error writing to file). Error occurred in file: /home/gytibor/psi4/psi4/src/psi4/libpsio/error.cc on line: 131; The most recent 5 function calls were:. psi::PsiException::PsiException(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char const*, int); psi::PSIO::rw(unsigned long, char*, psi::psio_address, unsigned long, int); psi::PSIO::write(unsigned long, char const*, char*, unsigned long, psi::psio_address, psi::psio_address*). Aborted (core dumped); ```; The reason why there is no ""disk is full"" error message, is because `SYSTEM_WRITE` only reports a failure and sets errno if the disk is already full when it is called. As long as it can write at least one out of _however many_ bytes it does not set errno. I both cases there is no e",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2756#issuecomment-1304899857
https://github.com/psi4/psi4/pull/2756#issuecomment-1304899857:541,Availability,error,error,541,"OK, I have finally managed to get a pair of builds (current master and this PR's branch) that do not entirely swallow the exception messages for write errors in the PK integral calculation. For me, it took building Psi4 entirely from source, with nothing from conda at all. stdout/stderr before this PR:. ```; PSIO_ERROR: unit = 34, errval = 12; terminate called after throwing an instance of 'psi::PsiException'; what():; Fatal Error: PSIO_ERROR: 12 (error writing to file). Error occurred in file: /home/gytibor/psi4/psi4/src/psi4/libpsio/error.cc on line: 131; The most recent 5 function calls were:. psi::PsiException::PsiException(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char const*, int); psi::PSIO::rw(unsigned long, char*, psi::psio_address, unsigned long, int); psi::PSIO::write(unsigned long, char const*, char*, unsigned long, psi::psio_address, psi::psio_address*). Aborted (core dumped); ```; stdout/stderr after this PR:; ```; PSIO_ERROR: unit = 34, errval = 12; terminate called after throwing an instance of 'psi::PsiException'; what():; Fatal Error: WRITE failed. Only some of the bytes were written!; Error writing the first partial page, unit 34.; PSIO_ERROR: 12 (error writing to file). Error occurred in file: /home/gytibor/psi4/psi4/src/psi4/libpsio/error.cc on line: 131; The most recent 5 function calls were:. psi::PsiException::PsiException(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char const*, int); psi::PSIO::rw(unsigned long, char*, psi::psio_address, unsigned long, int); psi::PSIO::write(unsigned long, char const*, char*, unsigned long, psi::psio_address, psi::psio_address*). Aborted (core dumped); ```; The reason why there is no ""disk is full"" error message, is because `SYSTEM_WRITE` only reports a failure and sets errno if the disk is already full when it is called. As long as it can write at least one out of _however many_ bytes it does not set errno. I both cases there is no e",MatchSource.ISSUE_COMMENT,psi4,psi4,v1.9.1,https://psicode.org,https://github.com/psi4/psi4/pull/2756#issuecomment-1304899857
